[
    {
        "rel_file_path": "django/db/models/sql/compiler.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__4.0/django/db/models/sql/compiler.py",
        "start": 1,
        "end": 1671,
        "class_name": null,
        "method_name": null,
        "code": "1 import collections\n2 import re\n3 from functools import partial\n4 from itertools import chain\n5 \n6 from django.core.exceptions import EmptyResultSet, FieldError\n7 from django.db import DatabaseError, NotSupportedError\n8 from django.db.models.constants import LOOKUP_SEP\n9 from django.db.models.expressions import F, OrderBy, RawSQL, Ref, Value\n10 from django.db.models.functions import Cast, Random\n11 from django.db.models.query_utils import Q, select_related_descend\n12 from django.db.models.sql.constants import (\n13     CURSOR, GET_ITERATOR_CHUNK_SIZE, MULTI, NO_RESULTS, ORDER_DIR, SINGLE,\n14 )\n15 from django.db.models.sql.query import Query, get_order_dir\n16 from django.db.transaction import TransactionManagementError\n17 from django.utils.functional import cached_property\n18 from django.utils.hashable import make_hashable\n19 from django.utils.regex_helper import _lazy_re_compile\n20 \n21 \n22 class SQLCompiler:\n23     # Multiline ordering SQL clause may appear from RawSQL.\n24     ordering_parts = _lazy_re_compile(\n25         r'^(.*)\\s(?:ASC|DESC).*',\n26         re.MULTILINE | re.DOTALL,\n27     )\n28 \n29     def __init__(self, query, connection, using):\n30         self.query = query\n31         self.connection = connection\n32         self.using = using\n33         self.quote_cache = {'*': '*'}\n34         # The select, klass_info, and annotations are needed by QuerySet.iterator()\n35         # these are set as a side-effect of executing the query. Note that we calculate\n36         # separately a list of extra select columns needed for grammatical correctness\n37         # of the query, but these columns are not included in self.select.\n38         self.select = None\n39         self.annotation_col_map = None\n40         self.klass_info = None\n41         self._meta_ordering = None\n42 \n43     def setup_query(self):\n44         if all(self.query.alias_refcount[a] == 0 for a in self.query.alias_map):\n45             self.query.get_initial_alias()\n46         self.select, self.klass_info, self.annotation_col_map = self.get_select()\n47         self.col_count = len(self.select)\n48 \n49     def pre_sql_setup(self):\n50         \"\"\"\n51         Do any necessary class setup immediately prior to producing SQL. This\n52         is for things that can't necessarily be done in __init__ because we\n53         might not have all the pieces in place at that time.\n54         \"\"\"\n55         self.setup_query()\n56         order_by = self.get_order_by()\n57         self.where, self.having = self.query.where.split_having()\n58         extra_select = self.get_extra_select(order_by, self.select)\n59         self.has_extra_select = bool(extra_select)\n60         group_by = self.get_group_by(self.select + extra_select, order_by)\n61         return extra_select, order_by, group_by\n62 \n63     def get_group_by(self, select, order_by):\n64         \"\"\"\n65         Return a list of 2-tuples of form (sql, params).\n66 \n67         The logic of what exactly the GROUP BY clause contains is hard\n68         to describe in other words than \"if it passes the test suite,\n69         then it is correct\".\n70         \"\"\"\n71         # Some examples:\n72         #     SomeModel.objects.annotate(Count('somecol'))\n73         #     GROUP BY: all fields of the model\n74         #\n75         #    SomeModel.objects.values('name').annotate(Count('somecol'))\n76         #    GROUP BY: name\n77         #\n78         #    SomeModel.objects.annotate(Count('somecol')).values('name')\n79         #    GROUP BY: all cols of the model\n80         #\n81         #    SomeModel.objects.values('name', 'pk').annotate(Count('somecol')).values('pk')\n82         #    GROUP BY: name, pk\n83         #\n84         #    SomeModel.objects.values('name').annotate(Count('somecol')).values('pk')\n85         #    GROUP BY: name, pk\n86         #\n87         # In fact, the self.query.group_by is the minimal set to GROUP BY. It\n88         # can't be ever restricted to a smaller set, but additional columns in\n89         # HAVING, ORDER BY, and SELECT clauses are added to it. Unfortunately\n90         # the end result is that it is impossible to force the query to have\n91         # a chosen GROUP BY clause - you can almost do this by using the form:\n92         #     .values(*wanted_cols).annotate(AnAggregate())\n93         # but any later annotations, extra selects, values calls that\n94         # refer some column outside of the wanted_cols, order_by, or even\n95         # filter calls can alter the GROUP BY clause.\n96 \n97         # The query.group_by is either None (no GROUP BY at all), True\n98         # (group by select fields), or a list of expressions to be added\n99         # to the group by.\n100         if self.query.group_by is None:\n101             return []\n102         expressions = []\n103         if self.query.group_by is not True:\n104             # If the group by is set to a list (by .values() call most likely),\n105             # then we need to add everything in it to the GROUP BY clause.\n106             # Backwards compatibility hack for setting query.group_by. Remove\n107             # when  we have public API way of forcing the GROUP BY clause.\n108             # Converts string references to expressions.\n109             for expr in self.query.group_by:\n110                 if not hasattr(expr, 'as_sql'):\n111                     expressions.append(self.query.resolve_ref(expr))\n112                 else:\n113                     expressions.append(expr)\n114         # Note that even if the group_by is set, it is only the minimal\n115         # set to group by. So, we need to add cols in select, order_by, and\n116         # having into the select in any case.\n117         ref_sources = {\n118             expr.source for expr in expressions if isinstance(expr, Ref)\n119         }\n120         for expr, _, _ in select:\n121             # Skip members of the select clause that are already included\n122             # by reference.\n123             if expr in ref_sources:\n124                 continue\n125             cols = expr.get_group_by_cols()\n126             for col in cols:\n127                 expressions.append(col)\n128         if not self._meta_ordering:\n129             for expr, (sql, params, is_ref) in order_by:\n130                 # Skip references to the SELECT clause, as all expressions in\n131                 # the SELECT clause are already part of the GROUP BY.\n132                 if not is_ref:\n133                     expressions.extend(expr.get_group_by_cols())\n134         having_group_by = self.having.get_group_by_cols() if self.having else ()\n135         for expr in having_group_by:\n136             expressions.append(expr)\n137         result = []\n138         seen = set()\n139         expressions = self.collapse_group_by(expressions, having_group_by)\n140 \n141         for expr in expressions:\n142             sql, params = self.compile(expr)\n143             sql, params = expr.select_format(self, sql, params)\n144             params_hash = make_hashable(params)\n145             if (sql, params_hash) not in seen:\n146                 result.append((sql, params))\n147                 seen.add((sql, params_hash))\n148         return result\n149 \n150     def collapse_group_by(self, expressions, having):\n151         # If the DB can group by primary key, then group by the primary key of\n152         # query's main model. Note that for PostgreSQL the GROUP BY clause must\n153         # include the primary key of every table, but for MySQL it is enough to\n154         # have the main table's primary key.\n155         if self.connection.features.allows_group_by_pk:\n156             # Determine if the main model's primary key is in the query.\n157             pk = None\n158             for expr in expressions:\n159                 # Is this a reference to query's base table primary key? If the\n160                 # expression isn't a Col-like, then skip the expression.\n161                 if (getattr(expr, 'target', None) == self.query.model._meta.pk and\n162                         getattr(expr, 'alias', None) == self.query.base_table):\n163                     pk = expr\n164                     break\n165             # If the main model's primary key is in the query, group by that\n166             # field, HAVING expressions, and expressions associated with tables\n167             # that don't have a primary key included in the grouped columns.\n168             if pk:\n169                 pk_aliases = {\n170                     expr.alias for expr in expressions\n171                     if hasattr(expr, 'target') and expr.target.primary_key\n172                 }\n173                 expressions = [pk] + [\n174                     expr for expr in expressions\n175                     if expr in having or (\n176                         getattr(expr, 'alias', None) is not None and expr.alias not in pk_aliases\n177                     )\n178                 ]\n179         elif self.connection.features.allows_group_by_selected_pks:\n180             # Filter out all expressions associated with a table's primary key\n181             # present in the grouped columns. This is done by identifying all\n182             # tables that have their primary key included in the grouped\n183             # columns and removing non-primary key columns referring to them.\n184             # Unmanaged models are excluded because they could be representing\n185             # database views on which the optimization might not be allowed.\n186             pks = {\n187                 expr for expr in expressions\n188                 if (\n189                     hasattr(expr, 'target') and\n190                     expr.target.primary_key and\n191                     self.connection.features.allows_group_by_selected_pks_on_model(expr.target.model)\n192                 )\n193             }\n194             aliases = {expr.alias for expr in pks}\n195             expressions = [\n196                 expr for expr in expressions if expr in pks or getattr(expr, 'alias', None) not in aliases\n197             ]\n198         return expressions\n199 \n200     def get_select(self):\n201         \"\"\"\n202         Return three values:\n203         - a list of 3-tuples of (expression, (sql, params), alias)\n204         - a klass_info structure,\n205         - a dictionary of annotations\n206 \n207         The (sql, params) is what the expression will produce, and alias is the\n208         \"AS alias\" for the column (possibly None).\n209 \n210         The klass_info structure contains the following information:\n211         - The base model of the query.\n212         - Which columns for that model are present in the query (by\n213           position of the select clause).\n214         - related_klass_infos: [f, klass_info] to descent into\n215 \n216         The annotations is a dictionary of {'attname': column position} values.\n217         \"\"\"\n218         select = []\n219         klass_info = None\n220         annotations = {}\n221         select_idx = 0\n222         for alias, (sql, params) in self.query.extra_select.items():\n223             annotations[alias] = select_idx\n224             select.append((RawSQL(sql, params), alias))\n225             select_idx += 1\n226         assert not (self.query.select and self.query.default_cols)\n227         if self.query.default_cols:\n228             cols = self.get_default_columns()\n229         else:\n230             # self.query.select is a special case. These columns never go to\n231             # any model.\n232             cols = self.query.select\n233         if cols:\n234             select_list = []\n235             for col in cols:\n236                 select_list.append(select_idx)\n237                 select.append((col, None))\n238                 select_idx += 1\n239             klass_info = {\n240                 'model': self.query.model,\n241                 'select_fields': select_list,\n242             }\n243         for alias, annotation in self.query.annotation_select.items():\n244             annotations[alias] = select_idx\n245             select.append((annotation, alias))\n246             select_idx += 1\n247 \n248         if self.query.select_related:\n249             related_klass_infos = self.get_related_selections(select)\n250             klass_info['related_klass_infos'] = related_klass_infos\n251 \n252             def get_select_from_parent(klass_info):\n253                 for ki in klass_info['related_klass_infos']:\n254                     if ki['from_parent']:\n255                         ki['select_fields'] = (klass_info['select_fields'] +\n256                                                ki['select_fields'])\n257                     get_select_from_parent(ki)\n258             get_select_from_parent(klass_info)\n259 \n260         ret = []\n261         for col, alias in select:\n262             try:\n263                 sql, params = self.compile(col)\n264             except EmptyResultSet:\n265                 # Select a predicate that's always False.\n266                 sql, params = '0', ()\n267             else:\n268                 sql, params = col.select_format(self, sql, params)\n269             ret.append((col, (sql, params), alias))\n270         return ret, klass_info, annotations\n271 \n272     def _order_by_pairs(self):\n273         if self.query.extra_order_by:\n274             ordering = self.query.extra_order_by\n275         elif not self.query.default_ordering:\n276             ordering = self.query.order_by\n277         elif self.query.order_by:\n278             ordering = self.query.order_by\n279         elif self.query.get_meta().ordering:\n280             ordering = self.query.get_meta().ordering\n281             self._meta_ordering = ordering\n282         else:\n283             ordering = []\n284         if self.query.standard_ordering:\n285             default_order, _ = ORDER_DIR['ASC']\n286         else:\n287             default_order, _ = ORDER_DIR['DESC']\n288 \n289         for field in ordering:\n290             if hasattr(field, 'resolve_expression'):\n291                 if isinstance(field, Value):\n292                     # output_field must be resolved for constants.\n293                     field = Cast(field, field.output_field)\n294                 if not isinstance(field, OrderBy):\n295                     field = field.asc()\n296                 if not self.query.standard_ordering:\n297                     field = field.copy()\n298                     field.reverse_ordering()\n299                 yield field, False\n300                 continue\n301             if field == '?':  # random\n302                 yield OrderBy(Random()), False\n303                 continue\n304 \n305             col, order = get_order_dir(field, default_order)\n306             descending = order == 'DESC'\n307 \n308             if col in self.query.annotation_select:\n309                 # Reference to expression in SELECT clause\n310                 yield (\n311                     OrderBy(\n312                         Ref(col, self.query.annotation_select[col]),\n313                         descending=descending,\n314                     ),\n315                     True,\n316                 )\n317                 continue\n318             if col in self.query.annotations:\n319                 # References to an expression which is masked out of the SELECT\n320                 # clause.\n321                 if self.query.combinator and self.select:\n322                     # Don't use the resolved annotation because other\n323                     # combinated queries might define it differently.\n324                     expr = F(col)\n325                 else:\n326                     expr = self.query.annotations[col]\n327                     if isinstance(expr, Value):\n328                         # output_field must be resolved for constants.\n329                         expr = Cast(expr, expr.output_field)\n330                 yield OrderBy(expr, descending=descending), False\n331                 continue\n332 \n333             if '.' in field:\n334                 # This came in through an extra(order_by=...) addition. Pass it\n335                 # on verbatim.\n336                 table, col = col.split('.', 1)\n337                 yield (\n338                     OrderBy(\n339                         RawSQL('%s.%s' % (self.quote_name_unless_alias(table), col), []),\n340                         descending=descending,\n341                     ),\n342                     False,\n343                 )\n344                 continue\n345 \n346             if self.query.extra and col in self.query.extra:\n347                 if col in self.query.extra_select:\n348                     yield (\n349                         OrderBy(Ref(col, RawSQL(*self.query.extra[col])), descending=descending),\n350                         True,\n351                     )\n352                 else:\n353                     yield (\n354                         OrderBy(RawSQL(*self.query.extra[col]), descending=descending),\n355                         False,\n356                     )\n357             else:\n358                 if self.query.combinator and self.select:\n359                     # Don't use the first model's field because other\n360                     # combinated queries might define it differently.\n361                     yield OrderBy(F(col), descending=descending), False\n362                 else:\n363                     # 'col' is of the form 'field' or 'field1__field2' or\n364                     # '-field1__field2__field', etc.\n365                     yield from self.find_ordering_name(\n366                         field, self.query.get_meta(), default_order=default_order,\n367                     )\n368 \n369     def get_order_by(self):\n370         \"\"\"\n371         Return a list of 2-tuples of the form (expr, (sql, params, is_ref)) for\n372         the ORDER BY clause.\n373 \n374         The order_by clause can alter the select clause (for example it can add\n375         aliases to clauses that do not yet have one, or it can add totally new\n376         select clauses).\n377         \"\"\"\n378         result = []\n379         seen = set()\n380 \n381         for expr, is_ref in self._order_by_pairs():\n382             resolved = expr.resolve_expression(self.query, allow_joins=True, reuse=None)\n383             if self.query.combinator and self.select:\n384                 src = resolved.get_source_expressions()[0]\n385                 expr_src = expr.get_source_expressions()[0]\n386                 # Relabel order by columns to raw numbers if this is a combined\n387                 # query; necessary since the columns can't be referenced by the\n388                 # fully qualified name and the simple column names may collide.\n389                 for idx, (sel_expr, _, col_alias) in enumerate(self.select):\n390                     if is_ref and col_alias == src.refs:\n391                         src = src.source\n392                     elif col_alias and not (\n393                         isinstance(expr_src, F) and col_alias == expr_src.name\n394                     ):\n395                         continue\n396                     if src == sel_expr:\n397                         resolved.set_source_expressions([RawSQL('%d' % (idx + 1), ())])\n398                         break\n399                 else:\n400                     if col_alias:\n401                         raise DatabaseError('ORDER BY term does not match any column in the result set.')\n402                     # Add column used in ORDER BY clause to the selected\n403                     # columns and to each combined query.\n404                     order_by_idx = len(self.query.select) + 1\n405                     col_name = f'__orderbycol{order_by_idx}'\n406                     for q in self.query.combined_queries:\n407                         q.add_annotation(expr_src, col_name)\n408                     self.query.add_select_col(resolved, col_name)\n409                     resolved.set_source_expressions([RawSQL(f'{order_by_idx}', ())])\n410             sql, params = self.compile(resolved)\n411             # Don't add the same column twice, but the order direction is\n412             # not taken into account so we strip it. When this entire method\n413             # is refactored into expressions, then we can check each part as we\n414             # generate it.\n415             without_ordering = self.ordering_parts.search(sql)[1]\n416             params_hash = make_hashable(params)\n417             if (without_ordering, params_hash) in seen:\n418                 continue\n419             seen.add((without_ordering, params_hash))\n420             result.append((resolved, (sql, params, is_ref)))\n421         return result\n422 \n423     def get_extra_select(self, order_by, select):\n424         extra_select = []\n425         if self.query.distinct and not self.query.distinct_fields:\n426             select_sql = [t[1] for t in select]\n427             for expr, (sql, params, is_ref) in order_by:\n428                 without_ordering = self.ordering_parts.search(sql)[1]\n429                 if not is_ref and (without_ordering, params) not in select_sql:\n430                     extra_select.append((expr, (without_ordering, params), None))\n431         return extra_select\n432 \n433     def quote_name_unless_alias(self, name):\n434         \"\"\"\n435         A wrapper around connection.ops.quote_name that doesn't quote aliases\n436         for table names. This avoids problems with some SQL dialects that treat\n437         quoted strings specially (e.g. PostgreSQL).\n438         \"\"\"\n439         if name in self.quote_cache:\n440             return self.quote_cache[name]\n441         if ((name in self.query.alias_map and name not in self.query.table_map) or\n442                 name in self.query.extra_select or (\n443                     self.query.external_aliases.get(name) and name not in self.query.table_map)):\n444             self.quote_cache[name] = name\n445             return name\n446         r = self.connection.ops.quote_name(name)\n447         self.quote_cache[name] = r\n448         return r\n449 \n450     def compile(self, node):\n451         vendor_impl = getattr(node, 'as_' + self.connection.vendor, None)\n452         if vendor_impl:\n453             sql, params = vendor_impl(self, self.connection)\n454         else:\n455             sql, params = node.as_sql(self, self.connection)\n456         return sql, params\n457 \n458     def get_combinator_sql(self, combinator, all):\n459         features = self.connection.features\n460         compilers = [\n461             query.get_compiler(self.using, self.connection)\n462             for query in self.query.combined_queries if not query.is_empty()\n463         ]\n464         if not features.supports_slicing_ordering_in_compound:\n465             for query, compiler in zip(self.query.combined_queries, compilers):\n466                 if query.low_mark or query.high_mark:\n467                     raise DatabaseError('LIMIT/OFFSET not allowed in subqueries of compound statements.')\n468                 if compiler.get_order_by():\n469                     raise DatabaseError('ORDER BY not allowed in subqueries of compound statements.')\n470         parts = ()\n471         for compiler in compilers:\n472             try:\n473                 # If the columns list is limited, then all combined queries\n474                 # must have the same columns list. Set the selects defined on\n475                 # the query on all combined queries, if not already set.\n476                 if not compiler.query.values_select and self.query.values_select:\n477                     compiler.query = compiler.query.clone()\n478                     compiler.query.set_values((\n479                         *self.query.extra_select,\n480                         *self.query.values_select,\n481                         *self.query.annotation_select,\n482                     ))\n483                 part_sql, part_args = compiler.as_sql()\n484                 if compiler.query.combinator:\n485                     # Wrap in a subquery if wrapping in parentheses isn't\n486                     # supported.\n487                     if not features.supports_parentheses_in_compound:\n488                         part_sql = 'SELECT * FROM ({})'.format(part_sql)\n489                     # Add parentheses when combining with compound query if not\n490                     # already added for all compound queries.\n491                     elif not features.supports_slicing_ordering_in_compound:\n492                         part_sql = '({})'.format(part_sql)\n493                 parts += ((part_sql, part_args),)\n494             except EmptyResultSet:\n495                 # Omit the empty queryset with UNION and with DIFFERENCE if the\n496                 # first queryset is nonempty.\n497                 if combinator == 'union' or (combinator == 'difference' and parts):\n498                     continue\n499                 raise\n500         if not parts:\n501             raise EmptyResultSet\n502         combinator_sql = self.connection.ops.set_operators[combinator]\n503         if all and combinator == 'union':\n504             combinator_sql += ' ALL'\n505         braces = '({})' if features.supports_slicing_ordering_in_compound else '{}'\n506         sql_parts, args_parts = zip(*((braces.format(sql), args) for sql, args in parts))\n507         result = [' {} '.format(combinator_sql).join(sql_parts)]\n508         params = []\n509         for part in args_parts:\n510             params.extend(part)\n511         return result, params\n512 \n513     def as_sql(self, with_limits=True, with_col_aliases=False):\n514         \"\"\"\n515         Create the SQL for this query. Return the SQL string and list of\n516         parameters.\n517 \n518         If 'with_limits' is False, any limit/offset information is not included\n519         in the query.\n520         \"\"\"\n521         refcounts_before = self.query.alias_refcount.copy()\n522         try:\n523             extra_select, order_by, group_by = self.pre_sql_setup()\n524             for_update_part = None\n525             # Is a LIMIT/OFFSET clause needed?\n526             with_limit_offset = with_limits and (self.query.high_mark is not None or self.query.low_mark)\n527             combinator = self.query.combinator\n528             features = self.connection.features\n529             if combinator:\n530                 if not getattr(features, 'supports_select_{}'.format(combinator)):\n531                     raise NotSupportedError('{} is not supported on this database backend.'.format(combinator))\n532                 result, params = self.get_combinator_sql(combinator, self.query.combinator_all)\n533             else:\n534                 distinct_fields, distinct_params = self.get_distinct()\n535                 # This must come after 'select', 'ordering', and 'distinct'\n536                 # (see docstring of get_from_clause() for details).\n537                 from_, f_params = self.get_from_clause()\n538                 where, w_params = self.compile(self.where) if self.where is not None else (\"\", [])\n539                 having, h_params = self.compile(self.having) if self.having is not None else (\"\", [])\n540                 result = ['SELECT']\n541                 params = []\n542 \n543                 if self.query.distinct:\n544                     distinct_result, distinct_params = self.connection.ops.distinct_sql(\n545                         distinct_fields,\n546                         distinct_params,\n547                     )\n548                     result += distinct_result\n549                     params += distinct_params\n550 \n551                 out_cols = []\n552                 col_idx = 1\n553                 for _, (s_sql, s_params), alias in self.select + extra_select:\n554                     if alias:\n555                         s_sql = '%s AS %s' % (s_sql, self.connection.ops.quote_name(alias))\n556                     elif with_col_aliases:\n557                         s_sql = '%s AS %s' % (\n558                             s_sql,\n559                             self.connection.ops.quote_name('col%d' % col_idx),\n560                         )\n561                         col_idx += 1\n562                     params.extend(s_params)\n563                     out_cols.append(s_sql)\n564 \n565                 result += [', '.join(out_cols), 'FROM', *from_]\n566                 params.extend(f_params)\n567 \n568                 if self.query.select_for_update and self.connection.features.has_select_for_update:\n569                     if self.connection.get_autocommit():\n570                         raise TransactionManagementError('select_for_update cannot be used outside of a transaction.')\n571 \n572                     if with_limit_offset and not self.connection.features.supports_select_for_update_with_limit:\n573                         raise NotSupportedError(\n574                             'LIMIT/OFFSET is not supported with '\n575                             'select_for_update on this database backend.'\n576                         )\n577                     nowait = self.query.select_for_update_nowait\n578                     skip_locked = self.query.select_for_update_skip_locked\n579                     of = self.query.select_for_update_of\n580                     no_key = self.query.select_for_no_key_update\n581                     # If it's a NOWAIT/SKIP LOCKED/OF/NO KEY query but the\n582                     # backend doesn't support it, raise NotSupportedError to\n583                     # prevent a possible deadlock.\n584                     if nowait and not self.connection.features.has_select_for_update_nowait:\n585                         raise NotSupportedError('NOWAIT is not supported on this database backend.')\n586                     elif skip_locked and not self.connection.features.has_select_for_update_skip_locked:\n587                         raise NotSupportedError('SKIP LOCKED is not supported on this database backend.')\n588                     elif of and not self.connection.features.has_select_for_update_of:\n589                         raise NotSupportedError('FOR UPDATE OF is not supported on this database backend.')\n590                     elif no_key and not self.connection.features.has_select_for_no_key_update:\n591                         raise NotSupportedError(\n592                             'FOR NO KEY UPDATE is not supported on this '\n593                             'database backend.'\n594                         )\n595                     for_update_part = self.connection.ops.for_update_sql(\n596                         nowait=nowait,\n597                         skip_locked=skip_locked,\n598                         of=self.get_select_for_update_of_arguments(),\n599                         no_key=no_key,\n600                     )\n601 \n602                 if for_update_part and self.connection.features.for_update_after_from:\n603                     result.append(for_update_part)\n604 \n605                 if where:\n606                     result.append('WHERE %s' % where)\n607                     params.extend(w_params)\n608 \n609                 grouping = []\n610                 for g_sql, g_params in group_by:\n611                     grouping.append(g_sql)\n612                     params.extend(g_params)\n613                 if grouping:\n614                     if distinct_fields:\n615                         raise NotImplementedError('annotate() + distinct(fields) is not implemented.')\n616                     order_by = order_by or self.connection.ops.force_no_ordering()\n617                     result.append('GROUP BY %s' % ', '.join(grouping))\n618                     if self._meta_ordering:\n619                         order_by = None\n620                 if having:\n621                     result.append('HAVING %s' % having)\n622                     params.extend(h_params)\n623 \n624             if self.query.explain_query:\n625                 result.insert(0, self.connection.ops.explain_query_prefix(\n626                     self.query.explain_format,\n627                     **self.query.explain_options\n628                 ))\n629 \n630             if order_by:\n631                 ordering = []\n632                 for _, (o_sql, o_params, _) in order_by:\n633                     ordering.append(o_sql)\n634                     params.extend(o_params)\n635                 result.append('ORDER BY %s' % ', '.join(ordering))\n636 \n637             if with_limit_offset:\n638                 result.append(self.connection.ops.limit_offset_sql(self.query.low_mark, self.query.high_mark))\n639 \n640             if for_update_part and not self.connection.features.for_update_after_from:\n641                 result.append(for_update_part)\n642 \n643             if self.query.subquery and extra_select:\n644                 # If the query is used as a subquery, the extra selects would\n645                 # result in more columns than the left-hand side expression is\n646                 # expecting. This can happen when a subquery uses a combination\n647                 # of order_by() and distinct(), forcing the ordering expressions\n648                 # to be selected as well. Wrap the query in another subquery\n649                 # to exclude extraneous selects.\n650                 sub_selects = []\n651                 sub_params = []\n652                 for index, (select, _, alias) in enumerate(self.select, start=1):\n653                     if not alias and with_col_aliases:\n654                         alias = 'col%d' % index\n655                     if alias:\n656                         sub_selects.append(\"%s.%s\" % (\n657                             self.connection.ops.quote_name('subquery'),\n658                             self.connection.ops.quote_name(alias),\n659                         ))\n660                     else:\n661                         select_clone = select.relabeled_clone({select.alias: 'subquery'})\n662                         subselect, subparams = select_clone.as_sql(self, self.connection)\n663                         sub_selects.append(subselect)\n664                         sub_params.extend(subparams)\n665                 return 'SELECT %s FROM (%s) subquery' % (\n666                     ', '.join(sub_selects),\n667                     ' '.join(result),\n668                 ), tuple(sub_params + params)\n669 \n670             return ' '.join(result), tuple(params)\n671         finally:\n672             # Finally do cleanup - get rid of the joins we created above.\n673             self.query.reset_refcounts(refcounts_before)\n674 \n675     def get_default_columns(self, start_alias=None, opts=None, from_parent=None):\n676         \"\"\"\n677         Compute the default columns for selecting every field in the base\n678         model. Will sometimes be called to pull in related models (e.g. via\n679         select_related), in which case \"opts\" and \"start_alias\" will be given\n680         to provide a starting point for the traversal.\n681 \n682         Return a list of strings, quoted appropriately for use in SQL\n683         directly, as well as a set of aliases used in the select statement (if\n684         'as_pairs' is True, return a list of (alias, col_name) pairs instead\n685         of strings as the first component and None as the second component).\n686         \"\"\"\n687         result = []\n688         if opts is None:\n689             opts = self.query.get_meta()\n690         only_load = self.deferred_to_columns()\n691         start_alias = start_alias or self.query.get_initial_alias()\n692         # The 'seen_models' is used to optimize checking the needed parent\n693         # alias for a given field. This also includes None -> start_alias to\n694         # be used by local fields.\n695         seen_models = {None: start_alias}\n696 \n697         for field in opts.concrete_fields:\n698             model = field.model._meta.concrete_model\n699             # A proxy model will have a different model and concrete_model. We\n700             # will assign None if the field belongs to this model.\n701             if model == opts.model:\n702                 model = None\n703             if from_parent and model is not None and issubclass(\n704                     from_parent._meta.concrete_model, model._meta.concrete_model):\n705                 # Avoid loading data for already loaded parents.\n706                 # We end up here in the case select_related() resolution\n707                 # proceeds from parent model to child model. In that case the\n708                 # parent model data is already present in the SELECT clause,\n709                 # and we want to avoid reloading the same data again.\n710                 continue\n711             if field.model in only_load and field.attname not in only_load[field.model]:\n712                 continue\n713             alias = self.query.join_parent_model(opts, model, start_alias,\n714                                                  seen_models)\n715             column = field.get_col(alias)\n716             result.append(column)\n717         return result\n718 \n719     def get_distinct(self):\n720         \"\"\"\n721         Return a quoted list of fields to use in DISTINCT ON part of the query.\n722 \n723         This method can alter the tables in the query, and thus it must be\n724         called before get_from_clause().\n725         \"\"\"\n726         result = []\n727         params = []\n728         opts = self.query.get_meta()\n729 \n730         for name in self.query.distinct_fields:\n731             parts = name.split(LOOKUP_SEP)\n732             _, targets, alias, joins, path, _, transform_function = self._setup_joins(parts, opts, None)\n733             targets, alias, _ = self.query.trim_joins(targets, joins, path)\n734             for target in targets:\n735                 if name in self.query.annotation_select:\n736                     result.append(name)\n737                 else:\n738                     r, p = self.compile(transform_function(target, alias))\n739                     result.append(r)\n740                     params.append(p)\n741         return result, params\n742 \n743     def find_ordering_name(self, name, opts, alias=None, default_order='ASC',\n744                            already_seen=None):\n745         \"\"\"\n746         Return the table alias (the name might be ambiguous, the alias will\n747         not be) and column name for ordering by the given 'name' parameter.\n748         The 'name' is of the form 'field1__field2__...__fieldN'.\n749         \"\"\"\n750         name, order = get_order_dir(name, default_order)\n751         descending = order == 'DESC'\n752         pieces = name.split(LOOKUP_SEP)\n753         field, targets, alias, joins, path, opts, transform_function = self._setup_joins(pieces, opts, alias)\n754 \n755         # If we get to this point and the field is a relation to another model,\n756         # append the default ordering for that model unless it is the pk\n757         # shortcut or the attribute name of the field that is specified.\n758         if (\n759             field.is_relation and\n760             opts.ordering and\n761             getattr(field, 'attname', None) != pieces[-1] and\n762             name != 'pk'\n763         ):\n764             # Firstly, avoid infinite loops.\n765             already_seen = already_seen or set()\n766             join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)\n767             if join_tuple in already_seen:\n768                 raise FieldError('Infinite loop caused by ordering.')\n769             already_seen.add(join_tuple)\n770 \n771             results = []\n772             for item in opts.ordering:\n773                 if hasattr(item, 'resolve_expression') and not isinstance(item, OrderBy):\n774                     item = item.desc() if descending else item.asc()\n775                 if isinstance(item, OrderBy):\n776                     results.append((item, False))\n777                     continue\n778                 results.extend(self.find_ordering_name(item, opts, alias,\n779                                                        order, already_seen))\n780             return results\n781         targets, alias, _ = self.query.trim_joins(targets, joins, path)\n782         return [(OrderBy(transform_function(t, alias), descending=descending), False) for t in targets]\n783 \n784     def _setup_joins(self, pieces, opts, alias):\n785         \"\"\"\n786         Helper method for get_order_by() and get_distinct().\n787 \n788         get_ordering() and get_distinct() must produce same target columns on\n789         same input, as the prefixes of get_ordering() and get_distinct() must\n790         match. Executing SQL where this is not true is an error.\n791         \"\"\"\n792         alias = alias or self.query.get_initial_alias()\n793         field, targets, opts, joins, path, transform_function = self.query.setup_joins(pieces, opts, alias)\n794         alias = joins[-1]\n795         return field, targets, alias, joins, path, opts, transform_function\n796 \n797     def get_from_clause(self):\n798         \"\"\"\n799         Return a list of strings that are joined together to go after the\n800         \"FROM\" part of the query, as well as a list any extra parameters that\n801         need to be included. Subclasses, can override this to create a\n802         from-clause via a \"select\".\n803 \n804         This should only be called after any SQL construction methods that\n805         might change the tables that are needed. This means the select columns,\n806         ordering, and distinct must be done first.\n807         \"\"\"\n808         result = []\n809         params = []\n810         for alias in tuple(self.query.alias_map):\n811             if not self.query.alias_refcount[alias]:\n812                 continue\n813             try:\n814                 from_clause = self.query.alias_map[alias]\n815             except KeyError:\n816                 # Extra tables can end up in self.tables, but not in the\n817                 # alias_map if they aren't in a join. That's OK. We skip them.\n818                 continue\n819             clause_sql, clause_params = self.compile(from_clause)\n820             result.append(clause_sql)\n821             params.extend(clause_params)\n822         for t in self.query.extra_tables:\n823             alias, _ = self.query.table_alias(t)\n824             # Only add the alias if it's not already present (the table_alias()\n825             # call increments the refcount, so an alias refcount of one means\n826             # this is the only reference).\n827             if alias not in self.query.alias_map or self.query.alias_refcount[alias] == 1:\n828                 result.append(', %s' % self.quote_name_unless_alias(alias))\n829         return result, params\n830 \n831     def get_related_selections(self, select, opts=None, root_alias=None, cur_depth=1,\n832                                requested=None, restricted=None):\n833         \"\"\"\n834         Fill in the information needed for a select_related query. The current\n835         depth is measured as the number of connections away from the root model\n836         (for example, cur_depth=1 means we are looking at models with direct\n837         connections to the root model).\n838         \"\"\"\n839         def _get_field_choices():\n840             direct_choices = (f.name for f in opts.fields if f.is_relation)\n841             reverse_choices = (\n842                 f.field.related_query_name()\n843                 for f in opts.related_objects if f.field.unique\n844             )\n845             return chain(direct_choices, reverse_choices, self.query._filtered_relations)\n846 \n847         related_klass_infos = []\n848         if not restricted and cur_depth > self.query.max_depth:\n849             # We've recursed far enough; bail out.\n850             return related_klass_infos\n851 \n852         if not opts:\n853             opts = self.query.get_meta()\n854             root_alias = self.query.get_initial_alias()\n855         only_load = self.query.get_loaded_field_names()\n856 \n857         # Setup for the case when only particular related fields should be\n858         # included in the related selection.\n859         fields_found = set()\n860         if requested is None:\n861             restricted = isinstance(self.query.select_related, dict)\n862             if restricted:\n863                 requested = self.query.select_related\n864 \n865         def get_related_klass_infos(klass_info, related_klass_infos):\n866             klass_info['related_klass_infos'] = related_klass_infos\n867 \n868         for f in opts.fields:\n869             field_model = f.model._meta.concrete_model\n870             fields_found.add(f.name)\n871 \n872             if restricted:\n873                 next = requested.get(f.name, {})\n874                 if not f.is_relation:\n875                     # If a non-related field is used like a relation,\n876                     # or if a single non-relational field is given.\n877                     if next or f.name in requested:\n878                         raise FieldError(\n879                             \"Non-relational field given in select_related: '%s'. \"\n880                             \"Choices are: %s\" % (\n881                                 f.name,\n882                                 \", \".join(_get_field_choices()) or '(none)',\n883                             )\n884                         )\n885             else:\n886                 next = False\n887 \n888             if not select_related_descend(f, restricted, requested,\n889                                           only_load.get(field_model)):\n890                 continue\n891             klass_info = {\n892                 'model': f.remote_field.model,\n893                 'field': f,\n894                 'reverse': False,\n895                 'local_setter': f.set_cached_value,\n896                 'remote_setter': f.remote_field.set_cached_value if f.unique else lambda x, y: None,\n897                 'from_parent': False,\n898             }\n899             related_klass_infos.append(klass_info)\n900             select_fields = []\n901             _, _, _, joins, _, _ = self.query.setup_joins(\n902                 [f.name], opts, root_alias)\n903             alias = joins[-1]\n904             columns = self.get_default_columns(start_alias=alias, opts=f.remote_field.model._meta)\n905             for col in columns:\n906                 select_fields.append(len(select))\n907                 select.append((col, None))\n908             klass_info['select_fields'] = select_fields\n909             next_klass_infos = self.get_related_selections(\n910                 select, f.remote_field.model._meta, alias, cur_depth + 1, next, restricted)\n911             get_related_klass_infos(klass_info, next_klass_infos)\n912 \n913         if restricted:\n914             related_fields = [\n915                 (o.field, o.related_model)\n916                 for o in opts.related_objects\n917                 if o.field.unique and not o.many_to_many\n918             ]\n919             for f, model in related_fields:\n920                 if not select_related_descend(f, restricted, requested,\n921                                               only_load.get(model), reverse=True):\n922                     continue\n923 \n924                 related_field_name = f.related_query_name()\n925                 fields_found.add(related_field_name)\n926 \n927                 join_info = self.query.setup_joins([related_field_name], opts, root_alias)\n928                 alias = join_info.joins[-1]\n929                 from_parent = issubclass(model, opts.model) and model is not opts.model\n930                 klass_info = {\n931                     'model': model,\n932                     'field': f,\n933                     'reverse': True,\n934                     'local_setter': f.remote_field.set_cached_value,\n935                     'remote_setter': f.set_cached_value,\n936                     'from_parent': from_parent,\n937                 }\n938                 related_klass_infos.append(klass_info)\n939                 select_fields = []\n940                 columns = self.get_default_columns(\n941                     start_alias=alias, opts=model._meta, from_parent=opts.model)\n942                 for col in columns:\n943                     select_fields.append(len(select))\n944                     select.append((col, None))\n945                 klass_info['select_fields'] = select_fields\n946                 next = requested.get(f.related_query_name(), {})\n947                 next_klass_infos = self.get_related_selections(\n948                     select, model._meta, alias, cur_depth + 1,\n949                     next, restricted)\n950                 get_related_klass_infos(klass_info, next_klass_infos)\n951 \n952             def local_setter(obj, from_obj):\n953                 # Set a reverse fk object when relation is non-empty.\n954                 if from_obj:\n955                     f.remote_field.set_cached_value(from_obj, obj)\n956 \n957             def remote_setter(name, obj, from_obj):\n958                 setattr(from_obj, name, obj)\n959 \n960             for name in list(requested):\n961                 # Filtered relations work only on the topmost level.\n962                 if cur_depth > 1:\n963                     break\n964                 if name in self.query._filtered_relations:\n965                     fields_found.add(name)\n966                     f, _, join_opts, joins, _, _ = self.query.setup_joins([name], opts, root_alias)\n967                     model = join_opts.model\n968                     alias = joins[-1]\n969                     from_parent = issubclass(model, opts.model) and model is not opts.model\n970                     klass_info = {\n971                         'model': model,\n972                         'field': f,\n973                         'reverse': True,\n974                         'local_setter': local_setter,\n975                         'remote_setter': partial(remote_setter, name),\n976                         'from_parent': from_parent,\n977                     }\n978                     related_klass_infos.append(klass_info)\n979                     select_fields = []\n980                     columns = self.get_default_columns(\n981                         start_alias=alias, opts=model._meta,\n982                         from_parent=opts.model,\n983                     )\n984                     for col in columns:\n985                         select_fields.append(len(select))\n986                         select.append((col, None))\n987                     klass_info['select_fields'] = select_fields\n988                     next_requested = requested.get(name, {})\n989                     next_klass_infos = self.get_related_selections(\n990                         select, opts=model._meta, root_alias=alias,\n991                         cur_depth=cur_depth + 1, requested=next_requested,\n992                         restricted=restricted,\n993                     )\n994                     get_related_klass_infos(klass_info, next_klass_infos)\n995             fields_not_found = set(requested).difference(fields_found)\n996             if fields_not_found:\n997                 invalid_fields = (\"'%s'\" % s for s in fields_not_found)\n998                 raise FieldError(\n999                     'Invalid field name(s) given in select_related: %s. '\n1000                     'Choices are: %s' % (\n1001                         ', '.join(invalid_fields),\n1002                         ', '.join(_get_field_choices()) or '(none)',\n1003                     )\n1004                 )\n1005         return related_klass_infos\n1006 \n1007     def get_select_for_update_of_arguments(self):\n1008         \"\"\"\n1009         Return a quoted list of arguments for the SELECT FOR UPDATE OF part of\n1010         the query.\n1011         \"\"\"\n1012         def _get_parent_klass_info(klass_info):\n1013             concrete_model = klass_info['model']._meta.concrete_model\n1014             for parent_model, parent_link in concrete_model._meta.parents.items():\n1015                 parent_list = parent_model._meta.get_parent_list()\n1016                 yield {\n1017                     'model': parent_model,\n1018                     'field': parent_link,\n1019                     'reverse': False,\n1020                     'select_fields': [\n1021                         select_index\n1022                         for select_index in klass_info['select_fields']\n1023                         # Selected columns from a model or its parents.\n1024                         if (\n1025                             self.select[select_index][0].target.model == parent_model or\n1026                             self.select[select_index][0].target.model in parent_list\n1027                         )\n1028                     ],\n1029                 }\n1030 \n1031         def _get_first_selected_col_from_model(klass_info):\n1032             \"\"\"\n1033             Find the first selected column from a model. If it doesn't exist,\n1034             don't lock a model.\n1035 \n1036             select_fields is filled recursively, so it also contains fields\n1037             from the parent models.\n1038             \"\"\"\n1039             concrete_model = klass_info['model']._meta.concrete_model\n1040             for select_index in klass_info['select_fields']:\n1041                 if self.select[select_index][0].target.model == concrete_model:\n1042                     return self.select[select_index][0]\n1043 \n1044         def _get_field_choices():\n1045             \"\"\"Yield all allowed field paths in breadth-first search order.\"\"\"\n1046             queue = collections.deque([(None, self.klass_info)])\n1047             while queue:\n1048                 parent_path, klass_info = queue.popleft()\n1049                 if parent_path is None:\n1050                     path = []\n1051                     yield 'self'\n1052                 else:\n1053                     field = klass_info['field']\n1054                     if klass_info['reverse']:\n1055                         field = field.remote_field\n1056                     path = parent_path + [field.name]\n1057                     yield LOOKUP_SEP.join(path)\n1058                 queue.extend(\n1059                     (path, klass_info)\n1060                     for klass_info in _get_parent_klass_info(klass_info)\n1061                 )\n1062                 queue.extend(\n1063                     (path, klass_info)\n1064                     for klass_info in klass_info.get('related_klass_infos', [])\n1065                 )\n1066         result = []\n1067         invalid_names = []\n1068         for name in self.query.select_for_update_of:\n1069             klass_info = self.klass_info\n1070             if name == 'self':\n1071                 col = _get_first_selected_col_from_model(klass_info)\n1072             else:\n1073                 for part in name.split(LOOKUP_SEP):\n1074                     klass_infos = (\n1075                         *klass_info.get('related_klass_infos', []),\n1076                         *_get_parent_klass_info(klass_info),\n1077                     )\n1078                     for related_klass_info in klass_infos:\n1079                         field = related_klass_info['field']\n1080                         if related_klass_info['reverse']:\n1081                             field = field.remote_field\n1082                         if field.name == part:\n1083                             klass_info = related_klass_info\n1084                             break\n1085                     else:\n1086                         klass_info = None\n1087                         break\n1088                 if klass_info is None:\n1089                     invalid_names.append(name)\n1090                     continue\n1091                 col = _get_first_selected_col_from_model(klass_info)\n1092             if col is not None:\n1093                 if self.connection.features.select_for_update_of_column:\n1094                     result.append(self.compile(col)[0])\n1095                 else:\n1096                     result.append(self.quote_name_unless_alias(col.alias))\n1097         if invalid_names:\n1098             raise FieldError(\n1099                 'Invalid field name(s) given in select_for_update(of=(...)): %s. '\n1100                 'Only relational fields followed in the query are allowed. '\n1101                 'Choices are: %s.' % (\n1102                     ', '.join(invalid_names),\n1103                     ', '.join(_get_field_choices()),\n1104                 )\n1105             )\n1106         return result\n1107 \n1108     def deferred_to_columns(self):\n1109         \"\"\"\n1110         Convert the self.deferred_loading data structure to mapping of table\n1111         names to sets of column names which are to be loaded. Return the\n1112         dictionary.\n1113         \"\"\"\n1114         columns = {}\n1115         self.query.deferred_to_data(columns, self.query.get_loaded_field_names_cb)\n1116         return columns\n1117 \n1118     def get_converters(self, expressions):\n1119         converters = {}\n1120         for i, expression in enumerate(expressions):\n1121             if expression:\n1122                 backend_converters = self.connection.ops.get_db_converters(expression)\n1123                 field_converters = expression.get_db_converters(self.connection)\n1124                 if backend_converters or field_converters:\n1125                     converters[i] = (backend_converters + field_converters, expression)\n1126         return converters\n1127 \n1128     def apply_converters(self, rows, converters):\n1129         connection = self.connection\n1130         converters = list(converters.items())\n1131         for row in map(list, rows):\n1132             for pos, (convs, expression) in converters:\n1133                 value = row[pos]\n1134                 for converter in convs:\n1135                     value = converter(value, expression, connection)\n1136                 row[pos] = value\n1137             yield row\n1138 \n1139     def results_iter(self, results=None, tuple_expected=False, chunked_fetch=False,\n1140                      chunk_size=GET_ITERATOR_CHUNK_SIZE):\n1141         \"\"\"Return an iterator over the results from executing this query.\"\"\"\n1142         if results is None:\n1143             results = self.execute_sql(MULTI, chunked_fetch=chunked_fetch, chunk_size=chunk_size)\n1144         fields = [s[0] for s in self.select[0:self.col_count]]\n1145         converters = self.get_converters(fields)\n1146         rows = chain.from_iterable(results)\n1147         if converters:\n1148             rows = self.apply_converters(rows, converters)\n1149             if tuple_expected:\n1150                 rows = map(tuple, rows)\n1151         return rows\n1152 \n1153     def has_results(self):\n1154         \"\"\"\n1155         Backends (e.g. NoSQL) can override this in order to use optimized\n1156         versions of \"query has any results.\"\n1157         \"\"\"\n1158         return bool(self.execute_sql(SINGLE))\n1159 \n1160     def execute_sql(self, result_type=MULTI, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE):\n1161         \"\"\"\n1162         Run the query against the database and return the result(s). The\n1163         return value is a single data item if result_type is SINGLE, or an\n1164         iterator over the results if the result_type is MULTI.\n1165 \n1166         result_type is either MULTI (use fetchmany() to retrieve all rows),\n1167         SINGLE (only retrieve a single row), or None. In this last case, the\n1168         cursor is returned if any query is executed, since it's used by\n1169         subclasses such as InsertQuery). It's possible, however, that no query\n1170         is needed, as the filters describe an empty set. In that case, None is\n1171         returned, to avoid any unnecessary database interaction.\n1172         \"\"\"\n1173         result_type = result_type or NO_RESULTS\n1174         try:\n1175             sql, params = self.as_sql()\n1176             if not sql:\n1177                 raise EmptyResultSet\n1178         except EmptyResultSet:\n1179             if result_type == MULTI:\n1180                 return iter([])\n1181             else:\n1182                 return\n1183         if chunked_fetch:\n1184             cursor = self.connection.chunked_cursor()\n1185         else:\n1186             cursor = self.connection.cursor()\n1187         try:\n1188             cursor.execute(sql, params)\n1189         except Exception:\n1190             # Might fail for server-side cursors (e.g. connection closed)\n1191             cursor.close()\n1192             raise\n1193 \n1194         if result_type == CURSOR:\n1195             # Give the caller the cursor to process and close.\n1196             return cursor\n1197         if result_type == SINGLE:\n1198             try:\n1199                 val = cursor.fetchone()\n1200                 if val:\n1201                     return val[0:self.col_count]\n1202                 return val\n1203             finally:\n1204                 # done with the cursor\n1205                 cursor.close()\n1206         if result_type == NO_RESULTS:\n1207             cursor.close()\n1208             return\n1209 \n1210         result = cursor_iter(\n1211             cursor, self.connection.features.empty_fetchmany_value,\n1212             self.col_count if self.has_extra_select else None,\n1213             chunk_size,\n1214         )\n1215         if not chunked_fetch or not self.connection.features.can_use_chunked_reads:\n1216             try:\n1217                 # If we are using non-chunked reads, we return the same data\n1218                 # structure as normally, but ensure it is all read into memory\n1219                 # before going any further. Use chunked_fetch if requested,\n1220                 # unless the database doesn't support it.\n1221                 return list(result)\n1222             finally:\n1223                 # done with the cursor\n1224                 cursor.close()\n1225         return result\n1226 \n1227     def as_subquery_condition(self, alias, columns, compiler):\n1228         qn = compiler.quote_name_unless_alias\n1229         qn2 = self.connection.ops.quote_name\n1230 \n1231         for index, select_col in enumerate(self.query.select):\n1232             lhs_sql, lhs_params = self.compile(select_col)\n1233             rhs = '%s.%s' % (qn(alias), qn2(columns[index]))\n1234             self.query.where.add(\n1235                 RawSQL('%s = %s' % (lhs_sql, rhs), lhs_params), 'AND')\n1236 \n1237         sql, params = self.as_sql()\n1238         return 'EXISTS (%s)' % sql, params\n1239 \n1240     def explain_query(self):\n1241         result = list(self.execute_sql())\n1242         # Some backends return 1 item tuples with strings, and others return\n1243         # tuples with integers and strings. Flatten them out into strings.\n1244         for row in result[0]:\n1245             if not isinstance(row, str):\n1246                 yield ' '.join(str(c) for c in row)\n1247             else:\n1248                 yield row\n1249 \n1250 \n1251 class SQLInsertCompiler(SQLCompiler):\n1252     returning_fields = None\n1253     returning_params = tuple()\n1254 \n1255     def field_as_sql(self, field, val):\n1256         \"\"\"\n1257         Take a field and a value intended to be saved on that field, and\n1258         return placeholder SQL and accompanying params. Check for raw values,\n1259         expressions, and fields with get_placeholder() defined in that order.\n1260 \n1261         When field is None, consider the value raw and use it as the\n1262         placeholder, with no corresponding parameters returned.\n1263         \"\"\"\n1264         if field is None:\n1265             # A field value of None means the value is raw.\n1266             sql, params = val, []\n1267         elif hasattr(val, 'as_sql'):\n1268             # This is an expression, let's compile it.\n1269             sql, params = self.compile(val)\n1270         elif hasattr(field, 'get_placeholder'):\n1271             # Some fields (e.g. geo fields) need special munging before\n1272             # they can be inserted.\n1273             sql, params = field.get_placeholder(val, self, self.connection), [val]\n1274         else:\n1275             # Return the common case for the placeholder\n1276             sql, params = '%s', [val]\n1277 \n1278         # The following hook is only used by Oracle Spatial, which sometimes\n1279         # needs to yield 'NULL' and [] as its placeholder and params instead\n1280         # of '%s' and [None]. The 'NULL' placeholder is produced earlier by\n1281         # OracleOperations.get_geom_placeholder(). The following line removes\n1282         # the corresponding None parameter. See ticket #10888.\n1283         params = self.connection.ops.modify_insert_params(sql, params)\n1284 \n1285         return sql, params\n1286 \n1287     def prepare_value(self, field, value):\n1288         \"\"\"\n1289         Prepare a value to be used in a query by resolving it if it is an\n1290         expression and otherwise calling the field's get_db_prep_save().\n1291         \"\"\"\n1292         if hasattr(value, 'resolve_expression'):\n1293             value = value.resolve_expression(self.query, allow_joins=False, for_save=True)\n1294             # Don't allow values containing Col expressions. They refer to\n1295             # existing columns on a row, but in the case of insert the row\n1296             # doesn't exist yet.\n1297             if value.contains_column_references:\n1298                 raise ValueError(\n1299                     'Failed to insert expression \"%s\" on %s. F() expressions '\n1300                     'can only be used to update, not to insert.' % (value, field)\n1301                 )\n1302             if value.contains_aggregate:\n1303                 raise FieldError(\n1304                     'Aggregate functions are not allowed in this query '\n1305                     '(%s=%r).' % (field.name, value)\n1306                 )\n1307             if value.contains_over_clause:\n1308                 raise FieldError(\n1309                     'Window expressions are not allowed in this query (%s=%r).'\n1310                     % (field.name, value)\n1311                 )\n1312         else:\n1313             value = field.get_db_prep_save(value, connection=self.connection)\n1314         return value\n1315 \n1316     def pre_save_val(self, field, obj):\n1317         \"\"\"\n1318         Get the given field's value off the given obj. pre_save() is used for\n1319         things like auto_now on DateTimeField. Skip it if this is a raw query.\n1320         \"\"\"\n1321         if self.query.raw:\n1322             return getattr(obj, field.attname)\n1323         return field.pre_save(obj, add=True)\n1324 \n1325     def assemble_as_sql(self, fields, value_rows):\n1326         \"\"\"\n1327         Take a sequence of N fields and a sequence of M rows of values, and\n1328         generate placeholder SQL and parameters for each field and value.\n1329         Return a pair containing:\n1330          * a sequence of M rows of N SQL placeholder strings, and\n1331          * a sequence of M rows of corresponding parameter values.\n1332 \n1333         Each placeholder string may contain any number of '%s' interpolation\n1334         strings, and each parameter row will contain exactly as many params\n1335         as the total number of '%s's in the corresponding placeholder row.\n1336         \"\"\"\n1337         if not value_rows:\n1338             return [], []\n1339 \n1340         # list of (sql, [params]) tuples for each object to be saved\n1341         # Shape: [n_objs][n_fields][2]\n1342         rows_of_fields_as_sql = (\n1343             (self.field_as_sql(field, v) for field, v in zip(fields, row))\n1344             for row in value_rows\n1345         )\n1346 \n1347         # tuple like ([sqls], [[params]s]) for each object to be saved\n1348         # Shape: [n_objs][2][n_fields]\n1349         sql_and_param_pair_rows = (zip(*row) for row in rows_of_fields_as_sql)\n1350 \n1351         # Extract separate lists for placeholders and params.\n1352         # Each of these has shape [n_objs][n_fields]\n1353         placeholder_rows, param_rows = zip(*sql_and_param_pair_rows)\n1354 \n1355         # Params for each field are still lists, and need to be flattened.\n1356         param_rows = [[p for ps in row for p in ps] for row in param_rows]\n1357 \n1358         return placeholder_rows, param_rows\n1359 \n1360     def as_sql(self):\n1361         # We don't need quote_name_unless_alias() here, since these are all\n1362         # going to be column names (so we can avoid the extra overhead).\n1363         qn = self.connection.ops.quote_name\n1364         opts = self.query.get_meta()\n1365         insert_statement = self.connection.ops.insert_statement(ignore_conflicts=self.query.ignore_conflicts)\n1366         result = ['%s %s' % (insert_statement, qn(opts.db_table))]\n1367         fields = self.query.fields or [opts.pk]\n1368         result.append('(%s)' % ', '.join(qn(f.column) for f in fields))\n1369 \n1370         if self.query.fields:\n1371             value_rows = [\n1372                 [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]\n1373                 for obj in self.query.objs\n1374             ]\n1375         else:\n1376             # An empty object.\n1377             value_rows = [[self.connection.ops.pk_default_value()] for _ in self.query.objs]\n1378             fields = [None]\n1379 \n1380         # Currently the backends just accept values when generating bulk\n1381         # queries and generate their own placeholders. Doing that isn't\n1382         # necessary and it should be possible to use placeholders and\n1383         # expressions in bulk inserts too.\n1384         can_bulk = (not self.returning_fields and self.connection.features.has_bulk_insert)\n1385 \n1386         placeholder_rows, param_rows = self.assemble_as_sql(fields, value_rows)\n1387 \n1388         ignore_conflicts_suffix_sql = self.connection.ops.ignore_conflicts_suffix_sql(\n1389             ignore_conflicts=self.query.ignore_conflicts\n1390         )\n1391         if self.returning_fields and self.connection.features.can_return_columns_from_insert:\n1392             if self.connection.features.can_return_rows_from_bulk_insert:\n1393                 result.append(self.connection.ops.bulk_insert_sql(fields, placeholder_rows))\n1394                 params = param_rows\n1395             else:\n1396                 result.append(\"VALUES (%s)\" % \", \".join(placeholder_rows[0]))\n1397                 params = [param_rows[0]]\n1398             if ignore_conflicts_suffix_sql:\n1399                 result.append(ignore_conflicts_suffix_sql)\n1400             # Skip empty r_sql to allow subclasses to customize behavior for\n1401             # 3rd party backends. Refs #19096.\n1402             r_sql, self.returning_params = self.connection.ops.return_insert_columns(self.returning_fields)\n1403             if r_sql:\n1404                 result.append(r_sql)\n1405                 params += [self.returning_params]\n1406             return [(\" \".join(result), tuple(chain.from_iterable(params)))]\n1407 \n1408         if can_bulk:\n1409             result.append(self.connection.ops.bulk_insert_sql(fields, placeholder_rows))\n1410             if ignore_conflicts_suffix_sql:\n1411                 result.append(ignore_conflicts_suffix_sql)\n1412             return [(\" \".join(result), tuple(p for ps in param_rows for p in ps))]\n1413         else:\n1414             if ignore_conflicts_suffix_sql:\n1415                 result.append(ignore_conflicts_suffix_sql)\n1416             return [\n1417                 (\" \".join(result + [\"VALUES (%s)\" % \", \".join(p)]), vals)\n1418                 for p, vals in zip(placeholder_rows, param_rows)\n1419             ]\n1420 \n1421     def execute_sql(self, returning_fields=None):\n1422         assert not (\n1423             returning_fields and len(self.query.objs) != 1 and\n1424             not self.connection.features.can_return_rows_from_bulk_insert\n1425         )\n1426         opts = self.query.get_meta()\n1427         self.returning_fields = returning_fields\n1428         with self.connection.cursor() as cursor:\n1429             for sql, params in self.as_sql():\n1430                 cursor.execute(sql, params)\n1431             if not self.returning_fields:\n1432                 return []\n1433             if self.connection.features.can_return_rows_from_bulk_insert and len(self.query.objs) > 1:\n1434                 rows = self.connection.ops.fetch_returned_insert_rows(cursor)\n1435             elif self.connection.features.can_return_columns_from_insert:\n1436                 assert len(self.query.objs) == 1\n1437                 rows = [self.connection.ops.fetch_returned_insert_columns(\n1438                     cursor, self.returning_params,\n1439                 )]\n1440             else:\n1441                 rows = [(self.connection.ops.last_insert_id(\n1442                     cursor, opts.db_table, opts.pk.column,\n1443                 ),)]\n1444         cols = [field.get_col(opts.db_table) for field in self.returning_fields]\n1445         converters = self.get_converters(cols)\n1446         if converters:\n1447             rows = list(self.apply_converters(rows, converters))\n1448         return rows\n1449 \n1450 \n1451 class SQLDeleteCompiler(SQLCompiler):\n1452     @cached_property\n1453     def single_alias(self):\n1454         # Ensure base table is in aliases.\n1455         self.query.get_initial_alias()\n1456         return sum(self.query.alias_refcount[t] > 0 for t in self.query.alias_map) == 1\n1457 \n1458     @classmethod\n1459     def _expr_refs_base_model(cls, expr, base_model):\n1460         if isinstance(expr, Query):\n1461             return expr.model == base_model\n1462         if not hasattr(expr, 'get_source_expressions'):\n1463             return False\n1464         return any(\n1465             cls._expr_refs_base_model(source_expr, base_model)\n1466             for source_expr in expr.get_source_expressions()\n1467         )\n1468 \n1469     @cached_property\n1470     def contains_self_reference_subquery(self):\n1471         return any(\n1472             self._expr_refs_base_model(expr, self.query.model)\n1473             for expr in chain(self.query.annotations.values(), self.query.where.children)\n1474         )\n1475 \n1476     def _as_sql(self, query):\n1477         result = [\n1478             'DELETE FROM %s' % self.quote_name_unless_alias(query.base_table)\n1479         ]\n1480         where, params = self.compile(query.where)\n1481         if where:\n1482             result.append('WHERE %s' % where)\n1483         return ' '.join(result), tuple(params)\n1484 \n1485     def as_sql(self):\n1486         \"\"\"\n1487         Create the SQL for this query. Return the SQL string and list of\n1488         parameters.\n1489         \"\"\"\n1490         if self.single_alias and not self.contains_self_reference_subquery:\n1491             return self._as_sql(self.query)\n1492         innerq = self.query.clone()\n1493         innerq.__class__ = Query\n1494         innerq.clear_select_clause()\n1495         pk = self.query.model._meta.pk\n1496         innerq.select = [\n1497             pk.get_col(self.query.get_initial_alias())\n1498         ]\n1499         outerq = Query(self.query.model)\n1500         outerq.where = self.query.where_class()\n1501         if not self.connection.features.update_can_self_select:\n1502             # Force the materialization of the inner query to allow reference\n1503             # to the target table on MySQL.\n1504             sql, params = innerq.get_compiler(connection=self.connection).as_sql()\n1505             innerq = RawSQL('SELECT * FROM (%s) subquery' % sql, params)\n1506         outerq.add_q(Q(pk__in=innerq))\n1507         return self._as_sql(outerq)\n1508 \n1509 \n1510 class SQLUpdateCompiler(SQLCompiler):\n1511     def as_sql(self):\n1512         \"\"\"\n1513         Create the SQL for this query. Return the SQL string and list of\n1514         parameters.\n1515         \"\"\"\n1516         self.pre_sql_setup()\n1517         if not self.query.values:\n1518             return '', ()\n1519         qn = self.quote_name_unless_alias\n1520         values, update_params = [], []\n1521         for field, model, val in self.query.values:\n1522             if hasattr(val, 'resolve_expression'):\n1523                 val = val.resolve_expression(self.query, allow_joins=False, for_save=True)\n1524                 if val.contains_aggregate:\n1525                     raise FieldError(\n1526                         'Aggregate functions are not allowed in this query '\n1527                         '(%s=%r).' % (field.name, val)\n1528                     )\n1529                 if val.contains_over_clause:\n1530                     raise FieldError(\n1531                         'Window expressions are not allowed in this query '\n1532                         '(%s=%r).' % (field.name, val)\n1533                     )\n1534             elif hasattr(val, 'prepare_database_save'):\n1535                 if field.remote_field:\n1536                     val = field.get_db_prep_save(\n1537                         val.prepare_database_save(field),\n1538                         connection=self.connection,\n1539                     )\n1540                 else:\n1541                     raise TypeError(\n1542                         \"Tried to update field %s with a model instance, %r. \"\n1543                         \"Use a value compatible with %s.\"\n1544                         % (field, val, field.__class__.__name__)\n1545                     )\n1546             else:\n1547                 val = field.get_db_prep_save(val, connection=self.connection)\n1548 \n1549             # Getting the placeholder for the field.\n1550             if hasattr(field, 'get_placeholder'):\n1551                 placeholder = field.get_placeholder(val, self, self.connection)\n1552             else:\n1553                 placeholder = '%s'\n1554             name = field.column\n1555             if hasattr(val, 'as_sql'):\n1556                 sql, params = self.compile(val)\n1557                 values.append('%s = %s' % (qn(name), placeholder % sql))\n1558                 update_params.extend(params)\n1559             elif val is not None:\n1560                 values.append('%s = %s' % (qn(name), placeholder))\n1561                 update_params.append(val)\n1562             else:\n1563                 values.append('%s = NULL' % qn(name))\n1564         table = self.query.base_table\n1565         result = [\n1566             'UPDATE %s SET' % qn(table),\n1567             ', '.join(values),\n1568         ]\n1569         where, params = self.compile(self.query.where)\n1570         if where:\n1571             result.append('WHERE %s' % where)\n1572         return ' '.join(result), tuple(update_params + params)\n1573 \n1574     def execute_sql(self, result_type):\n1575         \"\"\"\n1576         Execute the specified update. Return the number of rows affected by\n1577         the primary update query. The \"primary update query\" is the first\n1578         non-empty query that is executed. Row counts for any subsequent,\n1579         related queries are not available.\n1580         \"\"\"\n1581         cursor = super().execute_sql(result_type)\n1582         try:\n1583             rows = cursor.rowcount if cursor else 0\n1584             is_empty = cursor is None\n1585         finally:\n1586             if cursor:\n1587                 cursor.close()\n1588         for query in self.query.get_related_updates():\n1589             aux_rows = query.get_compiler(self.using).execute_sql(result_type)\n1590             if is_empty and aux_rows:\n1591                 rows = aux_rows\n1592                 is_empty = False\n1593         return rows\n1594 \n1595     def pre_sql_setup(self):\n1596         \"\"\"\n1597         If the update depends on results from other tables, munge the \"where\"\n1598         conditions to match the format required for (portable) SQL updates.\n1599 \n1600         If multiple updates are required, pull out the id values to update at\n1601         this point so that they don't change as a result of the progressive\n1602         updates.\n1603         \"\"\"\n1604         refcounts_before = self.query.alias_refcount.copy()\n1605         # Ensure base table is in the query\n1606         self.query.get_initial_alias()\n1607         count = self.query.count_active_tables()\n1608         if not self.query.related_updates and count == 1:\n1609             return\n1610         query = self.query.chain(klass=Query)\n1611         query.select_related = False\n1612         query.clear_ordering(force=True)\n1613         query.extra = {}\n1614         query.select = []\n1615         query.add_fields([query.get_meta().pk.name])\n1616         super().pre_sql_setup()\n1617 \n1618         must_pre_select = count > 1 and not self.connection.features.update_can_self_select\n1619 \n1620         # Now we adjust the current query: reset the where clause and get rid\n1621         # of all the tables we don't need (since they're in the sub-select).\n1622         self.query.where = self.query.where_class()\n1623         if self.query.related_updates or must_pre_select:\n1624             # Either we're using the idents in multiple update queries (so\n1625             # don't want them to change), or the db backend doesn't support\n1626             # selecting from the updating table (e.g. MySQL).\n1627             idents = []\n1628             for rows in query.get_compiler(self.using).execute_sql(MULTI):\n1629                 idents.extend(r[0] for r in rows)\n1630             self.query.add_filter(('pk__in', idents))\n1631             self.query.related_ids = idents\n1632         else:\n1633             # The fast path. Filters and updates in one query.\n1634             self.query.add_filter(('pk__in', query))\n1635         self.query.reset_refcounts(refcounts_before)\n1636 \n1637 \n1638 class SQLAggregateCompiler(SQLCompiler):\n1639     def as_sql(self):\n1640         \"\"\"\n1641         Create the SQL for this query. Return the SQL string and list of\n1642         parameters.\n1643         \"\"\"\n1644         sql, params = [], []\n1645         for annotation in self.query.annotation_select.values():\n1646             ann_sql, ann_params = self.compile(annotation)\n1647             ann_sql, ann_params = annotation.select_format(self, ann_sql, ann_params)\n1648             sql.append(ann_sql)\n1649             params.extend(ann_params)\n1650         self.col_count = len(self.query.annotation_select)\n1651         sql = ', '.join(sql)\n1652         params = tuple(params)\n1653 \n1654         inner_query_sql, inner_query_params = self.query.inner_query.get_compiler(\n1655             self.using\n1656         ).as_sql(with_col_aliases=True)\n1657         sql = 'SELECT %s FROM (%s) subquery' % (sql, inner_query_sql)\n1658         params = params + inner_query_params\n1659         return sql, params\n1660 \n1661 \n1662 def cursor_iter(cursor, sentinel, col_count, itersize):\n1663     \"\"\"\n1664     Yield blocks of rows from a cursor and ensure the cursor is closed when\n1665     done.\n1666     \"\"\"\n1667     try:\n1668         for rows in iter((lambda: cursor.fetchmany(itersize)), sentinel):\n1669             yield rows if col_count is None else [r[:col_count] for r in rows]\n1670     finally:\n1671         cursor.close()\n",
        "intended_behavior": "The method or methods within this class that execute aggregate queries need to be modified to account for 'EmptyResultSet' scenarios in a way that 'Coalesce' annotations can still enforce their default values. When an aggregate function is wrapped with 'Coalesce' and the query would traditionally lead to an 'EmptyResultSet', the system should return the 'Coalesce' default value instead of 'None'. This adjustment must preserve the functionality for all other types of queries and conditions, ensuring that it specifically addresses the case of aggregates with 'Coalesce' when facing 'EmptyResultSet' scenarios."
    },
    {
        "rel_file_path": "django/db/models/expressions.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__4.0/django/db/models/expressions.py",
        "start": 1,
        "end": 1451,
        "class_name": null,
        "method_name": null,
        "code": "1 import copy\n2 import datetime\n3 import functools\n4 import inspect\n5 from decimal import Decimal\n6 from uuid import UUID\n7 \n8 from django.core.exceptions import EmptyResultSet, FieldError\n9 from django.db import DatabaseError, NotSupportedError, connection\n10 from django.db.models import fields\n11 from django.db.models.constants import LOOKUP_SEP\n12 from django.db.models.query_utils import Q\n13 from django.utils.deconstruct import deconstructible\n14 from django.utils.functional import cached_property\n15 from django.utils.hashable import make_hashable\n16 \n17 \n18 class SQLiteNumericMixin:\n19     \"\"\"\n20     Some expressions with output_field=DecimalField() must be cast to\n21     numeric to be properly filtered.\n22     \"\"\"\n23     def as_sqlite(self, compiler, connection, **extra_context):\n24         sql, params = self.as_sql(compiler, connection, **extra_context)\n25         try:\n26             if self.output_field.get_internal_type() == 'DecimalField':\n27                 sql = 'CAST(%s AS NUMERIC)' % sql\n28         except FieldError:\n29             pass\n30         return sql, params\n31 \n32 \n33 class Combinable:\n34     \"\"\"\n35     Provide the ability to combine one or two objects with\n36     some connector. For example F('foo') + F('bar').\n37     \"\"\"\n38 \n39     # Arithmetic connectors\n40     ADD = '+'\n41     SUB = '-'\n42     MUL = '*'\n43     DIV = '/'\n44     POW = '^'\n45     # The following is a quoted % operator - it is quoted because it can be\n46     # used in strings that also have parameter substitution.\n47     MOD = '%%'\n48 \n49     # Bitwise operators - note that these are generated by .bitand()\n50     # and .bitor(), the '&' and '|' are reserved for boolean operator\n51     # usage.\n52     BITAND = '&'\n53     BITOR = '|'\n54     BITLEFTSHIFT = '<<'\n55     BITRIGHTSHIFT = '>>'\n56     BITXOR = '#'\n57 \n58     def _combine(self, other, connector, reversed):\n59         if not hasattr(other, 'resolve_expression'):\n60             # everything must be resolvable to an expression\n61             other = Value(other)\n62 \n63         if reversed:\n64             return CombinedExpression(other, connector, self)\n65         return CombinedExpression(self, connector, other)\n66 \n67     #############\n68     # OPERATORS #\n69     #############\n70 \n71     def __neg__(self):\n72         return self._combine(-1, self.MUL, False)\n73 \n74     def __add__(self, other):\n75         return self._combine(other, self.ADD, False)\n76 \n77     def __sub__(self, other):\n78         return self._combine(other, self.SUB, False)\n79 \n80     def __mul__(self, other):\n81         return self._combine(other, self.MUL, False)\n82 \n83     def __truediv__(self, other):\n84         return self._combine(other, self.DIV, False)\n85 \n86     def __mod__(self, other):\n87         return self._combine(other, self.MOD, False)\n88 \n89     def __pow__(self, other):\n90         return self._combine(other, self.POW, False)\n91 \n92     def __and__(self, other):\n93         if getattr(self, 'conditional', False) and getattr(other, 'conditional', False):\n94             return Q(self) & Q(other)\n95         raise NotImplementedError(\n96             \"Use .bitand() and .bitor() for bitwise logical operations.\"\n97         )\n98 \n99     def bitand(self, other):\n100         return self._combine(other, self.BITAND, False)\n101 \n102     def bitleftshift(self, other):\n103         return self._combine(other, self.BITLEFTSHIFT, False)\n104 \n105     def bitrightshift(self, other):\n106         return self._combine(other, self.BITRIGHTSHIFT, False)\n107 \n108     def bitxor(self, other):\n109         return self._combine(other, self.BITXOR, False)\n110 \n111     def __or__(self, other):\n112         if getattr(self, 'conditional', False) and getattr(other, 'conditional', False):\n113             return Q(self) | Q(other)\n114         raise NotImplementedError(\n115             \"Use .bitand() and .bitor() for bitwise logical operations.\"\n116         )\n117 \n118     def bitor(self, other):\n119         return self._combine(other, self.BITOR, False)\n120 \n121     def __radd__(self, other):\n122         return self._combine(other, self.ADD, True)\n123 \n124     def __rsub__(self, other):\n125         return self._combine(other, self.SUB, True)\n126 \n127     def __rmul__(self, other):\n128         return self._combine(other, self.MUL, True)\n129 \n130     def __rtruediv__(self, other):\n131         return self._combine(other, self.DIV, True)\n132 \n133     def __rmod__(self, other):\n134         return self._combine(other, self.MOD, True)\n135 \n136     def __rpow__(self, other):\n137         return self._combine(other, self.POW, True)\n138 \n139     def __rand__(self, other):\n140         raise NotImplementedError(\n141             \"Use .bitand() and .bitor() for bitwise logical operations.\"\n142         )\n143 \n144     def __ror__(self, other):\n145         raise NotImplementedError(\n146             \"Use .bitand() and .bitor() for bitwise logical operations.\"\n147         )\n148 \n149 \n150 class BaseExpression:\n151     \"\"\"Base class for all query expressions.\"\"\"\n152 \n153     # aggregate specific fields\n154     is_summary = False\n155     _output_field_resolved_to_none = False\n156     # Can the expression be used in a WHERE clause?\n157     filterable = True\n158     # Can the expression can be used as a source expression in Window?\n159     window_compatible = False\n160 \n161     def __init__(self, output_field=None):\n162         if output_field is not None:\n163             self.output_field = output_field\n164 \n165     def __getstate__(self):\n166         state = self.__dict__.copy()\n167         state.pop('convert_value', None)\n168         return state\n169 \n170     def get_db_converters(self, connection):\n171         return (\n172             []\n173             if self.convert_value is self._convert_value_noop else\n174             [self.convert_value]\n175         ) + self.output_field.get_db_converters(connection)\n176 \n177     def get_source_expressions(self):\n178         return []\n179 \n180     def set_source_expressions(self, exprs):\n181         assert not exprs\n182 \n183     def _parse_expressions(self, *expressions):\n184         return [\n185             arg if hasattr(arg, 'resolve_expression') else (\n186                 F(arg) if isinstance(arg, str) else Value(arg)\n187             ) for arg in expressions\n188         ]\n189 \n190     def as_sql(self, compiler, connection):\n191         \"\"\"\n192         Responsible for returning a (sql, [params]) tuple to be included\n193         in the current query.\n194 \n195         Different backends can provide their own implementation, by\n196         providing an `as_{vendor}` method and patching the Expression:\n197 \n198         ```\n199         def override_as_sql(self, compiler, connection):\n200             # custom logic\n201             return super().as_sql(compiler, connection)\n202         setattr(Expression, 'as_' + connection.vendor, override_as_sql)\n203         ```\n204 \n205         Arguments:\n206          * compiler: the query compiler responsible for generating the query.\n207            Must have a compile method, returning a (sql, [params]) tuple.\n208            Calling compiler(value) will return a quoted `value`.\n209 \n210          * connection: the database connection used for the current query.\n211 \n212         Return: (sql, params)\n213           Where `sql` is a string containing ordered sql parameters to be\n214           replaced with the elements of the list `params`.\n215         \"\"\"\n216         raise NotImplementedError(\"Subclasses must implement as_sql()\")\n217 \n218     @cached_property\n219     def contains_aggregate(self):\n220         return any(expr and expr.contains_aggregate for expr in self.get_source_expressions())\n221 \n222     @cached_property\n223     def contains_over_clause(self):\n224         return any(expr and expr.contains_over_clause for expr in self.get_source_expressions())\n225 \n226     @cached_property\n227     def contains_column_references(self):\n228         return any(expr and expr.contains_column_references for expr in self.get_source_expressions())\n229 \n230     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n231         \"\"\"\n232         Provide the chance to do any preprocessing or validation before being\n233         added to the query.\n234 \n235         Arguments:\n236          * query: the backend query implementation\n237          * allow_joins: boolean allowing or denying use of joins\n238            in this query\n239          * reuse: a set of reusable joins for multijoins\n240          * summarize: a terminal aggregate clause\n241          * for_save: whether this expression about to be used in a save or update\n242 \n243         Return: an Expression to be added to the query.\n244         \"\"\"\n245         c = self.copy()\n246         c.is_summary = summarize\n247         c.set_source_expressions([\n248             expr.resolve_expression(query, allow_joins, reuse, summarize)\n249             if expr else None\n250             for expr in c.get_source_expressions()\n251         ])\n252         return c\n253 \n254     @property\n255     def conditional(self):\n256         return isinstance(self.output_field, fields.BooleanField)\n257 \n258     @property\n259     def field(self):\n260         return self.output_field\n261 \n262     @cached_property\n263     def output_field(self):\n264         \"\"\"Return the output type of this expressions.\"\"\"\n265         output_field = self._resolve_output_field()\n266         if output_field is None:\n267             self._output_field_resolved_to_none = True\n268             raise FieldError('Cannot resolve expression type, unknown output_field')\n269         return output_field\n270 \n271     @cached_property\n272     def _output_field_or_none(self):\n273         \"\"\"\n274         Return the output field of this expression, or None if\n275         _resolve_output_field() didn't return an output type.\n276         \"\"\"\n277         try:\n278             return self.output_field\n279         except FieldError:\n280             if not self._output_field_resolved_to_none:\n281                 raise\n282 \n283     def _resolve_output_field(self):\n284         \"\"\"\n285         Attempt to infer the output type of the expression. If the output\n286         fields of all source fields match then, simply infer the same type\n287         here. This isn't always correct, but it makes sense most of the time.\n288 \n289         Consider the difference between `2 + 2` and `2 / 3`. Inferring\n290         the type here is a convenience for the common case. The user should\n291         supply their own output_field with more complex computations.\n292 \n293         If a source's output field resolves to None, exclude it from this check.\n294         If all sources are None, then an error is raised higher up the stack in\n295         the output_field property.\n296         \"\"\"\n297         sources_iter = (source for source in self.get_source_fields() if source is not None)\n298         for output_field in sources_iter:\n299             for source in sources_iter:\n300                 if not isinstance(output_field, source.__class__):\n301                     raise FieldError(\n302                         'Expression contains mixed types: %s, %s. You must '\n303                         'set output_field.' % (\n304                             output_field.__class__.__name__,\n305                             source.__class__.__name__,\n306                         )\n307                     )\n308             return output_field\n309 \n310     @staticmethod\n311     def _convert_value_noop(value, expression, connection):\n312         return value\n313 \n314     @cached_property\n315     def convert_value(self):\n316         \"\"\"\n317         Expressions provide their own converters because users have the option\n318         of manually specifying the output_field which may be a different type\n319         from the one the database returns.\n320         \"\"\"\n321         field = self.output_field\n322         internal_type = field.get_internal_type()\n323         if internal_type == 'FloatField':\n324             return lambda value, expression, connection: None if value is None else float(value)\n325         elif internal_type.endswith('IntegerField'):\n326             return lambda value, expression, connection: None if value is None else int(value)\n327         elif internal_type == 'DecimalField':\n328             return lambda value, expression, connection: None if value is None else Decimal(value)\n329         return self._convert_value_noop\n330 \n331     def get_lookup(self, lookup):\n332         return self.output_field.get_lookup(lookup)\n333 \n334     def get_transform(self, name):\n335         return self.output_field.get_transform(name)\n336 \n337     def relabeled_clone(self, change_map):\n338         clone = self.copy()\n339         clone.set_source_expressions([\n340             e.relabeled_clone(change_map) if e is not None else None\n341             for e in self.get_source_expressions()\n342         ])\n343         return clone\n344 \n345     def copy(self):\n346         return copy.copy(self)\n347 \n348     def get_group_by_cols(self, alias=None):\n349         if not self.contains_aggregate:\n350             return [self]\n351         cols = []\n352         for source in self.get_source_expressions():\n353             cols.extend(source.get_group_by_cols())\n354         return cols\n355 \n356     def get_source_fields(self):\n357         \"\"\"Return the underlying field types used by this aggregate.\"\"\"\n358         return [e._output_field_or_none for e in self.get_source_expressions()]\n359 \n360     def asc(self, **kwargs):\n361         return OrderBy(self, **kwargs)\n362 \n363     def desc(self, **kwargs):\n364         return OrderBy(self, descending=True, **kwargs)\n365 \n366     def reverse_ordering(self):\n367         return self\n368 \n369     def flatten(self):\n370         \"\"\"\n371         Recursively yield this expression and all subexpressions, in\n372         depth-first order.\n373         \"\"\"\n374         yield self\n375         for expr in self.get_source_expressions():\n376             if expr:\n377                 if hasattr(expr, 'flatten'):\n378                     yield from expr.flatten()\n379                 else:\n380                     yield expr\n381 \n382     def select_format(self, compiler, sql, params):\n383         \"\"\"\n384         Custom format for select clauses. For example, EXISTS expressions need\n385         to be wrapped in CASE WHEN on Oracle.\n386         \"\"\"\n387         if hasattr(self.output_field, 'select_format'):\n388             return self.output_field.select_format(compiler, sql, params)\n389         return sql, params\n390 \n391 \n392 @deconstructible\n393 class Expression(BaseExpression, Combinable):\n394     \"\"\"An expression that can be combined with other expressions.\"\"\"\n395 \n396     @cached_property\n397     def identity(self):\n398         constructor_signature = inspect.signature(self.__init__)\n399         args, kwargs = self._constructor_args\n400         signature = constructor_signature.bind_partial(*args, **kwargs)\n401         signature.apply_defaults()\n402         arguments = signature.arguments.items()\n403         identity = [self.__class__]\n404         for arg, value in arguments:\n405             if isinstance(value, fields.Field):\n406                 if value.name and value.model:\n407                     value = (value.model._meta.label, value.name)\n408                 else:\n409                     value = type(value)\n410             else:\n411                 value = make_hashable(value)\n412             identity.append((arg, value))\n413         return tuple(identity)\n414 \n415     def __eq__(self, other):\n416         if not isinstance(other, Expression):\n417             return NotImplemented\n418         return other.identity == self.identity\n419 \n420     def __hash__(self):\n421         return hash(self.identity)\n422 \n423 \n424 _connector_combinators = {\n425     connector: [\n426         (fields.IntegerField, fields.IntegerField, fields.IntegerField),\n427         (fields.IntegerField, fields.DecimalField, fields.DecimalField),\n428         (fields.DecimalField, fields.IntegerField, fields.DecimalField),\n429         (fields.IntegerField, fields.FloatField, fields.FloatField),\n430         (fields.FloatField, fields.IntegerField, fields.FloatField),\n431     ]\n432     for connector in (Combinable.ADD, Combinable.SUB, Combinable.MUL, Combinable.DIV)\n433 }\n434 \n435 \n436 @functools.lru_cache(maxsize=128)\n437 def _resolve_combined_type(connector, lhs_type, rhs_type):\n438     combinators = _connector_combinators.get(connector, ())\n439     for combinator_lhs_type, combinator_rhs_type, combined_type in combinators:\n440         if issubclass(lhs_type, combinator_lhs_type) and issubclass(rhs_type, combinator_rhs_type):\n441             return combined_type\n442 \n443 \n444 class CombinedExpression(SQLiteNumericMixin, Expression):\n445 \n446     def __init__(self, lhs, connector, rhs, output_field=None):\n447         super().__init__(output_field=output_field)\n448         self.connector = connector\n449         self.lhs = lhs\n450         self.rhs = rhs\n451 \n452     def __repr__(self):\n453         return \"<{}: {}>\".format(self.__class__.__name__, self)\n454 \n455     def __str__(self):\n456         return \"{} {} {}\".format(self.lhs, self.connector, self.rhs)\n457 \n458     def get_source_expressions(self):\n459         return [self.lhs, self.rhs]\n460 \n461     def set_source_expressions(self, exprs):\n462         self.lhs, self.rhs = exprs\n463 \n464     def _resolve_output_field(self):\n465         try:\n466             return super()._resolve_output_field()\n467         except FieldError:\n468             combined_type = _resolve_combined_type(\n469                 self.connector,\n470                 type(self.lhs.output_field),\n471                 type(self.rhs.output_field),\n472             )\n473             if combined_type is None:\n474                 raise\n475             return combined_type()\n476 \n477     def as_sql(self, compiler, connection):\n478         expressions = []\n479         expression_params = []\n480         sql, params = compiler.compile(self.lhs)\n481         expressions.append(sql)\n482         expression_params.extend(params)\n483         sql, params = compiler.compile(self.rhs)\n484         expressions.append(sql)\n485         expression_params.extend(params)\n486         # order of precedence\n487         expression_wrapper = '(%s)'\n488         sql = connection.ops.combine_expression(self.connector, expressions)\n489         return expression_wrapper % sql, expression_params\n490 \n491     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n492         lhs = self.lhs.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n493         rhs = self.rhs.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n494         if not isinstance(self, (DurationExpression, TemporalSubtraction)):\n495             try:\n496                 lhs_type = lhs.output_field.get_internal_type()\n497             except (AttributeError, FieldError):\n498                 lhs_type = None\n499             try:\n500                 rhs_type = rhs.output_field.get_internal_type()\n501             except (AttributeError, FieldError):\n502                 rhs_type = None\n503             if 'DurationField' in {lhs_type, rhs_type} and lhs_type != rhs_type:\n504                 return DurationExpression(self.lhs, self.connector, self.rhs).resolve_expression(\n505                     query, allow_joins, reuse, summarize, for_save,\n506                 )\n507             datetime_fields = {'DateField', 'DateTimeField', 'TimeField'}\n508             if self.connector == self.SUB and lhs_type in datetime_fields and lhs_type == rhs_type:\n509                 return TemporalSubtraction(self.lhs, self.rhs).resolve_expression(\n510                     query, allow_joins, reuse, summarize, for_save,\n511                 )\n512         c = self.copy()\n513         c.is_summary = summarize\n514         c.lhs = lhs\n515         c.rhs = rhs\n516         return c\n517 \n518 \n519 class DurationExpression(CombinedExpression):\n520     def compile(self, side, compiler, connection):\n521         try:\n522             output = side.output_field\n523         except FieldError:\n524             pass\n525         else:\n526             if output.get_internal_type() == 'DurationField':\n527                 sql, params = compiler.compile(side)\n528                 return connection.ops.format_for_duration_arithmetic(sql), params\n529         return compiler.compile(side)\n530 \n531     def as_sql(self, compiler, connection):\n532         if connection.features.has_native_duration_field:\n533             return super().as_sql(compiler, connection)\n534         connection.ops.check_expression_support(self)\n535         expressions = []\n536         expression_params = []\n537         sql, params = self.compile(self.lhs, compiler, connection)\n538         expressions.append(sql)\n539         expression_params.extend(params)\n540         sql, params = self.compile(self.rhs, compiler, connection)\n541         expressions.append(sql)\n542         expression_params.extend(params)\n543         # order of precedence\n544         expression_wrapper = '(%s)'\n545         sql = connection.ops.combine_duration_expression(self.connector, expressions)\n546         return expression_wrapper % sql, expression_params\n547 \n548     def as_sqlite(self, compiler, connection, **extra_context):\n549         sql, params = self.as_sql(compiler, connection, **extra_context)\n550         if self.connector in {Combinable.MUL, Combinable.DIV}:\n551             try:\n552                 lhs_type = self.lhs.output_field.get_internal_type()\n553                 rhs_type = self.rhs.output_field.get_internal_type()\n554             except (AttributeError, FieldError):\n555                 pass\n556             else:\n557                 allowed_fields = {\n558                     'DecimalField', 'DurationField', 'FloatField', 'IntegerField',\n559                 }\n560                 if lhs_type not in allowed_fields or rhs_type not in allowed_fields:\n561                     raise DatabaseError(\n562                         f'Invalid arguments for operator {self.connector}.'\n563                     )\n564         return sql, params\n565 \n566 \n567 class TemporalSubtraction(CombinedExpression):\n568     output_field = fields.DurationField()\n569 \n570     def __init__(self, lhs, rhs):\n571         super().__init__(lhs, self.SUB, rhs)\n572 \n573     def as_sql(self, compiler, connection):\n574         connection.ops.check_expression_support(self)\n575         lhs = compiler.compile(self.lhs)\n576         rhs = compiler.compile(self.rhs)\n577         return connection.ops.subtract_temporals(self.lhs.output_field.get_internal_type(), lhs, rhs)\n578 \n579 \n580 @deconstructible\n581 class F(Combinable):\n582     \"\"\"An object capable of resolving references to existing query objects.\"\"\"\n583 \n584     def __init__(self, name):\n585         \"\"\"\n586         Arguments:\n587          * name: the name of the field this expression references\n588         \"\"\"\n589         self.name = name\n590 \n591     def __repr__(self):\n592         return \"{}({})\".format(self.__class__.__name__, self.name)\n593 \n594     def resolve_expression(self, query=None, allow_joins=True, reuse=None,\n595                            summarize=False, for_save=False):\n596         return query.resolve_ref(self.name, allow_joins, reuse, summarize)\n597 \n598     def asc(self, **kwargs):\n599         return OrderBy(self, **kwargs)\n600 \n601     def desc(self, **kwargs):\n602         return OrderBy(self, descending=True, **kwargs)\n603 \n604     def __eq__(self, other):\n605         return self.__class__ == other.__class__ and self.name == other.name\n606 \n607     def __hash__(self):\n608         return hash(self.name)\n609 \n610 \n611 class ResolvedOuterRef(F):\n612     \"\"\"\n613     An object that contains a reference to an outer query.\n614 \n615     In this case, the reference to the outer query has been resolved because\n616     the inner query has been used as a subquery.\n617     \"\"\"\n618     contains_aggregate = False\n619 \n620     def as_sql(self, *args, **kwargs):\n621         raise ValueError(\n622             'This queryset contains a reference to an outer query and may '\n623             'only be used in a subquery.'\n624         )\n625 \n626     def resolve_expression(self, *args, **kwargs):\n627         col = super().resolve_expression(*args, **kwargs)\n628         # FIXME: Rename possibly_multivalued to multivalued and fix detection\n629         # for non-multivalued JOINs (e.g. foreign key fields). This should take\n630         # into account\u00a0only many-to-many and one-to-many relationships.\n631         col.possibly_multivalued = LOOKUP_SEP in self.name\n632         return col\n633 \n634     def relabeled_clone(self, relabels):\n635         return self\n636 \n637     def get_group_by_cols(self, alias=None):\n638         return []\n639 \n640 \n641 class OuterRef(F):\n642     contains_aggregate = False\n643 \n644     def resolve_expression(self, *args, **kwargs):\n645         if isinstance(self.name, self.__class__):\n646             return self.name\n647         return ResolvedOuterRef(self.name)\n648 \n649     def relabeled_clone(self, relabels):\n650         return self\n651 \n652 \n653 class Func(SQLiteNumericMixin, Expression):\n654     \"\"\"An SQL function call.\"\"\"\n655     function = None\n656     template = '%(function)s(%(expressions)s)'\n657     arg_joiner = ', '\n658     arity = None  # The number of arguments the function accepts.\n659 \n660     def __init__(self, *expressions, output_field=None, **extra):\n661         if self.arity is not None and len(expressions) != self.arity:\n662             raise TypeError(\n663                 \"'%s' takes exactly %s %s (%s given)\" % (\n664                     self.__class__.__name__,\n665                     self.arity,\n666                     \"argument\" if self.arity == 1 else \"arguments\",\n667                     len(expressions),\n668                 )\n669             )\n670         super().__init__(output_field=output_field)\n671         self.source_expressions = self._parse_expressions(*expressions)\n672         self.extra = extra\n673 \n674     def __repr__(self):\n675         args = self.arg_joiner.join(str(arg) for arg in self.source_expressions)\n676         extra = {**self.extra, **self._get_repr_options()}\n677         if extra:\n678             extra = ', '.join(str(key) + '=' + str(val) for key, val in sorted(extra.items()))\n679             return \"{}({}, {})\".format(self.__class__.__name__, args, extra)\n680         return \"{}({})\".format(self.__class__.__name__, args)\n681 \n682     def _get_repr_options(self):\n683         \"\"\"Return a dict of extra __init__() options to include in the repr.\"\"\"\n684         return {}\n685 \n686     def get_source_expressions(self):\n687         return self.source_expressions\n688 \n689     def set_source_expressions(self, exprs):\n690         self.source_expressions = exprs\n691 \n692     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n693         c = self.copy()\n694         c.is_summary = summarize\n695         for pos, arg in enumerate(c.source_expressions):\n696             c.source_expressions[pos] = arg.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n697         return c\n698 \n699     def as_sql(self, compiler, connection, function=None, template=None, arg_joiner=None, **extra_context):\n700         connection.ops.check_expression_support(self)\n701         sql_parts = []\n702         params = []\n703         for arg in self.source_expressions:\n704             arg_sql, arg_params = compiler.compile(arg)\n705             sql_parts.append(arg_sql)\n706             params.extend(arg_params)\n707         data = {**self.extra, **extra_context}\n708         # Use the first supplied value in this order: the parameter to this\n709         # method, a value supplied in __init__()'s **extra (the value in\n710         # `data`), or the value defined on the class.\n711         if function is not None:\n712             data['function'] = function\n713         else:\n714             data.setdefault('function', self.function)\n715         template = template or data.get('template', self.template)\n716         arg_joiner = arg_joiner or data.get('arg_joiner', self.arg_joiner)\n717         data['expressions'] = data['field'] = arg_joiner.join(sql_parts)\n718         return template % data, params\n719 \n720     def copy(self):\n721         copy = super().copy()\n722         copy.source_expressions = self.source_expressions[:]\n723         copy.extra = self.extra.copy()\n724         return copy\n725 \n726 \n727 class Value(SQLiteNumericMixin, Expression):\n728     \"\"\"Represent a wrapped value as a node within an expression.\"\"\"\n729     # Provide a default value for `for_save` in order to allow unresolved\n730     # instances to be compiled until a decision is taken in #25425.\n731     for_save = False\n732 \n733     def __init__(self, value, output_field=None):\n734         \"\"\"\n735         Arguments:\n736          * value: the value this expression represents. The value will be\n737            added into the sql parameter list and properly quoted.\n738 \n739          * output_field: an instance of the model field type that this\n740            expression will return, such as IntegerField() or CharField().\n741         \"\"\"\n742         super().__init__(output_field=output_field)\n743         self.value = value\n744 \n745     def __repr__(self):\n746         return f'{self.__class__.__name__}({self.value!r})'\n747 \n748     def as_sql(self, compiler, connection):\n749         connection.ops.check_expression_support(self)\n750         val = self.value\n751         output_field = self._output_field_or_none\n752         if output_field is not None:\n753             if self.for_save:\n754                 val = output_field.get_db_prep_save(val, connection=connection)\n755             else:\n756                 val = output_field.get_db_prep_value(val, connection=connection)\n757             if hasattr(output_field, 'get_placeholder'):\n758                 return output_field.get_placeholder(val, compiler, connection), [val]\n759         if val is None:\n760             # cx_Oracle does not always convert None to the appropriate\n761             # NULL type (like in case expressions using numbers), so we\n762             # use a literal SQL NULL\n763             return 'NULL', []\n764         return '%s', [val]\n765 \n766     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n767         c = super().resolve_expression(query, allow_joins, reuse, summarize, for_save)\n768         c.for_save = for_save\n769         return c\n770 \n771     def get_group_by_cols(self, alias=None):\n772         return []\n773 \n774     def _resolve_output_field(self):\n775         if isinstance(self.value, str):\n776             return fields.CharField()\n777         if isinstance(self.value, bool):\n778             return fields.BooleanField()\n779         if isinstance(self.value, int):\n780             return fields.IntegerField()\n781         if isinstance(self.value, float):\n782             return fields.FloatField()\n783         if isinstance(self.value, datetime.datetime):\n784             return fields.DateTimeField()\n785         if isinstance(self.value, datetime.date):\n786             return fields.DateField()\n787         if isinstance(self.value, datetime.time):\n788             return fields.TimeField()\n789         if isinstance(self.value, datetime.timedelta):\n790             return fields.DurationField()\n791         if isinstance(self.value, Decimal):\n792             return fields.DecimalField()\n793         if isinstance(self.value, bytes):\n794             return fields.BinaryField()\n795         if isinstance(self.value, UUID):\n796             return fields.UUIDField()\n797 \n798 \n799 class RawSQL(Expression):\n800     def __init__(self, sql, params, output_field=None):\n801         if output_field is None:\n802             output_field = fields.Field()\n803         self.sql, self.params = sql, params\n804         super().__init__(output_field=output_field)\n805 \n806     def __repr__(self):\n807         return \"{}({}, {})\".format(self.__class__.__name__, self.sql, self.params)\n808 \n809     def as_sql(self, compiler, connection):\n810         return '(%s)' % self.sql, self.params\n811 \n812     def get_group_by_cols(self, alias=None):\n813         return [self]\n814 \n815     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n816         # Resolve parents fields used in raw SQL.\n817         for parent in query.model._meta.get_parent_list():\n818             for parent_field in parent._meta.local_fields:\n819                 _, column_name = parent_field.get_attname_column()\n820                 if column_name.lower() in self.sql.lower():\n821                     query.resolve_ref(parent_field.name, allow_joins, reuse, summarize)\n822                     break\n823         return super().resolve_expression(query, allow_joins, reuse, summarize, for_save)\n824 \n825 \n826 class Star(Expression):\n827     def __repr__(self):\n828         return \"'*'\"\n829 \n830     def as_sql(self, compiler, connection):\n831         return '*', []\n832 \n833 \n834 class Col(Expression):\n835 \n836     contains_column_references = True\n837     possibly_multivalued = False\n838 \n839     def __init__(self, alias, target, output_field=None):\n840         if output_field is None:\n841             output_field = target\n842         super().__init__(output_field=output_field)\n843         self.alias, self.target = alias, target\n844 \n845     def __repr__(self):\n846         alias, target = self.alias, self.target\n847         identifiers = (alias, str(target)) if alias else (str(target),)\n848         return '{}({})'.format(self.__class__.__name__, ', '.join(identifiers))\n849 \n850     def as_sql(self, compiler, connection):\n851         alias, column = self.alias, self.target.column\n852         identifiers = (alias, column) if alias else (column,)\n853         sql = '.'.join(map(compiler.quote_name_unless_alias, identifiers))\n854         return sql, []\n855 \n856     def relabeled_clone(self, relabels):\n857         if self.alias is None:\n858             return self\n859         return self.__class__(relabels.get(self.alias, self.alias), self.target, self.output_field)\n860 \n861     def get_group_by_cols(self, alias=None):\n862         return [self]\n863 \n864     def get_db_converters(self, connection):\n865         if self.target == self.output_field:\n866             return self.output_field.get_db_converters(connection)\n867         return (self.output_field.get_db_converters(connection) +\n868                 self.target.get_db_converters(connection))\n869 \n870 \n871 class Ref(Expression):\n872     \"\"\"\n873     Reference to column alias of the query. For example, Ref('sum_cost') in\n874     qs.annotate(sum_cost=Sum('cost')) query.\n875     \"\"\"\n876     def __init__(self, refs, source):\n877         super().__init__()\n878         self.refs, self.source = refs, source\n879 \n880     def __repr__(self):\n881         return \"{}({}, {})\".format(self.__class__.__name__, self.refs, self.source)\n882 \n883     def get_source_expressions(self):\n884         return [self.source]\n885 \n886     def set_source_expressions(self, exprs):\n887         self.source, = exprs\n888 \n889     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n890         # The sub-expression `source` has already been resolved, as this is\n891         # just a reference to the name of `source`.\n892         return self\n893 \n894     def relabeled_clone(self, relabels):\n895         return self\n896 \n897     def as_sql(self, compiler, connection):\n898         return connection.ops.quote_name(self.refs), []\n899 \n900     def get_group_by_cols(self, alias=None):\n901         return [self]\n902 \n903 \n904 class ExpressionList(Func):\n905     \"\"\"\n906     An expression containing multiple expressions. Can be used to provide a\n907     list of expressions as an argument to another expression, like an\n908     ordering clause.\n909     \"\"\"\n910     template = '%(expressions)s'\n911 \n912     def __init__(self, *expressions, **extra):\n913         if not expressions:\n914             raise ValueError('%s requires at least one expression.' % self.__class__.__name__)\n915         super().__init__(*expressions, **extra)\n916 \n917     def __str__(self):\n918         return self.arg_joiner.join(str(arg) for arg in self.source_expressions)\n919 \n920     def as_sqlite(self, compiler, connection, **extra_context):\n921         # Casting to numeric is unnecessary.\n922         return self.as_sql(compiler, connection, **extra_context)\n923 \n924 \n925 class ExpressionWrapper(Expression):\n926     \"\"\"\n927     An expression that can wrap another expression so that it can provide\n928     extra context to the inner expression, such as the output_field.\n929     \"\"\"\n930 \n931     def __init__(self, expression, output_field):\n932         super().__init__(output_field=output_field)\n933         self.expression = expression\n934 \n935     def set_source_expressions(self, exprs):\n936         self.expression = exprs[0]\n937 \n938     def get_source_expressions(self):\n939         return [self.expression]\n940 \n941     def get_group_by_cols(self, alias=None):\n942         if isinstance(self.expression, Expression):\n943             expression = self.expression.copy()\n944             expression.output_field = self.output_field\n945             return expression.get_group_by_cols(alias=alias)\n946         # For non-expressions e.g. an SQL WHERE clause, the entire\n947         # `expression` must be included in the GROUP BY clause.\n948         return super().get_group_by_cols()\n949 \n950     def as_sql(self, compiler, connection):\n951         return compiler.compile(self.expression)\n952 \n953     def __repr__(self):\n954         return \"{}({})\".format(self.__class__.__name__, self.expression)\n955 \n956 \n957 class When(Expression):\n958     template = 'WHEN %(condition)s THEN %(result)s'\n959     # This isn't a complete conditional expression, must be used in Case().\n960     conditional = False\n961 \n962     def __init__(self, condition=None, then=None, **lookups):\n963         if lookups:\n964             if condition is None:\n965                 condition, lookups = Q(**lookups), None\n966             elif getattr(condition, 'conditional', False):\n967                 condition, lookups = Q(condition, **lookups), None\n968         if condition is None or not getattr(condition, 'conditional', False) or lookups:\n969             raise TypeError(\n970                 'When() supports a Q object, a boolean expression, or lookups '\n971                 'as a condition.'\n972             )\n973         if isinstance(condition, Q) and not condition:\n974             raise ValueError(\"An empty Q() can't be used as a When() condition.\")\n975         super().__init__(output_field=None)\n976         self.condition = condition\n977         self.result = self._parse_expressions(then)[0]\n978 \n979     def __str__(self):\n980         return \"WHEN %r THEN %r\" % (self.condition, self.result)\n981 \n982     def __repr__(self):\n983         return \"<%s: %s>\" % (self.__class__.__name__, self)\n984 \n985     def get_source_expressions(self):\n986         return [self.condition, self.result]\n987 \n988     def set_source_expressions(self, exprs):\n989         self.condition, self.result = exprs\n990 \n991     def get_source_fields(self):\n992         # We're only interested in the fields of the result expressions.\n993         return [self.result._output_field_or_none]\n994 \n995     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n996         c = self.copy()\n997         c.is_summary = summarize\n998         if hasattr(c.condition, 'resolve_expression'):\n999             c.condition = c.condition.resolve_expression(query, allow_joins, reuse, summarize, False)\n1000         c.result = c.result.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n1001         return c\n1002 \n1003     def as_sql(self, compiler, connection, template=None, **extra_context):\n1004         connection.ops.check_expression_support(self)\n1005         template_params = extra_context\n1006         sql_params = []\n1007         condition_sql, condition_params = compiler.compile(self.condition)\n1008         template_params['condition'] = condition_sql\n1009         sql_params.extend(condition_params)\n1010         result_sql, result_params = compiler.compile(self.result)\n1011         template_params['result'] = result_sql\n1012         sql_params.extend(result_params)\n1013         template = template or self.template\n1014         return template % template_params, sql_params\n1015 \n1016     def get_group_by_cols(self, alias=None):\n1017         # This is not a complete expression and cannot be used in GROUP BY.\n1018         cols = []\n1019         for source in self.get_source_expressions():\n1020             cols.extend(source.get_group_by_cols())\n1021         return cols\n1022 \n1023 \n1024 class Case(Expression):\n1025     \"\"\"\n1026     An SQL searched CASE expression:\n1027 \n1028         CASE\n1029             WHEN n > 0\n1030                 THEN 'positive'\n1031             WHEN n < 0\n1032                 THEN 'negative'\n1033             ELSE 'zero'\n1034         END\n1035     \"\"\"\n1036     template = 'CASE %(cases)s ELSE %(default)s END'\n1037     case_joiner = ' '\n1038 \n1039     def __init__(self, *cases, default=None, output_field=None, **extra):\n1040         if not all(isinstance(case, When) for case in cases):\n1041             raise TypeError(\"Positional arguments must all be When objects.\")\n1042         super().__init__(output_field)\n1043         self.cases = list(cases)\n1044         self.default = self._parse_expressions(default)[0]\n1045         self.extra = extra\n1046 \n1047     def __str__(self):\n1048         return \"CASE %s, ELSE %r\" % (', '.join(str(c) for c in self.cases), self.default)\n1049 \n1050     def __repr__(self):\n1051         return \"<%s: %s>\" % (self.__class__.__name__, self)\n1052 \n1053     def get_source_expressions(self):\n1054         return self.cases + [self.default]\n1055 \n1056     def set_source_expressions(self, exprs):\n1057         *self.cases, self.default = exprs\n1058 \n1059     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n1060         c = self.copy()\n1061         c.is_summary = summarize\n1062         for pos, case in enumerate(c.cases):\n1063             c.cases[pos] = case.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n1064         c.default = c.default.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n1065         return c\n1066 \n1067     def copy(self):\n1068         c = super().copy()\n1069         c.cases = c.cases[:]\n1070         return c\n1071 \n1072     def as_sql(self, compiler, connection, template=None, case_joiner=None, **extra_context):\n1073         connection.ops.check_expression_support(self)\n1074         if not self.cases:\n1075             return compiler.compile(self.default)\n1076         template_params = {**self.extra, **extra_context}\n1077         case_parts = []\n1078         sql_params = []\n1079         for case in self.cases:\n1080             try:\n1081                 case_sql, case_params = compiler.compile(case)\n1082             except EmptyResultSet:\n1083                 continue\n1084             case_parts.append(case_sql)\n1085             sql_params.extend(case_params)\n1086         default_sql, default_params = compiler.compile(self.default)\n1087         if not case_parts:\n1088             return default_sql, default_params\n1089         case_joiner = case_joiner or self.case_joiner\n1090         template_params['cases'] = case_joiner.join(case_parts)\n1091         template_params['default'] = default_sql\n1092         sql_params.extend(default_params)\n1093         template = template or template_params.get('template', self.template)\n1094         sql = template % template_params\n1095         if self._output_field_or_none is not None:\n1096             sql = connection.ops.unification_cast_sql(self.output_field) % sql\n1097         return sql, sql_params\n1098 \n1099     def get_group_by_cols(self, alias=None):\n1100         if not self.cases:\n1101             return self.default.get_group_by_cols(alias)\n1102         return super().get_group_by_cols(alias)\n1103 \n1104 \n1105 class Subquery(BaseExpression, Combinable):\n1106     \"\"\"\n1107     An explicit subquery. It may contain OuterRef() references to the outer\n1108     query which will be resolved when it is applied to that query.\n1109     \"\"\"\n1110     template = '(%(subquery)s)'\n1111     contains_aggregate = False\n1112 \n1113     def __init__(self, queryset, output_field=None, **extra):\n1114         # Allow the usage of both QuerySet and sql.Query objects.\n1115         self.query = getattr(queryset, 'query', queryset)\n1116         self.extra = extra\n1117         super().__init__(output_field)\n1118 \n1119     def get_source_expressions(self):\n1120         return [self.query]\n1121 \n1122     def set_source_expressions(self, exprs):\n1123         self.query = exprs[0]\n1124 \n1125     def _resolve_output_field(self):\n1126         return self.query.output_field\n1127 \n1128     def copy(self):\n1129         clone = super().copy()\n1130         clone.query = clone.query.clone()\n1131         return clone\n1132 \n1133     @property\n1134     def external_aliases(self):\n1135         return self.query.external_aliases\n1136 \n1137     def get_external_cols(self):\n1138         return self.query.get_external_cols()\n1139 \n1140     def as_sql(self, compiler, connection, template=None, query=None, **extra_context):\n1141         connection.ops.check_expression_support(self)\n1142         template_params = {**self.extra, **extra_context}\n1143         query = query or self.query\n1144         subquery_sql, sql_params = query.as_sql(compiler, connection)\n1145         template_params['subquery'] = subquery_sql[1:-1]\n1146 \n1147         template = template or template_params.get('template', self.template)\n1148         sql = template % template_params\n1149         return sql, sql_params\n1150 \n1151     def get_group_by_cols(self, alias=None):\n1152         if alias:\n1153             return [Ref(alias, self)]\n1154         external_cols = self.get_external_cols()\n1155         if any(col.possibly_multivalued for col in external_cols):\n1156             return [self]\n1157         return external_cols\n1158 \n1159 \n1160 class Exists(Subquery):\n1161     template = 'EXISTS(%(subquery)s)'\n1162     output_field = fields.BooleanField()\n1163 \n1164     def __init__(self, queryset, negated=False, **kwargs):\n1165         self.negated = negated\n1166         super().__init__(queryset, **kwargs)\n1167 \n1168     def __invert__(self):\n1169         clone = self.copy()\n1170         clone.negated = not self.negated\n1171         return clone\n1172 \n1173     def as_sql(self, compiler, connection, template=None, **extra_context):\n1174         query = self.query.exists(using=connection.alias)\n1175         sql, params = super().as_sql(\n1176             compiler,\n1177             connection,\n1178             template=template,\n1179             query=query,\n1180             **extra_context,\n1181         )\n1182         if self.negated:\n1183             sql = 'NOT {}'.format(sql)\n1184         return sql, params\n1185 \n1186     def select_format(self, compiler, sql, params):\n1187         # Wrap EXISTS() with a CASE WHEN expression if a database backend\n1188         # (e.g. Oracle) doesn't support boolean expression in SELECT or GROUP\n1189         # BY list.\n1190         if not compiler.connection.features.supports_boolean_expr_in_select_clause:\n1191             sql = 'CASE WHEN {} THEN 1 ELSE 0 END'.format(sql)\n1192         return sql, params\n1193 \n1194 \n1195 class OrderBy(Expression):\n1196     template = '%(expression)s %(ordering)s'\n1197     conditional = False\n1198 \n1199     def __init__(self, expression, descending=False, nulls_first=False, nulls_last=False):\n1200         if nulls_first and nulls_last:\n1201             raise ValueError('nulls_first and nulls_last are mutually exclusive')\n1202         self.nulls_first = nulls_first\n1203         self.nulls_last = nulls_last\n1204         self.descending = descending\n1205         if not hasattr(expression, 'resolve_expression'):\n1206             raise ValueError('expression must be an expression type')\n1207         self.expression = expression\n1208 \n1209     def __repr__(self):\n1210         return \"{}({}, descending={})\".format(\n1211             self.__class__.__name__, self.expression, self.descending)\n1212 \n1213     def set_source_expressions(self, exprs):\n1214         self.expression = exprs[0]\n1215 \n1216     def get_source_expressions(self):\n1217         return [self.expression]\n1218 \n1219     def as_sql(self, compiler, connection, template=None, **extra_context):\n1220         template = template or self.template\n1221         if connection.features.supports_order_by_nulls_modifier:\n1222             if self.nulls_last:\n1223                 template = '%s NULLS LAST' % template\n1224             elif self.nulls_first:\n1225                 template = '%s NULLS FIRST' % template\n1226         else:\n1227             if self.nulls_last and not (\n1228                 self.descending and connection.features.order_by_nulls_first\n1229             ):\n1230                 template = '%%(expression)s IS NULL, %s' % template\n1231             elif self.nulls_first and not (\n1232                 not self.descending and connection.features.order_by_nulls_first\n1233             ):\n1234                 template = '%%(expression)s IS NOT NULL, %s' % template\n1235         connection.ops.check_expression_support(self)\n1236         expression_sql, params = compiler.compile(self.expression)\n1237         placeholders = {\n1238             'expression': expression_sql,\n1239             'ordering': 'DESC' if self.descending else 'ASC',\n1240             **extra_context,\n1241         }\n1242         params *= template.count('%(expression)s')\n1243         return (template % placeholders).rstrip(), params\n1244 \n1245     def as_oracle(self, compiler, connection):\n1246         # Oracle doesn't allow ORDER BY EXISTS() unless it's wrapped in\n1247         # a CASE WHEN.\n1248         if isinstance(self.expression, Exists):\n1249             copy = self.copy()\n1250             copy.expression = Case(\n1251                 When(self.expression, then=True),\n1252                 default=False,\n1253             )\n1254             return copy.as_sql(compiler, connection)\n1255         return self.as_sql(compiler, connection)\n1256 \n1257     def get_group_by_cols(self, alias=None):\n1258         cols = []\n1259         for source in self.get_source_expressions():\n1260             cols.extend(source.get_group_by_cols())\n1261         return cols\n1262 \n1263     def reverse_ordering(self):\n1264         self.descending = not self.descending\n1265         if self.nulls_first or self.nulls_last:\n1266             self.nulls_first = not self.nulls_first\n1267             self.nulls_last = not self.nulls_last\n1268         return self\n1269 \n1270     def asc(self):\n1271         self.descending = False\n1272 \n1273     def desc(self):\n1274         self.descending = True\n1275 \n1276 \n1277 class Window(SQLiteNumericMixin, Expression):\n1278     template = '%(expression)s OVER (%(window)s)'\n1279     # Although the main expression may either be an aggregate or an\n1280     # expression with an aggregate function, the GROUP BY that will\n1281     # be introduced in the query as a result is not desired.\n1282     contains_aggregate = False\n1283     contains_over_clause = True\n1284     filterable = False\n1285 \n1286     def __init__(self, expression, partition_by=None, order_by=None, frame=None, output_field=None):\n1287         self.partition_by = partition_by\n1288         self.order_by = order_by\n1289         self.frame = frame\n1290 \n1291         if not getattr(expression, 'window_compatible', False):\n1292             raise ValueError(\n1293                 \"Expression '%s' isn't compatible with OVER clauses.\" %\n1294                 expression.__class__.__name__\n1295             )\n1296 \n1297         if self.partition_by is not None:\n1298             if not isinstance(self.partition_by, (tuple, list)):\n1299                 self.partition_by = (self.partition_by,)\n1300             self.partition_by = ExpressionList(*self.partition_by)\n1301 \n1302         if self.order_by is not None:\n1303             if isinstance(self.order_by, (list, tuple)):\n1304                 self.order_by = ExpressionList(*self.order_by)\n1305             elif not isinstance(self.order_by, BaseExpression):\n1306                 raise ValueError(\n1307                     'order_by must be either an Expression or a sequence of '\n1308                     'expressions.'\n1309                 )\n1310         super().__init__(output_field=output_field)\n1311         self.source_expression = self._parse_expressions(expression)[0]\n1312 \n1313     def _resolve_output_field(self):\n1314         return self.source_expression.output_field\n1315 \n1316     def get_source_expressions(self):\n1317         return [self.source_expression, self.partition_by, self.order_by, self.frame]\n1318 \n1319     def set_source_expressions(self, exprs):\n1320         self.source_expression, self.partition_by, self.order_by, self.frame = exprs\n1321 \n1322     def as_sql(self, compiler, connection, template=None):\n1323         connection.ops.check_expression_support(self)\n1324         if not connection.features.supports_over_clause:\n1325             raise NotSupportedError('This backend does not support window expressions.')\n1326         expr_sql, params = compiler.compile(self.source_expression)\n1327         window_sql, window_params = [], []\n1328 \n1329         if self.partition_by is not None:\n1330             sql_expr, sql_params = self.partition_by.as_sql(\n1331                 compiler=compiler, connection=connection,\n1332                 template='PARTITION BY %(expressions)s',\n1333             )\n1334             window_sql.extend(sql_expr)\n1335             window_params.extend(sql_params)\n1336 \n1337         if self.order_by is not None:\n1338             window_sql.append(' ORDER BY ')\n1339             order_sql, order_params = compiler.compile(self.order_by)\n1340             window_sql.extend(order_sql)\n1341             window_params.extend(order_params)\n1342 \n1343         if self.frame:\n1344             frame_sql, frame_params = compiler.compile(self.frame)\n1345             window_sql.append(' ' + frame_sql)\n1346             window_params.extend(frame_params)\n1347 \n1348         params.extend(window_params)\n1349         template = template or self.template\n1350 \n1351         return template % {\n1352             'expression': expr_sql,\n1353             'window': ''.join(window_sql).strip()\n1354         }, params\n1355 \n1356     def as_sqlite(self, compiler, connection):\n1357         if isinstance(self.output_field, fields.DecimalField):\n1358             # Casting to numeric must be outside of the window expression.\n1359             copy = self.copy()\n1360             source_expressions = copy.get_source_expressions()\n1361             source_expressions[0].output_field = fields.FloatField()\n1362             copy.set_source_expressions(source_expressions)\n1363             return super(Window, copy).as_sqlite(compiler, connection)\n1364         return self.as_sql(compiler, connection)\n1365 \n1366     def __str__(self):\n1367         return '{} OVER ({}{}{})'.format(\n1368             str(self.source_expression),\n1369             'PARTITION BY ' + str(self.partition_by) if self.partition_by else '',\n1370             'ORDER BY ' + str(self.order_by) if self.order_by else '',\n1371             str(self.frame or ''),\n1372         )\n1373 \n1374     def __repr__(self):\n1375         return '<%s: %s>' % (self.__class__.__name__, self)\n1376 \n1377     def get_group_by_cols(self, alias=None):\n1378         return []\n1379 \n1380 \n1381 class WindowFrame(Expression):\n1382     \"\"\"\n1383     Model the frame clause in window expressions. There are two types of frame\n1384     clauses which are subclasses, however, all processing and validation (by no\n1385     means intended to be complete) is done here. Thus, providing an end for a\n1386     frame is optional (the default is UNBOUNDED FOLLOWING, which is the last\n1387     row in the frame).\n1388     \"\"\"\n1389     template = '%(frame_type)s BETWEEN %(start)s AND %(end)s'\n1390 \n1391     def __init__(self, start=None, end=None):\n1392         self.start = Value(start)\n1393         self.end = Value(end)\n1394 \n1395     def set_source_expressions(self, exprs):\n1396         self.start, self.end = exprs\n1397 \n1398     def get_source_expressions(self):\n1399         return [self.start, self.end]\n1400 \n1401     def as_sql(self, compiler, connection):\n1402         connection.ops.check_expression_support(self)\n1403         start, end = self.window_frame_start_end(connection, self.start.value, self.end.value)\n1404         return self.template % {\n1405             'frame_type': self.frame_type,\n1406             'start': start,\n1407             'end': end,\n1408         }, []\n1409 \n1410     def __repr__(self):\n1411         return '<%s: %s>' % (self.__class__.__name__, self)\n1412 \n1413     def get_group_by_cols(self, alias=None):\n1414         return []\n1415 \n1416     def __str__(self):\n1417         if self.start.value is not None and self.start.value < 0:\n1418             start = '%d %s' % (abs(self.start.value), connection.ops.PRECEDING)\n1419         elif self.start.value is not None and self.start.value == 0:\n1420             start = connection.ops.CURRENT_ROW\n1421         else:\n1422             start = connection.ops.UNBOUNDED_PRECEDING\n1423 \n1424         if self.end.value is not None and self.end.value > 0:\n1425             end = '%d %s' % (self.end.value, connection.ops.FOLLOWING)\n1426         elif self.end.value is not None and self.end.value == 0:\n1427             end = connection.ops.CURRENT_ROW\n1428         else:\n1429             end = connection.ops.UNBOUNDED_FOLLOWING\n1430         return self.template % {\n1431             'frame_type': self.frame_type,\n1432             'start': start,\n1433             'end': end,\n1434         }\n1435 \n1436     def window_frame_start_end(self, connection, start, end):\n1437         raise NotImplementedError('Subclasses must implement window_frame_start_end().')\n1438 \n1439 \n1440 class RowRange(WindowFrame):\n1441     frame_type = 'ROWS'\n1442 \n1443     def window_frame_start_end(self, connection, start, end):\n1444         return connection.ops.window_frame_rows_start_end(start, end)\n1445 \n1446 \n1447 class ValueRange(WindowFrame):\n1448     frame_type = 'RANGE'\n1449 \n1450     def window_frame_start_end(self, connection, start, end):\n1451         return connection.ops.window_frame_range_start_end(start, end)\n",
        "intended_behavior": "Update or ensure that when expressions involving 'Coalesce' are evaluated, especially in the context of an anticipated 'EmptyResultSet' from a filter condition like 'pk__in=[]', the expression logic defaults to the 'Coalesce' specified value instead of yielding 'None'. This would ensure that 'Coalesce' effectively provides a default value even when no rows are matched, addressing the core issue and maintaining existing functionality where applicable."
    }
]