[
    {
        "rel_file_path": "django/db/backends/mysql/schema.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__4.1/django/db/backends/mysql/schema.py",
        "start": 1,
        "end": 174,
        "class_name": null,
        "method_name": null,
        "code": "1 from django.db.backends.base.schema import BaseDatabaseSchemaEditor\n2 from django.db.models import NOT_PROVIDED\n3 \n4 \n5 class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n6 \n7     sql_rename_table = \"RENAME TABLE %(old_table)s TO %(new_table)s\"\n8 \n9     sql_alter_column_null = \"MODIFY %(column)s %(type)s NULL\"\n10     sql_alter_column_not_null = \"MODIFY %(column)s %(type)s NOT NULL\"\n11     sql_alter_column_type = \"MODIFY %(column)s %(type)s\"\n12     sql_alter_column_collate = \"MODIFY %(column)s %(type)s%(collation)s\"\n13     sql_alter_column_no_default_null = \"ALTER COLUMN %(column)s SET DEFAULT NULL\"\n14 \n15     # No 'CASCADE' which works as a no-op in MySQL but is undocumented\n16     sql_delete_column = \"ALTER TABLE %(table)s DROP COLUMN %(column)s\"\n17 \n18     sql_delete_unique = \"ALTER TABLE %(table)s DROP INDEX %(name)s\"\n19     sql_create_column_inline_fk = (\n20         \", ADD CONSTRAINT %(name)s FOREIGN KEY (%(column)s) \"\n21         \"REFERENCES %(to_table)s(%(to_column)s)\"\n22     )\n23     sql_delete_fk = \"ALTER TABLE %(table)s DROP FOREIGN KEY %(name)s\"\n24 \n25     sql_delete_index = \"DROP INDEX %(name)s ON %(table)s\"\n26 \n27     sql_create_pk = (\n28         \"ALTER TABLE %(table)s ADD CONSTRAINT %(name)s PRIMARY KEY (%(columns)s)\"\n29     )\n30     sql_delete_pk = \"ALTER TABLE %(table)s DROP PRIMARY KEY\"\n31 \n32     sql_create_index = \"CREATE INDEX %(name)s ON %(table)s (%(columns)s)%(extra)s\"\n33 \n34     @property\n35     def sql_delete_check(self):\n36         if self.connection.mysql_is_mariadb:\n37             # The name of the column check constraint is the same as the field\n38             # name on MariaDB. Adding IF EXISTS clause prevents migrations\n39             # crash. Constraint is removed during a \"MODIFY\" column statement.\n40             return \"ALTER TABLE %(table)s DROP CONSTRAINT IF EXISTS %(name)s\"\n41         return \"ALTER TABLE %(table)s DROP CHECK %(name)s\"\n42 \n43     @property\n44     def sql_rename_column(self):\n45         # MariaDB >= 10.5.2 and MySQL >= 8.0.4 support an\n46         # \"ALTER TABLE ... RENAME COLUMN\" statement.\n47         if self.connection.mysql_is_mariadb:\n48             if self.connection.mysql_version >= (10, 5, 2):\n49                 return super().sql_rename_column\n50         elif self.connection.mysql_version >= (8, 0, 4):\n51             return super().sql_rename_column\n52         return \"ALTER TABLE %(table)s CHANGE %(old_column)s %(new_column)s %(type)s\"\n53 \n54     def quote_value(self, value):\n55         self.connection.ensure_connection()\n56         if isinstance(value, str):\n57             value = value.replace(\"%\", \"%%\")\n58         # MySQLdb escapes to string, PyMySQL to bytes.\n59         quoted = self.connection.connection.escape(\n60             value, self.connection.connection.encoders\n61         )\n62         if isinstance(value, str) and isinstance(quoted, bytes):\n63             quoted = quoted.decode()\n64         return quoted\n65 \n66     def _is_limited_data_type(self, field):\n67         db_type = field.db_type(self.connection)\n68         return (\n69             db_type is not None\n70             and db_type.lower() in self.connection._limited_data_types\n71         )\n72 \n73     def skip_default(self, field):\n74         if not self._supports_limited_data_type_defaults:\n75             return self._is_limited_data_type(field)\n76         return False\n77 \n78     def skip_default_on_alter(self, field):\n79         if self._is_limited_data_type(field) and not self.connection.mysql_is_mariadb:\n80             # MySQL doesn't support defaults for BLOB and TEXT in the\n81             # ALTER COLUMN statement.\n82             return True\n83         return False\n84 \n85     @property\n86     def _supports_limited_data_type_defaults(self):\n87         # MariaDB and MySQL >= 8.0.13 support defaults for BLOB and TEXT.\n88         if self.connection.mysql_is_mariadb:\n89             return True\n90         return self.connection.mysql_version >= (8, 0, 13)\n91 \n92     def _column_default_sql(self, field):\n93         if (\n94             not self.connection.mysql_is_mariadb\n95             and self._supports_limited_data_type_defaults\n96             and self._is_limited_data_type(field)\n97         ):\n98             # MySQL supports defaults for BLOB and TEXT columns only if the\n99             # default value is written as an expression i.e. in parentheses.\n100             return \"(%s)\"\n101         return super()._column_default_sql(field)\n102 \n103     def add_field(self, model, field):\n104         super().add_field(model, field)\n105 \n106         # Simulate the effect of a one-off default.\n107         # field.default may be unhashable, so a set isn't used for \"in\" check.\n108         if self.skip_default(field) and field.default not in (None, NOT_PROVIDED):\n109             effective_default = self.effective_default(field)\n110             self.execute(\n111                 \"UPDATE %(table)s SET %(column)s = %%s\"\n112                 % {\n113                     \"table\": self.quote_name(model._meta.db_table),\n114                     \"column\": self.quote_name(field.column),\n115                 },\n116                 [effective_default],\n117             )\n118 \n119     def _field_should_be_indexed(self, model, field):\n120         if not super()._field_should_be_indexed(model, field):\n121             return False\n122 \n123         storage = self.connection.introspection.get_storage_engine(\n124             self.connection.cursor(), model._meta.db_table\n125         )\n126         # No need to create an index for ForeignKey fields except if\n127         # db_constraint=False because the index from that constraint won't be\n128         # created.\n129         if (\n130             storage == \"InnoDB\"\n131             and field.get_internal_type() == \"ForeignKey\"\n132             and field.db_constraint\n133         ):\n134             return False\n135         return not self._is_limited_data_type(field)\n136 \n137     def _delete_composed_index(self, model, fields, *args):\n138         \"\"\"\n139         MySQL can remove an implicit FK index on a field when that field is\n140         covered by another index like a unique_together. \"covered\" here means\n141         that the more complex index starts like the simpler one.\n142         https://bugs.mysql.com/bug.php?id=37910 / Django ticket #24757\n143         We check here before removing the [unique|index]_together if we have to\n144         recreate a FK index.\n145         \"\"\"\n146         first_field = model._meta.get_field(fields[0])\n147         if first_field.get_internal_type() == \"ForeignKey\":\n148             constraint_names = self._constraint_names(\n149                 model, [first_field.column], index=True\n150             )\n151             if not constraint_names:\n152                 self.execute(\n153                     self._create_index_sql(model, fields=[first_field], suffix=\"\")\n154                 )\n155         return super()._delete_composed_index(model, fields, *args)\n156 \n157     def _set_field_new_type_null_status(self, field, new_type):\n158         \"\"\"\n159         Keep the null property of the old field. If it has changed, it will be\n160         handled separately.\n161         \"\"\"\n162         if field.null:\n163             new_type += \" NULL\"\n164         else:\n165             new_type += \" NOT NULL\"\n166         return new_type\n167 \n168     def _alter_column_type_sql(self, model, old_field, new_field, new_type):\n169         new_type = self._set_field_new_type_null_status(old_field, new_type)\n170         return super()._alter_column_type_sql(model, old_field, new_field, new_type)\n171 \n172     def _rename_field_sql(self, table, old_field, new_field, new_type):\n173         new_type = self._set_field_new_type_null_status(old_field, new_type)\n174         return super()._rename_field_sql(table, old_field, new_field, new_type)\n",
        "intended_behavior": "Ensure that when a foreign key is added or modified, the `db_collation` of the referenced primary key column is applied to the foreign key column. This may involve adjusting the SQL statement generation to include the `COLLATE` clause with the appropriate collation when altering foreign key columns."
    },
    {
        "rel_file_path": "django/db/migrations/autodetector.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__4.1/django/db/migrations/autodetector.py",
        "start": 1,
        "end": 1605,
        "class_name": null,
        "method_name": null,
        "code": "1 import functools\n2 import re\n3 from itertools import chain\n4 \n5 from django.conf import settings\n6 from django.db import models\n7 from django.db.migrations import operations\n8 from django.db.migrations.migration import Migration\n9 from django.db.migrations.operations.models import AlterModelOptions\n10 from django.db.migrations.optimizer import MigrationOptimizer\n11 from django.db.migrations.questioner import MigrationQuestioner\n12 from django.db.migrations.utils import (\n13     COMPILED_REGEX_TYPE,\n14     RegexObject,\n15     resolve_relation,\n16 )\n17 from django.utils.topological_sort import stable_topological_sort\n18 \n19 \n20 class MigrationAutodetector:\n21     \"\"\"\n22     Take a pair of ProjectStates and compare them to see what the first would\n23     need doing to make it match the second (the second usually being the\n24     project's current state).\n25 \n26     Note that this naturally operates on entire projects at a time,\n27     as it's likely that changes interact (for example, you can't\n28     add a ForeignKey without having a migration to add the table it\n29     depends on first). A user interface may offer single-app usage\n30     if it wishes, with the caveat that it may not always be possible.\n31     \"\"\"\n32 \n33     def __init__(self, from_state, to_state, questioner=None):\n34         self.from_state = from_state\n35         self.to_state = to_state\n36         self.questioner = questioner or MigrationQuestioner()\n37         self.existing_apps = {app for app, model in from_state.models}\n38 \n39     def changes(self, graph, trim_to_apps=None, convert_apps=None, migration_name=None):\n40         \"\"\"\n41         Main entry point to produce a list of applicable changes.\n42         Take a graph to base names on and an optional set of apps\n43         to try and restrict to (restriction is not guaranteed)\n44         \"\"\"\n45         changes = self._detect_changes(convert_apps, graph)\n46         changes = self.arrange_for_graph(changes, graph, migration_name)\n47         if trim_to_apps:\n48             changes = self._trim_to_apps(changes, trim_to_apps)\n49         return changes\n50 \n51     def deep_deconstruct(self, obj):\n52         \"\"\"\n53         Recursive deconstruction for a field and its arguments.\n54         Used for full comparison for rename/alter; sometimes a single-level\n55         deconstruction will not compare correctly.\n56         \"\"\"\n57         if isinstance(obj, list):\n58             return [self.deep_deconstruct(value) for value in obj]\n59         elif isinstance(obj, tuple):\n60             return tuple(self.deep_deconstruct(value) for value in obj)\n61         elif isinstance(obj, dict):\n62             return {key: self.deep_deconstruct(value) for key, value in obj.items()}\n63         elif isinstance(obj, functools.partial):\n64             return (\n65                 obj.func,\n66                 self.deep_deconstruct(obj.args),\n67                 self.deep_deconstruct(obj.keywords),\n68             )\n69         elif isinstance(obj, COMPILED_REGEX_TYPE):\n70             return RegexObject(obj)\n71         elif isinstance(obj, type):\n72             # If this is a type that implements 'deconstruct' as an instance method,\n73             # avoid treating this as being deconstructible itself - see #22951\n74             return obj\n75         elif hasattr(obj, \"deconstruct\"):\n76             deconstructed = obj.deconstruct()\n77             if isinstance(obj, models.Field):\n78                 # we have a field which also returns a name\n79                 deconstructed = deconstructed[1:]\n80             path, args, kwargs = deconstructed\n81             return (\n82                 path,\n83                 [self.deep_deconstruct(value) for value in args],\n84                 {key: self.deep_deconstruct(value) for key, value in kwargs.items()},\n85             )\n86         else:\n87             return obj\n88 \n89     def only_relation_agnostic_fields(self, fields):\n90         \"\"\"\n91         Return a definition of the fields that ignores field names and\n92         what related fields actually relate to. Used for detecting renames (as\n93         the related fields change during renames).\n94         \"\"\"\n95         fields_def = []\n96         for name, field in sorted(fields.items()):\n97             deconstruction = self.deep_deconstruct(field)\n98             if field.remote_field and field.remote_field.model:\n99                 deconstruction[2].pop(\"to\", None)\n100             fields_def.append(deconstruction)\n101         return fields_def\n102 \n103     def _detect_changes(self, convert_apps=None, graph=None):\n104         \"\"\"\n105         Return a dict of migration plans which will achieve the\n106         change from from_state to to_state. The dict has app labels\n107         as keys and a list of migrations as values.\n108 \n109         The resulting migrations aren't specially named, but the names\n110         do matter for dependencies inside the set.\n111 \n112         convert_apps is the list of apps to convert to use migrations\n113         (i.e. to make initial migrations for, in the usual case)\n114 \n115         graph is an optional argument that, if provided, can help improve\n116         dependency generation and avoid potential circular dependencies.\n117         \"\"\"\n118         # The first phase is generating all the operations for each app\n119         # and gathering them into a big per-app list.\n120         # Then go through that list, order it, and split into migrations to\n121         # resolve dependencies caused by M2Ms and FKs.\n122         self.generated_operations = {}\n123         self.altered_indexes = {}\n124         self.altered_constraints = {}\n125 \n126         # Prepare some old/new state and model lists, separating\n127         # proxy models and ignoring unmigrated apps.\n128         self.old_model_keys = set()\n129         self.old_proxy_keys = set()\n130         self.old_unmanaged_keys = set()\n131         self.new_model_keys = set()\n132         self.new_proxy_keys = set()\n133         self.new_unmanaged_keys = set()\n134         for (app_label, model_name), model_state in self.from_state.models.items():\n135             if not model_state.options.get(\"managed\", True):\n136                 self.old_unmanaged_keys.add((app_label, model_name))\n137             elif app_label not in self.from_state.real_apps:\n138                 if model_state.options.get(\"proxy\"):\n139                     self.old_proxy_keys.add((app_label, model_name))\n140                 else:\n141                     self.old_model_keys.add((app_label, model_name))\n142 \n143         for (app_label, model_name), model_state in self.to_state.models.items():\n144             if not model_state.options.get(\"managed\", True):\n145                 self.new_unmanaged_keys.add((app_label, model_name))\n146             elif app_label not in self.from_state.real_apps or (\n147                 convert_apps and app_label in convert_apps\n148             ):\n149                 if model_state.options.get(\"proxy\"):\n150                     self.new_proxy_keys.add((app_label, model_name))\n151                 else:\n152                     self.new_model_keys.add((app_label, model_name))\n153 \n154         self.from_state.resolve_fields_and_relations()\n155         self.to_state.resolve_fields_and_relations()\n156 \n157         # Renames have to come first\n158         self.generate_renamed_models()\n159 \n160         # Prepare lists of fields and generate through model map\n161         self._prepare_field_lists()\n162         self._generate_through_model_map()\n163 \n164         # Generate non-rename model operations\n165         self.generate_deleted_models()\n166         self.generate_created_models()\n167         self.generate_deleted_proxies()\n168         self.generate_created_proxies()\n169         self.generate_altered_options()\n170         self.generate_altered_managers()\n171 \n172         # Create the altered indexes and store them in self.altered_indexes.\n173         # This avoids the same computation in generate_removed_indexes()\n174         # and generate_added_indexes().\n175         self.create_altered_indexes()\n176         self.create_altered_constraints()\n177         # Generate index removal operations before field is removed\n178         self.generate_removed_constraints()\n179         self.generate_removed_indexes()\n180         # Generate field renaming operations.\n181         self.generate_renamed_fields()\n182         # Generate removal of foo together.\n183         self.generate_removed_altered_unique_together()\n184         self.generate_removed_altered_index_together()\n185         # Generate field operations.\n186         self.generate_removed_fields()\n187         self.generate_added_fields()\n188         self.generate_altered_fields()\n189         self.generate_altered_order_with_respect_to()\n190         self.generate_altered_unique_together()\n191         self.generate_altered_index_together()\n192         self.generate_added_indexes()\n193         self.generate_added_constraints()\n194         self.generate_altered_db_table()\n195 \n196         self._sort_migrations()\n197         self._build_migration_list(graph)\n198         self._optimize_migrations()\n199 \n200         return self.migrations\n201 \n202     def _prepare_field_lists(self):\n203         \"\"\"\n204         Prepare field lists and a list of the fields that used through models\n205         in the old state so dependencies can be made from the through model\n206         deletion to the field that uses it.\n207         \"\"\"\n208         self.kept_model_keys = self.old_model_keys & self.new_model_keys\n209         self.kept_proxy_keys = self.old_proxy_keys & self.new_proxy_keys\n210         self.kept_unmanaged_keys = self.old_unmanaged_keys & self.new_unmanaged_keys\n211         self.through_users = {}\n212         self.old_field_keys = {\n213             (app_label, model_name, field_name)\n214             for app_label, model_name in self.kept_model_keys\n215             for field_name in self.from_state.models[\n216                 app_label, self.renamed_models.get((app_label, model_name), model_name)\n217             ].fields\n218         }\n219         self.new_field_keys = {\n220             (app_label, model_name, field_name)\n221             for app_label, model_name in self.kept_model_keys\n222             for field_name in self.to_state.models[app_label, model_name].fields\n223         }\n224 \n225     def _generate_through_model_map(self):\n226         \"\"\"Through model map generation.\"\"\"\n227         for app_label, model_name in sorted(self.old_model_keys):\n228             old_model_name = self.renamed_models.get(\n229                 (app_label, model_name), model_name\n230             )\n231             old_model_state = self.from_state.models[app_label, old_model_name]\n232             for field_name, field in old_model_state.fields.items():\n233                 if hasattr(field, \"remote_field\") and getattr(\n234                     field.remote_field, \"through\", None\n235                 ):\n236                     through_key = resolve_relation(\n237                         field.remote_field.through, app_label, model_name\n238                     )\n239                     self.through_users[through_key] = (\n240                         app_label,\n241                         old_model_name,\n242                         field_name,\n243                     )\n244 \n245     @staticmethod\n246     def _resolve_dependency(dependency):\n247         \"\"\"\n248         Return the resolved dependency and a boolean denoting whether or not\n249         it was swappable.\n250         \"\"\"\n251         if dependency[0] != \"__setting__\":\n252             return dependency, False\n253         resolved_app_label, resolved_object_name = getattr(\n254             settings, dependency[1]\n255         ).split(\".\")\n256         return (resolved_app_label, resolved_object_name.lower()) + dependency[2:], True\n257 \n258     def _build_migration_list(self, graph=None):\n259         \"\"\"\n260         Chop the lists of operations up into migrations with dependencies on\n261         each other. Do this by going through an app's list of operations until\n262         one is found that has an outgoing dependency that isn't in another\n263         app's migration yet (hasn't been chopped off its list). Then chop off\n264         the operations before it into a migration and move onto the next app.\n265         If the loops completes without doing anything, there's a circular\n266         dependency (which _should_ be impossible as the operations are\n267         all split at this point so they can't depend and be depended on).\n268         \"\"\"\n269         self.migrations = {}\n270         num_ops = sum(len(x) for x in self.generated_operations.values())\n271         chop_mode = False\n272         while num_ops:\n273             # On every iteration, we step through all the apps and see if there\n274             # is a completed set of operations.\n275             # If we find that a subset of the operations are complete we can\n276             # try to chop it off from the rest and continue, but we only\n277             # do this if we've already been through the list once before\n278             # without any chopping and nothing has changed.\n279             for app_label in sorted(self.generated_operations):\n280                 chopped = []\n281                 dependencies = set()\n282                 for operation in list(self.generated_operations[app_label]):\n283                     deps_satisfied = True\n284                     operation_dependencies = set()\n285                     for dep in operation._auto_deps:\n286                         # Temporarily resolve the swappable dependency to\n287                         # prevent circular references. While keeping the\n288                         # dependency checks on the resolved model, add the\n289                         # swappable dependencies.\n290                         original_dep = dep\n291                         dep, is_swappable_dep = self._resolve_dependency(dep)\n292                         if dep[0] != app_label:\n293                             # External app dependency. See if it's not yet\n294                             # satisfied.\n295                             for other_operation in self.generated_operations.get(\n296                                 dep[0], []\n297                             ):\n298                                 if self.check_dependency(other_operation, dep):\n299                                     deps_satisfied = False\n300                                     break\n301                             if not deps_satisfied:\n302                                 break\n303                             else:\n304                                 if is_swappable_dep:\n305                                     operation_dependencies.add(\n306                                         (original_dep[0], original_dep[1])\n307                                     )\n308                                 elif dep[0] in self.migrations:\n309                                     operation_dependencies.add(\n310                                         (dep[0], self.migrations[dep[0]][-1].name)\n311                                     )\n312                                 else:\n313                                     # If we can't find the other app, we add a\n314                                     # first/last dependency, but only if we've\n315                                     # already been through once and checked\n316                                     # everything.\n317                                     if chop_mode:\n318                                         # If the app already exists, we add a\n319                                         # dependency on the last migration, as\n320                                         # we don't know which migration\n321                                         # contains the target field. If it's\n322                                         # not yet migrated or has no\n323                                         # migrations, we use __first__.\n324                                         if graph and graph.leaf_nodes(dep[0]):\n325                                             operation_dependencies.add(\n326                                                 graph.leaf_nodes(dep[0])[0]\n327                                             )\n328                                         else:\n329                                             operation_dependencies.add(\n330                                                 (dep[0], \"__first__\")\n331                                             )\n332                                     else:\n333                                         deps_satisfied = False\n334                     if deps_satisfied:\n335                         chopped.append(operation)\n336                         dependencies.update(operation_dependencies)\n337                         del self.generated_operations[app_label][0]\n338                     else:\n339                         break\n340                 # Make a migration! Well, only if there's stuff to put in it\n341                 if dependencies or chopped:\n342                     if not self.generated_operations[app_label] or chop_mode:\n343                         subclass = type(\n344                             \"Migration\",\n345                             (Migration,),\n346                             {\"operations\": [], \"dependencies\": []},\n347                         )\n348                         instance = subclass(\n349                             \"auto_%i\" % (len(self.migrations.get(app_label, [])) + 1),\n350                             app_label,\n351                         )\n352                         instance.dependencies = list(dependencies)\n353                         instance.operations = chopped\n354                         instance.initial = app_label not in self.existing_apps\n355                         self.migrations.setdefault(app_label, []).append(instance)\n356                         chop_mode = False\n357                     else:\n358                         self.generated_operations[app_label] = (\n359                             chopped + self.generated_operations[app_label]\n360                         )\n361             new_num_ops = sum(len(x) for x in self.generated_operations.values())\n362             if new_num_ops == num_ops:\n363                 if not chop_mode:\n364                     chop_mode = True\n365                 else:\n366                     raise ValueError(\n367                         \"Cannot resolve operation dependencies: %r\"\n368                         % self.generated_operations\n369                     )\n370             num_ops = new_num_ops\n371 \n372     def _sort_migrations(self):\n373         \"\"\"\n374         Reorder to make things possible. Reordering may be needed so FKs work\n375         nicely inside the same app.\n376         \"\"\"\n377         for app_label, ops in sorted(self.generated_operations.items()):\n378             # construct a dependency graph for intra-app dependencies\n379             dependency_graph = {op: set() for op in ops}\n380             for op in ops:\n381                 for dep in op._auto_deps:\n382                     # Resolve intra-app dependencies to handle circular\n383                     # references involving a swappable model.\n384                     dep = self._resolve_dependency(dep)[0]\n385                     if dep[0] == app_label:\n386                         for op2 in ops:\n387                             if self.check_dependency(op2, dep):\n388                                 dependency_graph[op].add(op2)\n389 \n390             # we use a stable sort for deterministic tests & general behavior\n391             self.generated_operations[app_label] = stable_topological_sort(\n392                 ops, dependency_graph\n393             )\n394 \n395     def _optimize_migrations(self):\n396         # Add in internal dependencies among the migrations\n397         for app_label, migrations in self.migrations.items():\n398             for m1, m2 in zip(migrations, migrations[1:]):\n399                 m2.dependencies.append((app_label, m1.name))\n400 \n401         # De-dupe dependencies\n402         for migrations in self.migrations.values():\n403             for migration in migrations:\n404                 migration.dependencies = list(set(migration.dependencies))\n405 \n406         # Optimize migrations\n407         for app_label, migrations in self.migrations.items():\n408             for migration in migrations:\n409                 migration.operations = MigrationOptimizer().optimize(\n410                     migration.operations, app_label\n411                 )\n412 \n413     def check_dependency(self, operation, dependency):\n414         \"\"\"\n415         Return True if the given operation depends on the given dependency,\n416         False otherwise.\n417         \"\"\"\n418         # Created model\n419         if dependency[2] is None and dependency[3] is True:\n420             return (\n421                 isinstance(operation, operations.CreateModel)\n422                 and operation.name_lower == dependency[1].lower()\n423             )\n424         # Created field\n425         elif dependency[2] is not None and dependency[3] is True:\n426             return (\n427                 isinstance(operation, operations.CreateModel)\n428                 and operation.name_lower == dependency[1].lower()\n429                 and any(dependency[2] == x for x, y in operation.fields)\n430             ) or (\n431                 isinstance(operation, operations.AddField)\n432                 and operation.model_name_lower == dependency[1].lower()\n433                 and operation.name_lower == dependency[2].lower()\n434             )\n435         # Removed field\n436         elif dependency[2] is not None and dependency[3] is False:\n437             return (\n438                 isinstance(operation, operations.RemoveField)\n439                 and operation.model_name_lower == dependency[1].lower()\n440                 and operation.name_lower == dependency[2].lower()\n441             )\n442         # Removed model\n443         elif dependency[2] is None and dependency[3] is False:\n444             return (\n445                 isinstance(operation, operations.DeleteModel)\n446                 and operation.name_lower == dependency[1].lower()\n447             )\n448         # Field being altered\n449         elif dependency[2] is not None and dependency[3] == \"alter\":\n450             return (\n451                 isinstance(operation, operations.AlterField)\n452                 and operation.model_name_lower == dependency[1].lower()\n453                 and operation.name_lower == dependency[2].lower()\n454             )\n455         # order_with_respect_to being unset for a field\n456         elif dependency[2] is not None and dependency[3] == \"order_wrt_unset\":\n457             return (\n458                 isinstance(operation, operations.AlterOrderWithRespectTo)\n459                 and operation.name_lower == dependency[1].lower()\n460                 and (operation.order_with_respect_to or \"\").lower()\n461                 != dependency[2].lower()\n462             )\n463         # Field is removed and part of an index/unique_together\n464         elif dependency[2] is not None and dependency[3] == \"foo_together_change\":\n465             return (\n466                 isinstance(\n467                     operation,\n468                     (operations.AlterUniqueTogether, operations.AlterIndexTogether),\n469                 )\n470                 and operation.name_lower == dependency[1].lower()\n471             )\n472         # Unknown dependency. Raise an error.\n473         else:\n474             raise ValueError(\"Can't handle dependency %r\" % (dependency,))\n475 \n476     def add_operation(self, app_label, operation, dependencies=None, beginning=False):\n477         # Dependencies are\n478         # (app_label, model_name, field_name, create/delete as True/False)\n479         operation._auto_deps = dependencies or []\n480         if beginning:\n481             self.generated_operations.setdefault(app_label, []).insert(0, operation)\n482         else:\n483             self.generated_operations.setdefault(app_label, []).append(operation)\n484 \n485     def swappable_first_key(self, item):\n486         \"\"\"\n487         Place potential swappable models first in lists of created models (only\n488         real way to solve #22783).\n489         \"\"\"\n490         try:\n491             model_state = self.to_state.models[item]\n492             base_names = {\n493                 base if isinstance(base, str) else base.__name__\n494                 for base in model_state.bases\n495             }\n496             string_version = \"%s.%s\" % (item[0], item[1])\n497             if (\n498                 model_state.options.get(\"swappable\")\n499                 or \"AbstractUser\" in base_names\n500                 or \"AbstractBaseUser\" in base_names\n501                 or settings.AUTH_USER_MODEL.lower() == string_version.lower()\n502             ):\n503                 return (\"___\" + item[0], \"___\" + item[1])\n504         except LookupError:\n505             pass\n506         return item\n507 \n508     def generate_renamed_models(self):\n509         \"\"\"\n510         Find any renamed models, generate the operations for them, and remove\n511         the old entry from the model lists. Must be run before other\n512         model-level generation.\n513         \"\"\"\n514         self.renamed_models = {}\n515         self.renamed_models_rel = {}\n516         added_models = self.new_model_keys - self.old_model_keys\n517         for app_label, model_name in sorted(added_models):\n518             model_state = self.to_state.models[app_label, model_name]\n519             model_fields_def = self.only_relation_agnostic_fields(model_state.fields)\n520 \n521             removed_models = self.old_model_keys - self.new_model_keys\n522             for rem_app_label, rem_model_name in removed_models:\n523                 if rem_app_label == app_label:\n524                     rem_model_state = self.from_state.models[\n525                         rem_app_label, rem_model_name\n526                     ]\n527                     rem_model_fields_def = self.only_relation_agnostic_fields(\n528                         rem_model_state.fields\n529                     )\n530                     if model_fields_def == rem_model_fields_def:\n531                         if self.questioner.ask_rename_model(\n532                             rem_model_state, model_state\n533                         ):\n534                             dependencies = []\n535                             fields = list(model_state.fields.values()) + [\n536                                 field.remote_field\n537                                 for relations in self.to_state.relations[\n538                                     app_label, model_name\n539                                 ].values()\n540                                 for field in relations.values()\n541                             ]\n542                             for field in fields:\n543                                 if field.is_relation:\n544                                     dependencies.extend(\n545                                         self._get_dependencies_for_foreign_key(\n546                                             app_label,\n547                                             model_name,\n548                                             field,\n549                                             self.to_state,\n550                                         )\n551                                     )\n552                             self.add_operation(\n553                                 app_label,\n554                                 operations.RenameModel(\n555                                     old_name=rem_model_state.name,\n556                                     new_name=model_state.name,\n557                                 ),\n558                                 dependencies=dependencies,\n559                             )\n560                             self.renamed_models[app_label, model_name] = rem_model_name\n561                             renamed_models_rel_key = \"%s.%s\" % (\n562                                 rem_model_state.app_label,\n563                                 rem_model_state.name_lower,\n564                             )\n565                             self.renamed_models_rel[\n566                                 renamed_models_rel_key\n567                             ] = \"%s.%s\" % (\n568                                 model_state.app_label,\n569                                 model_state.name_lower,\n570                             )\n571                             self.old_model_keys.remove((rem_app_label, rem_model_name))\n572                             self.old_model_keys.add((app_label, model_name))\n573                             break\n574 \n575     def generate_created_models(self):\n576         \"\"\"\n577         Find all new models (both managed and unmanaged) and make create\n578         operations for them as well as separate operations to create any\n579         foreign key or M2M relationships (these are optimized later, if\n580         possible).\n581 \n582         Defer any model options that refer to collections of fields that might\n583         be deferred (e.g. unique_together, index_together).\n584         \"\"\"\n585         old_keys = self.old_model_keys | self.old_unmanaged_keys\n586         added_models = self.new_model_keys - old_keys\n587         added_unmanaged_models = self.new_unmanaged_keys - old_keys\n588         all_added_models = chain(\n589             sorted(added_models, key=self.swappable_first_key, reverse=True),\n590             sorted(added_unmanaged_models, key=self.swappable_first_key, reverse=True),\n591         )\n592         for app_label, model_name in all_added_models:\n593             model_state = self.to_state.models[app_label, model_name]\n594             # Gather related fields\n595             related_fields = {}\n596             primary_key_rel = None\n597             for field_name, field in model_state.fields.items():\n598                 if field.remote_field:\n599                     if field.remote_field.model:\n600                         if field.primary_key:\n601                             primary_key_rel = field.remote_field.model\n602                         elif not field.remote_field.parent_link:\n603                             related_fields[field_name] = field\n604                     if getattr(field.remote_field, \"through\", None):\n605                         related_fields[field_name] = field\n606 \n607             # Are there indexes/unique|index_together to defer?\n608             indexes = model_state.options.pop(\"indexes\")\n609             constraints = model_state.options.pop(\"constraints\")\n610             unique_together = model_state.options.pop(\"unique_together\", None)\n611             index_together = model_state.options.pop(\"index_together\", None)\n612             order_with_respect_to = model_state.options.pop(\n613                 \"order_with_respect_to\", None\n614             )\n615             # Depend on the deletion of any possible proxy version of us\n616             dependencies = [\n617                 (app_label, model_name, None, False),\n618             ]\n619             # Depend on all bases\n620             for base in model_state.bases:\n621                 if isinstance(base, str) and \".\" in base:\n622                     base_app_label, base_name = base.split(\".\", 1)\n623                     dependencies.append((base_app_label, base_name, None, True))\n624                     # Depend on the removal of base fields if the new model has\n625                     # a field with the same name.\n626                     old_base_model_state = self.from_state.models.get(\n627                         (base_app_label, base_name)\n628                     )\n629                     new_base_model_state = self.to_state.models.get(\n630                         (base_app_label, base_name)\n631                     )\n632                     if old_base_model_state and new_base_model_state:\n633                         removed_base_fields = (\n634                             set(old_base_model_state.fields)\n635                             .difference(\n636                                 new_base_model_state.fields,\n637                             )\n638                             .intersection(model_state.fields)\n639                         )\n640                         for removed_base_field in removed_base_fields:\n641                             dependencies.append(\n642                                 (base_app_label, base_name, removed_base_field, False)\n643                             )\n644             # Depend on the other end of the primary key if it's a relation\n645             if primary_key_rel:\n646                 dependencies.append(\n647                     resolve_relation(\n648                         primary_key_rel,\n649                         app_label,\n650                         model_name,\n651                     )\n652                     + (None, True)\n653                 )\n654             # Generate creation operation\n655             self.add_operation(\n656                 app_label,\n657                 operations.CreateModel(\n658                     name=model_state.name,\n659                     fields=[\n660                         d\n661                         for d in model_state.fields.items()\n662                         if d[0] not in related_fields\n663                     ],\n664                     options=model_state.options,\n665                     bases=model_state.bases,\n666                     managers=model_state.managers,\n667                 ),\n668                 dependencies=dependencies,\n669                 beginning=True,\n670             )\n671 \n672             # Don't add operations which modify the database for unmanaged models\n673             if not model_state.options.get(\"managed\", True):\n674                 continue\n675 \n676             # Generate operations for each related field\n677             for name, field in sorted(related_fields.items()):\n678                 dependencies = self._get_dependencies_for_foreign_key(\n679                     app_label,\n680                     model_name,\n681                     field,\n682                     self.to_state,\n683                 )\n684                 # Depend on our own model being created\n685                 dependencies.append((app_label, model_name, None, True))\n686                 # Make operation\n687                 self.add_operation(\n688                     app_label,\n689                     operations.AddField(\n690                         model_name=model_name,\n691                         name=name,\n692                         field=field,\n693                     ),\n694                     dependencies=list(set(dependencies)),\n695                 )\n696             # Generate other opns\n697             if order_with_respect_to:\n698                 self.add_operation(\n699                     app_label,\n700                     operations.AlterOrderWithRespectTo(\n701                         name=model_name,\n702                         order_with_respect_to=order_with_respect_to,\n703                     ),\n704                     dependencies=[\n705                         (app_label, model_name, order_with_respect_to, True),\n706                         (app_label, model_name, None, True),\n707                     ],\n708                 )\n709             related_dependencies = [\n710                 (app_label, model_name, name, True) for name in sorted(related_fields)\n711             ]\n712             related_dependencies.append((app_label, model_name, None, True))\n713             for index in indexes:\n714                 self.add_operation(\n715                     app_label,\n716                     operations.AddIndex(\n717                         model_name=model_name,\n718                         index=index,\n719                     ),\n720                     dependencies=related_dependencies,\n721                 )\n722             for constraint in constraints:\n723                 self.add_operation(\n724                     app_label,\n725                     operations.AddConstraint(\n726                         model_name=model_name,\n727                         constraint=constraint,\n728                     ),\n729                     dependencies=related_dependencies,\n730                 )\n731             if unique_together:\n732                 self.add_operation(\n733                     app_label,\n734                     operations.AlterUniqueTogether(\n735                         name=model_name,\n736                         unique_together=unique_together,\n737                     ),\n738                     dependencies=related_dependencies,\n739                 )\n740             if index_together:\n741                 self.add_operation(\n742                     app_label,\n743                     operations.AlterIndexTogether(\n744                         name=model_name,\n745                         index_together=index_together,\n746                     ),\n747                     dependencies=related_dependencies,\n748                 )\n749             # Fix relationships if the model changed from a proxy model to a\n750             # concrete model.\n751             relations = self.to_state.relations\n752             if (app_label, model_name) in self.old_proxy_keys:\n753                 for related_model_key, related_fields in relations[\n754                     app_label, model_name\n755                 ].items():\n756                     related_model_state = self.to_state.models[related_model_key]\n757                     for related_field_name, related_field in related_fields.items():\n758                         self.add_operation(\n759                             related_model_state.app_label,\n760                             operations.AlterField(\n761                                 model_name=related_model_state.name,\n762                                 name=related_field_name,\n763                                 field=related_field,\n764                             ),\n765                             dependencies=[(app_label, model_name, None, True)],\n766                         )\n767 \n768     def generate_created_proxies(self):\n769         \"\"\"\n770         Make CreateModel statements for proxy models. Use the same statements\n771         as that way there's less code duplication, but for proxy models it's\n772         safe to skip all the pointless field stuff and chuck out an operation.\n773         \"\"\"\n774         added = self.new_proxy_keys - self.old_proxy_keys\n775         for app_label, model_name in sorted(added):\n776             model_state = self.to_state.models[app_label, model_name]\n777             assert model_state.options.get(\"proxy\")\n778             # Depend on the deletion of any possible non-proxy version of us\n779             dependencies = [\n780                 (app_label, model_name, None, False),\n781             ]\n782             # Depend on all bases\n783             for base in model_state.bases:\n784                 if isinstance(base, str) and \".\" in base:\n785                     base_app_label, base_name = base.split(\".\", 1)\n786                     dependencies.append((base_app_label, base_name, None, True))\n787             # Generate creation operation\n788             self.add_operation(\n789                 app_label,\n790                 operations.CreateModel(\n791                     name=model_state.name,\n792                     fields=[],\n793                     options=model_state.options,\n794                     bases=model_state.bases,\n795                     managers=model_state.managers,\n796                 ),\n797                 # Depend on the deletion of any possible non-proxy version of us\n798                 dependencies=dependencies,\n799             )\n800 \n801     def generate_deleted_models(self):\n802         \"\"\"\n803         Find all deleted models (managed and unmanaged) and make delete\n804         operations for them as well as separate operations to delete any\n805         foreign key or M2M relationships (these are optimized later, if\n806         possible).\n807 \n808         Also bring forward removal of any model options that refer to\n809         collections of fields - the inverse of generate_created_models().\n810         \"\"\"\n811         new_keys = self.new_model_keys | self.new_unmanaged_keys\n812         deleted_models = self.old_model_keys - new_keys\n813         deleted_unmanaged_models = self.old_unmanaged_keys - new_keys\n814         all_deleted_models = chain(\n815             sorted(deleted_models), sorted(deleted_unmanaged_models)\n816         )\n817         for app_label, model_name in all_deleted_models:\n818             model_state = self.from_state.models[app_label, model_name]\n819             # Gather related fields\n820             related_fields = {}\n821             for field_name, field in model_state.fields.items():\n822                 if field.remote_field:\n823                     if field.remote_field.model:\n824                         related_fields[field_name] = field\n825                     if getattr(field.remote_field, \"through\", None):\n826                         related_fields[field_name] = field\n827             # Generate option removal first\n828             unique_together = model_state.options.pop(\"unique_together\", None)\n829             index_together = model_state.options.pop(\"index_together\", None)\n830             if unique_together:\n831                 self.add_operation(\n832                     app_label,\n833                     operations.AlterUniqueTogether(\n834                         name=model_name,\n835                         unique_together=None,\n836                     ),\n837                 )\n838             if index_together:\n839                 self.add_operation(\n840                     app_label,\n841                     operations.AlterIndexTogether(\n842                         name=model_name,\n843                         index_together=None,\n844                     ),\n845                 )\n846             # Then remove each related field\n847             for name in sorted(related_fields):\n848                 self.add_operation(\n849                     app_label,\n850                     operations.RemoveField(\n851                         model_name=model_name,\n852                         name=name,\n853                     ),\n854                 )\n855             # Finally, remove the model.\n856             # This depends on both the removal/alteration of all incoming fields\n857             # and the removal of all its own related fields, and if it's\n858             # a through model the field that references it.\n859             dependencies = []\n860             relations = self.from_state.relations\n861             for (\n862                 related_object_app_label,\n863                 object_name,\n864             ), relation_related_fields in relations[app_label, model_name].items():\n865                 for field_name, field in relation_related_fields.items():\n866                     dependencies.append(\n867                         (related_object_app_label, object_name, field_name, False),\n868                     )\n869                     if not field.many_to_many:\n870                         dependencies.append(\n871                             (\n872                                 related_object_app_label,\n873                                 object_name,\n874                                 field_name,\n875                                 \"alter\",\n876                             ),\n877                         )\n878 \n879             for name in sorted(related_fields):\n880                 dependencies.append((app_label, model_name, name, False))\n881             # We're referenced in another field's through=\n882             through_user = self.through_users.get((app_label, model_state.name_lower))\n883             if through_user:\n884                 dependencies.append(\n885                     (through_user[0], through_user[1], through_user[2], False)\n886                 )\n887             # Finally, make the operation, deduping any dependencies\n888             self.add_operation(\n889                 app_label,\n890                 operations.DeleteModel(\n891                     name=model_state.name,\n892                 ),\n893                 dependencies=list(set(dependencies)),\n894             )\n895 \n896     def generate_deleted_proxies(self):\n897         \"\"\"Make DeleteModel options for proxy models.\"\"\"\n898         deleted = self.old_proxy_keys - self.new_proxy_keys\n899         for app_label, model_name in sorted(deleted):\n900             model_state = self.from_state.models[app_label, model_name]\n901             assert model_state.options.get(\"proxy\")\n902             self.add_operation(\n903                 app_label,\n904                 operations.DeleteModel(\n905                     name=model_state.name,\n906                 ),\n907             )\n908 \n909     def generate_renamed_fields(self):\n910         \"\"\"Work out renamed fields.\"\"\"\n911         self.renamed_fields = {}\n912         for app_label, model_name, field_name in sorted(\n913             self.new_field_keys - self.old_field_keys\n914         ):\n915             old_model_name = self.renamed_models.get(\n916                 (app_label, model_name), model_name\n917             )\n918             old_model_state = self.from_state.models[app_label, old_model_name]\n919             new_model_state = self.to_state.models[app_label, model_name]\n920             field = new_model_state.get_field(field_name)\n921             # Scan to see if this is actually a rename!\n922             field_dec = self.deep_deconstruct(field)\n923             for rem_app_label, rem_model_name, rem_field_name in sorted(\n924                 self.old_field_keys - self.new_field_keys\n925             ):\n926                 if rem_app_label == app_label and rem_model_name == model_name:\n927                     old_field = old_model_state.get_field(rem_field_name)\n928                     old_field_dec = self.deep_deconstruct(old_field)\n929                     if (\n930                         field.remote_field\n931                         and field.remote_field.model\n932                         and \"to\" in old_field_dec[2]\n933                     ):\n934                         old_rel_to = old_field_dec[2][\"to\"]\n935                         if old_rel_to in self.renamed_models_rel:\n936                             old_field_dec[2][\"to\"] = self.renamed_models_rel[old_rel_to]\n937                     old_field.set_attributes_from_name(rem_field_name)\n938                     old_db_column = old_field.get_attname_column()[1]\n939                     if old_field_dec == field_dec or (\n940                         # Was the field renamed and db_column equal to the\n941                         # old field's column added?\n942                         old_field_dec[0:2] == field_dec[0:2]\n943                         and dict(old_field_dec[2], db_column=old_db_column)\n944                         == field_dec[2]\n945                     ):\n946                         if self.questioner.ask_rename(\n947                             model_name, rem_field_name, field_name, field\n948                         ):\n949                             # A db_column mismatch requires a prior noop\n950                             # AlterField for the subsequent RenameField to be a\n951                             # noop on attempts at preserving the old name.\n952                             if old_field.db_column != field.db_column:\n953                                 altered_field = field.clone()\n954                                 altered_field.name = rem_field_name\n955                                 self.add_operation(\n956                                     app_label,\n957                                     operations.AlterField(\n958                                         model_name=model_name,\n959                                         name=rem_field_name,\n960                                         field=altered_field,\n961                                     ),\n962                                 )\n963                             self.add_operation(\n964                                 app_label,\n965                                 operations.RenameField(\n966                                     model_name=model_name,\n967                                     old_name=rem_field_name,\n968                                     new_name=field_name,\n969                                 ),\n970                             )\n971                             self.old_field_keys.remove(\n972                                 (rem_app_label, rem_model_name, rem_field_name)\n973                             )\n974                             self.old_field_keys.add((app_label, model_name, field_name))\n975                             self.renamed_fields[\n976                                 app_label, model_name, field_name\n977                             ] = rem_field_name\n978                             break\n979 \n980     def generate_added_fields(self):\n981         \"\"\"Make AddField operations.\"\"\"\n982         for app_label, model_name, field_name in sorted(\n983             self.new_field_keys - self.old_field_keys\n984         ):\n985             self._generate_added_field(app_label, model_name, field_name)\n986 \n987     def _generate_added_field(self, app_label, model_name, field_name):\n988         field = self.to_state.models[app_label, model_name].get_field(field_name)\n989         # Fields that are foreignkeys/m2ms depend on stuff\n990         dependencies = []\n991         if field.remote_field and field.remote_field.model:\n992             dependencies.extend(\n993                 self._get_dependencies_for_foreign_key(\n994                     app_label,\n995                     model_name,\n996                     field,\n997                     self.to_state,\n998                 )\n999             )\n1000         # You can't just add NOT NULL fields with no default or fields\n1001         # which don't allow empty strings as default.\n1002         time_fields = (models.DateField, models.DateTimeField, models.TimeField)\n1003         preserve_default = (\n1004             field.null\n1005             or field.has_default()\n1006             or field.many_to_many\n1007             or (field.blank and field.empty_strings_allowed)\n1008             or (isinstance(field, time_fields) and field.auto_now)\n1009         )\n1010         if not preserve_default:\n1011             field = field.clone()\n1012             if isinstance(field, time_fields) and field.auto_now_add:\n1013                 field.default = self.questioner.ask_auto_now_add_addition(\n1014                     field_name, model_name\n1015                 )\n1016             else:\n1017                 field.default = self.questioner.ask_not_null_addition(\n1018                     field_name, model_name\n1019                 )\n1020         if (\n1021             field.unique\n1022             and field.default is not models.NOT_PROVIDED\n1023             and callable(field.default)\n1024         ):\n1025             self.questioner.ask_unique_callable_default_addition(field_name, model_name)\n1026         self.add_operation(\n1027             app_label,\n1028             operations.AddField(\n1029                 model_name=model_name,\n1030                 name=field_name,\n1031                 field=field,\n1032                 preserve_default=preserve_default,\n1033             ),\n1034             dependencies=dependencies,\n1035         )\n1036 \n1037     def generate_removed_fields(self):\n1038         \"\"\"Make RemoveField operations.\"\"\"\n1039         for app_label, model_name, field_name in sorted(\n1040             self.old_field_keys - self.new_field_keys\n1041         ):\n1042             self._generate_removed_field(app_label, model_name, field_name)\n1043 \n1044     def _generate_removed_field(self, app_label, model_name, field_name):\n1045         self.add_operation(\n1046             app_label,\n1047             operations.RemoveField(\n1048                 model_name=model_name,\n1049                 name=field_name,\n1050             ),\n1051             # We might need to depend on the removal of an\n1052             # order_with_respect_to or index/unique_together operation;\n1053             # this is safely ignored if there isn't one\n1054             dependencies=[\n1055                 (app_label, model_name, field_name, \"order_wrt_unset\"),\n1056                 (app_label, model_name, field_name, \"foo_together_change\"),\n1057             ],\n1058         )\n1059 \n1060     def generate_altered_fields(self):\n1061         \"\"\"\n1062         Make AlterField operations, or possibly RemovedField/AddField if alter\n1063         isn't possible.\n1064         \"\"\"\n1065         for app_label, model_name, field_name in sorted(\n1066             self.old_field_keys & self.new_field_keys\n1067         ):\n1068             # Did the field change?\n1069             old_model_name = self.renamed_models.get(\n1070                 (app_label, model_name), model_name\n1071             )\n1072             old_field_name = self.renamed_fields.get(\n1073                 (app_label, model_name, field_name), field_name\n1074             )\n1075             old_field = self.from_state.models[app_label, old_model_name].get_field(\n1076                 old_field_name\n1077             )\n1078             new_field = self.to_state.models[app_label, model_name].get_field(\n1079                 field_name\n1080             )\n1081             dependencies = []\n1082             # Implement any model renames on relations; these are handled by RenameModel\n1083             # so we need to exclude them from the comparison\n1084             if hasattr(new_field, \"remote_field\") and getattr(\n1085                 new_field.remote_field, \"model\", None\n1086             ):\n1087                 rename_key = resolve_relation(\n1088                     new_field.remote_field.model, app_label, model_name\n1089                 )\n1090                 if rename_key in self.renamed_models:\n1091                     new_field.remote_field.model = old_field.remote_field.model\n1092                 # Handle ForeignKey which can only have a single to_field.\n1093                 remote_field_name = getattr(new_field.remote_field, \"field_name\", None)\n1094                 if remote_field_name:\n1095                     to_field_rename_key = rename_key + (remote_field_name,)\n1096                     if to_field_rename_key in self.renamed_fields:\n1097                         # Repoint both model and field name because to_field\n1098                         # inclusion in ForeignKey.deconstruct() is based on\n1099                         # both.\n1100                         new_field.remote_field.model = old_field.remote_field.model\n1101                         new_field.remote_field.field_name = (\n1102                             old_field.remote_field.field_name\n1103                         )\n1104                 # Handle ForeignObjects which can have multiple from_fields/to_fields.\n1105                 from_fields = getattr(new_field, \"from_fields\", None)\n1106                 if from_fields:\n1107                     from_rename_key = (app_label, model_name)\n1108                     new_field.from_fields = tuple(\n1109                         [\n1110                             self.renamed_fields.get(\n1111                                 from_rename_key + (from_field,), from_field\n1112                             )\n1113                             for from_field in from_fields\n1114                         ]\n1115                     )\n1116                     new_field.to_fields = tuple(\n1117                         [\n1118                             self.renamed_fields.get(rename_key + (to_field,), to_field)\n1119                             for to_field in new_field.to_fields\n1120                         ]\n1121                     )\n1122                 dependencies.extend(\n1123                     self._get_dependencies_for_foreign_key(\n1124                         app_label,\n1125                         model_name,\n1126                         new_field,\n1127                         self.to_state,\n1128                     )\n1129                 )\n1130             if hasattr(new_field, \"remote_field\") and getattr(\n1131                 new_field.remote_field, \"through\", None\n1132             ):\n1133                 rename_key = resolve_relation(\n1134                     new_field.remote_field.through, app_label, model_name\n1135                 )\n1136                 if rename_key in self.renamed_models:\n1137                     new_field.remote_field.through = old_field.remote_field.through\n1138             old_field_dec = self.deep_deconstruct(old_field)\n1139             new_field_dec = self.deep_deconstruct(new_field)\n1140             # If the field was confirmed to be renamed it means that only\n1141             # db_column was allowed to change which generate_renamed_fields()\n1142             # already accounts for by adding an AlterField operation.\n1143             if old_field_dec != new_field_dec and old_field_name == field_name:\n1144                 both_m2m = old_field.many_to_many and new_field.many_to_many\n1145                 neither_m2m = not old_field.many_to_many and not new_field.many_to_many\n1146                 if both_m2m or neither_m2m:\n1147                     # Either both fields are m2m or neither is\n1148                     preserve_default = True\n1149                     if (\n1150                         old_field.null\n1151                         and not new_field.null\n1152                         and not new_field.has_default()\n1153                         and not new_field.many_to_many\n1154                     ):\n1155                         field = new_field.clone()\n1156                         new_default = self.questioner.ask_not_null_alteration(\n1157                             field_name, model_name\n1158                         )\n1159                         if new_default is not models.NOT_PROVIDED:\n1160                             field.default = new_default\n1161                             preserve_default = False\n1162                     else:\n1163                         field = new_field\n1164                     self.add_operation(\n1165                         app_label,\n1166                         operations.AlterField(\n1167                             model_name=model_name,\n1168                             name=field_name,\n1169                             field=field,\n1170                             preserve_default=preserve_default,\n1171                         ),\n1172                         dependencies=dependencies,\n1173                     )\n1174                 else:\n1175                     # We cannot alter between m2m and concrete fields\n1176                     self._generate_removed_field(app_label, model_name, field_name)\n1177                     self._generate_added_field(app_label, model_name, field_name)\n1178 \n1179     def create_altered_indexes(self):\n1180         option_name = operations.AddIndex.option_name\n1181         for app_label, model_name in sorted(self.kept_model_keys):\n1182             old_model_name = self.renamed_models.get(\n1183                 (app_label, model_name), model_name\n1184             )\n1185             old_model_state = self.from_state.models[app_label, old_model_name]\n1186             new_model_state = self.to_state.models[app_label, model_name]\n1187 \n1188             old_indexes = old_model_state.options[option_name]\n1189             new_indexes = new_model_state.options[option_name]\n1190             add_idx = [idx for idx in new_indexes if idx not in old_indexes]\n1191             rem_idx = [idx for idx in old_indexes if idx not in new_indexes]\n1192 \n1193             self.altered_indexes.update(\n1194                 {\n1195                     (app_label, model_name): {\n1196                         \"added_indexes\": add_idx,\n1197                         \"removed_indexes\": rem_idx,\n1198                     }\n1199                 }\n1200             )\n1201 \n1202     def generate_added_indexes(self):\n1203         for (app_label, model_name), alt_indexes in self.altered_indexes.items():\n1204             for index in alt_indexes[\"added_indexes\"]:\n1205                 self.add_operation(\n1206                     app_label,\n1207                     operations.AddIndex(\n1208                         model_name=model_name,\n1209                         index=index,\n1210                     ),\n1211                 )\n1212 \n1213     def generate_removed_indexes(self):\n1214         for (app_label, model_name), alt_indexes in self.altered_indexes.items():\n1215             for index in alt_indexes[\"removed_indexes\"]:\n1216                 self.add_operation(\n1217                     app_label,\n1218                     operations.RemoveIndex(\n1219                         model_name=model_name,\n1220                         name=index.name,\n1221                     ),\n1222                 )\n1223 \n1224     def create_altered_constraints(self):\n1225         option_name = operations.AddConstraint.option_name\n1226         for app_label, model_name in sorted(self.kept_model_keys):\n1227             old_model_name = self.renamed_models.get(\n1228                 (app_label, model_name), model_name\n1229             )\n1230             old_model_state = self.from_state.models[app_label, old_model_name]\n1231             new_model_state = self.to_state.models[app_label, model_name]\n1232 \n1233             old_constraints = old_model_state.options[option_name]\n1234             new_constraints = new_model_state.options[option_name]\n1235             add_constraints = [c for c in new_constraints if c not in old_constraints]\n1236             rem_constraints = [c for c in old_constraints if c not in new_constraints]\n1237 \n1238             self.altered_constraints.update(\n1239                 {\n1240                     (app_label, model_name): {\n1241                         \"added_constraints\": add_constraints,\n1242                         \"removed_constraints\": rem_constraints,\n1243                     }\n1244                 }\n1245             )\n1246 \n1247     def generate_added_constraints(self):\n1248         for (\n1249             app_label,\n1250             model_name,\n1251         ), alt_constraints in self.altered_constraints.items():\n1252             for constraint in alt_constraints[\"added_constraints\"]:\n1253                 self.add_operation(\n1254                     app_label,\n1255                     operations.AddConstraint(\n1256                         model_name=model_name,\n1257                         constraint=constraint,\n1258                     ),\n1259                 )\n1260 \n1261     def generate_removed_constraints(self):\n1262         for (\n1263             app_label,\n1264             model_name,\n1265         ), alt_constraints in self.altered_constraints.items():\n1266             for constraint in alt_constraints[\"removed_constraints\"]:\n1267                 self.add_operation(\n1268                     app_label,\n1269                     operations.RemoveConstraint(\n1270                         model_name=model_name,\n1271                         name=constraint.name,\n1272                     ),\n1273                 )\n1274 \n1275     @staticmethod\n1276     def _get_dependencies_for_foreign_key(app_label, model_name, field, project_state):\n1277         remote_field_model = None\n1278         if hasattr(field.remote_field, \"model\"):\n1279             remote_field_model = field.remote_field.model\n1280         else:\n1281             relations = project_state.relations[app_label, model_name]\n1282             for (remote_app_label, remote_model_name), fields in relations.items():\n1283                 if any(\n1284                     field == related_field.remote_field\n1285                     for related_field in fields.values()\n1286                 ):\n1287                     remote_field_model = f\"{remote_app_label}.{remote_model_name}\"\n1288                     break\n1289         # Account for FKs to swappable models\n1290         swappable_setting = getattr(field, \"swappable_setting\", None)\n1291         if swappable_setting is not None:\n1292             dep_app_label = \"__setting__\"\n1293             dep_object_name = swappable_setting\n1294         else:\n1295             dep_app_label, dep_object_name = resolve_relation(\n1296                 remote_field_model,\n1297                 app_label,\n1298                 model_name,\n1299             )\n1300         dependencies = [(dep_app_label, dep_object_name, None, True)]\n1301         if getattr(field.remote_field, \"through\", None):\n1302             through_app_label, through_object_name = resolve_relation(\n1303                 remote_field_model,\n1304                 app_label,\n1305                 model_name,\n1306             )\n1307             dependencies.append((through_app_label, through_object_name, None, True))\n1308         return dependencies\n1309 \n1310     def _get_altered_foo_together_operations(self, option_name):\n1311         for app_label, model_name in sorted(self.kept_model_keys):\n1312             old_model_name = self.renamed_models.get(\n1313                 (app_label, model_name), model_name\n1314             )\n1315             old_model_state = self.from_state.models[app_label, old_model_name]\n1316             new_model_state = self.to_state.models[app_label, model_name]\n1317 \n1318             # We run the old version through the field renames to account for those\n1319             old_value = old_model_state.options.get(option_name)\n1320             old_value = (\n1321                 {\n1322                     tuple(\n1323                         self.renamed_fields.get((app_label, model_name, n), n)\n1324                         for n in unique\n1325                     )\n1326                     for unique in old_value\n1327                 }\n1328                 if old_value\n1329                 else set()\n1330             )\n1331 \n1332             new_value = new_model_state.options.get(option_name)\n1333             new_value = set(new_value) if new_value else set()\n1334 \n1335             if old_value != new_value:\n1336                 dependencies = []\n1337                 for foo_togethers in new_value:\n1338                     for field_name in foo_togethers:\n1339                         field = new_model_state.get_field(field_name)\n1340                         if field.remote_field and field.remote_field.model:\n1341                             dependencies.extend(\n1342                                 self._get_dependencies_for_foreign_key(\n1343                                     app_label,\n1344                                     model_name,\n1345                                     field,\n1346                                     self.to_state,\n1347                                 )\n1348                             )\n1349                 yield (\n1350                     old_value,\n1351                     new_value,\n1352                     app_label,\n1353                     model_name,\n1354                     dependencies,\n1355                 )\n1356 \n1357     def _generate_removed_altered_foo_together(self, operation):\n1358         for (\n1359             old_value,\n1360             new_value,\n1361             app_label,\n1362             model_name,\n1363             dependencies,\n1364         ) in self._get_altered_foo_together_operations(operation.option_name):\n1365             removal_value = new_value.intersection(old_value)\n1366             if removal_value or old_value:\n1367                 self.add_operation(\n1368                     app_label,\n1369                     operation(\n1370                         name=model_name, **{operation.option_name: removal_value}\n1371                     ),\n1372                     dependencies=dependencies,\n1373                 )\n1374 \n1375     def generate_removed_altered_unique_together(self):\n1376         self._generate_removed_altered_foo_together(operations.AlterUniqueTogether)\n1377 \n1378     def generate_removed_altered_index_together(self):\n1379         self._generate_removed_altered_foo_together(operations.AlterIndexTogether)\n1380 \n1381     def _generate_altered_foo_together(self, operation):\n1382         for (\n1383             old_value,\n1384             new_value,\n1385             app_label,\n1386             model_name,\n1387             dependencies,\n1388         ) in self._get_altered_foo_together_operations(operation.option_name):\n1389             removal_value = new_value.intersection(old_value)\n1390             if new_value != removal_value:\n1391                 self.add_operation(\n1392                     app_label,\n1393                     operation(name=model_name, **{operation.option_name: new_value}),\n1394                     dependencies=dependencies,\n1395                 )\n1396 \n1397     def generate_altered_unique_together(self):\n1398         self._generate_altered_foo_together(operations.AlterUniqueTogether)\n1399 \n1400     def generate_altered_index_together(self):\n1401         self._generate_altered_foo_together(operations.AlterIndexTogether)\n1402 \n1403     def generate_altered_db_table(self):\n1404         models_to_check = self.kept_model_keys.union(\n1405             self.kept_proxy_keys, self.kept_unmanaged_keys\n1406         )\n1407         for app_label, model_name in sorted(models_to_check):\n1408             old_model_name = self.renamed_models.get(\n1409                 (app_label, model_name), model_name\n1410             )\n1411             old_model_state = self.from_state.models[app_label, old_model_name]\n1412             new_model_state = self.to_state.models[app_label, model_name]\n1413             old_db_table_name = old_model_state.options.get(\"db_table\")\n1414             new_db_table_name = new_model_state.options.get(\"db_table\")\n1415             if old_db_table_name != new_db_table_name:\n1416                 self.add_operation(\n1417                     app_label,\n1418                     operations.AlterModelTable(\n1419                         name=model_name,\n1420                         table=new_db_table_name,\n1421                     ),\n1422                 )\n1423 \n1424     def generate_altered_options(self):\n1425         \"\"\"\n1426         Work out if any non-schema-affecting options have changed and make an\n1427         operation to represent them in state changes (in case Python code in\n1428         migrations needs them).\n1429         \"\"\"\n1430         models_to_check = self.kept_model_keys.union(\n1431             self.kept_proxy_keys,\n1432             self.kept_unmanaged_keys,\n1433             # unmanaged converted to managed\n1434             self.old_unmanaged_keys & self.new_model_keys,\n1435             # managed converted to unmanaged\n1436             self.old_model_keys & self.new_unmanaged_keys,\n1437         )\n1438 \n1439         for app_label, model_name in sorted(models_to_check):\n1440             old_model_name = self.renamed_models.get(\n1441                 (app_label, model_name), model_name\n1442             )\n1443             old_model_state = self.from_state.models[app_label, old_model_name]\n1444             new_model_state = self.to_state.models[app_label, model_name]\n1445             old_options = {\n1446                 key: value\n1447                 for key, value in old_model_state.options.items()\n1448                 if key in AlterModelOptions.ALTER_OPTION_KEYS\n1449             }\n1450             new_options = {\n1451                 key: value\n1452                 for key, value in new_model_state.options.items()\n1453                 if key in AlterModelOptions.ALTER_OPTION_KEYS\n1454             }\n1455             if old_options != new_options:\n1456                 self.add_operation(\n1457                     app_label,\n1458                     operations.AlterModelOptions(\n1459                         name=model_name,\n1460                         options=new_options,\n1461                     ),\n1462                 )\n1463 \n1464     def generate_altered_order_with_respect_to(self):\n1465         for app_label, model_name in sorted(self.kept_model_keys):\n1466             old_model_name = self.renamed_models.get(\n1467                 (app_label, model_name), model_name\n1468             )\n1469             old_model_state = self.from_state.models[app_label, old_model_name]\n1470             new_model_state = self.to_state.models[app_label, model_name]\n1471             if old_model_state.options.get(\n1472                 \"order_with_respect_to\"\n1473             ) != new_model_state.options.get(\"order_with_respect_to\"):\n1474                 # Make sure it comes second if we're adding\n1475                 # (removal dependency is part of RemoveField)\n1476                 dependencies = []\n1477                 if new_model_state.options.get(\"order_with_respect_to\"):\n1478                     dependencies.append(\n1479                         (\n1480                             app_label,\n1481                             model_name,\n1482                             new_model_state.options[\"order_with_respect_to\"],\n1483                             True,\n1484                         )\n1485                     )\n1486                 # Actually generate the operation\n1487                 self.add_operation(\n1488                     app_label,\n1489                     operations.AlterOrderWithRespectTo(\n1490                         name=model_name,\n1491                         order_with_respect_to=new_model_state.options.get(\n1492                             \"order_with_respect_to\"\n1493                         ),\n1494                     ),\n1495                     dependencies=dependencies,\n1496                 )\n1497 \n1498     def generate_altered_managers(self):\n1499         for app_label, model_name in sorted(self.kept_model_keys):\n1500             old_model_name = self.renamed_models.get(\n1501                 (app_label, model_name), model_name\n1502             )\n1503             old_model_state = self.from_state.models[app_label, old_model_name]\n1504             new_model_state = self.to_state.models[app_label, model_name]\n1505             if old_model_state.managers != new_model_state.managers:\n1506                 self.add_operation(\n1507                     app_label,\n1508                     operations.AlterModelManagers(\n1509                         name=model_name,\n1510                         managers=new_model_state.managers,\n1511                     ),\n1512                 )\n1513 \n1514     def arrange_for_graph(self, changes, graph, migration_name=None):\n1515         \"\"\"\n1516         Take a result from changes() and a MigrationGraph, and fix the names\n1517         and dependencies of the changes so they extend the graph from the leaf\n1518         nodes for each app.\n1519         \"\"\"\n1520         leaves = graph.leaf_nodes()\n1521         name_map = {}\n1522         for app_label, migrations in list(changes.items()):\n1523             if not migrations:\n1524                 continue\n1525             # Find the app label's current leaf node\n1526             app_leaf = None\n1527             for leaf in leaves:\n1528                 if leaf[0] == app_label:\n1529                     app_leaf = leaf\n1530                     break\n1531             # Do they want an initial migration for this app?\n1532             if app_leaf is None and not self.questioner.ask_initial(app_label):\n1533                 # They don't.\n1534                 for migration in migrations:\n1535                     name_map[(app_label, migration.name)] = (app_label, \"__first__\")\n1536                 del changes[app_label]\n1537                 continue\n1538             # Work out the next number in the sequence\n1539             if app_leaf is None:\n1540                 next_number = 1\n1541             else:\n1542                 next_number = (self.parse_number(app_leaf[1]) or 0) + 1\n1543             # Name each migration\n1544             for i, migration in enumerate(migrations):\n1545                 if i == 0 and app_leaf:\n1546                     migration.dependencies.append(app_leaf)\n1547                 new_name_parts = [\"%04i\" % next_number]\n1548                 if migration_name:\n1549                     new_name_parts.append(migration_name)\n1550                 elif i == 0 and not app_leaf:\n1551                     new_name_parts.append(\"initial\")\n1552                 else:\n1553                     new_name_parts.append(migration.suggest_name()[:100])\n1554                 new_name = \"_\".join(new_name_parts)\n1555                 name_map[(app_label, migration.name)] = (app_label, new_name)\n1556                 next_number += 1\n1557                 migration.name = new_name\n1558         # Now fix dependencies\n1559         for migrations in changes.values():\n1560             for migration in migrations:\n1561                 migration.dependencies = [\n1562                     name_map.get(d, d) for d in migration.dependencies\n1563                 ]\n1564         return changes\n1565 \n1566     def _trim_to_apps(self, changes, app_labels):\n1567         \"\"\"\n1568         Take changes from arrange_for_graph() and set of app labels, and return\n1569         a modified set of changes which trims out as many migrations that are\n1570         not in app_labels as possible. Note that some other migrations may\n1571         still be present as they may be required dependencies.\n1572         \"\"\"\n1573         # Gather other app dependencies in a first pass\n1574         app_dependencies = {}\n1575         for app_label, migrations in changes.items():\n1576             for migration in migrations:\n1577                 for dep_app_label, name in migration.dependencies:\n1578                     app_dependencies.setdefault(app_label, set()).add(dep_app_label)\n1579         required_apps = set(app_labels)\n1580         # Keep resolving till there's no change\n1581         old_required_apps = None\n1582         while old_required_apps != required_apps:\n1583             old_required_apps = set(required_apps)\n1584             required_apps.update(\n1585                 *[app_dependencies.get(app_label, ()) for app_label in required_apps]\n1586             )\n1587         # Remove all migrations that aren't needed\n1588         for app_label in list(changes):\n1589             if app_label not in required_apps:\n1590                 del changes[app_label]\n1591         return changes\n1592 \n1593     @classmethod\n1594     def parse_number(cls, name):\n1595         \"\"\"\n1596         Given a migration name, try to extract a number from the beginning of\n1597         it. For a squashed migration such as '0001_squashed_0004\u2026', return the\n1598         second number. If no number is found, return None.\n1599         \"\"\"\n1600         if squashed_match := re.search(r\".*_squashed_(\\d+)\", name):\n1601             return int(squashed_match[1])\n1602         match = re.match(r\"^\\d+\", name)\n1603         if match:\n1604             return int(match[0])\n1605         return None\n",
        "intended_behavior": "Enhance the detection logic to identify if a field involved in a migration is a foreign key referencing a field with a specific `db_collation`. If so, the migration operation should include steps to apply the same `db_collation` to the foreign key column."
    },
    {
        "rel_file_path": "django/db/models/fields/__init__.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__4.1/django/db/models/fields/__init__.py",
        "start": 1,
        "end": 2773,
        "class_name": null,
        "method_name": null,
        "code": "1 import collections.abc\n2 import copy\n3 import datetime\n4 import decimal\n5 import math\n6 import operator\n7 import uuid\n8 import warnings\n9 from base64 import b64decode, b64encode\n10 from functools import partialmethod, total_ordering\n11 \n12 from django import forms\n13 from django.apps import apps\n14 from django.conf import settings\n15 from django.core import checks, exceptions, validators\n16 from django.db import connection, connections, router\n17 from django.db.models.constants import LOOKUP_SEP\n18 from django.db.models.query_utils import DeferredAttribute, RegisterLookupMixin\n19 from django.utils import timezone\n20 from django.utils.datastructures import DictWrapper\n21 from django.utils.dateparse import (\n22     parse_date,\n23     parse_datetime,\n24     parse_duration,\n25     parse_time,\n26 )\n27 from django.utils.duration import duration_microseconds, duration_string\n28 from django.utils.functional import Promise, cached_property\n29 from django.utils.ipv6 import clean_ipv6_address\n30 from django.utils.itercompat import is_iterable\n31 from django.utils.text import capfirst\n32 from django.utils.translation import gettext_lazy as _\n33 \n34 __all__ = [\n35     \"AutoField\",\n36     \"BLANK_CHOICE_DASH\",\n37     \"BigAutoField\",\n38     \"BigIntegerField\",\n39     \"BinaryField\",\n40     \"BooleanField\",\n41     \"CharField\",\n42     \"CommaSeparatedIntegerField\",\n43     \"DateField\",\n44     \"DateTimeField\",\n45     \"DecimalField\",\n46     \"DurationField\",\n47     \"EmailField\",\n48     \"Empty\",\n49     \"Field\",\n50     \"FilePathField\",\n51     \"FloatField\",\n52     \"GenericIPAddressField\",\n53     \"IPAddressField\",\n54     \"IntegerField\",\n55     \"NOT_PROVIDED\",\n56     \"NullBooleanField\",\n57     \"PositiveBigIntegerField\",\n58     \"PositiveIntegerField\",\n59     \"PositiveSmallIntegerField\",\n60     \"SlugField\",\n61     \"SmallAutoField\",\n62     \"SmallIntegerField\",\n63     \"TextField\",\n64     \"TimeField\",\n65     \"URLField\",\n66     \"UUIDField\",\n67 ]\n68 \n69 \n70 class Empty:\n71     pass\n72 \n73 \n74 class NOT_PROVIDED:\n75     pass\n76 \n77 \n78 # The values to use for \"blank\" in SelectFields. Will be appended to the start\n79 # of most \"choices\" lists.\n80 BLANK_CHOICE_DASH = [(\"\", \"---------\")]\n81 \n82 \n83 def _load_field(app_label, model_name, field_name):\n84     return apps.get_model(app_label, model_name)._meta.get_field(field_name)\n85 \n86 \n87 # A guide to Field parameters:\n88 #\n89 #   * name:      The name of the field specified in the model.\n90 #   * attname:   The attribute to use on the model object. This is the same as\n91 #                \"name\", except in the case of ForeignKeys, where \"_id\" is\n92 #                appended.\n93 #   * db_column: The db_column specified in the model (or None).\n94 #   * column:    The database column for this field. This is the same as\n95 #                \"attname\", except if db_column is specified.\n96 #\n97 # Code that introspects values, or does other dynamic things, should use\n98 # attname. For example, this gets the primary key value of object \"obj\":\n99 #\n100 #     getattr(obj, opts.pk.attname)\n101 \n102 \n103 def _empty(of_cls):\n104     new = Empty()\n105     new.__class__ = of_cls\n106     return new\n107 \n108 \n109 def return_None():\n110     return None\n111 \n112 \n113 @total_ordering\n114 class Field(RegisterLookupMixin):\n115     \"\"\"Base class for all field types\"\"\"\n116 \n117     # Designates whether empty strings fundamentally are allowed at the\n118     # database level.\n119     empty_strings_allowed = True\n120     empty_values = list(validators.EMPTY_VALUES)\n121 \n122     # These track each time a Field instance is created. Used to retain order.\n123     # The auto_creation_counter is used for fields that Django implicitly\n124     # creates, creation_counter is used for all user-specified fields.\n125     creation_counter = 0\n126     auto_creation_counter = -1\n127     default_validators = []  # Default set of validators\n128     default_error_messages = {\n129         \"invalid_choice\": _(\"Value %(value)r is not a valid choice.\"),\n130         \"null\": _(\"This field cannot be null.\"),\n131         \"blank\": _(\"This field cannot be blank.\"),\n132         \"unique\": _(\"%(model_name)s with this %(field_label)s already exists.\"),\n133         # Translators: The 'lookup_type' is one of 'date', 'year' or 'month'.\n134         # Eg: \"Title must be unique for pub_date year\"\n135         \"unique_for_date\": _(\n136             \"%(field_label)s must be unique for \"\n137             \"%(date_field_label)s %(lookup_type)s.\"\n138         ),\n139     }\n140     system_check_deprecated_details = None\n141     system_check_removed_details = None\n142 \n143     # Attributes that don't affect a column definition.\n144     # These attributes are ignored when altering the field.\n145     non_db_attrs = (\n146         \"blank\",\n147         \"choices\",\n148         \"db_column\",\n149         \"editable\",\n150         \"error_messages\",\n151         \"help_text\",\n152         \"limit_choices_to\",\n153         # Database-level options are not supported, see #21961.\n154         \"on_delete\",\n155         \"related_name\",\n156         \"related_query_name\",\n157         \"validators\",\n158         \"verbose_name\",\n159     )\n160 \n161     # Field flags\n162     hidden = False\n163 \n164     many_to_many = None\n165     many_to_one = None\n166     one_to_many = None\n167     one_to_one = None\n168     related_model = None\n169 \n170     descriptor_class = DeferredAttribute\n171 \n172     # Generic field type description, usually overridden by subclasses\n173     def _description(self):\n174         return _(\"Field of type: %(field_type)s\") % {\n175             \"field_type\": self.__class__.__name__\n176         }\n177 \n178     description = property(_description)\n179 \n180     def __init__(\n181         self,\n182         verbose_name=None,\n183         name=None,\n184         primary_key=False,\n185         max_length=None,\n186         unique=False,\n187         blank=False,\n188         null=False,\n189         db_index=False,\n190         rel=None,\n191         default=NOT_PROVIDED,\n192         editable=True,\n193         serialize=True,\n194         unique_for_date=None,\n195         unique_for_month=None,\n196         unique_for_year=None,\n197         choices=None,\n198         help_text=\"\",\n199         db_column=None,\n200         db_tablespace=None,\n201         auto_created=False,\n202         validators=(),\n203         error_messages=None,\n204     ):\n205         self.name = name\n206         self.verbose_name = verbose_name  # May be set by set_attributes_from_name\n207         self._verbose_name = verbose_name  # Store original for deconstruction\n208         self.primary_key = primary_key\n209         self.max_length, self._unique = max_length, unique\n210         self.blank, self.null = blank, null\n211         self.remote_field = rel\n212         self.is_relation = self.remote_field is not None\n213         self.default = default\n214         self.editable = editable\n215         self.serialize = serialize\n216         self.unique_for_date = unique_for_date\n217         self.unique_for_month = unique_for_month\n218         self.unique_for_year = unique_for_year\n219         if isinstance(choices, collections.abc.Iterator):\n220             choices = list(choices)\n221         self.choices = choices\n222         self.help_text = help_text\n223         self.db_index = db_index\n224         self.db_column = db_column\n225         self._db_tablespace = db_tablespace\n226         self.auto_created = auto_created\n227 \n228         # Adjust the appropriate creation counter, and save our local copy.\n229         if auto_created:\n230             self.creation_counter = Field.auto_creation_counter\n231             Field.auto_creation_counter -= 1\n232         else:\n233             self.creation_counter = Field.creation_counter\n234             Field.creation_counter += 1\n235 \n236         self._validators = list(validators)  # Store for deconstruction later\n237 \n238         self._error_messages = error_messages  # Store for deconstruction later\n239 \n240     def __str__(self):\n241         \"\"\"\n242         Return \"app_label.model_label.field_name\" for fields attached to\n243         models.\n244         \"\"\"\n245         if not hasattr(self, \"model\"):\n246             return super().__str__()\n247         model = self.model\n248         return \"%s.%s\" % (model._meta.label, self.name)\n249 \n250     def __repr__(self):\n251         \"\"\"Display the module, class, and name of the field.\"\"\"\n252         path = \"%s.%s\" % (self.__class__.__module__, self.__class__.__qualname__)\n253         name = getattr(self, \"name\", None)\n254         if name is not None:\n255             return \"<%s: %s>\" % (path, name)\n256         return \"<%s>\" % path\n257 \n258     def check(self, **kwargs):\n259         return [\n260             *self._check_field_name(),\n261             *self._check_choices(),\n262             *self._check_db_index(),\n263             *self._check_null_allowed_for_primary_keys(),\n264             *self._check_backend_specific_checks(**kwargs),\n265             *self._check_validators(),\n266             *self._check_deprecation_details(),\n267         ]\n268 \n269     def _check_field_name(self):\n270         \"\"\"\n271         Check if field name is valid, i.e. 1) does not end with an\n272         underscore, 2) does not contain \"__\" and 3) is not \"pk\".\n273         \"\"\"\n274         if self.name.endswith(\"_\"):\n275             return [\n276                 checks.Error(\n277                     \"Field names must not end with an underscore.\",\n278                     obj=self,\n279                     id=\"fields.E001\",\n280                 )\n281             ]\n282         elif LOOKUP_SEP in self.name:\n283             return [\n284                 checks.Error(\n285                     'Field names must not contain \"%s\".' % LOOKUP_SEP,\n286                     obj=self,\n287                     id=\"fields.E002\",\n288                 )\n289             ]\n290         elif self.name == \"pk\":\n291             return [\n292                 checks.Error(\n293                     \"'pk' is a reserved word that cannot be used as a field name.\",\n294                     obj=self,\n295                     id=\"fields.E003\",\n296                 )\n297             ]\n298         else:\n299             return []\n300 \n301     @classmethod\n302     def _choices_is_value(cls, value):\n303         return isinstance(value, (str, Promise)) or not is_iterable(value)\n304 \n305     def _check_choices(self):\n306         if not self.choices:\n307             return []\n308 \n309         if not is_iterable(self.choices) or isinstance(self.choices, str):\n310             return [\n311                 checks.Error(\n312                     \"'choices' must be an iterable (e.g., a list or tuple).\",\n313                     obj=self,\n314                     id=\"fields.E004\",\n315                 )\n316             ]\n317 \n318         choice_max_length = 0\n319         # Expect [group_name, [value, display]]\n320         for choices_group in self.choices:\n321             try:\n322                 group_name, group_choices = choices_group\n323             except (TypeError, ValueError):\n324                 # Containing non-pairs\n325                 break\n326             try:\n327                 if not all(\n328                     self._choices_is_value(value) and self._choices_is_value(human_name)\n329                     for value, human_name in group_choices\n330                 ):\n331                     break\n332                 if self.max_length is not None and group_choices:\n333                     choice_max_length = max(\n334                         [\n335                             choice_max_length,\n336                             *(\n337                                 len(value)\n338                                 for value, _ in group_choices\n339                                 if isinstance(value, str)\n340                             ),\n341                         ]\n342                     )\n343             except (TypeError, ValueError):\n344                 # No groups, choices in the form [value, display]\n345                 value, human_name = group_name, group_choices\n346                 if not self._choices_is_value(value) or not self._choices_is_value(\n347                     human_name\n348                 ):\n349                     break\n350                 if self.max_length is not None and isinstance(value, str):\n351                     choice_max_length = max(choice_max_length, len(value))\n352 \n353             # Special case: choices=['ab']\n354             if isinstance(choices_group, str):\n355                 break\n356         else:\n357             if self.max_length is not None and choice_max_length > self.max_length:\n358                 return [\n359                     checks.Error(\n360                         \"'max_length' is too small to fit the longest value \"\n361                         \"in 'choices' (%d characters).\" % choice_max_length,\n362                         obj=self,\n363                         id=\"fields.E009\",\n364                     ),\n365                 ]\n366             return []\n367 \n368         return [\n369             checks.Error(\n370                 \"'choices' must be an iterable containing \"\n371                 \"(actual value, human readable name) tuples.\",\n372                 obj=self,\n373                 id=\"fields.E005\",\n374             )\n375         ]\n376 \n377     def _check_db_index(self):\n378         if self.db_index not in (None, True, False):\n379             return [\n380                 checks.Error(\n381                     \"'db_index' must be None, True or False.\",\n382                     obj=self,\n383                     id=\"fields.E006\",\n384                 )\n385             ]\n386         else:\n387             return []\n388 \n389     def _check_null_allowed_for_primary_keys(self):\n390         if (\n391             self.primary_key\n392             and self.null\n393             and not connection.features.interprets_empty_strings_as_nulls\n394         ):\n395             # We cannot reliably check this for backends like Oracle which\n396             # consider NULL and '' to be equal (and thus set up\n397             # character-based fields a little differently).\n398             return [\n399                 checks.Error(\n400                     \"Primary keys must not have null=True.\",\n401                     hint=(\n402                         \"Set null=False on the field, or \"\n403                         \"remove primary_key=True argument.\"\n404                     ),\n405                     obj=self,\n406                     id=\"fields.E007\",\n407                 )\n408             ]\n409         else:\n410             return []\n411 \n412     def _check_backend_specific_checks(self, databases=None, **kwargs):\n413         if databases is None:\n414             return []\n415         app_label = self.model._meta.app_label\n416         errors = []\n417         for alias in databases:\n418             if router.allow_migrate(\n419                 alias, app_label, model_name=self.model._meta.model_name\n420             ):\n421                 errors.extend(connections[alias].validation.check_field(self, **kwargs))\n422         return errors\n423 \n424     def _check_validators(self):\n425         errors = []\n426         for i, validator in enumerate(self.validators):\n427             if not callable(validator):\n428                 errors.append(\n429                     checks.Error(\n430                         \"All 'validators' must be callable.\",\n431                         hint=(\n432                             \"validators[{i}] ({repr}) isn't a function or \"\n433                             \"instance of a validator class.\".format(\n434                                 i=i,\n435                                 repr=repr(validator),\n436                             )\n437                         ),\n438                         obj=self,\n439                         id=\"fields.E008\",\n440                     )\n441                 )\n442         return errors\n443 \n444     def _check_deprecation_details(self):\n445         if self.system_check_removed_details is not None:\n446             return [\n447                 checks.Error(\n448                     self.system_check_removed_details.get(\n449                         \"msg\",\n450                         \"%s has been removed except for support in historical \"\n451                         \"migrations.\" % self.__class__.__name__,\n452                     ),\n453                     hint=self.system_check_removed_details.get(\"hint\"),\n454                     obj=self,\n455                     id=self.system_check_removed_details.get(\"id\", \"fields.EXXX\"),\n456                 )\n457             ]\n458         elif self.system_check_deprecated_details is not None:\n459             return [\n460                 checks.Warning(\n461                     self.system_check_deprecated_details.get(\n462                         \"msg\", \"%s has been deprecated.\" % self.__class__.__name__\n463                     ),\n464                     hint=self.system_check_deprecated_details.get(\"hint\"),\n465                     obj=self,\n466                     id=self.system_check_deprecated_details.get(\"id\", \"fields.WXXX\"),\n467                 )\n468             ]\n469         return []\n470 \n471     def get_col(self, alias, output_field=None):\n472         if alias == self.model._meta.db_table and (\n473             output_field is None or output_field == self\n474         ):\n475             return self.cached_col\n476         from django.db.models.expressions import Col\n477 \n478         return Col(alias, self, output_field)\n479 \n480     @cached_property\n481     def cached_col(self):\n482         from django.db.models.expressions import Col\n483 \n484         return Col(self.model._meta.db_table, self)\n485 \n486     def select_format(self, compiler, sql, params):\n487         \"\"\"\n488         Custom format for select clauses. For example, GIS columns need to be\n489         selected as AsText(table.col) on MySQL as the table.col data can't be\n490         used by Django.\n491         \"\"\"\n492         return sql, params\n493 \n494     def deconstruct(self):\n495         \"\"\"\n496         Return enough information to recreate the field as a 4-tuple:\n497 \n498          * The name of the field on the model, if contribute_to_class() has\n499            been run.\n500          * The import path of the field, including the class, e.g.\n501            django.db.models.IntegerField. This should be the most portable\n502            version, so less specific may be better.\n503          * A list of positional arguments.\n504          * A dict of keyword arguments.\n505 \n506         Note that the positional or keyword arguments must contain values of\n507         the following types (including inner values of collection types):\n508 \n509          * None, bool, str, int, float, complex, set, frozenset, list, tuple,\n510            dict\n511          * UUID\n512          * datetime.datetime (naive), datetime.date\n513          * top-level classes, top-level functions - will be referenced by their\n514            full import path\n515          * Storage instances - these have their own deconstruct() method\n516 \n517         This is because the values here must be serialized into a text format\n518         (possibly new Python code, possibly JSON) and these are the only types\n519         with encoding handlers defined.\n520 \n521         There's no need to return the exact way the field was instantiated this\n522         time, just ensure that the resulting field is the same - prefer keyword\n523         arguments over positional ones, and omit parameters with their default\n524         values.\n525         \"\"\"\n526         # Short-form way of fetching all the default parameters\n527         keywords = {}\n528         possibles = {\n529             \"verbose_name\": None,\n530             \"primary_key\": False,\n531             \"max_length\": None,\n532             \"unique\": False,\n533             \"blank\": False,\n534             \"null\": False,\n535             \"db_index\": False,\n536             \"default\": NOT_PROVIDED,\n537             \"editable\": True,\n538             \"serialize\": True,\n539             \"unique_for_date\": None,\n540             \"unique_for_month\": None,\n541             \"unique_for_year\": None,\n542             \"choices\": None,\n543             \"help_text\": \"\",\n544             \"db_column\": None,\n545             \"db_tablespace\": None,\n546             \"auto_created\": False,\n547             \"validators\": [],\n548             \"error_messages\": None,\n549         }\n550         attr_overrides = {\n551             \"unique\": \"_unique\",\n552             \"error_messages\": \"_error_messages\",\n553             \"validators\": \"_validators\",\n554             \"verbose_name\": \"_verbose_name\",\n555             \"db_tablespace\": \"_db_tablespace\",\n556         }\n557         equals_comparison = {\"choices\", \"validators\"}\n558         for name, default in possibles.items():\n559             value = getattr(self, attr_overrides.get(name, name))\n560             # Unroll anything iterable for choices into a concrete list\n561             if name == \"choices\" and isinstance(value, collections.abc.Iterable):\n562                 value = list(value)\n563             # Do correct kind of comparison\n564             if name in equals_comparison:\n565                 if value != default:\n566                     keywords[name] = value\n567             else:\n568                 if value is not default:\n569                     keywords[name] = value\n570         # Work out path - we shorten it for known Django core fields\n571         path = \"%s.%s\" % (self.__class__.__module__, self.__class__.__qualname__)\n572         if path.startswith(\"django.db.models.fields.related\"):\n573             path = path.replace(\"django.db.models.fields.related\", \"django.db.models\")\n574         elif path.startswith(\"django.db.models.fields.files\"):\n575             path = path.replace(\"django.db.models.fields.files\", \"django.db.models\")\n576         elif path.startswith(\"django.db.models.fields.json\"):\n577             path = path.replace(\"django.db.models.fields.json\", \"django.db.models\")\n578         elif path.startswith(\"django.db.models.fields.proxy\"):\n579             path = path.replace(\"django.db.models.fields.proxy\", \"django.db.models\")\n580         elif path.startswith(\"django.db.models.fields\"):\n581             path = path.replace(\"django.db.models.fields\", \"django.db.models\")\n582         # Return basic info - other fields should override this.\n583         return (self.name, path, [], keywords)\n584 \n585     def clone(self):\n586         \"\"\"\n587         Uses deconstruct() to clone a new copy of this Field.\n588         Will not preserve any class attachments/attribute names.\n589         \"\"\"\n590         name, path, args, kwargs = self.deconstruct()\n591         return self.__class__(*args, **kwargs)\n592 \n593     def __eq__(self, other):\n594         # Needed for @total_ordering\n595         if isinstance(other, Field):\n596             return self.creation_counter == other.creation_counter and getattr(\n597                 self, \"model\", None\n598             ) == getattr(other, \"model\", None)\n599         return NotImplemented\n600 \n601     def __lt__(self, other):\n602         # This is needed because bisect does not take a comparison function.\n603         # Order by creation_counter first for backward compatibility.\n604         if isinstance(other, Field):\n605             if (\n606                 self.creation_counter != other.creation_counter\n607                 or not hasattr(self, \"model\")\n608                 and not hasattr(other, \"model\")\n609             ):\n610                 return self.creation_counter < other.creation_counter\n611             elif hasattr(self, \"model\") != hasattr(other, \"model\"):\n612                 return not hasattr(self, \"model\")  # Order no-model fields first\n613             else:\n614                 # creation_counter's are equal, compare only models.\n615                 return (self.model._meta.app_label, self.model._meta.model_name) < (\n616                     other.model._meta.app_label,\n617                     other.model._meta.model_name,\n618                 )\n619         return NotImplemented\n620 \n621     def __hash__(self):\n622         return hash(self.creation_counter)\n623 \n624     def __deepcopy__(self, memodict):\n625         # We don't have to deepcopy very much here, since most things are not\n626         # intended to be altered after initial creation.\n627         obj = copy.copy(self)\n628         if self.remote_field:\n629             obj.remote_field = copy.copy(self.remote_field)\n630             if hasattr(self.remote_field, \"field\") and self.remote_field.field is self:\n631                 obj.remote_field.field = obj\n632         memodict[id(self)] = obj\n633         return obj\n634 \n635     def __copy__(self):\n636         # We need to avoid hitting __reduce__, so define this\n637         # slightly weird copy construct.\n638         obj = Empty()\n639         obj.__class__ = self.__class__\n640         obj.__dict__ = self.__dict__.copy()\n641         return obj\n642 \n643     def __reduce__(self):\n644         \"\"\"\n645         Pickling should return the model._meta.fields instance of the field,\n646         not a new copy of that field. So, use the app registry to load the\n647         model and then the field back.\n648         \"\"\"\n649         if not hasattr(self, \"model\"):\n650             # Fields are sometimes used without attaching them to models (for\n651             # example in aggregation). In this case give back a plain field\n652             # instance. The code below will create a new empty instance of\n653             # class self.__class__, then update its dict with self.__dict__\n654             # values - so, this is very close to normal pickle.\n655             state = self.__dict__.copy()\n656             # The _get_default cached_property can't be pickled due to lambda\n657             # usage.\n658             state.pop(\"_get_default\", None)\n659             return _empty, (self.__class__,), state\n660         return _load_field, (\n661             self.model._meta.app_label,\n662             self.model._meta.object_name,\n663             self.name,\n664         )\n665 \n666     def get_pk_value_on_save(self, instance):\n667         \"\"\"\n668         Hook to generate new PK values on save. This method is called when\n669         saving instances with no primary key value set. If this method returns\n670         something else than None, then the returned value is used when saving\n671         the new instance.\n672         \"\"\"\n673         if self.default:\n674             return self.get_default()\n675         return None\n676 \n677     def to_python(self, value):\n678         \"\"\"\n679         Convert the input value into the expected Python data type, raising\n680         django.core.exceptions.ValidationError if the data can't be converted.\n681         Return the converted value. Subclasses should override this.\n682         \"\"\"\n683         return value\n684 \n685     @cached_property\n686     def error_messages(self):\n687         messages = {}\n688         for c in reversed(self.__class__.__mro__):\n689             messages.update(getattr(c, \"default_error_messages\", {}))\n690         messages.update(self._error_messages or {})\n691         return messages\n692 \n693     @cached_property\n694     def validators(self):\n695         \"\"\"\n696         Some validators can't be created at field initialization time.\n697         This method provides a way to delay their creation until required.\n698         \"\"\"\n699         return [*self.default_validators, *self._validators]\n700 \n701     def run_validators(self, value):\n702         if value in self.empty_values:\n703             return\n704 \n705         errors = []\n706         for v in self.validators:\n707             try:\n708                 v(value)\n709             except exceptions.ValidationError as e:\n710                 if hasattr(e, \"code\") and e.code in self.error_messages:\n711                     e.message = self.error_messages[e.code]\n712                 errors.extend(e.error_list)\n713 \n714         if errors:\n715             raise exceptions.ValidationError(errors)\n716 \n717     def validate(self, value, model_instance):\n718         \"\"\"\n719         Validate value and raise ValidationError if necessary. Subclasses\n720         should override this to provide validation logic.\n721         \"\"\"\n722         if not self.editable:\n723             # Skip validation for non-editable fields.\n724             return\n725 \n726         if self.choices is not None and value not in self.empty_values:\n727             for option_key, option_value in self.choices:\n728                 if isinstance(option_value, (list, tuple)):\n729                     # This is an optgroup, so look inside the group for\n730                     # options.\n731                     for optgroup_key, optgroup_value in option_value:\n732                         if value == optgroup_key:\n733                             return\n734                 elif value == option_key:\n735                     return\n736             raise exceptions.ValidationError(\n737                 self.error_messages[\"invalid_choice\"],\n738                 code=\"invalid_choice\",\n739                 params={\"value\": value},\n740             )\n741 \n742         if value is None and not self.null:\n743             raise exceptions.ValidationError(self.error_messages[\"null\"], code=\"null\")\n744 \n745         if not self.blank and value in self.empty_values:\n746             raise exceptions.ValidationError(self.error_messages[\"blank\"], code=\"blank\")\n747 \n748     def clean(self, value, model_instance):\n749         \"\"\"\n750         Convert the value's type and run validation. Validation errors\n751         from to_python() and validate() are propagated. Return the correct\n752         value if no error is raised.\n753         \"\"\"\n754         value = self.to_python(value)\n755         self.validate(value, model_instance)\n756         self.run_validators(value)\n757         return value\n758 \n759     def db_type_parameters(self, connection):\n760         return DictWrapper(self.__dict__, connection.ops.quote_name, \"qn_\")\n761 \n762     def db_check(self, connection):\n763         \"\"\"\n764         Return the database column check constraint for this field, for the\n765         provided connection. Works the same way as db_type() for the case that\n766         get_internal_type() does not map to a preexisting model field.\n767         \"\"\"\n768         data = self.db_type_parameters(connection)\n769         try:\n770             return (\n771                 connection.data_type_check_constraints[self.get_internal_type()] % data\n772             )\n773         except KeyError:\n774             return None\n775 \n776     def db_type(self, connection):\n777         \"\"\"\n778         Return the database column data type for this field, for the provided\n779         connection.\n780         \"\"\"\n781         # The default implementation of this method looks at the\n782         # backend-specific data_types dictionary, looking up the field by its\n783         # \"internal type\".\n784         #\n785         # A Field class can implement the get_internal_type() method to specify\n786         # which *preexisting* Django Field class it's most similar to -- i.e.,\n787         # a custom field might be represented by a TEXT column type, which is\n788         # the same as the TextField Django field type, which means the custom\n789         # field's get_internal_type() returns 'TextField'.\n790         #\n791         # But the limitation of the get_internal_type() / data_types approach\n792         # is that it cannot handle database column types that aren't already\n793         # mapped to one of the built-in Django field types. In this case, you\n794         # can implement db_type() instead of get_internal_type() to specify\n795         # exactly which wacky database column type you want to use.\n796         data = self.db_type_parameters(connection)\n797         try:\n798             return connection.data_types[self.get_internal_type()] % data\n799         except KeyError:\n800             return None\n801 \n802     def rel_db_type(self, connection):\n803         \"\"\"\n804         Return the data type that a related field pointing to this field should\n805         use. For example, this method is called by ForeignKey and OneToOneField\n806         to determine its data type.\n807         \"\"\"\n808         return self.db_type(connection)\n809 \n810     def cast_db_type(self, connection):\n811         \"\"\"Return the data type to use in the Cast() function.\"\"\"\n812         db_type = connection.ops.cast_data_types.get(self.get_internal_type())\n813         if db_type:\n814             return db_type % self.db_type_parameters(connection)\n815         return self.db_type(connection)\n816 \n817     def db_parameters(self, connection):\n818         \"\"\"\n819         Extension of db_type(), providing a range of different return values\n820         (type, checks). This will look at db_type(), allowing custom model\n821         fields to override it.\n822         \"\"\"\n823         type_string = self.db_type(connection)\n824         check_string = self.db_check(connection)\n825         return {\n826             \"type\": type_string,\n827             \"check\": check_string,\n828         }\n829 \n830     def db_type_suffix(self, connection):\n831         return connection.data_types_suffix.get(self.get_internal_type())\n832 \n833     def get_db_converters(self, connection):\n834         if hasattr(self, \"from_db_value\"):\n835             return [self.from_db_value]\n836         return []\n837 \n838     @property\n839     def unique(self):\n840         return self._unique or self.primary_key\n841 \n842     @property\n843     def db_tablespace(self):\n844         return self._db_tablespace or settings.DEFAULT_INDEX_TABLESPACE\n845 \n846     @property\n847     def db_returning(self):\n848         \"\"\"\n849         Private API intended only to be used by Django itself. Currently only\n850         the PostgreSQL backend supports returning multiple fields on a model.\n851         \"\"\"\n852         return False\n853 \n854     def set_attributes_from_name(self, name):\n855         self.name = self.name or name\n856         self.attname, self.column = self.get_attname_column()\n857         self.concrete = self.column is not None\n858         if self.verbose_name is None and self.name:\n859             self.verbose_name = self.name.replace(\"_\", \" \")\n860 \n861     def contribute_to_class(self, cls, name, private_only=False):\n862         \"\"\"\n863         Register the field with the model class it belongs to.\n864 \n865         If private_only is True, create a separate instance of this field\n866         for every subclass of cls, even if cls is not an abstract model.\n867         \"\"\"\n868         self.set_attributes_from_name(name)\n869         self.model = cls\n870         cls._meta.add_field(self, private=private_only)\n871         if self.column:\n872             setattr(cls, self.attname, self.descriptor_class(self))\n873         if self.choices is not None:\n874             # Don't override a get_FOO_display() method defined explicitly on\n875             # this class, but don't check methods derived from inheritance, to\n876             # allow overriding inherited choices. For more complex inheritance\n877             # structures users should override contribute_to_class().\n878             if \"get_%s_display\" % self.name not in cls.__dict__:\n879                 setattr(\n880                     cls,\n881                     \"get_%s_display\" % self.name,\n882                     partialmethod(cls._get_FIELD_display, field=self),\n883                 )\n884 \n885     def get_filter_kwargs_for_object(self, obj):\n886         \"\"\"\n887         Return a dict that when passed as kwargs to self.model.filter(), would\n888         yield all instances having the same value for this field as obj has.\n889         \"\"\"\n890         return {self.name: getattr(obj, self.attname)}\n891 \n892     def get_attname(self):\n893         return self.name\n894 \n895     def get_attname_column(self):\n896         attname = self.get_attname()\n897         column = self.db_column or attname\n898         return attname, column\n899 \n900     def get_internal_type(self):\n901         return self.__class__.__name__\n902 \n903     def pre_save(self, model_instance, add):\n904         \"\"\"Return field's value just before saving.\"\"\"\n905         return getattr(model_instance, self.attname)\n906 \n907     def get_prep_value(self, value):\n908         \"\"\"Perform preliminary non-db specific value checks and conversions.\"\"\"\n909         if isinstance(value, Promise):\n910             value = value._proxy____cast()\n911         return value\n912 \n913     def get_db_prep_value(self, value, connection, prepared=False):\n914         \"\"\"\n915         Return field's value prepared for interacting with the database backend.\n916 \n917         Used by the default implementations of get_db_prep_save().\n918         \"\"\"\n919         if not prepared:\n920             value = self.get_prep_value(value)\n921         return value\n922 \n923     def get_db_prep_save(self, value, connection):\n924         \"\"\"Return field's value prepared for saving into a database.\"\"\"\n925         return self.get_db_prep_value(value, connection=connection, prepared=False)\n926 \n927     def has_default(self):\n928         \"\"\"Return a boolean of whether this field has a default value.\"\"\"\n929         return self.default is not NOT_PROVIDED\n930 \n931     def get_default(self):\n932         \"\"\"Return the default value for this field.\"\"\"\n933         return self._get_default()\n934 \n935     @cached_property\n936     def _get_default(self):\n937         if self.has_default():\n938             if callable(self.default):\n939                 return self.default\n940             return lambda: self.default\n941 \n942         if (\n943             not self.empty_strings_allowed\n944             or self.null\n945             and not connection.features.interprets_empty_strings_as_nulls\n946         ):\n947             return return_None\n948         return str  # return empty string\n949 \n950     def get_choices(\n951         self,\n952         include_blank=True,\n953         blank_choice=BLANK_CHOICE_DASH,\n954         limit_choices_to=None,\n955         ordering=(),\n956     ):\n957         \"\"\"\n958         Return choices with a default blank choices included, for use\n959         as <select> choices for this field.\n960         \"\"\"\n961         if self.choices is not None:\n962             choices = list(self.choices)\n963             if include_blank:\n964                 blank_defined = any(\n965                     choice in (\"\", None) for choice, _ in self.flatchoices\n966                 )\n967                 if not blank_defined:\n968                     choices = blank_choice + choices\n969             return choices\n970         rel_model = self.remote_field.model\n971         limit_choices_to = limit_choices_to or self.get_limit_choices_to()\n972         choice_func = operator.attrgetter(\n973             self.remote_field.get_related_field().attname\n974             if hasattr(self.remote_field, \"get_related_field\")\n975             else \"pk\"\n976         )\n977         qs = rel_model._default_manager.complex_filter(limit_choices_to)\n978         if ordering:\n979             qs = qs.order_by(*ordering)\n980         return (blank_choice if include_blank else []) + [\n981             (choice_func(x), str(x)) for x in qs\n982         ]\n983 \n984     def value_to_string(self, obj):\n985         \"\"\"\n986         Return a string value of this field from the passed obj.\n987         This is used by the serialization framework.\n988         \"\"\"\n989         return str(self.value_from_object(obj))\n990 \n991     def _get_flatchoices(self):\n992         \"\"\"Flattened version of choices tuple.\"\"\"\n993         if self.choices is None:\n994             return []\n995         flat = []\n996         for choice, value in self.choices:\n997             if isinstance(value, (list, tuple)):\n998                 flat.extend(value)\n999             else:\n1000                 flat.append((choice, value))\n1001         return flat\n1002 \n1003     flatchoices = property(_get_flatchoices)\n1004 \n1005     def save_form_data(self, instance, data):\n1006         setattr(instance, self.name, data)\n1007 \n1008     def formfield(self, form_class=None, choices_form_class=None, **kwargs):\n1009         \"\"\"Return a django.forms.Field instance for this field.\"\"\"\n1010         defaults = {\n1011             \"required\": not self.blank,\n1012             \"label\": capfirst(self.verbose_name),\n1013             \"help_text\": self.help_text,\n1014         }\n1015         if self.has_default():\n1016             if callable(self.default):\n1017                 defaults[\"initial\"] = self.default\n1018                 defaults[\"show_hidden_initial\"] = True\n1019             else:\n1020                 defaults[\"initial\"] = self.get_default()\n1021         if self.choices is not None:\n1022             # Fields with choices get special treatment.\n1023             include_blank = self.blank or not (\n1024                 self.has_default() or \"initial\" in kwargs\n1025             )\n1026             defaults[\"choices\"] = self.get_choices(include_blank=include_blank)\n1027             defaults[\"coerce\"] = self.to_python\n1028             if self.null:\n1029                 defaults[\"empty_value\"] = None\n1030             if choices_form_class is not None:\n1031                 form_class = choices_form_class\n1032             else:\n1033                 form_class = forms.TypedChoiceField\n1034             # Many of the subclass-specific formfield arguments (min_value,\n1035             # max_value) don't apply for choice fields, so be sure to only pass\n1036             # the values that TypedChoiceField will understand.\n1037             for k in list(kwargs):\n1038                 if k not in (\n1039                     \"coerce\",\n1040                     \"empty_value\",\n1041                     \"choices\",\n1042                     \"required\",\n1043                     \"widget\",\n1044                     \"label\",\n1045                     \"initial\",\n1046                     \"help_text\",\n1047                     \"error_messages\",\n1048                     \"show_hidden_initial\",\n1049                     \"disabled\",\n1050                 ):\n1051                     del kwargs[k]\n1052         defaults.update(kwargs)\n1053         if form_class is None:\n1054             form_class = forms.CharField\n1055         return form_class(**defaults)\n1056 \n1057     def value_from_object(self, obj):\n1058         \"\"\"Return the value of this field in the given model instance.\"\"\"\n1059         return getattr(obj, self.attname)\n1060 \n1061 \n1062 class BooleanField(Field):\n1063     empty_strings_allowed = False\n1064     default_error_messages = {\n1065         \"invalid\": _(\"\u201c%(value)s\u201d value must be either True or False.\"),\n1066         \"invalid_nullable\": _(\"\u201c%(value)s\u201d value must be either True, False, or None.\"),\n1067     }\n1068     description = _(\"Boolean (Either True or False)\")\n1069 \n1070     def get_internal_type(self):\n1071         return \"BooleanField\"\n1072 \n1073     def to_python(self, value):\n1074         if self.null and value in self.empty_values:\n1075             return None\n1076         if value in (True, False):\n1077             # 1/0 are equal to True/False. bool() converts former to latter.\n1078             return bool(value)\n1079         if value in (\"t\", \"True\", \"1\"):\n1080             return True\n1081         if value in (\"f\", \"False\", \"0\"):\n1082             return False\n1083         raise exceptions.ValidationError(\n1084             self.error_messages[\"invalid_nullable\" if self.null else \"invalid\"],\n1085             code=\"invalid\",\n1086             params={\"value\": value},\n1087         )\n1088 \n1089     def get_prep_value(self, value):\n1090         value = super().get_prep_value(value)\n1091         if value is None:\n1092             return None\n1093         return self.to_python(value)\n1094 \n1095     def formfield(self, **kwargs):\n1096         if self.choices is not None:\n1097             include_blank = not (self.has_default() or \"initial\" in kwargs)\n1098             defaults = {\"choices\": self.get_choices(include_blank=include_blank)}\n1099         else:\n1100             form_class = forms.NullBooleanField if self.null else forms.BooleanField\n1101             # In HTML checkboxes, 'required' means \"must be checked\" which is\n1102             # different from the choices case (\"must select some value\").\n1103             # required=False allows unchecked checkboxes.\n1104             defaults = {\"form_class\": form_class, \"required\": False}\n1105         return super().formfield(**{**defaults, **kwargs})\n1106 \n1107     def select_format(self, compiler, sql, params):\n1108         sql, params = super().select_format(compiler, sql, params)\n1109         # Filters that match everything are handled as empty strings in the\n1110         # WHERE clause, but in SELECT or GROUP BY list they must use a\n1111         # predicate that's always True.\n1112         if sql == \"\":\n1113             sql = \"1\"\n1114         return sql, params\n1115 \n1116 \n1117 class CharField(Field):\n1118     description = _(\"String (up to %(max_length)s)\")\n1119 \n1120     def __init__(self, *args, db_collation=None, **kwargs):\n1121         super().__init__(*args, **kwargs)\n1122         self.db_collation = db_collation\n1123         if self.max_length is not None:\n1124             self.validators.append(validators.MaxLengthValidator(self.max_length))\n1125 \n1126     def check(self, **kwargs):\n1127         databases = kwargs.get(\"databases\") or []\n1128         return [\n1129             *super().check(**kwargs),\n1130             *self._check_db_collation(databases),\n1131             *self._check_max_length_attribute(**kwargs),\n1132         ]\n1133 \n1134     def _check_max_length_attribute(self, **kwargs):\n1135         if self.max_length is None:\n1136             return [\n1137                 checks.Error(\n1138                     \"CharFields must define a 'max_length' attribute.\",\n1139                     obj=self,\n1140                     id=\"fields.E120\",\n1141                 )\n1142             ]\n1143         elif (\n1144             not isinstance(self.max_length, int)\n1145             or isinstance(self.max_length, bool)\n1146             or self.max_length <= 0\n1147         ):\n1148             return [\n1149                 checks.Error(\n1150                     \"'max_length' must be a positive integer.\",\n1151                     obj=self,\n1152                     id=\"fields.E121\",\n1153                 )\n1154             ]\n1155         else:\n1156             return []\n1157 \n1158     def _check_db_collation(self, databases):\n1159         errors = []\n1160         for db in databases:\n1161             if not router.allow_migrate_model(db, self.model):\n1162                 continue\n1163             connection = connections[db]\n1164             if not (\n1165                 self.db_collation is None\n1166                 or \"supports_collation_on_charfield\"\n1167                 in self.model._meta.required_db_features\n1168                 or connection.features.supports_collation_on_charfield\n1169             ):\n1170                 errors.append(\n1171                     checks.Error(\n1172                         \"%s does not support a database collation on \"\n1173                         \"CharFields.\" % connection.display_name,\n1174                         obj=self,\n1175                         id=\"fields.E190\",\n1176                     ),\n1177                 )\n1178         return errors\n1179 \n1180     def cast_db_type(self, connection):\n1181         if self.max_length is None:\n1182             return connection.ops.cast_char_field_without_max_length\n1183         return super().cast_db_type(connection)\n1184 \n1185     def db_parameters(self, connection):\n1186         db_params = super().db_parameters(connection)\n1187         db_params[\"collation\"] = self.db_collation\n1188         return db_params\n1189 \n1190     def get_internal_type(self):\n1191         return \"CharField\"\n1192 \n1193     def to_python(self, value):\n1194         if isinstance(value, str) or value is None:\n1195             return value\n1196         return str(value)\n1197 \n1198     def get_prep_value(self, value):\n1199         value = super().get_prep_value(value)\n1200         return self.to_python(value)\n1201 \n1202     def formfield(self, **kwargs):\n1203         # Passing max_length to forms.CharField means that the value's length\n1204         # will be validated twice. This is considered acceptable since we want\n1205         # the value in the form field (to pass into widget for example).\n1206         defaults = {\"max_length\": self.max_length}\n1207         # TODO: Handle multiple backends with different feature flags.\n1208         if self.null and not connection.features.interprets_empty_strings_as_nulls:\n1209             defaults[\"empty_value\"] = None\n1210         defaults.update(kwargs)\n1211         return super().formfield(**defaults)\n1212 \n1213     def deconstruct(self):\n1214         name, path, args, kwargs = super().deconstruct()\n1215         if self.db_collation:\n1216             kwargs[\"db_collation\"] = self.db_collation\n1217         return name, path, args, kwargs\n1218 \n1219 \n1220 class CommaSeparatedIntegerField(CharField):\n1221     default_validators = [validators.validate_comma_separated_integer_list]\n1222     description = _(\"Comma-separated integers\")\n1223     system_check_removed_details = {\n1224         \"msg\": (\n1225             \"CommaSeparatedIntegerField is removed except for support in \"\n1226             \"historical migrations.\"\n1227         ),\n1228         \"hint\": (\n1229             \"Use CharField(validators=[validate_comma_separated_integer_list]) \"\n1230             \"instead.\"\n1231         ),\n1232         \"id\": \"fields.E901\",\n1233     }\n1234 \n1235 \n1236 def _to_naive(value):\n1237     if timezone.is_aware(value):\n1238         value = timezone.make_naive(value, datetime.timezone.utc)\n1239     return value\n1240 \n1241 \n1242 def _get_naive_now():\n1243     return _to_naive(timezone.now())\n1244 \n1245 \n1246 class DateTimeCheckMixin:\n1247     def check(self, **kwargs):\n1248         return [\n1249             *super().check(**kwargs),\n1250             *self._check_mutually_exclusive_options(),\n1251             *self._check_fix_default_value(),\n1252         ]\n1253 \n1254     def _check_mutually_exclusive_options(self):\n1255         # auto_now, auto_now_add, and default are mutually exclusive\n1256         # options. The use of more than one of these options together\n1257         # will trigger an Error\n1258         mutually_exclusive_options = [\n1259             self.auto_now_add,\n1260             self.auto_now,\n1261             self.has_default(),\n1262         ]\n1263         enabled_options = [\n1264             option not in (None, False) for option in mutually_exclusive_options\n1265         ].count(True)\n1266         if enabled_options > 1:\n1267             return [\n1268                 checks.Error(\n1269                     \"The options auto_now, auto_now_add, and default \"\n1270                     \"are mutually exclusive. Only one of these options \"\n1271                     \"may be present.\",\n1272                     obj=self,\n1273                     id=\"fields.E160\",\n1274                 )\n1275             ]\n1276         else:\n1277             return []\n1278 \n1279     def _check_fix_default_value(self):\n1280         return []\n1281 \n1282     # Concrete subclasses use this in their implementations of\n1283     # _check_fix_default_value().\n1284     def _check_if_value_fixed(self, value, now=None):\n1285         \"\"\"\n1286         Check if the given value appears to have been provided as a \"fixed\"\n1287         time value, and include a warning in the returned list if it does. The\n1288         value argument must be a date object or aware/naive datetime object. If\n1289         now is provided, it must be a naive datetime object.\n1290         \"\"\"\n1291         if now is None:\n1292             now = _get_naive_now()\n1293         offset = datetime.timedelta(seconds=10)\n1294         lower = now - offset\n1295         upper = now + offset\n1296         if isinstance(value, datetime.datetime):\n1297             value = _to_naive(value)\n1298         else:\n1299             assert isinstance(value, datetime.date)\n1300             lower = lower.date()\n1301             upper = upper.date()\n1302         if lower <= value <= upper:\n1303             return [\n1304                 checks.Warning(\n1305                     \"Fixed default value provided.\",\n1306                     hint=(\n1307                         \"It seems you set a fixed date / time / datetime \"\n1308                         \"value as default for this field. This may not be \"\n1309                         \"what you want. If you want to have the current date \"\n1310                         \"as default, use `django.utils.timezone.now`\"\n1311                     ),\n1312                     obj=self,\n1313                     id=\"fields.W161\",\n1314                 )\n1315             ]\n1316         return []\n1317 \n1318 \n1319 class DateField(DateTimeCheckMixin, Field):\n1320     empty_strings_allowed = False\n1321     default_error_messages = {\n1322         \"invalid\": _(\n1323             \"\u201c%(value)s\u201d value has an invalid date format. It must be \"\n1324             \"in YYYY-MM-DD format.\"\n1325         ),\n1326         \"invalid_date\": _(\n1327             \"\u201c%(value)s\u201d value has the correct format (YYYY-MM-DD) \"\n1328             \"but it is an invalid date.\"\n1329         ),\n1330     }\n1331     description = _(\"Date (without time)\")\n1332 \n1333     def __init__(\n1334         self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs\n1335     ):\n1336         self.auto_now, self.auto_now_add = auto_now, auto_now_add\n1337         if auto_now or auto_now_add:\n1338             kwargs[\"editable\"] = False\n1339             kwargs[\"blank\"] = True\n1340         super().__init__(verbose_name, name, **kwargs)\n1341 \n1342     def _check_fix_default_value(self):\n1343         \"\"\"\n1344         Warn that using an actual date or datetime value is probably wrong;\n1345         it's only evaluated on server startup.\n1346         \"\"\"\n1347         if not self.has_default():\n1348             return []\n1349 \n1350         value = self.default\n1351         if isinstance(value, datetime.datetime):\n1352             value = _to_naive(value).date()\n1353         elif isinstance(value, datetime.date):\n1354             pass\n1355         else:\n1356             # No explicit date / datetime value -- no checks necessary\n1357             return []\n1358         # At this point, value is a date object.\n1359         return self._check_if_value_fixed(value)\n1360 \n1361     def deconstruct(self):\n1362         name, path, args, kwargs = super().deconstruct()\n1363         if self.auto_now:\n1364             kwargs[\"auto_now\"] = True\n1365         if self.auto_now_add:\n1366             kwargs[\"auto_now_add\"] = True\n1367         if self.auto_now or self.auto_now_add:\n1368             del kwargs[\"editable\"]\n1369             del kwargs[\"blank\"]\n1370         return name, path, args, kwargs\n1371 \n1372     def get_internal_type(self):\n1373         return \"DateField\"\n1374 \n1375     def to_python(self, value):\n1376         if value is None:\n1377             return value\n1378         if isinstance(value, datetime.datetime):\n1379             if settings.USE_TZ and timezone.is_aware(value):\n1380                 # Convert aware datetimes to the default time zone\n1381                 # before casting them to dates (#17742).\n1382                 default_timezone = timezone.get_default_timezone()\n1383                 value = timezone.make_naive(value, default_timezone)\n1384             return value.date()\n1385         if isinstance(value, datetime.date):\n1386             return value\n1387 \n1388         try:\n1389             parsed = parse_date(value)\n1390             if parsed is not None:\n1391                 return parsed\n1392         except ValueError:\n1393             raise exceptions.ValidationError(\n1394                 self.error_messages[\"invalid_date\"],\n1395                 code=\"invalid_date\",\n1396                 params={\"value\": value},\n1397             )\n1398 \n1399         raise exceptions.ValidationError(\n1400             self.error_messages[\"invalid\"],\n1401             code=\"invalid\",\n1402             params={\"value\": value},\n1403         )\n1404 \n1405     def pre_save(self, model_instance, add):\n1406         if self.auto_now or (self.auto_now_add and add):\n1407             value = datetime.date.today()\n1408             setattr(model_instance, self.attname, value)\n1409             return value\n1410         else:\n1411             return super().pre_save(model_instance, add)\n1412 \n1413     def contribute_to_class(self, cls, name, **kwargs):\n1414         super().contribute_to_class(cls, name, **kwargs)\n1415         if not self.null:\n1416             setattr(\n1417                 cls,\n1418                 \"get_next_by_%s\" % self.name,\n1419                 partialmethod(\n1420                     cls._get_next_or_previous_by_FIELD, field=self, is_next=True\n1421                 ),\n1422             )\n1423             setattr(\n1424                 cls,\n1425                 \"get_previous_by_%s\" % self.name,\n1426                 partialmethod(\n1427                     cls._get_next_or_previous_by_FIELD, field=self, is_next=False\n1428                 ),\n1429             )\n1430 \n1431     def get_prep_value(self, value):\n1432         value = super().get_prep_value(value)\n1433         return self.to_python(value)\n1434 \n1435     def get_db_prep_value(self, value, connection, prepared=False):\n1436         # Casts dates into the format expected by the backend\n1437         if not prepared:\n1438             value = self.get_prep_value(value)\n1439         return connection.ops.adapt_datefield_value(value)\n1440 \n1441     def value_to_string(self, obj):\n1442         val = self.value_from_object(obj)\n1443         return \"\" if val is None else val.isoformat()\n1444 \n1445     def formfield(self, **kwargs):\n1446         return super().formfield(\n1447             **{\n1448                 \"form_class\": forms.DateField,\n1449                 **kwargs,\n1450             }\n1451         )\n1452 \n1453 \n1454 class DateTimeField(DateField):\n1455     empty_strings_allowed = False\n1456     default_error_messages = {\n1457         \"invalid\": _(\n1458             \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n1459             \"YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.\"\n1460         ),\n1461         \"invalid_date\": _(\n1462             \"\u201c%(value)s\u201d value has the correct format \"\n1463             \"(YYYY-MM-DD) but it is an invalid date.\"\n1464         ),\n1465         \"invalid_datetime\": _(\n1466             \"\u201c%(value)s\u201d value has the correct format \"\n1467             \"(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) \"\n1468             \"but it is an invalid date/time.\"\n1469         ),\n1470     }\n1471     description = _(\"Date (with time)\")\n1472 \n1473     # __init__ is inherited from DateField\n1474 \n1475     def _check_fix_default_value(self):\n1476         \"\"\"\n1477         Warn that using an actual date or datetime value is probably wrong;\n1478         it's only evaluated on server startup.\n1479         \"\"\"\n1480         if not self.has_default():\n1481             return []\n1482 \n1483         value = self.default\n1484         if isinstance(value, (datetime.datetime, datetime.date)):\n1485             return self._check_if_value_fixed(value)\n1486         # No explicit date / datetime value -- no checks necessary.\n1487         return []\n1488 \n1489     def get_internal_type(self):\n1490         return \"DateTimeField\"\n1491 \n1492     def to_python(self, value):\n1493         if value is None:\n1494             return value\n1495         if isinstance(value, datetime.datetime):\n1496             return value\n1497         if isinstance(value, datetime.date):\n1498             value = datetime.datetime(value.year, value.month, value.day)\n1499             if settings.USE_TZ:\n1500                 # For backwards compatibility, interpret naive datetimes in\n1501                 # local time. This won't work during DST change, but we can't\n1502                 # do much about it, so we let the exceptions percolate up the\n1503                 # call stack.\n1504                 warnings.warn(\n1505                     \"DateTimeField %s.%s received a naive datetime \"\n1506                     \"(%s) while time zone support is active.\"\n1507                     % (self.model.__name__, self.name, value),\n1508                     RuntimeWarning,\n1509                 )\n1510                 default_timezone = timezone.get_default_timezone()\n1511                 value = timezone.make_aware(value, default_timezone)\n1512             return value\n1513 \n1514         try:\n1515             parsed = parse_datetime(value)\n1516             if parsed is not None:\n1517                 return parsed\n1518         except ValueError:\n1519             raise exceptions.ValidationError(\n1520                 self.error_messages[\"invalid_datetime\"],\n1521                 code=\"invalid_datetime\",\n1522                 params={\"value\": value},\n1523             )\n1524 \n1525         try:\n1526             parsed = parse_date(value)\n1527             if parsed is not None:\n1528                 return datetime.datetime(parsed.year, parsed.month, parsed.day)\n1529         except ValueError:\n1530             raise exceptions.ValidationError(\n1531                 self.error_messages[\"invalid_date\"],\n1532                 code=\"invalid_date\",\n1533                 params={\"value\": value},\n1534             )\n1535 \n1536         raise exceptions.ValidationError(\n1537             self.error_messages[\"invalid\"],\n1538             code=\"invalid\",\n1539             params={\"value\": value},\n1540         )\n1541 \n1542     def pre_save(self, model_instance, add):\n1543         if self.auto_now or (self.auto_now_add and add):\n1544             value = timezone.now()\n1545             setattr(model_instance, self.attname, value)\n1546             return value\n1547         else:\n1548             return super().pre_save(model_instance, add)\n1549 \n1550     # contribute_to_class is inherited from DateField, it registers\n1551     # get_next_by_FOO and get_prev_by_FOO\n1552 \n1553     def get_prep_value(self, value):\n1554         value = super().get_prep_value(value)\n1555         value = self.to_python(value)\n1556         if value is not None and settings.USE_TZ and timezone.is_naive(value):\n1557             # For backwards compatibility, interpret naive datetimes in local\n1558             # time. This won't work during DST change, but we can't do much\n1559             # about it, so we let the exceptions percolate up the call stack.\n1560             try:\n1561                 name = \"%s.%s\" % (self.model.__name__, self.name)\n1562             except AttributeError:\n1563                 name = \"(unbound)\"\n1564             warnings.warn(\n1565                 \"DateTimeField %s received a naive datetime (%s)\"\n1566                 \" while time zone support is active.\" % (name, value),\n1567                 RuntimeWarning,\n1568             )\n1569             default_timezone = timezone.get_default_timezone()\n1570             value = timezone.make_aware(value, default_timezone)\n1571         return value\n1572 \n1573     def get_db_prep_value(self, value, connection, prepared=False):\n1574         # Casts datetimes into the format expected by the backend\n1575         if not prepared:\n1576             value = self.get_prep_value(value)\n1577         return connection.ops.adapt_datetimefield_value(value)\n1578 \n1579     def value_to_string(self, obj):\n1580         val = self.value_from_object(obj)\n1581         return \"\" if val is None else val.isoformat()\n1582 \n1583     def formfield(self, **kwargs):\n1584         return super().formfield(\n1585             **{\n1586                 \"form_class\": forms.DateTimeField,\n1587                 **kwargs,\n1588             }\n1589         )\n1590 \n1591 \n1592 class DecimalField(Field):\n1593     empty_strings_allowed = False\n1594     default_error_messages = {\n1595         \"invalid\": _(\"\u201c%(value)s\u201d value must be a decimal number.\"),\n1596     }\n1597     description = _(\"Decimal number\")\n1598 \n1599     def __init__(\n1600         self,\n1601         verbose_name=None,\n1602         name=None,\n1603         max_digits=None,\n1604         decimal_places=None,\n1605         **kwargs,\n1606     ):\n1607         self.max_digits, self.decimal_places = max_digits, decimal_places\n1608         super().__init__(verbose_name, name, **kwargs)\n1609 \n1610     def check(self, **kwargs):\n1611         errors = super().check(**kwargs)\n1612 \n1613         digits_errors = [\n1614             *self._check_decimal_places(),\n1615             *self._check_max_digits(),\n1616         ]\n1617         if not digits_errors:\n1618             errors.extend(self._check_decimal_places_and_max_digits(**kwargs))\n1619         else:\n1620             errors.extend(digits_errors)\n1621         return errors\n1622 \n1623     def _check_decimal_places(self):\n1624         try:\n1625             decimal_places = int(self.decimal_places)\n1626             if decimal_places < 0:\n1627                 raise ValueError()\n1628         except TypeError:\n1629             return [\n1630                 checks.Error(\n1631                     \"DecimalFields must define a 'decimal_places' attribute.\",\n1632                     obj=self,\n1633                     id=\"fields.E130\",\n1634                 )\n1635             ]\n1636         except ValueError:\n1637             return [\n1638                 checks.Error(\n1639                     \"'decimal_places' must be a non-negative integer.\",\n1640                     obj=self,\n1641                     id=\"fields.E131\",\n1642                 )\n1643             ]\n1644         else:\n1645             return []\n1646 \n1647     def _check_max_digits(self):\n1648         try:\n1649             max_digits = int(self.max_digits)\n1650             if max_digits <= 0:\n1651                 raise ValueError()\n1652         except TypeError:\n1653             return [\n1654                 checks.Error(\n1655                     \"DecimalFields must define a 'max_digits' attribute.\",\n1656                     obj=self,\n1657                     id=\"fields.E132\",\n1658                 )\n1659             ]\n1660         except ValueError:\n1661             return [\n1662                 checks.Error(\n1663                     \"'max_digits' must be a positive integer.\",\n1664                     obj=self,\n1665                     id=\"fields.E133\",\n1666                 )\n1667             ]\n1668         else:\n1669             return []\n1670 \n1671     def _check_decimal_places_and_max_digits(self, **kwargs):\n1672         if int(self.decimal_places) > int(self.max_digits):\n1673             return [\n1674                 checks.Error(\n1675                     \"'max_digits' must be greater or equal to 'decimal_places'.\",\n1676                     obj=self,\n1677                     id=\"fields.E134\",\n1678                 )\n1679             ]\n1680         return []\n1681 \n1682     @cached_property\n1683     def validators(self):\n1684         return super().validators + [\n1685             validators.DecimalValidator(self.max_digits, self.decimal_places)\n1686         ]\n1687 \n1688     @cached_property\n1689     def context(self):\n1690         return decimal.Context(prec=self.max_digits)\n1691 \n1692     def deconstruct(self):\n1693         name, path, args, kwargs = super().deconstruct()\n1694         if self.max_digits is not None:\n1695             kwargs[\"max_digits\"] = self.max_digits\n1696         if self.decimal_places is not None:\n1697             kwargs[\"decimal_places\"] = self.decimal_places\n1698         return name, path, args, kwargs\n1699 \n1700     def get_internal_type(self):\n1701         return \"DecimalField\"\n1702 \n1703     def to_python(self, value):\n1704         if value is None:\n1705             return value\n1706         if isinstance(value, float):\n1707             if math.isnan(value):\n1708                 raise exceptions.ValidationError(\n1709                     self.error_messages[\"invalid\"],\n1710                     code=\"invalid\",\n1711                     params={\"value\": value},\n1712                 )\n1713             return self.context.create_decimal_from_float(value)\n1714         try:\n1715             return decimal.Decimal(value)\n1716         except (decimal.InvalidOperation, TypeError, ValueError):\n1717             raise exceptions.ValidationError(\n1718                 self.error_messages[\"invalid\"],\n1719                 code=\"invalid\",\n1720                 params={\"value\": value},\n1721             )\n1722 \n1723     def get_db_prep_save(self, value, connection):\n1724         return connection.ops.adapt_decimalfield_value(\n1725             self.to_python(value), self.max_digits, self.decimal_places\n1726         )\n1727 \n1728     def get_prep_value(self, value):\n1729         value = super().get_prep_value(value)\n1730         return self.to_python(value)\n1731 \n1732     def formfield(self, **kwargs):\n1733         return super().formfield(\n1734             **{\n1735                 \"max_digits\": self.max_digits,\n1736                 \"decimal_places\": self.decimal_places,\n1737                 \"form_class\": forms.DecimalField,\n1738                 **kwargs,\n1739             }\n1740         )\n1741 \n1742 \n1743 class DurationField(Field):\n1744     \"\"\"\n1745     Store timedelta objects.\n1746 \n1747     Use interval on PostgreSQL, INTERVAL DAY TO SECOND on Oracle, and bigint\n1748     of microseconds on other databases.\n1749     \"\"\"\n1750 \n1751     empty_strings_allowed = False\n1752     default_error_messages = {\n1753         \"invalid\": _(\n1754             \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n1755             \"[DD] [[HH:]MM:]ss[.uuuuuu] format.\"\n1756         )\n1757     }\n1758     description = _(\"Duration\")\n1759 \n1760     def get_internal_type(self):\n1761         return \"DurationField\"\n1762 \n1763     def to_python(self, value):\n1764         if value is None:\n1765             return value\n1766         if isinstance(value, datetime.timedelta):\n1767             return value\n1768         try:\n1769             parsed = parse_duration(value)\n1770         except ValueError:\n1771             pass\n1772         else:\n1773             if parsed is not None:\n1774                 return parsed\n1775 \n1776         raise exceptions.ValidationError(\n1777             self.error_messages[\"invalid\"],\n1778             code=\"invalid\",\n1779             params={\"value\": value},\n1780         )\n1781 \n1782     def get_db_prep_value(self, value, connection, prepared=False):\n1783         if connection.features.has_native_duration_field:\n1784             return value\n1785         if value is None:\n1786             return None\n1787         return duration_microseconds(value)\n1788 \n1789     def get_db_converters(self, connection):\n1790         converters = []\n1791         if not connection.features.has_native_duration_field:\n1792             converters.append(connection.ops.convert_durationfield_value)\n1793         return converters + super().get_db_converters(connection)\n1794 \n1795     def value_to_string(self, obj):\n1796         val = self.value_from_object(obj)\n1797         return \"\" if val is None else duration_string(val)\n1798 \n1799     def formfield(self, **kwargs):\n1800         return super().formfield(\n1801             **{\n1802                 \"form_class\": forms.DurationField,\n1803                 **kwargs,\n1804             }\n1805         )\n1806 \n1807 \n1808 class EmailField(CharField):\n1809     default_validators = [validators.validate_email]\n1810     description = _(\"Email address\")\n1811 \n1812     def __init__(self, *args, **kwargs):\n1813         # max_length=254 to be compliant with RFCs 3696 and 5321\n1814         kwargs.setdefault(\"max_length\", 254)\n1815         super().__init__(*args, **kwargs)\n1816 \n1817     def deconstruct(self):\n1818         name, path, args, kwargs = super().deconstruct()\n1819         # We do not exclude max_length if it matches default as we want to change\n1820         # the default in future.\n1821         return name, path, args, kwargs\n1822 \n1823     def formfield(self, **kwargs):\n1824         # As with CharField, this will cause email validation to be performed\n1825         # twice.\n1826         return super().formfield(\n1827             **{\n1828                 \"form_class\": forms.EmailField,\n1829                 **kwargs,\n1830             }\n1831         )\n1832 \n1833 \n1834 class FilePathField(Field):\n1835     description = _(\"File path\")\n1836 \n1837     def __init__(\n1838         self,\n1839         verbose_name=None,\n1840         name=None,\n1841         path=\"\",\n1842         match=None,\n1843         recursive=False,\n1844         allow_files=True,\n1845         allow_folders=False,\n1846         **kwargs,\n1847     ):\n1848         self.path, self.match, self.recursive = path, match, recursive\n1849         self.allow_files, self.allow_folders = allow_files, allow_folders\n1850         kwargs.setdefault(\"max_length\", 100)\n1851         super().__init__(verbose_name, name, **kwargs)\n1852 \n1853     def check(self, **kwargs):\n1854         return [\n1855             *super().check(**kwargs),\n1856             *self._check_allowing_files_or_folders(**kwargs),\n1857         ]\n1858 \n1859     def _check_allowing_files_or_folders(self, **kwargs):\n1860         if not self.allow_files and not self.allow_folders:\n1861             return [\n1862                 checks.Error(\n1863                     \"FilePathFields must have either 'allow_files' or 'allow_folders' \"\n1864                     \"set to True.\",\n1865                     obj=self,\n1866                     id=\"fields.E140\",\n1867                 )\n1868             ]\n1869         return []\n1870 \n1871     def deconstruct(self):\n1872         name, path, args, kwargs = super().deconstruct()\n1873         if self.path != \"\":\n1874             kwargs[\"path\"] = self.path\n1875         if self.match is not None:\n1876             kwargs[\"match\"] = self.match\n1877         if self.recursive is not False:\n1878             kwargs[\"recursive\"] = self.recursive\n1879         if self.allow_files is not True:\n1880             kwargs[\"allow_files\"] = self.allow_files\n1881         if self.allow_folders is not False:\n1882             kwargs[\"allow_folders\"] = self.allow_folders\n1883         if kwargs.get(\"max_length\") == 100:\n1884             del kwargs[\"max_length\"]\n1885         return name, path, args, kwargs\n1886 \n1887     def get_prep_value(self, value):\n1888         value = super().get_prep_value(value)\n1889         if value is None:\n1890             return None\n1891         return str(value)\n1892 \n1893     def formfield(self, **kwargs):\n1894         return super().formfield(\n1895             **{\n1896                 \"path\": self.path() if callable(self.path) else self.path,\n1897                 \"match\": self.match,\n1898                 \"recursive\": self.recursive,\n1899                 \"form_class\": forms.FilePathField,\n1900                 \"allow_files\": self.allow_files,\n1901                 \"allow_folders\": self.allow_folders,\n1902                 **kwargs,\n1903             }\n1904         )\n1905 \n1906     def get_internal_type(self):\n1907         return \"FilePathField\"\n1908 \n1909 \n1910 class FloatField(Field):\n1911     empty_strings_allowed = False\n1912     default_error_messages = {\n1913         \"invalid\": _(\"\u201c%(value)s\u201d value must be a float.\"),\n1914     }\n1915     description = _(\"Floating point number\")\n1916 \n1917     def get_prep_value(self, value):\n1918         value = super().get_prep_value(value)\n1919         if value is None:\n1920             return None\n1921         try:\n1922             return float(value)\n1923         except (TypeError, ValueError) as e:\n1924             raise e.__class__(\n1925                 \"Field '%s' expected a number but got %r.\" % (self.name, value),\n1926             ) from e\n1927 \n1928     def get_internal_type(self):\n1929         return \"FloatField\"\n1930 \n1931     def to_python(self, value):\n1932         if value is None:\n1933             return value\n1934         try:\n1935             return float(value)\n1936         except (TypeError, ValueError):\n1937             raise exceptions.ValidationError(\n1938                 self.error_messages[\"invalid\"],\n1939                 code=\"invalid\",\n1940                 params={\"value\": value},\n1941             )\n1942 \n1943     def formfield(self, **kwargs):\n1944         return super().formfield(\n1945             **{\n1946                 \"form_class\": forms.FloatField,\n1947                 **kwargs,\n1948             }\n1949         )\n1950 \n1951 \n1952 class IntegerField(Field):\n1953     empty_strings_allowed = False\n1954     default_error_messages = {\n1955         \"invalid\": _(\"\u201c%(value)s\u201d value must be an integer.\"),\n1956     }\n1957     description = _(\"Integer\")\n1958 \n1959     def check(self, **kwargs):\n1960         return [\n1961             *super().check(**kwargs),\n1962             *self._check_max_length_warning(),\n1963         ]\n1964 \n1965     def _check_max_length_warning(self):\n1966         if self.max_length is not None:\n1967             return [\n1968                 checks.Warning(\n1969                     \"'max_length' is ignored when used with %s.\"\n1970                     % self.__class__.__name__,\n1971                     hint=\"Remove 'max_length' from field\",\n1972                     obj=self,\n1973                     id=\"fields.W122\",\n1974                 )\n1975             ]\n1976         return []\n1977 \n1978     @cached_property\n1979     def validators(self):\n1980         # These validators can't be added at field initialization time since\n1981         # they're based on values retrieved from `connection`.\n1982         validators_ = super().validators\n1983         internal_type = self.get_internal_type()\n1984         min_value, max_value = connection.ops.integer_field_range(internal_type)\n1985         if min_value is not None and not any(\n1986             (\n1987                 isinstance(validator, validators.MinValueValidator)\n1988                 and (\n1989                     validator.limit_value()\n1990                     if callable(validator.limit_value)\n1991                     else validator.limit_value\n1992                 )\n1993                 >= min_value\n1994             )\n1995             for validator in validators_\n1996         ):\n1997             validators_.append(validators.MinValueValidator(min_value))\n1998         if max_value is not None and not any(\n1999             (\n2000                 isinstance(validator, validators.MaxValueValidator)\n2001                 and (\n2002                     validator.limit_value()\n2003                     if callable(validator.limit_value)\n2004                     else validator.limit_value\n2005                 )\n2006                 <= max_value\n2007             )\n2008             for validator in validators_\n2009         ):\n2010             validators_.append(validators.MaxValueValidator(max_value))\n2011         return validators_\n2012 \n2013     def get_prep_value(self, value):\n2014         value = super().get_prep_value(value)\n2015         if value is None:\n2016             return None\n2017         try:\n2018             return int(value)\n2019         except (TypeError, ValueError) as e:\n2020             raise e.__class__(\n2021                 \"Field '%s' expected a number but got %r.\" % (self.name, value),\n2022             ) from e\n2023 \n2024     def get_internal_type(self):\n2025         return \"IntegerField\"\n2026 \n2027     def to_python(self, value):\n2028         if value is None:\n2029             return value\n2030         try:\n2031             return int(value)\n2032         except (TypeError, ValueError):\n2033             raise exceptions.ValidationError(\n2034                 self.error_messages[\"invalid\"],\n2035                 code=\"invalid\",\n2036                 params={\"value\": value},\n2037             )\n2038 \n2039     def formfield(self, **kwargs):\n2040         return super().formfield(\n2041             **{\n2042                 \"form_class\": forms.IntegerField,\n2043                 **kwargs,\n2044             }\n2045         )\n2046 \n2047 \n2048 class BigIntegerField(IntegerField):\n2049     description = _(\"Big (8 byte) integer\")\n2050     MAX_BIGINT = 9223372036854775807\n2051 \n2052     def get_internal_type(self):\n2053         return \"BigIntegerField\"\n2054 \n2055     def formfield(self, **kwargs):\n2056         return super().formfield(\n2057             **{\n2058                 \"min_value\": -BigIntegerField.MAX_BIGINT - 1,\n2059                 \"max_value\": BigIntegerField.MAX_BIGINT,\n2060                 **kwargs,\n2061             }\n2062         )\n2063 \n2064 \n2065 class SmallIntegerField(IntegerField):\n2066     description = _(\"Small integer\")\n2067 \n2068     def get_internal_type(self):\n2069         return \"SmallIntegerField\"\n2070 \n2071 \n2072 class IPAddressField(Field):\n2073     empty_strings_allowed = False\n2074     description = _(\"IPv4 address\")\n2075     system_check_removed_details = {\n2076         \"msg\": (\n2077             \"IPAddressField has been removed except for support in \"\n2078             \"historical migrations.\"\n2079         ),\n2080         \"hint\": \"Use GenericIPAddressField instead.\",\n2081         \"id\": \"fields.E900\",\n2082     }\n2083 \n2084     def __init__(self, *args, **kwargs):\n2085         kwargs[\"max_length\"] = 15\n2086         super().__init__(*args, **kwargs)\n2087 \n2088     def deconstruct(self):\n2089         name, path, args, kwargs = super().deconstruct()\n2090         del kwargs[\"max_length\"]\n2091         return name, path, args, kwargs\n2092 \n2093     def get_prep_value(self, value):\n2094         value = super().get_prep_value(value)\n2095         if value is None:\n2096             return None\n2097         return str(value)\n2098 \n2099     def get_internal_type(self):\n2100         return \"IPAddressField\"\n2101 \n2102 \n2103 class GenericIPAddressField(Field):\n2104     empty_strings_allowed = False\n2105     description = _(\"IP address\")\n2106     default_error_messages = {}\n2107 \n2108     def __init__(\n2109         self,\n2110         verbose_name=None,\n2111         name=None,\n2112         protocol=\"both\",\n2113         unpack_ipv4=False,\n2114         *args,\n2115         **kwargs,\n2116     ):\n2117         self.unpack_ipv4 = unpack_ipv4\n2118         self.protocol = protocol\n2119         (\n2120             self.default_validators,\n2121             invalid_error_message,\n2122         ) = validators.ip_address_validators(protocol, unpack_ipv4)\n2123         self.default_error_messages[\"invalid\"] = invalid_error_message\n2124         kwargs[\"max_length\"] = 39\n2125         super().__init__(verbose_name, name, *args, **kwargs)\n2126 \n2127     def check(self, **kwargs):\n2128         return [\n2129             *super().check(**kwargs),\n2130             *self._check_blank_and_null_values(**kwargs),\n2131         ]\n2132 \n2133     def _check_blank_and_null_values(self, **kwargs):\n2134         if not getattr(self, \"null\", False) and getattr(self, \"blank\", False):\n2135             return [\n2136                 checks.Error(\n2137                     \"GenericIPAddressFields cannot have blank=True if null=False, \"\n2138                     \"as blank values are stored as nulls.\",\n2139                     obj=self,\n2140                     id=\"fields.E150\",\n2141                 )\n2142             ]\n2143         return []\n2144 \n2145     def deconstruct(self):\n2146         name, path, args, kwargs = super().deconstruct()\n2147         if self.unpack_ipv4 is not False:\n2148             kwargs[\"unpack_ipv4\"] = self.unpack_ipv4\n2149         if self.protocol != \"both\":\n2150             kwargs[\"protocol\"] = self.protocol\n2151         if kwargs.get(\"max_length\") == 39:\n2152             del kwargs[\"max_length\"]\n2153         return name, path, args, kwargs\n2154 \n2155     def get_internal_type(self):\n2156         return \"GenericIPAddressField\"\n2157 \n2158     def to_python(self, value):\n2159         if value is None:\n2160             return None\n2161         if not isinstance(value, str):\n2162             value = str(value)\n2163         value = value.strip()\n2164         if \":\" in value:\n2165             return clean_ipv6_address(\n2166                 value, self.unpack_ipv4, self.error_messages[\"invalid\"]\n2167             )\n2168         return value\n2169 \n2170     def get_db_prep_value(self, value, connection, prepared=False):\n2171         if not prepared:\n2172             value = self.get_prep_value(value)\n2173         return connection.ops.adapt_ipaddressfield_value(value)\n2174 \n2175     def get_prep_value(self, value):\n2176         value = super().get_prep_value(value)\n2177         if value is None:\n2178             return None\n2179         if value and \":\" in value:\n2180             try:\n2181                 return clean_ipv6_address(value, self.unpack_ipv4)\n2182             except exceptions.ValidationError:\n2183                 pass\n2184         return str(value)\n2185 \n2186     def formfield(self, **kwargs):\n2187         return super().formfield(\n2188             **{\n2189                 \"protocol\": self.protocol,\n2190                 \"form_class\": forms.GenericIPAddressField,\n2191                 **kwargs,\n2192             }\n2193         )\n2194 \n2195 \n2196 class NullBooleanField(BooleanField):\n2197     default_error_messages = {\n2198         \"invalid\": _(\"\u201c%(value)s\u201d value must be either None, True or False.\"),\n2199         \"invalid_nullable\": _(\"\u201c%(value)s\u201d value must be either None, True or False.\"),\n2200     }\n2201     description = _(\"Boolean (Either True, False or None)\")\n2202     system_check_removed_details = {\n2203         \"msg\": (\n2204             \"NullBooleanField is removed except for support in historical \"\n2205             \"migrations.\"\n2206         ),\n2207         \"hint\": \"Use BooleanField(null=True) instead.\",\n2208         \"id\": \"fields.E903\",\n2209     }\n2210 \n2211     def __init__(self, *args, **kwargs):\n2212         kwargs[\"null\"] = True\n2213         kwargs[\"blank\"] = True\n2214         super().__init__(*args, **kwargs)\n2215 \n2216     def deconstruct(self):\n2217         name, path, args, kwargs = super().deconstruct()\n2218         del kwargs[\"null\"]\n2219         del kwargs[\"blank\"]\n2220         return name, path, args, kwargs\n2221 \n2222 \n2223 class PositiveIntegerRelDbTypeMixin:\n2224     def __init_subclass__(cls, **kwargs):\n2225         super().__init_subclass__(**kwargs)\n2226         if not hasattr(cls, \"integer_field_class\"):\n2227             cls.integer_field_class = next(\n2228                 (\n2229                     parent\n2230                     for parent in cls.__mro__[1:]\n2231                     if issubclass(parent, IntegerField)\n2232                 ),\n2233                 None,\n2234             )\n2235 \n2236     def rel_db_type(self, connection):\n2237         \"\"\"\n2238         Return the data type that a related field pointing to this field should\n2239         use. In most cases, a foreign key pointing to a positive integer\n2240         primary key will have an integer column data type but some databases\n2241         (e.g. MySQL) have an unsigned integer type. In that case\n2242         (related_fields_match_type=True), the primary key should return its\n2243         db_type.\n2244         \"\"\"\n2245         if connection.features.related_fields_match_type:\n2246             return self.db_type(connection)\n2247         else:\n2248             return self.integer_field_class().db_type(connection=connection)\n2249 \n2250 \n2251 class PositiveBigIntegerField(PositiveIntegerRelDbTypeMixin, BigIntegerField):\n2252     description = _(\"Positive big integer\")\n2253 \n2254     def get_internal_type(self):\n2255         return \"PositiveBigIntegerField\"\n2256 \n2257     def formfield(self, **kwargs):\n2258         return super().formfield(\n2259             **{\n2260                 \"min_value\": 0,\n2261                 **kwargs,\n2262             }\n2263         )\n2264 \n2265 \n2266 class PositiveIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):\n2267     description = _(\"Positive integer\")\n2268 \n2269     def get_internal_type(self):\n2270         return \"PositiveIntegerField\"\n2271 \n2272     def formfield(self, **kwargs):\n2273         return super().formfield(\n2274             **{\n2275                 \"min_value\": 0,\n2276                 **kwargs,\n2277             }\n2278         )\n2279 \n2280 \n2281 class PositiveSmallIntegerField(PositiveIntegerRelDbTypeMixin, SmallIntegerField):\n2282     description = _(\"Positive small integer\")\n2283 \n2284     def get_internal_type(self):\n2285         return \"PositiveSmallIntegerField\"\n2286 \n2287     def formfield(self, **kwargs):\n2288         return super().formfield(\n2289             **{\n2290                 \"min_value\": 0,\n2291                 **kwargs,\n2292             }\n2293         )\n2294 \n2295 \n2296 class SlugField(CharField):\n2297     default_validators = [validators.validate_slug]\n2298     description = _(\"Slug (up to %(max_length)s)\")\n2299 \n2300     def __init__(\n2301         self, *args, max_length=50, db_index=True, allow_unicode=False, **kwargs\n2302     ):\n2303         self.allow_unicode = allow_unicode\n2304         if self.allow_unicode:\n2305             self.default_validators = [validators.validate_unicode_slug]\n2306         super().__init__(*args, max_length=max_length, db_index=db_index, **kwargs)\n2307 \n2308     def deconstruct(self):\n2309         name, path, args, kwargs = super().deconstruct()\n2310         if kwargs.get(\"max_length\") == 50:\n2311             del kwargs[\"max_length\"]\n2312         if self.db_index is False:\n2313             kwargs[\"db_index\"] = False\n2314         else:\n2315             del kwargs[\"db_index\"]\n2316         if self.allow_unicode is not False:\n2317             kwargs[\"allow_unicode\"] = self.allow_unicode\n2318         return name, path, args, kwargs\n2319 \n2320     def get_internal_type(self):\n2321         return \"SlugField\"\n2322 \n2323     def formfield(self, **kwargs):\n2324         return super().formfield(\n2325             **{\n2326                 \"form_class\": forms.SlugField,\n2327                 \"allow_unicode\": self.allow_unicode,\n2328                 **kwargs,\n2329             }\n2330         )\n2331 \n2332 \n2333 class TextField(Field):\n2334     description = _(\"Text\")\n2335 \n2336     def __init__(self, *args, db_collation=None, **kwargs):\n2337         super().__init__(*args, **kwargs)\n2338         self.db_collation = db_collation\n2339 \n2340     def check(self, **kwargs):\n2341         databases = kwargs.get(\"databases\") or []\n2342         return [\n2343             *super().check(**kwargs),\n2344             *self._check_db_collation(databases),\n2345         ]\n2346 \n2347     def _check_db_collation(self, databases):\n2348         errors = []\n2349         for db in databases:\n2350             if not router.allow_migrate_model(db, self.model):\n2351                 continue\n2352             connection = connections[db]\n2353             if not (\n2354                 self.db_collation is None\n2355                 or \"supports_collation_on_textfield\"\n2356                 in self.model._meta.required_db_features\n2357                 or connection.features.supports_collation_on_textfield\n2358             ):\n2359                 errors.append(\n2360                     checks.Error(\n2361                         \"%s does not support a database collation on \"\n2362                         \"TextFields.\" % connection.display_name,\n2363                         obj=self,\n2364                         id=\"fields.E190\",\n2365                     ),\n2366                 )\n2367         return errors\n2368 \n2369     def db_parameters(self, connection):\n2370         db_params = super().db_parameters(connection)\n2371         db_params[\"collation\"] = self.db_collation\n2372         return db_params\n2373 \n2374     def get_internal_type(self):\n2375         return \"TextField\"\n2376 \n2377     def to_python(self, value):\n2378         if isinstance(value, str) or value is None:\n2379             return value\n2380         return str(value)\n2381 \n2382     def get_prep_value(self, value):\n2383         value = super().get_prep_value(value)\n2384         return self.to_python(value)\n2385 \n2386     def formfield(self, **kwargs):\n2387         # Passing max_length to forms.CharField means that the value's length\n2388         # will be validated twice. This is considered acceptable since we want\n2389         # the value in the form field (to pass into widget for example).\n2390         return super().formfield(\n2391             **{\n2392                 \"max_length\": self.max_length,\n2393                 **({} if self.choices is not None else {\"widget\": forms.Textarea}),\n2394                 **kwargs,\n2395             }\n2396         )\n2397 \n2398     def deconstruct(self):\n2399         name, path, args, kwargs = super().deconstruct()\n2400         if self.db_collation:\n2401             kwargs[\"db_collation\"] = self.db_collation\n2402         return name, path, args, kwargs\n2403 \n2404 \n2405 class TimeField(DateTimeCheckMixin, Field):\n2406     empty_strings_allowed = False\n2407     default_error_messages = {\n2408         \"invalid\": _(\n2409             \"\u201c%(value)s\u201d value has an invalid format. It must be in \"\n2410             \"HH:MM[:ss[.uuuuuu]] format.\"\n2411         ),\n2412         \"invalid_time\": _(\n2413             \"\u201c%(value)s\u201d value has the correct format \"\n2414             \"(HH:MM[:ss[.uuuuuu]]) but it is an invalid time.\"\n2415         ),\n2416     }\n2417     description = _(\"Time\")\n2418 \n2419     def __init__(\n2420         self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs\n2421     ):\n2422         self.auto_now, self.auto_now_add = auto_now, auto_now_add\n2423         if auto_now or auto_now_add:\n2424             kwargs[\"editable\"] = False\n2425             kwargs[\"blank\"] = True\n2426         super().__init__(verbose_name, name, **kwargs)\n2427 \n2428     def _check_fix_default_value(self):\n2429         \"\"\"\n2430         Warn that using an actual date or datetime value is probably wrong;\n2431         it's only evaluated on server startup.\n2432         \"\"\"\n2433         if not self.has_default():\n2434             return []\n2435 \n2436         value = self.default\n2437         if isinstance(value, datetime.datetime):\n2438             now = None\n2439         elif isinstance(value, datetime.time):\n2440             now = _get_naive_now()\n2441             # This will not use the right date in the race condition where now\n2442             # is just before the date change and value is just past 0:00.\n2443             value = datetime.datetime.combine(now.date(), value)\n2444         else:\n2445             # No explicit time / datetime value -- no checks necessary\n2446             return []\n2447         # At this point, value is a datetime object.\n2448         return self._check_if_value_fixed(value, now=now)\n2449 \n2450     def deconstruct(self):\n2451         name, path, args, kwargs = super().deconstruct()\n2452         if self.auto_now is not False:\n2453             kwargs[\"auto_now\"] = self.auto_now\n2454         if self.auto_now_add is not False:\n2455             kwargs[\"auto_now_add\"] = self.auto_now_add\n2456         if self.auto_now or self.auto_now_add:\n2457             del kwargs[\"blank\"]\n2458             del kwargs[\"editable\"]\n2459         return name, path, args, kwargs\n2460 \n2461     def get_internal_type(self):\n2462         return \"TimeField\"\n2463 \n2464     def to_python(self, value):\n2465         if value is None:\n2466             return None\n2467         if isinstance(value, datetime.time):\n2468             return value\n2469         if isinstance(value, datetime.datetime):\n2470             # Not usually a good idea to pass in a datetime here (it loses\n2471             # information), but this can be a side-effect of interacting with a\n2472             # database backend (e.g. Oracle), so we'll be accommodating.\n2473             return value.time()\n2474 \n2475         try:\n2476             parsed = parse_time(value)\n2477             if parsed is not None:\n2478                 return parsed\n2479         except ValueError:\n2480             raise exceptions.ValidationError(\n2481                 self.error_messages[\"invalid_time\"],\n2482                 code=\"invalid_time\",\n2483                 params={\"value\": value},\n2484             )\n2485 \n2486         raise exceptions.ValidationError(\n2487             self.error_messages[\"invalid\"],\n2488             code=\"invalid\",\n2489             params={\"value\": value},\n2490         )\n2491 \n2492     def pre_save(self, model_instance, add):\n2493         if self.auto_now or (self.auto_now_add and add):\n2494             value = datetime.datetime.now().time()\n2495             setattr(model_instance, self.attname, value)\n2496             return value\n2497         else:\n2498             return super().pre_save(model_instance, add)\n2499 \n2500     def get_prep_value(self, value):\n2501         value = super().get_prep_value(value)\n2502         return self.to_python(value)\n2503 \n2504     def get_db_prep_value(self, value, connection, prepared=False):\n2505         # Casts times into the format expected by the backend\n2506         if not prepared:\n2507             value = self.get_prep_value(value)\n2508         return connection.ops.adapt_timefield_value(value)\n2509 \n2510     def value_to_string(self, obj):\n2511         val = self.value_from_object(obj)\n2512         return \"\" if val is None else val.isoformat()\n2513 \n2514     def formfield(self, **kwargs):\n2515         return super().formfield(\n2516             **{\n2517                 \"form_class\": forms.TimeField,\n2518                 **kwargs,\n2519             }\n2520         )\n2521 \n2522 \n2523 class URLField(CharField):\n2524     default_validators = [validators.URLValidator()]\n2525     description = _(\"URL\")\n2526 \n2527     def __init__(self, verbose_name=None, name=None, **kwargs):\n2528         kwargs.setdefault(\"max_length\", 200)\n2529         super().__init__(verbose_name, name, **kwargs)\n2530 \n2531     def deconstruct(self):\n2532         name, path, args, kwargs = super().deconstruct()\n2533         if kwargs.get(\"max_length\") == 200:\n2534             del kwargs[\"max_length\"]\n2535         return name, path, args, kwargs\n2536 \n2537     def formfield(self, **kwargs):\n2538         # As with CharField, this will cause URL validation to be performed\n2539         # twice.\n2540         return super().formfield(\n2541             **{\n2542                 \"form_class\": forms.URLField,\n2543                 **kwargs,\n2544             }\n2545         )\n2546 \n2547 \n2548 class BinaryField(Field):\n2549     description = _(\"Raw binary data\")\n2550     empty_values = [None, b\"\"]\n2551 \n2552     def __init__(self, *args, **kwargs):\n2553         kwargs.setdefault(\"editable\", False)\n2554         super().__init__(*args, **kwargs)\n2555         if self.max_length is not None:\n2556             self.validators.append(validators.MaxLengthValidator(self.max_length))\n2557 \n2558     def check(self, **kwargs):\n2559         return [*super().check(**kwargs), *self._check_str_default_value()]\n2560 \n2561     def _check_str_default_value(self):\n2562         if self.has_default() and isinstance(self.default, str):\n2563             return [\n2564                 checks.Error(\n2565                     \"BinaryField's default cannot be a string. Use bytes \"\n2566                     \"content instead.\",\n2567                     obj=self,\n2568                     id=\"fields.E170\",\n2569                 )\n2570             ]\n2571         return []\n2572 \n2573     def deconstruct(self):\n2574         name, path, args, kwargs = super().deconstruct()\n2575         if self.editable:\n2576             kwargs[\"editable\"] = True\n2577         else:\n2578             del kwargs[\"editable\"]\n2579         return name, path, args, kwargs\n2580 \n2581     def get_internal_type(self):\n2582         return \"BinaryField\"\n2583 \n2584     def get_placeholder(self, value, compiler, connection):\n2585         return connection.ops.binary_placeholder_sql(value)\n2586 \n2587     def get_default(self):\n2588         if self.has_default() and not callable(self.default):\n2589             return self.default\n2590         default = super().get_default()\n2591         if default == \"\":\n2592             return b\"\"\n2593         return default\n2594 \n2595     def get_db_prep_value(self, value, connection, prepared=False):\n2596         value = super().get_db_prep_value(value, connection, prepared)\n2597         if value is not None:\n2598             return connection.Database.Binary(value)\n2599         return value\n2600 \n2601     def value_to_string(self, obj):\n2602         \"\"\"Binary data is serialized as base64\"\"\"\n2603         return b64encode(self.value_from_object(obj)).decode(\"ascii\")\n2604 \n2605     def to_python(self, value):\n2606         # If it's a string, it should be base64-encoded data\n2607         if isinstance(value, str):\n2608             return memoryview(b64decode(value.encode(\"ascii\")))\n2609         return value\n2610 \n2611 \n2612 class UUIDField(Field):\n2613     default_error_messages = {\n2614         \"invalid\": _(\"\u201c%(value)s\u201d is not a valid UUID.\"),\n2615     }\n2616     description = _(\"Universally unique identifier\")\n2617     empty_strings_allowed = False\n2618 \n2619     def __init__(self, verbose_name=None, **kwargs):\n2620         kwargs[\"max_length\"] = 32\n2621         super().__init__(verbose_name, **kwargs)\n2622 \n2623     def deconstruct(self):\n2624         name, path, args, kwargs = super().deconstruct()\n2625         del kwargs[\"max_length\"]\n2626         return name, path, args, kwargs\n2627 \n2628     def get_internal_type(self):\n2629         return \"UUIDField\"\n2630 \n2631     def get_prep_value(self, value):\n2632         value = super().get_prep_value(value)\n2633         return self.to_python(value)\n2634 \n2635     def get_db_prep_value(self, value, connection, prepared=False):\n2636         if value is None:\n2637             return None\n2638         if not isinstance(value, uuid.UUID):\n2639             value = self.to_python(value)\n2640 \n2641         if connection.features.has_native_uuid_field:\n2642             return value\n2643         return value.hex\n2644 \n2645     def to_python(self, value):\n2646         if value is not None and not isinstance(value, uuid.UUID):\n2647             input_form = \"int\" if isinstance(value, int) else \"hex\"\n2648             try:\n2649                 return uuid.UUID(**{input_form: value})\n2650             except (AttributeError, ValueError):\n2651                 raise exceptions.ValidationError(\n2652                     self.error_messages[\"invalid\"],\n2653                     code=\"invalid\",\n2654                     params={\"value\": value},\n2655                 )\n2656         return value\n2657 \n2658     def formfield(self, **kwargs):\n2659         return super().formfield(\n2660             **{\n2661                 \"form_class\": forms.UUIDField,\n2662                 **kwargs,\n2663             }\n2664         )\n2665 \n2666 \n2667 class AutoFieldMixin:\n2668     db_returning = True\n2669 \n2670     def __init__(self, *args, **kwargs):\n2671         kwargs[\"blank\"] = True\n2672         super().__init__(*args, **kwargs)\n2673 \n2674     def check(self, **kwargs):\n2675         return [\n2676             *super().check(**kwargs),\n2677             *self._check_primary_key(),\n2678         ]\n2679 \n2680     def _check_primary_key(self):\n2681         if not self.primary_key:\n2682             return [\n2683                 checks.Error(\n2684                     \"AutoFields must set primary_key=True.\",\n2685                     obj=self,\n2686                     id=\"fields.E100\",\n2687                 ),\n2688             ]\n2689         else:\n2690             return []\n2691 \n2692     def deconstruct(self):\n2693         name, path, args, kwargs = super().deconstruct()\n2694         del kwargs[\"blank\"]\n2695         kwargs[\"primary_key\"] = True\n2696         return name, path, args, kwargs\n2697 \n2698     def validate(self, value, model_instance):\n2699         pass\n2700 \n2701     def get_db_prep_value(self, value, connection, prepared=False):\n2702         if not prepared:\n2703             value = self.get_prep_value(value)\n2704             value = connection.ops.validate_autopk_value(value)\n2705         return value\n2706 \n2707     def contribute_to_class(self, cls, name, **kwargs):\n2708         if cls._meta.auto_field:\n2709             raise ValueError(\n2710                 \"Model %s can't have more than one auto-generated field.\"\n2711                 % cls._meta.label\n2712             )\n2713         super().contribute_to_class(cls, name, **kwargs)\n2714         cls._meta.auto_field = self\n2715 \n2716     def formfield(self, **kwargs):\n2717         return None\n2718 \n2719 \n2720 class AutoFieldMeta(type):\n2721     \"\"\"\n2722     Metaclass to maintain backward inheritance compatibility for AutoField.\n2723 \n2724     It is intended that AutoFieldMixin become public API when it is possible to\n2725     create a non-integer automatically-generated field using column defaults\n2726     stored in the database.\n2727 \n2728     In many areas Django also relies on using isinstance() to check for an\n2729     automatically-generated field as a subclass of AutoField. A new flag needs\n2730     to be implemented on Field to be used instead.\n2731 \n2732     When these issues have been addressed, this metaclass could be used to\n2733     deprecate inheritance from AutoField and use of isinstance() with AutoField\n2734     for detecting automatically-generated fields.\n2735     \"\"\"\n2736 \n2737     @property\n2738     def _subclasses(self):\n2739         return (BigAutoField, SmallAutoField)\n2740 \n2741     def __instancecheck__(self, instance):\n2742         return isinstance(instance, self._subclasses) or super().__instancecheck__(\n2743             instance\n2744         )\n2745 \n2746     def __subclasscheck__(self, subclass):\n2747         return issubclass(subclass, self._subclasses) or super().__subclasscheck__(\n2748             subclass\n2749         )\n2750 \n2751 \n2752 class AutoField(AutoFieldMixin, IntegerField, metaclass=AutoFieldMeta):\n2753     def get_internal_type(self):\n2754         return \"AutoField\"\n2755 \n2756     def rel_db_type(self, connection):\n2757         return IntegerField().db_type(connection=connection)\n2758 \n2759 \n2760 class BigAutoField(AutoFieldMixin, BigIntegerField):\n2761     def get_internal_type(self):\n2762         return \"BigAutoField\"\n2763 \n2764     def rel_db_type(self, connection):\n2765         return BigIntegerField().db_type(connection=connection)\n2766 \n2767 \n2768 class SmallAutoField(AutoFieldMixin, SmallIntegerField):\n2769     def get_internal_type(self):\n2770         return \"SmallAutoField\"\n2771 \n2772     def rel_db_type(self, connection):\n2773         return SmallIntegerField().db_type(connection=connection)\n",
        "intended_behavior": "Ensure consistent handling and documentation around `db_collation` attribute, so it is clear how it should be propagated in the context of model relationships and migrations."
    }
]