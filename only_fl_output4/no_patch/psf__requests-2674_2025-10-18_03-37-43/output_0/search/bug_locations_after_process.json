[
    {
        "rel_file_path": "requests/adapters.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/psf__requests/setup_psf__requests__2.7/requests/adapters.py",
        "start": 1,
        "end": 435,
        "class_name": null,
        "method_name": null,
        "code": "1 # -*- coding: utf-8 -*-\n2 \n3 \"\"\"\n4 requests.adapters\n5 ~~~~~~~~~~~~~~~~~\n6 \n7 This module contains the transport adapters that Requests uses to define\n8 and maintain connections.\n9 \"\"\"\n10 \n11 import socket\n12 \n13 from .models import Response\n14 from .packages.urllib3.poolmanager import PoolManager, proxy_from_url\n15 from .packages.urllib3.response import HTTPResponse\n16 from .packages.urllib3.util import Timeout as TimeoutSauce\n17 from .packages.urllib3.util.retry import Retry\n18 from .compat import urlparse, basestring\n19 from .utils import (DEFAULT_CA_BUNDLE_PATH, get_encoding_from_headers,\n20                     prepend_scheme_if_needed, get_auth_from_url, urldefragauth)\n21 from .structures import CaseInsensitiveDict\n22 from .packages.urllib3.exceptions import ConnectTimeoutError\n23 from .packages.urllib3.exceptions import HTTPError as _HTTPError\n24 from .packages.urllib3.exceptions import MaxRetryError\n25 from .packages.urllib3.exceptions import ProxyError as _ProxyError\n26 from .packages.urllib3.exceptions import ProtocolError\n27 from .packages.urllib3.exceptions import ReadTimeoutError\n28 from .packages.urllib3.exceptions import SSLError as _SSLError\n29 from .packages.urllib3.exceptions import ResponseError\n30 from .cookies import extract_cookies_to_jar\n31 from .exceptions import (ConnectionError, ConnectTimeout, ReadTimeout, SSLError,\n32                          ProxyError, RetryError)\n33 from .auth import _basic_auth_str\n34 \n35 DEFAULT_POOLBLOCK = False\n36 DEFAULT_POOLSIZE = 10\n37 DEFAULT_RETRIES = 0\n38 DEFAULT_POOL_TIMEOUT = None\n39 \n40 \n41 class BaseAdapter(object):\n42     \"\"\"The Base Transport Adapter\"\"\"\n43 \n44     def __init__(self):\n45         super(BaseAdapter, self).__init__()\n46 \n47     def send(self):\n48         raise NotImplementedError\n49 \n50     def close(self):\n51         raise NotImplementedError\n52 \n53 \n54 class HTTPAdapter(BaseAdapter):\n55     \"\"\"The built-in HTTP Adapter for urllib3.\n56 \n57     Provides a general-case interface for Requests sessions to contact HTTP and\n58     HTTPS urls by implementing the Transport Adapter interface. This class will\n59     usually be created by the :class:`Session <Session>` class under the\n60     covers.\n61 \n62     :param pool_connections: The number of urllib3 connection pools to cache.\n63     :param pool_maxsize: The maximum number of connections to save in the pool.\n64     :param int max_retries: The maximum number of retries each connection\n65         should attempt. Note, this applies only to failed DNS lookups, socket\n66         connections and connection timeouts, never to requests where data has\n67         made it to the server. By default, Requests does not retry failed\n68         connections. If you need granular control over the conditions under\n69         which we retry a request, import urllib3's ``Retry`` class and pass\n70         that instead.\n71     :param pool_block: Whether the connection pool should block for connections.\n72 \n73     Usage::\n74 \n75       >>> import requests\n76       >>> s = requests.Session()\n77       >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n78       >>> s.mount('http://', a)\n79     \"\"\"\n80     __attrs__ = ['max_retries', 'config', '_pool_connections', '_pool_maxsize',\n81                  '_pool_block']\n82 \n83     def __init__(self, pool_connections=DEFAULT_POOLSIZE,\n84                  pool_maxsize=DEFAULT_POOLSIZE, max_retries=DEFAULT_RETRIES,\n85                  pool_block=DEFAULT_POOLBLOCK):\n86         if max_retries == DEFAULT_RETRIES:\n87             self.max_retries = Retry(0, read=False)\n88         else:\n89             self.max_retries = Retry.from_int(max_retries)\n90         self.config = {}\n91         self.proxy_manager = {}\n92 \n93         super(HTTPAdapter, self).__init__()\n94 \n95         self._pool_connections = pool_connections\n96         self._pool_maxsize = pool_maxsize\n97         self._pool_block = pool_block\n98 \n99         self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n100 \n101     def __getstate__(self):\n102         return dict((attr, getattr(self, attr, None)) for attr in\n103                     self.__attrs__)\n104 \n105     def __setstate__(self, state):\n106         # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n107         # because self.poolmanager uses a lambda function, which isn't pickleable.\n108         self.proxy_manager = {}\n109         self.config = {}\n110 \n111         for attr, value in state.items():\n112             setattr(self, attr, value)\n113 \n114         self.init_poolmanager(self._pool_connections, self._pool_maxsize,\n115                               block=self._pool_block)\n116 \n117     def init_poolmanager(self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs):\n118         \"\"\"Initializes a urllib3 PoolManager.\n119 \n120         This method should not be called from user code, and is only\n121         exposed for use when subclassing the\n122         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n123 \n124         :param connections: The number of urllib3 connection pools to cache.\n125         :param maxsize: The maximum number of connections to save in the pool.\n126         :param block: Block when no free connections are available.\n127         :param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.\n128         \"\"\"\n129         # save these values for pickling\n130         self._pool_connections = connections\n131         self._pool_maxsize = maxsize\n132         self._pool_block = block\n133 \n134         self.poolmanager = PoolManager(num_pools=connections, maxsize=maxsize,\n135                                        block=block, strict=True, **pool_kwargs)\n136 \n137     def proxy_manager_for(self, proxy, **proxy_kwargs):\n138         \"\"\"Return urllib3 ProxyManager for the given proxy.\n139 \n140         This method should not be called from user code, and is only\n141         exposed for use when subclassing the\n142         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n143 \n144         :param proxy: The proxy to return a urllib3 ProxyManager for.\n145         :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.\n146         :returns: ProxyManager\n147         \"\"\"\n148         if not proxy in self.proxy_manager:\n149             proxy_headers = self.proxy_headers(proxy)\n150             self.proxy_manager[proxy] = proxy_from_url(\n151                 proxy,\n152                 proxy_headers=proxy_headers,\n153                 num_pools=self._pool_connections,\n154                 maxsize=self._pool_maxsize,\n155                 block=self._pool_block,\n156                 **proxy_kwargs)\n157 \n158         return self.proxy_manager[proxy]\n159 \n160     def cert_verify(self, conn, url, verify, cert):\n161         \"\"\"Verify a SSL certificate. This method should not be called from user\n162         code, and is only exposed for use when subclassing the\n163         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n164 \n165         :param conn: The urllib3 connection object associated with the cert.\n166         :param url: The requested URL.\n167         :param verify: Whether we should actually verify the certificate.\n168         :param cert: The SSL certificate to verify.\n169         \"\"\"\n170         if url.lower().startswith('https') and verify:\n171 \n172             cert_loc = None\n173 \n174             # Allow self-specified cert location.\n175             if verify is not True:\n176                 cert_loc = verify\n177 \n178             if not cert_loc:\n179                 cert_loc = DEFAULT_CA_BUNDLE_PATH\n180 \n181             if not cert_loc:\n182                 raise Exception(\"Could not find a suitable SSL CA certificate bundle.\")\n183 \n184             conn.cert_reqs = 'CERT_REQUIRED'\n185             conn.ca_certs = cert_loc\n186         else:\n187             conn.cert_reqs = 'CERT_NONE'\n188             conn.ca_certs = None\n189 \n190         if cert:\n191             if not isinstance(cert, basestring):\n192                 conn.cert_file = cert[0]\n193                 conn.key_file = cert[1]\n194             else:\n195                 conn.cert_file = cert\n196 \n197     def build_response(self, req, resp):\n198         \"\"\"Builds a :class:`Response <requests.Response>` object from a urllib3\n199         response. This should not be called from user code, and is only exposed\n200         for use when subclassing the\n201         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`\n202 \n203         :param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.\n204         :param resp: The urllib3 response object.\n205         \"\"\"\n206         response = Response()\n207 \n208         # Fallback to None if there's no status_code, for whatever reason.\n209         response.status_code = getattr(resp, 'status', None)\n210 \n211         # Make headers case-insensitive.\n212         response.headers = CaseInsensitiveDict(getattr(resp, 'headers', {}))\n213 \n214         # Set encoding.\n215         response.encoding = get_encoding_from_headers(response.headers)\n216         response.raw = resp\n217         response.reason = response.raw.reason\n218 \n219         if isinstance(req.url, bytes):\n220             response.url = req.url.decode('utf-8')\n221         else:\n222             response.url = req.url\n223 \n224         # Add new cookies from the server.\n225         extract_cookies_to_jar(response.cookies, req, resp)\n226 \n227         # Give the Response some context.\n228         response.request = req\n229         response.connection = self\n230 \n231         return response\n232 \n233     def get_connection(self, url, proxies=None):\n234         \"\"\"Returns a urllib3 connection for the given URL. This should not be\n235         called from user code, and is only exposed for use when subclassing the\n236         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n237 \n238         :param url: The URL to connect to.\n239         :param proxies: (optional) A Requests-style dictionary of proxies used on this request.\n240         \"\"\"\n241         proxies = proxies or {}\n242         proxy = proxies.get(urlparse(url.lower()).scheme)\n243 \n244         if proxy:\n245             proxy = prepend_scheme_if_needed(proxy, 'http')\n246             proxy_manager = self.proxy_manager_for(proxy)\n247             conn = proxy_manager.connection_from_url(url)\n248         else:\n249             # Only scheme should be lower case\n250             parsed = urlparse(url)\n251             url = parsed.geturl()\n252             conn = self.poolmanager.connection_from_url(url)\n253 \n254         return conn\n255 \n256     def close(self):\n257         \"\"\"Disposes of any internal state.\n258 \n259         Currently, this just closes the PoolManager, which closes pooled\n260         connections.\n261         \"\"\"\n262         self.poolmanager.clear()\n263 \n264     def request_url(self, request, proxies):\n265         \"\"\"Obtain the url to use when making the final request.\n266 \n267         If the message is being sent through a HTTP proxy, the full URL has to\n268         be used. Otherwise, we should only use the path portion of the URL.\n269 \n270         This should not be called from user code, and is only exposed for use\n271         when subclassing the\n272         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n273 \n274         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n275         :param proxies: A dictionary of schemes to proxy URLs.\n276         \"\"\"\n277         proxies = proxies or {}\n278         scheme = urlparse(request.url).scheme\n279         proxy = proxies.get(scheme)\n280 \n281         if proxy and scheme != 'https':\n282             url = urldefragauth(request.url)\n283         else:\n284             url = request.path_url\n285 \n286         return url\n287 \n288     def add_headers(self, request, **kwargs):\n289         \"\"\"Add any headers needed by the connection. As of v2.0 this does\n290         nothing by default, but is left for overriding by users that subclass\n291         the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n292 \n293         This should not be called from user code, and is only exposed for use\n294         when subclassing the\n295         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n296 \n297         :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.\n298         :param kwargs: The keyword arguments from the call to send().\n299         \"\"\"\n300         pass\n301 \n302     def proxy_headers(self, proxy):\n303         \"\"\"Returns a dictionary of the headers to add to any request sent\n304         through a proxy. This works with urllib3 magic to ensure that they are\n305         correctly sent to the proxy, rather than in a tunnelled request if\n306         CONNECT is being used.\n307 \n308         This should not be called from user code, and is only exposed for use\n309         when subclassing the\n310         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n311 \n312         :param proxies: The url of the proxy being used for this request.\n313         :param kwargs: Optional additional keyword arguments.\n314         \"\"\"\n315         headers = {}\n316         username, password = get_auth_from_url(proxy)\n317 \n318         if username and password:\n319             headers['Proxy-Authorization'] = _basic_auth_str(username,\n320                                                              password)\n321 \n322         return headers\n323 \n324     def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n325         \"\"\"Sends PreparedRequest object. Returns Response object.\n326 \n327         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n328         :param stream: (optional) Whether to stream the request content.\n329         :param timeout: (optional) How long to wait for the server to send\n330             data before giving up, as a float, or a (`connect timeout, read\n331             timeout <user/advanced.html#timeouts>`_) tuple.\n332         :type timeout: float or tuple\n333         :param verify: (optional) Whether to verify SSL certificates.\n334         :param cert: (optional) Any user-provided SSL certificate to be trusted.\n335         :param proxies: (optional) The proxies dictionary to apply to the request.\n336         \"\"\"\n337 \n338         conn = self.get_connection(request.url, proxies)\n339 \n340         self.cert_verify(conn, request.url, verify, cert)\n341         url = self.request_url(request, proxies)\n342         self.add_headers(request)\n343 \n344         chunked = not (request.body is None or 'Content-Length' in request.headers)\n345 \n346         if isinstance(timeout, tuple):\n347             try:\n348                 connect, read = timeout\n349                 timeout = TimeoutSauce(connect=connect, read=read)\n350             except ValueError as e:\n351                 # this may raise a string formatting error.\n352                 err = (\"Invalid timeout {0}. Pass a (connect, read) \"\n353                        \"timeout tuple, or a single float to set \"\n354                        \"both timeouts to the same value\".format(timeout))\n355                 raise ValueError(err)\n356         else:\n357             timeout = TimeoutSauce(connect=timeout, read=timeout)\n358 \n359         try:\n360             if not chunked:\n361                 resp = conn.urlopen(\n362                     method=request.method,\n363                     url=url,\n364                     body=request.body,\n365                     headers=request.headers,\n366                     redirect=False,\n367                     assert_same_host=False,\n368                     preload_content=False,\n369                     decode_content=False,\n370                     retries=self.max_retries,\n371                     timeout=timeout\n372                 )\n373 \n374             # Send the request.\n375             else:\n376                 if hasattr(conn, 'proxy_pool'):\n377                     conn = conn.proxy_pool\n378 \n379                 low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)\n380 \n381                 try:\n382                     low_conn.putrequest(request.method,\n383                                         url,\n384                                         skip_accept_encoding=True)\n385 \n386                     for header, value in request.headers.items():\n387                         low_conn.putheader(header, value)\n388 \n389                     low_conn.endheaders()\n390 \n391                     for i in request.body:\n392                         low_conn.send(hex(len(i))[2:].encode('utf-8'))\n393                         low_conn.send(b'\\r\\n')\n394                         low_conn.send(i)\n395                         low_conn.send(b'\\r\\n')\n396                     low_conn.send(b'0\\r\\n\\r\\n')\n397 \n398                     r = low_conn.getresponse()\n399                     resp = HTTPResponse.from_httplib(\n400                         r,\n401                         pool=conn,\n402                         connection=low_conn,\n403                         preload_content=False,\n404                         decode_content=False\n405                     )\n406                 except:\n407                     # If we hit any problems here, clean up the connection.\n408                     # Then, reraise so that we can handle the actual exception.\n409                     low_conn.close()\n410                     raise\n411 \n412         except (ProtocolError, socket.error) as err:\n413             raise ConnectionError(err, request=request)\n414 \n415         except MaxRetryError as e:\n416             if isinstance(e.reason, ConnectTimeoutError):\n417                 raise ConnectTimeout(e, request=request)\n418 \n419             if isinstance(e.reason, ResponseError):\n420                 raise RetryError(e, request=request)\n421 \n422             raise ConnectionError(e, request=request)\n423 \n424         except _ProxyError as e:\n425             raise ProxyError(e)\n426 \n427         except (_SSLError, _HTTPError) as e:\n428             if isinstance(e, _SSLError):\n429                 raise SSLError(e, request=request)\n430             elif isinstance(e, ReadTimeoutError):\n431                 raise ReadTimeout(e, request=request)\n432             else:\n433                 raise\n434 \n435         return self.build_response(request, resp)\n",
        "intended_behavior": "Catch `urllib3` exceptions directly related to HTTP operations, such as timeout errors, connection errors, and decoding errors, and wrap these in the appropriate `requests` exceptions, ensuring that the original exception message and any other relevant diagnostic information are preserved."
    }
]