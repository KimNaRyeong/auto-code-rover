[
    {
        "rel_file_path": "sphinx/builders/linkcheck.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/sphinx-doc__sphinx/setup_sphinx-doc__sphinx__4.1/sphinx/builders/linkcheck.py",
        "start": 1,
        "end": 693,
        "class_name": null,
        "method_name": null,
        "code": "1 \"\"\"\n2     sphinx.builders.linkcheck\n3     ~~~~~~~~~~~~~~~~~~~~~~~~~\n4 \n5     The CheckExternalLinksBuilder class.\n6 \n7     :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.\n8     :license: BSD, see LICENSE for details.\n9 \"\"\"\n10 \n11 import json\n12 import re\n13 import socket\n14 import time\n15 import warnings\n16 from datetime import datetime, timezone\n17 from email.utils import parsedate_to_datetime\n18 from html.parser import HTMLParser\n19 from os import path\n20 from queue import PriorityQueue, Queue\n21 from threading import Thread\n22 from typing import (Any, Dict, Generator, List, NamedTuple, Optional, Pattern, Set, Tuple,\n23                     Union, cast)\n24 from urllib.parse import unquote, urlparse, urlunparse\n25 \n26 from docutils import nodes\n27 from docutils.nodes import Element\n28 from requests import Response\n29 from requests.exceptions import ConnectionError, HTTPError, TooManyRedirects\n30 \n31 from sphinx.application import Sphinx\n32 from sphinx.builders.dummy import DummyBuilder\n33 from sphinx.config import Config\n34 from sphinx.deprecation import RemovedInSphinx50Warning\n35 from sphinx.environment import BuildEnvironment\n36 from sphinx.locale import __\n37 from sphinx.transforms.post_transforms import SphinxPostTransform\n38 from sphinx.util import encode_uri, logging, requests\n39 from sphinx.util.console import darkgray, darkgreen, purple, red, turquoise  # type: ignore\n40 from sphinx.util.nodes import get_node_line\n41 \n42 logger = logging.getLogger(__name__)\n43 \n44 uri_re = re.compile('([a-z]+:)?//')  # matches to foo:// and // (a protocol relative URL)\n45 \n46 Hyperlink = NamedTuple('Hyperlink', (('uri', str),\n47                                      ('docname', str),\n48                                      ('lineno', Optional[int])))\n49 CheckRequest = NamedTuple('CheckRequest', (('next_check', float),\n50                                            ('hyperlink', Optional[Hyperlink])))\n51 CheckResult = NamedTuple('CheckResult', (('uri', str),\n52                                          ('docname', str),\n53                                          ('lineno', int),\n54                                          ('status', str),\n55                                          ('message', str),\n56                                          ('code', int)))\n57 RateLimit = NamedTuple('RateLimit', (('delay', float), ('next_check', float)))\n58 \n59 # Tuple is old styled CheckRequest\n60 CheckRequestType = Union[CheckRequest, Tuple[float, str, str, int]]\n61 \n62 DEFAULT_REQUEST_HEADERS = {\n63     'Accept': 'text/html,application/xhtml+xml;q=0.9,*/*;q=0.8',\n64 }\n65 CHECK_IMMEDIATELY = 0\n66 QUEUE_POLL_SECS = 1\n67 DEFAULT_DELAY = 60.0\n68 \n69 \n70 def node_line_or_0(node: Element) -> int:\n71     \"\"\"\n72     PriorityQueue items must be comparable. The line number is part of the\n73     tuple used by the PriorityQueue, keep an homogeneous type for comparison.\n74     \"\"\"\n75     warnings.warn('node_line_or_0() is deprecated.',\n76                   RemovedInSphinx50Warning, stacklevel=2)\n77     return get_node_line(node) or 0\n78 \n79 \n80 class AnchorCheckParser(HTMLParser):\n81     \"\"\"Specialized HTML parser that looks for a specific anchor.\"\"\"\n82 \n83     def __init__(self, search_anchor: str) -> None:\n84         super().__init__()\n85 \n86         self.search_anchor = search_anchor\n87         self.found = False\n88 \n89     def handle_starttag(self, tag: Any, attrs: Any) -> None:\n90         for key, value in attrs:\n91             if key in ('id', 'name') and value == self.search_anchor:\n92                 self.found = True\n93                 break\n94 \n95 \n96 def check_anchor(response: requests.requests.Response, anchor: str) -> bool:\n97     \"\"\"Reads HTML data from a response object `response` searching for `anchor`.\n98     Returns True if anchor was found, False otherwise.\n99     \"\"\"\n100     parser = AnchorCheckParser(anchor)\n101     # Read file in chunks. If we find a matching anchor, we break\n102     # the loop early in hopes not to have to download the whole thing.\n103     for chunk in response.iter_content(chunk_size=4096, decode_unicode=True):\n104         if isinstance(chunk, bytes):    # requests failed to decode\n105             chunk = chunk.decode()      # manually try to decode it\n106 \n107         parser.feed(chunk)\n108         if parser.found:\n109             break\n110     parser.close()\n111     return parser.found\n112 \n113 \n114 class CheckExternalLinksBuilder(DummyBuilder):\n115     \"\"\"\n116     Checks for broken external links.\n117     \"\"\"\n118     name = 'linkcheck'\n119     epilog = __('Look for any errors in the above output or in '\n120                 '%(outdir)s/output.txt')\n121 \n122     def init(self) -> None:\n123         self.hyperlinks: Dict[str, Hyperlink] = {}\n124         self._good: Set[str] = set()\n125         self._broken: Dict[str, str] = {}\n126         self._redirected: Dict[str, Tuple[str, int]] = {}\n127         # set a timeout for non-responding servers\n128         socket.setdefaulttimeout(5.0)\n129 \n130         # create queues and worker threads\n131         self._wqueue: PriorityQueue[CheckRequestType] = PriorityQueue()\n132         self._rqueue: Queue[CheckResult] = Queue()\n133 \n134     @property\n135     def anchors_ignore(self) -> List[Pattern]:\n136         warnings.warn(\n137             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"anchors_ignore\"),\n138             RemovedInSphinx50Warning,\n139             stacklevel=2,\n140         )\n141         return [re.compile(x) for x in self.config.linkcheck_anchors_ignore]\n142 \n143     @property\n144     def auth(self) -> List[Tuple[Pattern, Any]]:\n145         warnings.warn(\n146             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"auth\"),\n147             RemovedInSphinx50Warning,\n148             stacklevel=2,\n149         )\n150         return [(re.compile(pattern), auth_info) for pattern, auth_info\n151                 in self.config.linkcheck_auth]\n152 \n153     @property\n154     def to_ignore(self) -> List[Pattern]:\n155         warnings.warn(\n156             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"to_ignore\"),\n157             RemovedInSphinx50Warning,\n158             stacklevel=2,\n159         )\n160         return [re.compile(x) for x in self.config.linkcheck_ignore]\n161 \n162     @property\n163     def good(self) -> Set[str]:\n164         warnings.warn(\n165             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"good\"),\n166             RemovedInSphinx50Warning,\n167             stacklevel=2,\n168         )\n169         return self._good\n170 \n171     @property\n172     def broken(self) -> Dict[str, str]:\n173         warnings.warn(\n174             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"broken\"),\n175             RemovedInSphinx50Warning,\n176             stacklevel=2,\n177         )\n178         return self._broken\n179 \n180     @property\n181     def redirected(self) -> Dict[str, Tuple[str, int]]:\n182         warnings.warn(\n183             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"redirected\"),\n184             RemovedInSphinx50Warning,\n185             stacklevel=2,\n186         )\n187         return self._redirected\n188 \n189     def check_thread(self) -> None:\n190         warnings.warn(\n191             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"check_thread\"),\n192             RemovedInSphinx50Warning,\n193             stacklevel=2,\n194         )\n195         # do nothing.\n196 \n197     def limit_rate(self, response: Response) -> Optional[float]:\n198         warnings.warn(\n199             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"limit_rate\"),\n200             RemovedInSphinx50Warning,\n201             stacklevel=2,\n202         )\n203         worker = HyperlinkAvailabilityCheckWorker(self.env, self.config,\n204                                                   None, None, {})\n205         return worker.limit_rate(response)\n206 \n207     def rqueue(self, response: Response) -> Queue:\n208         warnings.warn(\n209             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"rqueue\"),\n210             RemovedInSphinx50Warning,\n211             stacklevel=2,\n212         )\n213         return self._rqueue\n214 \n215     def workers(self, response: Response) -> List[Thread]:\n216         warnings.warn(\n217             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"workers\"),\n218             RemovedInSphinx50Warning,\n219             stacklevel=2,\n220         )\n221         return []\n222 \n223     def wqueue(self, response: Response) -> Queue:\n224         warnings.warn(\n225             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"wqueue\"),\n226             RemovedInSphinx50Warning,\n227             stacklevel=2,\n228         )\n229         return self._wqueue\n230 \n231     def process_result(self, result: CheckResult) -> None:\n232         filename = self.env.doc2path(result.docname, None)\n233 \n234         linkstat = dict(filename=filename, lineno=result.lineno,\n235                         status=result.status, code=result.code, uri=result.uri,\n236                         info=result.message)\n237         self.write_linkstat(linkstat)\n238 \n239         if result.status == 'unchecked':\n240             return\n241         if result.status == 'working' and result.message == 'old':\n242             return\n243         if result.lineno:\n244             logger.info('(%16s: line %4d) ', result.docname, result.lineno, nonl=True)\n245         if result.status == 'ignored':\n246             if result.message:\n247                 logger.info(darkgray('-ignored- ') + result.uri + ': ' + result.message)\n248             else:\n249                 logger.info(darkgray('-ignored- ') + result.uri)\n250         elif result.status == 'local':\n251             logger.info(darkgray('-local-   ') + result.uri)\n252             self.write_entry('local', result.docname, filename, result.lineno, result.uri)\n253         elif result.status == 'working':\n254             logger.info(darkgreen('ok        ') + result.uri + result.message)\n255         elif result.status == 'broken':\n256             if self.app.quiet or self.app.warningiserror:\n257                 logger.warning(__('broken link: %s (%s)'), result.uri, result.message,\n258                                location=(filename, result.lineno))\n259             else:\n260                 logger.info(red('broken    ') + result.uri + red(' - ' + result.message))\n261             self.write_entry('broken', result.docname, filename, result.lineno,\n262                              result.uri + ': ' + result.message)\n263         elif result.status == 'redirected':\n264             try:\n265                 text, color = {\n266                     301: ('permanently', purple),\n267                     302: ('with Found', purple),\n268                     303: ('with See Other', purple),\n269                     307: ('temporarily', turquoise),\n270                     308: ('permanently', purple),\n271                 }[result.code]\n272             except KeyError:\n273                 text, color = ('with unknown code', purple)\n274             linkstat['text'] = text\n275             logger.info(color('redirect  ') + result.uri +\n276                         color(' - ' + text + ' to ' + result.message))\n277             self.write_entry('redirected ' + text, result.docname, filename,\n278                              result.lineno, result.uri + ' to ' + result.message)\n279         else:\n280             raise ValueError(\"Unknown status %s.\" % result.status)\n281 \n282     def write_entry(self, what: str, docname: str, filename: str, line: int,\n283                     uri: str) -> None:\n284         self.txt_outfile.write(\"%s:%s: [%s] %s\\n\" % (filename, line, what, uri))\n285 \n286     def write_linkstat(self, data: dict) -> None:\n287         self.json_outfile.write(json.dumps(data))\n288         self.json_outfile.write('\\n')\n289 \n290     def finish(self) -> None:\n291         checker = HyperlinkAvailabilityChecker(self.env, self.config, self)\n292         logger.info('')\n293 \n294         with open(path.join(self.outdir, 'output.txt'), 'w') as self.txt_outfile,\\\n295              open(path.join(self.outdir, 'output.json'), 'w') as self.json_outfile:\n296             for result in checker.check(self.hyperlinks):\n297                 self.process_result(result)\n298 \n299         if self._broken:\n300             self.app.statuscode = 1\n301 \n302 \n303 class HyperlinkAvailabilityChecker:\n304     def __init__(self, env: BuildEnvironment, config: Config,\n305                  builder: CheckExternalLinksBuilder = None) -> None:\n306         # Warning: builder argument will be removed in the sphinx-5.0.\n307         # Don't use it from extensions.\n308         # tag: RemovedInSphinx50Warning\n309         self.builder = builder\n310         self.config = config\n311         self.env = env\n312         self.rate_limits: Dict[str, RateLimit] = {}\n313         self.workers: List[Thread] = []\n314 \n315         self.to_ignore = [re.compile(x) for x in self.config.linkcheck_ignore]\n316 \n317         if builder:\n318             self.rqueue = builder._rqueue\n319             self.wqueue = builder._wqueue\n320         else:\n321             self.rqueue = Queue()\n322             self.wqueue = PriorityQueue()\n323 \n324     def invoke_threads(self) -> None:\n325         for i in range(self.config.linkcheck_workers):\n326             thread = HyperlinkAvailabilityCheckWorker(self.env, self.config,\n327                                                       self.rqueue, self.wqueue,\n328                                                       self.rate_limits, self.builder)\n329             thread.start()\n330             self.workers.append(thread)\n331 \n332     def shutdown_threads(self) -> None:\n333         self.wqueue.join()\n334         for worker in self.workers:\n335             self.wqueue.put(CheckRequest(CHECK_IMMEDIATELY, None), False)\n336 \n337     def check(self, hyperlinks: Dict[str, Hyperlink]) -> Generator[CheckResult, None, None]:\n338         self.invoke_threads()\n339 \n340         total_links = 0\n341         for hyperlink in hyperlinks.values():\n342             if self.is_ignored_uri(hyperlink.uri):\n343                 yield CheckResult(hyperlink.uri, hyperlink.docname, hyperlink.lineno,\n344                                   'ignored', '', 0)\n345             else:\n346                 self.wqueue.put(CheckRequest(CHECK_IMMEDIATELY, hyperlink), False)\n347                 total_links += 1\n348 \n349         done = 0\n350         while done < total_links:\n351             yield self.rqueue.get()\n352             done += 1\n353 \n354         self.shutdown_threads()\n355 \n356     def is_ignored_uri(self, uri: str) -> bool:\n357         return any(pat.match(uri) for pat in self.to_ignore)\n358 \n359 \n360 class HyperlinkAvailabilityCheckWorker(Thread):\n361     \"\"\"A worker class for checking the availability of hyperlinks.\"\"\"\n362 \n363     def __init__(self, env: BuildEnvironment, config: Config, rqueue: Queue,\n364                  wqueue: Queue, rate_limits: Dict[str, RateLimit],\n365                  builder: CheckExternalLinksBuilder = None) -> None:\n366         # Warning: builder argument will be removed in the sphinx-5.0.\n367         # Don't use it from extensions.\n368         # tag: RemovedInSphinx50Warning\n369         self.config = config\n370         self.env = env\n371         self.rate_limits = rate_limits\n372         self.rqueue = rqueue\n373         self.wqueue = wqueue\n374 \n375         self.anchors_ignore = [re.compile(x)\n376                                for x in self.config.linkcheck_anchors_ignore]\n377         self.auth = [(re.compile(pattern), auth_info) for pattern, auth_info\n378                      in self.config.linkcheck_auth]\n379 \n380         if builder:\n381             # if given, fill the result of checks as cache\n382             self._good = builder._good\n383             self._broken = builder._broken\n384             self._redirected = builder._redirected\n385         else:\n386             # only for compatibility. Will be removed in Sphinx-5.0\n387             self._good = set()\n388             self._broken = {}\n389             self._redirected = {}\n390 \n391         super().__init__(daemon=True)\n392 \n393     def run(self) -> None:\n394         kwargs = {}\n395         if self.config.linkcheck_timeout:\n396             kwargs['timeout'] = self.config.linkcheck_timeout\n397 \n398         def get_request_headers() -> Dict:\n399             url = urlparse(uri)\n400             candidates = [\"%s://%s\" % (url.scheme, url.netloc),\n401                           \"%s://%s/\" % (url.scheme, url.netloc),\n402                           uri,\n403                           \"*\"]\n404 \n405             for u in candidates:\n406                 if u in self.config.linkcheck_request_headers:\n407                     headers = dict(DEFAULT_REQUEST_HEADERS)\n408                     headers.update(self.config.linkcheck_request_headers[u])\n409                     return headers\n410 \n411             return {}\n412 \n413         def check_uri() -> Tuple[str, str, int]:\n414             # split off anchor\n415             if '#' in uri:\n416                 req_url, anchor = uri.split('#', 1)\n417                 for rex in self.anchors_ignore:\n418                     if rex.match(anchor):\n419                         anchor = None\n420                         break\n421             else:\n422                 req_url = uri\n423                 anchor = None\n424 \n425             # handle non-ASCII URIs\n426             try:\n427                 req_url.encode('ascii')\n428             except UnicodeError:\n429                 req_url = encode_uri(req_url)\n430 \n431             # Get auth info, if any\n432             for pattern, auth_info in self.auth:\n433                 if pattern.match(uri):\n434                     break\n435             else:\n436                 auth_info = None\n437 \n438             # update request headers for the URL\n439             kwargs['headers'] = get_request_headers()\n440 \n441             try:\n442                 if anchor and self.config.linkcheck_anchors:\n443                     # Read the whole document and see if #anchor exists\n444                     response = requests.get(req_url, stream=True, config=self.config,\n445                                             auth=auth_info, **kwargs)\n446                     response.raise_for_status()\n447                     found = check_anchor(response, unquote(anchor))\n448 \n449                     if not found:\n450                         raise Exception(__(\"Anchor '%s' not found\") % anchor)\n451                 else:\n452                     try:\n453                         # try a HEAD request first, which should be easier on\n454                         # the server and the network\n455                         response = requests.head(req_url, allow_redirects=True,\n456                                                  config=self.config, auth=auth_info,\n457                                                  **kwargs)\n458                         response.raise_for_status()\n459                     # Servers drop the connection on HEAD requests, causing\n460                     # ConnectionError.\n461                     except (ConnectionError, HTTPError, TooManyRedirects) as err:\n462                         if isinstance(err, HTTPError) and err.response.status_code == 429:\n463                             raise\n464                         # retry with GET request if that fails, some servers\n465                         # don't like HEAD requests.\n466                         response = requests.get(req_url, stream=True,\n467                                                 config=self.config,\n468                                                 auth=auth_info, **kwargs)\n469                         response.raise_for_status()\n470             except HTTPError as err:\n471                 if err.response.status_code == 401:\n472                     # We'll take \"Unauthorized\" as working.\n473                     return 'working', ' - unauthorized', 0\n474                 elif err.response.status_code == 429:\n475                     next_check = self.limit_rate(err.response)\n476                     if next_check is not None:\n477                         self.wqueue.put(CheckRequest(next_check, hyperlink), False)\n478                         return 'rate-limited', '', 0\n479                     return 'broken', str(err), 0\n480                 elif err.response.status_code == 503:\n481                     # We'll take \"Service Unavailable\" as ignored.\n482                     return 'ignored', str(err), 0\n483                 else:\n484                     return 'broken', str(err), 0\n485             except Exception as err:\n486                 return 'broken', str(err), 0\n487             else:\n488                 netloc = urlparse(req_url).netloc\n489                 try:\n490                     del self.rate_limits[netloc]\n491                 except KeyError:\n492                     pass\n493             if response.url.rstrip('/') == req_url.rstrip('/'):\n494                 return 'working', '', 0\n495             else:\n496                 new_url = response.url\n497                 if anchor:\n498                     new_url += '#' + anchor\n499                 # history contains any redirects, get last\n500                 if response.history:\n501                     code = response.history[-1].status_code\n502                     return 'redirected', new_url, code\n503                 else:\n504                     return 'redirected', new_url, 0\n505 \n506         def check(docname: str) -> Tuple[str, str, int]:\n507             # check for various conditions without bothering the network\n508             if len(uri) == 0 or uri.startswith(('#', 'mailto:', 'tel:')):\n509                 return 'unchecked', '', 0\n510             elif not uri.startswith(('http:', 'https:')):\n511                 if uri_re.match(uri):\n512                     # non supported URI schemes (ex. ftp)\n513                     return 'unchecked', '', 0\n514                 else:\n515                     srcdir = path.dirname(self.env.doc2path(docname))\n516                     if path.exists(path.join(srcdir, uri)):\n517                         return 'working', '', 0\n518                     else:\n519                         self._broken[uri] = ''\n520                         return 'broken', '', 0\n521             elif uri in self._good:\n522                 return 'working', 'old', 0\n523             elif uri in self._broken:\n524                 return 'broken', self._broken[uri], 0\n525             elif uri in self._redirected:\n526                 return 'redirected', self._redirected[uri][0], self._redirected[uri][1]\n527 \n528             # need to actually check the URI\n529             for _ in range(self.config.linkcheck_retries):\n530                 status, info, code = check_uri()\n531                 if status != \"broken\":\n532                     break\n533 \n534             if status == \"working\":\n535                 self._good.add(uri)\n536             elif status == \"broken\":\n537                 self._broken[uri] = info\n538             elif status == \"redirected\":\n539                 self._redirected[uri] = (info, code)\n540 \n541             return (status, info, code)\n542 \n543         while True:\n544             check_request = self.wqueue.get()\n545             try:\n546                 next_check, hyperlink = check_request\n547                 if hyperlink is None:\n548                     break\n549 \n550                 uri, docname, lineno = hyperlink\n551             except ValueError:\n552                 # old styled check_request (will be deprecated in Sphinx-5.0)\n553                 next_check, uri, docname, lineno = check_request\n554 \n555             if uri is None:\n556                 break\n557             netloc = urlparse(uri).netloc\n558             try:\n559                 # Refresh rate limit.\n560                 # When there are many links in the queue, workers are all stuck waiting\n561                 # for responses, but the builder keeps queuing. Links in the queue may\n562                 # have been queued before rate limits were discovered.\n563                 next_check = self.rate_limits[netloc].next_check\n564             except KeyError:\n565                 pass\n566             if next_check > time.time():\n567                 # Sleep before putting message back in the queue to avoid\n568                 # waking up other threads.\n569                 time.sleep(QUEUE_POLL_SECS)\n570                 self.wqueue.put(CheckRequest(next_check, hyperlink), False)\n571                 self.wqueue.task_done()\n572                 continue\n573             status, info, code = check(docname)\n574             if status == 'rate-limited':\n575                 logger.info(darkgray('-rate limited-   ') + uri + darkgray(' | sleeping...'))\n576             else:\n577                 self.rqueue.put(CheckResult(uri, docname, lineno, status, info, code))\n578             self.wqueue.task_done()\n579 \n580     def limit_rate(self, response: Response) -> Optional[float]:\n581         next_check = None\n582         retry_after = response.headers.get(\"Retry-After\")\n583         if retry_after:\n584             try:\n585                 # Integer: time to wait before next attempt.\n586                 delay = float(retry_after)\n587             except ValueError:\n588                 try:\n589                     # An HTTP-date: time of next attempt.\n590                     until = parsedate_to_datetime(retry_after)\n591                 except (TypeError, ValueError):\n592                     # TypeError: Invalid date format.\n593                     # ValueError: Invalid date, e.g. Oct 52th.\n594                     pass\n595                 else:\n596                     next_check = datetime.timestamp(until)\n597                     delay = (until - datetime.now(timezone.utc)).total_seconds()\n598             else:\n599                 next_check = time.time() + delay\n600         netloc = urlparse(response.url).netloc\n601         if next_check is None:\n602             max_delay = self.config.linkcheck_rate_limit_timeout\n603             try:\n604                 rate_limit = self.rate_limits[netloc]\n605             except KeyError:\n606                 delay = DEFAULT_DELAY\n607             else:\n608                 last_wait_time = rate_limit.delay\n609                 delay = 2.0 * last_wait_time\n610                 if delay > max_delay and last_wait_time < max_delay:\n611                     delay = max_delay\n612             if delay > max_delay:\n613                 return None\n614             next_check = time.time() + delay\n615         self.rate_limits[netloc] = RateLimit(delay, next_check)\n616         return next_check\n617 \n618 \n619 class HyperlinkCollector(SphinxPostTransform):\n620     builders = ('linkcheck',)\n621     default_priority = 800\n622 \n623     def run(self, **kwargs: Any) -> None:\n624         builder = cast(CheckExternalLinksBuilder, self.app.builder)\n625         hyperlinks = builder.hyperlinks\n626 \n627         # reference nodes\n628         for refnode in self.document.traverse(nodes.reference):\n629             if 'refuri' not in refnode:\n630                 continue\n631             uri = refnode['refuri']\n632             newuri = self.app.emit_firstresult('linkcheck-process-uri', uri)\n633             if newuri:\n634                 uri = newuri\n635 \n636             lineno = get_node_line(refnode)\n637             uri_info = Hyperlink(uri, self.env.docname, lineno)\n638             if uri not in hyperlinks:\n639                 hyperlinks[uri] = uri_info\n640 \n641         # image nodes\n642         for imgnode in self.document.traverse(nodes.image):\n643             uri = imgnode['candidates'].get('?')\n644             if uri and '://' in uri:\n645                 newuri = self.app.emit_firstresult('linkcheck-process-uri', uri)\n646                 if newuri:\n647                     uri = newuri\n648 \n649                 lineno = get_node_line(imgnode)\n650                 uri_info = Hyperlink(uri, self.env.docname, lineno)\n651                 if uri not in hyperlinks:\n652                     hyperlinks[uri] = uri_info\n653 \n654 \n655 def rewrite_github_anchor(app: Sphinx, uri: str) -> Optional[str]:\n656     \"\"\"Rewrite anchor name of the hyperlink to github.com\n657 \n658     The hyperlink anchors in github.com are dynamically generated.  This rewrites\n659     them before checking and makes them comparable.\n660     \"\"\"\n661     parsed = urlparse(uri)\n662     if parsed.hostname == \"github.com\" and parsed.fragment:\n663         prefixed = parsed.fragment.startswith('user-content-')\n664         if not prefixed:\n665             fragment = f'user-content-{parsed.fragment}'\n666             return urlunparse(parsed._replace(fragment=fragment))\n667     return None\n668 \n669 \n670 def setup(app: Sphinx) -> Dict[str, Any]:\n671     app.add_builder(CheckExternalLinksBuilder)\n672     app.add_post_transform(HyperlinkCollector)\n673 \n674     app.add_config_value('linkcheck_ignore', [], None)\n675     app.add_config_value('linkcheck_auth', [], None)\n676     app.add_config_value('linkcheck_request_headers', {}, None)\n677     app.add_config_value('linkcheck_retries', 1, None)\n678     app.add_config_value('linkcheck_timeout', None, None, [int])\n679     app.add_config_value('linkcheck_workers', 5, None)\n680     app.add_config_value('linkcheck_anchors', True, None)\n681     # Anchors starting with ! are ignored since they are\n682     # commonly used for dynamic pages\n683     app.add_config_value('linkcheck_anchors_ignore', [\"^!\"], None)\n684     app.add_config_value('linkcheck_rate_limit_timeout', 300.0, None)\n685 \n686     app.add_event('linkcheck-process-uri')\n687     app.connect('linkcheck-process-uri', rewrite_github_anchor)\n688 \n689     return {\n690         'version': 'builtin',\n691         'parallel_read_safe': True,\n692         'parallel_write_safe': True,\n693     }\n",
        "intended_behavior": "This file should be modified or extended to include: Configuration Handling: A mechanism to define and load allowed redirect pairs from the Sphinx configuration (e.g., in `conf.py`). This could involve adding a new configuration option such as `linkcheck_allowed_redirects` that accepts a list of tuples specifying allowed source and destination URL pairs. Redirect Validation: Modify or enhance the redirection handling logic to cross-check any encountered redirects against the list of allowed redirect pairs. Only redirects that match a pair in the list should be allowed. If a redirect does not match any allowed pair, it should be flagged as an error or warning. Reporting: Ensure that any disallowed redirects are reported to the user in a clear and actionable manner, potentially as part of the existing linkcheck output/reporting mechanism."
    }
]