2025-10-18 01:17:22.396 | INFO     | Starting overall retry 0 with model gpt-4-0125-preview
2025-10-18 01:17:26.197 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=511, output_tokens=12, cost=0.005470
2025-10-18 01:17:45.642 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=691, output_tokens=869, cost=0.032980
2025-10-18 01:17:46.896 | INFO     | registered non reproducing test 0
2025-10-18 01:18:08.313 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=2687, output_tokens=936, cost=0.054950
2025-10-18 01:18:09.481 | INFO     | registered non reproducing test 1
2025-10-18 01:18:24.733 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=2781, output_tokens=768, cost=0.050850
2025-10-18 01:18:25.881 | INFO     | registered non reproducing test 2
2025-10-18 01:18:25.881 | WARNING  | Failed to write a reproducer test; skipping reproducer tracing
2025-10-18 01:18:25.888 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-18 01:18:32.492 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=820, output_tokens=313, cost=0.017590
2025-10-18 01:18:32.500 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-18 01:18:35.405 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=667, output_tokens=62, cost=0.008530
2025-10-18 01:18:35.407 | DEBUG    | Extracted a valid json.
2025-10-18 01:18:35.407 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_class(\"EmptyResultSet\")",
        "search_method_in_class(\"get_aggregation\", \"Query\")",
        "search_code_in_file(\"raise EmptyResultSet()\", \"django/db/models/lookups.py\")"
    ],
    "bug_locations": []
}
2025-10-18 01:18:35.438 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-18 01:18:35.439 | DEBUG    | <Agent search> Analyzing search results.
2025-10-18 01:18:52.071 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=2380, output_tokens=743, cost=0.046090
2025-10-18 01:18:52.085 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-18 01:18:59.225 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=3339, output_tokens=262, cost=0.041250
2025-10-18 01:18:59.232 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-18 01:19:06.926 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=616, output_tokens=278, cost=0.014500
2025-10-18 01:19:06.927 | DEBUG    | Extracted a valid json.
2025-10-18 01:19:06.927 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_method(\"build_filter\")",
        "search_code(\"EmptyResultSet\")"
    ],
    "bug_locations": [
        {
            "file": "django/db/models/sql/query.py",
            "class": "Query",
            "method": "get_aggregation",
            "intended_behavior": "The `get_aggregation` method should be updated to correctly handle scenarios where an `EmptyResultSet` could be expected due to the usage of an `__in` lookup with an empty list. Specifically, when encountering an empty queryset that would normally result in an `EmptyResultSet`, and therefore no real SQL query execution, the method should instead ensure that `Coalesce` functions still return their specified default values (as provided by `Value`), instead of resulting in `None`. This requires implementing logic that detects when the queryset is empty due to an `__in` lookup with an empty list, and rather than bypassing the query execution or returning a default `None` for each aggregate, it should respect `Coalesce` wrappers and return their defined fallback values. This behavior should preserve the existing functionality where actual records are matched or actual empty result sets are encountered, ensuring that the fix is targeted only at cases that would incorrectly bypass `Coalesce` due to the queryset being programmatically empty from the start."
        }
    ]
}
2025-10-18 01:19:07.025 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-18 01:19:07.026 | DEBUG    | <Agent search> Analyzing search results.
2025-10-18 01:19:26.894 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=7317, output_tokens=813, cost=0.097560
2025-10-18 01:19:26.909 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-18 01:19:36.472 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=8346, output_tokens=374, cost=0.094680
2025-10-18 01:19:36.481 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-18 01:19:43.680 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=728, output_tokens=283, cost=0.015770
2025-10-18 01:19:43.681 | DEBUG    | Extracted a valid json.
2025-10-18 01:19:43.681 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [],
    "bug_locations": [
        {
            "file": "django/db/models/sql/compiler.py",
            "class": "",
            "method": "",
            "intended_behavior": "The method or methods within this class that execute aggregate queries need to be modified to account for 'EmptyResultSet' scenarios in a way that 'Coalesce' annotations can still enforce their default values. When an aggregate function is wrapped with 'Coalesce' and the query would traditionally lead to an 'EmptyResultSet', the system should return the 'Coalesce' default value instead of 'None'. This adjustment must preserve the functionality for all other types of queries and conditions, ensuring that it specifically addresses the case of aggregates with 'Coalesce' when facing 'EmptyResultSet' scenarios."
        },
        {
            "file": "django/db/models/expressions.py",
            "class": "",
            "method": "",
            "intended_behavior": "Update or ensure that when expressions involving 'Coalesce' are evaluated, especially in the context of an anticipated 'EmptyResultSet' from a filter condition like 'pk__in=[]', the expression logic defaults to the 'Coalesce' specified value instead of yielding 'None'. This would ensure that 'Coalesce' effectively provides a default value even when no rows are matched, addressing the core issue and maintaining existing functionality where applicable."
        }
    ]
}
2025-10-18 01:19:43.696 | DEBUG    | Bug location extracted successfully: [<file>django/db/models/sql/compiler.py</file>
<class>None</class>
<method>None</method>
<code>
1 import collections
2 import re
3 from functools import partial
4 from itertools import chain
5 
6 from django.core.exceptions import EmptyResultSet, FieldError
7 from django.db import DatabaseError, NotSupportedError
8 from django.db.models.constants import LOOKUP_SEP
9 from django.db.models.expressions import F, OrderBy, RawSQL, Ref, Value
10 from django.db.models.functions import Cast, Random
11 from django.db.models.query_utils import Q, select_related_descend
12 from django.db.models.sql.constants import (
13     CURSOR, GET_ITERATOR_CHUNK_SIZE, MULTI, NO_RESULTS, ORDER_DIR, SINGLE,
14 )
15 from django.db.models.sql.query import Query, get_order_dir
16 from django.db.transaction import TransactionManagementError
17 from django.utils.functional import cached_property
18 from django.utils.hashable import make_hashable
19 from django.utils.regex_helper import _lazy_re_compile
20 
21 
22 class SQLCompiler:
23     # Multiline ordering SQL clause may appear from RawSQL.
24     ordering_parts = _lazy_re_compile(
25         r'^(.*)\s(?:ASC|DESC).*',
26         re.MULTILINE | re.DOTALL,
27     )
28 
29     def __init__(self, query, connection, using):
30         self.query = query
31         self.connection = connection
32         self.using = using
33         self.quote_cache = {'*': '*'}
34         # The select, klass_info, and annotations are needed by QuerySet.iterator()
35         # these are set as a side-effect of executing the query. Note that we calculate
36         # separately a list of extra select columns needed for grammatical correctness
37         # of the query, but these columns are not included in self.select.
38         self.select = None
39         self.annotation_col_map = None
40         self.klass_info = None
41         self._meta_ordering = None
42 
43     def setup_query(self):
44         if all(self.query.alias_refcount[a] == 0 for a in self.query.alias_map):
45             self.query.get_initial_alias()
46         self.select, self.klass_info, self.annotation_col_map = self.get_select()
47         self.col_count = len(self.select)
48 
49     def pre_sql_setup(self):
50         """
51         Do any necessary class setup immediately prior to producing SQL. This
52         is for things that can't necessarily be done in __init__ because we
53         might not have all the pieces in place at that time.
54         """
55         self.setup_query()
56         order_by = self.get_order_by()
57         self.where, self.having = self.query.where.split_having()
58         extra_select = self.get_extra_select(order_by, self.select)
59         self.has_extra_select = bool(extra_select)
60         group_by = self.get_group_by(self.select + extra_select, order_by)
61         return extra_select, order_by, group_by
62 
63     def get_group_by(self, select, order_by):
64         """
65         Return a list of 2-tuples of form (sql, params).
66 
67         The logic of what exactly the GROUP BY clause contains is hard
68         to describe in other words than "if it passes the test suite,
69         then it is correct".
70         """
71         # Some examples:
72         #     SomeModel.objects.annotate(Count('somecol'))
73         #     GROUP BY: all fields of the model
74         #
75         #    SomeModel.objects.values('name').annotate(Count('somecol'))
76         #    GROUP BY: name
77         #
78         #    SomeModel.objects.annotate(Count('somecol')).values('name')
79         #    GROUP BY: all cols of the model
80         #
81         #    SomeModel.objects.values('name', 'pk').annotate(Count('somecol')).values('pk')
82         #    GROUP BY: name, pk
83         #
84         #    SomeModel.objects.values('name').annotate(Count('somecol')).values('pk')
85         #    GROUP BY: name, pk
86         #
87         # In fact, the self.query.group_by is the minimal set to GROUP BY. It
88         # can't be ever restricted to a smaller set, but additional columns in
89         # HAVING, ORDER BY, and SELECT clauses are added to it. Unfortunately
90         # the end result is that it is impossible to force the query to have
91         # a chosen GROUP BY clause - you can almost do this by using the form:
92         #     .values(*wanted_cols).annotate(AnAggregate())
93         # but any later annotations, extra selects, values calls that
94         # refer some column outside of the wanted_cols, order_by, or even
95         # filter calls can alter the GROUP BY clause.
96 
97         # The query.group_by is either None (no GROUP BY at all), True
98         # (group by select fields), or a list of expressions to be added
99         # to the group by.
100         if self.query.group_by is None:
101             return []
102         expressions = []
103         if self.query.group_by is not True:
104             # If the group by is set to a list (by .values() call most likely),
105             # then we need to add everything in it to the GROUP BY clause.
106             # Backwards compatibility hack for setting query.group_by. Remove
107             # when  we have public API way of forcing the GROUP BY clause.
108             # Converts string references to expressions.
109             for expr in self.query.group_by:
110                 if not hasattr(expr, 'as_sql'):
111                     expressions.append(self.query.resolve_ref(expr))
112                 else:
113                     expressions.append(expr)
114         # Note that even if the group_by is set, it is only the minimal
115         # set to group by. So, we need to add cols in select, order_by, and
116         # having into the select in any case.
117         ref_sources = {
118             expr.source for expr in expressions if isinstance(expr, Ref)
119         }
120         for expr, _, _ in select:
121             # Skip members of the select clause that are already included
122             # by reference.
123             if expr in ref_sources:
124                 continue
125             cols = expr.get_group_by_cols()
126             for col in cols:
127                 expressions.append(col)
128         if not self._meta_ordering:
129             for expr, (sql, params, is_ref) in order_by:
130                 # Skip references to the SELECT clause, as all expressions in
131                 # the SELECT clause are already part of the GROUP BY.
132                 if not is_ref:
133                     expressions.extend(expr.get_group_by_cols())
134         having_group_by = self.having.get_group_by_cols() if self.having else ()
135         for expr in having_group_by:
136             expressions.append(expr)
137         result = []
138         seen = set()
139         expressions = self.collapse_group_by(expressions, having_group_by)
140 
141         for expr in expressions:
142             sql, params = self.compile(expr)
143             sql, params = expr.select_format(self, sql, params)
144             params_hash = make_hashable(params)
145             if (sql, params_hash) not in seen:
146                 result.append((sql, params))
147                 seen.add((sql, params_hash))
148         return result
149 
150     def collapse_group_by(self, expressions, having):
151         # If the DB can group by primary key, then group by the primary key of
152         # query's main model. Note that for PostgreSQL the GROUP BY clause must
153         # include the primary key of every table, but for MySQL it is enough to
154         # have the main table's primary key.
155         if self.connection.features.allows_group_by_pk:
156             # Determine if the main model's primary key is in the query.
157             pk = None
158             for expr in expressions:
159                 # Is this a reference to query's base table primary key? If the
160                 # expression isn't a Col-like, then skip the expression.
161                 if (getattr(expr, 'target', None) == self.query.model._meta.pk and
162                         getattr(expr, 'alias', None) == self.query.base_table):
163                     pk = expr
164                     break
165             # If the main model's primary key is in the query, group by that
166             # field, HAVING expressions, and expressions associated with tables
167             # that don't have a primary key included in the grouped columns.
168             if pk:
169                 pk_aliases = {
170                     expr.alias for expr in expressions
171                     if hasattr(expr, 'target') and expr.target.primary_key
172                 }
173                 expressions = [pk] + [
174                     expr for expr in expressions
175                     if expr in having or (
176                         getattr(expr, 'alias', None) is not None and expr.alias not in pk_aliases
177                     )
178                 ]
179         elif self.connection.features.allows_group_by_selected_pks:
180             # Filter out all expressions associated with a table's primary key
181             # present in the grouped columns. This is done by identifying all
182             # tables that have their primary key included in the grouped
183             # columns and removing non-primary key columns referring to them.
184             # Unmanaged models are excluded because they could be representing
185             # database views on which the optimization might not be allowed.
186             pks = {
187                 expr for expr in expressions
188                 if (
189                     hasattr(expr, 'target') and
190                     expr.target.primary_key and
191                     self.connection.features.allows_group_by_selected_pks_on_model(expr.target.model)
192                 )
193             }
194             aliases = {expr.alias for expr in pks}
195             expressions = [
196                 expr for expr in expressions if expr in pks or getattr(expr, 'alias', None) not in aliases
197             ]
198         return expressions
199 
200     def get_select(self):
201         """
202         Return three values:
203         - a list of 3-tuples of (expression, (sql, params), alias)
204         - a klass_info structure,
205         - a dictionary of annotations
206 
207         The (sql, params) is what the expression will produce, and alias is the
208         "AS alias" for the column (possibly None).
209 
210         The klass_info structure contains the following information:
211         - The base model of the query.
212         - Which columns for that model are present in the query (by
213           position of the select clause).
214         - related_klass_infos: [f, klass_info] to descent into
215 
216         The annotations is a dictionary of {'attname': column position} values.
217         """
218         select = []
219         klass_info = None
220         annotations = {}
221         select_idx = 0
222         for alias, (sql, params) in self.query.extra_select.items():
223             annotations[alias] = select_idx
224             select.append((RawSQL(sql, params), alias))
225             select_idx += 1
226         assert not (self.query.select and self.query.default_cols)
227         if self.query.default_cols:
228             cols = self.get_default_columns()
229         else:
230             # self.query.select is a special case. These columns never go to
231             # any model.
232             cols = self.query.select
233         if cols:
234             select_list = []
235             for col in cols:
236                 select_list.append(select_idx)
237                 select.append((col, None))
238                 select_idx += 1
239             klass_info = {
240                 'model': self.query.model,
241                 'select_fields': select_list,
242             }
243         for alias, annotation in self.query.annotation_select.items():
244             annotations[alias] = select_idx
245             select.append((annotation, alias))
246             select_idx += 1
247 
248         if self.query.select_related:
249             related_klass_infos = self.get_related_selections(select)
250             klass_info['related_klass_infos'] = related_klass_infos
251 
252             def get_select_from_parent(klass_info):
253                 for ki in klass_info['related_klass_infos']:
254                     if ki['from_parent']:
255                         ki['select_fields'] = (klass_info['select_fields'] +
256                                                ki['select_fields'])
257                     get_select_from_parent(ki)
258             get_select_from_parent(klass_info)
259 
260         ret = []
261         for col, alias in select:
262             try:
263                 sql, params = self.compile(col)
264             except EmptyResultSet:
265                 # Select a predicate that's always False.
266                 sql, params = '0', ()
267             else:
268                 sql, params = col.select_format(self, sql, params)
269             ret.append((col, (sql, params), alias))
270         return ret, klass_info, annotations
271 
272     def _order_by_pairs(self):
273         if self.query.extra_order_by:
274             ordering = self.query.extra_order_by
275         elif not self.query.default_ordering:
276             ordering = self.query.order_by
277         elif self.query.order_by:
278             ordering = self.query.order_by
279         elif self.query.get_meta().ordering:
280             ordering = self.query.get_meta().ordering
281             self._meta_ordering = ordering
282         else:
283             ordering = []
284         if self.query.standard_ordering:
285             default_order, _ = ORDER_DIR['ASC']
286         else:
287             default_order, _ = ORDER_DIR['DESC']
288 
289         for field in ordering:
290             if hasattr(field, 'resolve_expression'):
291                 if isinstance(field, Value):
292                     # output_field must be resolved for constants.
293                     field = Cast(field, field.output_field)
294                 if not isinstance(field, OrderBy):
295                     field = field.asc()
296                 if not self.query.standard_ordering:
297                     field = field.copy()
298                     field.reverse_ordering()
299                 yield field, False
300                 continue
301             if field == '?':  # random
302                 yield OrderBy(Random()), False
303                 continue
304 
305             col, order = get_order_dir(field, default_order)
306             descending = order == 'DESC'
307 
308             if col in self.query.annotation_select:
309                 # Reference to expression in SELECT clause
310                 yield (
311                     OrderBy(
312                         Ref(col, self.query.annotation_select[col]),
313                         descending=descending,
314                     ),
315                     True,
316                 )
317                 continue
318             if col in self.query.annotations:
319                 # References to an expression which is masked out of the SELECT
320                 # clause.
321                 if self.query.combinator and self.select:
322                     # Don't use the resolved annotation because other
323                     # combinated queries might define it differently.
324                     expr = F(col)
325                 else:
326                     expr = self.query.annotations[col]
327                     if isinstance(expr, Value):
328                         # output_field must be resolved for constants.
329                         expr = Cast(expr, expr.output_field)
330                 yield OrderBy(expr, descending=descending), False
331                 continue
332 
333             if '.' in field:
334                 # This came in through an extra(order_by=...) addition. Pass it
335                 # on verbatim.
336                 table, col = col.split('.', 1)
337                 yield (
338                     OrderBy(
339                         RawSQL('%s.%s' % (self.quote_name_unless_alias(table), col), []),
340                         descending=descending,
341                     ),
342                     False,
343                 )
344                 continue
345 
346             if self.query.extra and col in self.query.extra:
347                 if col in self.query.extra_select:
348                     yield (
349                         OrderBy(Ref(col, RawSQL(*self.query.extra[col])), descending=descending),
350                         True,
351                     )
352                 else:
353                     yield (
354                         OrderBy(RawSQL(*self.query.extra[col]), descending=descending),
355                         False,
356                     )
357             else:
358                 if self.query.combinator and self.select:
359                     # Don't use the first model's field because other
360                     # combinated queries might define it differently.
361                     yield OrderBy(F(col), descending=descending), False
362                 else:
363                     # 'col' is of the form 'field' or 'field1__field2' or
364                     # '-field1__field2__field', etc.
365                     yield from self.find_ordering_name(
366                         field, self.query.get_meta(), default_order=default_order,
367                     )
368 
369     def get_order_by(self):
370         """
371         Return a list of 2-tuples of the form (expr, (sql, params, is_ref)) for
372         the ORDER BY clause.
373 
374         The order_by clause can alter the select clause (for example it can add
375         aliases to clauses that do not yet have one, or it can add totally new
376         select clauses).
377         """
378         result = []
379         seen = set()
380 
381         for expr, is_ref in self._order_by_pairs():
382             resolved = expr.resolve_expression(self.query, allow_joins=True, reuse=None)
383             if self.query.combinator and self.select:
384                 src = resolved.get_source_expressions()[0]
385                 expr_src = expr.get_source_expressions()[0]
386                 # Relabel order by columns to raw numbers if this is a combined
387                 # query; necessary since the columns can't be referenced by the
388                 # fully qualified name and the simple column names may collide.
389                 for idx, (sel_expr, _, col_alias) in enumerate(self.select):
390                     if is_ref and col_alias == src.refs:
391                         src = src.source
392                     elif col_alias and not (
393                         isinstance(expr_src, F) and col_alias == expr_src.name
394                     ):
395                         continue
396                     if src == sel_expr:
397                         resolved.set_source_expressions([RawSQL('%d' % (idx + 1), ())])
398                         break
399                 else:
400                     if col_alias:
401                         raise DatabaseError('ORDER BY term does not match any column in the result set.')
402                     # Add column used in ORDER BY clause to the selected
403                     # columns and to each combined query.
404                     order_by_idx = len(self.query.select) + 1
405                     col_name = f'__orderbycol{order_by_idx}'
406                     for q in self.query.combined_queries:
407                         q.add_annotation(expr_src, col_name)
408                     self.query.add_select_col(resolved, col_name)
409                     resolved.set_source_expressions([RawSQL(f'{order_by_idx}', ())])
410             sql, params = self.compile(resolved)
411             # Don't add the same column twice, but the order direction is
412             # not taken into account so we strip it. When this entire method
413             # is refactored into expressions, then we can check each part as we
414             # generate it.
415             without_ordering = self.ordering_parts.search(sql)[1]
416             params_hash = make_hashable(params)
417             if (without_ordering, params_hash) in seen:
418                 continue
419             seen.add((without_ordering, params_hash))
420             result.append((resolved, (sql, params, is_ref)))
421         return result
422 
423     def get_extra_select(self, order_by, select):
424         extra_select = []
425         if self.query.distinct and not self.query.distinct_fields:
426             select_sql = [t[1] for t in select]
427             for expr, (sql, params, is_ref) in order_by:
428                 without_ordering = self.ordering_parts.search(sql)[1]
429                 if not is_ref and (without_ordering, params) not in select_sql:
430                     extra_select.append((expr, (without_ordering, params), None))
431         return extra_select
432 
433     def quote_name_unless_alias(self, name):
434         """
435         A wrapper around connection.ops.quote_name that doesn't quote aliases
436         for table names. This avoids problems with some SQL dialects that treat
437         quoted strings specially (e.g. PostgreSQL).
438         """
439         if name in self.quote_cache:
440             return self.quote_cache[name]
441         if ((name in self.query.alias_map and name not in self.query.table_map) or
442                 name in self.query.extra_select or (
443                     self.query.external_aliases.get(name) and name not in self.query.table_map)):
444             self.quote_cache[name] = name
445             return name
446         r = self.connection.ops.quote_name(name)
447         self.quote_cache[name] = r
448         return r
449 
450     def compile(self, node):
451         vendor_impl = getattr(node, 'as_' + self.connection.vendor, None)
452         if vendor_impl:
453             sql, params = vendor_impl(self, self.connection)
454         else:
455             sql, params = node.as_sql(self, self.connection)
456         return sql, params
457 
458     def get_combinator_sql(self, combinator, all):
459         features = self.connection.features
460         compilers = [
461             query.get_compiler(self.using, self.connection)
462             for query in self.query.combined_queries if not query.is_empty()
463         ]
464         if not features.supports_slicing_ordering_in_compound:
465             for query, compiler in zip(self.query.combined_queries, compilers):
466                 if query.low_mark or query.high_mark:
467                     raise DatabaseError('LIMIT/OFFSET not allowed in subqueries of compound statements.')
468                 if compiler.get_order_by():
469                     raise DatabaseError('ORDER BY not allowed in subqueries of compound statements.')
470         parts = ()
471         for compiler in compilers:
472             try:
473                 # If the columns list is limited, then all combined queries
474                 # must have the same columns list. Set the selects defined on
475                 # the query on all combined queries, if not already set.
476                 if not compiler.query.values_select and self.query.values_select:
477                     compiler.query = compiler.query.clone()
478                     compiler.query.set_values((
479                         *self.query.extra_select,
480                         *self.query.values_select,
481                         *self.query.annotation_select,
482                     ))
483                 part_sql, part_args = compiler.as_sql()
484                 if compiler.query.combinator:
485                     # Wrap in a subquery if wrapping in parentheses isn't
486                     # supported.
487                     if not features.supports_parentheses_in_compound:
488                         part_sql = 'SELECT * FROM ({})'.format(part_sql)
489                     # Add parentheses when combining with compound query if not
490                     # already added for all compound queries.
491                     elif not features.supports_slicing_ordering_in_compound:
492                         part_sql = '({})'.format(part_sql)
493                 parts += ((part_sql, part_args),)
494             except EmptyResultSet:
495                 # Omit the empty queryset with UNION and with DIFFERENCE if the
496                 # first queryset is nonempty.
497                 if combinator == 'union' or (combinator == 'difference' and parts):
498                     continue
499                 raise
500         if not parts:
501             raise EmptyResultSet
502         combinator_sql = self.connection.ops.set_operators[combinator]
503         if all and combinator == 'union':
504             combinator_sql += ' ALL'
505         braces = '({})' if features.supports_slicing_ordering_in_compound else '{}'
506         sql_parts, args_parts = zip(*((braces.format(sql), args) for sql, args in parts))
507         result = [' {} '.format(combinator_sql).join(sql_parts)]
508         params = []
509         for part in args_parts:
510             params.extend(part)
511         return result, params
512 
513     def as_sql(self, with_limits=True, with_col_aliases=False):
514         """
515         Create the SQL for this query. Return the SQL string and list of
516         parameters.
517 
518         If 'with_limits' is False, any limit/offset information is not included
519         in the query.
520         """
521         refcounts_before = self.query.alias_refcount.copy()
522         try:
523             extra_select, order_by, group_by = self.pre_sql_setup()
524             for_update_part = None
525             # Is a LIMIT/OFFSET clause needed?
526             with_limit_offset = with_limits and (self.query.high_mark is not None or self.query.low_mark)
527             combinator = self.query.combinator
528             features = self.connection.features
529             if combinator:
530                 if not getattr(features, 'supports_select_{}'.format(combinator)):
531                     raise NotSupportedError('{} is not supported on this database backend.'.format(combinator))
532                 result, params = self.get_combinator_sql(combinator, self.query.combinator_all)
533             else:
534                 distinct_fields, distinct_params = self.get_distinct()
535                 # This must come after 'select', 'ordering', and 'distinct'
536                 # (see docstring of get_from_clause() for details).
537                 from_, f_params = self.get_from_clause()
538                 where, w_params = self.compile(self.where) if self.where is not None else ("", [])
539                 having, h_params = self.compile(self.having) if self.having is not None else ("", [])
540                 result = ['SELECT']
541                 params = []
542 
543                 if self.query.distinct:
544                     distinct_result, distinct_params = self.connection.ops.distinct_sql(
545                         distinct_fields,
546                         distinct_params,
547                     )
548                     result += distinct_result
549                     params += distinct_params
550 
551                 out_cols = []
552                 col_idx = 1
553                 for _, (s_sql, s_params), alias in self.select + extra_select:
554                     if alias:
555                         s_sql = '%s AS %s' % (s_sql, self.connection.ops.quote_name(alias))
556                     elif with_col_aliases:
557                         s_sql = '%s AS %s' % (
558                             s_sql,
559                             self.connection.ops.quote_name('col%d' % col_idx),
560                         )
561                         col_idx += 1
562                     params.extend(s_params)
563                     out_cols.append(s_sql)
564 
565                 result += [', '.join(out_cols), 'FROM', *from_]
566                 params.extend(f_params)
567 
568                 if self.query.select_for_update and self.connection.features.has_select_for_update:
569                     if self.connection.get_autocommit():
570                         raise TransactionManagementError('select_for_update cannot be used outside of a transaction.')
571 
572                     if with_limit_offset and not self.connection.features.supports_select_for_update_with_limit:
573                         raise NotSupportedError(
574                             'LIMIT/OFFSET is not supported with '
575                             'select_for_update on this database backend.'
576                         )
577                     nowait = self.query.select_for_update_nowait
578                     skip_locked = self.query.select_for_update_skip_locked
579                     of = self.query.select_for_update_of
580                     no_key = self.query.select_for_no_key_update
581                     # If it's a NOWAIT/SKIP LOCKED/OF/NO KEY query but the
582                     # backend doesn't support it, raise NotSupportedError to
583                     # prevent a possible deadlock.
584                     if nowait and not self.connection.features.has_select_for_update_nowait:
585                         raise NotSupportedError('NOWAIT is not supported on this database backend.')
586                     elif skip_locked and not self.connection.features.has_select_for_update_skip_locked:
587                         raise NotSupportedError('SKIP LOCKED is not supported on this database backend.')
588                     elif of and not self.connection.features.has_select_for_update_of:
589                         raise NotSupportedError('FOR UPDATE OF is not supported on this database backend.')
590                     elif no_key and not self.connection.features.has_select_for_no_key_update:
591                         raise NotSupportedError(
592                             'FOR NO KEY UPDATE is not supported on this '
593                             'database backend.'
594                         )
595                     for_update_part = self.connection.ops.for_update_sql(
596                         nowait=nowait,
597                         skip_locked=skip_locked,
598                         of=self.get_select_for_update_of_arguments(),
599                         no_key=no_key,
600                     )
601 
602                 if for_update_part and self.connection.features.for_update_after_from:
603                     result.append(for_update_part)
604 
605                 if where:
606                     result.append('WHERE %s' % where)
607                     params.extend(w_params)
608 
609                 grouping = []
610                 for g_sql, g_params in group_by:
611                     grouping.append(g_sql)
612                     params.extend(g_params)
613                 if grouping:
614                     if distinct_fields:
615                         raise NotImplementedError('annotate() + distinct(fields) is not implemented.')
616                     order_by = order_by or self.connection.ops.force_no_ordering()
617                     result.append('GROUP BY %s' % ', '.join(grouping))
618                     if self._meta_ordering:
619                         order_by = None
620                 if having:
621                     result.append('HAVING %s' % having)
622                     params.extend(h_params)
623 
624             if self.query.explain_query:
625                 result.insert(0, self.connection.ops.explain_query_prefix(
626                     self.query.explain_format,
627                     **self.query.explain_options
628                 ))
629 
630             if order_by:
631                 ordering = []
632                 for _, (o_sql, o_params, _) in order_by:
633                     ordering.append(o_sql)
634                     params.extend(o_params)
635                 result.append('ORDER BY %s' % ', '.join(ordering))
636 
637             if with_limit_offset:
638                 result.append(self.connection.ops.limit_offset_sql(self.query.low_mark, self.query.high_mark))
639 
640             if for_update_part and not self.connection.features.for_update_after_from:
641                 result.append(for_update_part)
642 
643             if self.query.subquery and extra_select:
644                 # If the query is used as a subquery, the extra selects would
645                 # result in more columns than the left-hand side expression is
646                 # expecting. This can happen when a subquery uses a combination
647                 # of order_by() and distinct(), forcing the ordering expressions
648                 # to be selected as well. Wrap the query in another subquery
649                 # to exclude extraneous selects.
650                 sub_selects = []
651                 sub_params = []
652                 for index, (select, _, alias) in enumerate(self.select, start=1):
653                     if not alias and with_col_aliases:
654                         alias = 'col%d' % index
655                     if alias:
656                         sub_selects.append("%s.%s" % (
657                             self.connection.ops.quote_name('subquery'),
658                             self.connection.ops.quote_name(alias),
659                         ))
660                     else:
661                         select_clone = select.relabeled_clone({select.alias: 'subquery'})
662                         subselect, subparams = select_clone.as_sql(self, self.connection)
663                         sub_selects.append(subselect)
664                         sub_params.extend(subparams)
665                 return 'SELECT %s FROM (%s) subquery' % (
666                     ', '.join(sub_selects),
667                     ' '.join(result),
668                 ), tuple(sub_params + params)
669 
670             return ' '.join(result), tuple(params)
671         finally:
672             # Finally do cleanup - get rid of the joins we created above.
673             self.query.reset_refcounts(refcounts_before)
674 
675     def get_default_columns(self, start_alias=None, opts=None, from_parent=None):
676         """
677         Compute the default columns for selecting every field in the base
678         model. Will sometimes be called to pull in related models (e.g. via
679         select_related), in which case "opts" and "start_alias" will be given
680         to provide a starting point for the traversal.
681 
682         Return a list of strings, quoted appropriately for use in SQL
683         directly, as well as a set of aliases used in the select statement (if
684         'as_pairs' is True, return a list of (alias, col_name) pairs instead
685         of strings as the first component and None as the second component).
686         """
687         result = []
688         if opts is None:
689             opts = self.query.get_meta()
690         only_load = self.deferred_to_columns()
691         start_alias = start_alias or self.query.get_initial_alias()
692         # The 'seen_models' is used to optimize checking the needed parent
693         # alias for a given field. This also includes None -> start_alias to
694         # be used by local fields.
695         seen_models = {None: start_alias}
696 
697         for field in opts.concrete_fields:
698             model = field.model._meta.concrete_model
699             # A proxy model will have a different model and concrete_model. We
700             # will assign None if the field belongs to this model.
701             if model == opts.model:
702                 model = None
703             if from_parent and model is not None and issubclass(
704                     from_parent._meta.concrete_model, model._meta.concrete_model):
705                 # Avoid loading data for already loaded parents.
706                 # We end up here in the case select_related() resolution
707                 # proceeds from parent model to child model. In that case the
708                 # parent model data is already present in the SELECT clause,
709                 # and we want to avoid reloading the same data again.
710                 continue
711             if field.model in only_load and field.attname not in only_load[field.model]:
712                 continue
713             alias = self.query.join_parent_model(opts, model, start_alias,
714                                                  seen_models)
715             column = field.get_col(alias)
716             result.append(column)
717         return result
718 
719     def get_distinct(self):
720         """
721         Return a quoted list of fields to use in DISTINCT ON part of the query.
722 
723         This method can alter the tables in the query, and thus it must be
724         called before get_from_clause().
725         """
726         result = []
727         params = []
728         opts = self.query.get_meta()
729 
730         for name in self.query.distinct_fields:
731             parts = name.split(LOOKUP_SEP)
732             _, targets, alias, joins, path, _, transform_function = self._setup_joins(parts, opts, None)
733             targets, alias, _ = self.query.trim_joins(targets, joins, path)
734             for target in targets:
735                 if name in self.query.annotation_select:
736                     result.append(name)
737                 else:
738                     r, p = self.compile(transform_function(target, alias))
739                     result.append(r)
740                     params.append(p)
741         return result, params
742 
743     def find_ordering_name(self, name, opts, alias=None, default_order='ASC',
744                            already_seen=None):
745         """
746         Return the table alias (the name might be ambiguous, the alias will
747         not be) and column name for ordering by the given 'name' parameter.
748         The 'name' is of the form 'field1__field2__...__fieldN'.
749         """
750         name, order = get_order_dir(name, default_order)
751         descending = order == 'DESC'
752         pieces = name.split(LOOKUP_SEP)
753         field, targets, alias, joins, path, opts, transform_function = self._setup_joins(pieces, opts, alias)
754 
755         # If we get to this point and the field is a relation to another model,
756         # append the default ordering for that model unless it is the pk
757         # shortcut or the attribute name of the field that is specified.
758         if (
759             field.is_relation and
760             opts.ordering and
761             getattr(field, 'attname', None) != pieces[-1] and
762             name != 'pk'
763         ):
764             # Firstly, avoid infinite loops.
765             already_seen = already_seen or set()
766             join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)
767             if join_tuple in already_seen:
768                 raise FieldError('Infinite loop caused by ordering.')
769             already_seen.add(join_tuple)
770 
771             results = []
772             for item in opts.ordering:
773                 if hasattr(item, 'resolve_expression') and not isinstance(item, OrderBy):
774                     item = item.desc() if descending else item.asc()
775                 if isinstance(item, OrderBy):
776                     results.append((item, False))
777                     continue
778                 results.extend(self.find_ordering_name(item, opts, alias,
779                                                        order, already_seen))
780             return results
781         targets, alias, _ = self.query.trim_joins(targets, joins, path)
782         return [(OrderBy(transform_function(t, alias), descending=descending), False) for t in targets]
783 
784     def _setup_joins(self, pieces, opts, alias):
785         """
786         Helper method for get_order_by() and get_distinct().
787 
788         get_ordering() and get_distinct() must produce same target columns on
789         same input, as the prefixes of get_ordering() and get_distinct() must
790         match. Executing SQL where this is not true is an error.
791         """
792         alias = alias or self.query.get_initial_alias()
793         field, targets, opts, joins, path, transform_function = self.query.setup_joins(pieces, opts, alias)
794         alias = joins[-1]
795         return field, targets, alias, joins, path, opts, transform_function
796 
797     def get_from_clause(self):
798         """
799         Return a list of strings that are joined together to go after the
800         "FROM" part of the query, as well as a list any extra parameters that
801         need to be included. Subclasses, can override this to create a
802         from-clause via a "select".
803 
804         This should only be called after any SQL construction methods that
805         might change the tables that are needed. This means the select columns,
806         ordering, and distinct must be done first.
807         """
808         result = []
809         params = []
810         for alias in tuple(self.query.alias_map):
811             if not self.query.alias_refcount[alias]:
812                 continue
813             try:
814                 from_clause = self.query.alias_map[alias]
815             except KeyError:
816                 # Extra tables can end up in self.tables, but not in the
817                 # alias_map if they aren't in a join. That's OK. We skip them.
818                 continue
819             clause_sql, clause_params = self.compile(from_clause)
820             result.append(clause_sql)
821             params.extend(clause_params)
822         for t in self.query.extra_tables:
823             alias, _ = self.query.table_alias(t)
824             # Only add the alias if it's not already present (the table_alias()
825             # call increments the refcount, so an alias refcount of one means
826             # this is the only reference).
827             if alias not in self.query.alias_map or self.query.alias_refcount[alias] == 1:
828                 result.append(', %s' % self.quote_name_unless_alias(alias))
829         return result, params
830 
831     def get_related_selections(self, select, opts=None, root_alias=None, cur_depth=1,
832                                requested=None, restricted=None):
833         """
834         Fill in the information needed for a select_related query. The current
835         depth is measured as the number of connections away from the root model
836         (for example, cur_depth=1 means we are looking at models with direct
837         connections to the root model).
838         """
839         def _get_field_choices():
840             direct_choices = (f.name for f in opts.fields if f.is_relation)
841             reverse_choices = (
842                 f.field.related_query_name()
843                 for f in opts.related_objects if f.field.unique
844             )
845             return chain(direct_choices, reverse_choices, self.query._filtered_relations)
846 
847         related_klass_infos = []
848         if not restricted and cur_depth > self.query.max_depth:
849             # We've recursed far enough; bail out.
850             return related_klass_infos
851 
852         if not opts:
853             opts = self.query.get_meta()
854             root_alias = self.query.get_initial_alias()
855         only_load = self.query.get_loaded_field_names()
856 
857         # Setup for the case when only particular related fields should be
858         # included in the related selection.
859         fields_found = set()
860         if requested is None:
861             restricted = isinstance(self.query.select_related, dict)
862             if restricted:
863                 requested = self.query.select_related
864 
865         def get_related_klass_infos(klass_info, related_klass_infos):
866             klass_info['related_klass_infos'] = related_klass_infos
867 
868         for f in opts.fields:
869             field_model = f.model._meta.concrete_model
870             fields_found.add(f.name)
871 
872             if restricted:
873                 next = requested.get(f.name, {})
874                 if not f.is_relation:
875                     # If a non-related field is used like a relation,
876                     # or if a single non-relational field is given.
877                     if next or f.name in requested:
878                         raise FieldError(
879                             "Non-relational field given in select_related: '%s'. "
880                             "Choices are: %s" % (
881                                 f.name,
882                                 ", ".join(_get_field_choices()) or '(none)',
883                             )
884                         )
885             else:
886                 next = False
887 
888             if not select_related_descend(f, restricted, requested,
889                                           only_load.get(field_model)):
890                 continue
891             klass_info = {
892                 'model': f.remote_field.model,
893                 'field': f,
894                 'reverse': False,
895                 'local_setter': f.set_cached_value,
896                 'remote_setter': f.remote_field.set_cached_value if f.unique else lambda x, y: None,
897                 'from_parent': False,
898             }
899             related_klass_infos.append(klass_info)
900             select_fields = []
901             _, _, _, joins, _, _ = self.query.setup_joins(
902                 [f.name], opts, root_alias)
903             alias = joins[-1]
904             columns = self.get_default_columns(start_alias=alias, opts=f.remote_field.model._meta)
905             for col in columns:
906                 select_fields.append(len(select))
907                 select.append((col, None))
908             klass_info['select_fields'] = select_fields
909             next_klass_infos = self.get_related_selections(
910                 select, f.remote_field.model._meta, alias, cur_depth + 1, next, restricted)
911             get_related_klass_infos(klass_info, next_klass_infos)
912 
913         if restricted:
914             related_fields = [
915                 (o.field, o.related_model)
916                 for o in opts.related_objects
917                 if o.field.unique and not o.many_to_many
918             ]
919             for f, model in related_fields:
920                 if not select_related_descend(f, restricted, requested,
921                                               only_load.get(model), reverse=True):
922                     continue
923 
924                 related_field_name = f.related_query_name()
925                 fields_found.add(related_field_name)
926 
927                 join_info = self.query.setup_joins([related_field_name], opts, root_alias)
928                 alias = join_info.joins[-1]
929                 from_parent = issubclass(model, opts.model) and model is not opts.model
930                 klass_info = {
931                     'model': model,
932                     'field': f,
933                     'reverse': True,
934                     'local_setter': f.remote_field.set_cached_value,
935                     'remote_setter': f.set_cached_value,
936                     'from_parent': from_parent,
937                 }
938                 related_klass_infos.append(klass_info)
939                 select_fields = []
940                 columns = self.get_default_columns(
941                     start_alias=alias, opts=model._meta, from_parent=opts.model)
942                 for col in columns:
943                     select_fields.append(len(select))
944                     select.append((col, None))
945                 klass_info['select_fields'] = select_fields
946                 next = requested.get(f.related_query_name(), {})
947                 next_klass_infos = self.get_related_selections(
948                     select, model._meta, alias, cur_depth + 1,
949                     next, restricted)
950                 get_related_klass_infos(klass_info, next_klass_infos)
951 
952             def local_setter(obj, from_obj):
953                 # Set a reverse fk object when relation is non-empty.
954                 if from_obj:
955                     f.remote_field.set_cached_value(from_obj, obj)
956 
957             def remote_setter(name, obj, from_obj):
958                 setattr(from_obj, name, obj)
959 
960             for name in list(requested):
961                 # Filtered relations work only on the topmost level.
962                 if cur_depth > 1:
963                     break
964                 if name in self.query._filtered_relations:
965                     fields_found.add(name)
966                     f, _, join_opts, joins, _, _ = self.query.setup_joins([name], opts, root_alias)
967                     model = join_opts.model
968                     alias = joins[-1]
969                     from_parent = issubclass(model, opts.model) and model is not opts.model
970                     klass_info = {
971                         'model': model,
972                         'field': f,
973                         'reverse': True,
974                         'local_setter': local_setter,
975                         'remote_setter': partial(remote_setter, name),
976                         'from_parent': from_parent,
977                     }
978                     related_klass_infos.append(klass_info)
979                     select_fields = []
980                     columns = self.get_default_columns(
981                         start_alias=alias, opts=model._meta,
982                         from_parent=opts.model,
983                     )
984                     for col in columns:
985                         select_fields.append(len(select))
986                         select.append((col, None))
987                     klass_info['select_fields'] = select_fields
988                     next_requested = requested.get(name, {})
989                     next_klass_infos = self.get_related_selections(
990                         select, opts=model._meta, root_alias=alias,
991                         cur_depth=cur_depth + 1, requested=next_requested,
992                         restricted=restricted,
993                     )
994                     get_related_klass_infos(klass_info, next_klass_infos)
995             fields_not_found = set(requested).difference(fields_found)
996             if fields_not_found:
997                 invalid_fields = ("'%s'" % s for s in fields_not_found)
998                 raise FieldError(
999                     'Invalid field name(s) given in select_related: %s. '
1000                     'Choices are: %s' % (
1001                         ', '.join(invalid_fields),
1002                         ', '.join(_get_field_choices()) or '(none)',
1003                     )
1004                 )
1005         return related_klass_infos
1006 
1007     def get_select_for_update_of_arguments(self):
1008         """
1009         Return a quoted list of arguments for the SELECT FOR UPDATE OF part of
1010         the query.
1011         """
1012         def _get_parent_klass_info(klass_info):
1013             concrete_model = klass_info['model']._meta.concrete_model
1014             for parent_model, parent_link in concrete_model._meta.parents.items():
1015                 parent_list = parent_model._meta.get_parent_list()
1016                 yield {
1017                     'model': parent_model,
1018                     'field': parent_link,
1019                     'reverse': False,
1020                     'select_fields': [
1021                         select_index
1022                         for select_index in klass_info['select_fields']
1023                         # Selected columns from a model or its parents.
1024                         if (
1025                             self.select[select_index][0].target.model == parent_model or
1026                             self.select[select_index][0].target.model in parent_list
1027                         )
1028                     ],
1029                 }
1030 
1031         def _get_first_selected_col_from_model(klass_info):
1032             """
1033             Find the first selected column from a model. If it doesn't exist,
1034             don't lock a model.
1035 
1036             select_fields is filled recursively, so it also contains fields
1037             from the parent models.
1038             """
1039             concrete_model = klass_info['model']._meta.concrete_model
1040             for select_index in klass_info['select_fields']:
1041                 if self.select[select_index][0].target.model == concrete_model:
1042                     return self.select[select_index][0]
1043 
1044         def _get_field_choices():
1045             """Yield all allowed field paths in breadth-first search order."""
1046             queue = collections.deque([(None, self.klass_info)])
1047             while queue:
1048                 parent_path, klass_info = queue.popleft()
1049                 if parent_path is None:
1050                     path = []
1051                     yield 'self'
1052                 else:
1053                     field = klass_info['field']
1054                     if klass_info['reverse']:
1055                         field = field.remote_field
1056                     path = parent_path + [field.name]
1057                     yield LOOKUP_SEP.join(path)
1058                 queue.extend(
1059                     (path, klass_info)
1060                     for klass_info in _get_parent_klass_info(klass_info)
1061                 )
1062                 queue.extend(
1063                     (path, klass_info)
1064                     for klass_info in klass_info.get('related_klass_infos', [])
1065                 )
1066         result = []
1067         invalid_names = []
1068         for name in self.query.select_for_update_of:
1069             klass_info = self.klass_info
1070             if name == 'self':
1071                 col = _get_first_selected_col_from_model(klass_info)
1072             else:
1073                 for part in name.split(LOOKUP_SEP):
1074                     klass_infos = (
1075                         *klass_info.get('related_klass_infos', []),
1076                         *_get_parent_klass_info(klass_info),
1077                     )
1078                     for related_klass_info in klass_infos:
1079                         field = related_klass_info['field']
1080                         if related_klass_info['reverse']:
1081                             field = field.remote_field
1082                         if field.name == part:
1083                             klass_info = related_klass_info
1084                             break
1085                     else:
1086                         klass_info = None
1087                         break
1088                 if klass_info is None:
1089                     invalid_names.append(name)
1090                     continue
1091                 col = _get_first_selected_col_from_model(klass_info)
1092             if col is not None:
1093                 if self.connection.features.select_for_update_of_column:
1094                     result.append(self.compile(col)[0])
1095                 else:
1096                     result.append(self.quote_name_unless_alias(col.alias))
1097         if invalid_names:
1098             raise FieldError(
1099                 'Invalid field name(s) given in select_for_update(of=(...)): %s. '
1100                 'Only relational fields followed in the query are allowed. '
1101                 'Choices are: %s.' % (
1102                     ', '.join(invalid_names),
1103                     ', '.join(_get_field_choices()),
1104                 )
1105             )
1106         return result
1107 
1108     def deferred_to_columns(self):
1109         """
1110         Convert the self.deferred_loading data structure to mapping of table
1111         names to sets of column names which are to be loaded. Return the
1112         dictionary.
1113         """
1114         columns = {}
1115         self.query.deferred_to_data(columns, self.query.get_loaded_field_names_cb)
1116         return columns
1117 
1118     def get_converters(self, expressions):
1119         converters = {}
1120         for i, expression in enumerate(expressions):
1121             if expression:
1122                 backend_converters = self.connection.ops.get_db_converters(expression)
1123                 field_converters = expression.get_db_converters(self.connection)
1124                 if backend_converters or field_converters:
1125                     converters[i] = (backend_converters + field_converters, expression)
1126         return converters
1127 
1128     def apply_converters(self, rows, converters):
1129         connection = self.connection
1130         converters = list(converters.items())
1131         for row in map(list, rows):
1132             for pos, (convs, expression) in converters:
1133                 value = row[pos]
1134                 for converter in convs:
1135                     value = converter(value, expression, connection)
1136                 row[pos] = value
1137             yield row
1138 
1139     def results_iter(self, results=None, tuple_expected=False, chunked_fetch=False,
1140                      chunk_size=GET_ITERATOR_CHUNK_SIZE):
1141         """Return an iterator over the results from executing this query."""
1142         if results is None:
1143             results = self.execute_sql(MULTI, chunked_fetch=chunked_fetch, chunk_size=chunk_size)
1144         fields = [s[0] for s in self.select[0:self.col_count]]
1145         converters = self.get_converters(fields)
1146         rows = chain.from_iterable(results)
1147         if converters:
1148             rows = self.apply_converters(rows, converters)
1149             if tuple_expected:
1150                 rows = map(tuple, rows)
1151         return rows
1152 
1153     def has_results(self):
1154         """
1155         Backends (e.g. NoSQL) can override this in order to use optimized
1156         versions of "query has any results."
1157         """
1158         return bool(self.execute_sql(SINGLE))
1159 
1160     def execute_sql(self, result_type=MULTI, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE):
1161         """
1162         Run the query against the database and return the result(s). The
1163         return value is a single data item if result_type is SINGLE, or an
1164         iterator over the results if the result_type is MULTI.
1165 
1166         result_type is either MULTI (use fetchmany() to retrieve all rows),
1167         SINGLE (only retrieve a single row), or None. In this last case, the
1168         cursor is returned if any query is executed, since it's used by
1169         subclasses such as InsertQuery). It's possible, however, that no query
1170         is needed, as the filters describe an empty set. In that case, None is
1171         returned, to avoid any unnecessary database interaction.
1172         """
1173         result_type = result_type or NO_RESULTS
1174         try:
1175             sql, params = self.as_sql()
1176             if not sql:
1177                 raise EmptyResultSet
1178         except EmptyResultSet:
1179             if result_type == MULTI:
1180                 return iter([])
1181             else:
1182                 return
1183         if chunked_fetch:
1184             cursor = self.connection.chunked_cursor()
1185         else:
1186             cursor = self.connection.cursor()
1187         try:
1188             cursor.execute(sql, params)
1189         except Exception:
1190             # Might fail for server-side cursors (e.g. connection closed)
1191             cursor.close()
1192             raise
1193 
1194         if result_type == CURSOR:
1195             # Give the caller the cursor to process and close.
1196             return cursor
1197         if result_type == SINGLE:
1198             try:
1199                 val = cursor.fetchone()
1200                 if val:
1201                     return val[0:self.col_count]
1202                 return val
1203             finally:
1204                 # done with the cursor
1205                 cursor.close()
1206         if result_type == NO_RESULTS:
1207             cursor.close()
1208             return
1209 
1210         result = cursor_iter(
1211             cursor, self.connection.features.empty_fetchmany_value,
1212             self.col_count if self.has_extra_select else None,
1213             chunk_size,
1214         )
1215         if not chunked_fetch or not self.connection.features.can_use_chunked_reads:
1216             try:
1217                 # If we are using non-chunked reads, we return the same data
1218                 # structure as normally, but ensure it is all read into memory
1219                 # before going any further. Use chunked_fetch if requested,
1220                 # unless the database doesn't support it.
1221                 return list(result)
1222             finally:
1223                 # done with the cursor
1224                 cursor.close()
1225         return result
1226 
1227     def as_subquery_condition(self, alias, columns, compiler):
1228         qn = compiler.quote_name_unless_alias
1229         qn2 = self.connection.ops.quote_name
1230 
1231         for index, select_col in enumerate(self.query.select):
1232             lhs_sql, lhs_params = self.compile(select_col)
1233             rhs = '%s.%s' % (qn(alias), qn2(columns[index]))
1234             self.query.where.add(
1235                 RawSQL('%s = %s' % (lhs_sql, rhs), lhs_params), 'AND')
1236 
1237         sql, params = self.as_sql()
1238         return 'EXISTS (%s)' % sql, params
1239 
1240     def explain_query(self):
1241         result = list(self.execute_sql())
1242         # Some backends return 1 item tuples with strings, and others return
1243         # tuples with integers and strings. Flatten them out into strings.
1244         for row in result[0]:
1245             if not isinstance(row, str):
1246                 yield ' '.join(str(c) for c in row)
1247             else:
1248                 yield row
1249 
1250 
1251 class SQLInsertCompiler(SQLCompiler):
1252     returning_fields = None
1253     returning_params = tuple()
1254 
1255     def field_as_sql(self, field, val):
1256         """
1257         Take a field and a value intended to be saved on that field, and
1258         return placeholder SQL and accompanying params. Check for raw values,
1259         expressions, and fields with get_placeholder() defined in that order.
1260 
1261         When field is None, consider the value raw and use it as the
1262         placeholder, with no corresponding parameters returned.
1263         """
1264         if field is None:
1265             # A field value of None means the value is raw.
1266             sql, params = val, []
1267         elif hasattr(val, 'as_sql'):
1268             # This is an expression, let's compile it.
1269             sql, params = self.compile(val)
1270         elif hasattr(field, 'get_placeholder'):
1271             # Some fields (e.g. geo fields) need special munging before
1272             # they can be inserted.
1273             sql, params = field.get_placeholder(val, self, self.connection), [val]
1274         else:
1275             # Return the common case for the placeholder
1276             sql, params = '%s', [val]
1277 
1278         # The following hook is only used by Oracle Spatial, which sometimes
1279         # needs to yield 'NULL' and [] as its placeholder and params instead
1280         # of '%s' and [None]. The 'NULL' placeholder is produced earlier by
1281         # OracleOperations.get_geom_placeholder(). The following line removes
1282         # the corresponding None parameter. See ticket #10888.
1283         params = self.connection.ops.modify_insert_params(sql, params)
1284 
1285         return sql, params
1286 
1287     def prepare_value(self, field, value):
1288         """
1289         Prepare a value to be used in a query by resolving it if it is an
1290         expression and otherwise calling the field's get_db_prep_save().
1291         """
1292         if hasattr(value, 'resolve_expression'):
1293             value = value.resolve_expression(self.query, allow_joins=False, for_save=True)
1294             # Don't allow values containing Col expressions. They refer to
1295             # existing columns on a row, but in the case of insert the row
1296             # doesn't exist yet.
1297             if value.contains_column_references:
1298                 raise ValueError(
1299                     'Failed to insert expression "%s" on %s. F() expressions '
1300                     'can only be used to update, not to insert.' % (value, field)
1301                 )
1302             if value.contains_aggregate:
1303                 raise FieldError(
1304                     'Aggregate functions are not allowed in this query '
1305                     '(%s=%r).' % (field.name, value)
1306                 )
1307             if value.contains_over_clause:
1308                 raise FieldError(
1309                     'Window expressions are not allowed in this query (%s=%r).'
1310                     % (field.name, value)
1311                 )
1312         else:
1313             value = field.get_db_prep_save(value, connection=self.connection)
1314         return value
1315 
1316     def pre_save_val(self, field, obj):
1317         """
1318         Get the given field's value off the given obj. pre_save() is used for
1319         things like auto_now on DateTimeField. Skip it if this is a raw query.
1320         """
1321         if self.query.raw:
1322             return getattr(obj, field.attname)
1323         return field.pre_save(obj, add=True)
1324 
1325     def assemble_as_sql(self, fields, value_rows):
1326         """
1327         Take a sequence of N fields and a sequence of M rows of values, and
1328         generate placeholder SQL and parameters for each field and value.
1329         Return a pair containing:
1330          * a sequence of M rows of N SQL placeholder strings, and
1331          * a sequence of M rows of corresponding parameter values.
1332 
1333         Each placeholder string may contain any number of '%s' interpolation
1334         strings, and each parameter row will contain exactly as many params
1335         as the total number of '%s's in the corresponding placeholder row.
1336         """
1337         if not value_rows:
1338             return [], []
1339 
1340         # list of (sql, [params]) tuples for each object to be saved
1341         # Shape: [n_objs][n_fields][2]
1342         rows_of_fields_as_sql = (
1343             (self.field_as_sql(field, v) for field, v in zip(fields, row))
1344             for row in value_rows
1345         )
1346 
1347         # tuple like ([sqls], [[params]s]) for each object to be saved
1348         # Shape: [n_objs][2][n_fields]
1349         sql_and_param_pair_rows = (zip(*row) for row in rows_of_fields_as_sql)
1350 
1351         # Extract separate lists for placeholders and params.
1352         # Each of these has shape [n_objs][n_fields]
1353         placeholder_rows, param_rows = zip(*sql_and_param_pair_rows)
1354 
1355         # Params for each field are still lists, and need to be flattened.
1356         param_rows = [[p for ps in row for p in ps] for row in param_rows]
1357 
1358         return placeholder_rows, param_rows
1359 
1360     def as_sql(self):
1361         # We don't need quote_name_unless_alias() here, since these are all
1362         # going to be column names (so we can avoid the extra overhead).
1363         qn = self.connection.ops.quote_name
1364         opts = self.query.get_meta()
1365         insert_statement = self.connection.ops.insert_statement(ignore_conflicts=self.query.ignore_conflicts)
1366         result = ['%s %s' % (insert_statement, qn(opts.db_table))]
1367         fields = self.query.fields or [opts.pk]
1368         result.append('(%s)' % ', '.join(qn(f.column) for f in fields))
1369 
1370         if self.query.fields:
1371             value_rows = [
1372                 [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
1373                 for obj in self.query.objs
1374             ]
1375         else:
1376             # An empty object.
1377             value_rows = [[self.connection.ops.pk_default_value()] for _ in self.query.objs]
1378             fields = [None]
1379 
1380         # Currently the backends just accept values when generating bulk
1381         # queries and generate their own placeholders. Doing that isn't
1382         # necessary and it should be possible to use placeholders and
1383         # expressions in bulk inserts too.
1384         can_bulk = (not self.returning_fields and self.connection.features.has_bulk_insert)
1385 
1386         placeholder_rows, param_rows = self.assemble_as_sql(fields, value_rows)
1387 
1388         ignore_conflicts_suffix_sql = self.connection.ops.ignore_conflicts_suffix_sql(
1389             ignore_conflicts=self.query.ignore_conflicts
1390         )
1391         if self.returning_fields and self.connection.features.can_return_columns_from_insert:
1392             if self.connection.features.can_return_rows_from_bulk_insert:
1393                 result.append(self.connection.ops.bulk_insert_sql(fields, placeholder_rows))
1394                 params = param_rows
1395             else:
1396                 result.append("VALUES (%s)" % ", ".join(placeholder_rows[0]))
1397                 params = [param_rows[0]]
1398             if ignore_conflicts_suffix_sql:
1399                 result.append(ignore_conflicts_suffix_sql)
1400             # Skip empty r_sql to allow subclasses to customize behavior for
1401             # 3rd party backends. Refs #19096.
1402             r_sql, self.returning_params = self.connection.ops.return_insert_columns(self.returning_fields)
1403             if r_sql:
1404                 result.append(r_sql)
1405                 params += [self.returning_params]
1406             return [(" ".join(result), tuple(chain.from_iterable(params)))]
1407 
1408         if can_bulk:
1409             result.append(self.connection.ops.bulk_insert_sql(fields, placeholder_rows))
1410             if ignore_conflicts_suffix_sql:
1411                 result.append(ignore_conflicts_suffix_sql)
1412             return [(" ".join(result), tuple(p for ps in param_rows for p in ps))]
1413         else:
1414             if ignore_conflicts_suffix_sql:
1415                 result.append(ignore_conflicts_suffix_sql)
1416             return [
1417                 (" ".join(result + ["VALUES (%s)" % ", ".join(p)]), vals)
1418                 for p, vals in zip(placeholder_rows, param_rows)
1419             ]
1420 
1421     def execute_sql(self, returning_fields=None):
1422         assert not (
1423             returning_fields and len(self.query.objs) != 1 and
1424             not self.connection.features.can_return_rows_from_bulk_insert
1425         )
1426         opts = self.query.get_meta()
1427         self.returning_fields = returning_fields
1428         with self.connection.cursor() as cursor:
1429             for sql, params in self.as_sql():
1430                 cursor.execute(sql, params)
1431             if not self.returning_fields:
1432                 return []
1433             if self.connection.features.can_return_rows_from_bulk_insert and len(self.query.objs) > 1:
1434                 rows = self.connection.ops.fetch_returned_insert_rows(cursor)
1435             elif self.connection.features.can_return_columns_from_insert:
1436                 assert len(self.query.objs) == 1
1437                 rows = [self.connection.ops.fetch_returned_insert_columns(
1438                     cursor, self.returning_params,
1439                 )]
1440             else:
1441                 rows = [(self.connection.ops.last_insert_id(
1442                     cursor, opts.db_table, opts.pk.column,
1443                 ),)]
1444         cols = [field.get_col(opts.db_table) for field in self.returning_fields]
1445         converters = self.get_converters(cols)
1446         if converters:
1447             rows = list(self.apply_converters(rows, converters))
1448         return rows
1449 
1450 
1451 class SQLDeleteCompiler(SQLCompiler):
1452     @cached_property
1453     def single_alias(self):
1454         # Ensure base table is in aliases.
1455         self.query.get_initial_alias()
1456         return sum(self.query.alias_refcount[t] > 0 for t in self.query.alias_map) == 1
1457 
1458     @classmethod
1459     def _expr_refs_base_model(cls, expr, base_model):
1460         if isinstance(expr, Query):
1461             return expr.model == base_model
1462         if not hasattr(expr, 'get_source_expressions'):
1463             return False
1464         return any(
1465             cls._expr_refs_base_model(source_expr, base_model)
1466             for source_expr in expr.get_source_expressions()
1467         )
1468 
1469     @cached_property
1470     def contains_self_reference_subquery(self):
1471         return any(
1472             self._expr_refs_base_model(expr, self.query.model)
1473             for expr in chain(self.query.annotations.values(), self.query.where.children)
1474         )
1475 
1476     def _as_sql(self, query):
1477         result = [
1478             'DELETE FROM %s' % self.quote_name_unless_alias(query.base_table)
1479         ]
1480         where, params = self.compile(query.where)
1481         if where:
1482             result.append('WHERE %s' % where)
1483         return ' '.join(result), tuple(params)
1484 
1485     def as_sql(self):
1486         """
1487         Create the SQL for this query. Return the SQL string and list of
1488         parameters.
1489         """
1490         if self.single_alias and not self.contains_self_reference_subquery:
1491             return self._as_sql(self.query)
1492         innerq = self.query.clone()
1493         innerq.__class__ = Query
1494         innerq.clear_select_clause()
1495         pk = self.query.model._meta.pk
1496         innerq.select = [
1497             pk.get_col(self.query.get_initial_alias())
1498         ]
1499         outerq = Query(self.query.model)
1500         outerq.where = self.query.where_class()
1501         if not self.connection.features.update_can_self_select:
1502             # Force the materialization of the inner query to allow reference
1503             # to the target table on MySQL.
1504             sql, params = innerq.get_compiler(connection=self.connection).as_sql()
1505             innerq = RawSQL('SELECT * FROM (%s) subquery' % sql, params)
1506         outerq.add_q(Q(pk__in=innerq))
1507         return self._as_sql(outerq)
1508 
1509 
1510 class SQLUpdateCompiler(SQLCompiler):
1511     def as_sql(self):
1512         """
1513         Create the SQL for this query. Return the SQL string and list of
1514         parameters.
1515         """
1516         self.pre_sql_setup()
1517         if not self.query.values:
1518             return '', ()
1519         qn = self.quote_name_unless_alias
1520         values, update_params = [], []
1521         for field, model, val in self.query.values:
1522             if hasattr(val, 'resolve_expression'):
1523                 val = val.resolve_expression(self.query, allow_joins=False, for_save=True)
1524                 if val.contains_aggregate:
1525                     raise FieldError(
1526                         'Aggregate functions are not allowed in this query '
1527                         '(%s=%r).' % (field.name, val)
1528                     )
1529                 if val.contains_over_clause:
1530                     raise FieldError(
1531                         'Window expressions are not allowed in this query '
1532                         '(%s=%r).' % (field.name, val)
1533                     )
1534             elif hasattr(val, 'prepare_database_save'):
1535                 if field.remote_field:
1536                     val = field.get_db_prep_save(
1537                         val.prepare_database_save(field),
1538                         connection=self.connection,
1539                     )
1540                 else:
1541                     raise TypeError(
1542                         "Tried to update field %s with a model instance, %r. "
1543                         "Use a value compatible with %s."
1544                         % (field, val, field.__class__.__name__)
1545                     )
1546             else:
1547                 val = field.get_db_prep_save(val, connection=self.connection)
1548 
1549             # Getting the placeholder for the field.
1550             if hasattr(field, 'get_placeholder'):
1551                 placeholder = field.get_placeholder(val, self, self.connection)
1552             else:
1553                 placeholder = '%s'
1554             name = field.column
1555             if hasattr(val, 'as_sql'):
1556                 sql, params = self.compile(val)
1557                 values.append('%s = %s' % (qn(name), placeholder % sql))
1558                 update_params.extend(params)
1559             elif val is not None:
1560                 values.append('%s = %s' % (qn(name), placeholder))
1561                 update_params.append(val)
1562             else:
1563                 values.append('%s = NULL' % qn(name))
1564         table = self.query.base_table
1565         result = [
1566             'UPDATE %s SET' % qn(table),
1567             ', '.join(values),
1568         ]
1569         where, params = self.compile(self.query.where)
1570         if where:
1571             result.append('WHERE %s' % where)
1572         return ' '.join(result), tuple(update_params + params)
1573 
1574     def execute_sql(self, result_type):
1575         """
1576         Execute the specified update. Return the number of rows affected by
1577         the primary update query. The "primary update query" is the first
1578         non-empty query that is executed. Row counts for any subsequent,
1579         related queries are not available.
1580         """
1581         cursor = super().execute_sql(result_type)
1582         try:
1583             rows = cursor.rowcount if cursor else 0
1584             is_empty = cursor is None
1585         finally:
1586             if cursor:
1587                 cursor.close()
1588         for query in self.query.get_related_updates():
1589             aux_rows = query.get_compiler(self.using).execute_sql(result_type)
1590             if is_empty and aux_rows:
1591                 rows = aux_rows
1592                 is_empty = False
1593         return rows
1594 
1595     def pre_sql_setup(self):
1596         """
1597         If the update depends on results from other tables, munge the "where"
1598         conditions to match the format required for (portable) SQL updates.
1599 
1600         If multiple updates are required, pull out the id values to update at
1601         this point so that they don't change as a result of the progressive
1602         updates.
1603         """
1604         refcounts_before = self.query.alias_refcount.copy()
1605         # Ensure base table is in the query
1606         self.query.get_initial_alias()
1607         count = self.query.count_active_tables()
1608         if not self.query.related_updates and count == 1:
1609             return
1610         query = self.query.chain(klass=Query)
1611         query.select_related = False
1612         query.clear_ordering(force=True)
1613         query.extra = {}
1614         query.select = []
1615         query.add_fields([query.get_meta().pk.name])
1616         super().pre_sql_setup()
1617 
1618         must_pre_select = count > 1 and not self.connection.features.update_can_self_select
1619 
1620         # Now we adjust the current query: reset the where clause and get rid
1621         # of all the tables we don't need (since they're in the sub-select).
1622         self.query.where = self.query.where_class()
1623         if self.query.related_updates or must_pre_select:
1624             # Either we're using the idents in multiple update queries (so
1625             # don't want them to change), or the db backend doesn't support
1626             # selecting from the updating table (e.g. MySQL).
1627             idents = []
1628             for rows in query.get_compiler(self.using).execute_sql(MULTI):
1629                 idents.extend(r[0] for r in rows)
1630             self.query.add_filter(('pk__in', idents))
1631             self.query.related_ids = idents
1632         else:
1633             # The fast path. Filters and updates in one query.
1634             self.query.add_filter(('pk__in', query))
1635         self.query.reset_refcounts(refcounts_before)
1636 
1637 
1638 class SQLAggregateCompiler(SQLCompiler):
1639     def as_sql(self):
1640         """
1641         Create the SQL for this query. Return the SQL string and list of
1642         parameters.
1643         """
1644         sql, params = [], []
1645         for annotation in self.query.annotation_select.values():
1646             ann_sql, ann_params = self.compile(annotation)
1647             ann_sql, ann_params = annotation.select_format(self, ann_sql, ann_params)
1648             sql.append(ann_sql)
1649             params.extend(ann_params)
1650         self.col_count = len(self.query.annotation_select)
1651         sql = ', '.join(sql)
1652         params = tuple(params)
1653 
1654         inner_query_sql, inner_query_params = self.query.inner_query.get_compiler(
1655             self.using
1656         ).as_sql(with_col_aliases=True)
1657         sql = 'SELECT %s FROM (%s) subquery' % (sql, inner_query_sql)
1658         params = params + inner_query_params
1659         return sql, params
1660 
1661 
1662 def cursor_iter(cursor, sentinel, col_count, itersize):
1663     """
1664     Yield blocks of rows from a cursor and ensure the cursor is closed when
1665     done.
1666     """
1667     try:
1668         for rows in iter((lambda: cursor.fetchmany(itersize)), sentinel):
1669             yield rows if col_count is None else [r[:col_count] for r in rows]
1670     finally:
1671         cursor.close()

</code><intended_behavior>The method or methods within this class that execute aggregate queries need to be modified to account for 'EmptyResultSet' scenarios in a way that 'Coalesce' annotations can still enforce their default values. When an aggregate function is wrapped with 'Coalesce' and the query would traditionally lead to an 'EmptyResultSet', the system should return the 'Coalesce' default value instead of 'None'. This adjustment must preserve the functionality for all other types of queries and conditions, ensuring that it specifically addresses the case of aggregates with 'Coalesce' when facing 'EmptyResultSet' scenarios.</intended_behavior>, <file>django/db/models/expressions.py</file>
<class>None</class>
<method>None</method>
<code>
1 import copy
2 import datetime
3 import functools
4 import inspect
5 from decimal import Decimal
6 from uuid import UUID
7 
8 from django.core.exceptions import EmptyResultSet, FieldError
9 from django.db import DatabaseError, NotSupportedError, connection
10 from django.db.models import fields
11 from django.db.models.constants import LOOKUP_SEP
12 from django.db.models.query_utils import Q
13 from django.utils.deconstruct import deconstructible
14 from django.utils.functional import cached_property
15 from django.utils.hashable import make_hashable
16 
17 
18 class SQLiteNumericMixin:
19     """
20     Some expressions with output_field=DecimalField() must be cast to
21     numeric to be properly filtered.
22     """
23     def as_sqlite(self, compiler, connection, **extra_context):
24         sql, params = self.as_sql(compiler, connection, **extra_context)
25         try:
26             if self.output_field.get_internal_type() == 'DecimalField':
27                 sql = 'CAST(%s AS NUMERIC)' % sql
28         except FieldError:
29             pass
30         return sql, params
31 
32 
33 class Combinable:
34     """
35     Provide the ability to combine one or two objects with
36     some connector. For example F('foo') + F('bar').
37     """
38 
39     # Arithmetic connectors
40     ADD = '+'
41     SUB = '-'
42     MUL = '*'
43     DIV = '/'
44     POW = '^'
45     # The following is a quoted % operator - it is quoted because it can be
46     # used in strings that also have parameter substitution.
47     MOD = '%%'
48 
49     # Bitwise operators - note that these are generated by .bitand()
50     # and .bitor(), the '&' and '|' are reserved for boolean operator
51     # usage.
52     BITAND = '&'
53     BITOR = '|'
54     BITLEFTSHIFT = '<<'
55     BITRIGHTSHIFT = '>>'
56     BITXOR = '#'
57 
58     def _combine(self, other, connector, reversed):
59         if not hasattr(other, 'resolve_expression'):
60             # everything must be resolvable to an expression
61             other = Value(other)
62 
63         if reversed:
64             return CombinedExpression(other, connector, self)
65         return CombinedExpression(self, connector, other)
66 
67     #############
68     # OPERATORS #
69     #############
70 
71     def __neg__(self):
72         return self._combine(-1, self.MUL, False)
73 
74     def __add__(self, other):
75         return self._combine(other, self.ADD, False)
76 
77     def __sub__(self, other):
78         return self._combine(other, self.SUB, False)
79 
80     def __mul__(self, other):
81         return self._combine(other, self.MUL, False)
82 
83     def __truediv__(self, other):
84         return self._combine(other, self.DIV, False)
85 
86     def __mod__(self, other):
87         return self._combine(other, self.MOD, False)
88 
89     def __pow__(self, other):
90         return self._combine(other, self.POW, False)
91 
92     def __and__(self, other):
93         if getattr(self, 'conditional', False) and getattr(other, 'conditional', False):
94             return Q(self) & Q(other)
95         raise NotImplementedError(
96             "Use .bitand() and .bitor() for bitwise logical operations."
97         )
98 
99     def bitand(self, other):
100         return self._combine(other, self.BITAND, False)
101 
102     def bitleftshift(self, other):
103         return self._combine(other, self.BITLEFTSHIFT, False)
104 
105     def bitrightshift(self, other):
106         return self._combine(other, self.BITRIGHTSHIFT, False)
107 
108     def bitxor(self, other):
109         return self._combine(other, self.BITXOR, False)
110 
111     def __or__(self, other):
112         if getattr(self, 'conditional', False) and getattr(other, 'conditional', False):
113             return Q(self) | Q(other)
114         raise NotImplementedError(
115             "Use .bitand() and .bitor() for bitwise logical operations."
116         )
117 
118     def bitor(self, other):
119         return self._combine(other, self.BITOR, False)
120 
121     def __radd__(self, other):
122         return self._combine(other, self.ADD, True)
123 
124     def __rsub__(self, other):
125         return self._combine(other, self.SUB, True)
126 
127     def __rmul__(self, other):
128         return self._combine(other, self.MUL, True)
129 
130     def __rtruediv__(self, other):
131         return self._combine(other, self.DIV, True)
132 
133     def __rmod__(self, other):
134         return self._combine(other, self.MOD, True)
135 
136     def __rpow__(self, other):
137         return self._combine(other, self.POW, True)
138 
139     def __rand__(self, other):
140         raise NotImplementedError(
141             "Use .bitand() and .bitor() for bitwise logical operations."
142         )
143 
144     def __ror__(self, other):
145         raise NotImplementedError(
146             "Use .bitand() and .bitor() for bitwise logical operations."
147         )
148 
149 
150 class BaseExpression:
151     """Base class for all query expressions."""
152 
153     # aggregate specific fields
154     is_summary = False
155     _output_field_resolved_to_none = False
156     # Can the expression be used in a WHERE clause?
157     filterable = True
158     # Can the expression can be used as a source expression in Window?
159     window_compatible = False
160 
161     def __init__(self, output_field=None):
162         if output_field is not None:
163             self.output_field = output_field
164 
165     def __getstate__(self):
166         state = self.__dict__.copy()
167         state.pop('convert_value', None)
168         return state
169 
170     def get_db_converters(self, connection):
171         return (
172             []
173             if self.convert_value is self._convert_value_noop else
174             [self.convert_value]
175         ) + self.output_field.get_db_converters(connection)
176 
177     def get_source_expressions(self):
178         return []
179 
180     def set_source_expressions(self, exprs):
181         assert not exprs
182 
183     def _parse_expressions(self, *expressions):
184         return [
185             arg if hasattr(arg, 'resolve_expression') else (
186                 F(arg) if isinstance(arg, str) else Value(arg)
187             ) for arg in expressions
188         ]
189 
190     def as_sql(self, compiler, connection):
191         """
192         Responsible for returning a (sql, [params]) tuple to be included
193         in the current query.
194 
195         Different backends can provide their own implementation, by
196         providing an `as_{vendor}` method and patching the Expression:
197 
198         ```
199         def override_as_sql(self, compiler, connection):
200             # custom logic
201             return super().as_sql(compiler, connection)
202         setattr(Expression, 'as_' + connection.vendor, override_as_sql)
203         ```
204 
205         Arguments:
206          * compiler: the query compiler responsible for generating the query.
207            Must have a compile method, returning a (sql, [params]) tuple.
208            Calling compiler(value) will return a quoted `value`.
209 
210          * connection: the database connection used for the current query.
211 
212         Return: (sql, params)
213           Where `sql` is a string containing ordered sql parameters to be
214           replaced with the elements of the list `params`.
215         """
216         raise NotImplementedError("Subclasses must implement as_sql()")
217 
218     @cached_property
219     def contains_aggregate(self):
220         return any(expr and expr.contains_aggregate for expr in self.get_source_expressions())
221 
222     @cached_property
223     def contains_over_clause(self):
224         return any(expr and expr.contains_over_clause for expr in self.get_source_expressions())
225 
226     @cached_property
227     def contains_column_references(self):
228         return any(expr and expr.contains_column_references for expr in self.get_source_expressions())
229 
230     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):
231         """
232         Provide the chance to do any preprocessing or validation before being
233         added to the query.
234 
235         Arguments:
236          * query: the backend query implementation
237          * allow_joins: boolean allowing or denying use of joins
238            in this query
239          * reuse: a set of reusable joins for multijoins
240          * summarize: a terminal aggregate clause
241          * for_save: whether this expression about to be used in a save or update
242 
243         Return: an Expression to be added to the query.
244         """
245         c = self.copy()
246         c.is_summary = summarize
247         c.set_source_expressions([
248             expr.resolve_expression(query, allow_joins, reuse, summarize)
249             if expr else None
250             for expr in c.get_source_expressions()
251         ])
252         return c
253 
254     @property
255     def conditional(self):
256         return isinstance(self.output_field, fields.BooleanField)
257 
258     @property
259     def field(self):
260         return self.output_field
261 
262     @cached_property
263     def output_field(self):
264         """Return the output type of this expressions."""
265         output_field = self._resolve_output_field()
266         if output_field is None:
267             self._output_field_resolved_to_none = True
268             raise FieldError('Cannot resolve expression type, unknown output_field')
269         return output_field
270 
271     @cached_property
272     def _output_field_or_none(self):
273         """
274         Return the output field of this expression, or None if
275         _resolve_output_field() didn't return an output type.
276         """
277         try:
278             return self.output_field
279         except FieldError:
280             if not self._output_field_resolved_to_none:
281                 raise
282 
283     def _resolve_output_field(self):
284         """
285         Attempt to infer the output type of the expression. If the output
286         fields of all source fields match then, simply infer the same type
287         here. This isn't always correct, but it makes sense most of the time.
288 
289         Consider the difference between `2 + 2` and `2 / 3`. Inferring
290         the type here is a convenience for the common case. The user should
291         supply their own output_field with more complex computations.
292 
293         If a source's output field resolves to None, exclude it from this check.
294         If all sources are None, then an error is raised higher up the stack in
295         the output_field property.
296         """
297         sources_iter = (source for source in self.get_source_fields() if source is not None)
298         for output_field in sources_iter:
299             for source in sources_iter:
300                 if not isinstance(output_field, source.__class__):
301                     raise FieldError(
302                         'Expression contains mixed types: %s, %s. You must '
303                         'set output_field.' % (
304                             output_field.__class__.__name__,
305                             source.__class__.__name__,
306                         )
307                     )
308             return output_field
309 
310     @staticmethod
311     def _convert_value_noop(value, expression, connection):
312         return value
313 
314     @cached_property
315     def convert_value(self):
316         """
317         Expressions provide their own converters because users have the option
318         of manually specifying the output_field which may be a different type
319         from the one the database returns.
320         """
321         field = self.output_field
322         internal_type = field.get_internal_type()
323         if internal_type == 'FloatField':
324             return lambda value, expression, connection: None if value is None else float(value)
325         elif internal_type.endswith('IntegerField'):
326             return lambda value, expression, connection: None if value is None else int(value)
327         elif internal_type == 'DecimalField':
328             return lambda value, expression, connection: None if value is None else Decimal(value)
329         return self._convert_value_noop
330 
331     def get_lookup(self, lookup):
332         return self.output_field.get_lookup(lookup)
333 
334     def get_transform(self, name):
335         return self.output_field.get_transform(name)
336 
337     def relabeled_clone(self, change_map):
338         clone = self.copy()
339         clone.set_source_expressions([
340             e.relabeled_clone(change_map) if e is not None else None
341             for e in self.get_source_expressions()
342         ])
343         return clone
344 
345     def copy(self):
346         return copy.copy(self)
347 
348     def get_group_by_cols(self, alias=None):
349         if not self.contains_aggregate:
350             return [self]
351         cols = []
352         for source in self.get_source_expressions():
353             cols.extend(source.get_group_by_cols())
354         return cols
355 
356     def get_source_fields(self):
357         """Return the underlying field types used by this aggregate."""
358         return [e._output_field_or_none for e in self.get_source_expressions()]
359 
360     def asc(self, **kwargs):
361         return OrderBy(self, **kwargs)
362 
363     def desc(self, **kwargs):
364         return OrderBy(self, descending=True, **kwargs)
365 
366     def reverse_ordering(self):
367         return self
368 
369     def flatten(self):
370         """
371         Recursively yield this expression and all subexpressions, in
372         depth-first order.
373         """
374         yield self
375         for expr in self.get_source_expressions():
376             if expr:
377                 if hasattr(expr, 'flatten'):
378                     yield from expr.flatten()
379                 else:
380                     yield expr
381 
382     def select_format(self, compiler, sql, params):
383         """
384         Custom format for select clauses. For example, EXISTS expressions need
385         to be wrapped in CASE WHEN on Oracle.
386         """
387         if hasattr(self.output_field, 'select_format'):
388             return self.output_field.select_format(compiler, sql, params)
389         return sql, params
390 
391 
392 @deconstructible
393 class Expression(BaseExpression, Combinable):
394     """An expression that can be combined with other expressions."""
395 
396     @cached_property
397     def identity(self):
398         constructor_signature = inspect.signature(self.__init__)
399         args, kwargs = self._constructor_args
400         signature = constructor_signature.bind_partial(*args, **kwargs)
401         signature.apply_defaults()
402         arguments = signature.arguments.items()
403         identity = [self.__class__]
404         for arg, value in arguments:
405             if isinstance(value, fields.Field):
406                 if value.name and value.model:
407                     value = (value.model._meta.label, value.name)
408                 else:
409                     value = type(value)
410             else:
411                 value = make_hashable(value)
412             identity.append((arg, value))
413         return tuple(identity)
414 
415     def __eq__(self, other):
416         if not isinstance(other, Expression):
417             return NotImplemented
418         return other.identity == self.identity
419 
420     def __hash__(self):
421         return hash(self.identity)
422 
423 
424 _connector_combinators = {
425     connector: [
426         (fields.IntegerField, fields.IntegerField, fields.IntegerField),
427         (fields.IntegerField, fields.DecimalField, fields.DecimalField),
428         (fields.DecimalField, fields.IntegerField, fields.DecimalField),
429         (fields.IntegerField, fields.FloatField, fields.FloatField),
430         (fields.FloatField, fields.IntegerField, fields.FloatField),
431     ]
432     for connector in (Combinable.ADD, Combinable.SUB, Combinable.MUL, Combinable.DIV)
433 }
434 
435 
436 @functools.lru_cache(maxsize=128)
437 def _resolve_combined_type(connector, lhs_type, rhs_type):
438     combinators = _connector_combinators.get(connector, ())
439     for combinator_lhs_type, combinator_rhs_type, combined_type in combinators:
440         if issubclass(lhs_type, combinator_lhs_type) and issubclass(rhs_type, combinator_rhs_type):
441             return combined_type
442 
443 
444 class CombinedExpression(SQLiteNumericMixin, Expression):
445 
446     def __init__(self, lhs, connector, rhs, output_field=None):
447         super().__init__(output_field=output_field)
448         self.connector = connector
449         self.lhs = lhs
450         self.rhs = rhs
451 
452     def __repr__(self):
453         return "<{}: {}>".format(self.__class__.__name__, self)
454 
455     def __str__(self):
456         return "{} {} {}".format(self.lhs, self.connector, self.rhs)
457 
458     def get_source_expressions(self):
459         return [self.lhs, self.rhs]
460 
461     def set_source_expressions(self, exprs):
462         self.lhs, self.rhs = exprs
463 
464     def _resolve_output_field(self):
465         try:
466             return super()._resolve_output_field()
467         except FieldError:
468             combined_type = _resolve_combined_type(
469                 self.connector,
470                 type(self.lhs.output_field),
471                 type(self.rhs.output_field),
472             )
473             if combined_type is None:
474                 raise
475             return combined_type()
476 
477     def as_sql(self, compiler, connection):
478         expressions = []
479         expression_params = []
480         sql, params = compiler.compile(self.lhs)
481         expressions.append(sql)
482         expression_params.extend(params)
483         sql, params = compiler.compile(self.rhs)
484         expressions.append(sql)
485         expression_params.extend(params)
486         # order of precedence
487         expression_wrapper = '(%s)'
488         sql = connection.ops.combine_expression(self.connector, expressions)
489         return expression_wrapper % sql, expression_params
490 
491     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):
492         lhs = self.lhs.resolve_expression(query, allow_joins, reuse, summarize, for_save)
493         rhs = self.rhs.resolve_expression(query, allow_joins, reuse, summarize, for_save)
494         if not isinstance(self, (DurationExpression, TemporalSubtraction)):
495             try:
496                 lhs_type = lhs.output_field.get_internal_type()
497             except (AttributeError, FieldError):
498                 lhs_type = None
499             try:
500                 rhs_type = rhs.output_field.get_internal_type()
501             except (AttributeError, FieldError):
502                 rhs_type = None
503             if 'DurationField' in {lhs_type, rhs_type} and lhs_type != rhs_type:
504                 return DurationExpression(self.lhs, self.connector, self.rhs).resolve_expression(
505                     query, allow_joins, reuse, summarize, for_save,
506                 )
507             datetime_fields = {'DateField', 'DateTimeField', 'TimeField'}
508             if self.connector == self.SUB and lhs_type in datetime_fields and lhs_type == rhs_type:
509                 return TemporalSubtraction(self.lhs, self.rhs).resolve_expression(
510                     query, allow_joins, reuse, summarize, for_save,
511                 )
512         c = self.copy()
513         c.is_summary = summarize
514         c.lhs = lhs
515         c.rhs = rhs
516         return c
517 
518 
519 class DurationExpression(CombinedExpression):
520     def compile(self, side, compiler, connection):
521         try:
522             output = side.output_field
523         except FieldError:
524             pass
525         else:
526             if output.get_internal_type() == 'DurationField':
527                 sql, params = compiler.compile(side)
528                 return connection.ops.format_for_duration_arithmetic(sql), params
529         return compiler.compile(side)
530 
531     def as_sql(self, compiler, connection):
532         if connection.features.has_native_duration_field:
533             return super().as_sql(compiler, connection)
534         connection.ops.check_expression_support(self)
535         expressions = []
536         expression_params = []
537         sql, params = self.compile(self.lhs, compiler, connection)
538         expressions.append(sql)
539         expression_params.extend(params)
540         sql, params = self.compile(self.rhs, compiler, connection)
541         expressions.append(sql)
542         expression_params.extend(params)
543         # order of precedence
544         expression_wrapper = '(%s)'
545         sql = connection.ops.combine_duration_expression(self.connector, expressions)
546         return expression_wrapper % sql, expression_params
547 
548     def as_sqlite(self, compiler, connection, **extra_context):
549         sql, params = self.as_sql(compiler, connection, **extra_context)
550         if self.connector in {Combinable.MUL, Combinable.DIV}:
551             try:
552                 lhs_type = self.lhs.output_field.get_internal_type()
553                 rhs_type = self.rhs.output_field.get_internal_type()
554             except (AttributeError, FieldError):
555                 pass
556             else:
557                 allowed_fields = {
558                     'DecimalField', 'DurationField', 'FloatField', 'IntegerField',
559                 }
560                 if lhs_type not in allowed_fields or rhs_type not in allowed_fields:
561                     raise DatabaseError(
562                         f'Invalid arguments for operator {self.connector}.'
563                     )
564         return sql, params
565 
566 
567 class TemporalSubtraction(CombinedExpression):
568     output_field = fields.DurationField()
569 
570     def __init__(self, lhs, rhs):
571         super().__init__(lhs, self.SUB, rhs)
572 
573     def as_sql(self, compiler, connection):
574         connection.ops.check_expression_support(self)
575         lhs = compiler.compile(self.lhs)
576         rhs = compiler.compile(self.rhs)
577         return connection.ops.subtract_temporals(self.lhs.output_field.get_internal_type(), lhs, rhs)
578 
579 
580 @deconstructible
581 class F(Combinable):
582     """An object capable of resolving references to existing query objects."""
583 
584     def __init__(self, name):
585         """
586         Arguments:
587          * name: the name of the field this expression references
588         """
589         self.name = name
590 
591     def __repr__(self):
592         return "{}({})".format(self.__class__.__name__, self.name)
593 
594     def resolve_expression(self, query=None, allow_joins=True, reuse=None,
595                            summarize=False, for_save=False):
596         return query.resolve_ref(self.name, allow_joins, reuse, summarize)
597 
598     def asc(self, **kwargs):
599         return OrderBy(self, **kwargs)
600 
601     def desc(self, **kwargs):
602         return OrderBy(self, descending=True, **kwargs)
603 
604     def __eq__(self, other):
605         return self.__class__ == other.__class__ and self.name == other.name
606 
607     def __hash__(self):
608         return hash(self.name)
609 
610 
611 class ResolvedOuterRef(F):
612     """
613     An object that contains a reference to an outer query.
614 
615     In this case, the reference to the outer query has been resolved because
616     the inner query has been used as a subquery.
617     """
618     contains_aggregate = False
619 
620     def as_sql(self, *args, **kwargs):
621         raise ValueError(
622             'This queryset contains a reference to an outer query and may '
623             'only be used in a subquery.'
624         )
625 
626     def resolve_expression(self, *args, **kwargs):
627         col = super().resolve_expression(*args, **kwargs)
628         # FIXME: Rename possibly_multivalued to multivalued and fix detection
629         # for non-multivalued JOINs (e.g. foreign key fields). This should take
630         # into accountonly many-to-many and one-to-many relationships.
631         col.possibly_multivalued = LOOKUP_SEP in self.name
632         return col
633 
634     def relabeled_clone(self, relabels):
635         return self
636 
637     def get_group_by_cols(self, alias=None):
638         return []
639 
640 
641 class OuterRef(F):
642     contains_aggregate = False
643 
644     def resolve_expression(self, *args, **kwargs):
645         if isinstance(self.name, self.__class__):
646             return self.name
647         return ResolvedOuterRef(self.name)
648 
649     def relabeled_clone(self, relabels):
650         return self
651 
652 
653 class Func(SQLiteNumericMixin, Expression):
654     """An SQL function call."""
655     function = None
656     template = '%(function)s(%(expressions)s)'
657     arg_joiner = ', '
658     arity = None  # The number of arguments the function accepts.
659 
660     def __init__(self, *expressions, output_field=None, **extra):
661         if self.arity is not None and len(expressions) != self.arity:
662             raise TypeError(
663                 "'%s' takes exactly %s %s (%s given)" % (
664                     self.__class__.__name__,
665                     self.arity,
666                     "argument" if self.arity == 1 else "arguments",
667                     len(expressions),
668                 )
669             )
670         super().__init__(output_field=output_field)
671         self.source_expressions = self._parse_expressions(*expressions)
672         self.extra = extra
673 
674     def __repr__(self):
675         args = self.arg_joiner.join(str(arg) for arg in self.source_expressions)
676         extra = {**self.extra, **self._get_repr_options()}
677         if extra:
678             extra = ', '.join(str(key) + '=' + str(val) for key, val in sorted(extra.items()))
679             return "{}({}, {})".format(self.__class__.__name__, args, extra)
680         return "{}({})".format(self.__class__.__name__, args)
681 
682     def _get_repr_options(self):
683         """Return a dict of extra __init__() options to include in the repr."""
684         return {}
685 
686     def get_source_expressions(self):
687         return self.source_expressions
688 
689     def set_source_expressions(self, exprs):
690         self.source_expressions = exprs
691 
692     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):
693         c = self.copy()
694         c.is_summary = summarize
695         for pos, arg in enumerate(c.source_expressions):
696             c.source_expressions[pos] = arg.resolve_expression(query, allow_joins, reuse, summarize, for_save)
697         return c
698 
699     def as_sql(self, compiler, connection, function=None, template=None, arg_joiner=None, **extra_context):
700         connection.ops.check_expression_support(self)
701         sql_parts = []
702         params = []
703         for arg in self.source_expressions:
704             arg_sql, arg_params = compiler.compile(arg)
705             sql_parts.append(arg_sql)
706             params.extend(arg_params)
707         data = {**self.extra, **extra_context}
708         # Use the first supplied value in this order: the parameter to this
709         # method, a value supplied in __init__()'s **extra (the value in
710         # `data`), or the value defined on the class.
711         if function is not None:
712             data['function'] = function
713         else:
714             data.setdefault('function', self.function)
715         template = template or data.get('template', self.template)
716         arg_joiner = arg_joiner or data.get('arg_joiner', self.arg_joiner)
717         data['expressions'] = data['field'] = arg_joiner.join(sql_parts)
718         return template % data, params
719 
720     def copy(self):
721         copy = super().copy()
722         copy.source_expressions = self.source_expressions[:]
723         copy.extra = self.extra.copy()
724         return copy
725 
726 
727 class Value(SQLiteNumericMixin, Expression):
728     """Represent a wrapped value as a node within an expression."""
729     # Provide a default value for `for_save` in order to allow unresolved
730     # instances to be compiled until a decision is taken in #25425.
731     for_save = False
732 
733     def __init__(self, value, output_field=None):
734         """
735         Arguments:
736          * value: the value this expression represents. The value will be
737            added into the sql parameter list and properly quoted.
738 
739          * output_field: an instance of the model field type that this
740            expression will return, such as IntegerField() or CharField().
741         """
742         super().__init__(output_field=output_field)
743         self.value = value
744 
745     def __repr__(self):
746         return f'{self.__class__.__name__}({self.value!r})'
747 
748     def as_sql(self, compiler, connection):
749         connection.ops.check_expression_support(self)
750         val = self.value
751         output_field = self._output_field_or_none
752         if output_field is not None:
753             if self.for_save:
754                 val = output_field.get_db_prep_save(val, connection=connection)
755             else:
756                 val = output_field.get_db_prep_value(val, connection=connection)
757             if hasattr(output_field, 'get_placeholder'):
758                 return output_field.get_placeholder(val, compiler, connection), [val]
759         if val is None:
760             # cx_Oracle does not always convert None to the appropriate
761             # NULL type (like in case expressions using numbers), so we
762             # use a literal SQL NULL
763             return 'NULL', []
764         return '%s', [val]
765 
766     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):
767         c = super().resolve_expression(query, allow_joins, reuse, summarize, for_save)
768         c.for_save = for_save
769         return c
770 
771     def get_group_by_cols(self, alias=None):
772         return []
773 
774     def _resolve_output_field(self):
775         if isinstance(self.value, str):
776             return fields.CharField()
777         if isinstance(self.value, bool):
778             return fields.BooleanField()
779         if isinstance(self.value, int):
780             return fields.IntegerField()
781         if isinstance(self.value, float):
782             return fields.FloatField()
783         if isinstance(self.value, datetime.datetime):
784             return fields.DateTimeField()
785         if isinstance(self.value, datetime.date):
786             return fields.DateField()
787         if isinstance(self.value, datetime.time):
788             return fields.TimeField()
789         if isinstance(self.value, datetime.timedelta):
790             return fields.DurationField()
791         if isinstance(self.value, Decimal):
792             return fields.DecimalField()
793         if isinstance(self.value, bytes):
794             return fields.BinaryField()
795         if isinstance(self.value, UUID):
796             return fields.UUIDField()
797 
798 
799 class RawSQL(Expression):
800     def __init__(self, sql, params, output_field=None):
801         if output_field is None:
802             output_field = fields.Field()
803         self.sql, self.params = sql, params
804         super().__init__(output_field=output_field)
805 
806     def __repr__(self):
807         return "{}({}, {})".format(self.__class__.__name__, self.sql, self.params)
808 
809     def as_sql(self, compiler, connection):
810         return '(%s)' % self.sql, self.params
811 
812     def get_group_by_cols(self, alias=None):
813         return [self]
814 
815     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):
816         # Resolve parents fields used in raw SQL.
817         for parent in query.model._meta.get_parent_list():
818             for parent_field in parent._meta.local_fields:
819                 _, column_name = parent_field.get_attname_column()
820                 if column_name.lower() in self.sql.lower():
821                     query.resolve_ref(parent_field.name, allow_joins, reuse, summarize)
822                     break
823         return super().resolve_expression(query, allow_joins, reuse, summarize, for_save)
824 
825 
826 class Star(Expression):
827     def __repr__(self):
828         return "'*'"
829 
830     def as_sql(self, compiler, connection):
831         return '*', []
832 
833 
834 class Col(Expression):
835 
836     contains_column_references = True
837     possibly_multivalued = False
838 
839     def __init__(self, alias, target, output_field=None):
840         if output_field is None:
841             output_field = target
842         super().__init__(output_field=output_field)
843         self.alias, self.target = alias, target
844 
845     def __repr__(self):
846         alias, target = self.alias, self.target
847         identifiers = (alias, str(target)) if alias else (str(target),)
848         return '{}({})'.format(self.__class__.__name__, ', '.join(identifiers))
849 
850     def as_sql(self, compiler, connection):
851         alias, column = self.alias, self.target.column
852         identifiers = (alias, column) if alias else (column,)
853         sql = '.'.join(map(compiler.quote_name_unless_alias, identifiers))
854         return sql, []
855 
856     def relabeled_clone(self, relabels):
857         if self.alias is None:
858             return self
859         return self.__class__(relabels.get(self.alias, self.alias), self.target, self.output_field)
860 
861     def get_group_by_cols(self, alias=None):
862         return [self]
863 
864     def get_db_converters(self, connection):
865         if self.target == self.output_field:
866             return self.output_field.get_db_converters(connection)
867         return (self.output_field.get_db_converters(connection) +
868                 self.target.get_db_converters(connection))
869 
870 
871 class Ref(Expression):
872     """
873     Reference to column alias of the query. For example, Ref('sum_cost') in
874     qs.annotate(sum_cost=Sum('cost')) query.
875     """
876     def __init__(self, refs, source):
877         super().__init__()
878         self.refs, self.source = refs, source
879 
880     def __repr__(self):
881         return "{}({}, {})".format(self.__class__.__name__, self.refs, self.source)
882 
883     def get_source_expressions(self):
884         return [self.source]
885 
886     def set_source_expressions(self, exprs):
887         self.source, = exprs
888 
889     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):
890         # The sub-expression `source` has already been resolved, as this is
891         # just a reference to the name of `source`.
892         return self
893 
894     def relabeled_clone(self, relabels):
895         return self
896 
897     def as_sql(self, compiler, connection):
898         return connection.ops.quote_name(self.refs), []
899 
900     def get_group_by_cols(self, alias=None):
901         return [self]
902 
903 
904 class ExpressionList(Func):
905     """
906     An expression containing multiple expressions. Can be used to provide a
907     list of expressions as an argument to another expression, like an
908     ordering clause.
909     """
910     template = '%(expressions)s'
911 
912     def __init__(self, *expressions, **extra):
913         if not expressions:
914             raise ValueError('%s requires at least one expression.' % self.__class__.__name__)
915         super().__init__(*expressions, **extra)
916 
917     def __str__(self):
918         return self.arg_joiner.join(str(arg) for arg in self.source_expressions)
919 
920     def as_sqlite(self, compiler, connection, **extra_context):
921         # Casting to numeric is unnecessary.
922         return self.as_sql(compiler, connection, **extra_context)
923 
924 
925 class ExpressionWrapper(Expression):
926     """
927     An expression that can wrap another expression so that it can provide
928     extra context to the inner expression, such as the output_field.
929     """
930 
931     def __init__(self, expression, output_field):
932         super().__init__(output_field=output_field)
933         self.expression = expression
934 
935     def set_source_expressions(self, exprs):
936         self.expression = exprs[0]
937 
938     def get_source_expressions(self):
939         return [self.expression]
940 
941     def get_group_by_cols(self, alias=None):
942         if isinstance(self.expression, Expression):
943             expression = self.expression.copy()
944             expression.output_field = self.output_field
945             return expression.get_group_by_cols(alias=alias)
946         # For non-expressions e.g. an SQL WHERE clause, the entire
947         # `expression` must be included in the GROUP BY clause.
948         return super().get_group_by_cols()
949 
950     def as_sql(self, compiler, connection):
951         return compiler.compile(self.expression)
952 
953     def __repr__(self):
954         return "{}({})".format(self.__class__.__name__, self.expression)
955 
956 
957 class When(Expression):
958     template = 'WHEN %(condition)s THEN %(result)s'
959     # This isn't a complete conditional expression, must be used in Case().
960     conditional = False
961 
962     def __init__(self, condition=None, then=None, **lookups):
963         if lookups:
964             if condition is None:
965                 condition, lookups = Q(**lookups), None
966             elif getattr(condition, 'conditional', False):
967                 condition, lookups = Q(condition, **lookups), None
968         if condition is None or not getattr(condition, 'conditional', False) or lookups:
969             raise TypeError(
970                 'When() supports a Q object, a boolean expression, or lookups '
971                 'as a condition.'
972             )
973         if isinstance(condition, Q) and not condition:
974             raise ValueError("An empty Q() can't be used as a When() condition.")
975         super().__init__(output_field=None)
976         self.condition = condition
977         self.result = self._parse_expressions(then)[0]
978 
979     def __str__(self):
980         return "WHEN %r THEN %r" % (self.condition, self.result)
981 
982     def __repr__(self):
983         return "<%s: %s>" % (self.__class__.__name__, self)
984 
985     def get_source_expressions(self):
986         return [self.condition, self.result]
987 
988     def set_source_expressions(self, exprs):
989         self.condition, self.result = exprs
990 
991     def get_source_fields(self):
992         # We're only interested in the fields of the result expressions.
993         return [self.result._output_field_or_none]
994 
995     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):
996         c = self.copy()
997         c.is_summary = summarize
998         if hasattr(c.condition, 'resolve_expression'):
999             c.condition = c.condition.resolve_expression(query, allow_joins, reuse, summarize, False)
1000         c.result = c.result.resolve_expression(query, allow_joins, reuse, summarize, for_save)
1001         return c
1002 
1003     def as_sql(self, compiler, connection, template=None, **extra_context):
1004         connection.ops.check_expression_support(self)
1005         template_params = extra_context
1006         sql_params = []
1007         condition_sql, condition_params = compiler.compile(self.condition)
1008         template_params['condition'] = condition_sql
1009         sql_params.extend(condition_params)
1010         result_sql, result_params = compiler.compile(self.result)
1011         template_params['result'] = result_sql
1012         sql_params.extend(result_params)
1013         template = template or self.template
1014         return template % template_params, sql_params
1015 
1016     def get_group_by_cols(self, alias=None):
1017         # This is not a complete expression and cannot be used in GROUP BY.
1018         cols = []
1019         for source in self.get_source_expressions():
1020             cols.extend(source.get_group_by_cols())
1021         return cols
1022 
1023 
1024 class Case(Expression):
1025     """
1026     An SQL searched CASE expression:
1027 
1028         CASE
1029             WHEN n > 0
1030                 THEN 'positive'
1031             WHEN n < 0
1032                 THEN 'negative'
1033             ELSE 'zero'
1034         END
1035     """
1036     template = 'CASE %(cases)s ELSE %(default)s END'
1037     case_joiner = ' '
1038 
1039     def __init__(self, *cases, default=None, output_field=None, **extra):
1040         if not all(isinstance(case, When) for case in cases):
1041             raise TypeError("Positional arguments must all be When objects.")
1042         super().__init__(output_field)
1043         self.cases = list(cases)
1044         self.default = self._parse_expressions(default)[0]
1045         self.extra = extra
1046 
1047     def __str__(self):
1048         return "CASE %s, ELSE %r" % (', '.join(str(c) for c in self.cases), self.default)
1049 
1050     def __repr__(self):
1051         return "<%s: %s>" % (self.__class__.__name__, self)
1052 
1053     def get_source_expressions(self):
1054         return self.cases + [self.default]
1055 
1056     def set_source_expressions(self, exprs):
1057         *self.cases, self.default = exprs
1058 
1059     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):
1060         c = self.copy()
1061         c.is_summary = summarize
1062         for pos, case in enumerate(c.cases):
1063             c.cases[pos] = case.resolve_expression(query, allow_joins, reuse, summarize, for_save)
1064         c.default = c.default.resolve_expression(query, allow_joins, reuse, summarize, for_save)
1065         return c
1066 
1067     def copy(self):
1068         c = super().copy()
1069         c.cases = c.cases[:]
1070         return c
1071 
1072     def as_sql(self, compiler, connection, template=None, case_joiner=None, **extra_context):
1073         connection.ops.check_expression_support(self)
1074         if not self.cases:
1075             return compiler.compile(self.default)
1076         template_params = {**self.extra, **extra_context}
1077         case_parts = []
1078         sql_params = []
1079         for case in self.cases:
1080             try:
1081                 case_sql, case_params = compiler.compile(case)
1082             except EmptyResultSet:
1083                 continue
1084             case_parts.append(case_sql)
1085             sql_params.extend(case_params)
1086         default_sql, default_params = compiler.compile(self.default)
1087         if not case_parts:
1088             return default_sql, default_params
1089         case_joiner = case_joiner or self.case_joiner
1090         template_params['cases'] = case_joiner.join(case_parts)
1091         template_params['default'] = default_sql
1092         sql_params.extend(default_params)
1093         template = template or template_params.get('template', self.template)
1094         sql = template % template_params
1095         if self._output_field_or_none is not None:
1096             sql = connection.ops.unification_cast_sql(self.output_field) % sql
1097         return sql, sql_params
1098 
1099     def get_group_by_cols(self, alias=None):
1100         if not self.cases:
1101             return self.default.get_group_by_cols(alias)
1102         return super().get_group_by_cols(alias)
1103 
1104 
1105 class Subquery(BaseExpression, Combinable):
1106     """
1107     An explicit subquery. It may contain OuterRef() references to the outer
1108     query which will be resolved when it is applied to that query.
1109     """
1110     template = '(%(subquery)s)'
1111     contains_aggregate = False
1112 
1113     def __init__(self, queryset, output_field=None, **extra):
1114         # Allow the usage of both QuerySet and sql.Query objects.
1115         self.query = getattr(queryset, 'query', queryset)
1116         self.extra = extra
1117         super().__init__(output_field)
1118 
1119     def get_source_expressions(self):
1120         return [self.query]
1121 
1122     def set_source_expressions(self, exprs):
1123         self.query = exprs[0]
1124 
1125     def _resolve_output_field(self):
1126         return self.query.output_field
1127 
1128     def copy(self):
1129         clone = super().copy()
1130         clone.query = clone.query.clone()
1131         return clone
1132 
1133     @property
1134     def external_aliases(self):
1135         return self.query.external_aliases
1136 
1137     def get_external_cols(self):
1138         return self.query.get_external_cols()
1139 
1140     def as_sql(self, compiler, connection, template=None, query=None, **extra_context):
1141         connection.ops.check_expression_support(self)
1142         template_params = {**self.extra, **extra_context}
1143         query = query or self.query
1144         subquery_sql, sql_params = query.as_sql(compiler, connection)
1145         template_params['subquery'] = subquery_sql[1:-1]
1146 
1147         template = template or template_params.get('template', self.template)
1148         sql = template % template_params
1149         return sql, sql_params
1150 
1151     def get_group_by_cols(self, alias=None):
1152         if alias:
1153             return [Ref(alias, self)]
1154         external_cols = self.get_external_cols()
1155         if any(col.possibly_multivalued for col in external_cols):
1156             return [self]
1157         return external_cols
1158 
1159 
1160 class Exists(Subquery):
1161     template = 'EXISTS(%(subquery)s)'
1162     output_field = fields.BooleanField()
1163 
1164     def __init__(self, queryset, negated=False, **kwargs):
1165         self.negated = negated
1166         super().__init__(queryset, **kwargs)
1167 
1168     def __invert__(self):
1169         clone = self.copy()
1170         clone.negated = not self.negated
1171         return clone
1172 
1173     def as_sql(self, compiler, connection, template=None, **extra_context):
1174         query = self.query.exists(using=connection.alias)
1175         sql, params = super().as_sql(
1176             compiler,
1177             connection,
1178             template=template,
1179             query=query,
1180             **extra_context,
1181         )
1182         if self.negated:
1183             sql = 'NOT {}'.format(sql)
1184         return sql, params
1185 
1186     def select_format(self, compiler, sql, params):
1187         # Wrap EXISTS() with a CASE WHEN expression if a database backend
1188         # (e.g. Oracle) doesn't support boolean expression in SELECT or GROUP
1189         # BY list.
1190         if not compiler.connection.features.supports_boolean_expr_in_select_clause:
1191             sql = 'CASE WHEN {} THEN 1 ELSE 0 END'.format(sql)
1192         return sql, params
1193 
1194 
1195 class OrderBy(Expression):
1196     template = '%(expression)s %(ordering)s'
1197     conditional = False
1198 
1199     def __init__(self, expression, descending=False, nulls_first=False, nulls_last=False):
1200         if nulls_first and nulls_last:
1201             raise ValueError('nulls_first and nulls_last are mutually exclusive')
1202         self.nulls_first = nulls_first
1203         self.nulls_last = nulls_last
1204         self.descending = descending
1205         if not hasattr(expression, 'resolve_expression'):
1206             raise ValueError('expression must be an expression type')
1207         self.expression = expression
1208 
1209     def __repr__(self):
1210         return "{}({}, descending={})".format(
1211             self.__class__.__name__, self.expression, self.descending)
1212 
1213     def set_source_expressions(self, exprs):
1214         self.expression = exprs[0]
1215 
1216     def get_source_expressions(self):
1217         return [self.expression]
1218 
1219     def as_sql(self, compiler, connection, template=None, **extra_context):
1220         template = template or self.template
1221         if connection.features.supports_order_by_nulls_modifier:
1222             if self.nulls_last:
1223                 template = '%s NULLS LAST' % template
1224             elif self.nulls_first:
1225                 template = '%s NULLS FIRST' % template
1226         else:
1227             if self.nulls_last and not (
1228                 self.descending and connection.features.order_by_nulls_first
1229             ):
1230                 template = '%%(expression)s IS NULL, %s' % template
1231             elif self.nulls_first and not (
1232                 not self.descending and connection.features.order_by_nulls_first
1233             ):
1234                 template = '%%(expression)s IS NOT NULL, %s' % template
1235         connection.ops.check_expression_support(self)
1236         expression_sql, params = compiler.compile(self.expression)
1237         placeholders = {
1238             'expression': expression_sql,
1239             'ordering': 'DESC' if self.descending else 'ASC',
1240             **extra_context,
1241         }
1242         params *= template.count('%(expression)s')
1243         return (template % placeholders).rstrip(), params
1244 
1245     def as_oracle(self, compiler, connection):
1246         # Oracle doesn't allow ORDER BY EXISTS() unless it's wrapped in
1247         # a CASE WHEN.
1248         if isinstance(self.expression, Exists):
1249             copy = self.copy()
1250             copy.expression = Case(
1251                 When(self.expression, then=True),
1252                 default=False,
1253             )
1254             return copy.as_sql(compiler, connection)
1255         return self.as_sql(compiler, connection)
1256 
1257     def get_group_by_cols(self, alias=None):
1258         cols = []
1259         for source in self.get_source_expressions():
1260             cols.extend(source.get_group_by_cols())
1261         return cols
1262 
1263     def reverse_ordering(self):
1264         self.descending = not self.descending
1265         if self.nulls_first or self.nulls_last:
1266             self.nulls_first = not self.nulls_first
1267             self.nulls_last = not self.nulls_last
1268         return self
1269 
1270     def asc(self):
1271         self.descending = False
1272 
1273     def desc(self):
1274         self.descending = True
1275 
1276 
1277 class Window(SQLiteNumericMixin, Expression):
1278     template = '%(expression)s OVER (%(window)s)'
1279     # Although the main expression may either be an aggregate or an
1280     # expression with an aggregate function, the GROUP BY that will
1281     # be introduced in the query as a result is not desired.
1282     contains_aggregate = False
1283     contains_over_clause = True
1284     filterable = False
1285 
1286     def __init__(self, expression, partition_by=None, order_by=None, frame=None, output_field=None):
1287         self.partition_by = partition_by
1288         self.order_by = order_by
1289         self.frame = frame
1290 
1291         if not getattr(expression, 'window_compatible', False):
1292             raise ValueError(
1293                 "Expression '%s' isn't compatible with OVER clauses." %
1294                 expression.__class__.__name__
1295             )
1296 
1297         if self.partition_by is not None:
1298             if not isinstance(self.partition_by, (tuple, list)):
1299                 self.partition_by = (self.partition_by,)
1300             self.partition_by = ExpressionList(*self.partition_by)
1301 
1302         if self.order_by is not None:
1303             if isinstance(self.order_by, (list, tuple)):
1304                 self.order_by = ExpressionList(*self.order_by)
1305             elif not isinstance(self.order_by, BaseExpression):
1306                 raise ValueError(
1307                     'order_by must be either an Expression or a sequence of '
1308                     'expressions.'
1309                 )
1310         super().__init__(output_field=output_field)
1311         self.source_expression = self._parse_expressions(expression)[0]
1312 
1313     def _resolve_output_field(self):
1314         return self.source_expression.output_field
1315 
1316     def get_source_expressions(self):
1317         return [self.source_expression, self.partition_by, self.order_by, self.frame]
1318 
1319     def set_source_expressions(self, exprs):
1320         self.source_expression, self.partition_by, self.order_by, self.frame = exprs
1321 
1322     def as_sql(self, compiler, connection, template=None):
1323         connection.ops.check_expression_support(self)
1324         if not connection.features.supports_over_clause:
1325             raise NotSupportedError('This backend does not support window expressions.')
1326         expr_sql, params = compiler.compile(self.source_expression)
1327         window_sql, window_params = [], []
1328 
1329         if self.partition_by is not None:
1330             sql_expr, sql_params = self.partition_by.as_sql(
1331                 compiler=compiler, connection=connection,
1332                 template='PARTITION BY %(expressions)s',
1333             )
1334             window_sql.extend(sql_expr)
1335             window_params.extend(sql_params)
1336 
1337         if self.order_by is not None:
1338             window_sql.append(' ORDER BY ')
1339             order_sql, order_params = compiler.compile(self.order_by)
1340             window_sql.extend(order_sql)
1341             window_params.extend(order_params)
1342 
1343         if self.frame:
1344             frame_sql, frame_params = compiler.compile(self.frame)
1345             window_sql.append(' ' + frame_sql)
1346             window_params.extend(frame_params)
1347 
1348         params.extend(window_params)
1349         template = template or self.template
1350 
1351         return template % {
1352             'expression': expr_sql,
1353             'window': ''.join(window_sql).strip()
1354         }, params
1355 
1356     def as_sqlite(self, compiler, connection):
1357         if isinstance(self.output_field, fields.DecimalField):
1358             # Casting to numeric must be outside of the window expression.
1359             copy = self.copy()
1360             source_expressions = copy.get_source_expressions()
1361             source_expressions[0].output_field = fields.FloatField()
1362             copy.set_source_expressions(source_expressions)
1363             return super(Window, copy).as_sqlite(compiler, connection)
1364         return self.as_sql(compiler, connection)
1365 
1366     def __str__(self):
1367         return '{} OVER ({}{}{})'.format(
1368             str(self.source_expression),
1369             'PARTITION BY ' + str(self.partition_by) if self.partition_by else '',
1370             'ORDER BY ' + str(self.order_by) if self.order_by else '',
1371             str(self.frame or ''),
1372         )
1373 
1374     def __repr__(self):
1375         return '<%s: %s>' % (self.__class__.__name__, self)
1376 
1377     def get_group_by_cols(self, alias=None):
1378         return []
1379 
1380 
1381 class WindowFrame(Expression):
1382     """
1383     Model the frame clause in window expressions. There are two types of frame
1384     clauses which are subclasses, however, all processing and validation (by no
1385     means intended to be complete) is done here. Thus, providing an end for a
1386     frame is optional (the default is UNBOUNDED FOLLOWING, which is the last
1387     row in the frame).
1388     """
1389     template = '%(frame_type)s BETWEEN %(start)s AND %(end)s'
1390 
1391     def __init__(self, start=None, end=None):
1392         self.start = Value(start)
1393         self.end = Value(end)
1394 
1395     def set_source_expressions(self, exprs):
1396         self.start, self.end = exprs
1397 
1398     def get_source_expressions(self):
1399         return [self.start, self.end]
1400 
1401     def as_sql(self, compiler, connection):
1402         connection.ops.check_expression_support(self)
1403         start, end = self.window_frame_start_end(connection, self.start.value, self.end.value)
1404         return self.template % {
1405             'frame_type': self.frame_type,
1406             'start': start,
1407             'end': end,
1408         }, []
1409 
1410     def __repr__(self):
1411         return '<%s: %s>' % (self.__class__.__name__, self)
1412 
1413     def get_group_by_cols(self, alias=None):
1414         return []
1415 
1416     def __str__(self):
1417         if self.start.value is not None and self.start.value < 0:
1418             start = '%d %s' % (abs(self.start.value), connection.ops.PRECEDING)
1419         elif self.start.value is not None and self.start.value == 0:
1420             start = connection.ops.CURRENT_ROW
1421         else:
1422             start = connection.ops.UNBOUNDED_PRECEDING
1423 
1424         if self.end.value is not None and self.end.value > 0:
1425             end = '%d %s' % (self.end.value, connection.ops.FOLLOWING)
1426         elif self.end.value is not None and self.end.value == 0:
1427             end = connection.ops.CURRENT_ROW
1428         else:
1429             end = connection.ops.UNBOUNDED_FOLLOWING
1430         return self.template % {
1431             'frame_type': self.frame_type,
1432             'start': start,
1433             'end': end,
1434         }
1435 
1436     def window_frame_start_end(self, connection, start, end):
1437         raise NotImplementedError('Subclasses must implement window_frame_start_end().')
1438 
1439 
1440 class RowRange(WindowFrame):
1441     frame_type = 'ROWS'
1442 
1443     def window_frame_start_end(self, connection, start, end):
1444         return connection.ops.window_frame_rows_start_end(start, end)
1445 
1446 
1447 class ValueRange(WindowFrame):
1448     frame_type = 'RANGE'
1449 
1450     def window_frame_start_end(self, connection, start, end):
1451         return connection.ops.window_frame_range_start_end(start, end)

</code><intended_behavior>Update or ensure that when expressions involving 'Coalesce' are evaluated, especially in the context of an anticipated 'EmptyResultSet' from a filter condition like 'pk__in=[]', the expression logic defaults to the 'Coalesce' specified value instead of yielding 'None'. This would ensure that 'Coalesce' effectively provides a default value even when no rows are matched, addressing the core issue and maintaining existing functionality where applicable.</intended_behavior>]
2025-10-18 01:19:43.697 | INFO     | Search completed. Bug locations: [<file>django/db/models/sql/compiler.py</file>
<class>None</class>
<method>None</method>
<code>
1 import collections
2 import re
3 from functools import partial
4 from itertools import chain
5 
6 from django.core.exceptions import EmptyResultSet, FieldError
7 from django.db import DatabaseError, NotSupportedError
8 from django.db.models.constants import LOOKUP_SEP
9 from django.db.models.expressions import F, OrderBy, RawSQL, Ref, Value
10 from django.db.models.functions import Cast, Random
11 from django.db.models.query_utils import Q, select_related_descend
12 from django.db.models.sql.constants import (
13     CURSOR, GET_ITERATOR_CHUNK_SIZE, MULTI, NO_RESULTS, ORDER_DIR, SINGLE,
14 )
15 from django.db.models.sql.query import Query, get_order_dir
16 from django.db.transaction import TransactionManagementError
17 from django.utils.functional import cached_property
18 from django.utils.hashable import make_hashable
19 from django.utils.regex_helper import _lazy_re_compile
20 
21 
22 class SQLCompiler:
23     # Multiline ordering SQL clause may appear from RawSQL.
24     ordering_parts = _lazy_re_compile(
25         r'^(.*)\s(?:ASC|DESC).*',
26         re.MULTILINE | re.DOTALL,
27     )
28 
29     def __init__(self, query, connection, using):
30         self.query = query
31         self.connection = connection
32         self.using = using
33         self.quote_cache = {'*': '*'}
34         # The select, klass_info, and annotations are needed by QuerySet.iterator()
35         # these are set as a side-effect of executing the query. Note that we calculate
36         # separately a list of extra select columns needed for grammatical correctness
37         # of the query, but these columns are not included in self.select.
38         self.select = None
39         self.annotation_col_map = None
40         self.klass_info = None
41         self._meta_ordering = None
42 
43     def setup_query(self):
44         if all(self.query.alias_refcount[a] == 0 for a in self.query.alias_map):
45             self.query.get_initial_alias()
46         self.select, self.klass_info, self.annotation_col_map = self.get_select()
47         self.col_count = len(self.select)
48 
49     def pre_sql_setup(self):
50         """
51         Do any necessary class setup immediately prior to producing SQL. This
52         is for things that can't necessarily be done in __init__ because we
53         might not have all the pieces in place at that time.
54         """
55         self.setup_query()
56         order_by = self.get_order_by()
57         self.where, self.having = self.query.where.split_having()
58         extra_select = self.get_extra_select(order_by, self.select)
59         self.has_extra_select = bool(extra_select)
60         group_by = self.get_group_by(self.select + extra_select, order_by)
61         return extra_select, order_by, group_by
62 
63     def get_group_by(self, select, order_by):
64         """
65         Return a list of 2-tuples of form (sql, params).
66 
67         The logic of what exactly the GROUP BY clause contains is hard
68         to describe in other words than "if it passes the test suite,
69         then it is correct".
70         """
71         # Some examples:
72         #     SomeModel.objects.annotate(Count('somecol'))
73         #     GROUP BY: all fields of the model
74         #
75         #    SomeModel.objects.values('name').annotate(Count('somecol'))
76         #    GROUP BY: name
77         #
78         #    SomeModel.objects.annotate(Count('somecol')).values('name')
79         #    GROUP BY: all cols of the model
80         #
81         #    SomeModel.objects.values('name', 'pk').annotate(Count('somecol')).values('pk')
82         #    GROUP BY: name, pk
83         #
84         #    SomeModel.objects.values('name').annotate(Count('somecol')).values('pk')
85         #    GROUP BY: name, pk
86         #
87         # In fact, the self.query.group_by is the minimal set to GROUP BY. It
88         # can't be ever restricted to a smaller set, but additional columns in
89         # HAVING, ORDER BY, and SELECT clauses are added to it. Unfortunately
90         # the end result is that it is impossible to force the query to have
91         # a chosen GROUP BY clause - you can almost do this by using the form:
92         #     .values(*wanted_cols).annotate(AnAggregate())
93         # but any later annotations, extra selects, values calls that
94         # refer some column outside of the wanted_cols, order_by, or even
95         # filter calls can alter the GROUP BY clause.
96 
97         # The query.group_by is either None (no GROUP BY at all), True
98         # (group by select fields), or a list of expressions to be added
99         # to the group by.
100         if self.query.group_by is None:
101             return []
102         expressions = []
103         if self.query.group_by is not True:
104             # If the group by is set to a list (by .values() call most likely),
105             # then we need to add everything in it to the GROUP BY clause.
106             # Backwards compatibility hack for setting query.group_by. Remove
107             # when  we have public API way of forcing the GROUP BY clause.
108             # Converts string references to expressions.
109             for expr in self.query.group_by:
110                 if not hasattr(expr, 'as_sql'):
111                     expressions.append(self.query.resolve_ref(expr))
112                 else:
113                     expressions.append(expr)
114         # Note that even if the group_by is set, it is only the minimal
115         # set to group by. So, we need to add cols in select, order_by, and
116         # having into the select in any case.
117         ref_sources = {
118             expr.source for expr in expressions if isinstance(expr, Ref)
119         }
120         for expr, _, _ in select:
121             # Skip members of the select clause that are already included
122             # by reference.
123             if expr in ref_sources:
124                 continue
125             cols = expr.get_group_by_cols()
126             for col in cols:
127                 expressions.append(col)
128         if not self._meta_ordering:
129             for expr, (sql, params, is_ref) in order_by:
130                 # Skip references to the SELECT clause, as all expressions in
131                 # the SELECT clause are already part of the GROUP BY.
132                 if not is_ref:
133                     expressions.extend(expr.get_group_by_cols())
134         having_group_by = self.having.get_group_by_cols() if self.having else ()
135         for expr in having_group_by:
136             expressions.append(expr)
137         result = []
138         seen = set()
139         expressions = self.collapse_group_by(expressions, having_group_by)
140 
141         for expr in expressions:
142             sql, params = self.compile(expr)
143             sql, params = expr.select_format(self, sql, params)
144             params_hash = make_hashable(params)
145             if (sql, params_hash) not in seen:
146                 result.append((sql, params))
147                 seen.add((sql, params_hash))
148         return result
149 
150     def collapse_group_by(self, expressions, having):
151         # If the DB can group by primary key, then group by the primary key of
152         # query's main model. Note that for PostgreSQL the GROUP BY clause must
153         # include the primary key of every table, but for MySQL it is enough to
154         # have the main table's primary key.
155         if self.connection.features.allows_group_by_pk:
156             # Determine if the main model's primary key is in the query.
157             pk = None
158             for expr in expressions:
159                 # Is this a reference to query's base table primary key? If the
160                 # expression isn't a Col-like, then skip the expression.
161                 if (getattr(expr, 'target', None) == self.query.model._meta.pk and
162                         getattr(expr, 'alias', None) == self.query.base_table):
163                     pk = expr
164                     break
165             # If the main model's primary key is in the query, group by that
166             # field, HAVING expressions, and expressions associated with tables
167             # that don't have a primary key included in the grouped columns.
168             if pk:
169                 pk_aliases = {
170                     expr.alias for expr in expressions
171                     if hasattr(expr, 'target') and expr.target.primary_key
172                 }
173                 expressions = [pk] + [
174                     expr for expr in expressions
175                     if expr in having or (
176                         getattr(expr, 'alias', None) is not None and expr.alias not in pk_aliases
177                     )
178                 ]
179         elif self.connection.features.allows_group_by_selected_pks:
180             # Filter out all expressions associated with a table's primary key
181             # present in the grouped columns. This is done by identifying all
182             # tables that have their primary key included in the grouped
183             # columns and removing non-primary key columns referring to them.
184             # Unmanaged models are excluded because they could be representing
185             # database views on which the optimization might not be allowed.
186             pks = {
187                 expr for expr in expressions
188                 if (
189                     hasattr(expr, 'target') and
190                     expr.target.primary_key and
191                     self.connection.features.allows_group_by_selected_pks_on_model(expr.target.model)
192                 )
193             }
194             aliases = {expr.alias for expr in pks}
195             expressions = [
196                 expr for expr in expressions if expr in pks or getattr(expr, 'alias', None) not in aliases
197             ]
198         return expressions
199 
200     def get_select(self):
201         """
202         Return three values:
203         - a list of 3-tuples of (expression, (sql, params), alias)
204         - a klass_info structure,
205         - a dictionary of annotations
206 
207         The (sql, params) is what the expression will produce, and alias is the
208         "AS alias" for the column (possibly None).
209 
210         The klass_info structure contains the following information:
211         - The base model of the query.
212         - Which columns for that model are present in the query (by
213           position of the select clause).
214         - related_klass_infos: [f, klass_info] to descent into
215 
216         The annotations is a dictionary of {'attname': column position} values.
217         """
218         select = []
219         klass_info = None
220         annotations = {}
221         select_idx = 0
222         for alias, (sql, params) in self.query.extra_select.items():
223             annotations[alias] = select_idx
224             select.append((RawSQL(sql, params), alias))
225             select_idx += 1
226         assert not (self.query.select and self.query.default_cols)
227         if self.query.default_cols:
228             cols = self.get_default_columns()
229         else:
230             # self.query.select is a special case. These columns never go to
231             # any model.
232             cols = self.query.select
233         if cols:
234             select_list = []
235             for col in cols:
236                 select_list.append(select_idx)
237                 select.append((col, None))
238                 select_idx += 1
239             klass_info = {
240                 'model': self.query.model,
241                 'select_fields': select_list,
242             }
243         for alias, annotation in self.query.annotation_select.items():
244             annotations[alias] = select_idx
245             select.append((annotation, alias))
246             select_idx += 1
247 
248         if self.query.select_related:
249             related_klass_infos = self.get_related_selections(select)
250             klass_info['related_klass_infos'] = related_klass_infos
251 
252             def get_select_from_parent(klass_info):
253                 for ki in klass_info['related_klass_infos']:
254                     if ki['from_parent']:
255                         ki['select_fields'] = (klass_info['select_fields'] +
256                                                ki['select_fields'])
257                     get_select_from_parent(ki)
258             get_select_from_parent(klass_info)
259 
260         ret = []
261         for col, alias in select:
262             try:
263                 sql, params = self.compile(col)
264             except EmptyResultSet:
265                 # Select a predicate that's always False.
266                 sql, params = '0', ()
267             else:
268                 sql, params = col.select_format(self, sql, params)
269             ret.append((col, (sql, params), alias))
270         return ret, klass_info, annotations
271 
272     def _order_by_pairs(self):
273         if self.query.extra_order_by:
274             ordering = self.query.extra_order_by
275         elif not self.query.default_ordering:
276             ordering = self.query.order_by
277         elif self.query.order_by:
278             ordering = self.query.order_by
279         elif self.query.get_meta().ordering:
280             ordering = self.query.get_meta().ordering
281             self._meta_ordering = ordering
282         else:
283             ordering = []
284         if self.query.standard_ordering:
285             default_order, _ = ORDER_DIR['ASC']
286         else:
287             default_order, _ = ORDER_DIR['DESC']
288 
289         for field in ordering:
290             if hasattr(field, 'resolve_expression'):
291                 if isinstance(field, Value):
292                     # output_field must be resolved for constants.
293                     field = Cast(field, field.output_field)
294                 if not isinstance(field, OrderBy):
295                     field = field.asc()
296                 if not self.query.standard_ordering:
297                     field = field.copy()
298                     field.reverse_ordering()
299                 yield field, False
300                 continue
301             if field == '?':  # random
302                 yield OrderBy(Random()), False
303                 continue
304 
305             col, order = get_order_dir(field, default_order)
306             descending = order == 'DESC'
307 
308             if col in self.query.annotation_select:
309                 # Reference to expression in SELECT clause
310                 yield (
311                     OrderBy(
312                         Ref(col, self.query.annotation_select[col]),
313                         descending=descending,
314                     ),
315                     True,
316                 )
317                 continue
318             if col in self.query.annotations:
319                 # References to an expression which is masked out of the SELECT
320                 # clause.
321                 if self.query.combinator and self.select:
322                     # Don't use the resolved annotation because other
323                     # combinated queries might define it differently.
324                     expr = F(col)
325                 else:
326                     expr = self.query.annotations[col]
327                     if isinstance(expr, Value):
328                         # output_field must be resolved for constants.
329                         expr = Cast(expr, expr.output_field)
330                 yield OrderBy(expr, descending=descending), False
331                 continue
332 
333             if '.' in field:
334                 # This came in through an extra(order_by=...) addition. Pass it
335                 # on verbatim.
336                 table, col = col.split('.', 1)
337                 yield (
338                     OrderBy(
339                         RawSQL('%s.%s' % (self.quote_name_unless_alias(table), col), []),
340                         descending=descending,
341                     ),
342                     False,
343                 )
344                 continue
345 
346             if self.query.extra and col in self.query.extra:
347                 if col in self.query.extra_select:
348                     yield (
349                         OrderBy(Ref(col, RawSQL(*self.query.extra[col])), descending=descending),
350                         True,
351                     )
352                 else:
353                     yield (
354                         OrderBy(RawSQL(*self.query.extra[col]), descending=descending),
355                         False,
356                     )
357             else:
358                 if self.query.combinator and self.select:
359                     # Don't use the first model's field because other
360                     # combinated queries might define it differently.
361                     yield OrderBy(F(col), descending=descending), False
362                 else:
363                     # 'col' is of the form 'field' or 'field1__field2' or
364                     # '-field1__field2__field', etc.
365                     yield from self.find_ordering_name(
366                         field, self.query.get_meta(), default_order=default_order,
367                     )
368 
369     def get_order_by(self):
370         """
371         Return a list of 2-tuples of the form (expr, (sql, params, is_ref)) for
372         the ORDER BY clause.
373 
374         The order_by clause can alter the select clause (for example it can add
375         aliases to clauses that do not yet have one, or it can add totally new
376         select clauses).
377         """
378         result = []
379         seen = set()
380 
381         for expr, is_ref in self._order_by_pairs():
382             resolved = expr.resolve_expression(self.query, allow_joins=True, reuse=None)
383             if self.query.combinator and self.select:
384                 src = resolved.get_source_expressions()[0]
385                 expr_src = expr.get_source_expressions()[0]
386                 # Relabel order by columns to raw numbers if this is a combined
387                 # query; necessary since the columns can't be referenced by the
388                 # fully qualified name and the simple column names may collide.
389                 for idx, (sel_expr, _, col_alias) in enumerate(self.select):
390                     if is_ref and col_alias == src.refs:
391                         src = src.source
392                     elif col_alias and not (
393                         isinstance(expr_src, F) and col_alias == expr_src.name
394                     ):
395                         continue
396                     if src == sel_expr:
397                         resolved.set_source_expressions([RawSQL('%d' % (idx + 1), ())])
398                         break
399                 else:
400                     if col_alias:
401                         raise DatabaseError('ORDER BY term does not match any column in the result set.')
402                     # Add column used in ORDER BY clause to the selected
403                     # columns and to each combined query.
404                     order_by_idx = len(self.query.select) + 1
405                     col_name = f'__orderbycol{order_by_idx}'
406                     for q in self.query.combined_queries:
407                         q.add_annotation(expr_src, col_name)
408                     self.query.add_select_col(resolved, col_name)
409                     resolved.set_source_expressions([RawSQL(f'{order_by_idx}', ())])
410             sql, params = self.compile(resolved)
411             # Don't add the same column twice, but the order direction is
412             # not taken into account so we strip it. When this entire method
413             # is refactored into expressions, then we can check each part as we
414             # generate it.
415             without_ordering = self.ordering_parts.search(sql)[1]
416             params_hash = make_hashable(params)
417             if (without_ordering, params_hash) in seen:
418                 continue
419             seen.add((without_ordering, params_hash))
420             result.append((resolved, (sql, params, is_ref)))
421         return result
422 
423     def get_extra_select(self, order_by, select):
424         extra_select = []
425         if self.query.distinct and not self.query.distinct_fields:
426             select_sql = [t[1] for t in select]
427             for expr, (sql, params, is_ref) in order_by:
428                 without_ordering = self.ordering_parts.search(sql)[1]
429                 if not is_ref and (without_ordering, params) not in select_sql:
430                     extra_select.append((expr, (without_ordering, params), None))
431         return extra_select
432 
433     def quote_name_unless_alias(self, name):
434         """
435         A wrapper around connection.ops.quote_name that doesn't quote aliases
436         for table names. This avoids problems with some SQL dialects that treat
437         quoted strings specially (e.g. PostgreSQL).
438         """
439         if name in self.quote_cache:
440             return self.quote_cache[name]
441         if ((name in self.query.alias_map and name not in self.query.table_map) or
442                 name in self.query.extra_select or (
443                     self.query.external_aliases.get(name) and name not in self.query.table_map)):
444             self.quote_cache[name] = name
445             return name
446         r = self.connection.ops.quote_name(name)
447         self.quote_cache[name] = r
448         return r
449 
450     def compile(self, node):
451         vendor_impl = getattr(node, 'as_' + self.connection.vendor, None)
452         if vendor_impl:
453             sql, params = vendor_impl(self, self.connection)
454         else:
455             sql, params = node.as_sql(self, self.connection)
456         return sql, params
457 
458     def get_combinator_sql(self, combinator, all):
459         features = self.connection.features
460         compilers = [
461             query.get_compiler(self.using, self.connection)
462             for query in self.query.combined_queries if not query.is_empty()
463         ]
464         if not features.supports_slicing_ordering_in_compound:
465             for query, compiler in zip(self.query.combined_queries, compilers):
466                 if query.low_mark or query.high_mark:
467                     raise DatabaseError('LIMIT/OFFSET not allowed in subqueries of compound statements.')
468                 if compiler.get_order_by():
469                     raise DatabaseError('ORDER BY not allowed in subqueries of compound statements.')
470         parts = ()
471         for compiler in compilers:
472             try:
473                 # If the columns list is limited, then all combined queries
474                 # must have the same columns list. Set the selects defined on
475                 # the query on all combined queries, if not already set.
476                 if not compiler.query.values_select and self.query.values_select:
477                     compiler.query = compiler.query.clone()
478                     compiler.query.set_values((
479                         *self.query.extra_select,
480                         *self.query.values_select,
481                         *self.query.annotation_select,
482                     ))
483                 part_sql, part_args = compiler.as_sql()
484                 if compiler.query.combinator:
485                     # Wrap in a subquery if wrapping in parentheses isn't
486                     # supported.
487                     if not features.supports_parentheses_in_compound:
488                         part_sql = 'SELECT * FROM ({})'.format(part_sql)
489                     # Add parentheses when combining with compound query if not
490                     # already added for all compound queries.
491                     elif not features.supports_slicing_ordering_in_compound:
492                         part_sql = '({})'.format(part_sql)
493                 parts += ((part_sql, part_args),)
494             except EmptyResultSet:
495                 # Omit the empty queryset with UNION and with DIFFERENCE if the
496                 # first queryset is nonempty.
497                 if combinator == 'union' or (combinator == 'difference' and parts):
498                     continue
499                 raise
500         if not parts:
501             raise EmptyResultSet
502         combinator_sql = self.connection.ops.set_operators[combinator]
503         if all and combinator == 'union':
504             combinator_sql += ' ALL'
505         braces = '({})' if features.supports_slicing_ordering_in_compound else '{}'
506         sql_parts, args_parts = zip(*((braces.format(sql), args) for sql, args in parts))
507         result = [' {} '.format(combinator_sql).join(sql_parts)]
508         params = []
509         for part in args_parts:
510             params.extend(part)
511         return result, params
512 
513     def as_sql(self, with_limits=True, with_col_aliases=False):
514         """
515         Create the SQL for this query. Return the SQL string and list of
516         parameters.
517 
518         If 'with_limits' is False, any limit/offset information is not included
519         in the query.
520         """
521         refcounts_before = self.query.alias_refcount.copy()
522         try:
523             extra_select, order_by, group_by = self.pre_sql_setup()
524             for_update_part = None
525             # Is a LIMIT/OFFSET clause needed?
526             with_limit_offset = with_limits and (self.query.high_mark is not None or self.query.low_mark)
527             combinator = self.query.combinator
528             features = self.connection.features
529             if combinator:
530                 if not getattr(features, 'supports_select_{}'.format(combinator)):
531                     raise NotSupportedError('{} is not supported on this database backend.'.format(combinator))
532                 result, params = self.get_combinator_sql(combinator, self.query.combinator_all)
533             else:
534                 distinct_fields, distinct_params = self.get_distinct()
535                 # This must come after 'select', 'ordering', and 'distinct'
536                 # (see docstring of get_from_clause() for details).
537                 from_, f_params = self.get_from_clause()
538                 where, w_params = self.compile(self.where) if self.where is not None else ("", [])
539                 having, h_params = self.compile(self.having) if self.having is not None else ("", [])
540                 result = ['SELECT']
541                 params = []
542 
543                 if self.query.distinct:
544                     distinct_result, distinct_params = self.connection.ops.distinct_sql(
545                         distinct_fields,
546                         distinct_params,
547                     )
548                     result += distinct_result
549                     params += distinct_params
550 
551                 out_cols = []
552                 col_idx = 1
553                 for _, (s_sql, s_params), alias in self.select + extra_select:
554                     if alias:
555                         s_sql = '%s AS %s' % (s_sql, self.connection.ops.quote_name(alias))
556                     elif with_col_aliases:
557                         s_sql = '%s AS %s' % (
558                             s_sql,
559                             self.connection.ops.quote_name('col%d' % col_idx),
560                         )
561                         col_idx += 1
562                     params.extend(s_params)
563                     out_cols.append(s_sql)
564 
565                 result += [', '.join(out_cols), 'FROM', *from_]
566                 params.extend(f_params)
567 
568                 if self.query.select_for_update and self.connection.features.has_select_for_update:
569                     if self.connection.get_autocommit():
570                         raise TransactionManagementError('select_for_update cannot be used outside of a transaction.')
571 
572                     if with_limit_offset and not self.connection.features.supports_select_for_update_with_limit:
573                         raise NotSupportedError(
574                             'LIMIT/OFFSET is not supported with '
575                             'select_for_update on this database backend.'
576                         )
577                     nowait = self.query.select_for_update_nowait
578                     skip_locked = self.query.select_for_update_skip_locked
579                     of = self.query.select_for_update_of
580                     no_key = self.query.select_for_no_key_update
581                     # If it's a NOWAIT/SKIP LOCKED/OF/NO KEY query but the
582                     # backend doesn't support it, raise NotSupportedError to
583                     # prevent a possible deadlock.
584                     if nowait and not self.connection.features.has_select_for_update_nowait:
585                         raise NotSupportedError('NOWAIT is not supported on this database backend.')
586                     elif skip_locked and not self.connection.features.has_select_for_update_skip_locked:
587                         raise NotSupportedError('SKIP LOCKED is not supported on this database backend.')
588                     elif of and not self.connection.features.has_select_for_update_of:
589                         raise NotSupportedError('FOR UPDATE OF is not supported on this database backend.')
590                     elif no_key and not self.connection.features.has_select_for_no_key_update:
591                         raise NotSupportedError(
592                             'FOR NO KEY UPDATE is not supported on this '
593                             'database backend.'
594                         )
595                     for_update_part = self.connection.ops.for_update_sql(
596                         nowait=nowait,
597                         skip_locked=skip_locked,
598                         of=self.get_select_for_update_of_arguments(),
599                         no_key=no_key,
600                     )
601 
602                 if for_update_part and self.connection.features.for_update_after_from:
603                     result.append(for_update_part)
604 
605                 if where:
606                     result.append('WHERE %s' % where)
607                     params.extend(w_params)
608 
609                 grouping = []
610                 for g_sql, g_params in group_by:
611                     grouping.append(g_sql)
612                     params.extend(g_params)
613                 if grouping:
614                     if distinct_fields:
615                         raise NotImplementedError('annotate() + distinct(fields) is not implemented.')
616                     order_by = order_by or self.connection.ops.force_no_ordering()
617                     result.append('GROUP BY %s' % ', '.join(grouping))
618                     if self._meta_ordering:
619                         order_by = None
620                 if having:
621                     result.append('HAVING %s' % having)
622                     params.extend(h_params)
623 
624             if self.query.explain_query:
625                 result.insert(0, self.connection.ops.explain_query_prefix(
626                     self.query.explain_format,
627                     **self.query.explain_options
628                 ))
629 
630             if order_by:
631                 ordering = []
632                 for _, (o_sql, o_params, _) in order_by:
633                     ordering.append(o_sql)
634                     params.extend(o_params)
635                 result.append('ORDER BY %s' % ', '.join(ordering))
636 
637             if with_limit_offset:
638                 result.append(self.connection.ops.limit_offset_sql(self.query.low_mark, self.query.high_mark))
639 
640             if for_update_part and not self.connection.features.for_update_after_from:
641                 result.append(for_update_part)
642 
643             if self.query.subquery and extra_select:
644                 # If the query is used as a subquery, the extra selects would
645                 # result in more columns than the left-hand side expression is
646                 # expecting. This can happen when a subquery uses a combination
647                 # of order_by() and distinct(), forcing the ordering expressions
648                 # to be selected as well. Wrap the query in another subquery
649                 # to exclude extraneous selects.
650                 sub_selects = []
651                 sub_params = []
652                 for index, (select, _, alias) in enumerate(self.select, start=1):
653                     if not alias and with_col_aliases:
654                         alias = 'col%d' % index
655                     if alias:
656                         sub_selects.append("%s.%s" % (
657                             self.connection.ops.quote_name('subquery'),
658                             self.connection.ops.quote_name(alias),
659                         ))
660                     else:
661                         select_clone = select.relabeled_clone({select.alias: 'subquery'})
662                         subselect, subparams = select_clone.as_sql(self, self.connection)
663                         sub_selects.append(subselect)
664                         sub_params.extend(subparams)
665                 return 'SELECT %s FROM (%s) subquery' % (
666                     ', '.join(sub_selects),
667                     ' '.join(result),
668                 ), tuple(sub_params + params)
669 
670             return ' '.join(result), tuple(params)
671         finally:
672             # Finally do cleanup - get rid of the joins we created above.
673             self.query.reset_refcounts(refcounts_before)
674 
675     def get_default_columns(self, start_alias=None, opts=None, from_parent=None):
676         """
677         Compute the default columns for selecting every field in the base
678         model. Will sometimes be called to pull in related models (e.g. via
679         select_related), in which case "opts" and "start_alias" will be given
680         to provide a starting point for the traversal.
681 
682         Return a list of strings, quoted appropriately for use in SQL
683         directly, as well as a set of aliases used in the select statement (if
684         'as_pairs' is True, return a list of (alias, col_name) pairs instead
685         of strings as the first component and None as the second component).
686         """
687         result = []
688         if opts is None:
689             opts = self.query.get_meta()
690         only_load = self.deferred_to_columns()
691         start_alias = start_alias or self.query.get_initial_alias()
692         # The 'seen_models' is used to optimize checking the needed parent
693         # alias for a given field. This also includes None -> start_alias to
694         # be used by local fields.
695         seen_models = {None: start_alias}
696 
697         for field in opts.concrete_fields:
698             model = field.model._meta.concrete_model
699             # A proxy model will have a different model and concrete_model. We
700             # will assign None if the field belongs to this model.
701             if model == opts.model:
702                 model = None
703             if from_parent and model is not None and issubclass(
704                     from_parent._meta.concrete_model, model._meta.concrete_model):
705                 # Avoid loading data for already loaded parents.
706                 # We end up here in the case select_related() resolution
707                 # proceeds from parent model to child model. In that case the
708                 # parent model data is already present in the SELECT clause,
709                 # and we want to avoid reloading the same data again.
710                 continue
711             if field.model in only_load and field.attname not in only_load[field.model]:
712                 continue
713             alias = self.query.join_parent_model(opts, model, start_alias,
714                                                  seen_models)
715             column = field.get_col(alias)
716             result.append(column)
717         return result
718 
719     def get_distinct(self):
720         """
721         Return a quoted list of fields to use in DISTINCT ON part of the query.
722 
723         This method can alter the tables in the query, and thus it must be
724         called before get_from_clause().
725         """
726         result = []
727         params = []
728         opts = self.query.get_meta()
729 
730         for name in self.query.distinct_fields:
731             parts = name.split(LOOKUP_SEP)
732             _, targets, alias, joins, path, _, transform_function = self._setup_joins(parts, opts, None)
733             targets, alias, _ = self.query.trim_joins(targets, joins, path)
734             for target in targets:
735                 if name in self.query.annotation_select:
736                     result.append(name)
737                 else:
738                     r, p = self.compile(transform_function(target, alias))
739                     result.append(r)
740                     params.append(p)
741         return result, params
742 
743     def find_ordering_name(self, name, opts, alias=None, default_order='ASC',
744                            already_seen=None):
745         """
746         Return the table alias (the name might be ambiguous, the alias will
747         not be) and column name for ordering by the given 'name' parameter.
748         The 'name' is of the form 'field1__field2__...__fieldN'.
749         """
750         name, order = get_order_dir(name, default_order)
751         descending = order == 'DESC'
752         pieces = name.split(LOOKUP_SEP)
753         field, targets, alias, joins, path, opts, transform_function = self._setup_joins(pieces, opts, alias)
754 
755         # If we get to this point and the field is a relation to another model,
756         # append the default ordering for that model unless it is the pk
757         # shortcut or the attribute name of the field that is specified.
758         if (
759             field.is_relation and
760             opts.ordering and
761             getattr(field, 'attname', None) != pieces[-1] and
762             name != 'pk'
763         ):
764             # Firstly, avoid infinite loops.
765             already_seen = already_seen or set()
766             join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)
767             if join_tuple in already_seen:
768                 raise FieldError('Infinite loop caused by ordering.')
769             already_seen.add(join_tuple)
770 
771             results = []
772             for item in opts.ordering:
773                 if hasattr(item, 'resolve_expression') and not isinstance(item, OrderBy):
774                     item = item.desc() if descending else item.asc()
775                 if isinstance(item, OrderBy):
776                     results.append((item, False))
777                     continue
778                 results.extend(self.find_ordering_name(item, opts, alias,
779                                                        order, already_seen))
780             return results
781         targets, alias, _ = self.query.trim_joins(targets, joins, path)
782         return [(OrderBy(transform_function(t, alias), descending=descending), False) for t in targets]
783 
784     def _setup_joins(self, pieces, opts, alias):
785         """
786         Helper method for get_order_by() and get_distinct().
787 
788         get_ordering() and get_distinct() must produce same target columns on
789         same input, as the prefixes of get_ordering() and get_distinct() must
790         match. Executing SQL where this is not true is an error.
791         """
792         alias = alias or self.query.get_initial_alias()
793         field, targets, opts, joins, path, transform_function = self.query.setup_joins(pieces, opts, alias)
794         alias = joins[-1]
795         return field, targets, alias, joins, path, opts, transform_function
796 
797     def get_from_clause(self):
798         """
799         Return a list of strings that are joined together to go after the
800         "FROM" part of the query, as well as a list any extra parameters that
801         need to be included. Subclasses, can override this to create a
802         from-clause via a "select".
803 
804         This should only be called after any SQL construction methods that
805         might change the tables that are needed. This means the select columns,
806         ordering, and distinct must be done first.
807         """
808         result = []
809         params = []
810         for alias in tuple(self.query.alias_map):
811             if not self.query.alias_refcount[alias]:
812                 continue
813             try:
814                 from_clause = self.query.alias_map[alias]
815             except KeyError:
816                 # Extra tables can end up in self.tables, but not in the
817                 # alias_map if they aren't in a join. That's OK. We skip them.
818                 continue
819             clause_sql, clause_params = self.compile(from_clause)
820             result.append(clause_sql)
821             params.extend(clause_params)
822         for t in self.query.extra_tables:
823             alias, _ = self.query.table_alias(t)
824             # Only add the alias if it's not already present (the table_alias()
825             # call increments the refcount, so an alias refcount of one means
826             # this is the only reference).
827             if alias not in self.query.alias_map or self.query.alias_refcount[alias] == 1:
828                 result.append(', %s' % self.quote_name_unless_alias(alias))
829         return result, params
830 
831     def get_related_selections(self, select, opts=None, root_alias=None, cur_depth=1,
832                                requested=None, restricted=None):
833         """
834         Fill in the information needed for a select_related query. The current
835         depth is measured as the number of connections away from the root model
836         (for example, cur_depth=1 means we are looking at models with direct
837         connections to the root model).
838         """
839         def _get_field_choices():
840             direct_choices = (f.name for f in opts.fields if f.is_relation)
841             reverse_choices = (
842                 f.field.related_query_name()
843                 for f in opts.related_objects if f.field.unique
844             )
845             return chain(direct_choices, reverse_choices, self.query._filtered_relations)
846 
847         related_klass_infos = []
848         if not restricted and cur_depth > self.query.max_depth:
849             # We've recursed far enough; bail out.
850             return related_klass_infos
851 
852         if not opts:
853             opts = self.query.get_meta()
854             root_alias = self.query.get_initial_alias()
855         only_load = self.query.get_loaded_field_names()
856 
857         # Setup for the case when only particular related fields should be
858         # included in the related selection.
859         fields_found = set()
860         if requested is None:
861             restricted = isinstance(self.query.select_related, dict)
862             if restricted:
863                 requested = self.query.select_related
864 
865         def get_related_klass_infos(klass_info, related_klass_infos):
866             klass_info['related_klass_infos'] = related_klass_infos
867 
868         for f in opts.fields:
869             field_model = f.model._meta.concrete_model
870             fields_found.add(f.name)
871 
872             if restricted:
873                 next = requested.get(f.name, {})
874                 if not f.is_relation:
875                     # If a non-related field is used like a relation,
876                     # or if a single non-relational field is given.
877                     if next or f.name in requested:
878                         raise FieldError(
879                             "Non-relational field given in select_related: '%s'. "
880                             "Choices are: %s" % (
881                                 f.name,
882                                 ", ".join(_get_field_choices()) or '(none)',
883                             )
884                         )
885             else:
886                 next = False
887 
888             if not select_related_descend(f, restricted, requested,
889                                           only_load.get(field_model)):
890                 continue
891             klass_info = {
892                 'model': f.remote_field.model,
893                 'field': f,
894                 'reverse': False,
895                 'local_setter': f.set_cached_value,
896                 'remote_setter': f.remote_field.set_cached_value if f.unique else lambda x, y: None,
897                 'from_parent': False,
898             }
899             related_klass_infos.append(klass_info)
900             select_fields = []
901             _, _, _, joins, _, _ = self.query.setup_joins(
902                 [f.name], opts, root_alias)
903             alias = joins[-1]
904             columns = self.get_default_columns(start_alias=alias, opts=f.remote_field.model._meta)
905             for col in columns:
906                 select_fields.append(len(select))
907                 select.append((col, None))
908             klass_info['select_fields'] = select_fields
909             next_klass_infos = self.get_related_selections(
910                 select, f.remote_field.model._meta, alias, cur_depth + 1, next, restricted)
911             get_related_klass_infos(klass_info, next_klass_infos)
912 
913         if restricted:
914             related_fields = [
915                 (o.field, o.related_model)
916                 for o in opts.related_objects
917                 if o.field.unique and not o.many_to_many
918             ]
919             for f, model in related_fields:
920                 if not select_related_descend(f, restricted, requested,
921                                               only_load.get(model), reverse=True):
922                     continue
923 
924                 related_field_name = f.related_query_name()
925                 fields_found.add(related_field_name)
926 
927                 join_info = self.query.setup_joins([related_field_name], opts, root_alias)
928                 alias = join_info.joins[-1]
929                 from_parent = issubclass(model, opts.model) and model is not opts.model
930                 klass_info = {
931                     'model': model,
932                     'field': f,
933                     'reverse': True,
934                     'local_setter': f.remote_field.set_cached_value,
935                     'remote_setter': f.set_cached_value,
936                     'from_parent': from_parent,
937                 }
938                 related_klass_infos.append(klass_info)
939                 select_fields = []
940                 columns = self.get_default_columns(
941                     start_alias=alias, opts=model._meta, from_parent=opts.model)
942                 for col in columns:
943                     select_fields.append(len(select))
944                     select.append((col, None))
945                 klass_info['select_fields'] = select_fields
946                 next = requested.get(f.related_query_name(), {})
947                 next_klass_infos = self.get_related_selections(
948                     select, model._meta, alias, cur_depth + 1,
949                     next, restricted)
950                 get_related_klass_infos(klass_info, next_klass_infos)
951 
952             def local_setter(obj, from_obj):
953                 # Set a reverse fk object when relation is non-empty.
954                 if from_obj:
955                     f.remote_field.set_cached_value(from_obj, obj)
956 
957             def remote_setter(name, obj, from_obj):
958                 setattr(from_obj, name, obj)
959 
960             for name in list(requested):
961                 # Filtered relations work only on the topmost level.
962                 if cur_depth > 1:
963                     break
964                 if name in self.query._filtered_relations:
965                     fields_found.add(name)
966                     f, _, join_opts, joins, _, _ = self.query.setup_joins([name], opts, root_alias)
967                     model = join_opts.model
968                     alias = joins[-1]
969                     from_parent = issubclass(model, opts.model) and model is not opts.model
970                     klass_info = {
971                         'model': model,
972                         'field': f,
973                         'reverse': True,
974                         'local_setter': local_setter,
975                         'remote_setter': partial(remote_setter, name),
976                         'from_parent': from_parent,
977                     }
978                     related_klass_infos.append(klass_info)
979                     select_fields = []
980                     columns = self.get_default_columns(
981                         start_alias=alias, opts=model._meta,
982                         from_parent=opts.model,
983                     )
984                     for col in columns:
985                         select_fields.append(len(select))
986                         select.append((col, None))
987                     klass_info['select_fields'] = select_fields
988                     next_requested = requested.get(name, {})
989                     next_klass_infos = self.get_related_selections(
990                         select, opts=model._meta, root_alias=alias,
991                         cur_depth=cur_depth + 1, requested=next_requested,
992                         restricted=restricted,
993                     )
994                     get_related_klass_infos(klass_info, next_klass_infos)
995             fields_not_found = set(requested).difference(fields_found)
996             if fields_not_found:
997                 invalid_fields = ("'%s'" % s for s in fields_not_found)
998                 raise FieldError(
999                     'Invalid field name(s) given in select_related: %s. '
1000                     'Choices are: %s' % (
1001                         ', '.join(invalid_fields),
1002                         ', '.join(_get_field_choices()) or '(none)',
1003                     )
1004                 )
1005         return related_klass_infos
1006 
1007     def get_select_for_update_of_arguments(self):
1008         """
1009         Return a quoted list of arguments for the SELECT FOR UPDATE OF part of
1010         the query.
1011         """
1012         def _get_parent_klass_info(klass_info):
1013             concrete_model = klass_info['model']._meta.concrete_model
1014             for parent_model, parent_link in concrete_model._meta.parents.items():
1015                 parent_list = parent_model._meta.get_parent_list()
1016                 yield {
1017                     'model': parent_model,
1018                     'field': parent_link,
1019                     'reverse': False,
1020                     'select_fields': [
1021                         select_index
1022                         for select_index in klass_info['select_fields']
1023                         # Selected columns from a model or its parents.
1024                         if (
1025                             self.select[select_index][0].target.model == parent_model or
1026                             self.select[select_index][0].target.model in parent_list
1027                         )
1028                     ],
1029                 }
1030 
1031         def _get_first_selected_col_from_model(klass_info):
1032             """
1033             Find the first selected column from a model. If it doesn't exist,
1034             don't lock a model.
1035 
1036             select_fields is filled recursively, so it also contains fields
1037             from the parent models.
1038             """
1039             concrete_model = klass_info['model']._meta.concrete_model
1040             for select_index in klass_info['select_fields']:
1041                 if self.select[select_index][0].target.model == concrete_model:
1042                     return self.select[select_index][0]
1043 
1044         def _get_field_choices():
1045             """Yield all allowed field paths in breadth-first search order."""
1046             queue = collections.deque([(None, self.klass_info)])
1047             while queue:
1048                 parent_path, klass_info = queue.popleft()
1049                 if parent_path is None:
1050                     path = []
1051                     yield 'self'
1052                 else:
1053                     field = klass_info['field']
1054                     if klass_info['reverse']:
1055                         field = field.remote_field
1056                     path = parent_path + [field.name]
1057                     yield LOOKUP_SEP.join(path)
1058                 queue.extend(
1059                     (path, klass_info)
1060                     for klass_info in _get_parent_klass_info(klass_info)
1061                 )
1062                 queue.extend(
1063                     (path, klass_info)
1064                     for klass_info in klass_info.get('related_klass_infos', [])
1065                 )
1066         result = []
1067         invalid_names = []
1068         for name in self.query.select_for_update_of:
1069             klass_info = self.klass_info
1070             if name == 'self':
1071                 col = _get_first_selected_col_from_model(klass_info)
1072             else:
1073                 for part in name.split(LOOKUP_SEP):
1074                     klass_infos = (
1075                         *klass_info.get('related_klass_infos', []),
1076                         *_get_parent_klass_info(klass_info),
1077                     )
1078                     for related_klass_info in klass_infos:
1079                         field = related_klass_info['field']
1080                         if related_klass_info['reverse']:
1081                             field = field.remote_field
1082                         if field.name == part:
1083                             klass_info = related_klass_info
1084                             break
1085                     else:
1086                         klass_info = None
1087                         break
1088                 if klass_info is None:
1089                     invalid_names.append(name)
1090                     continue
1091                 col = _get_first_selected_col_from_model(klass_info)
1092             if col is not None:
1093                 if self.connection.features.select_for_update_of_column:
1094                     result.append(self.compile(col)[0])
1095                 else:
1096                     result.append(self.quote_name_unless_alias(col.alias))
1097         if invalid_names:
1098             raise FieldError(
1099                 'Invalid field name(s) given in select_for_update(of=(...)): %s. '
1100                 'Only relational fields followed in the query are allowed. '
1101                 'Choices are: %s.' % (
1102                     ', '.join(invalid_names),
1103                     ', '.join(_get_field_choices()),
1104                 )
1105             )
1106         return result
1107 
1108     def deferred_to_columns(self):
1109         """
1110         Convert the self.deferred_loading data structure to mapping of table
1111         names to sets of column names which are to be loaded. Return the
1112         dictionary.
1113         """
1114         columns = {}
1115         self.query.deferred_to_data(columns, self.query.get_loaded_field_names_cb)
1116         return columns
1117 
1118     def get_converters(self, expressions):
1119         converters = {}
1120         for i, expression in enumerate(expressions):
1121             if expression:
1122                 backend_converters = self.connection.ops.get_db_converters(expression)
1123                 field_converters = expression.get_db_converters(self.connection)
1124                 if backend_converters or field_converters:
1125                     converters[i] = (backend_converters + field_converters, expression)
1126         return converters
1127 
1128     def apply_converters(self, rows, converters):
1129         connection = self.connection
1130         converters = list(converters.items())
1131         for row in map(list, rows):
1132             for pos, (convs, expression) in converters:
1133                 value = row[pos]
1134                 for converter in convs:
1135                     value = converter(value, expression, connection)
1136                 row[pos] = value
1137             yield row
1138 
1139     def results_iter(self, results=None, tuple_expected=False, chunked_fetch=False,
1140                      chunk_size=GET_ITERATOR_CHUNK_SIZE):
1141         """Return an iterator over the results from executing this query."""
1142         if results is None:
1143             results = self.execute_sql(MULTI, chunked_fetch=chunked_fetch, chunk_size=chunk_size)
1144         fields = [s[0] for s in self.select[0:self.col_count]]
1145         converters = self.get_converters(fields)
1146         rows = chain.from_iterable(results)
1147         if converters:
1148             rows = self.apply_converters(rows, converters)
1149             if tuple_expected:
1150                 rows = map(tuple, rows)
1151         return rows
1152 
1153     def has_results(self):
1154         """
1155         Backends (e.g. NoSQL) can override this in order to use optimized
1156         versions of "query has any results."
1157         """
1158         return bool(self.execute_sql(SINGLE))
1159 
1160     def execute_sql(self, result_type=MULTI, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE):
1161         """
1162         Run the query against the database and return the result(s). The
1163         return value is a single data item if result_type is SINGLE, or an
1164         iterator over the results if the result_type is MULTI.
1165 
1166         result_type is either MULTI (use fetchmany() to retrieve all rows),
1167         SINGLE (only retrieve a single row), or None. In this last case, the
1168         cursor is returned if any query is executed, since it's used by
1169         subclasses such as InsertQuery). It's possible, however, that no query
1170         is needed, as the filters describe an empty set. In that case, None is
1171         returned, to avoid any unnecessary database interaction.
1172         """
1173         result_type = result_type or NO_RESULTS
1174         try:
1175             sql, params = self.as_sql()
1176             if not sql:
1177                 raise EmptyResultSet
1178         except EmptyResultSet:
1179             if result_type == MULTI:
1180                 return iter([])
1181             else:
1182                 return
1183         if chunked_fetch:
1184             cursor = self.connection.chunked_cursor()
1185         else:
1186             cursor = self.connection.cursor()
1187         try:
1188             cursor.execute(sql, params)
1189         except Exception:
1190             # Might fail for server-side cursors (e.g. connection closed)
1191             cursor.close()
1192             raise
1193 
1194         if result_type == CURSOR:
1195             # Give the caller the cursor to process and close.
1196             return cursor
1197         if result_type == SINGLE:
1198             try:
1199                 val = cursor.fetchone()
1200                 if val:
1201                     return val[0:self.col_count]
1202                 return val
1203             finally:
1204                 # done with the cursor
1205                 cursor.close()
1206         if result_type == NO_RESULTS:
1207             cursor.close()
1208             return
1209 
1210         result = cursor_iter(
1211             cursor, self.connection.features.empty_fetchmany_value,
1212             self.col_count if self.has_extra_select else None,
1213             chunk_size,
1214         )
1215         if not chunked_fetch or not self.connection.features.can_use_chunked_reads:
1216             try:
1217                 # If we are using non-chunked reads, we return the same data
1218                 # structure as normally, but ensure it is all read into memory
1219                 # before going any further. Use chunked_fetch if requested,
1220                 # unless the database doesn't support it.
1221                 return list(result)
1222             finally:
1223                 # done with the cursor
1224                 cursor.close()
1225         return result
1226 
1227     def as_subquery_condition(self, alias, columns, compiler):
1228         qn = compiler.quote_name_unless_alias
1229         qn2 = self.connection.ops.quote_name
1230 
1231         for index, select_col in enumerate(self.query.select):
1232             lhs_sql, lhs_params = self.compile(select_col)
1233             rhs = '%s.%s' % (qn(alias), qn2(columns[index]))
1234             self.query.where.add(
1235                 RawSQL('%s = %s' % (lhs_sql, rhs), lhs_params), 'AND')
1236 
1237         sql, params = self.as_sql()
1238         return 'EXISTS (%s)' % sql, params
1239 
1240     def explain_query(self):
1241         result = list(self.execute_sql())
1242         # Some backends return 1 item tuples with strings, and others return
1243         # tuples with integers and strings. Flatten them out into strings.
1244         for row in result[0]:
1245             if not isinstance(row, str):
1246                 yield ' '.join(str(c) for c in row)
1247             else:
1248                 yield row
1249 
1250 
1251 class SQLInsertCompiler(SQLCompiler):
1252     returning_fields = None
1253     returning_params = tuple()
1254 
1255     def field_as_sql(self, field, val):
1256         """
1257         Take a field and a value intended to be saved on that field, and
1258         return placeholder SQL and accompanying params. Check for raw values,
1259         expressions, and fields with get_placeholder() defined in that order.
1260 
1261         When field is None, consider the value raw and use it as the
1262         placeholder, with no corresponding parameters returned.
1263         """
1264         if field is None:
1265             # A field value of None means the value is raw.
1266             sql, params = val, []
1267         elif hasattr(val, 'as_sql'):
1268             # This is an expression, let's compile it.
1269             sql, params = self.compile(val)
1270         elif hasattr(field, 'get_placeholder'):
1271             # Some fields (e.g. geo fields) need special munging before
1272             # they can be inserted.
1273             sql, params = field.get_placeholder(val, self, self.connection), [val]
1274         else:
1275             # Return the common case for the placeholder
1276             sql, params = '%s', [val]
1277 
1278         # The following hook is only used by Oracle Spatial, which sometimes
1279         # needs to yield 'NULL' and [] as its placeholder and params instead
1280         # of '%s' and [None]. The 'NULL' placeholder is produced earlier by
1281         # OracleOperations.get_geom_placeholder(). The following line removes
1282         # the corresponding None parameter. See ticket #10888.
1283         params = self.connection.ops.modify_insert_params(sql, params)
1284 
1285         return sql, params
1286 
1287     def prepare_value(self, field, value):
1288         """
1289         Prepare a value to be used in a query by resolving it if it is an
1290         expression and otherwise calling the field's get_db_prep_save().
1291         """
1292         if hasattr(value, 'resolve_expression'):
1293             value = value.resolve_expression(self.query, allow_joins=False, for_save=True)
1294             # Don't allow values containing Col expressions. They refer to
1295             # existing columns on a row, but in the case of insert the row
1296             # doesn't exist yet.
1297             if value.contains_column_references:
1298                 raise ValueError(
1299                     'Failed to insert expression "%s" on %s. F() expressions '
1300                     'can only be used to update, not to insert.' % (value, field)
1301                 )
1302             if value.contains_aggregate:
1303                 raise FieldError(
1304                     'Aggregate functions are not allowed in this query '
1305                     '(%s=%r).' % (field.name, value)
1306                 )
1307             if value.contains_over_clause:
1308                 raise FieldError(
1309                     'Window expressions are not allowed in this query (%s=%r).'
1310                     % (field.name, value)
1311                 )
1312         else:
1313             value = field.get_db_prep_save(value, connection=self.connection)
1314         return value
1315 
1316     def pre_save_val(self, field, obj):
1317         """
1318         Get the given field's value off the given obj. pre_save() is used for
1319         things like auto_now on DateTimeField. Skip it if this is a raw query.
1320         """
1321         if self.query.raw:
1322             return getattr(obj, field.attname)
1323         return field.pre_save(obj, add=True)
1324 
1325     def assemble_as_sql(self, fields, value_rows):
1326         """
1327         Take a sequence of N fields and a sequence of M rows of values, and
1328         generate placeholder SQL and parameters for each field and value.
1329         Return a pair containing:
1330          * a sequence of M rows of N SQL placeholder strings, and
1331          * a sequence of M rows of corresponding parameter values.
1332 
1333         Each placeholder string may contain any number of '%s' interpolation
1334         strings, and each parameter row will contain exactly as many params
1335         as the total number of '%s's in the corresponding placeholder row.
1336         """
1337         if not value_rows:
1338             return [], []
1339 
1340         # list of (sql, [params]) tuples for each object to be saved
1341         # Shape: [n_objs][n_fields][2]
1342         rows_of_fields_as_sql = (
1343             (self.field_as_sql(field, v) for field, v in zip(fields, row))
1344             for row in value_rows
1345         )
1346 
1347         # tuple like ([sqls], [[params]s]) for each object to be saved
1348         # Shape: [n_objs][2][n_fields]
1349         sql_and_param_pair_rows = (zip(*row) for row in rows_of_fields_as_sql)
1350 
1351         # Extract separate lists for placeholders and params.
1352         # Each of these has shape [n_objs][n_fields]
1353         placeholder_rows, param_rows = zip(*sql_and_param_pair_rows)
1354 
1355         # Params for each field are still lists, and need to be flattened.
1356         param_rows = [[p for ps in row for p in ps] for row in param_rows]
1357 
1358         return placeholder_rows, param_rows
1359 
1360     def as_sql(self):
1361         # We don't need quote_name_unless_alias() here, since these are all
1362         # going to be column names (so we can avoid the extra overhead).
1363         qn = self.connection.ops.quote_name
1364         opts = self.query.get_meta()
1365         insert_statement = self.connection.ops.insert_statement(ignore_conflicts=self.query.ignore_conflicts)
1366         result = ['%s %s' % (insert_statement, qn(opts.db_table))]
1367         fields = self.query.fields or [opts.pk]
1368         result.append('(%s)' % ', '.join(qn(f.column) for f in fields))
1369 
1370         if self.query.fields:
1371             value_rows = [
1372                 [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
1373                 for obj in self.query.objs
1374             ]
1375         else:
1376             # An empty object.
1377             value_rows = [[self.connection.ops.pk_default_value()] for _ in self.query.objs]
1378             fields = [None]
1379 
1380         # Currently the backends just accept values when generating bulk
1381         # queries and generate their own placeholders. Doing that isn't
1382         # necessary and it should be possible to use placeholders and
1383         # expressions in bulk inserts too.
1384         can_bulk = (not self.returning_fields and self.connection.features.has_bulk_insert)
1385 
1386         placeholder_rows, param_rows = self.assemble_as_sql(fields, value_rows)
1387 
1388         ignore_conflicts_suffix_sql = self.connection.ops.ignore_conflicts_suffix_sql(
1389             ignore_conflicts=self.query.ignore_conflicts
1390         )
1391         if self.returning_fields and self.connection.features.can_return_columns_from_insert:
1392             if self.connection.features.can_return_rows_from_bulk_insert:
1393                 result.append(self.connection.ops.bulk_insert_sql(fields, placeholder_rows))
1394                 params = param_rows
1395             else:
1396                 result.append("VALUES (%s)" % ", ".join(placeholder_rows[0]))
1397                 params = [param_rows[0]]
1398             if ignore_conflicts_suffix_sql:
1399                 result.append(ignore_conflicts_suffix_sql)
1400             # Skip empty r_sql to allow subclasses to customize behavior for
1401             # 3rd party backends. Refs #19096.
1402             r_sql, self.returning_params = self.connection.ops.return_insert_columns(self.returning_fields)
1403             if r_sql:
1404                 result.append(r_sql)
1405                 params += [self.returning_params]
1406             return [(" ".join(result), tuple(chain.from_iterable(params)))]
1407 
1408         if can_bulk:
1409             result.append(self.connection.ops.bulk_insert_sql(fields, placeholder_rows))
1410             if ignore_conflicts_suffix_sql:
1411                 result.append(ignore_conflicts_suffix_sql)
1412             return [(" ".join(result), tuple(p for ps in param_rows for p in ps))]
1413         else:
1414             if ignore_conflicts_suffix_sql:
1415                 result.append(ignore_conflicts_suffix_sql)
1416             return [
1417                 (" ".join(result + ["VALUES (%s)" % ", ".join(p)]), vals)
1418                 for p, vals in zip(placeholder_rows, param_rows)
1419             ]
1420 
1421     def execute_sql(self, returning_fields=None):
1422         assert not (
1423             returning_fields and len(self.query.objs) != 1 and
1424             not self.connection.features.can_return_rows_from_bulk_insert
1425         )
1426         opts = self.query.get_meta()
1427         self.returning_fields = returning_fields
1428         with self.connection.cursor() as cursor:
1429             for sql, params in self.as_sql():
1430                 cursor.execute(sql, params)
1431             if not self.returning_fields:
1432                 return []
1433             if self.connection.features.can_return_rows_from_bulk_insert and len(self.query.objs) > 1:
1434                 rows = self.connection.ops.fetch_returned_insert_rows(cursor)
1435             elif self.connection.features.can_return_columns_from_insert:
1436                 assert len(self.query.objs) == 1
1437                 rows = [self.connection.ops.fetch_returned_insert_columns(
1438                     cursor, self.returning_params,
1439                 )]
1440             else:
1441                 rows = [(self.connection.ops.last_insert_id(
1442                     cursor, opts.db_table, opts.pk.column,
1443                 ),)]
1444         cols = [field.get_col(opts.db_table) for field in self.returning_fields]
1445         converters = self.get_converters(cols)
1446         if converters:
1447             rows = list(self.apply_converters(rows, converters))
1448         return rows
1449 
1450 
1451 class SQLDeleteCompiler(SQLCompiler):
1452     @cached_property
1453     def single_alias(self):
1454         # Ensure base table is in aliases.
1455         self.query.get_initial_alias()
1456         return sum(self.query.alias_refcount[t] > 0 for t in self.query.alias_map) == 1
1457 
1458     @classmethod
1459     def _expr_refs_base_model(cls, expr, base_model):
1460         if isinstance(expr, Query):
1461             return expr.model == base_model
1462         if not hasattr(expr, 'get_source_expressions'):
1463             return False
1464         return any(
1465             cls._expr_refs_base_model(source_expr, base_model)
1466             for source_expr in expr.get_source_expressions()
1467         )
1468 
1469     @cached_property
1470     def contains_self_reference_subquery(self):
1471         return any(
1472             self._expr_refs_base_model(expr, self.query.model)
1473             for expr in chain(self.query.annotations.values(), self.query.where.children)
1474         )
1475 
1476     def _as_sql(self, query):
1477         result = [
1478             'DELETE FROM %s' % self.quote_name_unless_alias(query.base_table)
1479         ]
1480         where, params = self.compile(query.where)
1481         if where:
1482             result.append('WHERE %s' % where)
1483         return ' '.join(result), tuple(params)
1484 
1485     def as_sql(self):
1486         """
1487         Create the SQL for this query. Return the SQL string and list of
1488         parameters.
1489         """
1490         if self.single_alias and not self.contains_self_reference_subquery:
1491             return self._as_sql(self.query)
1492         innerq = self.query.clone()
1493         innerq.__class__ = Query
1494         innerq.clear_select_clause()
1495         pk = self.query.model._meta.pk
1496         innerq.select = [
1497             pk.get_col(self.query.get_initial_alias())
1498         ]
1499         outerq = Query(self.query.model)
1500         outerq.where = self.query.where_class()
1501         if not self.connection.features.update_can_self_select:
1502             # Force the materialization of the inner query to allow reference
1503             # to the target table on MySQL.
1504             sql, params = innerq.get_compiler(connection=self.connection).as_sql()
1505             innerq = RawSQL('SELECT * FROM (%s) subquery' % sql, params)
1506         outerq.add_q(Q(pk__in=innerq))
1507         return self._as_sql(outerq)
1508 
1509 
1510 class SQLUpdateCompiler(SQLCompiler):
1511     def as_sql(self):
1512         """
1513         Create the SQL for this query. Return the SQL string and list of
1514         parameters.
1515         """
1516         self.pre_sql_setup()
1517         if not self.query.values:
1518             return '', ()
1519         qn = self.quote_name_unless_alias
1520         values, update_params = [], []
1521         for field, model, val in self.query.values:
1522             if hasattr(val, 'resolve_expression'):
1523                 val = val.resolve_expression(self.query, allow_joins=False, for_save=True)
1524                 if val.contains_aggregate:
1525                     raise FieldError(
1526                         'Aggregate functions are not allowed in this query '
1527                         '(%s=%r).' % (field.name, val)
1528                     )
1529                 if val.contains_over_clause:
1530                     raise FieldError(
1531                         'Window expressions are not allowed in this query '
1532                         '(%s=%r).' % (field.name, val)
1533                     )
1534             elif hasattr(val, 'prepare_database_save'):
1535                 if field.remote_field:
1536                     val = field.get_db_prep_save(
1537                         val.prepare_database_save(field),
1538                         connection=self.connection,
1539                     )
1540                 else:
1541                     raise TypeError(
1542                         "Tried to update field %s with a model instance, %r. "
1543                         "Use a value compatible with %s."
1544                         % (field, val, field.__class__.__name__)
1545                     )
1546             else:
1547                 val = field.get_db_prep_save(val, connection=self.connection)
1548 
1549             # Getting the placeholder for the field.
1550             if hasattr(field, 'get_placeholder'):
1551                 placeholder = field.get_placeholder(val, self, self.connection)
1552             else:
1553                 placeholder = '%s'
1554             name = field.column
1555             if hasattr(val, 'as_sql'):
1556                 sql, params = self.compile(val)
1557                 values.append('%s = %s' % (qn(name), placeholder % sql))
1558                 update_params.extend(params)
1559             elif val is not None:
1560                 values.append('%s = %s' % (qn(name), placeholder))
1561                 update_params.append(val)
1562             else:
1563                 values.append('%s = NULL' % qn(name))
1564         table = self.query.base_table
1565         result = [
1566             'UPDATE %s SET' % qn(table),
1567             ', '.join(values),
1568         ]
1569         where, params = self.compile(self.query.where)
1570         if where:
1571             result.append('WHERE %s' % where)
1572         return ' '.join(result), tuple(update_params + params)
1573 
1574     def execute_sql(self, result_type):
1575         """
1576         Execute the specified update. Return the number of rows affected by
1577         the primary update query. The "primary update query" is the first
1578         non-empty query that is executed. Row counts for any subsequent,
1579         related queries are not available.
1580         """
1581         cursor = super().execute_sql(result_type)
1582         try:
1583             rows = cursor.rowcount if cursor else 0
1584             is_empty = cursor is None
1585         finally:
1586             if cursor:
1587                 cursor.close()
1588         for query in self.query.get_related_updates():
1589             aux_rows = query.get_compiler(self.using).execute_sql(result_type)
1590             if is_empty and aux_rows:
1591                 rows = aux_rows
1592                 is_empty = False
1593         return rows
1594 
1595     def pre_sql_setup(self):
1596         """
1597         If the update depends on results from other tables, munge the "where"
1598         conditions to match the format required for (portable) SQL updates.
1599 
1600         If multiple updates are required, pull out the id values to update at
1601         this point so that they don't change as a result of the progressive
1602         updates.
1603         """
1604         refcounts_before = self.query.alias_refcount.copy()
1605         # Ensure base table is in the query
1606         self.query.get_initial_alias()
1607         count = self.query.count_active_tables()
1608         if not self.query.related_updates and count == 1:
1609             return
1610         query = self.query.chain(klass=Query)
1611         query.select_related = False
1612         query.clear_ordering(force=True)
1613         query.extra = {}
1614         query.select = []
1615         query.add_fields([query.get_meta().pk.name])
1616         super().pre_sql_setup()
1617 
1618         must_pre_select = count > 1 and not self.connection.features.update_can_self_select
1619 
1620         # Now we adjust the current query: reset the where clause and get rid
1621         # of all the tables we don't need (since they're in the sub-select).
1622         self.query.where = self.query.where_class()
1623         if self.query.related_updates or must_pre_select:
1624             # Either we're using the idents in multiple update queries (so
1625             # don't want them to change), or the db backend doesn't support
1626             # selecting from the updating table (e.g. MySQL).
1627             idents = []
1628             for rows in query.get_compiler(self.using).execute_sql(MULTI):
1629                 idents.extend(r[0] for r in rows)
1630             self.query.add_filter(('pk__in', idents))
1631             self.query.related_ids = idents
1632         else:
1633             # The fast path. Filters and updates in one query.
1634             self.query.add_filter(('pk__in', query))
1635         self.query.reset_refcounts(refcounts_before)
1636 
1637 
1638 class SQLAggregateCompiler(SQLCompiler):
1639     def as_sql(self):
1640         """
1641         Create the SQL for this query. Return the SQL string and list of
1642         parameters.
1643         """
1644         sql, params = [], []
1645         for annotation in self.query.annotation_select.values():
1646             ann_sql, ann_params = self.compile(annotation)
1647             ann_sql, ann_params = annotation.select_format(self, ann_sql, ann_params)
1648             sql.append(ann_sql)
1649             params.extend(ann_params)
1650         self.col_count = len(self.query.annotation_select)
1651         sql = ', '.join(sql)
1652         params = tuple(params)
1653 
1654         inner_query_sql, inner_query_params = self.query.inner_query.get_compiler(
1655             self.using
1656         ).as_sql(with_col_aliases=True)
1657         sql = 'SELECT %s FROM (%s) subquery' % (sql, inner_query_sql)
1658         params = params + inner_query_params
1659         return sql, params
1660 
1661 
1662 def cursor_iter(cursor, sentinel, col_count, itersize):
1663     """
1664     Yield blocks of rows from a cursor and ensure the cursor is closed when
1665     done.
1666     """
1667     try:
1668         for rows in iter((lambda: cursor.fetchmany(itersize)), sentinel):
1669             yield rows if col_count is None else [r[:col_count] for r in rows]
1670     finally:
1671         cursor.close()

</code><intended_behavior>The method or methods within this class that execute aggregate queries need to be modified to account for 'EmptyResultSet' scenarios in a way that 'Coalesce' annotations can still enforce their default values. When an aggregate function is wrapped with 'Coalesce' and the query would traditionally lead to an 'EmptyResultSet', the system should return the 'Coalesce' default value instead of 'None'. This adjustment must preserve the functionality for all other types of queries and conditions, ensuring that it specifically addresses the case of aggregates with 'Coalesce' when facing 'EmptyResultSet' scenarios.</intended_behavior>, <file>django/db/models/expressions.py</file>
<class>None</class>
<method>None</method>
<code>
1 import copy
2 import datetime
3 import functools
4 import inspect
5 from decimal import Decimal
6 from uuid import UUID
7 
8 from django.core.exceptions import EmptyResultSet, FieldError
9 from django.db import DatabaseError, NotSupportedError, connection
10 from django.db.models import fields
11 from django.db.models.constants import LOOKUP_SEP
12 from django.db.models.query_utils import Q
13 from django.utils.deconstruct import deconstructible
14 from django.utils.functional import cached_property
15 from django.utils.hashable import make_hashable
16 
17 
18 class SQLiteNumericMixin:
19     """
20     Some expressions with output_field=DecimalField() must be cast to
21     numeric to be properly filtered.
22     """
23     def as_sqlite(self, compiler, connection, **extra_context):
24         sql, params = self.as_sql(compiler, connection, **extra_context)
25         try:
26             if self.output_field.get_internal_type() == 'DecimalField':
27                 sql = 'CAST(%s AS NUMERIC)' % sql
28         except FieldError:
29             pass
30         return sql, params
31 
32 
33 class Combinable:
34     """
35     Provide the ability to combine one or two objects with
36     some connector. For example F('foo') + F('bar').
37     """
38 
39     # Arithmetic connectors
40     ADD = '+'
41     SUB = '-'
42     MUL = '*'
43     DIV = '/'
44     POW = '^'
45     # The following is a quoted % operator - it is quoted because it can be
46     # used in strings that also have parameter substitution.
47     MOD = '%%'
48 
49     # Bitwise operators - note that these are generated by .bitand()
50     # and .bitor(), the '&' and '|' are reserved for boolean operator
51     # usage.
52     BITAND = '&'
53     BITOR = '|'
54     BITLEFTSHIFT = '<<'
55     BITRIGHTSHIFT = '>>'
56     BITXOR = '#'
57 
58     def _combine(self, other, connector, reversed):
59         if not hasattr(other, 'resolve_expression'):
60             # everything must be resolvable to an expression
61             other = Value(other)
62 
63         if reversed:
64             return CombinedExpression(other, connector, self)
65         return CombinedExpression(self, connector, other)
66 
67     #############
68     # OPERATORS #
69     #############
70 
71     def __neg__(self):
72         return self._combine(-1, self.MUL, False)
73 
74     def __add__(self, other):
75         return self._combine(other, self.ADD, False)
76 
77     def __sub__(self, other):
78         return self._combine(other, self.SUB, False)
79 
80     def __mul__(self, other):
81         return self._combine(other, self.MUL, False)
82 
83     def __truediv__(self, other):
84         return self._combine(other, self.DIV, False)
85 
86     def __mod__(self, other):
87         return self._combine(other, self.MOD, False)
88 
89     def __pow__(self, other):
90         return self._combine(other, self.POW, False)
91 
92     def __and__(self, other):
93         if getattr(self, 'conditional', False) and getattr(other, 'conditional', False):
94             return Q(self) & Q(other)
95         raise NotImplementedError(
96             "Use .bitand() and .bitor() for bitwise logical operations."
97         )
98 
99     def bitand(self, other):
100         return self._combine(other, self.BITAND, False)
101 
102     def bitleftshift(self, other):
103         return self._combine(other, self.BITLEFTSHIFT, False)
104 
105     def bitrightshift(self, other):
106         return self._combine(other, self.BITRIGHTSHIFT, False)
107 
108     def bitxor(self, other):
109         return self._combine(other, self.BITXOR, False)
110 
111     def __or__(self, other):
112         if getattr(self, 'conditional', False) and getattr(other, 'conditional', False):
113             return Q(self) | Q(other)
114         raise NotImplementedError(
115             "Use .bitand() and .bitor() for bitwise logical operations."
116         )
117 
118     def bitor(self, other):
119         return self._combine(other, self.BITOR, False)
120 
121     def __radd__(self, other):
122         return self._combine(other, self.ADD, True)
123 
124     def __rsub__(self, other):
125         return self._combine(other, self.SUB, True)
126 
127     def __rmul__(self, other):
128         return self._combine(other, self.MUL, True)
129 
130     def __rtruediv__(self, other):
131         return self._combine(other, self.DIV, True)
132 
133     def __rmod__(self, other):
134         return self._combine(other, self.MOD, True)
135 
136     def __rpow__(self, other):
137         return self._combine(other, self.POW, True)
138 
139     def __rand__(self, other):
140         raise NotImplementedError(
141             "Use .bitand() and .bitor() for bitwise logical operations."
142         )
143 
144     def __ror__(self, other):
145         raise NotImplementedError(
146             "Use .bitand() and .bitor() for bitwise logical operations."
147         )
148 
149 
150 class BaseExpression:
151     """Base class for all query expressions."""
152 
153     # aggregate specific fields
154     is_summary = False
155     _output_field_resolved_to_none = False
156     # Can the expression be used in a WHERE clause?
157     filterable = True
158     # Can the expression can be used as a source expression in Window?
159     window_compatible = False
160 
161     def __init__(self, output_field=None):
162         if output_field is not None:
163             self.output_field = output_field
164 
165     def __getstate__(self):
166         state = self.__dict__.copy()
167         state.pop('convert_value', None)
168         return state
169 
170     def get_db_converters(self, connection):
171         return (
172             []
173             if self.convert_value is self._convert_value_noop else
174             [self.convert_value]
175         ) + self.output_field.get_db_converters(connection)
176 
177     def get_source_expressions(self):
178         return []
179 
180     def set_source_expressions(self, exprs):
181         assert not exprs
182 
183     def _parse_expressions(self, *expressions):
184         return [
185             arg if hasattr(arg, 'resolve_expression') else (
186                 F(arg) if isinstance(arg, str) else Value(arg)
187             ) for arg in expressions
188         ]
189 
190     def as_sql(self, compiler, connection):
191         """
192         Responsible for returning a (sql, [params]) tuple to be included
193         in the current query.
194 
195         Different backends can provide their own implementation, by
196         providing an `as_{vendor}` method and patching the Expression:
197 
198         ```
199         def override_as_sql(self, compiler, connection):
200             # custom logic
201             return super().as_sql(compiler, connection)
202         setattr(Expression, 'as_' + connection.vendor, override_as_sql)
203         ```
204 
205         Arguments:
206          * compiler: the query compiler responsible for generating the query.
207            Must have a compile method, returning a (sql, [params]) tuple.
208            Calling compiler(value) will return a quoted `value`.
209 
210          * connection: the database connection used for the current query.
211 
212         Return: (sql, params)
213           Where `sql` is a string containing ordered sql parameters to be
214           replaced with the elements of the list `params`.
215         """
216         raise NotImplementedError("Subclasses must implement as_sql()")
217 
218     @cached_property
219     def contains_aggregate(self):
220         return any(expr and expr.contains_aggregate for expr in self.get_source_expressions())
221 
222     @cached_property
223     def contains_over_clause(self):
224         return any(expr and expr.contains_over_clause for expr in self.get_source_expressions())
225 
226     @cached_property
227     def contains_column_references(self):
228         return any(expr and expr.contains_column_references for expr in self.get_source_expressions())
229 
230     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):
231         """
232         Provide the chance to do any preprocessing or validation before being
233         added to the query.
234 
235         Arguments:
236          * query: the backend query implementation
237          * allow_joins: boolean allowing or denying use of joins
238            in this query
239          * reuse: a set of reusable joins for multijoins
240          * summarize: a terminal aggregate clause
241          * for_save: whether this expression about to be used in a save or update
242 
243         Return: an Expression to be added to the query.
244         """
245         c = self.copy()
246         c.is_summary = summarize
247         c.set_source_expressions([
248             expr.resolve_expression(query, allow_joins, reuse, summarize)
249             if expr else None
250             for expr in c.get_source_expressions()
251         ])
252         return c
253 
254     @property
255     def conditional(self):
256         return isinstance(self.output_field, fields.BooleanField)
257 
258     @property
259     def field(self):
260         return self.output_field
261 
262     @cached_property
263     def output_field(self):
264         """Return the output type of this expressions."""
265         output_field = self._resolve_output_field()
266         if output_field is None:
267             self._output_field_resolved_to_none = True
268             raise FieldError('Cannot resolve expression type, unknown output_field')
269         return output_field
270 
271     @cached_property
272     def _output_field_or_none(self):
273         """
274         Return the output field of this expression, or None if
275         _resolve_output_field() didn't return an output type.
276         """
277         try:
278             return self.output_field
279         except FieldError:
280             if not self._output_field_resolved_to_none:
281                 raise
282 
283     def _resolve_output_field(self):
284         """
285         Attempt to infer the output type of the expression. If the output
286         fields of all source fields match then, simply infer the same type
287         here. This isn't always correct, but it makes sense most of the time.
288 
289         Consider the difference between `2 + 2` and `2 / 3`. Inferring
290         the type here is a convenience for the common case. The user should
291         supply their own output_field with more complex computations.
292 
293         If a source's output field resolves to None, exclude it from this check.
294         If all sources are None, then an error is raised higher up the stack in
295         the output_field property.
296         """
297         sources_iter = (source for source in self.get_source_fields() if source is not None)
298         for output_field in sources_iter:
299             for source in sources_iter:
300                 if not isinstance(output_field, source.__class__):
301                     raise FieldError(
302                         'Expression contains mixed types: %s, %s. You must '
303                         'set output_field.' % (
304                             output_field.__class__.__name__,
305                             source.__class__.__name__,
306                         )
307                     )
308             return output_field
309 
310     @staticmethod
311     def _convert_value_noop(value, expression, connection):
312         return value
313 
314     @cached_property
315     def convert_value(self):
316         """
317         Expressions provide their own converters because users have the option
318         of manually specifying the output_field which may be a different type
319         from the one the database returns.
320         """
321         field = self.output_field
322         internal_type = field.get_internal_type()
323         if internal_type == 'FloatField':
324             return lambda value, expression, connection: None if value is None else float(value)
325         elif internal_type.endswith('IntegerField'):
326             return lambda value, expression, connection: None if value is None else int(value)
327         elif internal_type == 'DecimalField':
328             return lambda value, expression, connection: None if value is None else Decimal(value)
329         return self._convert_value_noop
330 
331     def get_lookup(self, lookup):
332         return self.output_field.get_lookup(lookup)
333 
334     def get_transform(self, name):
335         return self.output_field.get_transform(name)
336 
337     def relabeled_clone(self, change_map):
338         clone = self.copy()
339         clone.set_source_expressions([
340             e.relabeled_clone(change_map) if e is not None else None
341             for e in self.get_source_expressions()
342         ])
343         return clone
344 
345     def copy(self):
346         return copy.copy(self)
347 
348     def get_group_by_cols(self, alias=None):
349         if not self.contains_aggregate:
350             return [self]
351         cols = []
352         for source in self.get_source_expressions():
353             cols.extend(source.get_group_by_cols())
354         return cols
355 
356     def get_source_fields(self):
357         """Return the underlying field types used by this aggregate."""
358         return [e._output_field_or_none for e in self.get_source_expressions()]
359 
360     def asc(self, **kwargs):
361         return OrderBy(self, **kwargs)
362 
363     def desc(self, **kwargs):
364         return OrderBy(self, descending=True, **kwargs)
365 
366     def reverse_ordering(self):
367         return self
368 
369     def flatten(self):
370         """
371         Recursively yield this expression and all subexpressions, in
372         depth-first order.
373         """
374         yield self
375         for expr in self.get_source_expressions():
376             if expr:
377                 if hasattr(expr, 'flatten'):
378                     yield from expr.flatten()
379                 else:
380                     yield expr
381 
382     def select_format(self, compiler, sql, params):
383         """
384         Custom format for select clauses. For example, EXISTS expressions need
385         to be wrapped in CASE WHEN on Oracle.
386         """
387         if hasattr(self.output_field, 'select_format'):
388             return self.output_field.select_format(compiler, sql, params)
389         return sql, params
390 
391 
392 @deconstructible
393 class Expression(BaseExpression, Combinable):
394     """An expression that can be combined with other expressions."""
395 
396     @cached_property
397     def identity(self):
398         constructor_signature = inspect.signature(self.__init__)
399         args, kwargs = self._constructor_args
400         signature = constructor_signature.bind_partial(*args, **kwargs)
401         signature.apply_defaults()
402         arguments = signature.arguments.items()
403         identity = [self.__class__]
404         for arg, value in arguments:
405             if isinstance(value, fields.Field):
406                 if value.name and value.model:
407                     value = (value.model._meta.label, value.name)
408                 else:
409                     value = type(value)
410             else:
411                 value = make_hashable(value)
412             identity.append((arg, value))
413         return tuple(identity)
414 
415     def __eq__(self, other):
416         if not isinstance(other, Expression):
417             return NotImplemented
418         return other.identity == self.identity
419 
420     def __hash__(self):
421         return hash(self.identity)
422 
423 
424 _connector_combinators = {
425     connector: [
426         (fields.IntegerField, fields.IntegerField, fields.IntegerField),
427         (fields.IntegerField, fields.DecimalField, fields.DecimalField),
428         (fields.DecimalField, fields.IntegerField, fields.DecimalField),
429         (fields.IntegerField, fields.FloatField, fields.FloatField),
430         (fields.FloatField, fields.IntegerField, fields.FloatField),
431     ]
432     for connector in (Combinable.ADD, Combinable.SUB, Combinable.MUL, Combinable.DIV)
433 }
434 
435 
436 @functools.lru_cache(maxsize=128)
437 def _resolve_combined_type(connector, lhs_type, rhs_type):
438     combinators = _connector_combinators.get(connector, ())
439     for combinator_lhs_type, combinator_rhs_type, combined_type in combinators:
440         if issubclass(lhs_type, combinator_lhs_type) and issubclass(rhs_type, combinator_rhs_type):
441             return combined_type
442 
443 
444 class CombinedExpression(SQLiteNumericMixin, Expression):
445 
446     def __init__(self, lhs, connector, rhs, output_field=None):
447         super().__init__(output_field=output_field)
448         self.connector = connector
449         self.lhs = lhs
450         self.rhs = rhs
451 
452     def __repr__(self):
453         return "<{}: {}>".format(self.__class__.__name__, self)
454 
455     def __str__(self):
456         return "{} {} {}".format(self.lhs, self.connector, self.rhs)
457 
458     def get_source_expressions(self):
459         return [self.lhs, self.rhs]
460 
461     def set_source_expressions(self, exprs):
462         self.lhs, self.rhs = exprs
463 
464     def _resolve_output_field(self):
465         try:
466             return super()._resolve_output_field()
467         except FieldError:
468             combined_type = _resolve_combined_type(
469                 self.connector,
470                 type(self.lhs.output_field),
471                 type(self.rhs.output_field),
472             )
473             if combined_type is None:
474                 raise
475             return combined_type()
476 
477     def as_sql(self, compiler, connection):
478         expressions = []
479         expression_params = []
480         sql, params = compiler.compile(self.lhs)
481         expressions.append(sql)
482         expression_params.extend(params)
483         sql, params = compiler.compile(self.rhs)
484         expressions.append(sql)
485         expression_params.extend(params)
486         # order of precedence
487         expression_wrapper = '(%s)'
488         sql = connection.ops.combine_expression(self.connector, expressions)
489         return expression_wrapper % sql, expression_params
490 
491     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):
492         lhs = self.lhs.resolve_expression(query, allow_joins, reuse, summarize, for_save)
493         rhs = self.rhs.resolve_expression(query, allow_joins, reuse, summarize, for_save)
494         if not isinstance(self, (DurationExpression, TemporalSubtraction)):
495             try:
496                 lhs_type = lhs.output_field.get_internal_type()
497             except (AttributeError, FieldError):
498                 lhs_type = None
499             try:
500                 rhs_type = rhs.output_field.get_internal_type()
501             except (AttributeError, FieldError):
502                 rhs_type = None
503             if 'DurationField' in {lhs_type, rhs_type} and lhs_type != rhs_type:
504                 return DurationExpression(self.lhs, self.connector, self.rhs).resolve_expression(
505                     query, allow_joins, reuse, summarize, for_save,
506                 )
507             datetime_fields = {'DateField', 'DateTimeField', 'TimeField'}
508             if self.connector == self.SUB and lhs_type in datetime_fields and lhs_type == rhs_type:
509                 return TemporalSubtraction(self.lhs, self.rhs).resolve_expression(
510                     query, allow_joins, reuse, summarize, for_save,
511                 )
512         c = self.copy()
513         c.is_summary = summarize
514         c.lhs = lhs
515         c.rhs = rhs
516         return c
517 
518 
519 class DurationExpression(CombinedExpression):
520     def compile(self, side, compiler, connection):
521         try:
522             output = side.output_field
523         except FieldError:
524             pass
525         else:
526             if output.get_internal_type() == 'DurationField':
527                 sql, params = compiler.compile(side)
528                 return connection.ops.format_for_duration_arithmetic(sql), params
529         return compiler.compile(side)
530 
531     def as_sql(self, compiler, connection):
532         if connection.features.has_native_duration_field:
533             return super().as_sql(compiler, connection)
534         connection.ops.check_expression_support(self)
535         expressions = []
536         expression_params = []
537         sql, params = self.compile(self.lhs, compiler, connection)
538         expressions.append(sql)
539         expression_params.extend(params)
540         sql, params = self.compile(self.rhs, compiler, connection)
541         expressions.append(sql)
542         expression_params.extend(params)
543         # order of precedence
544         expression_wrapper = '(%s)'
545         sql = connection.ops.combine_duration_expression(self.connector, expressions)
546         return expression_wrapper % sql, expression_params
547 
548     def as_sqlite(self, compiler, connection, **extra_context):
549         sql, params = self.as_sql(compiler, connection, **extra_context)
550         if self.connector in {Combinable.MUL, Combinable.DIV}:
551             try:
552                 lhs_type = self.lhs.output_field.get_internal_type()
553                 rhs_type = self.rhs.output_field.get_internal_type()
554             except (AttributeError, FieldError):
555                 pass
556             else:
557                 allowed_fields = {
558                     'DecimalField', 'DurationField', 'FloatField', 'IntegerField',
559                 }
560                 if lhs_type not in allowed_fields or rhs_type not in allowed_fields:
561                     raise DatabaseError(
562                         f'Invalid arguments for operator {self.connector}.'
563                     )
564         return sql, params
565 
566 
567 class TemporalSubtraction(CombinedExpression):
568     output_field = fields.DurationField()
569 
570     def __init__(self, lhs, rhs):
571         super().__init__(lhs, self.SUB, rhs)
572 
573     def as_sql(self, compiler, connection):
574         connection.ops.check_expression_support(self)
575         lhs = compiler.compile(self.lhs)
576         rhs = compiler.compile(self.rhs)
577         return connection.ops.subtract_temporals(self.lhs.output_field.get_internal_type(), lhs, rhs)
578 
579 
580 @deconstructible
581 class F(Combinable):
582     """An object capable of resolving references to existing query objects."""
583 
584     def __init__(self, name):
585         """
586         Arguments:
587          * name: the name of the field this expression references
588         """
589         self.name = name
590 
591     def __repr__(self):
592         return "{}({})".format(self.__class__.__name__, self.name)
593 
594     def resolve_expression(self, query=None, allow_joins=True, reuse=None,
595                            summarize=False, for_save=False):
596         return query.resolve_ref(self.name, allow_joins, reuse, summarize)
597 
598     def asc(self, **kwargs):
599         return OrderBy(self, **kwargs)
600 
601     def desc(self, **kwargs):
602         return OrderBy(self, descending=True, **kwargs)
603 
604     def __eq__(self, other):
605         return self.__class__ == other.__class__ and self.name == other.name
606 
607     def __hash__(self):
608         return hash(self.name)
609 
610 
611 class ResolvedOuterRef(F):
612     """
613     An object that contains a reference to an outer query.
614 
615     In this case, the reference to the outer query has been resolved because
616     the inner query has been used as a subquery.
617     """
618     contains_aggregate = False
619 
620     def as_sql(self, *args, **kwargs):
621         raise ValueError(
622             'This queryset contains a reference to an outer query and may '
623             'only be used in a subquery.'
624         )
625 
626     def resolve_expression(self, *args, **kwargs):
627         col = super().resolve_expression(*args, **kwargs)
628         # FIXME: Rename possibly_multivalued to multivalued and fix detection
629         # for non-multivalued JOINs (e.g. foreign key fields). This should take
630         # into accountonly many-to-many and one-to-many relationships.
631         col.possibly_multivalued = LOOKUP_SEP in self.name
632         return col
633 
634     def relabeled_clone(self, relabels):
635         return self
636 
637     def get_group_by_cols(self, alias=None):
638         return []
639 
640 
641 class OuterRef(F):
642     contains_aggregate = False
643 
644     def resolve_expression(self, *args, **kwargs):
645         if isinstance(self.name, self.__class__):
646             return self.name
647         return ResolvedOuterRef(self.name)
648 
649     def relabeled_clone(self, relabels):
650         return self
651 
652 
653 class Func(SQLiteNumericMixin, Expression):
654     """An SQL function call."""
655     function = None
656     template = '%(function)s(%(expressions)s)'
657     arg_joiner = ', '
658     arity = None  # The number of arguments the function accepts.
659 
660     def __init__(self, *expressions, output_field=None, **extra):
661         if self.arity is not None and len(expressions) != self.arity:
662             raise TypeError(
663                 "'%s' takes exactly %s %s (%s given)" % (
664                     self.__class__.__name__,
665                     self.arity,
666                     "argument" if self.arity == 1 else "arguments",
667                     len(expressions),
668                 )
669             )
670         super().__init__(output_field=output_field)
671         self.source_expressions = self._parse_expressions(*expressions)
672         self.extra = extra
673 
674     def __repr__(self):
675         args = self.arg_joiner.join(str(arg) for arg in self.source_expressions)
676         extra = {**self.extra, **self._get_repr_options()}
677         if extra:
678             extra = ', '.join(str(key) + '=' + str(val) for key, val in sorted(extra.items()))
679             return "{}({}, {})".format(self.__class__.__name__, args, extra)
680         return "{}({})".format(self.__class__.__name__, args)
681 
682     def _get_repr_options(self):
683         """Return a dict of extra __init__() options to include in the repr."""
684         return {}
685 
686     def get_source_expressions(self):
687         return self.source_expressions
688 
689     def set_source_expressions(self, exprs):
690         self.source_expressions = exprs
691 
692     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):
693         c = self.copy()
694         c.is_summary = summarize
695         for pos, arg in enumerate(c.source_expressions):
696             c.source_expressions[pos] = arg.resolve_expression(query, allow_joins, reuse, summarize, for_save)
697         return c
698 
699     def as_sql(self, compiler, connection, function=None, template=None, arg_joiner=None, **extra_context):
700         connection.ops.check_expression_support(self)
701         sql_parts = []
702         params = []
703         for arg in self.source_expressions:
704             arg_sql, arg_params = compiler.compile(arg)
705             sql_parts.append(arg_sql)
706             params.extend(arg_params)
707         data = {**self.extra, **extra_context}
708         # Use the first supplied value in this order: the parameter to this
709         # method, a value supplied in __init__()'s **extra (the value in
710         # `data`), or the value defined on the class.
711         if function is not None:
712             data['function'] = function
713         else:
714             data.setdefault('function', self.function)
715         template = template or data.get('template', self.template)
716         arg_joiner = arg_joiner or data.get('arg_joiner', self.arg_joiner)
717         data['expressions'] = data['field'] = arg_joiner.join(sql_parts)
718         return template % data, params
719 
720     def copy(self):
721         copy = super().copy()
722         copy.source_expressions = self.source_expressions[:]
723         copy.extra = self.extra.copy()
724         return copy
725 
726 
727 class Value(SQLiteNumericMixin, Expression):
728     """Represent a wrapped value as a node within an expression."""
729     # Provide a default value for `for_save` in order to allow unresolved
730     # instances to be compiled until a decision is taken in #25425.
731     for_save = False
732 
733     def __init__(self, value, output_field=None):
734         """
735         Arguments:
736          * value: the value this expression represents. The value will be
737            added into the sql parameter list and properly quoted.
738 
739          * output_field: an instance of the model field type that this
740            expression will return, such as IntegerField() or CharField().
741         """
742         super().__init__(output_field=output_field)
743         self.value = value
744 
745     def __repr__(self):
746         return f'{self.__class__.__name__}({self.value!r})'
747 
748     def as_sql(self, compiler, connection):
749         connection.ops.check_expression_support(self)
750         val = self.value
751         output_field = self._output_field_or_none
752         if output_field is not None:
753             if self.for_save:
754                 val = output_field.get_db_prep_save(val, connection=connection)
755             else:
756                 val = output_field.get_db_prep_value(val, connection=connection)
757             if hasattr(output_field, 'get_placeholder'):
758                 return output_field.get_placeholder(val, compiler, connection), [val]
759         if val is None:
760             # cx_Oracle does not always convert None to the appropriate
761             # NULL type (like in case expressions using numbers), so we
762             # use a literal SQL NULL
763             return 'NULL', []
764         return '%s', [val]
765 
766     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):
767         c = super().resolve_expression(query, allow_joins, reuse, summarize, for_save)
768         c.for_save = for_save
769         return c
770 
771     def get_group_by_cols(self, alias=None):
772         return []
773 
774     def _resolve_output_field(self):
775         if isinstance(self.value, str):
776             return fields.CharField()
777         if isinstance(self.value, bool):
778             return fields.BooleanField()
779         if isinstance(self.value, int):
780             return fields.IntegerField()
781         if isinstance(self.value, float):
782             return fields.FloatField()
783         if isinstance(self.value, datetime.datetime):
784             return fields.DateTimeField()
785         if isinstance(self.value, datetime.date):
786             return fields.DateField()
787         if isinstance(self.value, datetime.time):
788             return fields.TimeField()
789         if isinstance(self.value, datetime.timedelta):
790             return fields.DurationField()
791         if isinstance(self.value, Decimal):
792             return fields.DecimalField()
793         if isinstance(self.value, bytes):
794             return fields.BinaryField()
795         if isinstance(self.value, UUID):
796             return fields.UUIDField()
797 
798 
799 class RawSQL(Expression):
800     def __init__(self, sql, params, output_field=None):
801         if output_field is None:
802             output_field = fields.Field()
803         self.sql, self.params = sql, params
804         super().__init__(output_field=output_field)
805 
806     def __repr__(self):
807         return "{}({}, {})".format(self.__class__.__name__, self.sql, self.params)
808 
809     def as_sql(self, compiler, connection):
810         return '(%s)' % self.sql, self.params
811 
812     def get_group_by_cols(self, alias=None):
813         return [self]
814 
815     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):
816         # Resolve parents fields used in raw SQL.
817         for parent in query.model._meta.get_parent_list():
818             for parent_field in parent._meta.local_fields:
819                 _, column_name = parent_field.get_attname_column()
820                 if column_name.lower() in self.sql.lower():
821                     query.resolve_ref(parent_field.name, allow_joins, reuse, summarize)
822                     break
823         return super().resolve_expression(query, allow_joins, reuse, summarize, for_save)
824 
825 
826 class Star(Expression):
827     def __repr__(self):
828         return "'*'"
829 
830     def as_sql(self, compiler, connection):
831         return '*', []
832 
833 
834 class Col(Expression):
835 
836     contains_column_references = True
837     possibly_multivalued = False
838 
839     def __init__(self, alias, target, output_field=None):
840         if output_field is None:
841             output_field = target
842         super().__init__(output_field=output_field)
843         self.alias, self.target = alias, target
844 
845     def __repr__(self):
846         alias, target = self.alias, self.target
847         identifiers = (alias, str(target)) if alias else (str(target),)
848         return '{}({})'.format(self.__class__.__name__, ', '.join(identifiers))
849 
850     def as_sql(self, compiler, connection):
851         alias, column = self.alias, self.target.column
852         identifiers = (alias, column) if alias else (column,)
853         sql = '.'.join(map(compiler.quote_name_unless_alias, identifiers))
854         return sql, []
855 
856     def relabeled_clone(self, relabels):
857         if self.alias is None:
858             return self
859         return self.__class__(relabels.get(self.alias, self.alias), self.target, self.output_field)
860 
861     def get_group_by_cols(self, alias=None):
862         return [self]
863 
864     def get_db_converters(self, connection):
865         if self.target == self.output_field:
866             return self.output_field.get_db_converters(connection)
867         return (self.output_field.get_db_converters(connection) +
868                 self.target.get_db_converters(connection))
869 
870 
871 class Ref(Expression):
872     """
873     Reference to column alias of the query. For example, Ref('sum_cost') in
874     qs.annotate(sum_cost=Sum('cost')) query.
875     """
876     def __init__(self, refs, source):
877         super().__init__()
878         self.refs, self.source = refs, source
879 
880     def __repr__(self):
881         return "{}({}, {})".format(self.__class__.__name__, self.refs, self.source)
882 
883     def get_source_expressions(self):
884         return [self.source]
885 
886     def set_source_expressions(self, exprs):
887         self.source, = exprs
888 
889     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):
890         # The sub-expression `source` has already been resolved, as this is
891         # just a reference to the name of `source`.
892         return self
893 
894     def relabeled_clone(self, relabels):
895         return self
896 
897     def as_sql(self, compiler, connection):
898         return connection.ops.quote_name(self.refs), []
899 
900     def get_group_by_cols(self, alias=None):
901         return [self]
902 
903 
904 class ExpressionList(Func):
905     """
906     An expression containing multiple expressions. Can be used to provide a
907     list of expressions as an argument to another expression, like an
908     ordering clause.
909     """
910     template = '%(expressions)s'
911 
912     def __init__(self, *expressions, **extra):
913         if not expressions:
914             raise ValueError('%s requires at least one expression.' % self.__class__.__name__)
915         super().__init__(*expressions, **extra)
916 
917     def __str__(self):
918         return self.arg_joiner.join(str(arg) for arg in self.source_expressions)
919 
920     def as_sqlite(self, compiler, connection, **extra_context):
921         # Casting to numeric is unnecessary.
922         return self.as_sql(compiler, connection, **extra_context)
923 
924 
925 class ExpressionWrapper(Expression):
926     """
927     An expression that can wrap another expression so that it can provide
928     extra context to the inner expression, such as the output_field.
929     """
930 
931     def __init__(self, expression, output_field):
932         super().__init__(output_field=output_field)
933         self.expression = expression
934 
935     def set_source_expressions(self, exprs):
936         self.expression = exprs[0]
937 
938     def get_source_expressions(self):
939         return [self.expression]
940 
941     def get_group_by_cols(self, alias=None):
942         if isinstance(self.expression, Expression):
943             expression = self.expression.copy()
944             expression.output_field = self.output_field
945             return expression.get_group_by_cols(alias=alias)
946         # For non-expressions e.g. an SQL WHERE clause, the entire
947         # `expression` must be included in the GROUP BY clause.
948         return super().get_group_by_cols()
949 
950     def as_sql(self, compiler, connection):
951         return compiler.compile(self.expression)
952 
953     def __repr__(self):
954         return "{}({})".format(self.__class__.__name__, self.expression)
955 
956 
957 class When(Expression):
958     template = 'WHEN %(condition)s THEN %(result)s'
959     # This isn't a complete conditional expression, must be used in Case().
960     conditional = False
961 
962     def __init__(self, condition=None, then=None, **lookups):
963         if lookups:
964             if condition is None:
965                 condition, lookups = Q(**lookups), None
966             elif getattr(condition, 'conditional', False):
967                 condition, lookups = Q(condition, **lookups), None
968         if condition is None or not getattr(condition, 'conditional', False) or lookups:
969             raise TypeError(
970                 'When() supports a Q object, a boolean expression, or lookups '
971                 'as a condition.'
972             )
973         if isinstance(condition, Q) and not condition:
974             raise ValueError("An empty Q() can't be used as a When() condition.")
975         super().__init__(output_field=None)
976         self.condition = condition
977         self.result = self._parse_expressions(then)[0]
978 
979     def __str__(self):
980         return "WHEN %r THEN %r" % (self.condition, self.result)
981 
982     def __repr__(self):
983         return "<%s: %s>" % (self.__class__.__name__, self)
984 
985     def get_source_expressions(self):
986         return [self.condition, self.result]
987 
988     def set_source_expressions(self, exprs):
989         self.condition, self.result = exprs
990 
991     def get_source_fields(self):
992         # We're only interested in the fields of the result expressions.
993         return [self.result._output_field_or_none]
994 
995     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):
996         c = self.copy()
997         c.is_summary = summarize
998         if hasattr(c.condition, 'resolve_expression'):
999             c.condition = c.condition.resolve_expression(query, allow_joins, reuse, summarize, False)
1000         c.result = c.result.resolve_expression(query, allow_joins, reuse, summarize, for_save)
1001         return c
1002 
1003     def as_sql(self, compiler, connection, template=None, **extra_context):
1004         connection.ops.check_expression_support(self)
1005         template_params = extra_context
1006         sql_params = []
1007         condition_sql, condition_params = compiler.compile(self.condition)
1008         template_params['condition'] = condition_sql
1009         sql_params.extend(condition_params)
1010         result_sql, result_params = compiler.compile(self.result)
1011         template_params['result'] = result_sql
1012         sql_params.extend(result_params)
1013         template = template or self.template
1014         return template % template_params, sql_params
1015 
1016     def get_group_by_cols(self, alias=None):
1017         # This is not a complete expression and cannot be used in GROUP BY.
1018         cols = []
1019         for source in self.get_source_expressions():
1020             cols.extend(source.get_group_by_cols())
1021         return cols
1022 
1023 
1024 class Case(Expression):
1025     """
1026     An SQL searched CASE expression:
1027 
1028         CASE
1029             WHEN n > 0
1030                 THEN 'positive'
1031             WHEN n < 0
1032                 THEN 'negative'
1033             ELSE 'zero'
1034         END
1035     """
1036     template = 'CASE %(cases)s ELSE %(default)s END'
1037     case_joiner = ' '
1038 
1039     def __init__(self, *cases, default=None, output_field=None, **extra):
1040         if not all(isinstance(case, When) for case in cases):
1041             raise TypeError("Positional arguments must all be When objects.")
1042         super().__init__(output_field)
1043         self.cases = list(cases)
1044         self.default = self._parse_expressions(default)[0]
1045         self.extra = extra
1046 
1047     def __str__(self):
1048         return "CASE %s, ELSE %r" % (', '.join(str(c) for c in self.cases), self.default)
1049 
1050     def __repr__(self):
1051         return "<%s: %s>" % (self.__class__.__name__, self)
1052 
1053     def get_source_expressions(self):
1054         return self.cases + [self.default]
1055 
1056     def set_source_expressions(self, exprs):
1057         *self.cases, self.default = exprs
1058 
1059     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):
1060         c = self.copy()
1061         c.is_summary = summarize
1062         for pos, case in enumerate(c.cases):
1063             c.cases[pos] = case.resolve_expression(query, allow_joins, reuse, summarize, for_save)
1064         c.default = c.default.resolve_expression(query, allow_joins, reuse, summarize, for_save)
1065         return c
1066 
1067     def copy(self):
1068         c = super().copy()
1069         c.cases = c.cases[:]
1070         return c
1071 
1072     def as_sql(self, compiler, connection, template=None, case_joiner=None, **extra_context):
1073         connection.ops.check_expression_support(self)
1074         if not self.cases:
1075             return compiler.compile(self.default)
1076         template_params = {**self.extra, **extra_context}
1077         case_parts = []
1078         sql_params = []
1079         for case in self.cases:
1080             try:
1081                 case_sql, case_params = compiler.compile(case)
1082             except EmptyResultSet:
1083                 continue
1084             case_parts.append(case_sql)
1085             sql_params.extend(case_params)
1086         default_sql, default_params = compiler.compile(self.default)
1087         if not case_parts:
1088             return default_sql, default_params
1089         case_joiner = case_joiner or self.case_joiner
1090         template_params['cases'] = case_joiner.join(case_parts)
1091         template_params['default'] = default_sql
1092         sql_params.extend(default_params)
1093         template = template or template_params.get('template', self.template)
1094         sql = template % template_params
1095         if self._output_field_or_none is not None:
1096             sql = connection.ops.unification_cast_sql(self.output_field) % sql
1097         return sql, sql_params
1098 
1099     def get_group_by_cols(self, alias=None):
1100         if not self.cases:
1101             return self.default.get_group_by_cols(alias)
1102         return super().get_group_by_cols(alias)
1103 
1104 
1105 class Subquery(BaseExpression, Combinable):
1106     """
1107     An explicit subquery. It may contain OuterRef() references to the outer
1108     query which will be resolved when it is applied to that query.
1109     """
1110     template = '(%(subquery)s)'
1111     contains_aggregate = False
1112 
1113     def __init__(self, queryset, output_field=None, **extra):
1114         # Allow the usage of both QuerySet and sql.Query objects.
1115         self.query = getattr(queryset, 'query', queryset)
1116         self.extra = extra
1117         super().__init__(output_field)
1118 
1119     def get_source_expressions(self):
1120         return [self.query]
1121 
1122     def set_source_expressions(self, exprs):
1123         self.query = exprs[0]
1124 
1125     def _resolve_output_field(self):
1126         return self.query.output_field
1127 
1128     def copy(self):
1129         clone = super().copy()
1130         clone.query = clone.query.clone()
1131         return clone
1132 
1133     @property
1134     def external_aliases(self):
1135         return self.query.external_aliases
1136 
1137     def get_external_cols(self):
1138         return self.query.get_external_cols()
1139 
1140     def as_sql(self, compiler, connection, template=None, query=None, **extra_context):
1141         connection.ops.check_expression_support(self)
1142         template_params = {**self.extra, **extra_context}
1143         query = query or self.query
1144         subquery_sql, sql_params = query.as_sql(compiler, connection)
1145         template_params['subquery'] = subquery_sql[1:-1]
1146 
1147         template = template or template_params.get('template', self.template)
1148         sql = template % template_params
1149         return sql, sql_params
1150 
1151     def get_group_by_cols(self, alias=None):
1152         if alias:
1153             return [Ref(alias, self)]
1154         external_cols = self.get_external_cols()
1155         if any(col.possibly_multivalued for col in external_cols):
1156             return [self]
1157         return external_cols
1158 
1159 
1160 class Exists(Subquery):
1161     template = 'EXISTS(%(subquery)s)'
1162     output_field = fields.BooleanField()
1163 
1164     def __init__(self, queryset, negated=False, **kwargs):
1165         self.negated = negated
1166         super().__init__(queryset, **kwargs)
1167 
1168     def __invert__(self):
1169         clone = self.copy()
1170         clone.negated = not self.negated
1171         return clone
1172 
1173     def as_sql(self, compiler, connection, template=None, **extra_context):
1174         query = self.query.exists(using=connection.alias)
1175         sql, params = super().as_sql(
1176             compiler,
1177             connection,
1178             template=template,
1179             query=query,
1180             **extra_context,
1181         )
1182         if self.negated:
1183             sql = 'NOT {}'.format(sql)
1184         return sql, params
1185 
1186     def select_format(self, compiler, sql, params):
1187         # Wrap EXISTS() with a CASE WHEN expression if a database backend
1188         # (e.g. Oracle) doesn't support boolean expression in SELECT or GROUP
1189         # BY list.
1190         if not compiler.connection.features.supports_boolean_expr_in_select_clause:
1191             sql = 'CASE WHEN {} THEN 1 ELSE 0 END'.format(sql)
1192         return sql, params
1193 
1194 
1195 class OrderBy(Expression):
1196     template = '%(expression)s %(ordering)s'
1197     conditional = False
1198 
1199     def __init__(self, expression, descending=False, nulls_first=False, nulls_last=False):
1200         if nulls_first and nulls_last:
1201             raise ValueError('nulls_first and nulls_last are mutually exclusive')
1202         self.nulls_first = nulls_first
1203         self.nulls_last = nulls_last
1204         self.descending = descending
1205         if not hasattr(expression, 'resolve_expression'):
1206             raise ValueError('expression must be an expression type')
1207         self.expression = expression
1208 
1209     def __repr__(self):
1210         return "{}({}, descending={})".format(
1211             self.__class__.__name__, self.expression, self.descending)
1212 
1213     def set_source_expressions(self, exprs):
1214         self.expression = exprs[0]
1215 
1216     def get_source_expressions(self):
1217         return [self.expression]
1218 
1219     def as_sql(self, compiler, connection, template=None, **extra_context):
1220         template = template or self.template
1221         if connection.features.supports_order_by_nulls_modifier:
1222             if self.nulls_last:
1223                 template = '%s NULLS LAST' % template
1224             elif self.nulls_first:
1225                 template = '%s NULLS FIRST' % template
1226         else:
1227             if self.nulls_last and not (
1228                 self.descending and connection.features.order_by_nulls_first
1229             ):
1230                 template = '%%(expression)s IS NULL, %s' % template
1231             elif self.nulls_first and not (
1232                 not self.descending and connection.features.order_by_nulls_first
1233             ):
1234                 template = '%%(expression)s IS NOT NULL, %s' % template
1235         connection.ops.check_expression_support(self)
1236         expression_sql, params = compiler.compile(self.expression)
1237         placeholders = {
1238             'expression': expression_sql,
1239             'ordering': 'DESC' if self.descending else 'ASC',
1240             **extra_context,
1241         }
1242         params *= template.count('%(expression)s')
1243         return (template % placeholders).rstrip(), params
1244 
1245     def as_oracle(self, compiler, connection):
1246         # Oracle doesn't allow ORDER BY EXISTS() unless it's wrapped in
1247         # a CASE WHEN.
1248         if isinstance(self.expression, Exists):
1249             copy = self.copy()
1250             copy.expression = Case(
1251                 When(self.expression, then=True),
1252                 default=False,
1253             )
1254             return copy.as_sql(compiler, connection)
1255         return self.as_sql(compiler, connection)
1256 
1257     def get_group_by_cols(self, alias=None):
1258         cols = []
1259         for source in self.get_source_expressions():
1260             cols.extend(source.get_group_by_cols())
1261         return cols
1262 
1263     def reverse_ordering(self):
1264         self.descending = not self.descending
1265         if self.nulls_first or self.nulls_last:
1266             self.nulls_first = not self.nulls_first
1267             self.nulls_last = not self.nulls_last
1268         return self
1269 
1270     def asc(self):
1271         self.descending = False
1272 
1273     def desc(self):
1274         self.descending = True
1275 
1276 
1277 class Window(SQLiteNumericMixin, Expression):
1278     template = '%(expression)s OVER (%(window)s)'
1279     # Although the main expression may either be an aggregate or an
1280     # expression with an aggregate function, the GROUP BY that will
1281     # be introduced in the query as a result is not desired.
1282     contains_aggregate = False
1283     contains_over_clause = True
1284     filterable = False
1285 
1286     def __init__(self, expression, partition_by=None, order_by=None, frame=None, output_field=None):
1287         self.partition_by = partition_by
1288         self.order_by = order_by
1289         self.frame = frame
1290 
1291         if not getattr(expression, 'window_compatible', False):
1292             raise ValueError(
1293                 "Expression '%s' isn't compatible with OVER clauses." %
1294                 expression.__class__.__name__
1295             )
1296 
1297         if self.partition_by is not None:
1298             if not isinstance(self.partition_by, (tuple, list)):
1299                 self.partition_by = (self.partition_by,)
1300             self.partition_by = ExpressionList(*self.partition_by)
1301 
1302         if self.order_by is not None:
1303             if isinstance(self.order_by, (list, tuple)):
1304                 self.order_by = ExpressionList(*self.order_by)
1305             elif not isinstance(self.order_by, BaseExpression):
1306                 raise ValueError(
1307                     'order_by must be either an Expression or a sequence of '
1308                     'expressions.'
1309                 )
1310         super().__init__(output_field=output_field)
1311         self.source_expression = self._parse_expressions(expression)[0]
1312 
1313     def _resolve_output_field(self):
1314         return self.source_expression.output_field
1315 
1316     def get_source_expressions(self):
1317         return [self.source_expression, self.partition_by, self.order_by, self.frame]
1318 
1319     def set_source_expressions(self, exprs):
1320         self.source_expression, self.partition_by, self.order_by, self.frame = exprs
1321 
1322     def as_sql(self, compiler, connection, template=None):
1323         connection.ops.check_expression_support(self)
1324         if not connection.features.supports_over_clause:
1325             raise NotSupportedError('This backend does not support window expressions.')
1326         expr_sql, params = compiler.compile(self.source_expression)
1327         window_sql, window_params = [], []
1328 
1329         if self.partition_by is not None:
1330             sql_expr, sql_params = self.partition_by.as_sql(
1331                 compiler=compiler, connection=connection,
1332                 template='PARTITION BY %(expressions)s',
1333             )
1334             window_sql.extend(sql_expr)
1335             window_params.extend(sql_params)
1336 
1337         if self.order_by is not None:
1338             window_sql.append(' ORDER BY ')
1339             order_sql, order_params = compiler.compile(self.order_by)
1340             window_sql.extend(order_sql)
1341             window_params.extend(order_params)
1342 
1343         if self.frame:
1344             frame_sql, frame_params = compiler.compile(self.frame)
1345             window_sql.append(' ' + frame_sql)
1346             window_params.extend(frame_params)
1347 
1348         params.extend(window_params)
1349         template = template or self.template
1350 
1351         return template % {
1352             'expression': expr_sql,
1353             'window': ''.join(window_sql).strip()
1354         }, params
1355 
1356     def as_sqlite(self, compiler, connection):
1357         if isinstance(self.output_field, fields.DecimalField):
1358             # Casting to numeric must be outside of the window expression.
1359             copy = self.copy()
1360             source_expressions = copy.get_source_expressions()
1361             source_expressions[0].output_field = fields.FloatField()
1362             copy.set_source_expressions(source_expressions)
1363             return super(Window, copy).as_sqlite(compiler, connection)
1364         return self.as_sql(compiler, connection)
1365 
1366     def __str__(self):
1367         return '{} OVER ({}{}{})'.format(
1368             str(self.source_expression),
1369             'PARTITION BY ' + str(self.partition_by) if self.partition_by else '',
1370             'ORDER BY ' + str(self.order_by) if self.order_by else '',
1371             str(self.frame or ''),
1372         )
1373 
1374     def __repr__(self):
1375         return '<%s: %s>' % (self.__class__.__name__, self)
1376 
1377     def get_group_by_cols(self, alias=None):
1378         return []
1379 
1380 
1381 class WindowFrame(Expression):
1382     """
1383     Model the frame clause in window expressions. There are two types of frame
1384     clauses which are subclasses, however, all processing and validation (by no
1385     means intended to be complete) is done here. Thus, providing an end for a
1386     frame is optional (the default is UNBOUNDED FOLLOWING, which is the last
1387     row in the frame).
1388     """
1389     template = '%(frame_type)s BETWEEN %(start)s AND %(end)s'
1390 
1391     def __init__(self, start=None, end=None):
1392         self.start = Value(start)
1393         self.end = Value(end)
1394 
1395     def set_source_expressions(self, exprs):
1396         self.start, self.end = exprs
1397 
1398     def get_source_expressions(self):
1399         return [self.start, self.end]
1400 
1401     def as_sql(self, compiler, connection):
1402         connection.ops.check_expression_support(self)
1403         start, end = self.window_frame_start_end(connection, self.start.value, self.end.value)
1404         return self.template % {
1405             'frame_type': self.frame_type,
1406             'start': start,
1407             'end': end,
1408         }, []
1409 
1410     def __repr__(self):
1411         return '<%s: %s>' % (self.__class__.__name__, self)
1412 
1413     def get_group_by_cols(self, alias=None):
1414         return []
1415 
1416     def __str__(self):
1417         if self.start.value is not None and self.start.value < 0:
1418             start = '%d %s' % (abs(self.start.value), connection.ops.PRECEDING)
1419         elif self.start.value is not None and self.start.value == 0:
1420             start = connection.ops.CURRENT_ROW
1421         else:
1422             start = connection.ops.UNBOUNDED_PRECEDING
1423 
1424         if self.end.value is not None and self.end.value > 0:
1425             end = '%d %s' % (self.end.value, connection.ops.FOLLOWING)
1426         elif self.end.value is not None and self.end.value == 0:
1427             end = connection.ops.CURRENT_ROW
1428         else:
1429             end = connection.ops.UNBOUNDED_FOLLOWING
1430         return self.template % {
1431             'frame_type': self.frame_type,
1432             'start': start,
1433             'end': end,
1434         }
1435 
1436     def window_frame_start_end(self, connection, start, end):
1437         raise NotImplementedError('Subclasses must implement window_frame_start_end().')
1438 
1439 
1440 class RowRange(WindowFrame):
1441     frame_type = 'ROWS'
1442 
1443     def window_frame_start_end(self, connection, start, end):
1444         return connection.ops.window_frame_rows_start_end(start, end)
1445 
1446 
1447 class ValueRange(WindowFrame):
1448     frame_type = 'RANGE'
1449 
1450     def window_frame_start_end(self, connection, start, end):
1451         return connection.ops.window_frame_range_start_end(start, end)

</code><intended_behavior>Update or ensure that when expressions involving 'Coalesce' are evaluated, especially in the context of an anticipated 'EmptyResultSet' from a filter condition like 'pk__in=[]', the expression logic defaults to the 'Coalesce' specified value instead of yielding 'None'. This would ensure that 'Coalesce' effectively provides a default value even when no rows are matched, addressing the core issue and maintaining existing functionality where applicable.</intended_behavior>]
2025-10-18 01:19:43.698 | INFO     | Overall retry 0 succeeded; ending workflow
2025-10-18 01:19:43.698 | INFO     | Search-only: skipping patch selection
2025-10-18 01:19:43.880 | INFO     | Task django__django-14430 completed successfully.
2025-10-18 01:19:43.881 | INFO     | No patch generated. You can try running ACR again.
