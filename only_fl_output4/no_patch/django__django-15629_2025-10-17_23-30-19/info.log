2025-10-17 23:30:19.545 | INFO     | Starting overall retry 0 with model gpt-4-0125-preview
2025-10-17 23:30:22.410 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=652, output_tokens=12, cost=0.006880
2025-10-17 23:30:22.410 | INFO     | Test agent decides that the issue statement does not contain reproduction steps; skipping reproducer tracing
2025-10-17 23:30:22.414 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-17 23:30:30.936 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=952, output_tokens=391, cost=0.021250
2025-10-17 23:30:30.945 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-17 23:30:34.231 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=745, output_tokens=70, cost=0.009550
2025-10-17 23:30:34.233 | DEBUG    | Extracted a valid json.
2025-10-17 23:30:34.233 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_class(\"Account\")",
        "search_class(\"Address\")",
        "search_class(\"Profile\")",
        "search_class(\"ShortUUIDField\")",
        "search_method(\"makemigrations\")",
        "search_method(\"sqlmigrate\")"
    ],
    "bug_locations": []
}
2025-10-17 23:30:34.241 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-17 23:30:34.241 | DEBUG    | <Agent search> Analyzing search results.
2025-10-17 23:30:45.289 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=1574, output_tokens=513, cost=0.031130
2025-10-17 23:30:45.302 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-17 23:30:47.557 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=2303, output_tokens=84, cost=0.025550
2025-10-17 23:30:47.561 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-17 23:30:50.831 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=438, output_tokens=29, cost=0.005250
2025-10-17 23:30:50.833 | DEBUG    | Extracted a valid json.
2025-10-17 23:30:50.838 | DEBUG    | Agent proxy return the following json: {
    "API_calls": ["search_code(\"db_collation\")", "search_code(\"ForeignKey\")"],
    "bug_locations": []
}
2025-10-17 23:30:51.063 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-17 23:30:51.063 | DEBUG    | <Agent search> Analyzing search results.
2025-10-17 23:31:07.888 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=3330, output_tokens=747, cost=0.055710
2025-10-17 23:31:07.895 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-17 23:31:18.840 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=4293, output_tokens=503, cost=0.058020
2025-10-17 23:31:18.851 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-17 23:31:27.460 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=857, output_tokens=272, cost=0.016730
2025-10-17 23:31:27.461 | DEBUG    | Extracted a valid json.
2025-10-17 23:31:27.461 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [],
    "bug_locations": [
        {
            "file": "django/db/backends/mysql/schema.py",
            "class": "",
            "method": "",
            "intended_behavior": "Ensure that when a foreign key is added or modified, the `db_collation` of the referenced primary key column is applied to the foreign key column. This may involve adjusting the SQL statement generation to include the `COLLATE` clause with the appropriate collation when altering foreign key columns."
        },
        {
            "file": "django/db/migrations/autodetector.py",
            "class": "Migration autodetector",
            "method": "",
            "intended_behavior": "Enhance the detection logic to identify if a field involved in a migration is a foreign key referencing a field with a specific `db_collation`. If so, the migration operation should include steps to apply the same `db_collation` to the foreign key column."
        },
        {
            "file": "django/db/models/fields/__init__.py",
            "class": "",
            "method": "",
            "intended_behavior": "Ensure consistent handling and documentation around `db_collation` attribute, so it is clear how it should be propagated in the context of model relationships and migrations."
        }
    ]
}
2025-10-17 23:31:27.482 | DEBUG    | Bug location extracted successfully: [<file>django/db/backends/mysql/schema.py</file>
<class>None</class>
<method>None</method>
<code>
1 from django.db.backends.base.schema import BaseDatabaseSchemaEditor
2 from django.db.models import NOT_PROVIDED
3 
4 
5 class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):
6 
7     sql_rename_table = "RENAME TABLE %(old_table)s TO %(new_table)s"
8 
9     sql_alter_column_null = "MODIFY %(column)s %(type)s NULL"
10     sql_alter_column_not_null = "MODIFY %(column)s %(type)s NOT NULL"
11     sql_alter_column_type = "MODIFY %(column)s %(type)s"
12     sql_alter_column_collate = "MODIFY %(column)s %(type)s%(collation)s"
13     sql_alter_column_no_default_null = "ALTER COLUMN %(column)s SET DEFAULT NULL"
14 
15     # No 'CASCADE' which works as a no-op in MySQL but is undocumented
16     sql_delete_column = "ALTER TABLE %(table)s DROP COLUMN %(column)s"
17 
18     sql_delete_unique = "ALTER TABLE %(table)s DROP INDEX %(name)s"
19     sql_create_column_inline_fk = (
20         ", ADD CONSTRAINT %(name)s FOREIGN KEY (%(column)s) "
21         "REFERENCES %(to_table)s(%(to_column)s)"
22     )
23     sql_delete_fk = "ALTER TABLE %(table)s DROP FOREIGN KEY %(name)s"
24 
25     sql_delete_index = "DROP INDEX %(name)s ON %(table)s"
26 
27     sql_create_pk = (
28         "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s PRIMARY KEY (%(columns)s)"
29     )
30     sql_delete_pk = "ALTER TABLE %(table)s DROP PRIMARY KEY"
31 
32     sql_create_index = "CREATE INDEX %(name)s ON %(table)s (%(columns)s)%(extra)s"
33 
34     @property
35     def sql_delete_check(self):
36         if self.connection.mysql_is_mariadb:
37             # The name of the column check constraint is the same as the field
38             # name on MariaDB. Adding IF EXISTS clause prevents migrations
39             # crash. Constraint is removed during a "MODIFY" column statement.
40             return "ALTER TABLE %(table)s DROP CONSTRAINT IF EXISTS %(name)s"
41         return "ALTER TABLE %(table)s DROP CHECK %(name)s"
42 
43     @property
44     def sql_rename_column(self):
45         # MariaDB >= 10.5.2 and MySQL >= 8.0.4 support an
46         # "ALTER TABLE ... RENAME COLUMN" statement.
47         if self.connection.mysql_is_mariadb:
48             if self.connection.mysql_version >= (10, 5, 2):
49                 return super().sql_rename_column
50         elif self.connection.mysql_version >= (8, 0, 4):
51             return super().sql_rename_column
52         return "ALTER TABLE %(table)s CHANGE %(old_column)s %(new_column)s %(type)s"
53 
54     def quote_value(self, value):
55         self.connection.ensure_connection()
56         if isinstance(value, str):
57             value = value.replace("%", "%%")
58         # MySQLdb escapes to string, PyMySQL to bytes.
59         quoted = self.connection.connection.escape(
60             value, self.connection.connection.encoders
61         )
62         if isinstance(value, str) and isinstance(quoted, bytes):
63             quoted = quoted.decode()
64         return quoted
65 
66     def _is_limited_data_type(self, field):
67         db_type = field.db_type(self.connection)
68         return (
69             db_type is not None
70             and db_type.lower() in self.connection._limited_data_types
71         )
72 
73     def skip_default(self, field):
74         if not self._supports_limited_data_type_defaults:
75             return self._is_limited_data_type(field)
76         return False
77 
78     def skip_default_on_alter(self, field):
79         if self._is_limited_data_type(field) and not self.connection.mysql_is_mariadb:
80             # MySQL doesn't support defaults for BLOB and TEXT in the
81             # ALTER COLUMN statement.
82             return True
83         return False
84 
85     @property
86     def _supports_limited_data_type_defaults(self):
87         # MariaDB and MySQL >= 8.0.13 support defaults for BLOB and TEXT.
88         if self.connection.mysql_is_mariadb:
89             return True
90         return self.connection.mysql_version >= (8, 0, 13)
91 
92     def _column_default_sql(self, field):
93         if (
94             not self.connection.mysql_is_mariadb
95             and self._supports_limited_data_type_defaults
96             and self._is_limited_data_type(field)
97         ):
98             # MySQL supports defaults for BLOB and TEXT columns only if the
99             # default value is written as an expression i.e. in parentheses.
100             return "(%s)"
101         return super()._column_default_sql(field)
102 
103     def add_field(self, model, field):
104         super().add_field(model, field)
105 
106         # Simulate the effect of a one-off default.
107         # field.default may be unhashable, so a set isn't used for "in" check.
108         if self.skip_default(field) and field.default not in (None, NOT_PROVIDED):
109             effective_default = self.effective_default(field)
110             self.execute(
111                 "UPDATE %(table)s SET %(column)s = %%s"
112                 % {
113                     "table": self.quote_name(model._meta.db_table),
114                     "column": self.quote_name(field.column),
115                 },
116                 [effective_default],
117             )
118 
119     def _field_should_be_indexed(self, model, field):
120         if not super()._field_should_be_indexed(model, field):
121             return False
122 
123         storage = self.connection.introspection.get_storage_engine(
124             self.connection.cursor(), model._meta.db_table
125         )
126         # No need to create an index for ForeignKey fields except if
127         # db_constraint=False because the index from that constraint won't be
128         # created.
129         if (
130             storage == "InnoDB"
131             and field.get_internal_type() == "ForeignKey"
132             and field.db_constraint
133         ):
134             return False
135         return not self._is_limited_data_type(field)
136 
137     def _delete_composed_index(self, model, fields, *args):
138         """
139         MySQL can remove an implicit FK index on a field when that field is
140         covered by another index like a unique_together. "covered" here means
141         that the more complex index starts like the simpler one.
142         https://bugs.mysql.com/bug.php?id=37910 / Django ticket #24757
143         We check here before removing the [unique|index]_together if we have to
144         recreate a FK index.
145         """
146         first_field = model._meta.get_field(fields[0])
147         if first_field.get_internal_type() == "ForeignKey":
148             constraint_names = self._constraint_names(
149                 model, [first_field.column], index=True
150             )
151             if not constraint_names:
152                 self.execute(
153                     self._create_index_sql(model, fields=[first_field], suffix="")
154                 )
155         return super()._delete_composed_index(model, fields, *args)
156 
157     def _set_field_new_type_null_status(self, field, new_type):
158         """
159         Keep the null property of the old field. If it has changed, it will be
160         handled separately.
161         """
162         if field.null:
163             new_type += " NULL"
164         else:
165             new_type += " NOT NULL"
166         return new_type
167 
168     def _alter_column_type_sql(self, model, old_field, new_field, new_type):
169         new_type = self._set_field_new_type_null_status(old_field, new_type)
170         return super()._alter_column_type_sql(model, old_field, new_field, new_type)
171 
172     def _rename_field_sql(self, table, old_field, new_field, new_type):
173         new_type = self._set_field_new_type_null_status(old_field, new_type)
174         return super()._rename_field_sql(table, old_field, new_field, new_type)

</code><intended_behavior>Ensure that when a foreign key is added or modified, the `db_collation` of the referenced primary key column is applied to the foreign key column. This may involve adjusting the SQL statement generation to include the `COLLATE` clause with the appropriate collation when altering foreign key columns.</intended_behavior>, <file>django/db/migrations/autodetector.py</file>
<class>None</class>
<method>None</method>
<code>
1 import functools
2 import re
3 from itertools import chain
4 
5 from django.conf import settings
6 from django.db import models
7 from django.db.migrations import operations
8 from django.db.migrations.migration import Migration
9 from django.db.migrations.operations.models import AlterModelOptions
10 from django.db.migrations.optimizer import MigrationOptimizer
11 from django.db.migrations.questioner import MigrationQuestioner
12 from django.db.migrations.utils import (
13     COMPILED_REGEX_TYPE,
14     RegexObject,
15     resolve_relation,
16 )
17 from django.utils.topological_sort import stable_topological_sort
18 
19 
20 class MigrationAutodetector:
21     """
22     Take a pair of ProjectStates and compare them to see what the first would
23     need doing to make it match the second (the second usually being the
24     project's current state).
25 
26     Note that this naturally operates on entire projects at a time,
27     as it's likely that changes interact (for example, you can't
28     add a ForeignKey without having a migration to add the table it
29     depends on first). A user interface may offer single-app usage
30     if it wishes, with the caveat that it may not always be possible.
31     """
32 
33     def __init__(self, from_state, to_state, questioner=None):
34         self.from_state = from_state
35         self.to_state = to_state
36         self.questioner = questioner or MigrationQuestioner()
37         self.existing_apps = {app for app, model in from_state.models}
38 
39     def changes(self, graph, trim_to_apps=None, convert_apps=None, migration_name=None):
40         """
41         Main entry point to produce a list of applicable changes.
42         Take a graph to base names on and an optional set of apps
43         to try and restrict to (restriction is not guaranteed)
44         """
45         changes = self._detect_changes(convert_apps, graph)
46         changes = self.arrange_for_graph(changes, graph, migration_name)
47         if trim_to_apps:
48             changes = self._trim_to_apps(changes, trim_to_apps)
49         return changes
50 
51     def deep_deconstruct(self, obj):
52         """
53         Recursive deconstruction for a field and its arguments.
54         Used for full comparison for rename/alter; sometimes a single-level
55         deconstruction will not compare correctly.
56         """
57         if isinstance(obj, list):
58             return [self.deep_deconstruct(value) for value in obj]
59         elif isinstance(obj, tuple):
60             return tuple(self.deep_deconstruct(value) for value in obj)
61         elif isinstance(obj, dict):
62             return {key: self.deep_deconstruct(value) for key, value in obj.items()}
63         elif isinstance(obj, functools.partial):
64             return (
65                 obj.func,
66                 self.deep_deconstruct(obj.args),
67                 self.deep_deconstruct(obj.keywords),
68             )
69         elif isinstance(obj, COMPILED_REGEX_TYPE):
70             return RegexObject(obj)
71         elif isinstance(obj, type):
72             # If this is a type that implements 'deconstruct' as an instance method,
73             # avoid treating this as being deconstructible itself - see #22951
74             return obj
75         elif hasattr(obj, "deconstruct"):
76             deconstructed = obj.deconstruct()
77             if isinstance(obj, models.Field):
78                 # we have a field which also returns a name
79                 deconstructed = deconstructed[1:]
80             path, args, kwargs = deconstructed
81             return (
82                 path,
83                 [self.deep_deconstruct(value) for value in args],
84                 {key: self.deep_deconstruct(value) for key, value in kwargs.items()},
85             )
86         else:
87             return obj
88 
89     def only_relation_agnostic_fields(self, fields):
90         """
91         Return a definition of the fields that ignores field names and
92         what related fields actually relate to. Used for detecting renames (as
93         the related fields change during renames).
94         """
95         fields_def = []
96         for name, field in sorted(fields.items()):
97             deconstruction = self.deep_deconstruct(field)
98             if field.remote_field and field.remote_field.model:
99                 deconstruction[2].pop("to", None)
100             fields_def.append(deconstruction)
101         return fields_def
102 
103     def _detect_changes(self, convert_apps=None, graph=None):
104         """
105         Return a dict of migration plans which will achieve the
106         change from from_state to to_state. The dict has app labels
107         as keys and a list of migrations as values.
108 
109         The resulting migrations aren't specially named, but the names
110         do matter for dependencies inside the set.
111 
112         convert_apps is the list of apps to convert to use migrations
113         (i.e. to make initial migrations for, in the usual case)
114 
115         graph is an optional argument that, if provided, can help improve
116         dependency generation and avoid potential circular dependencies.
117         """
118         # The first phase is generating all the operations for each app
119         # and gathering them into a big per-app list.
120         # Then go through that list, order it, and split into migrations to
121         # resolve dependencies caused by M2Ms and FKs.
122         self.generated_operations = {}
123         self.altered_indexes = {}
124         self.altered_constraints = {}
125 
126         # Prepare some old/new state and model lists, separating
127         # proxy models and ignoring unmigrated apps.
128         self.old_model_keys = set()
129         self.old_proxy_keys = set()
130         self.old_unmanaged_keys = set()
131         self.new_model_keys = set()
132         self.new_proxy_keys = set()
133         self.new_unmanaged_keys = set()
134         for (app_label, model_name), model_state in self.from_state.models.items():
135             if not model_state.options.get("managed", True):
136                 self.old_unmanaged_keys.add((app_label, model_name))
137             elif app_label not in self.from_state.real_apps:
138                 if model_state.options.get("proxy"):
139                     self.old_proxy_keys.add((app_label, model_name))
140                 else:
141                     self.old_model_keys.add((app_label, model_name))
142 
143         for (app_label, model_name), model_state in self.to_state.models.items():
144             if not model_state.options.get("managed", True):
145                 self.new_unmanaged_keys.add((app_label, model_name))
146             elif app_label not in self.from_state.real_apps or (
147                 convert_apps and app_label in convert_apps
148             ):
149                 if model_state.options.get("proxy"):
150                     self.new_proxy_keys.add((app_label, model_name))
151                 else:
152                     self.new_model_keys.add((app_label, model_name))
153 
154         self.from_state.resolve_fields_and_relations()
155         self.to_state.resolve_fields_and_relations()
156 
157         # Renames have to come first
158         self.generate_renamed_models()
159 
160         # Prepare lists of fields and generate through model map
161         self._prepare_field_lists()
162         self._generate_through_model_map()
163 
164         # Generate non-rename model operations
165         self.generate_deleted_models()
166         self.generate_created_models()
167         self.generate_deleted_proxies()
168         self.generate_created_proxies()
169         self.generate_altered_options()
170         self.generate_altered_managers()
171 
172         # Create the altered indexes and store them in self.altered_indexes.
173         # This avoids the same computation in generate_removed_indexes()
174         # and generate_added_indexes().
175         self.create_altered_indexes()
176         self.create_altered_constraints()
177         # Generate index removal operations before field is removed
178         self.generate_removed_constraints()
179         self.generate_removed_indexes()
180         # Generate field renaming operations.
181         self.generate_renamed_fields()
182         # Generate removal of foo together.
183         self.generate_removed_altered_unique_together()
184         self.generate_removed_altered_index_together()
185         # Generate field operations.
186         self.generate_removed_fields()
187         self.generate_added_fields()
188         self.generate_altered_fields()
189         self.generate_altered_order_with_respect_to()
190         self.generate_altered_unique_together()
191         self.generate_altered_index_together()
192         self.generate_added_indexes()
193         self.generate_added_constraints()
194         self.generate_altered_db_table()
195 
196         self._sort_migrations()
197         self._build_migration_list(graph)
198         self._optimize_migrations()
199 
200         return self.migrations
201 
202     def _prepare_field_lists(self):
203         """
204         Prepare field lists and a list of the fields that used through models
205         in the old state so dependencies can be made from the through model
206         deletion to the field that uses it.
207         """
208         self.kept_model_keys = self.old_model_keys & self.new_model_keys
209         self.kept_proxy_keys = self.old_proxy_keys & self.new_proxy_keys
210         self.kept_unmanaged_keys = self.old_unmanaged_keys & self.new_unmanaged_keys
211         self.through_users = {}
212         self.old_field_keys = {
213             (app_label, model_name, field_name)
214             for app_label, model_name in self.kept_model_keys
215             for field_name in self.from_state.models[
216                 app_label, self.renamed_models.get((app_label, model_name), model_name)
217             ].fields
218         }
219         self.new_field_keys = {
220             (app_label, model_name, field_name)
221             for app_label, model_name in self.kept_model_keys
222             for field_name in self.to_state.models[app_label, model_name].fields
223         }
224 
225     def _generate_through_model_map(self):
226         """Through model map generation."""
227         for app_label, model_name in sorted(self.old_model_keys):
228             old_model_name = self.renamed_models.get(
229                 (app_label, model_name), model_name
230             )
231             old_model_state = self.from_state.models[app_label, old_model_name]
232             for field_name, field in old_model_state.fields.items():
233                 if hasattr(field, "remote_field") and getattr(
234                     field.remote_field, "through", None
235                 ):
236                     through_key = resolve_relation(
237                         field.remote_field.through, app_label, model_name
238                     )
239                     self.through_users[through_key] = (
240                         app_label,
241                         old_model_name,
242                         field_name,
243                     )
244 
245     @staticmethod
246     def _resolve_dependency(dependency):
247         """
248         Return the resolved dependency and a boolean denoting whether or not
249         it was swappable.
250         """
251         if dependency[0] != "__setting__":
252             return dependency, False
253         resolved_app_label, resolved_object_name = getattr(
254             settings, dependency[1]
255         ).split(".")
256         return (resolved_app_label, resolved_object_name.lower()) + dependency[2:], True
257 
258     def _build_migration_list(self, graph=None):
259         """
260         Chop the lists of operations up into migrations with dependencies on
261         each other. Do this by going through an app's list of operations until
262         one is found that has an outgoing dependency that isn't in another
263         app's migration yet (hasn't been chopped off its list). Then chop off
264         the operations before it into a migration and move onto the next app.
265         If the loops completes without doing anything, there's a circular
266         dependency (which _should_ be impossible as the operations are
267         all split at this point so they can't depend and be depended on).
268         """
269         self.migrations = {}
270         num_ops = sum(len(x) for x in self.generated_operations.values())
271         chop_mode = False
272         while num_ops:
273             # On every iteration, we step through all the apps and see if there
274             # is a completed set of operations.
275             # If we find that a subset of the operations are complete we can
276             # try to chop it off from the rest and continue, but we only
277             # do this if we've already been through the list once before
278             # without any chopping and nothing has changed.
279             for app_label in sorted(self.generated_operations):
280                 chopped = []
281                 dependencies = set()
282                 for operation in list(self.generated_operations[app_label]):
283                     deps_satisfied = True
284                     operation_dependencies = set()
285                     for dep in operation._auto_deps:
286                         # Temporarily resolve the swappable dependency to
287                         # prevent circular references. While keeping the
288                         # dependency checks on the resolved model, add the
289                         # swappable dependencies.
290                         original_dep = dep
291                         dep, is_swappable_dep = self._resolve_dependency(dep)
292                         if dep[0] != app_label:
293                             # External app dependency. See if it's not yet
294                             # satisfied.
295                             for other_operation in self.generated_operations.get(
296                                 dep[0], []
297                             ):
298                                 if self.check_dependency(other_operation, dep):
299                                     deps_satisfied = False
300                                     break
301                             if not deps_satisfied:
302                                 break
303                             else:
304                                 if is_swappable_dep:
305                                     operation_dependencies.add(
306                                         (original_dep[0], original_dep[1])
307                                     )
308                                 elif dep[0] in self.migrations:
309                                     operation_dependencies.add(
310                                         (dep[0], self.migrations[dep[0]][-1].name)
311                                     )
312                                 else:
313                                     # If we can't find the other app, we add a
314                                     # first/last dependency, but only if we've
315                                     # already been through once and checked
316                                     # everything.
317                                     if chop_mode:
318                                         # If the app already exists, we add a
319                                         # dependency on the last migration, as
320                                         # we don't know which migration
321                                         # contains the target field. If it's
322                                         # not yet migrated or has no
323                                         # migrations, we use __first__.
324                                         if graph and graph.leaf_nodes(dep[0]):
325                                             operation_dependencies.add(
326                                                 graph.leaf_nodes(dep[0])[0]
327                                             )
328                                         else:
329                                             operation_dependencies.add(
330                                                 (dep[0], "__first__")
331                                             )
332                                     else:
333                                         deps_satisfied = False
334                     if deps_satisfied:
335                         chopped.append(operation)
336                         dependencies.update(operation_dependencies)
337                         del self.generated_operations[app_label][0]
338                     else:
339                         break
340                 # Make a migration! Well, only if there's stuff to put in it
341                 if dependencies or chopped:
342                     if not self.generated_operations[app_label] or chop_mode:
343                         subclass = type(
344                             "Migration",
345                             (Migration,),
346                             {"operations": [], "dependencies": []},
347                         )
348                         instance = subclass(
349                             "auto_%i" % (len(self.migrations.get(app_label, [])) + 1),
350                             app_label,
351                         )
352                         instance.dependencies = list(dependencies)
353                         instance.operations = chopped
354                         instance.initial = app_label not in self.existing_apps
355                         self.migrations.setdefault(app_label, []).append(instance)
356                         chop_mode = False
357                     else:
358                         self.generated_operations[app_label] = (
359                             chopped + self.generated_operations[app_label]
360                         )
361             new_num_ops = sum(len(x) for x in self.generated_operations.values())
362             if new_num_ops == num_ops:
363                 if not chop_mode:
364                     chop_mode = True
365                 else:
366                     raise ValueError(
367                         "Cannot resolve operation dependencies: %r"
368                         % self.generated_operations
369                     )
370             num_ops = new_num_ops
371 
372     def _sort_migrations(self):
373         """
374         Reorder to make things possible. Reordering may be needed so FKs work
375         nicely inside the same app.
376         """
377         for app_label, ops in sorted(self.generated_operations.items()):
378             # construct a dependency graph for intra-app dependencies
379             dependency_graph = {op: set() for op in ops}
380             for op in ops:
381                 for dep in op._auto_deps:
382                     # Resolve intra-app dependencies to handle circular
383                     # references involving a swappable model.
384                     dep = self._resolve_dependency(dep)[0]
385                     if dep[0] == app_label:
386                         for op2 in ops:
387                             if self.check_dependency(op2, dep):
388                                 dependency_graph[op].add(op2)
389 
390             # we use a stable sort for deterministic tests & general behavior
391             self.generated_operations[app_label] = stable_topological_sort(
392                 ops, dependency_graph
393             )
394 
395     def _optimize_migrations(self):
396         # Add in internal dependencies among the migrations
397         for app_label, migrations in self.migrations.items():
398             for m1, m2 in zip(migrations, migrations[1:]):
399                 m2.dependencies.append((app_label, m1.name))
400 
401         # De-dupe dependencies
402         for migrations in self.migrations.values():
403             for migration in migrations:
404                 migration.dependencies = list(set(migration.dependencies))
405 
406         # Optimize migrations
407         for app_label, migrations in self.migrations.items():
408             for migration in migrations:
409                 migration.operations = MigrationOptimizer().optimize(
410                     migration.operations, app_label
411                 )
412 
413     def check_dependency(self, operation, dependency):
414         """
415         Return True if the given operation depends on the given dependency,
416         False otherwise.
417         """
418         # Created model
419         if dependency[2] is None and dependency[3] is True:
420             return (
421                 isinstance(operation, operations.CreateModel)
422                 and operation.name_lower == dependency[1].lower()
423             )
424         # Created field
425         elif dependency[2] is not None and dependency[3] is True:
426             return (
427                 isinstance(operation, operations.CreateModel)
428                 and operation.name_lower == dependency[1].lower()
429                 and any(dependency[2] == x for x, y in operation.fields)
430             ) or (
431                 isinstance(operation, operations.AddField)
432                 and operation.model_name_lower == dependency[1].lower()
433                 and operation.name_lower == dependency[2].lower()
434             )
435         # Removed field
436         elif dependency[2] is not None and dependency[3] is False:
437             return (
438                 isinstance(operation, operations.RemoveField)
439                 and operation.model_name_lower == dependency[1].lower()
440                 and operation.name_lower == dependency[2].lower()
441             )
442         # Removed model
443         elif dependency[2] is None and dependency[3] is False:
444             return (
445                 isinstance(operation, operations.DeleteModel)
446                 and operation.name_lower == dependency[1].lower()
447             )
448         # Field being altered
449         elif dependency[2] is not None and dependency[3] == "alter":
450             return (
451                 isinstance(operation, operations.AlterField)
452                 and operation.model_name_lower == dependency[1].lower()
453                 and operation.name_lower == dependency[2].lower()
454             )
455         # order_with_respect_to being unset for a field
456         elif dependency[2] is not None and dependency[3] == "order_wrt_unset":
457             return (
458                 isinstance(operation, operations.AlterOrderWithRespectTo)
459                 and operation.name_lower == dependency[1].lower()
460                 and (operation.order_with_respect_to or "").lower()
461                 != dependency[2].lower()
462             )
463         # Field is removed and part of an index/unique_together
464         elif dependency[2] is not None and dependency[3] == "foo_together_change":
465             return (
466                 isinstance(
467                     operation,
468                     (operations.AlterUniqueTogether, operations.AlterIndexTogether),
469                 )
470                 and operation.name_lower == dependency[1].lower()
471             )
472         # Unknown dependency. Raise an error.
473         else:
474             raise ValueError("Can't handle dependency %r" % (dependency,))
475 
476     def add_operation(self, app_label, operation, dependencies=None, beginning=False):
477         # Dependencies are
478         # (app_label, model_name, field_name, create/delete as True/False)
479         operation._auto_deps = dependencies or []
480         if beginning:
481             self.generated_operations.setdefault(app_label, []).insert(0, operation)
482         else:
483             self.generated_operations.setdefault(app_label, []).append(operation)
484 
485     def swappable_first_key(self, item):
486         """
487         Place potential swappable models first in lists of created models (only
488         real way to solve #22783).
489         """
490         try:
491             model_state = self.to_state.models[item]
492             base_names = {
493                 base if isinstance(base, str) else base.__name__
494                 for base in model_state.bases
495             }
496             string_version = "%s.%s" % (item[0], item[1])
497             if (
498                 model_state.options.get("swappable")
499                 or "AbstractUser" in base_names
500                 or "AbstractBaseUser" in base_names
501                 or settings.AUTH_USER_MODEL.lower() == string_version.lower()
502             ):
503                 return ("___" + item[0], "___" + item[1])
504         except LookupError:
505             pass
506         return item
507 
508     def generate_renamed_models(self):
509         """
510         Find any renamed models, generate the operations for them, and remove
511         the old entry from the model lists. Must be run before other
512         model-level generation.
513         """
514         self.renamed_models = {}
515         self.renamed_models_rel = {}
516         added_models = self.new_model_keys - self.old_model_keys
517         for app_label, model_name in sorted(added_models):
518             model_state = self.to_state.models[app_label, model_name]
519             model_fields_def = self.only_relation_agnostic_fields(model_state.fields)
520 
521             removed_models = self.old_model_keys - self.new_model_keys
522             for rem_app_label, rem_model_name in removed_models:
523                 if rem_app_label == app_label:
524                     rem_model_state = self.from_state.models[
525                         rem_app_label, rem_model_name
526                     ]
527                     rem_model_fields_def = self.only_relation_agnostic_fields(
528                         rem_model_state.fields
529                     )
530                     if model_fields_def == rem_model_fields_def:
531                         if self.questioner.ask_rename_model(
532                             rem_model_state, model_state
533                         ):
534                             dependencies = []
535                             fields = list(model_state.fields.values()) + [
536                                 field.remote_field
537                                 for relations in self.to_state.relations[
538                                     app_label, model_name
539                                 ].values()
540                                 for field in relations.values()
541                             ]
542                             for field in fields:
543                                 if field.is_relation:
544                                     dependencies.extend(
545                                         self._get_dependencies_for_foreign_key(
546                                             app_label,
547                                             model_name,
548                                             field,
549                                             self.to_state,
550                                         )
551                                     )
552                             self.add_operation(
553                                 app_label,
554                                 operations.RenameModel(
555                                     old_name=rem_model_state.name,
556                                     new_name=model_state.name,
557                                 ),
558                                 dependencies=dependencies,
559                             )
560                             self.renamed_models[app_label, model_name] = rem_model_name
561                             renamed_models_rel_key = "%s.%s" % (
562                                 rem_model_state.app_label,
563                                 rem_model_state.name_lower,
564                             )
565                             self.renamed_models_rel[
566                                 renamed_models_rel_key
567                             ] = "%s.%s" % (
568                                 model_state.app_label,
569                                 model_state.name_lower,
570                             )
571                             self.old_model_keys.remove((rem_app_label, rem_model_name))
572                             self.old_model_keys.add((app_label, model_name))
573                             break
574 
575     def generate_created_models(self):
576         """
577         Find all new models (both managed and unmanaged) and make create
578         operations for them as well as separate operations to create any
579         foreign key or M2M relationships (these are optimized later, if
580         possible).
581 
582         Defer any model options that refer to collections of fields that might
583         be deferred (e.g. unique_together, index_together).
584         """
585         old_keys = self.old_model_keys | self.old_unmanaged_keys
586         added_models = self.new_model_keys - old_keys
587         added_unmanaged_models = self.new_unmanaged_keys - old_keys
588         all_added_models = chain(
589             sorted(added_models, key=self.swappable_first_key, reverse=True),
590             sorted(added_unmanaged_models, key=self.swappable_first_key, reverse=True),
591         )
592         for app_label, model_name in all_added_models:
593             model_state = self.to_state.models[app_label, model_name]
594             # Gather related fields
595             related_fields = {}
596             primary_key_rel = None
597             for field_name, field in model_state.fields.items():
598                 if field.remote_field:
599                     if field.remote_field.model:
600                         if field.primary_key:
601                             primary_key_rel = field.remote_field.model
602                         elif not field.remote_field.parent_link:
603                             related_fields[field_name] = field
604                     if getattr(field.remote_field, "through", None):
605                         related_fields[field_name] = field
606 
607             # Are there indexes/unique|index_together to defer?
608             indexes = model_state.options.pop("indexes")
609             constraints = model_state.options.pop("constraints")
610             unique_together = model_state.options.pop("unique_together", None)
611             index_together = model_state.options.pop("index_together", None)
612             order_with_respect_to = model_state.options.pop(
613                 "order_with_respect_to", None
614             )
615             # Depend on the deletion of any possible proxy version of us
616             dependencies = [
617                 (app_label, model_name, None, False),
618             ]
619             # Depend on all bases
620             for base in model_state.bases:
621                 if isinstance(base, str) and "." in base:
622                     base_app_label, base_name = base.split(".", 1)
623                     dependencies.append((base_app_label, base_name, None, True))
624                     # Depend on the removal of base fields if the new model has
625                     # a field with the same name.
626                     old_base_model_state = self.from_state.models.get(
627                         (base_app_label, base_name)
628                     )
629                     new_base_model_state = self.to_state.models.get(
630                         (base_app_label, base_name)
631                     )
632                     if old_base_model_state and new_base_model_state:
633                         removed_base_fields = (
634                             set(old_base_model_state.fields)
635                             .difference(
636                                 new_base_model_state.fields,
637                             )
638                             .intersection(model_state.fields)
639                         )
640                         for removed_base_field in removed_base_fields:
641                             dependencies.append(
642                                 (base_app_label, base_name, removed_base_field, False)
643                             )
644             # Depend on the other end of the primary key if it's a relation
645             if primary_key_rel:
646                 dependencies.append(
647                     resolve_relation(
648                         primary_key_rel,
649                         app_label,
650                         model_name,
651                     )
652                     + (None, True)
653                 )
654             # Generate creation operation
655             self.add_operation(
656                 app_label,
657                 operations.CreateModel(
658                     name=model_state.name,
659                     fields=[
660                         d
661                         for d in model_state.fields.items()
662                         if d[0] not in related_fields
663                     ],
664                     options=model_state.options,
665                     bases=model_state.bases,
666                     managers=model_state.managers,
667                 ),
668                 dependencies=dependencies,
669                 beginning=True,
670             )
671 
672             # Don't add operations which modify the database for unmanaged models
673             if not model_state.options.get("managed", True):
674                 continue
675 
676             # Generate operations for each related field
677             for name, field in sorted(related_fields.items()):
678                 dependencies = self._get_dependencies_for_foreign_key(
679                     app_label,
680                     model_name,
681                     field,
682                     self.to_state,
683                 )
684                 # Depend on our own model being created
685                 dependencies.append((app_label, model_name, None, True))
686                 # Make operation
687                 self.add_operation(
688                     app_label,
689                     operations.AddField(
690                         model_name=model_name,
691                         name=name,
692                         field=field,
693                     ),
694                     dependencies=list(set(dependencies)),
695                 )
696             # Generate other opns
697             if order_with_respect_to:
698                 self.add_operation(
699                     app_label,
700                     operations.AlterOrderWithRespectTo(
701                         name=model_name,
702                         order_with_respect_to=order_with_respect_to,
703                     ),
704                     dependencies=[
705                         (app_label, model_name, order_with_respect_to, True),
706                         (app_label, model_name, None, True),
707                     ],
708                 )
709             related_dependencies = [
710                 (app_label, model_name, name, True) for name in sorted(related_fields)
711             ]
712             related_dependencies.append((app_label, model_name, None, True))
713             for index in indexes:
714                 self.add_operation(
715                     app_label,
716                     operations.AddIndex(
717                         model_name=model_name,
718                         index=index,
719                     ),
720                     dependencies=related_dependencies,
721                 )
722             for constraint in constraints:
723                 self.add_operation(
724                     app_label,
725                     operations.AddConstraint(
726                         model_name=model_name,
727                         constraint=constraint,
728                     ),
729                     dependencies=related_dependencies,
730                 )
731             if unique_together:
732                 self.add_operation(
733                     app_label,
734                     operations.AlterUniqueTogether(
735                         name=model_name,
736                         unique_together=unique_together,
737                     ),
738                     dependencies=related_dependencies,
739                 )
740             if index_together:
741                 self.add_operation(
742                     app_label,
743                     operations.AlterIndexTogether(
744                         name=model_name,
745                         index_together=index_together,
746                     ),
747                     dependencies=related_dependencies,
748                 )
749             # Fix relationships if the model changed from a proxy model to a
750             # concrete model.
751             relations = self.to_state.relations
752             if (app_label, model_name) in self.old_proxy_keys:
753                 for related_model_key, related_fields in relations[
754                     app_label, model_name
755                 ].items():
756                     related_model_state = self.to_state.models[related_model_key]
757                     for related_field_name, related_field in related_fields.items():
758                         self.add_operation(
759                             related_model_state.app_label,
760                             operations.AlterField(
761                                 model_name=related_model_state.name,
762                                 name=related_field_name,
763                                 field=related_field,
764                             ),
765                             dependencies=[(app_label, model_name, None, True)],
766                         )
767 
768     def generate_created_proxies(self):
769         """
770         Make CreateModel statements for proxy models. Use the same statements
771         as that way there's less code duplication, but for proxy models it's
772         safe to skip all the pointless field stuff and chuck out an operation.
773         """
774         added = self.new_proxy_keys - self.old_proxy_keys
775         for app_label, model_name in sorted(added):
776             model_state = self.to_state.models[app_label, model_name]
777             assert model_state.options.get("proxy")
778             # Depend on the deletion of any possible non-proxy version of us
779             dependencies = [
780                 (app_label, model_name, None, False),
781             ]
782             # Depend on all bases
783             for base in model_state.bases:
784                 if isinstance(base, str) and "." in base:
785                     base_app_label, base_name = base.split(".", 1)
786                     dependencies.append((base_app_label, base_name, None, True))
787             # Generate creation operation
788             self.add_operation(
789                 app_label,
790                 operations.CreateModel(
791                     name=model_state.name,
792                     fields=[],
793                     options=model_state.options,
794                     bases=model_state.bases,
795                     managers=model_state.managers,
796                 ),
797                 # Depend on the deletion of any possible non-proxy version of us
798                 dependencies=dependencies,
799             )
800 
801     def generate_deleted_models(self):
802         """
803         Find all deleted models (managed and unmanaged) and make delete
804         operations for them as well as separate operations to delete any
805         foreign key or M2M relationships (these are optimized later, if
806         possible).
807 
808         Also bring forward removal of any model options that refer to
809         collections of fields - the inverse of generate_created_models().
810         """
811         new_keys = self.new_model_keys | self.new_unmanaged_keys
812         deleted_models = self.old_model_keys - new_keys
813         deleted_unmanaged_models = self.old_unmanaged_keys - new_keys
814         all_deleted_models = chain(
815             sorted(deleted_models), sorted(deleted_unmanaged_models)
816         )
817         for app_label, model_name in all_deleted_models:
818             model_state = self.from_state.models[app_label, model_name]
819             # Gather related fields
820             related_fields = {}
821             for field_name, field in model_state.fields.items():
822                 if field.remote_field:
823                     if field.remote_field.model:
824                         related_fields[field_name] = field
825                     if getattr(field.remote_field, "through", None):
826                         related_fields[field_name] = field
827             # Generate option removal first
828             unique_together = model_state.options.pop("unique_together", None)
829             index_together = model_state.options.pop("index_together", None)
830             if unique_together:
831                 self.add_operation(
832                     app_label,
833                     operations.AlterUniqueTogether(
834                         name=model_name,
835                         unique_together=None,
836                     ),
837                 )
838             if index_together:
839                 self.add_operation(
840                     app_label,
841                     operations.AlterIndexTogether(
842                         name=model_name,
843                         index_together=None,
844                     ),
845                 )
846             # Then remove each related field
847             for name in sorted(related_fields):
848                 self.add_operation(
849                     app_label,
850                     operations.RemoveField(
851                         model_name=model_name,
852                         name=name,
853                     ),
854                 )
855             # Finally, remove the model.
856             # This depends on both the removal/alteration of all incoming fields
857             # and the removal of all its own related fields, and if it's
858             # a through model the field that references it.
859             dependencies = []
860             relations = self.from_state.relations
861             for (
862                 related_object_app_label,
863                 object_name,
864             ), relation_related_fields in relations[app_label, model_name].items():
865                 for field_name, field in relation_related_fields.items():
866                     dependencies.append(
867                         (related_object_app_label, object_name, field_name, False),
868                     )
869                     if not field.many_to_many:
870                         dependencies.append(
871                             (
872                                 related_object_app_label,
873                                 object_name,
874                                 field_name,
875                                 "alter",
876                             ),
877                         )
878 
879             for name in sorted(related_fields):
880                 dependencies.append((app_label, model_name, name, False))
881             # We're referenced in another field's through=
882             through_user = self.through_users.get((app_label, model_state.name_lower))
883             if through_user:
884                 dependencies.append(
885                     (through_user[0], through_user[1], through_user[2], False)
886                 )
887             # Finally, make the operation, deduping any dependencies
888             self.add_operation(
889                 app_label,
890                 operations.DeleteModel(
891                     name=model_state.name,
892                 ),
893                 dependencies=list(set(dependencies)),
894             )
895 
896     def generate_deleted_proxies(self):
897         """Make DeleteModel options for proxy models."""
898         deleted = self.old_proxy_keys - self.new_proxy_keys
899         for app_label, model_name in sorted(deleted):
900             model_state = self.from_state.models[app_label, model_name]
901             assert model_state.options.get("proxy")
902             self.add_operation(
903                 app_label,
904                 operations.DeleteModel(
905                     name=model_state.name,
906                 ),
907             )
908 
909     def generate_renamed_fields(self):
910         """Work out renamed fields."""
911         self.renamed_fields = {}
912         for app_label, model_name, field_name in sorted(
913             self.new_field_keys - self.old_field_keys
914         ):
915             old_model_name = self.renamed_models.get(
916                 (app_label, model_name), model_name
917             )
918             old_model_state = self.from_state.models[app_label, old_model_name]
919             new_model_state = self.to_state.models[app_label, model_name]
920             field = new_model_state.get_field(field_name)
921             # Scan to see if this is actually a rename!
922             field_dec = self.deep_deconstruct(field)
923             for rem_app_label, rem_model_name, rem_field_name in sorted(
924                 self.old_field_keys - self.new_field_keys
925             ):
926                 if rem_app_label == app_label and rem_model_name == model_name:
927                     old_field = old_model_state.get_field(rem_field_name)
928                     old_field_dec = self.deep_deconstruct(old_field)
929                     if (
930                         field.remote_field
931                         and field.remote_field.model
932                         and "to" in old_field_dec[2]
933                     ):
934                         old_rel_to = old_field_dec[2]["to"]
935                         if old_rel_to in self.renamed_models_rel:
936                             old_field_dec[2]["to"] = self.renamed_models_rel[old_rel_to]
937                     old_field.set_attributes_from_name(rem_field_name)
938                     old_db_column = old_field.get_attname_column()[1]
939                     if old_field_dec == field_dec or (
940                         # Was the field renamed and db_column equal to the
941                         # old field's column added?
942                         old_field_dec[0:2] == field_dec[0:2]
943                         and dict(old_field_dec[2], db_column=old_db_column)
944                         == field_dec[2]
945                     ):
946                         if self.questioner.ask_rename(
947                             model_name, rem_field_name, field_name, field
948                         ):
949                             # A db_column mismatch requires a prior noop
950                             # AlterField for the subsequent RenameField to be a
951                             # noop on attempts at preserving the old name.
952                             if old_field.db_column != field.db_column:
953                                 altered_field = field.clone()
954                                 altered_field.name = rem_field_name
955                                 self.add_operation(
956                                     app_label,
957                                     operations.AlterField(
958                                         model_name=model_name,
959                                         name=rem_field_name,
960                                         field=altered_field,
961                                     ),
962                                 )
963                             self.add_operation(
964                                 app_label,
965                                 operations.RenameField(
966                                     model_name=model_name,
967                                     old_name=rem_field_name,
968                                     new_name=field_name,
969                                 ),
970                             )
971                             self.old_field_keys.remove(
972                                 (rem_app_label, rem_model_name, rem_field_name)
973                             )
974                             self.old_field_keys.add((app_label, model_name, field_name))
975                             self.renamed_fields[
976                                 app_label, model_name, field_name
977                             ] = rem_field_name
978                             break
979 
980     def generate_added_fields(self):
981         """Make AddField operations."""
982         for app_label, model_name, field_name in sorted(
983             self.new_field_keys - self.old_field_keys
984         ):
985             self._generate_added_field(app_label, model_name, field_name)
986 
987     def _generate_added_field(self, app_label, model_name, field_name):
988         field = self.to_state.models[app_label, model_name].get_field(field_name)
989         # Fields that are foreignkeys/m2ms depend on stuff
990         dependencies = []
991         if field.remote_field and field.remote_field.model:
992             dependencies.extend(
993                 self._get_dependencies_for_foreign_key(
994                     app_label,
995                     model_name,
996                     field,
997                     self.to_state,
998                 )
999             )
1000         # You can't just add NOT NULL fields with no default or fields
1001         # which don't allow empty strings as default.
1002         time_fields = (models.DateField, models.DateTimeField, models.TimeField)
1003         preserve_default = (
1004             field.null
1005             or field.has_default()
1006             or field.many_to_many
1007             or (field.blank and field.empty_strings_allowed)
1008             or (isinstance(field, time_fields) and field.auto_now)
1009         )
1010         if not preserve_default:
1011             field = field.clone()
1012             if isinstance(field, time_fields) and field.auto_now_add:
1013                 field.default = self.questioner.ask_auto_now_add_addition(
1014                     field_name, model_name
1015                 )
1016             else:
1017                 field.default = self.questioner.ask_not_null_addition(
1018                     field_name, model_name
1019                 )
1020         if (
1021             field.unique
1022             and field.default is not models.NOT_PROVIDED
1023             and callable(field.default)
1024         ):
1025             self.questioner.ask_unique_callable_default_addition(field_name, model_name)
1026         self.add_operation(
1027             app_label,
1028             operations.AddField(
1029                 model_name=model_name,
1030                 name=field_name,
1031                 field=field,
1032                 preserve_default=preserve_default,
1033             ),
1034             dependencies=dependencies,
1035         )
1036 
1037     def generate_removed_fields(self):
1038         """Make RemoveField operations."""
1039         for app_label, model_name, field_name in sorted(
1040             self.old_field_keys - self.new_field_keys
1041         ):
1042             self._generate_removed_field(app_label, model_name, field_name)
1043 
1044     def _generate_removed_field(self, app_label, model_name, field_name):
1045         self.add_operation(
1046             app_label,
1047             operations.RemoveField(
1048                 model_name=model_name,
1049                 name=field_name,
1050             ),
1051             # We might need to depend on the removal of an
1052             # order_with_respect_to or index/unique_together operation;
1053             # this is safely ignored if there isn't one
1054             dependencies=[
1055                 (app_label, model_name, field_name, "order_wrt_unset"),
1056                 (app_label, model_name, field_name, "foo_together_change"),
1057             ],
1058         )
1059 
1060     def generate_altered_fields(self):
1061         """
1062         Make AlterField operations, or possibly RemovedField/AddField if alter
1063         isn't possible.
1064         """
1065         for app_label, model_name, field_name in sorted(
1066             self.old_field_keys & self.new_field_keys
1067         ):
1068             # Did the field change?
1069             old_model_name = self.renamed_models.get(
1070                 (app_label, model_name), model_name
1071             )
1072             old_field_name = self.renamed_fields.get(
1073                 (app_label, model_name, field_name), field_name
1074             )
1075             old_field = self.from_state.models[app_label, old_model_name].get_field(
1076                 old_field_name
1077             )
1078             new_field = self.to_state.models[app_label, model_name].get_field(
1079                 field_name
1080             )
1081             dependencies = []
1082             # Implement any model renames on relations; these are handled by RenameModel
1083             # so we need to exclude them from the comparison
1084             if hasattr(new_field, "remote_field") and getattr(
1085                 new_field.remote_field, "model", None
1086             ):
1087                 rename_key = resolve_relation(
1088                     new_field.remote_field.model, app_label, model_name
1089                 )
1090                 if rename_key in self.renamed_models:
1091                     new_field.remote_field.model = old_field.remote_field.model
1092                 # Handle ForeignKey which can only have a single to_field.
1093                 remote_field_name = getattr(new_field.remote_field, "field_name", None)
1094                 if remote_field_name:
1095                     to_field_rename_key = rename_key + (remote_field_name,)
1096                     if to_field_rename_key in self.renamed_fields:
1097                         # Repoint both model and field name because to_field
1098                         # inclusion in ForeignKey.deconstruct() is based on
1099                         # both.
1100                         new_field.remote_field.model = old_field.remote_field.model
1101                         new_field.remote_field.field_name = (
1102                             old_field.remote_field.field_name
1103                         )
1104                 # Handle ForeignObjects which can have multiple from_fields/to_fields.
1105                 from_fields = getattr(new_field, "from_fields", None)
1106                 if from_fields:
1107                     from_rename_key = (app_label, model_name)
1108                     new_field.from_fields = tuple(
1109                         [
1110                             self.renamed_fields.get(
1111                                 from_rename_key + (from_field,), from_field
1112                             )
1113                             for from_field in from_fields
1114                         ]
1115                     )
1116                     new_field.to_fields = tuple(
1117                         [
1118                             self.renamed_fields.get(rename_key + (to_field,), to_field)
1119                             for to_field in new_field.to_fields
1120                         ]
1121                     )
1122                 dependencies.extend(
1123                     self._get_dependencies_for_foreign_key(
1124                         app_label,
1125                         model_name,
1126                         new_field,
1127                         self.to_state,
1128                     )
1129                 )
1130             if hasattr(new_field, "remote_field") and getattr(
1131                 new_field.remote_field, "through", None
1132             ):
1133                 rename_key = resolve_relation(
1134                     new_field.remote_field.through, app_label, model_name
1135                 )
1136                 if rename_key in self.renamed_models:
1137                     new_field.remote_field.through = old_field.remote_field.through
1138             old_field_dec = self.deep_deconstruct(old_field)
1139             new_field_dec = self.deep_deconstruct(new_field)
1140             # If the field was confirmed to be renamed it means that only
1141             # db_column was allowed to change which generate_renamed_fields()
1142             # already accounts for by adding an AlterField operation.
1143             if old_field_dec != new_field_dec and old_field_name == field_name:
1144                 both_m2m = old_field.many_to_many and new_field.many_to_many
1145                 neither_m2m = not old_field.many_to_many and not new_field.many_to_many
1146                 if both_m2m or neither_m2m:
1147                     # Either both fields are m2m or neither is
1148                     preserve_default = True
1149                     if (
1150                         old_field.null
1151                         and not new_field.null
1152                         and not new_field.has_default()
1153                         and not new_field.many_to_many
1154                     ):
1155                         field = new_field.clone()
1156                         new_default = self.questioner.ask_not_null_alteration(
1157                             field_name, model_name
1158                         )
1159                         if new_default is not models.NOT_PROVIDED:
1160                             field.default = new_default
1161                             preserve_default = False
1162                     else:
1163                         field = new_field
1164                     self.add_operation(
1165                         app_label,
1166                         operations.AlterField(
1167                             model_name=model_name,
1168                             name=field_name,
1169                             field=field,
1170                             preserve_default=preserve_default,
1171                         ),
1172                         dependencies=dependencies,
1173                     )
1174                 else:
1175                     # We cannot alter between m2m and concrete fields
1176                     self._generate_removed_field(app_label, model_name, field_name)
1177                     self._generate_added_field(app_label, model_name, field_name)
1178 
1179     def create_altered_indexes(self):
1180         option_name = operations.AddIndex.option_name
1181         for app_label, model_name in sorted(self.kept_model_keys):
1182             old_model_name = self.renamed_models.get(
1183                 (app_label, model_name), model_name
1184             )
1185             old_model_state = self.from_state.models[app_label, old_model_name]
1186             new_model_state = self.to_state.models[app_label, model_name]
1187 
1188             old_indexes = old_model_state.options[option_name]
1189             new_indexes = new_model_state.options[option_name]
1190             add_idx = [idx for idx in new_indexes if idx not in old_indexes]
1191             rem_idx = [idx for idx in old_indexes if idx not in new_indexes]
1192 
1193             self.altered_indexes.update(
1194                 {
1195                     (app_label, model_name): {
1196                         "added_indexes": add_idx,
1197                         "removed_indexes": rem_idx,
1198                     }
1199                 }
1200             )
1201 
1202     def generate_added_indexes(self):
1203         for (app_label, model_name), alt_indexes in self.altered_indexes.items():
1204             for index in alt_indexes["added_indexes"]:
1205                 self.add_operation(
1206                     app_label,
1207                     operations.AddIndex(
1208                         model_name=model_name,
1209                         index=index,
1210                     ),
1211                 )
1212 
1213     def generate_removed_indexes(self):
1214         for (app_label, model_name), alt_indexes in self.altered_indexes.items():
1215             for index in alt_indexes["removed_indexes"]:
1216                 self.add_operation(
1217                     app_label,
1218                     operations.RemoveIndex(
1219                         model_name=model_name,
1220                         name=index.name,
1221                     ),
1222                 )
1223 
1224     def create_altered_constraints(self):
1225         option_name = operations.AddConstraint.option_name
1226         for app_label, model_name in sorted(self.kept_model_keys):
1227             old_model_name = self.renamed_models.get(
1228                 (app_label, model_name), model_name
1229             )
1230             old_model_state = self.from_state.models[app_label, old_model_name]
1231             new_model_state = self.to_state.models[app_label, model_name]
1232 
1233             old_constraints = old_model_state.options[option_name]
1234             new_constraints = new_model_state.options[option_name]
1235             add_constraints = [c for c in new_constraints if c not in old_constraints]
1236             rem_constraints = [c for c in old_constraints if c not in new_constraints]
1237 
1238             self.altered_constraints.update(
1239                 {
1240                     (app_label, model_name): {
1241                         "added_constraints": add_constraints,
1242                         "removed_constraints": rem_constraints,
1243                     }
1244                 }
1245             )
1246 
1247     def generate_added_constraints(self):
1248         for (
1249             app_label,
1250             model_name,
1251         ), alt_constraints in self.altered_constraints.items():
1252             for constraint in alt_constraints["added_constraints"]:
1253                 self.add_operation(
1254                     app_label,
1255                     operations.AddConstraint(
1256                         model_name=model_name,
1257                         constraint=constraint,
1258                     ),
1259                 )
1260 
1261     def generate_removed_constraints(self):
1262         for (
1263             app_label,
1264             model_name,
1265         ), alt_constraints in self.altered_constraints.items():
1266             for constraint in alt_constraints["removed_constraints"]:
1267                 self.add_operation(
1268                     app_label,
1269                     operations.RemoveConstraint(
1270                         model_name=model_name,
1271                         name=constraint.name,
1272                     ),
1273                 )
1274 
1275     @staticmethod
1276     def _get_dependencies_for_foreign_key(app_label, model_name, field, project_state):
1277         remote_field_model = None
1278         if hasattr(field.remote_field, "model"):
1279             remote_field_model = field.remote_field.model
1280         else:
1281             relations = project_state.relations[app_label, model_name]
1282             for (remote_app_label, remote_model_name), fields in relations.items():
1283                 if any(
1284                     field == related_field.remote_field
1285                     for related_field in fields.values()
1286                 ):
1287                     remote_field_model = f"{remote_app_label}.{remote_model_name}"
1288                     break
1289         # Account for FKs to swappable models
1290         swappable_setting = getattr(field, "swappable_setting", None)
1291         if swappable_setting is not None:
1292             dep_app_label = "__setting__"
1293             dep_object_name = swappable_setting
1294         else:
1295             dep_app_label, dep_object_name = resolve_relation(
1296                 remote_field_model,
1297                 app_label,
1298                 model_name,
1299             )
1300         dependencies = [(dep_app_label, dep_object_name, None, True)]
1301         if getattr(field.remote_field, "through", None):
1302             through_app_label, through_object_name = resolve_relation(
1303                 remote_field_model,
1304                 app_label,
1305                 model_name,
1306             )
1307             dependencies.append((through_app_label, through_object_name, None, True))
1308         return dependencies
1309 
1310     def _get_altered_foo_together_operations(self, option_name):
1311         for app_label, model_name in sorted(self.kept_model_keys):
1312             old_model_name = self.renamed_models.get(
1313                 (app_label, model_name), model_name
1314             )
1315             old_model_state = self.from_state.models[app_label, old_model_name]
1316             new_model_state = self.to_state.models[app_label, model_name]
1317 
1318             # We run the old version through the field renames to account for those
1319             old_value = old_model_state.options.get(option_name)
1320             old_value = (
1321                 {
1322                     tuple(
1323                         self.renamed_fields.get((app_label, model_name, n), n)
1324                         for n in unique
1325                     )
1326                     for unique in old_value
1327                 }
1328                 if old_value
1329                 else set()
1330             )
1331 
1332             new_value = new_model_state.options.get(option_name)
1333             new_value = set(new_value) if new_value else set()
1334 
1335             if old_value != new_value:
1336                 dependencies = []
1337                 for foo_togethers in new_value:
1338                     for field_name in foo_togethers:
1339                         field = new_model_state.get_field(field_name)
1340                         if field.remote_field and field.remote_field.model:
1341                             dependencies.extend(
1342                                 self._get_dependencies_for_foreign_key(
1343                                     app_label,
1344                                     model_name,
1345                                     field,
1346                                     self.to_state,
1347                                 )
1348                             )
1349                 yield (
1350                     old_value,
1351                     new_value,
1352                     app_label,
1353                     model_name,
1354                     dependencies,
1355                 )
1356 
1357     def _generate_removed_altered_foo_together(self, operation):
1358         for (
1359             old_value,
1360             new_value,
1361             app_label,
1362             model_name,
1363             dependencies,
1364         ) in self._get_altered_foo_together_operations(operation.option_name):
1365             removal_value = new_value.intersection(old_value)
1366             if removal_value or old_value:
1367                 self.add_operation(
1368                     app_label,
1369                     operation(
1370                         name=model_name, **{operation.option_name: removal_value}
1371                     ),
1372                     dependencies=dependencies,
1373                 )
1374 
1375     def generate_removed_altered_unique_together(self):
1376         self._generate_removed_altered_foo_together(operations.AlterUniqueTogether)
1377 
1378     def generate_removed_altered_index_together(self):
1379         self._generate_removed_altered_foo_together(operations.AlterIndexTogether)
1380 
1381     def _generate_altered_foo_together(self, operation):
1382         for (
1383             old_value,
1384             new_value,
1385             app_label,
1386             model_name,
1387             dependencies,
1388         ) in self._get_altered_foo_together_operations(operation.option_name):
1389             removal_value = new_value.intersection(old_value)
1390             if new_value != removal_value:
1391                 self.add_operation(
1392                     app_label,
1393                     operation(name=model_name, **{operation.option_name: new_value}),
1394                     dependencies=dependencies,
1395                 )
1396 
1397     def generate_altered_unique_together(self):
1398         self._generate_altered_foo_together(operations.AlterUniqueTogether)
1399 
1400     def generate_altered_index_together(self):
1401         self._generate_altered_foo_together(operations.AlterIndexTogether)
1402 
1403     def generate_altered_db_table(self):
1404         models_to_check = self.kept_model_keys.union(
1405             self.kept_proxy_keys, self.kept_unmanaged_keys
1406         )
1407         for app_label, model_name in sorted(models_to_check):
1408             old_model_name = self.renamed_models.get(
1409                 (app_label, model_name), model_name
1410             )
1411             old_model_state = self.from_state.models[app_label, old_model_name]
1412             new_model_state = self.to_state.models[app_label, model_name]
1413             old_db_table_name = old_model_state.options.get("db_table")
1414             new_db_table_name = new_model_state.options.get("db_table")
1415             if old_db_table_name != new_db_table_name:
1416                 self.add_operation(
1417                     app_label,
1418                     operations.AlterModelTable(
1419                         name=model_name,
1420                         table=new_db_table_name,
1421                     ),
1422                 )
1423 
1424     def generate_altered_options(self):
1425         """
1426         Work out if any non-schema-affecting options have changed and make an
1427         operation to represent them in state changes (in case Python code in
1428         migrations needs them).
1429         """
1430         models_to_check = self.kept_model_keys.union(
1431             self.kept_proxy_keys,
1432             self.kept_unmanaged_keys,
1433             # unmanaged converted to managed
1434             self.old_unmanaged_keys & self.new_model_keys,
1435             # managed converted to unmanaged
1436             self.old_model_keys & self.new_unmanaged_keys,
1437         )
1438 
1439         for app_label, model_name in sorted(models_to_check):
1440             old_model_name = self.renamed_models.get(
1441                 (app_label, model_name), model_name
1442             )
1443             old_model_state = self.from_state.models[app_label, old_model_name]
1444             new_model_state = self.to_state.models[app_label, model_name]
1445             old_options = {
1446                 key: value
1447                 for key, value in old_model_state.options.items()
1448                 if key in AlterModelOptions.ALTER_OPTION_KEYS
1449             }
1450             new_options = {
1451                 key: value
1452                 for key, value in new_model_state.options.items()
1453                 if key in AlterModelOptions.ALTER_OPTION_KEYS
1454             }
1455             if old_options != new_options:
1456                 self.add_operation(
1457                     app_label,
1458                     operations.AlterModelOptions(
1459                         name=model_name,
1460                         options=new_options,
1461                     ),
1462                 )
1463 
1464     def generate_altered_order_with_respect_to(self):
1465         for app_label, model_name in sorted(self.kept_model_keys):
1466             old_model_name = self.renamed_models.get(
1467                 (app_label, model_name), model_name
1468             )
1469             old_model_state = self.from_state.models[app_label, old_model_name]
1470             new_model_state = self.to_state.models[app_label, model_name]
1471             if old_model_state.options.get(
1472                 "order_with_respect_to"
1473             ) != new_model_state.options.get("order_with_respect_to"):
1474                 # Make sure it comes second if we're adding
1475                 # (removal dependency is part of RemoveField)
1476                 dependencies = []
1477                 if new_model_state.options.get("order_with_respect_to"):
1478                     dependencies.append(
1479                         (
1480                             app_label,
1481                             model_name,
1482                             new_model_state.options["order_with_respect_to"],
1483                             True,
1484                         )
1485                     )
1486                 # Actually generate the operation
1487                 self.add_operation(
1488                     app_label,
1489                     operations.AlterOrderWithRespectTo(
1490                         name=model_name,
1491                         order_with_respect_to=new_model_state.options.get(
1492                             "order_with_respect_to"
1493                         ),
1494                     ),
1495                     dependencies=dependencies,
1496                 )
1497 
1498     def generate_altered_managers(self):
1499         for app_label, model_name in sorted(self.kept_model_keys):
1500             old_model_name = self.renamed_models.get(
1501                 (app_label, model_name), model_name
1502             )
1503             old_model_state = self.from_state.models[app_label, old_model_name]
1504             new_model_state = self.to_state.models[app_label, model_name]
1505             if old_model_state.managers != new_model_state.managers:
1506                 self.add_operation(
1507                     app_label,
1508                     operations.AlterModelManagers(
1509                         name=model_name,
1510                         managers=new_model_state.managers,
1511                     ),
1512                 )
1513 
1514     def arrange_for_graph(self, changes, graph, migration_name=None):
1515         """
1516         Take a result from changes() and a MigrationGraph, and fix the names
1517         and dependencies of the changes so they extend the graph from the leaf
1518         nodes for each app.
1519         """
1520         leaves = graph.leaf_nodes()
1521         name_map = {}
1522         for app_label, migrations in list(changes.items()):
1523             if not migrations:
1524                 continue
1525             # Find the app label's current leaf node
1526             app_leaf = None
1527             for leaf in leaves:
1528                 if leaf[0] == app_label:
1529                     app_leaf = leaf
1530                     break
1531             # Do they want an initial migration for this app?
1532             if app_leaf is None and not self.questioner.ask_initial(app_label):
1533                 # They don't.
1534                 for migration in migrations:
1535                     name_map[(app_label, migration.name)] = (app_label, "__first__")
1536                 del changes[app_label]
1537                 continue
1538             # Work out the next number in the sequence
1539             if app_leaf is None:
1540                 next_number = 1
1541             else:
1542                 next_number = (self.parse_number(app_leaf[1]) or 0) + 1
1543             # Name each migration
1544             for i, migration in enumerate(migrations):
1545                 if i == 0 and app_leaf:
1546                     migration.dependencies.append(app_leaf)
1547                 new_name_parts = ["%04i" % next_number]
1548                 if migration_name:
1549                     new_name_parts.append(migration_name)
1550                 elif i == 0 and not app_leaf:
1551                     new_name_parts.append("initial")
1552                 else:
1553                     new_name_parts.append(migration.suggest_name()[:100])
1554                 new_name = "_".join(new_name_parts)
1555                 name_map[(app_label, migration.name)] = (app_label, new_name)
1556                 next_number += 1
1557                 migration.name = new_name
1558         # Now fix dependencies
1559         for migrations in changes.values():
1560             for migration in migrations:
1561                 migration.dependencies = [
1562                     name_map.get(d, d) for d in migration.dependencies
1563                 ]
1564         return changes
1565 
1566     def _trim_to_apps(self, changes, app_labels):
1567         """
1568         Take changes from arrange_for_graph() and set of app labels, and return
1569         a modified set of changes which trims out as many migrations that are
1570         not in app_labels as possible. Note that some other migrations may
1571         still be present as they may be required dependencies.
1572         """
1573         # Gather other app dependencies in a first pass
1574         app_dependencies = {}
1575         for app_label, migrations in changes.items():
1576             for migration in migrations:
1577                 for dep_app_label, name in migration.dependencies:
1578                     app_dependencies.setdefault(app_label, set()).add(dep_app_label)
1579         required_apps = set(app_labels)
1580         # Keep resolving till there's no change
1581         old_required_apps = None
1582         while old_required_apps != required_apps:
1583             old_required_apps = set(required_apps)
1584             required_apps.update(
1585                 *[app_dependencies.get(app_label, ()) for app_label in required_apps]
1586             )
1587         # Remove all migrations that aren't needed
1588         for app_label in list(changes):
1589             if app_label not in required_apps:
1590                 del changes[app_label]
1591         return changes
1592 
1593     @classmethod
1594     def parse_number(cls, name):
1595         """
1596         Given a migration name, try to extract a number from the beginning of
1597         it. For a squashed migration such as '0001_squashed_0004…', return the
1598         second number. If no number is found, return None.
1599         """
1600         if squashed_match := re.search(r".*_squashed_(\d+)", name):
1601             return int(squashed_match[1])
1602         match = re.match(r"^\d+", name)
1603         if match:
1604             return int(match[0])
1605         return None

</code><intended_behavior>Enhance the detection logic to identify if a field involved in a migration is a foreign key referencing a field with a specific `db_collation`. If so, the migration operation should include steps to apply the same `db_collation` to the foreign key column.</intended_behavior>, <file>django/db/models/fields/__init__.py</file>
<class>None</class>
<method>None</method>
<code>
1 import collections.abc
2 import copy
3 import datetime
4 import decimal
5 import math
6 import operator
7 import uuid
8 import warnings
9 from base64 import b64decode, b64encode
10 from functools import partialmethod, total_ordering
11 
12 from django import forms
13 from django.apps import apps
14 from django.conf import settings
15 from django.core import checks, exceptions, validators
16 from django.db import connection, connections, router
17 from django.db.models.constants import LOOKUP_SEP
18 from django.db.models.query_utils import DeferredAttribute, RegisterLookupMixin
19 from django.utils import timezone
20 from django.utils.datastructures import DictWrapper
21 from django.utils.dateparse import (
22     parse_date,
23     parse_datetime,
24     parse_duration,
25     parse_time,
26 )
27 from django.utils.duration import duration_microseconds, duration_string
28 from django.utils.functional import Promise, cached_property
29 from django.utils.ipv6 import clean_ipv6_address
30 from django.utils.itercompat import is_iterable
31 from django.utils.text import capfirst
32 from django.utils.translation import gettext_lazy as _
33 
34 __all__ = [
35     "AutoField",
36     "BLANK_CHOICE_DASH",
37     "BigAutoField",
38     "BigIntegerField",
39     "BinaryField",
40     "BooleanField",
41     "CharField",
42     "CommaSeparatedIntegerField",
43     "DateField",
44     "DateTimeField",
45     "DecimalField",
46     "DurationField",
47     "EmailField",
48     "Empty",
49     "Field",
50     "FilePathField",
51     "FloatField",
52     "GenericIPAddressField",
53     "IPAddressField",
54     "IntegerField",
55     "NOT_PROVIDED",
56     "NullBooleanField",
57     "PositiveBigIntegerField",
58     "PositiveIntegerField",
59     "PositiveSmallIntegerField",
60     "SlugField",
61     "SmallAutoField",
62     "SmallIntegerField",
63     "TextField",
64     "TimeField",
65     "URLField",
66     "UUIDField",
67 ]
68 
69 
70 class Empty:
71     pass
72 
73 
74 class NOT_PROVIDED:
75     pass
76 
77 
78 # The values to use for "blank" in SelectFields. Will be appended to the start
79 # of most "choices" lists.
80 BLANK_CHOICE_DASH = [("", "---------")]
81 
82 
83 def _load_field(app_label, model_name, field_name):
84     return apps.get_model(app_label, model_name)._meta.get_field(field_name)
85 
86 
87 # A guide to Field parameters:
88 #
89 #   * name:      The name of the field specified in the model.
90 #   * attname:   The attribute to use on the model object. This is the same as
91 #                "name", except in the case of ForeignKeys, where "_id" is
92 #                appended.
93 #   * db_column: The db_column specified in the model (or None).
94 #   * column:    The database column for this field. This is the same as
95 #                "attname", except if db_column is specified.
96 #
97 # Code that introspects values, or does other dynamic things, should use
98 # attname. For example, this gets the primary key value of object "obj":
99 #
100 #     getattr(obj, opts.pk.attname)
101 
102 
103 def _empty(of_cls):
104     new = Empty()
105     new.__class__ = of_cls
106     return new
107 
108 
109 def return_None():
110     return None
111 
112 
113 @total_ordering
114 class Field(RegisterLookupMixin):
115     """Base class for all field types"""
116 
117     # Designates whether empty strings fundamentally are allowed at the
118     # database level.
119     empty_strings_allowed = True
120     empty_values = list(validators.EMPTY_VALUES)
121 
122     # These track each time a Field instance is created. Used to retain order.
123     # The auto_creation_counter is used for fields that Django implicitly
124     # creates, creation_counter is used for all user-specified fields.
125     creation_counter = 0
126     auto_creation_counter = -1
127     default_validators = []  # Default set of validators
128     default_error_messages = {
129         "invalid_choice": _("Value %(value)r is not a valid choice."),
130         "null": _("This field cannot be null."),
131         "blank": _("This field cannot be blank."),
132         "unique": _("%(model_name)s with this %(field_label)s already exists."),
133         # Translators: The 'lookup_type' is one of 'date', 'year' or 'month'.
134         # Eg: "Title must be unique for pub_date year"
135         "unique_for_date": _(
136             "%(field_label)s must be unique for "
137             "%(date_field_label)s %(lookup_type)s."
138         ),
139     }
140     system_check_deprecated_details = None
141     system_check_removed_details = None
142 
143     # Attributes that don't affect a column definition.
144     # These attributes are ignored when altering the field.
145     non_db_attrs = (
146         "blank",
147         "choices",
148         "db_column",
149         "editable",
150         "error_messages",
151         "help_text",
152         "limit_choices_to",
153         # Database-level options are not supported, see #21961.
154         "on_delete",
155         "related_name",
156         "related_query_name",
157         "validators",
158         "verbose_name",
159     )
160 
161     # Field flags
162     hidden = False
163 
164     many_to_many = None
165     many_to_one = None
166     one_to_many = None
167     one_to_one = None
168     related_model = None
169 
170     descriptor_class = DeferredAttribute
171 
172     # Generic field type description, usually overridden by subclasses
173     def _description(self):
174         return _("Field of type: %(field_type)s") % {
175             "field_type": self.__class__.__name__
176         }
177 
178     description = property(_description)
179 
180     def __init__(
181         self,
182         verbose_name=None,
183         name=None,
184         primary_key=False,
185         max_length=None,
186         unique=False,
187         blank=False,
188         null=False,
189         db_index=False,
190         rel=None,
191         default=NOT_PROVIDED,
192         editable=True,
193         serialize=True,
194         unique_for_date=None,
195         unique_for_month=None,
196         unique_for_year=None,
197         choices=None,
198         help_text="",
199         db_column=None,
200         db_tablespace=None,
201         auto_created=False,
202         validators=(),
203         error_messages=None,
204     ):
205         self.name = name
206         self.verbose_name = verbose_name  # May be set by set_attributes_from_name
207         self._verbose_name = verbose_name  # Store original for deconstruction
208         self.primary_key = primary_key
209         self.max_length, self._unique = max_length, unique
210         self.blank, self.null = blank, null
211         self.remote_field = rel
212         self.is_relation = self.remote_field is not None
213         self.default = default
214         self.editable = editable
215         self.serialize = serialize
216         self.unique_for_date = unique_for_date
217         self.unique_for_month = unique_for_month
218         self.unique_for_year = unique_for_year
219         if isinstance(choices, collections.abc.Iterator):
220             choices = list(choices)
221         self.choices = choices
222         self.help_text = help_text
223         self.db_index = db_index
224         self.db_column = db_column
225         self._db_tablespace = db_tablespace
226         self.auto_created = auto_created
227 
228         # Adjust the appropriate creation counter, and save our local copy.
229         if auto_created:
230             self.creation_counter = Field.auto_creation_counter
231             Field.auto_creation_counter -= 1
232         else:
233             self.creation_counter = Field.creation_counter
234             Field.creation_counter += 1
235 
236         self._validators = list(validators)  # Store for deconstruction later
237 
238         self._error_messages = error_messages  # Store for deconstruction later
239 
240     def __str__(self):
241         """
242         Return "app_label.model_label.field_name" for fields attached to
243         models.
244         """
245         if not hasattr(self, "model"):
246             return super().__str__()
247         model = self.model
248         return "%s.%s" % (model._meta.label, self.name)
249 
250     def __repr__(self):
251         """Display the module, class, and name of the field."""
252         path = "%s.%s" % (self.__class__.__module__, self.__class__.__qualname__)
253         name = getattr(self, "name", None)
254         if name is not None:
255             return "<%s: %s>" % (path, name)
256         return "<%s>" % path
257 
258     def check(self, **kwargs):
259         return [
260             *self._check_field_name(),
261             *self._check_choices(),
262             *self._check_db_index(),
263             *self._check_null_allowed_for_primary_keys(),
264             *self._check_backend_specific_checks(**kwargs),
265             *self._check_validators(),
266             *self._check_deprecation_details(),
267         ]
268 
269     def _check_field_name(self):
270         """
271         Check if field name is valid, i.e. 1) does not end with an
272         underscore, 2) does not contain "__" and 3) is not "pk".
273         """
274         if self.name.endswith("_"):
275             return [
276                 checks.Error(
277                     "Field names must not end with an underscore.",
278                     obj=self,
279                     id="fields.E001",
280                 )
281             ]
282         elif LOOKUP_SEP in self.name:
283             return [
284                 checks.Error(
285                     'Field names must not contain "%s".' % LOOKUP_SEP,
286                     obj=self,
287                     id="fields.E002",
288                 )
289             ]
290         elif self.name == "pk":
291             return [
292                 checks.Error(
293                     "'pk' is a reserved word that cannot be used as a field name.",
294                     obj=self,
295                     id="fields.E003",
296                 )
297             ]
298         else:
299             return []
300 
301     @classmethod
302     def _choices_is_value(cls, value):
303         return isinstance(value, (str, Promise)) or not is_iterable(value)
304 
305     def _check_choices(self):
306         if not self.choices:
307             return []
308 
309         if not is_iterable(self.choices) or isinstance(self.choices, str):
310             return [
311                 checks.Error(
312                     "'choices' must be an iterable (e.g., a list or tuple).",
313                     obj=self,
314                     id="fields.E004",
315                 )
316             ]
317 
318         choice_max_length = 0
319         # Expect [group_name, [value, display]]
320         for choices_group in self.choices:
321             try:
322                 group_name, group_choices = choices_group
323             except (TypeError, ValueError):
324                 # Containing non-pairs
325                 break
326             try:
327                 if not all(
328                     self._choices_is_value(value) and self._choices_is_value(human_name)
329                     for value, human_name in group_choices
330                 ):
331                     break
332                 if self.max_length is not None and group_choices:
333                     choice_max_length = max(
334                         [
335                             choice_max_length,
336                             *(
337                                 len(value)
338                                 for value, _ in group_choices
339                                 if isinstance(value, str)
340                             ),
341                         ]
342                     )
343             except (TypeError, ValueError):
344                 # No groups, choices in the form [value, display]
345                 value, human_name = group_name, group_choices
346                 if not self._choices_is_value(value) or not self._choices_is_value(
347                     human_name
348                 ):
349                     break
350                 if self.max_length is not None and isinstance(value, str):
351                     choice_max_length = max(choice_max_length, len(value))
352 
353             # Special case: choices=['ab']
354             if isinstance(choices_group, str):
355                 break
356         else:
357             if self.max_length is not None and choice_max_length > self.max_length:
358                 return [
359                     checks.Error(
360                         "'max_length' is too small to fit the longest value "
361                         "in 'choices' (%d characters)." % choice_max_length,
362                         obj=self,
363                         id="fields.E009",
364                     ),
365                 ]
366             return []
367 
368         return [
369             checks.Error(
370                 "'choices' must be an iterable containing "
371                 "(actual value, human readable name) tuples.",
372                 obj=self,
373                 id="fields.E005",
374             )
375         ]
376 
377     def _check_db_index(self):
378         if self.db_index not in (None, True, False):
379             return [
380                 checks.Error(
381                     "'db_index' must be None, True or False.",
382                     obj=self,
383                     id="fields.E006",
384                 )
385             ]
386         else:
387             return []
388 
389     def _check_null_allowed_for_primary_keys(self):
390         if (
391             self.primary_key
392             and self.null
393             and not connection.features.interprets_empty_strings_as_nulls
394         ):
395             # We cannot reliably check this for backends like Oracle which
396             # consider NULL and '' to be equal (and thus set up
397             # character-based fields a little differently).
398             return [
399                 checks.Error(
400                     "Primary keys must not have null=True.",
401                     hint=(
402                         "Set null=False on the field, or "
403                         "remove primary_key=True argument."
404                     ),
405                     obj=self,
406                     id="fields.E007",
407                 )
408             ]
409         else:
410             return []
411 
412     def _check_backend_specific_checks(self, databases=None, **kwargs):
413         if databases is None:
414             return []
415         app_label = self.model._meta.app_label
416         errors = []
417         for alias in databases:
418             if router.allow_migrate(
419                 alias, app_label, model_name=self.model._meta.model_name
420             ):
421                 errors.extend(connections[alias].validation.check_field(self, **kwargs))
422         return errors
423 
424     def _check_validators(self):
425         errors = []
426         for i, validator in enumerate(self.validators):
427             if not callable(validator):
428                 errors.append(
429                     checks.Error(
430                         "All 'validators' must be callable.",
431                         hint=(
432                             "validators[{i}] ({repr}) isn't a function or "
433                             "instance of a validator class.".format(
434                                 i=i,
435                                 repr=repr(validator),
436                             )
437                         ),
438                         obj=self,
439                         id="fields.E008",
440                     )
441                 )
442         return errors
443 
444     def _check_deprecation_details(self):
445         if self.system_check_removed_details is not None:
446             return [
447                 checks.Error(
448                     self.system_check_removed_details.get(
449                         "msg",
450                         "%s has been removed except for support in historical "
451                         "migrations." % self.__class__.__name__,
452                     ),
453                     hint=self.system_check_removed_details.get("hint"),
454                     obj=self,
455                     id=self.system_check_removed_details.get("id", "fields.EXXX"),
456                 )
457             ]
458         elif self.system_check_deprecated_details is not None:
459             return [
460                 checks.Warning(
461                     self.system_check_deprecated_details.get(
462                         "msg", "%s has been deprecated." % self.__class__.__name__
463                     ),
464                     hint=self.system_check_deprecated_details.get("hint"),
465                     obj=self,
466                     id=self.system_check_deprecated_details.get("id", "fields.WXXX"),
467                 )
468             ]
469         return []
470 
471     def get_col(self, alias, output_field=None):
472         if alias == self.model._meta.db_table and (
473             output_field is None or output_field == self
474         ):
475             return self.cached_col
476         from django.db.models.expressions import Col
477 
478         return Col(alias, self, output_field)
479 
480     @cached_property
481     def cached_col(self):
482         from django.db.models.expressions import Col
483 
484         return Col(self.model._meta.db_table, self)
485 
486     def select_format(self, compiler, sql, params):
487         """
488         Custom format for select clauses. For example, GIS columns need to be
489         selected as AsText(table.col) on MySQL as the table.col data can't be
490         used by Django.
491         """
492         return sql, params
493 
494     def deconstruct(self):
495         """
496         Return enough information to recreate the field as a 4-tuple:
497 
498          * The name of the field on the model, if contribute_to_class() has
499            been run.
500          * The import path of the field, including the class, e.g.
501            django.db.models.IntegerField. This should be the most portable
502            version, so less specific may be better.
503          * A list of positional arguments.
504          * A dict of keyword arguments.
505 
506         Note that the positional or keyword arguments must contain values of
507         the following types (including inner values of collection types):
508 
509          * None, bool, str, int, float, complex, set, frozenset, list, tuple,
510            dict
511          * UUID
512          * datetime.datetime (naive), datetime.date
513          * top-level classes, top-level functions - will be referenced by their
514            full import path
515          * Storage instances - these have their own deconstruct() method
516 
517         This is because the values here must be serialized into a text format
518         (possibly new Python code, possibly JSON) and these are the only types
519         with encoding handlers defined.
520 
521         There's no need to return the exact way the field was instantiated this
522         time, just ensure that the resulting field is the same - prefer keyword
523         arguments over positional ones, and omit parameters with their default
524         values.
525         """
526         # Short-form way of fetching all the default parameters
527         keywords = {}
528         possibles = {
529             "verbose_name": None,
530             "primary_key": False,
531             "max_length": None,
532             "unique": False,
533             "blank": False,
534             "null": False,
535             "db_index": False,
536             "default": NOT_PROVIDED,
537             "editable": True,
538             "serialize": True,
539             "unique_for_date": None,
540             "unique_for_month": None,
541             "unique_for_year": None,
542             "choices": None,
543             "help_text": "",
544             "db_column": None,
545             "db_tablespace": None,
546             "auto_created": False,
547             "validators": [],
548             "error_messages": None,
549         }
550         attr_overrides = {
551             "unique": "_unique",
552             "error_messages": "_error_messages",
553             "validators": "_validators",
554             "verbose_name": "_verbose_name",
555             "db_tablespace": "_db_tablespace",
556         }
557         equals_comparison = {"choices", "validators"}
558         for name, default in possibles.items():
559             value = getattr(self, attr_overrides.get(name, name))
560             # Unroll anything iterable for choices into a concrete list
561             if name == "choices" and isinstance(value, collections.abc.Iterable):
562                 value = list(value)
563             # Do correct kind of comparison
564             if name in equals_comparison:
565                 if value != default:
566                     keywords[name] = value
567             else:
568                 if value is not default:
569                     keywords[name] = value
570         # Work out path - we shorten it for known Django core fields
571         path = "%s.%s" % (self.__class__.__module__, self.__class__.__qualname__)
572         if path.startswith("django.db.models.fields.related"):
573             path = path.replace("django.db.models.fields.related", "django.db.models")
574         elif path.startswith("django.db.models.fields.files"):
575             path = path.replace("django.db.models.fields.files", "django.db.models")
576         elif path.startswith("django.db.models.fields.json"):
577             path = path.replace("django.db.models.fields.json", "django.db.models")
578         elif path.startswith("django.db.models.fields.proxy"):
579             path = path.replace("django.db.models.fields.proxy", "django.db.models")
580         elif path.startswith("django.db.models.fields"):
581             path = path.replace("django.db.models.fields", "django.db.models")
582         # Return basic info - other fields should override this.
583         return (self.name, path, [], keywords)
584 
585     def clone(self):
586         """
587         Uses deconstruct() to clone a new copy of this Field.
588         Will not preserve any class attachments/attribute names.
589         """
590         name, path, args, kwargs = self.deconstruct()
591         return self.__class__(*args, **kwargs)
592 
593     def __eq__(self, other):
594         # Needed for @total_ordering
595         if isinstance(other, Field):
596             return self.creation_counter == other.creation_counter and getattr(
597                 self, "model", None
598             ) == getattr(other, "model", None)
599         return NotImplemented
600 
601     def __lt__(self, other):
602         # This is needed because bisect does not take a comparison function.
603         # Order by creation_counter first for backward compatibility.
604         if isinstance(other, Field):
605             if (
606                 self.creation_counter != other.creation_counter
607                 or not hasattr(self, "model")
608                 and not hasattr(other, "model")
609             ):
610                 return self.creation_counter < other.creation_counter
611             elif hasattr(self, "model") != hasattr(other, "model"):
612                 return not hasattr(self, "model")  # Order no-model fields first
613             else:
614                 # creation_counter's are equal, compare only models.
615                 return (self.model._meta.app_label, self.model._meta.model_name) < (
616                     other.model._meta.app_label,
617                     other.model._meta.model_name,
618                 )
619         return NotImplemented
620 
621     def __hash__(self):
622         return hash(self.creation_counter)
623 
624     def __deepcopy__(self, memodict):
625         # We don't have to deepcopy very much here, since most things are not
626         # intended to be altered after initial creation.
627         obj = copy.copy(self)
628         if self.remote_field:
629             obj.remote_field = copy.copy(self.remote_field)
630             if hasattr(self.remote_field, "field") and self.remote_field.field is self:
631                 obj.remote_field.field = obj
632         memodict[id(self)] = obj
633         return obj
634 
635     def __copy__(self):
636         # We need to avoid hitting __reduce__, so define this
637         # slightly weird copy construct.
638         obj = Empty()
639         obj.__class__ = self.__class__
640         obj.__dict__ = self.__dict__.copy()
641         return obj
642 
643     def __reduce__(self):
644         """
645         Pickling should return the model._meta.fields instance of the field,
646         not a new copy of that field. So, use the app registry to load the
647         model and then the field back.
648         """
649         if not hasattr(self, "model"):
650             # Fields are sometimes used without attaching them to models (for
651             # example in aggregation). In this case give back a plain field
652             # instance. The code below will create a new empty instance of
653             # class self.__class__, then update its dict with self.__dict__
654             # values - so, this is very close to normal pickle.
655             state = self.__dict__.copy()
656             # The _get_default cached_property can't be pickled due to lambda
657             # usage.
658             state.pop("_get_default", None)
659             return _empty, (self.__class__,), state
660         return _load_field, (
661             self.model._meta.app_label,
662             self.model._meta.object_name,
663             self.name,
664         )
665 
666     def get_pk_value_on_save(self, instance):
667         """
668         Hook to generate new PK values on save. This method is called when
669         saving instances with no primary key value set. If this method returns
670         something else than None, then the returned value is used when saving
671         the new instance.
672         """
673         if self.default:
674             return self.get_default()
675         return None
676 
677     def to_python(self, value):
678         """
679         Convert the input value into the expected Python data type, raising
680         django.core.exceptions.ValidationError if the data can't be converted.
681         Return the converted value. Subclasses should override this.
682         """
683         return value
684 
685     @cached_property
686     def error_messages(self):
687         messages = {}
688         for c in reversed(self.__class__.__mro__):
689             messages.update(getattr(c, "default_error_messages", {}))
690         messages.update(self._error_messages or {})
691         return messages
692 
693     @cached_property
694     def validators(self):
695         """
696         Some validators can't be created at field initialization time.
697         This method provides a way to delay their creation until required.
698         """
699         return [*self.default_validators, *self._validators]
700 
701     def run_validators(self, value):
702         if value in self.empty_values:
703             return
704 
705         errors = []
706         for v in self.validators:
707             try:
708                 v(value)
709             except exceptions.ValidationError as e:
710                 if hasattr(e, "code") and e.code in self.error_messages:
711                     e.message = self.error_messages[e.code]
712                 errors.extend(e.error_list)
713 
714         if errors:
715             raise exceptions.ValidationError(errors)
716 
717     def validate(self, value, model_instance):
718         """
719         Validate value and raise ValidationError if necessary. Subclasses
720         should override this to provide validation logic.
721         """
722         if not self.editable:
723             # Skip validation for non-editable fields.
724             return
725 
726         if self.choices is not None and value not in self.empty_values:
727             for option_key, option_value in self.choices:
728                 if isinstance(option_value, (list, tuple)):
729                     # This is an optgroup, so look inside the group for
730                     # options.
731                     for optgroup_key, optgroup_value in option_value:
732                         if value == optgroup_key:
733                             return
734                 elif value == option_key:
735                     return
736             raise exceptions.ValidationError(
737                 self.error_messages["invalid_choice"],
738                 code="invalid_choice",
739                 params={"value": value},
740             )
741 
742         if value is None and not self.null:
743             raise exceptions.ValidationError(self.error_messages["null"], code="null")
744 
745         if not self.blank and value in self.empty_values:
746             raise exceptions.ValidationError(self.error_messages["blank"], code="blank")
747 
748     def clean(self, value, model_instance):
749         """
750         Convert the value's type and run validation. Validation errors
751         from to_python() and validate() are propagated. Return the correct
752         value if no error is raised.
753         """
754         value = self.to_python(value)
755         self.validate(value, model_instance)
756         self.run_validators(value)
757         return value
758 
759     def db_type_parameters(self, connection):
760         return DictWrapper(self.__dict__, connection.ops.quote_name, "qn_")
761 
762     def db_check(self, connection):
763         """
764         Return the database column check constraint for this field, for the
765         provided connection. Works the same way as db_type() for the case that
766         get_internal_type() does not map to a preexisting model field.
767         """
768         data = self.db_type_parameters(connection)
769         try:
770             return (
771                 connection.data_type_check_constraints[self.get_internal_type()] % data
772             )
773         except KeyError:
774             return None
775 
776     def db_type(self, connection):
777         """
778         Return the database column data type for this field, for the provided
779         connection.
780         """
781         # The default implementation of this method looks at the
782         # backend-specific data_types dictionary, looking up the field by its
783         # "internal type".
784         #
785         # A Field class can implement the get_internal_type() method to specify
786         # which *preexisting* Django Field class it's most similar to -- i.e.,
787         # a custom field might be represented by a TEXT column type, which is
788         # the same as the TextField Django field type, which means the custom
789         # field's get_internal_type() returns 'TextField'.
790         #
791         # But the limitation of the get_internal_type() / data_types approach
792         # is that it cannot handle database column types that aren't already
793         # mapped to one of the built-in Django field types. In this case, you
794         # can implement db_type() instead of get_internal_type() to specify
795         # exactly which wacky database column type you want to use.
796         data = self.db_type_parameters(connection)
797         try:
798             return connection.data_types[self.get_internal_type()] % data
799         except KeyError:
800             return None
801 
802     def rel_db_type(self, connection):
803         """
804         Return the data type that a related field pointing to this field should
805         use. For example, this method is called by ForeignKey and OneToOneField
806         to determine its data type.
807         """
808         return self.db_type(connection)
809 
810     def cast_db_type(self, connection):
811         """Return the data type to use in the Cast() function."""
812         db_type = connection.ops.cast_data_types.get(self.get_internal_type())
813         if db_type:
814             return db_type % self.db_type_parameters(connection)
815         return self.db_type(connection)
816 
817     def db_parameters(self, connection):
818         """
819         Extension of db_type(), providing a range of different return values
820         (type, checks). This will look at db_type(), allowing custom model
821         fields to override it.
822         """
823         type_string = self.db_type(connection)
824         check_string = self.db_check(connection)
825         return {
826             "type": type_string,
827             "check": check_string,
828         }
829 
830     def db_type_suffix(self, connection):
831         return connection.data_types_suffix.get(self.get_internal_type())
832 
833     def get_db_converters(self, connection):
834         if hasattr(self, "from_db_value"):
835             return [self.from_db_value]
836         return []
837 
838     @property
839     def unique(self):
840         return self._unique or self.primary_key
841 
842     @property
843     def db_tablespace(self):
844         return self._db_tablespace or settings.DEFAULT_INDEX_TABLESPACE
845 
846     @property
847     def db_returning(self):
848         """
849         Private API intended only to be used by Django itself. Currently only
850         the PostgreSQL backend supports returning multiple fields on a model.
851         """
852         return False
853 
854     def set_attributes_from_name(self, name):
855         self.name = self.name or name
856         self.attname, self.column = self.get_attname_column()
857         self.concrete = self.column is not None
858         if self.verbose_name is None and self.name:
859             self.verbose_name = self.name.replace("_", " ")
860 
861     def contribute_to_class(self, cls, name, private_only=False):
862         """
863         Register the field with the model class it belongs to.
864 
865         If private_only is True, create a separate instance of this field
866         for every subclass of cls, even if cls is not an abstract model.
867         """
868         self.set_attributes_from_name(name)
869         self.model = cls
870         cls._meta.add_field(self, private=private_only)
871         if self.column:
872             setattr(cls, self.attname, self.descriptor_class(self))
873         if self.choices is not None:
874             # Don't override a get_FOO_display() method defined explicitly on
875             # this class, but don't check methods derived from inheritance, to
876             # allow overriding inherited choices. For more complex inheritance
877             # structures users should override contribute_to_class().
878             if "get_%s_display" % self.name not in cls.__dict__:
879                 setattr(
880                     cls,
881                     "get_%s_display" % self.name,
882                     partialmethod(cls._get_FIELD_display, field=self),
883                 )
884 
885     def get_filter_kwargs_for_object(self, obj):
886         """
887         Return a dict that when passed as kwargs to self.model.filter(), would
888         yield all instances having the same value for this field as obj has.
889         """
890         return {self.name: getattr(obj, self.attname)}
891 
892     def get_attname(self):
893         return self.name
894 
895     def get_attname_column(self):
896         attname = self.get_attname()
897         column = self.db_column or attname
898         return attname, column
899 
900     def get_internal_type(self):
901         return self.__class__.__name__
902 
903     def pre_save(self, model_instance, add):
904         """Return field's value just before saving."""
905         return getattr(model_instance, self.attname)
906 
907     def get_prep_value(self, value):
908         """Perform preliminary non-db specific value checks and conversions."""
909         if isinstance(value, Promise):
910             value = value._proxy____cast()
911         return value
912 
913     def get_db_prep_value(self, value, connection, prepared=False):
914         """
915         Return field's value prepared for interacting with the database backend.
916 
917         Used by the default implementations of get_db_prep_save().
918         """
919         if not prepared:
920             value = self.get_prep_value(value)
921         return value
922 
923     def get_db_prep_save(self, value, connection):
924         """Return field's value prepared for saving into a database."""
925         return self.get_db_prep_value(value, connection=connection, prepared=False)
926 
927     def has_default(self):
928         """Return a boolean of whether this field has a default value."""
929         return self.default is not NOT_PROVIDED
930 
931     def get_default(self):
932         """Return the default value for this field."""
933         return self._get_default()
934 
935     @cached_property
936     def _get_default(self):
937         if self.has_default():
938             if callable(self.default):
939                 return self.default
940             return lambda: self.default
941 
942         if (
943             not self.empty_strings_allowed
944             or self.null
945             and not connection.features.interprets_empty_strings_as_nulls
946         ):
947             return return_None
948         return str  # return empty string
949 
950     def get_choices(
951         self,
952         include_blank=True,
953         blank_choice=BLANK_CHOICE_DASH,
954         limit_choices_to=None,
955         ordering=(),
956     ):
957         """
958         Return choices with a default blank choices included, for use
959         as <select> choices for this field.
960         """
961         if self.choices is not None:
962             choices = list(self.choices)
963             if include_blank:
964                 blank_defined = any(
965                     choice in ("", None) for choice, _ in self.flatchoices
966                 )
967                 if not blank_defined:
968                     choices = blank_choice + choices
969             return choices
970         rel_model = self.remote_field.model
971         limit_choices_to = limit_choices_to or self.get_limit_choices_to()
972         choice_func = operator.attrgetter(
973             self.remote_field.get_related_field().attname
974             if hasattr(self.remote_field, "get_related_field")
975             else "pk"
976         )
977         qs = rel_model._default_manager.complex_filter(limit_choices_to)
978         if ordering:
979             qs = qs.order_by(*ordering)
980         return (blank_choice if include_blank else []) + [
981             (choice_func(x), str(x)) for x in qs
982         ]
983 
984     def value_to_string(self, obj):
985         """
986         Return a string value of this field from the passed obj.
987         This is used by the serialization framework.
988         """
989         return str(self.value_from_object(obj))
990 
991     def _get_flatchoices(self):
992         """Flattened version of choices tuple."""
993         if self.choices is None:
994             return []
995         flat = []
996         for choice, value in self.choices:
997             if isinstance(value, (list, tuple)):
998                 flat.extend(value)
999             else:
1000                 flat.append((choice, value))
1001         return flat
1002 
1003     flatchoices = property(_get_flatchoices)
1004 
1005     def save_form_data(self, instance, data):
1006         setattr(instance, self.name, data)
1007 
1008     def formfield(self, form_class=None, choices_form_class=None, **kwargs):
1009         """Return a django.forms.Field instance for this field."""
1010         defaults = {
1011             "required": not self.blank,
1012             "label": capfirst(self.verbose_name),
1013             "help_text": self.help_text,
1014         }
1015         if self.has_default():
1016             if callable(self.default):
1017                 defaults["initial"] = self.default
1018                 defaults["show_hidden_initial"] = True
1019             else:
1020                 defaults["initial"] = self.get_default()
1021         if self.choices is not None:
1022             # Fields with choices get special treatment.
1023             include_blank = self.blank or not (
1024                 self.has_default() or "initial" in kwargs
1025             )
1026             defaults["choices"] = self.get_choices(include_blank=include_blank)
1027             defaults["coerce"] = self.to_python
1028             if self.null:
1029                 defaults["empty_value"] = None
1030             if choices_form_class is not None:
1031                 form_class = choices_form_class
1032             else:
1033                 form_class = forms.TypedChoiceField
1034             # Many of the subclass-specific formfield arguments (min_value,
1035             # max_value) don't apply for choice fields, so be sure to only pass
1036             # the values that TypedChoiceField will understand.
1037             for k in list(kwargs):
1038                 if k not in (
1039                     "coerce",
1040                     "empty_value",
1041                     "choices",
1042                     "required",
1043                     "widget",
1044                     "label",
1045                     "initial",
1046                     "help_text",
1047                     "error_messages",
1048                     "show_hidden_initial",
1049                     "disabled",
1050                 ):
1051                     del kwargs[k]
1052         defaults.update(kwargs)
1053         if form_class is None:
1054             form_class = forms.CharField
1055         return form_class(**defaults)
1056 
1057     def value_from_object(self, obj):
1058         """Return the value of this field in the given model instance."""
1059         return getattr(obj, self.attname)
1060 
1061 
1062 class BooleanField(Field):
1063     empty_strings_allowed = False
1064     default_error_messages = {
1065         "invalid": _("“%(value)s” value must be either True or False."),
1066         "invalid_nullable": _("“%(value)s” value must be either True, False, or None."),
1067     }
1068     description = _("Boolean (Either True or False)")
1069 
1070     def get_internal_type(self):
1071         return "BooleanField"
1072 
1073     def to_python(self, value):
1074         if self.null and value in self.empty_values:
1075             return None
1076         if value in (True, False):
1077             # 1/0 are equal to True/False. bool() converts former to latter.
1078             return bool(value)
1079         if value in ("t", "True", "1"):
1080             return True
1081         if value in ("f", "False", "0"):
1082             return False
1083         raise exceptions.ValidationError(
1084             self.error_messages["invalid_nullable" if self.null else "invalid"],
1085             code="invalid",
1086             params={"value": value},
1087         )
1088 
1089     def get_prep_value(self, value):
1090         value = super().get_prep_value(value)
1091         if value is None:
1092             return None
1093         return self.to_python(value)
1094 
1095     def formfield(self, **kwargs):
1096         if self.choices is not None:
1097             include_blank = not (self.has_default() or "initial" in kwargs)
1098             defaults = {"choices": self.get_choices(include_blank=include_blank)}
1099         else:
1100             form_class = forms.NullBooleanField if self.null else forms.BooleanField
1101             # In HTML checkboxes, 'required' means "must be checked" which is
1102             # different from the choices case ("must select some value").
1103             # required=False allows unchecked checkboxes.
1104             defaults = {"form_class": form_class, "required": False}
1105         return super().formfield(**{**defaults, **kwargs})
1106 
1107     def select_format(self, compiler, sql, params):
1108         sql, params = super().select_format(compiler, sql, params)
1109         # Filters that match everything are handled as empty strings in the
1110         # WHERE clause, but in SELECT or GROUP BY list they must use a
1111         # predicate that's always True.
1112         if sql == "":
1113             sql = "1"
1114         return sql, params
1115 
1116 
1117 class CharField(Field):
1118     description = _("String (up to %(max_length)s)")
1119 
1120     def __init__(self, *args, db_collation=None, **kwargs):
1121         super().__init__(*args, **kwargs)
1122         self.db_collation = db_collation
1123         if self.max_length is not None:
1124             self.validators.append(validators.MaxLengthValidator(self.max_length))
1125 
1126     def check(self, **kwargs):
1127         databases = kwargs.get("databases") or []
1128         return [
1129             *super().check(**kwargs),
1130             *self._check_db_collation(databases),
1131             *self._check_max_length_attribute(**kwargs),
1132         ]
1133 
1134     def _check_max_length_attribute(self, **kwargs):
1135         if self.max_length is None:
1136             return [
1137                 checks.Error(
1138                     "CharFields must define a 'max_length' attribute.",
1139                     obj=self,
1140                     id="fields.E120",
1141                 )
1142             ]
1143         elif (
1144             not isinstance(self.max_length, int)
1145             or isinstance(self.max_length, bool)
1146             or self.max_length <= 0
1147         ):
1148             return [
1149                 checks.Error(
1150                     "'max_length' must be a positive integer.",
1151                     obj=self,
1152                     id="fields.E121",
1153                 )
1154             ]
1155         else:
1156             return []
1157 
1158     def _check_db_collation(self, databases):
1159         errors = []
1160         for db in databases:
1161             if not router.allow_migrate_model(db, self.model):
1162                 continue
1163             connection = connections[db]
1164             if not (
1165                 self.db_collation is None
1166                 or "supports_collation_on_charfield"
1167                 in self.model._meta.required_db_features
1168                 or connection.features.supports_collation_on_charfield
1169             ):
1170                 errors.append(
1171                     checks.Error(
1172                         "%s does not support a database collation on "
1173                         "CharFields." % connection.display_name,
1174                         obj=self,
1175                         id="fields.E190",
1176                     ),
1177                 )
1178         return errors
1179 
1180     def cast_db_type(self, connection):
1181         if self.max_length is None:
1182             return connection.ops.cast_char_field_without_max_length
1183         return super().cast_db_type(connection)
1184 
1185     def db_parameters(self, connection):
1186         db_params = super().db_parameters(connection)
1187         db_params["collation"] = self.db_collation
1188         return db_params
1189 
1190     def get_internal_type(self):
1191         return "CharField"
1192 
1193     def to_python(self, value):
1194         if isinstance(value, str) or value is None:
1195             return value
1196         return str(value)
1197 
1198     def get_prep_value(self, value):
1199         value = super().get_prep_value(value)
1200         return self.to_python(value)
1201 
1202     def formfield(self, **kwargs):
1203         # Passing max_length to forms.CharField means that the value's length
1204         # will be validated twice. This is considered acceptable since we want
1205         # the value in the form field (to pass into widget for example).
1206         defaults = {"max_length": self.max_length}
1207         # TODO: Handle multiple backends with different feature flags.
1208         if self.null and not connection.features.interprets_empty_strings_as_nulls:
1209             defaults["empty_value"] = None
1210         defaults.update(kwargs)
1211         return super().formfield(**defaults)
1212 
1213     def deconstruct(self):
1214         name, path, args, kwargs = super().deconstruct()
1215         if self.db_collation:
1216             kwargs["db_collation"] = self.db_collation
1217         return name, path, args, kwargs
1218 
1219 
1220 class CommaSeparatedIntegerField(CharField):
1221     default_validators = [validators.validate_comma_separated_integer_list]
1222     description = _("Comma-separated integers")
1223     system_check_removed_details = {
1224         "msg": (
1225             "CommaSeparatedIntegerField is removed except for support in "
1226             "historical migrations."
1227         ),
1228         "hint": (
1229             "Use CharField(validators=[validate_comma_separated_integer_list]) "
1230             "instead."
1231         ),
1232         "id": "fields.E901",
1233     }
1234 
1235 
1236 def _to_naive(value):
1237     if timezone.is_aware(value):
1238         value = timezone.make_naive(value, datetime.timezone.utc)
1239     return value
1240 
1241 
1242 def _get_naive_now():
1243     return _to_naive(timezone.now())
1244 
1245 
1246 class DateTimeCheckMixin:
1247     def check(self, **kwargs):
1248         return [
1249             *super().check(**kwargs),
1250             *self._check_mutually_exclusive_options(),
1251             *self._check_fix_default_value(),
1252         ]
1253 
1254     def _check_mutually_exclusive_options(self):
1255         # auto_now, auto_now_add, and default are mutually exclusive
1256         # options. The use of more than one of these options together
1257         # will trigger an Error
1258         mutually_exclusive_options = [
1259             self.auto_now_add,
1260             self.auto_now,
1261             self.has_default(),
1262         ]
1263         enabled_options = [
1264             option not in (None, False) for option in mutually_exclusive_options
1265         ].count(True)
1266         if enabled_options > 1:
1267             return [
1268                 checks.Error(
1269                     "The options auto_now, auto_now_add, and default "
1270                     "are mutually exclusive. Only one of these options "
1271                     "may be present.",
1272                     obj=self,
1273                     id="fields.E160",
1274                 )
1275             ]
1276         else:
1277             return []
1278 
1279     def _check_fix_default_value(self):
1280         return []
1281 
1282     # Concrete subclasses use this in their implementations of
1283     # _check_fix_default_value().
1284     def _check_if_value_fixed(self, value, now=None):
1285         """
1286         Check if the given value appears to have been provided as a "fixed"
1287         time value, and include a warning in the returned list if it does. The
1288         value argument must be a date object or aware/naive datetime object. If
1289         now is provided, it must be a naive datetime object.
1290         """
1291         if now is None:
1292             now = _get_naive_now()
1293         offset = datetime.timedelta(seconds=10)
1294         lower = now - offset
1295         upper = now + offset
1296         if isinstance(value, datetime.datetime):
1297             value = _to_naive(value)
1298         else:
1299             assert isinstance(value, datetime.date)
1300             lower = lower.date()
1301             upper = upper.date()
1302         if lower <= value <= upper:
1303             return [
1304                 checks.Warning(
1305                     "Fixed default value provided.",
1306                     hint=(
1307                         "It seems you set a fixed date / time / datetime "
1308                         "value as default for this field. This may not be "
1309                         "what you want. If you want to have the current date "
1310                         "as default, use `django.utils.timezone.now`"
1311                     ),
1312                     obj=self,
1313                     id="fields.W161",
1314                 )
1315             ]
1316         return []
1317 
1318 
1319 class DateField(DateTimeCheckMixin, Field):
1320     empty_strings_allowed = False
1321     default_error_messages = {
1322         "invalid": _(
1323             "“%(value)s” value has an invalid date format. It must be "
1324             "in YYYY-MM-DD format."
1325         ),
1326         "invalid_date": _(
1327             "“%(value)s” value has the correct format (YYYY-MM-DD) "
1328             "but it is an invalid date."
1329         ),
1330     }
1331     description = _("Date (without time)")
1332 
1333     def __init__(
1334         self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs
1335     ):
1336         self.auto_now, self.auto_now_add = auto_now, auto_now_add
1337         if auto_now or auto_now_add:
1338             kwargs["editable"] = False
1339             kwargs["blank"] = True
1340         super().__init__(verbose_name, name, **kwargs)
1341 
1342     def _check_fix_default_value(self):
1343         """
1344         Warn that using an actual date or datetime value is probably wrong;
1345         it's only evaluated on server startup.
1346         """
1347         if not self.has_default():
1348             return []
1349 
1350         value = self.default
1351         if isinstance(value, datetime.datetime):
1352             value = _to_naive(value).date()
1353         elif isinstance(value, datetime.date):
1354             pass
1355         else:
1356             # No explicit date / datetime value -- no checks necessary
1357             return []
1358         # At this point, value is a date object.
1359         return self._check_if_value_fixed(value)
1360 
1361     def deconstruct(self):
1362         name, path, args, kwargs = super().deconstruct()
1363         if self.auto_now:
1364             kwargs["auto_now"] = True
1365         if self.auto_now_add:
1366             kwargs["auto_now_add"] = True
1367         if self.auto_now or self.auto_now_add:
1368             del kwargs["editable"]
1369             del kwargs["blank"]
1370         return name, path, args, kwargs
1371 
1372     def get_internal_type(self):
1373         return "DateField"
1374 
1375     def to_python(self, value):
1376         if value is None:
1377             return value
1378         if isinstance(value, datetime.datetime):
1379             if settings.USE_TZ and timezone.is_aware(value):
1380                 # Convert aware datetimes to the default time zone
1381                 # before casting them to dates (#17742).
1382                 default_timezone = timezone.get_default_timezone()
1383                 value = timezone.make_naive(value, default_timezone)
1384             return value.date()
1385         if isinstance(value, datetime.date):
1386             return value
1387 
1388         try:
1389             parsed = parse_date(value)
1390             if parsed is not None:
1391                 return parsed
1392         except ValueError:
1393             raise exceptions.ValidationError(
1394                 self.error_messages["invalid_date"],
1395                 code="invalid_date",
1396                 params={"value": value},
1397             )
1398 
1399         raise exceptions.ValidationError(
1400             self.error_messages["invalid"],
1401             code="invalid",
1402             params={"value": value},
1403         )
1404 
1405     def pre_save(self, model_instance, add):
1406         if self.auto_now or (self.auto_now_add and add):
1407             value = datetime.date.today()
1408             setattr(model_instance, self.attname, value)
1409             return value
1410         else:
1411             return super().pre_save(model_instance, add)
1412 
1413     def contribute_to_class(self, cls, name, **kwargs):
1414         super().contribute_to_class(cls, name, **kwargs)
1415         if not self.null:
1416             setattr(
1417                 cls,
1418                 "get_next_by_%s" % self.name,
1419                 partialmethod(
1420                     cls._get_next_or_previous_by_FIELD, field=self, is_next=True
1421                 ),
1422             )
1423             setattr(
1424                 cls,
1425                 "get_previous_by_%s" % self.name,
1426                 partialmethod(
1427                     cls._get_next_or_previous_by_FIELD, field=self, is_next=False
1428                 ),
1429             )
1430 
1431     def get_prep_value(self, value):
1432         value = super().get_prep_value(value)
1433         return self.to_python(value)
1434 
1435     def get_db_prep_value(self, value, connection, prepared=False):
1436         # Casts dates into the format expected by the backend
1437         if not prepared:
1438             value = self.get_prep_value(value)
1439         return connection.ops.adapt_datefield_value(value)
1440 
1441     def value_to_string(self, obj):
1442         val = self.value_from_object(obj)
1443         return "" if val is None else val.isoformat()
1444 
1445     def formfield(self, **kwargs):
1446         return super().formfield(
1447             **{
1448                 "form_class": forms.DateField,
1449                 **kwargs,
1450             }
1451         )
1452 
1453 
1454 class DateTimeField(DateField):
1455     empty_strings_allowed = False
1456     default_error_messages = {
1457         "invalid": _(
1458             "“%(value)s” value has an invalid format. It must be in "
1459             "YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format."
1460         ),
1461         "invalid_date": _(
1462             "“%(value)s” value has the correct format "
1463             "(YYYY-MM-DD) but it is an invalid date."
1464         ),
1465         "invalid_datetime": _(
1466             "“%(value)s” value has the correct format "
1467             "(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) "
1468             "but it is an invalid date/time."
1469         ),
1470     }
1471     description = _("Date (with time)")
1472 
1473     # __init__ is inherited from DateField
1474 
1475     def _check_fix_default_value(self):
1476         """
1477         Warn that using an actual date or datetime value is probably wrong;
1478         it's only evaluated on server startup.
1479         """
1480         if not self.has_default():
1481             return []
1482 
1483         value = self.default
1484         if isinstance(value, (datetime.datetime, datetime.date)):
1485             return self._check_if_value_fixed(value)
1486         # No explicit date / datetime value -- no checks necessary.
1487         return []
1488 
1489     def get_internal_type(self):
1490         return "DateTimeField"
1491 
1492     def to_python(self, value):
1493         if value is None:
1494             return value
1495         if isinstance(value, datetime.datetime):
1496             return value
1497         if isinstance(value, datetime.date):
1498             value = datetime.datetime(value.year, value.month, value.day)
1499             if settings.USE_TZ:
1500                 # For backwards compatibility, interpret naive datetimes in
1501                 # local time. This won't work during DST change, but we can't
1502                 # do much about it, so we let the exceptions percolate up the
1503                 # call stack.
1504                 warnings.warn(
1505                     "DateTimeField %s.%s received a naive datetime "
1506                     "(%s) while time zone support is active."
1507                     % (self.model.__name__, self.name, value),
1508                     RuntimeWarning,
1509                 )
1510                 default_timezone = timezone.get_default_timezone()
1511                 value = timezone.make_aware(value, default_timezone)
1512             return value
1513 
1514         try:
1515             parsed = parse_datetime(value)
1516             if parsed is not None:
1517                 return parsed
1518         except ValueError:
1519             raise exceptions.ValidationError(
1520                 self.error_messages["invalid_datetime"],
1521                 code="invalid_datetime",
1522                 params={"value": value},
1523             )
1524 
1525         try:
1526             parsed = parse_date(value)
1527             if parsed is not None:
1528                 return datetime.datetime(parsed.year, parsed.month, parsed.day)
1529         except ValueError:
1530             raise exceptions.ValidationError(
1531                 self.error_messages["invalid_date"],
1532                 code="invalid_date",
1533                 params={"value": value},
1534             )
1535 
1536         raise exceptions.ValidationError(
1537             self.error_messages["invalid"],
1538             code="invalid",
1539             params={"value": value},
1540         )
1541 
1542     def pre_save(self, model_instance, add):
1543         if self.auto_now or (self.auto_now_add and add):
1544             value = timezone.now()
1545             setattr(model_instance, self.attname, value)
1546             return value
1547         else:
1548             return super().pre_save(model_instance, add)
1549 
1550     # contribute_to_class is inherited from DateField, it registers
1551     # get_next_by_FOO and get_prev_by_FOO
1552 
1553     def get_prep_value(self, value):
1554         value = super().get_prep_value(value)
1555         value = self.to_python(value)
1556         if value is not None and settings.USE_TZ and timezone.is_naive(value):
1557             # For backwards compatibility, interpret naive datetimes in local
1558             # time. This won't work during DST change, but we can't do much
1559             # about it, so we let the exceptions percolate up the call stack.
1560             try:
1561                 name = "%s.%s" % (self.model.__name__, self.name)
1562             except AttributeError:
1563                 name = "(unbound)"
1564             warnings.warn(
1565                 "DateTimeField %s received a naive datetime (%s)"
1566                 " while time zone support is active." % (name, value),
1567                 RuntimeWarning,
1568             )
1569             default_timezone = timezone.get_default_timezone()
1570             value = timezone.make_aware(value, default_timezone)
1571         return value
1572 
1573     def get_db_prep_value(self, value, connection, prepared=False):
1574         # Casts datetimes into the format expected by the backend
1575         if not prepared:
1576             value = self.get_prep_value(value)
1577         return connection.ops.adapt_datetimefield_value(value)
1578 
1579     def value_to_string(self, obj):
1580         val = self.value_from_object(obj)
1581         return "" if val is None else val.isoformat()
1582 
1583     def formfield(self, **kwargs):
1584         return super().formfield(
1585             **{
1586                 "form_class": forms.DateTimeField,
1587                 **kwargs,
1588             }
1589         )
1590 
1591 
1592 class DecimalField(Field):
1593     empty_strings_allowed = False
1594     default_error_messages = {
1595         "invalid": _("“%(value)s” value must be a decimal number."),
1596     }
1597     description = _("Decimal number")
1598 
1599     def __init__(
1600         self,
1601         verbose_name=None,
1602         name=None,
1603         max_digits=None,
1604         decimal_places=None,
1605         **kwargs,
1606     ):
1607         self.max_digits, self.decimal_places = max_digits, decimal_places
1608         super().__init__(verbose_name, name, **kwargs)
1609 
1610     def check(self, **kwargs):
1611         errors = super().check(**kwargs)
1612 
1613         digits_errors = [
1614             *self._check_decimal_places(),
1615             *self._check_max_digits(),
1616         ]
1617         if not digits_errors:
1618             errors.extend(self._check_decimal_places_and_max_digits(**kwargs))
1619         else:
1620             errors.extend(digits_errors)
1621         return errors
1622 
1623     def _check_decimal_places(self):
1624         try:
1625             decimal_places = int(self.decimal_places)
1626             if decimal_places < 0:
1627                 raise ValueError()
1628         except TypeError:
1629             return [
1630                 checks.Error(
1631                     "DecimalFields must define a 'decimal_places' attribute.",
1632                     obj=self,
1633                     id="fields.E130",
1634                 )
1635             ]
1636         except ValueError:
1637             return [
1638                 checks.Error(
1639                     "'decimal_places' must be a non-negative integer.",
1640                     obj=self,
1641                     id="fields.E131",
1642                 )
1643             ]
1644         else:
1645             return []
1646 
1647     def _check_max_digits(self):
1648         try:
1649             max_digits = int(self.max_digits)
1650             if max_digits <= 0:
1651                 raise ValueError()
1652         except TypeError:
1653             return [
1654                 checks.Error(
1655                     "DecimalFields must define a 'max_digits' attribute.",
1656                     obj=self,
1657                     id="fields.E132",
1658                 )
1659             ]
1660         except ValueError:
1661             return [
1662                 checks.Error(
1663                     "'max_digits' must be a positive integer.",
1664                     obj=self,
1665                     id="fields.E133",
1666                 )
1667             ]
1668         else:
1669             return []
1670 
1671     def _check_decimal_places_and_max_digits(self, **kwargs):
1672         if int(self.decimal_places) > int(self.max_digits):
1673             return [
1674                 checks.Error(
1675                     "'max_digits' must be greater or equal to 'decimal_places'.",
1676                     obj=self,
1677                     id="fields.E134",
1678                 )
1679             ]
1680         return []
1681 
1682     @cached_property
1683     def validators(self):
1684         return super().validators + [
1685             validators.DecimalValidator(self.max_digits, self.decimal_places)
1686         ]
1687 
1688     @cached_property
1689     def context(self):
1690         return decimal.Context(prec=self.max_digits)
1691 
1692     def deconstruct(self):
1693         name, path, args, kwargs = super().deconstruct()
1694         if self.max_digits is not None:
1695             kwargs["max_digits"] = self.max_digits
1696         if self.decimal_places is not None:
1697             kwargs["decimal_places"] = self.decimal_places
1698         return name, path, args, kwargs
1699 
1700     def get_internal_type(self):
1701         return "DecimalField"
1702 
1703     def to_python(self, value):
1704         if value is None:
1705             return value
1706         if isinstance(value, float):
1707             if math.isnan(value):
1708                 raise exceptions.ValidationError(
1709                     self.error_messages["invalid"],
1710                     code="invalid",
1711                     params={"value": value},
1712                 )
1713             return self.context.create_decimal_from_float(value)
1714         try:
1715             return decimal.Decimal(value)
1716         except (decimal.InvalidOperation, TypeError, ValueError):
1717             raise exceptions.ValidationError(
1718                 self.error_messages["invalid"],
1719                 code="invalid",
1720                 params={"value": value},
1721             )
1722 
1723     def get_db_prep_save(self, value, connection):
1724         return connection.ops.adapt_decimalfield_value(
1725             self.to_python(value), self.max_digits, self.decimal_places
1726         )
1727 
1728     def get_prep_value(self, value):
1729         value = super().get_prep_value(value)
1730         return self.to_python(value)
1731 
1732     def formfield(self, **kwargs):
1733         return super().formfield(
1734             **{
1735                 "max_digits": self.max_digits,
1736                 "decimal_places": self.decimal_places,
1737                 "form_class": forms.DecimalField,
1738                 **kwargs,
1739             }
1740         )
1741 
1742 
1743 class DurationField(Field):
1744     """
1745     Store timedelta objects.
1746 
1747     Use interval on PostgreSQL, INTERVAL DAY TO SECOND on Oracle, and bigint
1748     of microseconds on other databases.
1749     """
1750 
1751     empty_strings_allowed = False
1752     default_error_messages = {
1753         "invalid": _(
1754             "“%(value)s” value has an invalid format. It must be in "
1755             "[DD] [[HH:]MM:]ss[.uuuuuu] format."
1756         )
1757     }
1758     description = _("Duration")
1759 
1760     def get_internal_type(self):
1761         return "DurationField"
1762 
1763     def to_python(self, value):
1764         if value is None:
1765             return value
1766         if isinstance(value, datetime.timedelta):
1767             return value
1768         try:
1769             parsed = parse_duration(value)
1770         except ValueError:
1771             pass
1772         else:
1773             if parsed is not None:
1774                 return parsed
1775 
1776         raise exceptions.ValidationError(
1777             self.error_messages["invalid"],
1778             code="invalid",
1779             params={"value": value},
1780         )
1781 
1782     def get_db_prep_value(self, value, connection, prepared=False):
1783         if connection.features.has_native_duration_field:
1784             return value
1785         if value is None:
1786             return None
1787         return duration_microseconds(value)
1788 
1789     def get_db_converters(self, connection):
1790         converters = []
1791         if not connection.features.has_native_duration_field:
1792             converters.append(connection.ops.convert_durationfield_value)
1793         return converters + super().get_db_converters(connection)
1794 
1795     def value_to_string(self, obj):
1796         val = self.value_from_object(obj)
1797         return "" if val is None else duration_string(val)
1798 
1799     def formfield(self, **kwargs):
1800         return super().formfield(
1801             **{
1802                 "form_class": forms.DurationField,
1803                 **kwargs,
1804             }
1805         )
1806 
1807 
1808 class EmailField(CharField):
1809     default_validators = [validators.validate_email]
1810     description = _("Email address")
1811 
1812     def __init__(self, *args, **kwargs):
1813         # max_length=254 to be compliant with RFCs 3696 and 5321
1814         kwargs.setdefault("max_length", 254)
1815         super().__init__(*args, **kwargs)
1816 
1817     def deconstruct(self):
1818         name, path, args, kwargs = super().deconstruct()
1819         # We do not exclude max_length if it matches default as we want to change
1820         # the default in future.
1821         return name, path, args, kwargs
1822 
1823     def formfield(self, **kwargs):
1824         # As with CharField, this will cause email validation to be performed
1825         # twice.
1826         return super().formfield(
1827             **{
1828                 "form_class": forms.EmailField,
1829                 **kwargs,
1830             }
1831         )
1832 
1833 
1834 class FilePathField(Field):
1835     description = _("File path")
1836 
1837     def __init__(
1838         self,
1839         verbose_name=None,
1840         name=None,
1841         path="",
1842         match=None,
1843         recursive=False,
1844         allow_files=True,
1845         allow_folders=False,
1846         **kwargs,
1847     ):
1848         self.path, self.match, self.recursive = path, match, recursive
1849         self.allow_files, self.allow_folders = allow_files, allow_folders
1850         kwargs.setdefault("max_length", 100)
1851         super().__init__(verbose_name, name, **kwargs)
1852 
1853     def check(self, **kwargs):
1854         return [
1855             *super().check(**kwargs),
1856             *self._check_allowing_files_or_folders(**kwargs),
1857         ]
1858 
1859     def _check_allowing_files_or_folders(self, **kwargs):
1860         if not self.allow_files and not self.allow_folders:
1861             return [
1862                 checks.Error(
1863                     "FilePathFields must have either 'allow_files' or 'allow_folders' "
1864                     "set to True.",
1865                     obj=self,
1866                     id="fields.E140",
1867                 )
1868             ]
1869         return []
1870 
1871     def deconstruct(self):
1872         name, path, args, kwargs = super().deconstruct()
1873         if self.path != "":
1874             kwargs["path"] = self.path
1875         if self.match is not None:
1876             kwargs["match"] = self.match
1877         if self.recursive is not False:
1878             kwargs["recursive"] = self.recursive
1879         if self.allow_files is not True:
1880             kwargs["allow_files"] = self.allow_files
1881         if self.allow_folders is not False:
1882             kwargs["allow_folders"] = self.allow_folders
1883         if kwargs.get("max_length") == 100:
1884             del kwargs["max_length"]
1885         return name, path, args, kwargs
1886 
1887     def get_prep_value(self, value):
1888         value = super().get_prep_value(value)
1889         if value is None:
1890             return None
1891         return str(value)
1892 
1893     def formfield(self, **kwargs):
1894         return super().formfield(
1895             **{
1896                 "path": self.path() if callable(self.path) else self.path,
1897                 "match": self.match,
1898                 "recursive": self.recursive,
1899                 "form_class": forms.FilePathField,
1900                 "allow_files": self.allow_files,
1901                 "allow_folders": self.allow_folders,
1902                 **kwargs,
1903             }
1904         )
1905 
1906     def get_internal_type(self):
1907         return "FilePathField"
1908 
1909 
1910 class FloatField(Field):
1911     empty_strings_allowed = False
1912     default_error_messages = {
1913         "invalid": _("“%(value)s” value must be a float."),
1914     }
1915     description = _("Floating point number")
1916 
1917     def get_prep_value(self, value):
1918         value = super().get_prep_value(value)
1919         if value is None:
1920             return None
1921         try:
1922             return float(value)
1923         except (TypeError, ValueError) as e:
1924             raise e.__class__(
1925                 "Field '%s' expected a number but got %r." % (self.name, value),
1926             ) from e
1927 
1928     def get_internal_type(self):
1929         return "FloatField"
1930 
1931     def to_python(self, value):
1932         if value is None:
1933             return value
1934         try:
1935             return float(value)
1936         except (TypeError, ValueError):
1937             raise exceptions.ValidationError(
1938                 self.error_messages["invalid"],
1939                 code="invalid",
1940                 params={"value": value},
1941             )
1942 
1943     def formfield(self, **kwargs):
1944         return super().formfield(
1945             **{
1946                 "form_class": forms.FloatField,
1947                 **kwargs,
1948             }
1949         )
1950 
1951 
1952 class IntegerField(Field):
1953     empty_strings_allowed = False
1954     default_error_messages = {
1955         "invalid": _("“%(value)s” value must be an integer."),
1956     }
1957     description = _("Integer")
1958 
1959     def check(self, **kwargs):
1960         return [
1961             *super().check(**kwargs),
1962             *self._check_max_length_warning(),
1963         ]
1964 
1965     def _check_max_length_warning(self):
1966         if self.max_length is not None:
1967             return [
1968                 checks.Warning(
1969                     "'max_length' is ignored when used with %s."
1970                     % self.__class__.__name__,
1971                     hint="Remove 'max_length' from field",
1972                     obj=self,
1973                     id="fields.W122",
1974                 )
1975             ]
1976         return []
1977 
1978     @cached_property
1979     def validators(self):
1980         # These validators can't be added at field initialization time since
1981         # they're based on values retrieved from `connection`.
1982         validators_ = super().validators
1983         internal_type = self.get_internal_type()
1984         min_value, max_value = connection.ops.integer_field_range(internal_type)
1985         if min_value is not None and not any(
1986             (
1987                 isinstance(validator, validators.MinValueValidator)
1988                 and (
1989                     validator.limit_value()
1990                     if callable(validator.limit_value)
1991                     else validator.limit_value
1992                 )
1993                 >= min_value
1994             )
1995             for validator in validators_
1996         ):
1997             validators_.append(validators.MinValueValidator(min_value))
1998         if max_value is not None and not any(
1999             (
2000                 isinstance(validator, validators.MaxValueValidator)
2001                 and (
2002                     validator.limit_value()
2003                     if callable(validator.limit_value)
2004                     else validator.limit_value
2005                 )
2006                 <= max_value
2007             )
2008             for validator in validators_
2009         ):
2010             validators_.append(validators.MaxValueValidator(max_value))
2011         return validators_
2012 
2013     def get_prep_value(self, value):
2014         value = super().get_prep_value(value)
2015         if value is None:
2016             return None
2017         try:
2018             return int(value)
2019         except (TypeError, ValueError) as e:
2020             raise e.__class__(
2021                 "Field '%s' expected a number but got %r." % (self.name, value),
2022             ) from e
2023 
2024     def get_internal_type(self):
2025         return "IntegerField"
2026 
2027     def to_python(self, value):
2028         if value is None:
2029             return value
2030         try:
2031             return int(value)
2032         except (TypeError, ValueError):
2033             raise exceptions.ValidationError(
2034                 self.error_messages["invalid"],
2035                 code="invalid",
2036                 params={"value": value},
2037             )
2038 
2039     def formfield(self, **kwargs):
2040         return super().formfield(
2041             **{
2042                 "form_class": forms.IntegerField,
2043                 **kwargs,
2044             }
2045         )
2046 
2047 
2048 class BigIntegerField(IntegerField):
2049     description = _("Big (8 byte) integer")
2050     MAX_BIGINT = 9223372036854775807
2051 
2052     def get_internal_type(self):
2053         return "BigIntegerField"
2054 
2055     def formfield(self, **kwargs):
2056         return super().formfield(
2057             **{
2058                 "min_value": -BigIntegerField.MAX_BIGINT - 1,
2059                 "max_value": BigIntegerField.MAX_BIGINT,
2060                 **kwargs,
2061             }
2062         )
2063 
2064 
2065 class SmallIntegerField(IntegerField):
2066     description = _("Small integer")
2067 
2068     def get_internal_type(self):
2069         return "SmallIntegerField"
2070 
2071 
2072 class IPAddressField(Field):
2073     empty_strings_allowed = False
2074     description = _("IPv4 address")
2075     system_check_removed_details = {
2076         "msg": (
2077             "IPAddressField has been removed except for support in "
2078             "historical migrations."
2079         ),
2080         "hint": "Use GenericIPAddressField instead.",
2081         "id": "fields.E900",
2082     }
2083 
2084     def __init__(self, *args, **kwargs):
2085         kwargs["max_length"] = 15
2086         super().__init__(*args, **kwargs)
2087 
2088     def deconstruct(self):
2089         name, path, args, kwargs = super().deconstruct()
2090         del kwargs["max_length"]
2091         return name, path, args, kwargs
2092 
2093     def get_prep_value(self, value):
2094         value = super().get_prep_value(value)
2095         if value is None:
2096             return None
2097         return str(value)
2098 
2099     def get_internal_type(self):
2100         return "IPAddressField"
2101 
2102 
2103 class GenericIPAddressField(Field):
2104     empty_strings_allowed = False
2105     description = _("IP address")
2106     default_error_messages = {}
2107 
2108     def __init__(
2109         self,
2110         verbose_name=None,
2111         name=None,
2112         protocol="both",
2113         unpack_ipv4=False,
2114         *args,
2115         **kwargs,
2116     ):
2117         self.unpack_ipv4 = unpack_ipv4
2118         self.protocol = protocol
2119         (
2120             self.default_validators,
2121             invalid_error_message,
2122         ) = validators.ip_address_validators(protocol, unpack_ipv4)
2123         self.default_error_messages["invalid"] = invalid_error_message
2124         kwargs["max_length"] = 39
2125         super().__init__(verbose_name, name, *args, **kwargs)
2126 
2127     def check(self, **kwargs):
2128         return [
2129             *super().check(**kwargs),
2130             *self._check_blank_and_null_values(**kwargs),
2131         ]
2132 
2133     def _check_blank_and_null_values(self, **kwargs):
2134         if not getattr(self, "null", False) and getattr(self, "blank", False):
2135             return [
2136                 checks.Error(
2137                     "GenericIPAddressFields cannot have blank=True if null=False, "
2138                     "as blank values are stored as nulls.",
2139                     obj=self,
2140                     id="fields.E150",
2141                 )
2142             ]
2143         return []
2144 
2145     def deconstruct(self):
2146         name, path, args, kwargs = super().deconstruct()
2147         if self.unpack_ipv4 is not False:
2148             kwargs["unpack_ipv4"] = self.unpack_ipv4
2149         if self.protocol != "both":
2150             kwargs["protocol"] = self.protocol
2151         if kwargs.get("max_length") == 39:
2152             del kwargs["max_length"]
2153         return name, path, args, kwargs
2154 
2155     def get_internal_type(self):
2156         return "GenericIPAddressField"
2157 
2158     def to_python(self, value):
2159         if value is None:
2160             return None
2161         if not isinstance(value, str):
2162             value = str(value)
2163         value = value.strip()
2164         if ":" in value:
2165             return clean_ipv6_address(
2166                 value, self.unpack_ipv4, self.error_messages["invalid"]
2167             )
2168         return value
2169 
2170     def get_db_prep_value(self, value, connection, prepared=False):
2171         if not prepared:
2172             value = self.get_prep_value(value)
2173         return connection.ops.adapt_ipaddressfield_value(value)
2174 
2175     def get_prep_value(self, value):
2176         value = super().get_prep_value(value)
2177         if value is None:
2178             return None
2179         if value and ":" in value:
2180             try:
2181                 return clean_ipv6_address(value, self.unpack_ipv4)
2182             except exceptions.ValidationError:
2183                 pass
2184         return str(value)
2185 
2186     def formfield(self, **kwargs):
2187         return super().formfield(
2188             **{
2189                 "protocol": self.protocol,
2190                 "form_class": forms.GenericIPAddressField,
2191                 **kwargs,
2192             }
2193         )
2194 
2195 
2196 class NullBooleanField(BooleanField):
2197     default_error_messages = {
2198         "invalid": _("“%(value)s” value must be either None, True or False."),
2199         "invalid_nullable": _("“%(value)s” value must be either None, True or False."),
2200     }
2201     description = _("Boolean (Either True, False or None)")
2202     system_check_removed_details = {
2203         "msg": (
2204             "NullBooleanField is removed except for support in historical "
2205             "migrations."
2206         ),
2207         "hint": "Use BooleanField(null=True) instead.",
2208         "id": "fields.E903",
2209     }
2210 
2211     def __init__(self, *args, **kwargs):
2212         kwargs["null"] = True
2213         kwargs["blank"] = True
2214         super().__init__(*args, **kwargs)
2215 
2216     def deconstruct(self):
2217         name, path, args, kwargs = super().deconstruct()
2218         del kwargs["null"]
2219         del kwargs["blank"]
2220         return name, path, args, kwargs
2221 
2222 
2223 class PositiveIntegerRelDbTypeMixin:
2224     def __init_subclass__(cls, **kwargs):
2225         super().__init_subclass__(**kwargs)
2226         if not hasattr(cls, "integer_field_class"):
2227             cls.integer_field_class = next(
2228                 (
2229                     parent
2230                     for parent in cls.__mro__[1:]
2231                     if issubclass(parent, IntegerField)
2232                 ),
2233                 None,
2234             )
2235 
2236     def rel_db_type(self, connection):
2237         """
2238         Return the data type that a related field pointing to this field should
2239         use. In most cases, a foreign key pointing to a positive integer
2240         primary key will have an integer column data type but some databases
2241         (e.g. MySQL) have an unsigned integer type. In that case
2242         (related_fields_match_type=True), the primary key should return its
2243         db_type.
2244         """
2245         if connection.features.related_fields_match_type:
2246             return self.db_type(connection)
2247         else:
2248             return self.integer_field_class().db_type(connection=connection)
2249 
2250 
2251 class PositiveBigIntegerField(PositiveIntegerRelDbTypeMixin, BigIntegerField):
2252     description = _("Positive big integer")
2253 
2254     def get_internal_type(self):
2255         return "PositiveBigIntegerField"
2256 
2257     def formfield(self, **kwargs):
2258         return super().formfield(
2259             **{
2260                 "min_value": 0,
2261                 **kwargs,
2262             }
2263         )
2264 
2265 
2266 class PositiveIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):
2267     description = _("Positive integer")
2268 
2269     def get_internal_type(self):
2270         return "PositiveIntegerField"
2271 
2272     def formfield(self, **kwargs):
2273         return super().formfield(
2274             **{
2275                 "min_value": 0,
2276                 **kwargs,
2277             }
2278         )
2279 
2280 
2281 class PositiveSmallIntegerField(PositiveIntegerRelDbTypeMixin, SmallIntegerField):
2282     description = _("Positive small integer")
2283 
2284     def get_internal_type(self):
2285         return "PositiveSmallIntegerField"
2286 
2287     def formfield(self, **kwargs):
2288         return super().formfield(
2289             **{
2290                 "min_value": 0,
2291                 **kwargs,
2292             }
2293         )
2294 
2295 
2296 class SlugField(CharField):
2297     default_validators = [validators.validate_slug]
2298     description = _("Slug (up to %(max_length)s)")
2299 
2300     def __init__(
2301         self, *args, max_length=50, db_index=True, allow_unicode=False, **kwargs
2302     ):
2303         self.allow_unicode = allow_unicode
2304         if self.allow_unicode:
2305             self.default_validators = [validators.validate_unicode_slug]
2306         super().__init__(*args, max_length=max_length, db_index=db_index, **kwargs)
2307 
2308     def deconstruct(self):
2309         name, path, args, kwargs = super().deconstruct()
2310         if kwargs.get("max_length") == 50:
2311             del kwargs["max_length"]
2312         if self.db_index is False:
2313             kwargs["db_index"] = False
2314         else:
2315             del kwargs["db_index"]
2316         if self.allow_unicode is not False:
2317             kwargs["allow_unicode"] = self.allow_unicode
2318         return name, path, args, kwargs
2319 
2320     def get_internal_type(self):
2321         return "SlugField"
2322 
2323     def formfield(self, **kwargs):
2324         return super().formfield(
2325             **{
2326                 "form_class": forms.SlugField,
2327                 "allow_unicode": self.allow_unicode,
2328                 **kwargs,
2329             }
2330         )
2331 
2332 
2333 class TextField(Field):
2334     description = _("Text")
2335 
2336     def __init__(self, *args, db_collation=None, **kwargs):
2337         super().__init__(*args, **kwargs)
2338         self.db_collation = db_collation
2339 
2340     def check(self, **kwargs):
2341         databases = kwargs.get("databases") or []
2342         return [
2343             *super().check(**kwargs),
2344             *self._check_db_collation(databases),
2345         ]
2346 
2347     def _check_db_collation(self, databases):
2348         errors = []
2349         for db in databases:
2350             if not router.allow_migrate_model(db, self.model):
2351                 continue
2352             connection = connections[db]
2353             if not (
2354                 self.db_collation is None
2355                 or "supports_collation_on_textfield"
2356                 in self.model._meta.required_db_features
2357                 or connection.features.supports_collation_on_textfield
2358             ):
2359                 errors.append(
2360                     checks.Error(
2361                         "%s does not support a database collation on "
2362                         "TextFields." % connection.display_name,
2363                         obj=self,
2364                         id="fields.E190",
2365                     ),
2366                 )
2367         return errors
2368 
2369     def db_parameters(self, connection):
2370         db_params = super().db_parameters(connection)
2371         db_params["collation"] = self.db_collation
2372         return db_params
2373 
2374     def get_internal_type(self):
2375         return "TextField"
2376 
2377     def to_python(self, value):
2378         if isinstance(value, str) or value is None:
2379             return value
2380         return str(value)
2381 
2382     def get_prep_value(self, value):
2383         value = super().get_prep_value(value)
2384         return self.to_python(value)
2385 
2386     def formfield(self, **kwargs):
2387         # Passing max_length to forms.CharField means that the value's length
2388         # will be validated twice. This is considered acceptable since we want
2389         # the value in the form field (to pass into widget for example).
2390         return super().formfield(
2391             **{
2392                 "max_length": self.max_length,
2393                 **({} if self.choices is not None else {"widget": forms.Textarea}),
2394                 **kwargs,
2395             }
2396         )
2397 
2398     def deconstruct(self):
2399         name, path, args, kwargs = super().deconstruct()
2400         if self.db_collation:
2401             kwargs["db_collation"] = self.db_collation
2402         return name, path, args, kwargs
2403 
2404 
2405 class TimeField(DateTimeCheckMixin, Field):
2406     empty_strings_allowed = False
2407     default_error_messages = {
2408         "invalid": _(
2409             "“%(value)s” value has an invalid format. It must be in "
2410             "HH:MM[:ss[.uuuuuu]] format."
2411         ),
2412         "invalid_time": _(
2413             "“%(value)s” value has the correct format "
2414             "(HH:MM[:ss[.uuuuuu]]) but it is an invalid time."
2415         ),
2416     }
2417     description = _("Time")
2418 
2419     def __init__(
2420         self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs
2421     ):
2422         self.auto_now, self.auto_now_add = auto_now, auto_now_add
2423         if auto_now or auto_now_add:
2424             kwargs["editable"] = False
2425             kwargs["blank"] = True
2426         super().__init__(verbose_name, name, **kwargs)
2427 
2428     def _check_fix_default_value(self):
2429         """
2430         Warn that using an actual date or datetime value is probably wrong;
2431         it's only evaluated on server startup.
2432         """
2433         if not self.has_default():
2434             return []
2435 
2436         value = self.default
2437         if isinstance(value, datetime.datetime):
2438             now = None
2439         elif isinstance(value, datetime.time):
2440             now = _get_naive_now()
2441             # This will not use the right date in the race condition where now
2442             # is just before the date change and value is just past 0:00.
2443             value = datetime.datetime.combine(now.date(), value)
2444         else:
2445             # No explicit time / datetime value -- no checks necessary
2446             return []
2447         # At this point, value is a datetime object.
2448         return self._check_if_value_fixed(value, now=now)
2449 
2450     def deconstruct(self):
2451         name, path, args, kwargs = super().deconstruct()
2452         if self.auto_now is not False:
2453             kwargs["auto_now"] = self.auto_now
2454         if self.auto_now_add is not False:
2455             kwargs["auto_now_add"] = self.auto_now_add
2456         if self.auto_now or self.auto_now_add:
2457             del kwargs["blank"]
2458             del kwargs["editable"]
2459         return name, path, args, kwargs
2460 
2461     def get_internal_type(self):
2462         return "TimeField"
2463 
2464     def to_python(self, value):
2465         if value is None:
2466             return None
2467         if isinstance(value, datetime.time):
2468             return value
2469         if isinstance(value, datetime.datetime):
2470             # Not usually a good idea to pass in a datetime here (it loses
2471             # information), but this can be a side-effect of interacting with a
2472             # database backend (e.g. Oracle), so we'll be accommodating.
2473             return value.time()
2474 
2475         try:
2476             parsed = parse_time(value)
2477             if parsed is not None:
2478                 return parsed
2479         except ValueError:
2480             raise exceptions.ValidationError(
2481                 self.error_messages["invalid_time"],
2482                 code="invalid_time",
2483                 params={"value": value},
2484             )
2485 
2486         raise exceptions.ValidationError(
2487             self.error_messages["invalid"],
2488             code="invalid",
2489             params={"value": value},
2490         )
2491 
2492     def pre_save(self, model_instance, add):
2493         if self.auto_now or (self.auto_now_add and add):
2494             value = datetime.datetime.now().time()
2495             setattr(model_instance, self.attname, value)
2496             return value
2497         else:
2498             return super().pre_save(model_instance, add)
2499 
2500     def get_prep_value(self, value):
2501         value = super().get_prep_value(value)
2502         return self.to_python(value)
2503 
2504     def get_db_prep_value(self, value, connection, prepared=False):
2505         # Casts times into the format expected by the backend
2506         if not prepared:
2507             value = self.get_prep_value(value)
2508         return connection.ops.adapt_timefield_value(value)
2509 
2510     def value_to_string(self, obj):
2511         val = self.value_from_object(obj)
2512         return "" if val is None else val.isoformat()
2513 
2514     def formfield(self, **kwargs):
2515         return super().formfield(
2516             **{
2517                 "form_class": forms.TimeField,
2518                 **kwargs,
2519             }
2520         )
2521 
2522 
2523 class URLField(CharField):
2524     default_validators = [validators.URLValidator()]
2525     description = _("URL")
2526 
2527     def __init__(self, verbose_name=None, name=None, **kwargs):
2528         kwargs.setdefault("max_length", 200)
2529         super().__init__(verbose_name, name, **kwargs)
2530 
2531     def deconstruct(self):
2532         name, path, args, kwargs = super().deconstruct()
2533         if kwargs.get("max_length") == 200:
2534             del kwargs["max_length"]
2535         return name, path, args, kwargs
2536 
2537     def formfield(self, **kwargs):
2538         # As with CharField, this will cause URL validation to be performed
2539         # twice.
2540         return super().formfield(
2541             **{
2542                 "form_class": forms.URLField,
2543                 **kwargs,
2544             }
2545         )
2546 
2547 
2548 class BinaryField(Field):
2549     description = _("Raw binary data")
2550     empty_values = [None, b""]
2551 
2552     def __init__(self, *args, **kwargs):
2553         kwargs.setdefault("editable", False)
2554         super().__init__(*args, **kwargs)
2555         if self.max_length is not None:
2556             self.validators.append(validators.MaxLengthValidator(self.max_length))
2557 
2558     def check(self, **kwargs):
2559         return [*super().check(**kwargs), *self._check_str_default_value()]
2560 
2561     def _check_str_default_value(self):
2562         if self.has_default() and isinstance(self.default, str):
2563             return [
2564                 checks.Error(
2565                     "BinaryField's default cannot be a string. Use bytes "
2566                     "content instead.",
2567                     obj=self,
2568                     id="fields.E170",
2569                 )
2570             ]
2571         return []
2572 
2573     def deconstruct(self):
2574         name, path, args, kwargs = super().deconstruct()
2575         if self.editable:
2576             kwargs["editable"] = True
2577         else:
2578             del kwargs["editable"]
2579         return name, path, args, kwargs
2580 
2581     def get_internal_type(self):
2582         return "BinaryField"
2583 
2584     def get_placeholder(self, value, compiler, connection):
2585         return connection.ops.binary_placeholder_sql(value)
2586 
2587     def get_default(self):
2588         if self.has_default() and not callable(self.default):
2589             return self.default
2590         default = super().get_default()
2591         if default == "":
2592             return b""
2593         return default
2594 
2595     def get_db_prep_value(self, value, connection, prepared=False):
2596         value = super().get_db_prep_value(value, connection, prepared)
2597         if value is not None:
2598             return connection.Database.Binary(value)
2599         return value
2600 
2601     def value_to_string(self, obj):
2602         """Binary data is serialized as base64"""
2603         return b64encode(self.value_from_object(obj)).decode("ascii")
2604 
2605     def to_python(self, value):
2606         # If it's a string, it should be base64-encoded data
2607         if isinstance(value, str):
2608             return memoryview(b64decode(value.encode("ascii")))
2609         return value
2610 
2611 
2612 class UUIDField(Field):
2613     default_error_messages = {
2614         "invalid": _("“%(value)s” is not a valid UUID."),
2615     }
2616     description = _("Universally unique identifier")
2617     empty_strings_allowed = False
2618 
2619     def __init__(self, verbose_name=None, **kwargs):
2620         kwargs["max_length"] = 32
2621         super().__init__(verbose_name, **kwargs)
2622 
2623     def deconstruct(self):
2624         name, path, args, kwargs = super().deconstruct()
2625         del kwargs["max_length"]
2626         return name, path, args, kwargs
2627 
2628     def get_internal_type(self):
2629         return "UUIDField"
2630 
2631     def get_prep_value(self, value):
2632         value = super().get_prep_value(value)
2633         return self.to_python(value)
2634 
2635     def get_db_prep_value(self, value, connection, prepared=False):
2636         if value is None:
2637             return None
2638         if not isinstance(value, uuid.UUID):
2639             value = self.to_python(value)
2640 
2641         if connection.features.has_native_uuid_field:
2642             return value
2643         return value.hex
2644 
2645     def to_python(self, value):
2646         if value is not None and not isinstance(value, uuid.UUID):
2647             input_form = "int" if isinstance(value, int) else "hex"
2648             try:
2649                 return uuid.UUID(**{input_form: value})
2650             except (AttributeError, ValueError):
2651                 raise exceptions.ValidationError(
2652                     self.error_messages["invalid"],
2653                     code="invalid",
2654                     params={"value": value},
2655                 )
2656         return value
2657 
2658     def formfield(self, **kwargs):
2659         return super().formfield(
2660             **{
2661                 "form_class": forms.UUIDField,
2662                 **kwargs,
2663             }
2664         )
2665 
2666 
2667 class AutoFieldMixin:
2668     db_returning = True
2669 
2670     def __init__(self, *args, **kwargs):
2671         kwargs["blank"] = True
2672         super().__init__(*args, **kwargs)
2673 
2674     def check(self, **kwargs):
2675         return [
2676             *super().check(**kwargs),
2677             *self._check_primary_key(),
2678         ]
2679 
2680     def _check_primary_key(self):
2681         if not self.primary_key:
2682             return [
2683                 checks.Error(
2684                     "AutoFields must set primary_key=True.",
2685                     obj=self,
2686                     id="fields.E100",
2687                 ),
2688             ]
2689         else:
2690             return []
2691 
2692     def deconstruct(self):
2693         name, path, args, kwargs = super().deconstruct()
2694         del kwargs["blank"]
2695         kwargs["primary_key"] = True
2696         return name, path, args, kwargs
2697 
2698     def validate(self, value, model_instance):
2699         pass
2700 
2701     def get_db_prep_value(self, value, connection, prepared=False):
2702         if not prepared:
2703             value = self.get_prep_value(value)
2704             value = connection.ops.validate_autopk_value(value)
2705         return value
2706 
2707     def contribute_to_class(self, cls, name, **kwargs):
2708         if cls._meta.auto_field:
2709             raise ValueError(
2710                 "Model %s can't have more than one auto-generated field."
2711                 % cls._meta.label
2712             )
2713         super().contribute_to_class(cls, name, **kwargs)
2714         cls._meta.auto_field = self
2715 
2716     def formfield(self, **kwargs):
2717         return None
2718 
2719 
2720 class AutoFieldMeta(type):
2721     """
2722     Metaclass to maintain backward inheritance compatibility for AutoField.
2723 
2724     It is intended that AutoFieldMixin become public API when it is possible to
2725     create a non-integer automatically-generated field using column defaults
2726     stored in the database.
2727 
2728     In many areas Django also relies on using isinstance() to check for an
2729     automatically-generated field as a subclass of AutoField. A new flag needs
2730     to be implemented on Field to be used instead.
2731 
2732     When these issues have been addressed, this metaclass could be used to
2733     deprecate inheritance from AutoField and use of isinstance() with AutoField
2734     for detecting automatically-generated fields.
2735     """
2736 
2737     @property
2738     def _subclasses(self):
2739         return (BigAutoField, SmallAutoField)
2740 
2741     def __instancecheck__(self, instance):
2742         return isinstance(instance, self._subclasses) or super().__instancecheck__(
2743             instance
2744         )
2745 
2746     def __subclasscheck__(self, subclass):
2747         return issubclass(subclass, self._subclasses) or super().__subclasscheck__(
2748             subclass
2749         )
2750 
2751 
2752 class AutoField(AutoFieldMixin, IntegerField, metaclass=AutoFieldMeta):
2753     def get_internal_type(self):
2754         return "AutoField"
2755 
2756     def rel_db_type(self, connection):
2757         return IntegerField().db_type(connection=connection)
2758 
2759 
2760 class BigAutoField(AutoFieldMixin, BigIntegerField):
2761     def get_internal_type(self):
2762         return "BigAutoField"
2763 
2764     def rel_db_type(self, connection):
2765         return BigIntegerField().db_type(connection=connection)
2766 
2767 
2768 class SmallAutoField(AutoFieldMixin, SmallIntegerField):
2769     def get_internal_type(self):
2770         return "SmallAutoField"
2771 
2772     def rel_db_type(self, connection):
2773         return SmallIntegerField().db_type(connection=connection)

</code><intended_behavior>Ensure consistent handling and documentation around `db_collation` attribute, so it is clear how it should be propagated in the context of model relationships and migrations.</intended_behavior>]
2025-10-17 23:31:27.483 | INFO     | Search completed. Bug locations: [<file>django/db/backends/mysql/schema.py</file>
<class>None</class>
<method>None</method>
<code>
1 from django.db.backends.base.schema import BaseDatabaseSchemaEditor
2 from django.db.models import NOT_PROVIDED
3 
4 
5 class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):
6 
7     sql_rename_table = "RENAME TABLE %(old_table)s TO %(new_table)s"
8 
9     sql_alter_column_null = "MODIFY %(column)s %(type)s NULL"
10     sql_alter_column_not_null = "MODIFY %(column)s %(type)s NOT NULL"
11     sql_alter_column_type = "MODIFY %(column)s %(type)s"
12     sql_alter_column_collate = "MODIFY %(column)s %(type)s%(collation)s"
13     sql_alter_column_no_default_null = "ALTER COLUMN %(column)s SET DEFAULT NULL"
14 
15     # No 'CASCADE' which works as a no-op in MySQL but is undocumented
16     sql_delete_column = "ALTER TABLE %(table)s DROP COLUMN %(column)s"
17 
18     sql_delete_unique = "ALTER TABLE %(table)s DROP INDEX %(name)s"
19     sql_create_column_inline_fk = (
20         ", ADD CONSTRAINT %(name)s FOREIGN KEY (%(column)s) "
21         "REFERENCES %(to_table)s(%(to_column)s)"
22     )
23     sql_delete_fk = "ALTER TABLE %(table)s DROP FOREIGN KEY %(name)s"
24 
25     sql_delete_index = "DROP INDEX %(name)s ON %(table)s"
26 
27     sql_create_pk = (
28         "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s PRIMARY KEY (%(columns)s)"
29     )
30     sql_delete_pk = "ALTER TABLE %(table)s DROP PRIMARY KEY"
31 
32     sql_create_index = "CREATE INDEX %(name)s ON %(table)s (%(columns)s)%(extra)s"
33 
34     @property
35     def sql_delete_check(self):
36         if self.connection.mysql_is_mariadb:
37             # The name of the column check constraint is the same as the field
38             # name on MariaDB. Adding IF EXISTS clause prevents migrations
39             # crash. Constraint is removed during a "MODIFY" column statement.
40             return "ALTER TABLE %(table)s DROP CONSTRAINT IF EXISTS %(name)s"
41         return "ALTER TABLE %(table)s DROP CHECK %(name)s"
42 
43     @property
44     def sql_rename_column(self):
45         # MariaDB >= 10.5.2 and MySQL >= 8.0.4 support an
46         # "ALTER TABLE ... RENAME COLUMN" statement.
47         if self.connection.mysql_is_mariadb:
48             if self.connection.mysql_version >= (10, 5, 2):
49                 return super().sql_rename_column
50         elif self.connection.mysql_version >= (8, 0, 4):
51             return super().sql_rename_column
52         return "ALTER TABLE %(table)s CHANGE %(old_column)s %(new_column)s %(type)s"
53 
54     def quote_value(self, value):
55         self.connection.ensure_connection()
56         if isinstance(value, str):
57             value = value.replace("%", "%%")
58         # MySQLdb escapes to string, PyMySQL to bytes.
59         quoted = self.connection.connection.escape(
60             value, self.connection.connection.encoders
61         )
62         if isinstance(value, str) and isinstance(quoted, bytes):
63             quoted = quoted.decode()
64         return quoted
65 
66     def _is_limited_data_type(self, field):
67         db_type = field.db_type(self.connection)
68         return (
69             db_type is not None
70             and db_type.lower() in self.connection._limited_data_types
71         )
72 
73     def skip_default(self, field):
74         if not self._supports_limited_data_type_defaults:
75             return self._is_limited_data_type(field)
76         return False
77 
78     def skip_default_on_alter(self, field):
79         if self._is_limited_data_type(field) and not self.connection.mysql_is_mariadb:
80             # MySQL doesn't support defaults for BLOB and TEXT in the
81             # ALTER COLUMN statement.
82             return True
83         return False
84 
85     @property
86     def _supports_limited_data_type_defaults(self):
87         # MariaDB and MySQL >= 8.0.13 support defaults for BLOB and TEXT.
88         if self.connection.mysql_is_mariadb:
89             return True
90         return self.connection.mysql_version >= (8, 0, 13)
91 
92     def _column_default_sql(self, field):
93         if (
94             not self.connection.mysql_is_mariadb
95             and self._supports_limited_data_type_defaults
96             and self._is_limited_data_type(field)
97         ):
98             # MySQL supports defaults for BLOB and TEXT columns only if the
99             # default value is written as an expression i.e. in parentheses.
100             return "(%s)"
101         return super()._column_default_sql(field)
102 
103     def add_field(self, model, field):
104         super().add_field(model, field)
105 
106         # Simulate the effect of a one-off default.
107         # field.default may be unhashable, so a set isn't used for "in" check.
108         if self.skip_default(field) and field.default not in (None, NOT_PROVIDED):
109             effective_default = self.effective_default(field)
110             self.execute(
111                 "UPDATE %(table)s SET %(column)s = %%s"
112                 % {
113                     "table": self.quote_name(model._meta.db_table),
114                     "column": self.quote_name(field.column),
115                 },
116                 [effective_default],
117             )
118 
119     def _field_should_be_indexed(self, model, field):
120         if not super()._field_should_be_indexed(model, field):
121             return False
122 
123         storage = self.connection.introspection.get_storage_engine(
124             self.connection.cursor(), model._meta.db_table
125         )
126         # No need to create an index for ForeignKey fields except if
127         # db_constraint=False because the index from that constraint won't be
128         # created.
129         if (
130             storage == "InnoDB"
131             and field.get_internal_type() == "ForeignKey"
132             and field.db_constraint
133         ):
134             return False
135         return not self._is_limited_data_type(field)
136 
137     def _delete_composed_index(self, model, fields, *args):
138         """
139         MySQL can remove an implicit FK index on a field when that field is
140         covered by another index like a unique_together. "covered" here means
141         that the more complex index starts like the simpler one.
142         https://bugs.mysql.com/bug.php?id=37910 / Django ticket #24757
143         We check here before removing the [unique|index]_together if we have to
144         recreate a FK index.
145         """
146         first_field = model._meta.get_field(fields[0])
147         if first_field.get_internal_type() == "ForeignKey":
148             constraint_names = self._constraint_names(
149                 model, [first_field.column], index=True
150             )
151             if not constraint_names:
152                 self.execute(
153                     self._create_index_sql(model, fields=[first_field], suffix="")
154                 )
155         return super()._delete_composed_index(model, fields, *args)
156 
157     def _set_field_new_type_null_status(self, field, new_type):
158         """
159         Keep the null property of the old field. If it has changed, it will be
160         handled separately.
161         """
162         if field.null:
163             new_type += " NULL"
164         else:
165             new_type += " NOT NULL"
166         return new_type
167 
168     def _alter_column_type_sql(self, model, old_field, new_field, new_type):
169         new_type = self._set_field_new_type_null_status(old_field, new_type)
170         return super()._alter_column_type_sql(model, old_field, new_field, new_type)
171 
172     def _rename_field_sql(self, table, old_field, new_field, new_type):
173         new_type = self._set_field_new_type_null_status(old_field, new_type)
174         return super()._rename_field_sql(table, old_field, new_field, new_type)

</code><intended_behavior>Ensure that when a foreign key is added or modified, the `db_collation` of the referenced primary key column is applied to the foreign key column. This may involve adjusting the SQL statement generation to include the `COLLATE` clause with the appropriate collation when altering foreign key columns.</intended_behavior>, <file>django/db/migrations/autodetector.py</file>
<class>None</class>
<method>None</method>
<code>
1 import functools
2 import re
3 from itertools import chain
4 
5 from django.conf import settings
6 from django.db import models
7 from django.db.migrations import operations
8 from django.db.migrations.migration import Migration
9 from django.db.migrations.operations.models import AlterModelOptions
10 from django.db.migrations.optimizer import MigrationOptimizer
11 from django.db.migrations.questioner import MigrationQuestioner
12 from django.db.migrations.utils import (
13     COMPILED_REGEX_TYPE,
14     RegexObject,
15     resolve_relation,
16 )
17 from django.utils.topological_sort import stable_topological_sort
18 
19 
20 class MigrationAutodetector:
21     """
22     Take a pair of ProjectStates and compare them to see what the first would
23     need doing to make it match the second (the second usually being the
24     project's current state).
25 
26     Note that this naturally operates on entire projects at a time,
27     as it's likely that changes interact (for example, you can't
28     add a ForeignKey without having a migration to add the table it
29     depends on first). A user interface may offer single-app usage
30     if it wishes, with the caveat that it may not always be possible.
31     """
32 
33     def __init__(self, from_state, to_state, questioner=None):
34         self.from_state = from_state
35         self.to_state = to_state
36         self.questioner = questioner or MigrationQuestioner()
37         self.existing_apps = {app for app, model in from_state.models}
38 
39     def changes(self, graph, trim_to_apps=None, convert_apps=None, migration_name=None):
40         """
41         Main entry point to produce a list of applicable changes.
42         Take a graph to base names on and an optional set of apps
43         to try and restrict to (restriction is not guaranteed)
44         """
45         changes = self._detect_changes(convert_apps, graph)
46         changes = self.arrange_for_graph(changes, graph, migration_name)
47         if trim_to_apps:
48             changes = self._trim_to_apps(changes, trim_to_apps)
49         return changes
50 
51     def deep_deconstruct(self, obj):
52         """
53         Recursive deconstruction for a field and its arguments.
54         Used for full comparison for rename/alter; sometimes a single-level
55         deconstruction will not compare correctly.
56         """
57         if isinstance(obj, list):
58             return [self.deep_deconstruct(value) for value in obj]
59         elif isinstance(obj, tuple):
60             return tuple(self.deep_deconstruct(value) for value in obj)
61         elif isinstance(obj, dict):
62             return {key: self.deep_deconstruct(value) for key, value in obj.items()}
63         elif isinstance(obj, functools.partial):
64             return (
65                 obj.func,
66                 self.deep_deconstruct(obj.args),
67                 self.deep_deconstruct(obj.keywords),
68             )
69         elif isinstance(obj, COMPILED_REGEX_TYPE):
70             return RegexObject(obj)
71         elif isinstance(obj, type):
72             # If this is a type that implements 'deconstruct' as an instance method,
73             # avoid treating this as being deconstructible itself - see #22951
74             return obj
75         elif hasattr(obj, "deconstruct"):
76             deconstructed = obj.deconstruct()
77             if isinstance(obj, models.Field):
78                 # we have a field which also returns a name
79                 deconstructed = deconstructed[1:]
80             path, args, kwargs = deconstructed
81             return (
82                 path,
83                 [self.deep_deconstruct(value) for value in args],
84                 {key: self.deep_deconstruct(value) for key, value in kwargs.items()},
85             )
86         else:
87             return obj
88 
89     def only_relation_agnostic_fields(self, fields):
90         """
91         Return a definition of the fields that ignores field names and
92         what related fields actually relate to. Used for detecting renames (as
93         the related fields change during renames).
94         """
95         fields_def = []
96         for name, field in sorted(fields.items()):
97             deconstruction = self.deep_deconstruct(field)
98             if field.remote_field and field.remote_field.model:
99                 deconstruction[2].pop("to", None)
100             fields_def.append(deconstruction)
101         return fields_def
102 
103     def _detect_changes(self, convert_apps=None, graph=None):
104         """
105         Return a dict of migration plans which will achieve the
106         change from from_state to to_state. The dict has app labels
107         as keys and a list of migrations as values.
108 
109         The resulting migrations aren't specially named, but the names
110         do matter for dependencies inside the set.
111 
112         convert_apps is the list of apps to convert to use migrations
113         (i.e. to make initial migrations for, in the usual case)
114 
115         graph is an optional argument that, if provided, can help improve
116         dependency generation and avoid potential circular dependencies.
117         """
118         # The first phase is generating all the operations for each app
119         # and gathering them into a big per-app list.
120         # Then go through that list, order it, and split into migrations to
121         # resolve dependencies caused by M2Ms and FKs.
122         self.generated_operations = {}
123         self.altered_indexes = {}
124         self.altered_constraints = {}
125 
126         # Prepare some old/new state and model lists, separating
127         # proxy models and ignoring unmigrated apps.
128         self.old_model_keys = set()
129         self.old_proxy_keys = set()
130         self.old_unmanaged_keys = set()
131         self.new_model_keys = set()
132         self.new_proxy_keys = set()
133         self.new_unmanaged_keys = set()
134         for (app_label, model_name), model_state in self.from_state.models.items():
135             if not model_state.options.get("managed", True):
136                 self.old_unmanaged_keys.add((app_label, model_name))
137             elif app_label not in self.from_state.real_apps:
138                 if model_state.options.get("proxy"):
139                     self.old_proxy_keys.add((app_label, model_name))
140                 else:
141                     self.old_model_keys.add((app_label, model_name))
142 
143         for (app_label, model_name), model_state in self.to_state.models.items():
144             if not model_state.options.get("managed", True):
145                 self.new_unmanaged_keys.add((app_label, model_name))
146             elif app_label not in self.from_state.real_apps or (
147                 convert_apps and app_label in convert_apps
148             ):
149                 if model_state.options.get("proxy"):
150                     self.new_proxy_keys.add((app_label, model_name))
151                 else:
152                     self.new_model_keys.add((app_label, model_name))
153 
154         self.from_state.resolve_fields_and_relations()
155         self.to_state.resolve_fields_and_relations()
156 
157         # Renames have to come first
158         self.generate_renamed_models()
159 
160         # Prepare lists of fields and generate through model map
161         self._prepare_field_lists()
162         self._generate_through_model_map()
163 
164         # Generate non-rename model operations
165         self.generate_deleted_models()
166         self.generate_created_models()
167         self.generate_deleted_proxies()
168         self.generate_created_proxies()
169         self.generate_altered_options()
170         self.generate_altered_managers()
171 
172         # Create the altered indexes and store them in self.altered_indexes.
173         # This avoids the same computation in generate_removed_indexes()
174         # and generate_added_indexes().
175         self.create_altered_indexes()
176         self.create_altered_constraints()
177         # Generate index removal operations before field is removed
178         self.generate_removed_constraints()
179         self.generate_removed_indexes()
180         # Generate field renaming operations.
181         self.generate_renamed_fields()
182         # Generate removal of foo together.
183         self.generate_removed_altered_unique_together()
184         self.generate_removed_altered_index_together()
185         # Generate field operations.
186         self.generate_removed_fields()
187         self.generate_added_fields()
188         self.generate_altered_fields()
189         self.generate_altered_order_with_respect_to()
190         self.generate_altered_unique_together()
191         self.generate_altered_index_together()
192         self.generate_added_indexes()
193         self.generate_added_constraints()
194         self.generate_altered_db_table()
195 
196         self._sort_migrations()
197         self._build_migration_list(graph)
198         self._optimize_migrations()
199 
200         return self.migrations
201 
202     def _prepare_field_lists(self):
203         """
204         Prepare field lists and a list of the fields that used through models
205         in the old state so dependencies can be made from the through model
206         deletion to the field that uses it.
207         """
208         self.kept_model_keys = self.old_model_keys & self.new_model_keys
209         self.kept_proxy_keys = self.old_proxy_keys & self.new_proxy_keys
210         self.kept_unmanaged_keys = self.old_unmanaged_keys & self.new_unmanaged_keys
211         self.through_users = {}
212         self.old_field_keys = {
213             (app_label, model_name, field_name)
214             for app_label, model_name in self.kept_model_keys
215             for field_name in self.from_state.models[
216                 app_label, self.renamed_models.get((app_label, model_name), model_name)
217             ].fields
218         }
219         self.new_field_keys = {
220             (app_label, model_name, field_name)
221             for app_label, model_name in self.kept_model_keys
222             for field_name in self.to_state.models[app_label, model_name].fields
223         }
224 
225     def _generate_through_model_map(self):
226         """Through model map generation."""
227         for app_label, model_name in sorted(self.old_model_keys):
228             old_model_name = self.renamed_models.get(
229                 (app_label, model_name), model_name
230             )
231             old_model_state = self.from_state.models[app_label, old_model_name]
232             for field_name, field in old_model_state.fields.items():
233                 if hasattr(field, "remote_field") and getattr(
234                     field.remote_field, "through", None
235                 ):
236                     through_key = resolve_relation(
237                         field.remote_field.through, app_label, model_name
238                     )
239                     self.through_users[through_key] = (
240                         app_label,
241                         old_model_name,
242                         field_name,
243                     )
244 
245     @staticmethod
246     def _resolve_dependency(dependency):
247         """
248         Return the resolved dependency and a boolean denoting whether or not
249         it was swappable.
250         """
251         if dependency[0] != "__setting__":
252             return dependency, False
253         resolved_app_label, resolved_object_name = getattr(
254             settings, dependency[1]
255         ).split(".")
256         return (resolved_app_label, resolved_object_name.lower()) + dependency[2:], True
257 
258     def _build_migration_list(self, graph=None):
259         """
260         Chop the lists of operations up into migrations with dependencies on
261         each other. Do this by going through an app's list of operations until
262         one is found that has an outgoing dependency that isn't in another
263         app's migration yet (hasn't been chopped off its list). Then chop off
264         the operations before it into a migration and move onto the next app.
265         If the loops completes without doing anything, there's a circular
266         dependency (which _should_ be impossible as the operations are
267         all split at this point so they can't depend and be depended on).
268         """
269         self.migrations = {}
270         num_ops = sum(len(x) for x in self.generated_operations.values())
271         chop_mode = False
272         while num_ops:
273             # On every iteration, we step through all the apps and see if there
274             # is a completed set of operations.
275             # If we find that a subset of the operations are complete we can
276             # try to chop it off from the rest and continue, but we only
277             # do this if we've already been through the list once before
278             # without any chopping and nothing has changed.
279             for app_label in sorted(self.generated_operations):
280                 chopped = []
281                 dependencies = set()
282                 for operation in list(self.generated_operations[app_label]):
283                     deps_satisfied = True
284                     operation_dependencies = set()
285                     for dep in operation._auto_deps:
286                         # Temporarily resolve the swappable dependency to
287                         # prevent circular references. While keeping the
288                         # dependency checks on the resolved model, add the
289                         # swappable dependencies.
290                         original_dep = dep
291                         dep, is_swappable_dep = self._resolve_dependency(dep)
292                         if dep[0] != app_label:
293                             # External app dependency. See if it's not yet
294                             # satisfied.
295                             for other_operation in self.generated_operations.get(
296                                 dep[0], []
297                             ):
298                                 if self.check_dependency(other_operation, dep):
299                                     deps_satisfied = False
300                                     break
301                             if not deps_satisfied:
302                                 break
303                             else:
304                                 if is_swappable_dep:
305                                     operation_dependencies.add(
306                                         (original_dep[0], original_dep[1])
307                                     )
308                                 elif dep[0] in self.migrations:
309                                     operation_dependencies.add(
310                                         (dep[0], self.migrations[dep[0]][-1].name)
311                                     )
312                                 else:
313                                     # If we can't find the other app, we add a
314                                     # first/last dependency, but only if we've
315                                     # already been through once and checked
316                                     # everything.
317                                     if chop_mode:
318                                         # If the app already exists, we add a
319                                         # dependency on the last migration, as
320                                         # we don't know which migration
321                                         # contains the target field. If it's
322                                         # not yet migrated or has no
323                                         # migrations, we use __first__.
324                                         if graph and graph.leaf_nodes(dep[0]):
325                                             operation_dependencies.add(
326                                                 graph.leaf_nodes(dep[0])[0]
327                                             )
328                                         else:
329                                             operation_dependencies.add(
330                                                 (dep[0], "__first__")
331                                             )
332                                     else:
333                                         deps_satisfied = False
334                     if deps_satisfied:
335                         chopped.append(operation)
336                         dependencies.update(operation_dependencies)
337                         del self.generated_operations[app_label][0]
338                     else:
339                         break
340                 # Make a migration! Well, only if there's stuff to put in it
341                 if dependencies or chopped:
342                     if not self.generated_operations[app_label] or chop_mode:
343                         subclass = type(
344                             "Migration",
345                             (Migration,),
346                             {"operations": [], "dependencies": []},
347                         )
348                         instance = subclass(
349                             "auto_%i" % (len(self.migrations.get(app_label, [])) + 1),
350                             app_label,
351                         )
352                         instance.dependencies = list(dependencies)
353                         instance.operations = chopped
354                         instance.initial = app_label not in self.existing_apps
355                         self.migrations.setdefault(app_label, []).append(instance)
356                         chop_mode = False
357                     else:
358                         self.generated_operations[app_label] = (
359                             chopped + self.generated_operations[app_label]
360                         )
361             new_num_ops = sum(len(x) for x in self.generated_operations.values())
362             if new_num_ops == num_ops:
363                 if not chop_mode:
364                     chop_mode = True
365                 else:
366                     raise ValueError(
367                         "Cannot resolve operation dependencies: %r"
368                         % self.generated_operations
369                     )
370             num_ops = new_num_ops
371 
372     def _sort_migrations(self):
373         """
374         Reorder to make things possible. Reordering may be needed so FKs work
375         nicely inside the same app.
376         """
377         for app_label, ops in sorted(self.generated_operations.items()):
378             # construct a dependency graph for intra-app dependencies
379             dependency_graph = {op: set() for op in ops}
380             for op in ops:
381                 for dep in op._auto_deps:
382                     # Resolve intra-app dependencies to handle circular
383                     # references involving a swappable model.
384                     dep = self._resolve_dependency(dep)[0]
385                     if dep[0] == app_label:
386                         for op2 in ops:
387                             if self.check_dependency(op2, dep):
388                                 dependency_graph[op].add(op2)
389 
390             # we use a stable sort for deterministic tests & general behavior
391             self.generated_operations[app_label] = stable_topological_sort(
392                 ops, dependency_graph
393             )
394 
395     def _optimize_migrations(self):
396         # Add in internal dependencies among the migrations
397         for app_label, migrations in self.migrations.items():
398             for m1, m2 in zip(migrations, migrations[1:]):
399                 m2.dependencies.append((app_label, m1.name))
400 
401         # De-dupe dependencies
402         for migrations in self.migrations.values():
403             for migration in migrations:
404                 migration.dependencies = list(set(migration.dependencies))
405 
406         # Optimize migrations
407         for app_label, migrations in self.migrations.items():
408             for migration in migrations:
409                 migration.operations = MigrationOptimizer().optimize(
410                     migration.operations, app_label
411                 )
412 
413     def check_dependency(self, operation, dependency):
414         """
415         Return True if the given operation depends on the given dependency,
416         False otherwise.
417         """
418         # Created model
419         if dependency[2] is None and dependency[3] is True:
420             return (
421                 isinstance(operation, operations.CreateModel)
422                 and operation.name_lower == dependency[1].lower()
423             )
424         # Created field
425         elif dependency[2] is not None and dependency[3] is True:
426             return (
427                 isinstance(operation, operations.CreateModel)
428                 and operation.name_lower == dependency[1].lower()
429                 and any(dependency[2] == x for x, y in operation.fields)
430             ) or (
431                 isinstance(operation, operations.AddField)
432                 and operation.model_name_lower == dependency[1].lower()
433                 and operation.name_lower == dependency[2].lower()
434             )
435         # Removed field
436         elif dependency[2] is not None and dependency[3] is False:
437             return (
438                 isinstance(operation, operations.RemoveField)
439                 and operation.model_name_lower == dependency[1].lower()
440                 and operation.name_lower == dependency[2].lower()
441             )
442         # Removed model
443         elif dependency[2] is None and dependency[3] is False:
444             return (
445                 isinstance(operation, operations.DeleteModel)
446                 and operation.name_lower == dependency[1].lower()
447             )
448         # Field being altered
449         elif dependency[2] is not None and dependency[3] == "alter":
450             return (
451                 isinstance(operation, operations.AlterField)
452                 and operation.model_name_lower == dependency[1].lower()
453                 and operation.name_lower == dependency[2].lower()
454             )
455         # order_with_respect_to being unset for a field
456         elif dependency[2] is not None and dependency[3] == "order_wrt_unset":
457             return (
458                 isinstance(operation, operations.AlterOrderWithRespectTo)
459                 and operation.name_lower == dependency[1].lower()
460                 and (operation.order_with_respect_to or "").lower()
461                 != dependency[2].lower()
462             )
463         # Field is removed and part of an index/unique_together
464         elif dependency[2] is not None and dependency[3] == "foo_together_change":
465             return (
466                 isinstance(
467                     operation,
468                     (operations.AlterUniqueTogether, operations.AlterIndexTogether),
469                 )
470                 and operation.name_lower == dependency[1].lower()
471             )
472         # Unknown dependency. Raise an error.
473         else:
474             raise ValueError("Can't handle dependency %r" % (dependency,))
475 
476     def add_operation(self, app_label, operation, dependencies=None, beginning=False):
477         # Dependencies are
478         # (app_label, model_name, field_name, create/delete as True/False)
479         operation._auto_deps = dependencies or []
480         if beginning:
481             self.generated_operations.setdefault(app_label, []).insert(0, operation)
482         else:
483             self.generated_operations.setdefault(app_label, []).append(operation)
484 
485     def swappable_first_key(self, item):
486         """
487         Place potential swappable models first in lists of created models (only
488         real way to solve #22783).
489         """
490         try:
491             model_state = self.to_state.models[item]
492             base_names = {
493                 base if isinstance(base, str) else base.__name__
494                 for base in model_state.bases
495             }
496             string_version = "%s.%s" % (item[0], item[1])
497             if (
498                 model_state.options.get("swappable")
499                 or "AbstractUser" in base_names
500                 or "AbstractBaseUser" in base_names
501                 or settings.AUTH_USER_MODEL.lower() == string_version.lower()
502             ):
503                 return ("___" + item[0], "___" + item[1])
504         except LookupError:
505             pass
506         return item
507 
508     def generate_renamed_models(self):
509         """
510         Find any renamed models, generate the operations for them, and remove
511         the old entry from the model lists. Must be run before other
512         model-level generation.
513         """
514         self.renamed_models = {}
515         self.renamed_models_rel = {}
516         added_models = self.new_model_keys - self.old_model_keys
517         for app_label, model_name in sorted(added_models):
518             model_state = self.to_state.models[app_label, model_name]
519             model_fields_def = self.only_relation_agnostic_fields(model_state.fields)
520 
521             removed_models = self.old_model_keys - self.new_model_keys
522             for rem_app_label, rem_model_name in removed_models:
523                 if rem_app_label == app_label:
524                     rem_model_state = self.from_state.models[
525                         rem_app_label, rem_model_name
526                     ]
527                     rem_model_fields_def = self.only_relation_agnostic_fields(
528                         rem_model_state.fields
529                     )
530                     if model_fields_def == rem_model_fields_def:
531                         if self.questioner.ask_rename_model(
532                             rem_model_state, model_state
533                         ):
534                             dependencies = []
535                             fields = list(model_state.fields.values()) + [
536                                 field.remote_field
537                                 for relations in self.to_state.relations[
538                                     app_label, model_name
539                                 ].values()
540                                 for field in relations.values()
541                             ]
542                             for field in fields:
543                                 if field.is_relation:
544                                     dependencies.extend(
545                                         self._get_dependencies_for_foreign_key(
546                                             app_label,
547                                             model_name,
548                                             field,
549                                             self.to_state,
550                                         )
551                                     )
552                             self.add_operation(
553                                 app_label,
554                                 operations.RenameModel(
555                                     old_name=rem_model_state.name,
556                                     new_name=model_state.name,
557                                 ),
558                                 dependencies=dependencies,
559                             )
560                             self.renamed_models[app_label, model_name] = rem_model_name
561                             renamed_models_rel_key = "%s.%s" % (
562                                 rem_model_state.app_label,
563                                 rem_model_state.name_lower,
564                             )
565                             self.renamed_models_rel[
566                                 renamed_models_rel_key
567                             ] = "%s.%s" % (
568                                 model_state.app_label,
569                                 model_state.name_lower,
570                             )
571                             self.old_model_keys.remove((rem_app_label, rem_model_name))
572                             self.old_model_keys.add((app_label, model_name))
573                             break
574 
575     def generate_created_models(self):
576         """
577         Find all new models (both managed and unmanaged) and make create
578         operations for them as well as separate operations to create any
579         foreign key or M2M relationships (these are optimized later, if
580         possible).
581 
582         Defer any model options that refer to collections of fields that might
583         be deferred (e.g. unique_together, index_together).
584         """
585         old_keys = self.old_model_keys | self.old_unmanaged_keys
586         added_models = self.new_model_keys - old_keys
587         added_unmanaged_models = self.new_unmanaged_keys - old_keys
588         all_added_models = chain(
589             sorted(added_models, key=self.swappable_first_key, reverse=True),
590             sorted(added_unmanaged_models, key=self.swappable_first_key, reverse=True),
591         )
592         for app_label, model_name in all_added_models:
593             model_state = self.to_state.models[app_label, model_name]
594             # Gather related fields
595             related_fields = {}
596             primary_key_rel = None
597             for field_name, field in model_state.fields.items():
598                 if field.remote_field:
599                     if field.remote_field.model:
600                         if field.primary_key:
601                             primary_key_rel = field.remote_field.model
602                         elif not field.remote_field.parent_link:
603                             related_fields[field_name] = field
604                     if getattr(field.remote_field, "through", None):
605                         related_fields[field_name] = field
606 
607             # Are there indexes/unique|index_together to defer?
608             indexes = model_state.options.pop("indexes")
609             constraints = model_state.options.pop("constraints")
610             unique_together = model_state.options.pop("unique_together", None)
611             index_together = model_state.options.pop("index_together", None)
612             order_with_respect_to = model_state.options.pop(
613                 "order_with_respect_to", None
614             )
615             # Depend on the deletion of any possible proxy version of us
616             dependencies = [
617                 (app_label, model_name, None, False),
618             ]
619             # Depend on all bases
620             for base in model_state.bases:
621                 if isinstance(base, str) and "." in base:
622                     base_app_label, base_name = base.split(".", 1)
623                     dependencies.append((base_app_label, base_name, None, True))
624                     # Depend on the removal of base fields if the new model has
625                     # a field with the same name.
626                     old_base_model_state = self.from_state.models.get(
627                         (base_app_label, base_name)
628                     )
629                     new_base_model_state = self.to_state.models.get(
630                         (base_app_label, base_name)
631                     )
632                     if old_base_model_state and new_base_model_state:
633                         removed_base_fields = (
634                             set(old_base_model_state.fields)
635                             .difference(
636                                 new_base_model_state.fields,
637                             )
638                             .intersection(model_state.fields)
639                         )
640                         for removed_base_field in removed_base_fields:
641                             dependencies.append(
642                                 (base_app_label, base_name, removed_base_field, False)
643                             )
644             # Depend on the other end of the primary key if it's a relation
645             if primary_key_rel:
646                 dependencies.append(
647                     resolve_relation(
648                         primary_key_rel,
649                         app_label,
650                         model_name,
651                     )
652                     + (None, True)
653                 )
654             # Generate creation operation
655             self.add_operation(
656                 app_label,
657                 operations.CreateModel(
658                     name=model_state.name,
659                     fields=[
660                         d
661                         for d in model_state.fields.items()
662                         if d[0] not in related_fields
663                     ],
664                     options=model_state.options,
665                     bases=model_state.bases,
666                     managers=model_state.managers,
667                 ),
668                 dependencies=dependencies,
669                 beginning=True,
670             )
671 
672             # Don't add operations which modify the database for unmanaged models
673             if not model_state.options.get("managed", True):
674                 continue
675 
676             # Generate operations for each related field
677             for name, field in sorted(related_fields.items()):
678                 dependencies = self._get_dependencies_for_foreign_key(
679                     app_label,
680                     model_name,
681                     field,
682                     self.to_state,
683                 )
684                 # Depend on our own model being created
685                 dependencies.append((app_label, model_name, None, True))
686                 # Make operation
687                 self.add_operation(
688                     app_label,
689                     operations.AddField(
690                         model_name=model_name,
691                         name=name,
692                         field=field,
693                     ),
694                     dependencies=list(set(dependencies)),
695                 )
696             # Generate other opns
697             if order_with_respect_to:
698                 self.add_operation(
699                     app_label,
700                     operations.AlterOrderWithRespectTo(
701                         name=model_name,
702                         order_with_respect_to=order_with_respect_to,
703                     ),
704                     dependencies=[
705                         (app_label, model_name, order_with_respect_to, True),
706                         (app_label, model_name, None, True),
707                     ],
708                 )
709             related_dependencies = [
710                 (app_label, model_name, name, True) for name in sorted(related_fields)
711             ]
712             related_dependencies.append((app_label, model_name, None, True))
713             for index in indexes:
714                 self.add_operation(
715                     app_label,
716                     operations.AddIndex(
717                         model_name=model_name,
718                         index=index,
719                     ),
720                     dependencies=related_dependencies,
721                 )
722             for constraint in constraints:
723                 self.add_operation(
724                     app_label,
725                     operations.AddConstraint(
726                         model_name=model_name,
727                         constraint=constraint,
728                     ),
729                     dependencies=related_dependencies,
730                 )
731             if unique_together:
732                 self.add_operation(
733                     app_label,
734                     operations.AlterUniqueTogether(
735                         name=model_name,
736                         unique_together=unique_together,
737                     ),
738                     dependencies=related_dependencies,
739                 )
740             if index_together:
741                 self.add_operation(
742                     app_label,
743                     operations.AlterIndexTogether(
744                         name=model_name,
745                         index_together=index_together,
746                     ),
747                     dependencies=related_dependencies,
748                 )
749             # Fix relationships if the model changed from a proxy model to a
750             # concrete model.
751             relations = self.to_state.relations
752             if (app_label, model_name) in self.old_proxy_keys:
753                 for related_model_key, related_fields in relations[
754                     app_label, model_name
755                 ].items():
756                     related_model_state = self.to_state.models[related_model_key]
757                     for related_field_name, related_field in related_fields.items():
758                         self.add_operation(
759                             related_model_state.app_label,
760                             operations.AlterField(
761                                 model_name=related_model_state.name,
762                                 name=related_field_name,
763                                 field=related_field,
764                             ),
765                             dependencies=[(app_label, model_name, None, True)],
766                         )
767 
768     def generate_created_proxies(self):
769         """
770         Make CreateModel statements for proxy models. Use the same statements
771         as that way there's less code duplication, but for proxy models it's
772         safe to skip all the pointless field stuff and chuck out an operation.
773         """
774         added = self.new_proxy_keys - self.old_proxy_keys
775         for app_label, model_name in sorted(added):
776             model_state = self.to_state.models[app_label, model_name]
777             assert model_state.options.get("proxy")
778             # Depend on the deletion of any possible non-proxy version of us
779             dependencies = [
780                 (app_label, model_name, None, False),
781             ]
782             # Depend on all bases
783             for base in model_state.bases:
784                 if isinstance(base, str) and "." in base:
785                     base_app_label, base_name = base.split(".", 1)
786                     dependencies.append((base_app_label, base_name, None, True))
787             # Generate creation operation
788             self.add_operation(
789                 app_label,
790                 operations.CreateModel(
791                     name=model_state.name,
792                     fields=[],
793                     options=model_state.options,
794                     bases=model_state.bases,
795                     managers=model_state.managers,
796                 ),
797                 # Depend on the deletion of any possible non-proxy version of us
798                 dependencies=dependencies,
799             )
800 
801     def generate_deleted_models(self):
802         """
803         Find all deleted models (managed and unmanaged) and make delete
804         operations for them as well as separate operations to delete any
805         foreign key or M2M relationships (these are optimized later, if
806         possible).
807 
808         Also bring forward removal of any model options that refer to
809         collections of fields - the inverse of generate_created_models().
810         """
811         new_keys = self.new_model_keys | self.new_unmanaged_keys
812         deleted_models = self.old_model_keys - new_keys
813         deleted_unmanaged_models = self.old_unmanaged_keys - new_keys
814         all_deleted_models = chain(
815             sorted(deleted_models), sorted(deleted_unmanaged_models)
816         )
817         for app_label, model_name in all_deleted_models:
818             model_state = self.from_state.models[app_label, model_name]
819             # Gather related fields
820             related_fields = {}
821             for field_name, field in model_state.fields.items():
822                 if field.remote_field:
823                     if field.remote_field.model:
824                         related_fields[field_name] = field
825                     if getattr(field.remote_field, "through", None):
826                         related_fields[field_name] = field
827             # Generate option removal first
828             unique_together = model_state.options.pop("unique_together", None)
829             index_together = model_state.options.pop("index_together", None)
830             if unique_together:
831                 self.add_operation(
832                     app_label,
833                     operations.AlterUniqueTogether(
834                         name=model_name,
835                         unique_together=None,
836                     ),
837                 )
838             if index_together:
839                 self.add_operation(
840                     app_label,
841                     operations.AlterIndexTogether(
842                         name=model_name,
843                         index_together=None,
844                     ),
845                 )
846             # Then remove each related field
847             for name in sorted(related_fields):
848                 self.add_operation(
849                     app_label,
850                     operations.RemoveField(
851                         model_name=model_name,
852                         name=name,
853                     ),
854                 )
855             # Finally, remove the model.
856             # This depends on both the removal/alteration of all incoming fields
857             # and the removal of all its own related fields, and if it's
858             # a through model the field that references it.
859             dependencies = []
860             relations = self.from_state.relations
861             for (
862                 related_object_app_label,
863                 object_name,
864             ), relation_related_fields in relations[app_label, model_name].items():
865                 for field_name, field in relation_related_fields.items():
866                     dependencies.append(
867                         (related_object_app_label, object_name, field_name, False),
868                     )
869                     if not field.many_to_many:
870                         dependencies.append(
871                             (
872                                 related_object_app_label,
873                                 object_name,
874                                 field_name,
875                                 "alter",
876                             ),
877                         )
878 
879             for name in sorted(related_fields):
880                 dependencies.append((app_label, model_name, name, False))
881             # We're referenced in another field's through=
882             through_user = self.through_users.get((app_label, model_state.name_lower))
883             if through_user:
884                 dependencies.append(
885                     (through_user[0], through_user[1], through_user[2], False)
886                 )
887             # Finally, make the operation, deduping any dependencies
888             self.add_operation(
889                 app_label,
890                 operations.DeleteModel(
891                     name=model_state.name,
892                 ),
893                 dependencies=list(set(dependencies)),
894             )
895 
896     def generate_deleted_proxies(self):
897         """Make DeleteModel options for proxy models."""
898         deleted = self.old_proxy_keys - self.new_proxy_keys
899         for app_label, model_name in sorted(deleted):
900             model_state = self.from_state.models[app_label, model_name]
901             assert model_state.options.get("proxy")
902             self.add_operation(
903                 app_label,
904                 operations.DeleteModel(
905                     name=model_state.name,
906                 ),
907             )
908 
909     def generate_renamed_fields(self):
910         """Work out renamed fields."""
911         self.renamed_fields = {}
912         for app_label, model_name, field_name in sorted(
913             self.new_field_keys - self.old_field_keys
914         ):
915             old_model_name = self.renamed_models.get(
916                 (app_label, model_name), model_name
917             )
918             old_model_state = self.from_state.models[app_label, old_model_name]
919             new_model_state = self.to_state.models[app_label, model_name]
920             field = new_model_state.get_field(field_name)
921             # Scan to see if this is actually a rename!
922             field_dec = self.deep_deconstruct(field)
923             for rem_app_label, rem_model_name, rem_field_name in sorted(
924                 self.old_field_keys - self.new_field_keys
925             ):
926                 if rem_app_label == app_label and rem_model_name == model_name:
927                     old_field = old_model_state.get_field(rem_field_name)
928                     old_field_dec = self.deep_deconstruct(old_field)
929                     if (
930                         field.remote_field
931                         and field.remote_field.model
932                         and "to" in old_field_dec[2]
933                     ):
934                         old_rel_to = old_field_dec[2]["to"]
935                         if old_rel_to in self.renamed_models_rel:
936                             old_field_dec[2]["to"] = self.renamed_models_rel[old_rel_to]
937                     old_field.set_attributes_from_name(rem_field_name)
938                     old_db_column = old_field.get_attname_column()[1]
939                     if old_field_dec == field_dec or (
940                         # Was the field renamed and db_column equal to the
941                         # old field's column added?
942                         old_field_dec[0:2] == field_dec[0:2]
943                         and dict(old_field_dec[2], db_column=old_db_column)
944                         == field_dec[2]
945                     ):
946                         if self.questioner.ask_rename(
947                             model_name, rem_field_name, field_name, field
948                         ):
949                             # A db_column mismatch requires a prior noop
950                             # AlterField for the subsequent RenameField to be a
951                             # noop on attempts at preserving the old name.
952                             if old_field.db_column != field.db_column:
953                                 altered_field = field.clone()
954                                 altered_field.name = rem_field_name
955                                 self.add_operation(
956                                     app_label,
957                                     operations.AlterField(
958                                         model_name=model_name,
959                                         name=rem_field_name,
960                                         field=altered_field,
961                                     ),
962                                 )
963                             self.add_operation(
964                                 app_label,
965                                 operations.RenameField(
966                                     model_name=model_name,
967                                     old_name=rem_field_name,
968                                     new_name=field_name,
969                                 ),
970                             )
971                             self.old_field_keys.remove(
972                                 (rem_app_label, rem_model_name, rem_field_name)
973                             )
974                             self.old_field_keys.add((app_label, model_name, field_name))
975                             self.renamed_fields[
976                                 app_label, model_name, field_name
977                             ] = rem_field_name
978                             break
979 
980     def generate_added_fields(self):
981         """Make AddField operations."""
982         for app_label, model_name, field_name in sorted(
983             self.new_field_keys - self.old_field_keys
984         ):
985             self._generate_added_field(app_label, model_name, field_name)
986 
987     def _generate_added_field(self, app_label, model_name, field_name):
988         field = self.to_state.models[app_label, model_name].get_field(field_name)
989         # Fields that are foreignkeys/m2ms depend on stuff
990         dependencies = []
991         if field.remote_field and field.remote_field.model:
992             dependencies.extend(
993                 self._get_dependencies_for_foreign_key(
994                     app_label,
995                     model_name,
996                     field,
997                     self.to_state,
998                 )
999             )
1000         # You can't just add NOT NULL fields with no default or fields
1001         # which don't allow empty strings as default.
1002         time_fields = (models.DateField, models.DateTimeField, models.TimeField)
1003         preserve_default = (
1004             field.null
1005             or field.has_default()
1006             or field.many_to_many
1007             or (field.blank and field.empty_strings_allowed)
1008             or (isinstance(field, time_fields) and field.auto_now)
1009         )
1010         if not preserve_default:
1011             field = field.clone()
1012             if isinstance(field, time_fields) and field.auto_now_add:
1013                 field.default = self.questioner.ask_auto_now_add_addition(
1014                     field_name, model_name
1015                 )
1016             else:
1017                 field.default = self.questioner.ask_not_null_addition(
1018                     field_name, model_name
1019                 )
1020         if (
1021             field.unique
1022             and field.default is not models.NOT_PROVIDED
1023             and callable(field.default)
1024         ):
1025             self.questioner.ask_unique_callable_default_addition(field_name, model_name)
1026         self.add_operation(
1027             app_label,
1028             operations.AddField(
1029                 model_name=model_name,
1030                 name=field_name,
1031                 field=field,
1032                 preserve_default=preserve_default,
1033             ),
1034             dependencies=dependencies,
1035         )
1036 
1037     def generate_removed_fields(self):
1038         """Make RemoveField operations."""
1039         for app_label, model_name, field_name in sorted(
1040             self.old_field_keys - self.new_field_keys
1041         ):
1042             self._generate_removed_field(app_label, model_name, field_name)
1043 
1044     def _generate_removed_field(self, app_label, model_name, field_name):
1045         self.add_operation(
1046             app_label,
1047             operations.RemoveField(
1048                 model_name=model_name,
1049                 name=field_name,
1050             ),
1051             # We might need to depend on the removal of an
1052             # order_with_respect_to or index/unique_together operation;
1053             # this is safely ignored if there isn't one
1054             dependencies=[
1055                 (app_label, model_name, field_name, "order_wrt_unset"),
1056                 (app_label, model_name, field_name, "foo_together_change"),
1057             ],
1058         )
1059 
1060     def generate_altered_fields(self):
1061         """
1062         Make AlterField operations, or possibly RemovedField/AddField if alter
1063         isn't possible.
1064         """
1065         for app_label, model_name, field_name in sorted(
1066             self.old_field_keys & self.new_field_keys
1067         ):
1068             # Did the field change?
1069             old_model_name = self.renamed_models.get(
1070                 (app_label, model_name), model_name
1071             )
1072             old_field_name = self.renamed_fields.get(
1073                 (app_label, model_name, field_name), field_name
1074             )
1075             old_field = self.from_state.models[app_label, old_model_name].get_field(
1076                 old_field_name
1077             )
1078             new_field = self.to_state.models[app_label, model_name].get_field(
1079                 field_name
1080             )
1081             dependencies = []
1082             # Implement any model renames on relations; these are handled by RenameModel
1083             # so we need to exclude them from the comparison
1084             if hasattr(new_field, "remote_field") and getattr(
1085                 new_field.remote_field, "model", None
1086             ):
1087                 rename_key = resolve_relation(
1088                     new_field.remote_field.model, app_label, model_name
1089                 )
1090                 if rename_key in self.renamed_models:
1091                     new_field.remote_field.model = old_field.remote_field.model
1092                 # Handle ForeignKey which can only have a single to_field.
1093                 remote_field_name = getattr(new_field.remote_field, "field_name", None)
1094                 if remote_field_name:
1095                     to_field_rename_key = rename_key + (remote_field_name,)
1096                     if to_field_rename_key in self.renamed_fields:
1097                         # Repoint both model and field name because to_field
1098                         # inclusion in ForeignKey.deconstruct() is based on
1099                         # both.
1100                         new_field.remote_field.model = old_field.remote_field.model
1101                         new_field.remote_field.field_name = (
1102                             old_field.remote_field.field_name
1103                         )
1104                 # Handle ForeignObjects which can have multiple from_fields/to_fields.
1105                 from_fields = getattr(new_field, "from_fields", None)
1106                 if from_fields:
1107                     from_rename_key = (app_label, model_name)
1108                     new_field.from_fields = tuple(
1109                         [
1110                             self.renamed_fields.get(
1111                                 from_rename_key + (from_field,), from_field
1112                             )
1113                             for from_field in from_fields
1114                         ]
1115                     )
1116                     new_field.to_fields = tuple(
1117                         [
1118                             self.renamed_fields.get(rename_key + (to_field,), to_field)
1119                             for to_field in new_field.to_fields
1120                         ]
1121                     )
1122                 dependencies.extend(
1123                     self._get_dependencies_for_foreign_key(
1124                         app_label,
1125                         model_name,
1126                         new_field,
1127                         self.to_state,
1128                     )
1129                 )
1130             if hasattr(new_field, "remote_field") and getattr(
1131                 new_field.remote_field, "through", None
1132             ):
1133                 rename_key = resolve_relation(
1134                     new_field.remote_field.through, app_label, model_name
1135                 )
1136                 if rename_key in self.renamed_models:
1137                     new_field.remote_field.through = old_field.remote_field.through
1138             old_field_dec = self.deep_deconstruct(old_field)
1139             new_field_dec = self.deep_deconstruct(new_field)
1140             # If the field was confirmed to be renamed it means that only
1141             # db_column was allowed to change which generate_renamed_fields()
1142             # already accounts for by adding an AlterField operation.
1143             if old_field_dec != new_field_dec and old_field_name == field_name:
1144                 both_m2m = old_field.many_to_many and new_field.many_to_many
1145                 neither_m2m = not old_field.many_to_many and not new_field.many_to_many
1146                 if both_m2m or neither_m2m:
1147                     # Either both fields are m2m or neither is
1148                     preserve_default = True
1149                     if (
1150                         old_field.null
1151                         and not new_field.null
1152                         and not new_field.has_default()
1153                         and not new_field.many_to_many
1154                     ):
1155                         field = new_field.clone()
1156                         new_default = self.questioner.ask_not_null_alteration(
1157                             field_name, model_name
1158                         )
1159                         if new_default is not models.NOT_PROVIDED:
1160                             field.default = new_default
1161                             preserve_default = False
1162                     else:
1163                         field = new_field
1164                     self.add_operation(
1165                         app_label,
1166                         operations.AlterField(
1167                             model_name=model_name,
1168                             name=field_name,
1169                             field=field,
1170                             preserve_default=preserve_default,
1171                         ),
1172                         dependencies=dependencies,
1173                     )
1174                 else:
1175                     # We cannot alter between m2m and concrete fields
1176                     self._generate_removed_field(app_label, model_name, field_name)
1177                     self._generate_added_field(app_label, model_name, field_name)
1178 
1179     def create_altered_indexes(self):
1180         option_name = operations.AddIndex.option_name
1181         for app_label, model_name in sorted(self.kept_model_keys):
1182             old_model_name = self.renamed_models.get(
1183                 (app_label, model_name), model_name
1184             )
1185             old_model_state = self.from_state.models[app_label, old_model_name]
1186             new_model_state = self.to_state.models[app_label, model_name]
1187 
1188             old_indexes = old_model_state.options[option_name]
1189             new_indexes = new_model_state.options[option_name]
1190             add_idx = [idx for idx in new_indexes if idx not in old_indexes]
1191             rem_idx = [idx for idx in old_indexes if idx not in new_indexes]
1192 
1193             self.altered_indexes.update(
1194                 {
1195                     (app_label, model_name): {
1196                         "added_indexes": add_idx,
1197                         "removed_indexes": rem_idx,
1198                     }
1199                 }
1200             )
1201 
1202     def generate_added_indexes(self):
1203         for (app_label, model_name), alt_indexes in self.altered_indexes.items():
1204             for index in alt_indexes["added_indexes"]:
1205                 self.add_operation(
1206                     app_label,
1207                     operations.AddIndex(
1208                         model_name=model_name,
1209                         index=index,
1210                     ),
1211                 )
1212 
1213     def generate_removed_indexes(self):
1214         for (app_label, model_name), alt_indexes in self.altered_indexes.items():
1215             for index in alt_indexes["removed_indexes"]:
1216                 self.add_operation(
1217                     app_label,
1218                     operations.RemoveIndex(
1219                         model_name=model_name,
1220                         name=index.name,
1221                     ),
1222                 )
1223 
1224     def create_altered_constraints(self):
1225         option_name = operations.AddConstraint.option_name
1226         for app_label, model_name in sorted(self.kept_model_keys):
1227             old_model_name = self.renamed_models.get(
1228                 (app_label, model_name), model_name
1229             )
1230             old_model_state = self.from_state.models[app_label, old_model_name]
1231             new_model_state = self.to_state.models[app_label, model_name]
1232 
1233             old_constraints = old_model_state.options[option_name]
1234             new_constraints = new_model_state.options[option_name]
1235             add_constraints = [c for c in new_constraints if c not in old_constraints]
1236             rem_constraints = [c for c in old_constraints if c not in new_constraints]
1237 
1238             self.altered_constraints.update(
1239                 {
1240                     (app_label, model_name): {
1241                         "added_constraints": add_constraints,
1242                         "removed_constraints": rem_constraints,
1243                     }
1244                 }
1245             )
1246 
1247     def generate_added_constraints(self):
1248         for (
1249             app_label,
1250             model_name,
1251         ), alt_constraints in self.altered_constraints.items():
1252             for constraint in alt_constraints["added_constraints"]:
1253                 self.add_operation(
1254                     app_label,
1255                     operations.AddConstraint(
1256                         model_name=model_name,
1257                         constraint=constraint,
1258                     ),
1259                 )
1260 
1261     def generate_removed_constraints(self):
1262         for (
1263             app_label,
1264             model_name,
1265         ), alt_constraints in self.altered_constraints.items():
1266             for constraint in alt_constraints["removed_constraints"]:
1267                 self.add_operation(
1268                     app_label,
1269                     operations.RemoveConstraint(
1270                         model_name=model_name,
1271                         name=constraint.name,
1272                     ),
1273                 )
1274 
1275     @staticmethod
1276     def _get_dependencies_for_foreign_key(app_label, model_name, field, project_state):
1277         remote_field_model = None
1278         if hasattr(field.remote_field, "model"):
1279             remote_field_model = field.remote_field.model
1280         else:
1281             relations = project_state.relations[app_label, model_name]
1282             for (remote_app_label, remote_model_name), fields in relations.items():
1283                 if any(
1284                     field == related_field.remote_field
1285                     for related_field in fields.values()
1286                 ):
1287                     remote_field_model = f"{remote_app_label}.{remote_model_name}"
1288                     break
1289         # Account for FKs to swappable models
1290         swappable_setting = getattr(field, "swappable_setting", None)
1291         if swappable_setting is not None:
1292             dep_app_label = "__setting__"
1293             dep_object_name = swappable_setting
1294         else:
1295             dep_app_label, dep_object_name = resolve_relation(
1296                 remote_field_model,
1297                 app_label,
1298                 model_name,
1299             )
1300         dependencies = [(dep_app_label, dep_object_name, None, True)]
1301         if getattr(field.remote_field, "through", None):
1302             through_app_label, through_object_name = resolve_relation(
1303                 remote_field_model,
1304                 app_label,
1305                 model_name,
1306             )
1307             dependencies.append((through_app_label, through_object_name, None, True))
1308         return dependencies
1309 
1310     def _get_altered_foo_together_operations(self, option_name):
1311         for app_label, model_name in sorted(self.kept_model_keys):
1312             old_model_name = self.renamed_models.get(
1313                 (app_label, model_name), model_name
1314             )
1315             old_model_state = self.from_state.models[app_label, old_model_name]
1316             new_model_state = self.to_state.models[app_label, model_name]
1317 
1318             # We run the old version through the field renames to account for those
1319             old_value = old_model_state.options.get(option_name)
1320             old_value = (
1321                 {
1322                     tuple(
1323                         self.renamed_fields.get((app_label, model_name, n), n)
1324                         for n in unique
1325                     )
1326                     for unique in old_value
1327                 }
1328                 if old_value
1329                 else set()
1330             )
1331 
1332             new_value = new_model_state.options.get(option_name)
1333             new_value = set(new_value) if new_value else set()
1334 
1335             if old_value != new_value:
1336                 dependencies = []
1337                 for foo_togethers in new_value:
1338                     for field_name in foo_togethers:
1339                         field = new_model_state.get_field(field_name)
1340                         if field.remote_field and field.remote_field.model:
1341                             dependencies.extend(
1342                                 self._get_dependencies_for_foreign_key(
1343                                     app_label,
1344                                     model_name,
1345                                     field,
1346                                     self.to_state,
1347                                 )
1348                             )
1349                 yield (
1350                     old_value,
1351                     new_value,
1352                     app_label,
1353                     model_name,
1354                     dependencies,
1355                 )
1356 
1357     def _generate_removed_altered_foo_together(self, operation):
1358         for (
1359             old_value,
1360             new_value,
1361             app_label,
1362             model_name,
1363             dependencies,
1364         ) in self._get_altered_foo_together_operations(operation.option_name):
1365             removal_value = new_value.intersection(old_value)
1366             if removal_value or old_value:
1367                 self.add_operation(
1368                     app_label,
1369                     operation(
1370                         name=model_name, **{operation.option_name: removal_value}
1371                     ),
1372                     dependencies=dependencies,
1373                 )
1374 
1375     def generate_removed_altered_unique_together(self):
1376         self._generate_removed_altered_foo_together(operations.AlterUniqueTogether)
1377 
1378     def generate_removed_altered_index_together(self):
1379         self._generate_removed_altered_foo_together(operations.AlterIndexTogether)
1380 
1381     def _generate_altered_foo_together(self, operation):
1382         for (
1383             old_value,
1384             new_value,
1385             app_label,
1386             model_name,
1387             dependencies,
1388         ) in self._get_altered_foo_together_operations(operation.option_name):
1389             removal_value = new_value.intersection(old_value)
1390             if new_value != removal_value:
1391                 self.add_operation(
1392                     app_label,
1393                     operation(name=model_name, **{operation.option_name: new_value}),
1394                     dependencies=dependencies,
1395                 )
1396 
1397     def generate_altered_unique_together(self):
1398         self._generate_altered_foo_together(operations.AlterUniqueTogether)
1399 
1400     def generate_altered_index_together(self):
1401         self._generate_altered_foo_together(operations.AlterIndexTogether)
1402 
1403     def generate_altered_db_table(self):
1404         models_to_check = self.kept_model_keys.union(
1405             self.kept_proxy_keys, self.kept_unmanaged_keys
1406         )
1407         for app_label, model_name in sorted(models_to_check):
1408             old_model_name = self.renamed_models.get(
1409                 (app_label, model_name), model_name
1410             )
1411             old_model_state = self.from_state.models[app_label, old_model_name]
1412             new_model_state = self.to_state.models[app_label, model_name]
1413             old_db_table_name = old_model_state.options.get("db_table")
1414             new_db_table_name = new_model_state.options.get("db_table")
1415             if old_db_table_name != new_db_table_name:
1416                 self.add_operation(
1417                     app_label,
1418                     operations.AlterModelTable(
1419                         name=model_name,
1420                         table=new_db_table_name,
1421                     ),
1422                 )
1423 
1424     def generate_altered_options(self):
1425         """
1426         Work out if any non-schema-affecting options have changed and make an
1427         operation to represent them in state changes (in case Python code in
1428         migrations needs them).
1429         """
1430         models_to_check = self.kept_model_keys.union(
1431             self.kept_proxy_keys,
1432             self.kept_unmanaged_keys,
1433             # unmanaged converted to managed
1434             self.old_unmanaged_keys & self.new_model_keys,
1435             # managed converted to unmanaged
1436             self.old_model_keys & self.new_unmanaged_keys,
1437         )
1438 
1439         for app_label, model_name in sorted(models_to_check):
1440             old_model_name = self.renamed_models.get(
1441                 (app_label, model_name), model_name
1442             )
1443             old_model_state = self.from_state.models[app_label, old_model_name]
1444             new_model_state = self.to_state.models[app_label, model_name]
1445             old_options = {
1446                 key: value
1447                 for key, value in old_model_state.options.items()
1448                 if key in AlterModelOptions.ALTER_OPTION_KEYS
1449             }
1450             new_options = {
1451                 key: value
1452                 for key, value in new_model_state.options.items()
1453                 if key in AlterModelOptions.ALTER_OPTION_KEYS
1454             }
1455             if old_options != new_options:
1456                 self.add_operation(
1457                     app_label,
1458                     operations.AlterModelOptions(
1459                         name=model_name,
1460                         options=new_options,
1461                     ),
1462                 )
1463 
1464     def generate_altered_order_with_respect_to(self):
1465         for app_label, model_name in sorted(self.kept_model_keys):
1466             old_model_name = self.renamed_models.get(
1467                 (app_label, model_name), model_name
1468             )
1469             old_model_state = self.from_state.models[app_label, old_model_name]
1470             new_model_state = self.to_state.models[app_label, model_name]
1471             if old_model_state.options.get(
1472                 "order_with_respect_to"
1473             ) != new_model_state.options.get("order_with_respect_to"):
1474                 # Make sure it comes second if we're adding
1475                 # (removal dependency is part of RemoveField)
1476                 dependencies = []
1477                 if new_model_state.options.get("order_with_respect_to"):
1478                     dependencies.append(
1479                         (
1480                             app_label,
1481                             model_name,
1482                             new_model_state.options["order_with_respect_to"],
1483                             True,
1484                         )
1485                     )
1486                 # Actually generate the operation
1487                 self.add_operation(
1488                     app_label,
1489                     operations.AlterOrderWithRespectTo(
1490                         name=model_name,
1491                         order_with_respect_to=new_model_state.options.get(
1492                             "order_with_respect_to"
1493                         ),
1494                     ),
1495                     dependencies=dependencies,
1496                 )
1497 
1498     def generate_altered_managers(self):
1499         for app_label, model_name in sorted(self.kept_model_keys):
1500             old_model_name = self.renamed_models.get(
1501                 (app_label, model_name), model_name
1502             )
1503             old_model_state = self.from_state.models[app_label, old_model_name]
1504             new_model_state = self.to_state.models[app_label, model_name]
1505             if old_model_state.managers != new_model_state.managers:
1506                 self.add_operation(
1507                     app_label,
1508                     operations.AlterModelManagers(
1509                         name=model_name,
1510                         managers=new_model_state.managers,
1511                     ),
1512                 )
1513 
1514     def arrange_for_graph(self, changes, graph, migration_name=None):
1515         """
1516         Take a result from changes() and a MigrationGraph, and fix the names
1517         and dependencies of the changes so they extend the graph from the leaf
1518         nodes for each app.
1519         """
1520         leaves = graph.leaf_nodes()
1521         name_map = {}
1522         for app_label, migrations in list(changes.items()):
1523             if not migrations:
1524                 continue
1525             # Find the app label's current leaf node
1526             app_leaf = None
1527             for leaf in leaves:
1528                 if leaf[0] == app_label:
1529                     app_leaf = leaf
1530                     break
1531             # Do they want an initial migration for this app?
1532             if app_leaf is None and not self.questioner.ask_initial(app_label):
1533                 # They don't.
1534                 for migration in migrations:
1535                     name_map[(app_label, migration.name)] = (app_label, "__first__")
1536                 del changes[app_label]
1537                 continue
1538             # Work out the next number in the sequence
1539             if app_leaf is None:
1540                 next_number = 1
1541             else:
1542                 next_number = (self.parse_number(app_leaf[1]) or 0) + 1
1543             # Name each migration
1544             for i, migration in enumerate(migrations):
1545                 if i == 0 and app_leaf:
1546                     migration.dependencies.append(app_leaf)
1547                 new_name_parts = ["%04i" % next_number]
1548                 if migration_name:
1549                     new_name_parts.append(migration_name)
1550                 elif i == 0 and not app_leaf:
1551                     new_name_parts.append("initial")
1552                 else:
1553                     new_name_parts.append(migration.suggest_name()[:100])
1554                 new_name = "_".join(new_name_parts)
1555                 name_map[(app_label, migration.name)] = (app_label, new_name)
1556                 next_number += 1
1557                 migration.name = new_name
1558         # Now fix dependencies
1559         for migrations in changes.values():
1560             for migration in migrations:
1561                 migration.dependencies = [
1562                     name_map.get(d, d) for d in migration.dependencies
1563                 ]
1564         return changes
1565 
1566     def _trim_to_apps(self, changes, app_labels):
1567         """
1568         Take changes from arrange_for_graph() and set of app labels, and return
1569         a modified set of changes which trims out as many migrations that are
1570         not in app_labels as possible. Note that some other migrations may
1571         still be present as they may be required dependencies.
1572         """
1573         # Gather other app dependencies in a first pass
1574         app_dependencies = {}
1575         for app_label, migrations in changes.items():
1576             for migration in migrations:
1577                 for dep_app_label, name in migration.dependencies:
1578                     app_dependencies.setdefault(app_label, set()).add(dep_app_label)
1579         required_apps = set(app_labels)
1580         # Keep resolving till there's no change
1581         old_required_apps = None
1582         while old_required_apps != required_apps:
1583             old_required_apps = set(required_apps)
1584             required_apps.update(
1585                 *[app_dependencies.get(app_label, ()) for app_label in required_apps]
1586             )
1587         # Remove all migrations that aren't needed
1588         for app_label in list(changes):
1589             if app_label not in required_apps:
1590                 del changes[app_label]
1591         return changes
1592 
1593     @classmethod
1594     def parse_number(cls, name):
1595         """
1596         Given a migration name, try to extract a number from the beginning of
1597         it. For a squashed migration such as '0001_squashed_0004…', return the
1598         second number. If no number is found, return None.
1599         """
1600         if squashed_match := re.search(r".*_squashed_(\d+)", name):
1601             return int(squashed_match[1])
1602         match = re.match(r"^\d+", name)
1603         if match:
1604             return int(match[0])
1605         return None

</code><intended_behavior>Enhance the detection logic to identify if a field involved in a migration is a foreign key referencing a field with a specific `db_collation`. If so, the migration operation should include steps to apply the same `db_collation` to the foreign key column.</intended_behavior>, <file>django/db/models/fields/__init__.py</file>
<class>None</class>
<method>None</method>
<code>
1 import collections.abc
2 import copy
3 import datetime
4 import decimal
5 import math
6 import operator
7 import uuid
8 import warnings
9 from base64 import b64decode, b64encode
10 from functools import partialmethod, total_ordering
11 
12 from django import forms
13 from django.apps import apps
14 from django.conf import settings
15 from django.core import checks, exceptions, validators
16 from django.db import connection, connections, router
17 from django.db.models.constants import LOOKUP_SEP
18 from django.db.models.query_utils import DeferredAttribute, RegisterLookupMixin
19 from django.utils import timezone
20 from django.utils.datastructures import DictWrapper
21 from django.utils.dateparse import (
22     parse_date,
23     parse_datetime,
24     parse_duration,
25     parse_time,
26 )
27 from django.utils.duration import duration_microseconds, duration_string
28 from django.utils.functional import Promise, cached_property
29 from django.utils.ipv6 import clean_ipv6_address
30 from django.utils.itercompat import is_iterable
31 from django.utils.text import capfirst
32 from django.utils.translation import gettext_lazy as _
33 
34 __all__ = [
35     "AutoField",
36     "BLANK_CHOICE_DASH",
37     "BigAutoField",
38     "BigIntegerField",
39     "BinaryField",
40     "BooleanField",
41     "CharField",
42     "CommaSeparatedIntegerField",
43     "DateField",
44     "DateTimeField",
45     "DecimalField",
46     "DurationField",
47     "EmailField",
48     "Empty",
49     "Field",
50     "FilePathField",
51     "FloatField",
52     "GenericIPAddressField",
53     "IPAddressField",
54     "IntegerField",
55     "NOT_PROVIDED",
56     "NullBooleanField",
57     "PositiveBigIntegerField",
58     "PositiveIntegerField",
59     "PositiveSmallIntegerField",
60     "SlugField",
61     "SmallAutoField",
62     "SmallIntegerField",
63     "TextField",
64     "TimeField",
65     "URLField",
66     "UUIDField",
67 ]
68 
69 
70 class Empty:
71     pass
72 
73 
74 class NOT_PROVIDED:
75     pass
76 
77 
78 # The values to use for "blank" in SelectFields. Will be appended to the start
79 # of most "choices" lists.
80 BLANK_CHOICE_DASH = [("", "---------")]
81 
82 
83 def _load_field(app_label, model_name, field_name):
84     return apps.get_model(app_label, model_name)._meta.get_field(field_name)
85 
86 
87 # A guide to Field parameters:
88 #
89 #   * name:      The name of the field specified in the model.
90 #   * attname:   The attribute to use on the model object. This is the same as
91 #                "name", except in the case of ForeignKeys, where "_id" is
92 #                appended.
93 #   * db_column: The db_column specified in the model (or None).
94 #   * column:    The database column for this field. This is the same as
95 #                "attname", except if db_column is specified.
96 #
97 # Code that introspects values, or does other dynamic things, should use
98 # attname. For example, this gets the primary key value of object "obj":
99 #
100 #     getattr(obj, opts.pk.attname)
101 
102 
103 def _empty(of_cls):
104     new = Empty()
105     new.__class__ = of_cls
106     return new
107 
108 
109 def return_None():
110     return None
111 
112 
113 @total_ordering
114 class Field(RegisterLookupMixin):
115     """Base class for all field types"""
116 
117     # Designates whether empty strings fundamentally are allowed at the
118     # database level.
119     empty_strings_allowed = True
120     empty_values = list(validators.EMPTY_VALUES)
121 
122     # These track each time a Field instance is created. Used to retain order.
123     # The auto_creation_counter is used for fields that Django implicitly
124     # creates, creation_counter is used for all user-specified fields.
125     creation_counter = 0
126     auto_creation_counter = -1
127     default_validators = []  # Default set of validators
128     default_error_messages = {
129         "invalid_choice": _("Value %(value)r is not a valid choice."),
130         "null": _("This field cannot be null."),
131         "blank": _("This field cannot be blank."),
132         "unique": _("%(model_name)s with this %(field_label)s already exists."),
133         # Translators: The 'lookup_type' is one of 'date', 'year' or 'month'.
134         # Eg: "Title must be unique for pub_date year"
135         "unique_for_date": _(
136             "%(field_label)s must be unique for "
137             "%(date_field_label)s %(lookup_type)s."
138         ),
139     }
140     system_check_deprecated_details = None
141     system_check_removed_details = None
142 
143     # Attributes that don't affect a column definition.
144     # These attributes are ignored when altering the field.
145     non_db_attrs = (
146         "blank",
147         "choices",
148         "db_column",
149         "editable",
150         "error_messages",
151         "help_text",
152         "limit_choices_to",
153         # Database-level options are not supported, see #21961.
154         "on_delete",
155         "related_name",
156         "related_query_name",
157         "validators",
158         "verbose_name",
159     )
160 
161     # Field flags
162     hidden = False
163 
164     many_to_many = None
165     many_to_one = None
166     one_to_many = None
167     one_to_one = None
168     related_model = None
169 
170     descriptor_class = DeferredAttribute
171 
172     # Generic field type description, usually overridden by subclasses
173     def _description(self):
174         return _("Field of type: %(field_type)s") % {
175             "field_type": self.__class__.__name__
176         }
177 
178     description = property(_description)
179 
180     def __init__(
181         self,
182         verbose_name=None,
183         name=None,
184         primary_key=False,
185         max_length=None,
186         unique=False,
187         blank=False,
188         null=False,
189         db_index=False,
190         rel=None,
191         default=NOT_PROVIDED,
192         editable=True,
193         serialize=True,
194         unique_for_date=None,
195         unique_for_month=None,
196         unique_for_year=None,
197         choices=None,
198         help_text="",
199         db_column=None,
200         db_tablespace=None,
201         auto_created=False,
202         validators=(),
203         error_messages=None,
204     ):
205         self.name = name
206         self.verbose_name = verbose_name  # May be set by set_attributes_from_name
207         self._verbose_name = verbose_name  # Store original for deconstruction
208         self.primary_key = primary_key
209         self.max_length, self._unique = max_length, unique
210         self.blank, self.null = blank, null
211         self.remote_field = rel
212         self.is_relation = self.remote_field is not None
213         self.default = default
214         self.editable = editable
215         self.serialize = serialize
216         self.unique_for_date = unique_for_date
217         self.unique_for_month = unique_for_month
218         self.unique_for_year = unique_for_year
219         if isinstance(choices, collections.abc.Iterator):
220             choices = list(choices)
221         self.choices = choices
222         self.help_text = help_text
223         self.db_index = db_index
224         self.db_column = db_column
225         self._db_tablespace = db_tablespace
226         self.auto_created = auto_created
227 
228         # Adjust the appropriate creation counter, and save our local copy.
229         if auto_created:
230             self.creation_counter = Field.auto_creation_counter
231             Field.auto_creation_counter -= 1
232         else:
233             self.creation_counter = Field.creation_counter
234             Field.creation_counter += 1
235 
236         self._validators = list(validators)  # Store for deconstruction later
237 
238         self._error_messages = error_messages  # Store for deconstruction later
239 
240     def __str__(self):
241         """
242         Return "app_label.model_label.field_name" for fields attached to
243         models.
244         """
245         if not hasattr(self, "model"):
246             return super().__str__()
247         model = self.model
248         return "%s.%s" % (model._meta.label, self.name)
249 
250     def __repr__(self):
251         """Display the module, class, and name of the field."""
252         path = "%s.%s" % (self.__class__.__module__, self.__class__.__qualname__)
253         name = getattr(self, "name", None)
254         if name is not None:
255             return "<%s: %s>" % (path, name)
256         return "<%s>" % path
257 
258     def check(self, **kwargs):
259         return [
260             *self._check_field_name(),
261             *self._check_choices(),
262             *self._check_db_index(),
263             *self._check_null_allowed_for_primary_keys(),
264             *self._check_backend_specific_checks(**kwargs),
265             *self._check_validators(),
266             *self._check_deprecation_details(),
267         ]
268 
269     def _check_field_name(self):
270         """
271         Check if field name is valid, i.e. 1) does not end with an
272         underscore, 2) does not contain "__" and 3) is not "pk".
273         """
274         if self.name.endswith("_"):
275             return [
276                 checks.Error(
277                     "Field names must not end with an underscore.",
278                     obj=self,
279                     id="fields.E001",
280                 )
281             ]
282         elif LOOKUP_SEP in self.name:
283             return [
284                 checks.Error(
285                     'Field names must not contain "%s".' % LOOKUP_SEP,
286                     obj=self,
287                     id="fields.E002",
288                 )
289             ]
290         elif self.name == "pk":
291             return [
292                 checks.Error(
293                     "'pk' is a reserved word that cannot be used as a field name.",
294                     obj=self,
295                     id="fields.E003",
296                 )
297             ]
298         else:
299             return []
300 
301     @classmethod
302     def _choices_is_value(cls, value):
303         return isinstance(value, (str, Promise)) or not is_iterable(value)
304 
305     def _check_choices(self):
306         if not self.choices:
307             return []
308 
309         if not is_iterable(self.choices) or isinstance(self.choices, str):
310             return [
311                 checks.Error(
312                     "'choices' must be an iterable (e.g., a list or tuple).",
313                     obj=self,
314                     id="fields.E004",
315                 )
316             ]
317 
318         choice_max_length = 0
319         # Expect [group_name, [value, display]]
320         for choices_group in self.choices:
321             try:
322                 group_name, group_choices = choices_group
323             except (TypeError, ValueError):
324                 # Containing non-pairs
325                 break
326             try:
327                 if not all(
328                     self._choices_is_value(value) and self._choices_is_value(human_name)
329                     for value, human_name in group_choices
330                 ):
331                     break
332                 if self.max_length is not None and group_choices:
333                     choice_max_length = max(
334                         [
335                             choice_max_length,
336                             *(
337                                 len(value)
338                                 for value, _ in group_choices
339                                 if isinstance(value, str)
340                             ),
341                         ]
342                     )
343             except (TypeError, ValueError):
344                 # No groups, choices in the form [value, display]
345                 value, human_name = group_name, group_choices
346                 if not self._choices_is_value(value) or not self._choices_is_value(
347                     human_name
348                 ):
349                     break
350                 if self.max_length is not None and isinstance(value, str):
351                     choice_max_length = max(choice_max_length, len(value))
352 
353             # Special case: choices=['ab']
354             if isinstance(choices_group, str):
355                 break
356         else:
357             if self.max_length is not None and choice_max_length > self.max_length:
358                 return [
359                     checks.Error(
360                         "'max_length' is too small to fit the longest value "
361                         "in 'choices' (%d characters)." % choice_max_length,
362                         obj=self,
363                         id="fields.E009",
364                     ),
365                 ]
366             return []
367 
368         return [
369             checks.Error(
370                 "'choices' must be an iterable containing "
371                 "(actual value, human readable name) tuples.",
372                 obj=self,
373                 id="fields.E005",
374             )
375         ]
376 
377     def _check_db_index(self):
378         if self.db_index not in (None, True, False):
379             return [
380                 checks.Error(
381                     "'db_index' must be None, True or False.",
382                     obj=self,
383                     id="fields.E006",
384                 )
385             ]
386         else:
387             return []
388 
389     def _check_null_allowed_for_primary_keys(self):
390         if (
391             self.primary_key
392             and self.null
393             and not connection.features.interprets_empty_strings_as_nulls
394         ):
395             # We cannot reliably check this for backends like Oracle which
396             # consider NULL and '' to be equal (and thus set up
397             # character-based fields a little differently).
398             return [
399                 checks.Error(
400                     "Primary keys must not have null=True.",
401                     hint=(
402                         "Set null=False on the field, or "
403                         "remove primary_key=True argument."
404                     ),
405                     obj=self,
406                     id="fields.E007",
407                 )
408             ]
409         else:
410             return []
411 
412     def _check_backend_specific_checks(self, databases=None, **kwargs):
413         if databases is None:
414             return []
415         app_label = self.model._meta.app_label
416         errors = []
417         for alias in databases:
418             if router.allow_migrate(
419                 alias, app_label, model_name=self.model._meta.model_name
420             ):
421                 errors.extend(connections[alias].validation.check_field(self, **kwargs))
422         return errors
423 
424     def _check_validators(self):
425         errors = []
426         for i, validator in enumerate(self.validators):
427             if not callable(validator):
428                 errors.append(
429                     checks.Error(
430                         "All 'validators' must be callable.",
431                         hint=(
432                             "validators[{i}] ({repr}) isn't a function or "
433                             "instance of a validator class.".format(
434                                 i=i,
435                                 repr=repr(validator),
436                             )
437                         ),
438                         obj=self,
439                         id="fields.E008",
440                     )
441                 )
442         return errors
443 
444     def _check_deprecation_details(self):
445         if self.system_check_removed_details is not None:
446             return [
447                 checks.Error(
448                     self.system_check_removed_details.get(
449                         "msg",
450                         "%s has been removed except for support in historical "
451                         "migrations." % self.__class__.__name__,
452                     ),
453                     hint=self.system_check_removed_details.get("hint"),
454                     obj=self,
455                     id=self.system_check_removed_details.get("id", "fields.EXXX"),
456                 )
457             ]
458         elif self.system_check_deprecated_details is not None:
459             return [
460                 checks.Warning(
461                     self.system_check_deprecated_details.get(
462                         "msg", "%s has been deprecated." % self.__class__.__name__
463                     ),
464                     hint=self.system_check_deprecated_details.get("hint"),
465                     obj=self,
466                     id=self.system_check_deprecated_details.get("id", "fields.WXXX"),
467                 )
468             ]
469         return []
470 
471     def get_col(self, alias, output_field=None):
472         if alias == self.model._meta.db_table and (
473             output_field is None or output_field == self
474         ):
475             return self.cached_col
476         from django.db.models.expressions import Col
477 
478         return Col(alias, self, output_field)
479 
480     @cached_property
481     def cached_col(self):
482         from django.db.models.expressions import Col
483 
484         return Col(self.model._meta.db_table, self)
485 
486     def select_format(self, compiler, sql, params):
487         """
488         Custom format for select clauses. For example, GIS columns need to be
489         selected as AsText(table.col) on MySQL as the table.col data can't be
490         used by Django.
491         """
492         return sql, params
493 
494     def deconstruct(self):
495         """
496         Return enough information to recreate the field as a 4-tuple:
497 
498          * The name of the field on the model, if contribute_to_class() has
499            been run.
500          * The import path of the field, including the class, e.g.
501            django.db.models.IntegerField. This should be the most portable
502            version, so less specific may be better.
503          * A list of positional arguments.
504          * A dict of keyword arguments.
505 
506         Note that the positional or keyword arguments must contain values of
507         the following types (including inner values of collection types):
508 
509          * None, bool, str, int, float, complex, set, frozenset, list, tuple,
510            dict
511          * UUID
512          * datetime.datetime (naive), datetime.date
513          * top-level classes, top-level functions - will be referenced by their
514            full import path
515          * Storage instances - these have their own deconstruct() method
516 
517         This is because the values here must be serialized into a text format
518         (possibly new Python code, possibly JSON) and these are the only types
519         with encoding handlers defined.
520 
521         There's no need to return the exact way the field was instantiated this
522         time, just ensure that the resulting field is the same - prefer keyword
523         arguments over positional ones, and omit parameters with their default
524         values.
525         """
526         # Short-form way of fetching all the default parameters
527         keywords = {}
528         possibles = {
529             "verbose_name": None,
530             "primary_key": False,
531             "max_length": None,
532             "unique": False,
533             "blank": False,
534             "null": False,
535             "db_index": False,
536             "default": NOT_PROVIDED,
537             "editable": True,
538             "serialize": True,
539             "unique_for_date": None,
540             "unique_for_month": None,
541             "unique_for_year": None,
542             "choices": None,
543             "help_text": "",
544             "db_column": None,
545             "db_tablespace": None,
546             "auto_created": False,
547             "validators": [],
548             "error_messages": None,
549         }
550         attr_overrides = {
551             "unique": "_unique",
552             "error_messages": "_error_messages",
553             "validators": "_validators",
554             "verbose_name": "_verbose_name",
555             "db_tablespace": "_db_tablespace",
556         }
557         equals_comparison = {"choices", "validators"}
558         for name, default in possibles.items():
559             value = getattr(self, attr_overrides.get(name, name))
560             # Unroll anything iterable for choices into a concrete list
561             if name == "choices" and isinstance(value, collections.abc.Iterable):
562                 value = list(value)
563             # Do correct kind of comparison
564             if name in equals_comparison:
565                 if value != default:
566                     keywords[name] = value
567             else:
568                 if value is not default:
569                     keywords[name] = value
570         # Work out path - we shorten it for known Django core fields
571         path = "%s.%s" % (self.__class__.__module__, self.__class__.__qualname__)
572         if path.startswith("django.db.models.fields.related"):
573             path = path.replace("django.db.models.fields.related", "django.db.models")
574         elif path.startswith("django.db.models.fields.files"):
575             path = path.replace("django.db.models.fields.files", "django.db.models")
576         elif path.startswith("django.db.models.fields.json"):
577             path = path.replace("django.db.models.fields.json", "django.db.models")
578         elif path.startswith("django.db.models.fields.proxy"):
579             path = path.replace("django.db.models.fields.proxy", "django.db.models")
580         elif path.startswith("django.db.models.fields"):
581             path = path.replace("django.db.models.fields", "django.db.models")
582         # Return basic info - other fields should override this.
583         return (self.name, path, [], keywords)
584 
585     def clone(self):
586         """
587         Uses deconstruct() to clone a new copy of this Field.
588         Will not preserve any class attachments/attribute names.
589         """
590         name, path, args, kwargs = self.deconstruct()
591         return self.__class__(*args, **kwargs)
592 
593     def __eq__(self, other):
594         # Needed for @total_ordering
595         if isinstance(other, Field):
596             return self.creation_counter == other.creation_counter and getattr(
597                 self, "model", None
598             ) == getattr(other, "model", None)
599         return NotImplemented
600 
601     def __lt__(self, other):
602         # This is needed because bisect does not take a comparison function.
603         # Order by creation_counter first for backward compatibility.
604         if isinstance(other, Field):
605             if (
606                 self.creation_counter != other.creation_counter
607                 or not hasattr(self, "model")
608                 and not hasattr(other, "model")
609             ):
610                 return self.creation_counter < other.creation_counter
611             elif hasattr(self, "model") != hasattr(other, "model"):
612                 return not hasattr(self, "model")  # Order no-model fields first
613             else:
614                 # creation_counter's are equal, compare only models.
615                 return (self.model._meta.app_label, self.model._meta.model_name) < (
616                     other.model._meta.app_label,
617                     other.model._meta.model_name,
618                 )
619         return NotImplemented
620 
621     def __hash__(self):
622         return hash(self.creation_counter)
623 
624     def __deepcopy__(self, memodict):
625         # We don't have to deepcopy very much here, since most things are not
626         # intended to be altered after initial creation.
627         obj = copy.copy(self)
628         if self.remote_field:
629             obj.remote_field = copy.copy(self.remote_field)
630             if hasattr(self.remote_field, "field") and self.remote_field.field is self:
631                 obj.remote_field.field = obj
632         memodict[id(self)] = obj
633         return obj
634 
635     def __copy__(self):
636         # We need to avoid hitting __reduce__, so define this
637         # slightly weird copy construct.
638         obj = Empty()
639         obj.__class__ = self.__class__
640         obj.__dict__ = self.__dict__.copy()
641         return obj
642 
643     def __reduce__(self):
644         """
645         Pickling should return the model._meta.fields instance of the field,
646         not a new copy of that field. So, use the app registry to load the
647         model and then the field back.
648         """
649         if not hasattr(self, "model"):
650             # Fields are sometimes used without attaching them to models (for
651             # example in aggregation). In this case give back a plain field
652             # instance. The code below will create a new empty instance of
653             # class self.__class__, then update its dict with self.__dict__
654             # values - so, this is very close to normal pickle.
655             state = self.__dict__.copy()
656             # The _get_default cached_property can't be pickled due to lambda
657             # usage.
658             state.pop("_get_default", None)
659             return _empty, (self.__class__,), state
660         return _load_field, (
661             self.model._meta.app_label,
662             self.model._meta.object_name,
663             self.name,
664         )
665 
666     def get_pk_value_on_save(self, instance):
667         """
668         Hook to generate new PK values on save. This method is called when
669         saving instances with no primary key value set. If this method returns
670         something else than None, then the returned value is used when saving
671         the new instance.
672         """
673         if self.default:
674             return self.get_default()
675         return None
676 
677     def to_python(self, value):
678         """
679         Convert the input value into the expected Python data type, raising
680         django.core.exceptions.ValidationError if the data can't be converted.
681         Return the converted value. Subclasses should override this.
682         """
683         return value
684 
685     @cached_property
686     def error_messages(self):
687         messages = {}
688         for c in reversed(self.__class__.__mro__):
689             messages.update(getattr(c, "default_error_messages", {}))
690         messages.update(self._error_messages or {})
691         return messages
692 
693     @cached_property
694     def validators(self):
695         """
696         Some validators can't be created at field initialization time.
697         This method provides a way to delay their creation until required.
698         """
699         return [*self.default_validators, *self._validators]
700 
701     def run_validators(self, value):
702         if value in self.empty_values:
703             return
704 
705         errors = []
706         for v in self.validators:
707             try:
708                 v(value)
709             except exceptions.ValidationError as e:
710                 if hasattr(e, "code") and e.code in self.error_messages:
711                     e.message = self.error_messages[e.code]
712                 errors.extend(e.error_list)
713 
714         if errors:
715             raise exceptions.ValidationError(errors)
716 
717     def validate(self, value, model_instance):
718         """
719         Validate value and raise ValidationError if necessary. Subclasses
720         should override this to provide validation logic.
721         """
722         if not self.editable:
723             # Skip validation for non-editable fields.
724             return
725 
726         if self.choices is not None and value not in self.empty_values:
727             for option_key, option_value in self.choices:
728                 if isinstance(option_value, (list, tuple)):
729                     # This is an optgroup, so look inside the group for
730                     # options.
731                     for optgroup_key, optgroup_value in option_value:
732                         if value == optgroup_key:
733                             return
734                 elif value == option_key:
735                     return
736             raise exceptions.ValidationError(
737                 self.error_messages["invalid_choice"],
738                 code="invalid_choice",
739                 params={"value": value},
740             )
741 
742         if value is None and not self.null:
743             raise exceptions.ValidationError(self.error_messages["null"], code="null")
744 
745         if not self.blank and value in self.empty_values:
746             raise exceptions.ValidationError(self.error_messages["blank"], code="blank")
747 
748     def clean(self, value, model_instance):
749         """
750         Convert the value's type and run validation. Validation errors
751         from to_python() and validate() are propagated. Return the correct
752         value if no error is raised.
753         """
754         value = self.to_python(value)
755         self.validate(value, model_instance)
756         self.run_validators(value)
757         return value
758 
759     def db_type_parameters(self, connection):
760         return DictWrapper(self.__dict__, connection.ops.quote_name, "qn_")
761 
762     def db_check(self, connection):
763         """
764         Return the database column check constraint for this field, for the
765         provided connection. Works the same way as db_type() for the case that
766         get_internal_type() does not map to a preexisting model field.
767         """
768         data = self.db_type_parameters(connection)
769         try:
770             return (
771                 connection.data_type_check_constraints[self.get_internal_type()] % data
772             )
773         except KeyError:
774             return None
775 
776     def db_type(self, connection):
777         """
778         Return the database column data type for this field, for the provided
779         connection.
780         """
781         # The default implementation of this method looks at the
782         # backend-specific data_types dictionary, looking up the field by its
783         # "internal type".
784         #
785         # A Field class can implement the get_internal_type() method to specify
786         # which *preexisting* Django Field class it's most similar to -- i.e.,
787         # a custom field might be represented by a TEXT column type, which is
788         # the same as the TextField Django field type, which means the custom
789         # field's get_internal_type() returns 'TextField'.
790         #
791         # But the limitation of the get_internal_type() / data_types approach
792         # is that it cannot handle database column types that aren't already
793         # mapped to one of the built-in Django field types. In this case, you
794         # can implement db_type() instead of get_internal_type() to specify
795         # exactly which wacky database column type you want to use.
796         data = self.db_type_parameters(connection)
797         try:
798             return connection.data_types[self.get_internal_type()] % data
799         except KeyError:
800             return None
801 
802     def rel_db_type(self, connection):
803         """
804         Return the data type that a related field pointing to this field should
805         use. For example, this method is called by ForeignKey and OneToOneField
806         to determine its data type.
807         """
808         return self.db_type(connection)
809 
810     def cast_db_type(self, connection):
811         """Return the data type to use in the Cast() function."""
812         db_type = connection.ops.cast_data_types.get(self.get_internal_type())
813         if db_type:
814             return db_type % self.db_type_parameters(connection)
815         return self.db_type(connection)
816 
817     def db_parameters(self, connection):
818         """
819         Extension of db_type(), providing a range of different return values
820         (type, checks). This will look at db_type(), allowing custom model
821         fields to override it.
822         """
823         type_string = self.db_type(connection)
824         check_string = self.db_check(connection)
825         return {
826             "type": type_string,
827             "check": check_string,
828         }
829 
830     def db_type_suffix(self, connection):
831         return connection.data_types_suffix.get(self.get_internal_type())
832 
833     def get_db_converters(self, connection):
834         if hasattr(self, "from_db_value"):
835             return [self.from_db_value]
836         return []
837 
838     @property
839     def unique(self):
840         return self._unique or self.primary_key
841 
842     @property
843     def db_tablespace(self):
844         return self._db_tablespace or settings.DEFAULT_INDEX_TABLESPACE
845 
846     @property
847     def db_returning(self):
848         """
849         Private API intended only to be used by Django itself. Currently only
850         the PostgreSQL backend supports returning multiple fields on a model.
851         """
852         return False
853 
854     def set_attributes_from_name(self, name):
855         self.name = self.name or name
856         self.attname, self.column = self.get_attname_column()
857         self.concrete = self.column is not None
858         if self.verbose_name is None and self.name:
859             self.verbose_name = self.name.replace("_", " ")
860 
861     def contribute_to_class(self, cls, name, private_only=False):
862         """
863         Register the field with the model class it belongs to.
864 
865         If private_only is True, create a separate instance of this field
866         for every subclass of cls, even if cls is not an abstract model.
867         """
868         self.set_attributes_from_name(name)
869         self.model = cls
870         cls._meta.add_field(self, private=private_only)
871         if self.column:
872             setattr(cls, self.attname, self.descriptor_class(self))
873         if self.choices is not None:
874             # Don't override a get_FOO_display() method defined explicitly on
875             # this class, but don't check methods derived from inheritance, to
876             # allow overriding inherited choices. For more complex inheritance
877             # structures users should override contribute_to_class().
878             if "get_%s_display" % self.name not in cls.__dict__:
879                 setattr(
880                     cls,
881                     "get_%s_display" % self.name,
882                     partialmethod(cls._get_FIELD_display, field=self),
883                 )
884 
885     def get_filter_kwargs_for_object(self, obj):
886         """
887         Return a dict that when passed as kwargs to self.model.filter(), would
888         yield all instances having the same value for this field as obj has.
889         """
890         return {self.name: getattr(obj, self.attname)}
891 
892     def get_attname(self):
893         return self.name
894 
895     def get_attname_column(self):
896         attname = self.get_attname()
897         column = self.db_column or attname
898         return attname, column
899 
900     def get_internal_type(self):
901         return self.__class__.__name__
902 
903     def pre_save(self, model_instance, add):
904         """Return field's value just before saving."""
905         return getattr(model_instance, self.attname)
906 
907     def get_prep_value(self, value):
908         """Perform preliminary non-db specific value checks and conversions."""
909         if isinstance(value, Promise):
910             value = value._proxy____cast()
911         return value
912 
913     def get_db_prep_value(self, value, connection, prepared=False):
914         """
915         Return field's value prepared for interacting with the database backend.
916 
917         Used by the default implementations of get_db_prep_save().
918         """
919         if not prepared:
920             value = self.get_prep_value(value)
921         return value
922 
923     def get_db_prep_save(self, value, connection):
924         """Return field's value prepared for saving into a database."""
925         return self.get_db_prep_value(value, connection=connection, prepared=False)
926 
927     def has_default(self):
928         """Return a boolean of whether this field has a default value."""
929         return self.default is not NOT_PROVIDED
930 
931     def get_default(self):
932         """Return the default value for this field."""
933         return self._get_default()
934 
935     @cached_property
936     def _get_default(self):
937         if self.has_default():
938             if callable(self.default):
939                 return self.default
940             return lambda: self.default
941 
942         if (
943             not self.empty_strings_allowed
944             or self.null
945             and not connection.features.interprets_empty_strings_as_nulls
946         ):
947             return return_None
948         return str  # return empty string
949 
950     def get_choices(
951         self,
952         include_blank=True,
953         blank_choice=BLANK_CHOICE_DASH,
954         limit_choices_to=None,
955         ordering=(),
956     ):
957         """
958         Return choices with a default blank choices included, for use
959         as <select> choices for this field.
960         """
961         if self.choices is not None:
962             choices = list(self.choices)
963             if include_blank:
964                 blank_defined = any(
965                     choice in ("", None) for choice, _ in self.flatchoices
966                 )
967                 if not blank_defined:
968                     choices = blank_choice + choices
969             return choices
970         rel_model = self.remote_field.model
971         limit_choices_to = limit_choices_to or self.get_limit_choices_to()
972         choice_func = operator.attrgetter(
973             self.remote_field.get_related_field().attname
974             if hasattr(self.remote_field, "get_related_field")
975             else "pk"
976         )
977         qs = rel_model._default_manager.complex_filter(limit_choices_to)
978         if ordering:
979             qs = qs.order_by(*ordering)
980         return (blank_choice if include_blank else []) + [
981             (choice_func(x), str(x)) for x in qs
982         ]
983 
984     def value_to_string(self, obj):
985         """
986         Return a string value of this field from the passed obj.
987         This is used by the serialization framework.
988         """
989         return str(self.value_from_object(obj))
990 
991     def _get_flatchoices(self):
992         """Flattened version of choices tuple."""
993         if self.choices is None:
994             return []
995         flat = []
996         for choice, value in self.choices:
997             if isinstance(value, (list, tuple)):
998                 flat.extend(value)
999             else:
1000                 flat.append((choice, value))
1001         return flat
1002 
1003     flatchoices = property(_get_flatchoices)
1004 
1005     def save_form_data(self, instance, data):
1006         setattr(instance, self.name, data)
1007 
1008     def formfield(self, form_class=None, choices_form_class=None, **kwargs):
1009         """Return a django.forms.Field instance for this field."""
1010         defaults = {
1011             "required": not self.blank,
1012             "label": capfirst(self.verbose_name),
1013             "help_text": self.help_text,
1014         }
1015         if self.has_default():
1016             if callable(self.default):
1017                 defaults["initial"] = self.default
1018                 defaults["show_hidden_initial"] = True
1019             else:
1020                 defaults["initial"] = self.get_default()
1021         if self.choices is not None:
1022             # Fields with choices get special treatment.
1023             include_blank = self.blank or not (
1024                 self.has_default() or "initial" in kwargs
1025             )
1026             defaults["choices"] = self.get_choices(include_blank=include_blank)
1027             defaults["coerce"] = self.to_python
1028             if self.null:
1029                 defaults["empty_value"] = None
1030             if choices_form_class is not None:
1031                 form_class = choices_form_class
1032             else:
1033                 form_class = forms.TypedChoiceField
1034             # Many of the subclass-specific formfield arguments (min_value,
1035             # max_value) don't apply for choice fields, so be sure to only pass
1036             # the values that TypedChoiceField will understand.
1037             for k in list(kwargs):
1038                 if k not in (
1039                     "coerce",
1040                     "empty_value",
1041                     "choices",
1042                     "required",
1043                     "widget",
1044                     "label",
1045                     "initial",
1046                     "help_text",
1047                     "error_messages",
1048                     "show_hidden_initial",
1049                     "disabled",
1050                 ):
1051                     del kwargs[k]
1052         defaults.update(kwargs)
1053         if form_class is None:
1054             form_class = forms.CharField
1055         return form_class(**defaults)
1056 
1057     def value_from_object(self, obj):
1058         """Return the value of this field in the given model instance."""
1059         return getattr(obj, self.attname)
1060 
1061 
1062 class BooleanField(Field):
1063     empty_strings_allowed = False
1064     default_error_messages = {
1065         "invalid": _("“%(value)s” value must be either True or False."),
1066         "invalid_nullable": _("“%(value)s” value must be either True, False, or None."),
1067     }
1068     description = _("Boolean (Either True or False)")
1069 
1070     def get_internal_type(self):
1071         return "BooleanField"
1072 
1073     def to_python(self, value):
1074         if self.null and value in self.empty_values:
1075             return None
1076         if value in (True, False):
1077             # 1/0 are equal to True/False. bool() converts former to latter.
1078             return bool(value)
1079         if value in ("t", "True", "1"):
1080             return True
1081         if value in ("f", "False", "0"):
1082             return False
1083         raise exceptions.ValidationError(
1084             self.error_messages["invalid_nullable" if self.null else "invalid"],
1085             code="invalid",
1086             params={"value": value},
1087         )
1088 
1089     def get_prep_value(self, value):
1090         value = super().get_prep_value(value)
1091         if value is None:
1092             return None
1093         return self.to_python(value)
1094 
1095     def formfield(self, **kwargs):
1096         if self.choices is not None:
1097             include_blank = not (self.has_default() or "initial" in kwargs)
1098             defaults = {"choices": self.get_choices(include_blank=include_blank)}
1099         else:
1100             form_class = forms.NullBooleanField if self.null else forms.BooleanField
1101             # In HTML checkboxes, 'required' means "must be checked" which is
1102             # different from the choices case ("must select some value").
1103             # required=False allows unchecked checkboxes.
1104             defaults = {"form_class": form_class, "required": False}
1105         return super().formfield(**{**defaults, **kwargs})
1106 
1107     def select_format(self, compiler, sql, params):
1108         sql, params = super().select_format(compiler, sql, params)
1109         # Filters that match everything are handled as empty strings in the
1110         # WHERE clause, but in SELECT or GROUP BY list they must use a
1111         # predicate that's always True.
1112         if sql == "":
1113             sql = "1"
1114         return sql, params
1115 
1116 
1117 class CharField(Field):
1118     description = _("String (up to %(max_length)s)")
1119 
1120     def __init__(self, *args, db_collation=None, **kwargs):
1121         super().__init__(*args, **kwargs)
1122         self.db_collation = db_collation
1123         if self.max_length is not None:
1124             self.validators.append(validators.MaxLengthValidator(self.max_length))
1125 
1126     def check(self, **kwargs):
1127         databases = kwargs.get("databases") or []
1128         return [
1129             *super().check(**kwargs),
1130             *self._check_db_collation(databases),
1131             *self._check_max_length_attribute(**kwargs),
1132         ]
1133 
1134     def _check_max_length_attribute(self, **kwargs):
1135         if self.max_length is None:
1136             return [
1137                 checks.Error(
1138                     "CharFields must define a 'max_length' attribute.",
1139                     obj=self,
1140                     id="fields.E120",
1141                 )
1142             ]
1143         elif (
1144             not isinstance(self.max_length, int)
1145             or isinstance(self.max_length, bool)
1146             or self.max_length <= 0
1147         ):
1148             return [
1149                 checks.Error(
1150                     "'max_length' must be a positive integer.",
1151                     obj=self,
1152                     id="fields.E121",
1153                 )
1154             ]
1155         else:
1156             return []
1157 
1158     def _check_db_collation(self, databases):
1159         errors = []
1160         for db in databases:
1161             if not router.allow_migrate_model(db, self.model):
1162                 continue
1163             connection = connections[db]
1164             if not (
1165                 self.db_collation is None
1166                 or "supports_collation_on_charfield"
1167                 in self.model._meta.required_db_features
1168                 or connection.features.supports_collation_on_charfield
1169             ):
1170                 errors.append(
1171                     checks.Error(
1172                         "%s does not support a database collation on "
1173                         "CharFields." % connection.display_name,
1174                         obj=self,
1175                         id="fields.E190",
1176                     ),
1177                 )
1178         return errors
1179 
1180     def cast_db_type(self, connection):
1181         if self.max_length is None:
1182             return connection.ops.cast_char_field_without_max_length
1183         return super().cast_db_type(connection)
1184 
1185     def db_parameters(self, connection):
1186         db_params = super().db_parameters(connection)
1187         db_params["collation"] = self.db_collation
1188         return db_params
1189 
1190     def get_internal_type(self):
1191         return "CharField"
1192 
1193     def to_python(self, value):
1194         if isinstance(value, str) or value is None:
1195             return value
1196         return str(value)
1197 
1198     def get_prep_value(self, value):
1199         value = super().get_prep_value(value)
1200         return self.to_python(value)
1201 
1202     def formfield(self, **kwargs):
1203         # Passing max_length to forms.CharField means that the value's length
1204         # will be validated twice. This is considered acceptable since we want
1205         # the value in the form field (to pass into widget for example).
1206         defaults = {"max_length": self.max_length}
1207         # TODO: Handle multiple backends with different feature flags.
1208         if self.null and not connection.features.interprets_empty_strings_as_nulls:
1209             defaults["empty_value"] = None
1210         defaults.update(kwargs)
1211         return super().formfield(**defaults)
1212 
1213     def deconstruct(self):
1214         name, path, args, kwargs = super().deconstruct()
1215         if self.db_collation:
1216             kwargs["db_collation"] = self.db_collation
1217         return name, path, args, kwargs
1218 
1219 
1220 class CommaSeparatedIntegerField(CharField):
1221     default_validators = [validators.validate_comma_separated_integer_list]
1222     description = _("Comma-separated integers")
1223     system_check_removed_details = {
1224         "msg": (
1225             "CommaSeparatedIntegerField is removed except for support in "
1226             "historical migrations."
1227         ),
1228         "hint": (
1229             "Use CharField(validators=[validate_comma_separated_integer_list]) "
1230             "instead."
1231         ),
1232         "id": "fields.E901",
1233     }
1234 
1235 
1236 def _to_naive(value):
1237     if timezone.is_aware(value):
1238         value = timezone.make_naive(value, datetime.timezone.utc)
1239     return value
1240 
1241 
1242 def _get_naive_now():
1243     return _to_naive(timezone.now())
1244 
1245 
1246 class DateTimeCheckMixin:
1247     def check(self, **kwargs):
1248         return [
1249             *super().check(**kwargs),
1250             *self._check_mutually_exclusive_options(),
1251             *self._check_fix_default_value(),
1252         ]
1253 
1254     def _check_mutually_exclusive_options(self):
1255         # auto_now, auto_now_add, and default are mutually exclusive
1256         # options. The use of more than one of these options together
1257         # will trigger an Error
1258         mutually_exclusive_options = [
1259             self.auto_now_add,
1260             self.auto_now,
1261             self.has_default(),
1262         ]
1263         enabled_options = [
1264             option not in (None, False) for option in mutually_exclusive_options
1265         ].count(True)
1266         if enabled_options > 1:
1267             return [
1268                 checks.Error(
1269                     "The options auto_now, auto_now_add, and default "
1270                     "are mutually exclusive. Only one of these options "
1271                     "may be present.",
1272                     obj=self,
1273                     id="fields.E160",
1274                 )
1275             ]
1276         else:
1277             return []
1278 
1279     def _check_fix_default_value(self):
1280         return []
1281 
1282     # Concrete subclasses use this in their implementations of
1283     # _check_fix_default_value().
1284     def _check_if_value_fixed(self, value, now=None):
1285         """
1286         Check if the given value appears to have been provided as a "fixed"
1287         time value, and include a warning in the returned list if it does. The
1288         value argument must be a date object or aware/naive datetime object. If
1289         now is provided, it must be a naive datetime object.
1290         """
1291         if now is None:
1292             now = _get_naive_now()
1293         offset = datetime.timedelta(seconds=10)
1294         lower = now - offset
1295         upper = now + offset
1296         if isinstance(value, datetime.datetime):
1297             value = _to_naive(value)
1298         else:
1299             assert isinstance(value, datetime.date)
1300             lower = lower.date()
1301             upper = upper.date()
1302         if lower <= value <= upper:
1303             return [
1304                 checks.Warning(
1305                     "Fixed default value provided.",
1306                     hint=(
1307                         "It seems you set a fixed date / time / datetime "
1308                         "value as default for this field. This may not be "
1309                         "what you want. If you want to have the current date "
1310                         "as default, use `django.utils.timezone.now`"
1311                     ),
1312                     obj=self,
1313                     id="fields.W161",
1314                 )
1315             ]
1316         return []
1317 
1318 
1319 class DateField(DateTimeCheckMixin, Field):
1320     empty_strings_allowed = False
1321     default_error_messages = {
1322         "invalid": _(
1323             "“%(value)s” value has an invalid date format. It must be "
1324             "in YYYY-MM-DD format."
1325         ),
1326         "invalid_date": _(
1327             "“%(value)s” value has the correct format (YYYY-MM-DD) "
1328             "but it is an invalid date."
1329         ),
1330     }
1331     description = _("Date (without time)")
1332 
1333     def __init__(
1334         self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs
1335     ):
1336         self.auto_now, self.auto_now_add = auto_now, auto_now_add
1337         if auto_now or auto_now_add:
1338             kwargs["editable"] = False
1339             kwargs["blank"] = True
1340         super().__init__(verbose_name, name, **kwargs)
1341 
1342     def _check_fix_default_value(self):
1343         """
1344         Warn that using an actual date or datetime value is probably wrong;
1345         it's only evaluated on server startup.
1346         """
1347         if not self.has_default():
1348             return []
1349 
1350         value = self.default
1351         if isinstance(value, datetime.datetime):
1352             value = _to_naive(value).date()
1353         elif isinstance(value, datetime.date):
1354             pass
1355         else:
1356             # No explicit date / datetime value -- no checks necessary
1357             return []
1358         # At this point, value is a date object.
1359         return self._check_if_value_fixed(value)
1360 
1361     def deconstruct(self):
1362         name, path, args, kwargs = super().deconstruct()
1363         if self.auto_now:
1364             kwargs["auto_now"] = True
1365         if self.auto_now_add:
1366             kwargs["auto_now_add"] = True
1367         if self.auto_now or self.auto_now_add:
1368             del kwargs["editable"]
1369             del kwargs["blank"]
1370         return name, path, args, kwargs
1371 
1372     def get_internal_type(self):
1373         return "DateField"
1374 
1375     def to_python(self, value):
1376         if value is None:
1377             return value
1378         if isinstance(value, datetime.datetime):
1379             if settings.USE_TZ and timezone.is_aware(value):
1380                 # Convert aware datetimes to the default time zone
1381                 # before casting them to dates (#17742).
1382                 default_timezone = timezone.get_default_timezone()
1383                 value = timezone.make_naive(value, default_timezone)
1384             return value.date()
1385         if isinstance(value, datetime.date):
1386             return value
1387 
1388         try:
1389             parsed = parse_date(value)
1390             if parsed is not None:
1391                 return parsed
1392         except ValueError:
1393             raise exceptions.ValidationError(
1394                 self.error_messages["invalid_date"],
1395                 code="invalid_date",
1396                 params={"value": value},
1397             )
1398 
1399         raise exceptions.ValidationError(
1400             self.error_messages["invalid"],
1401             code="invalid",
1402             params={"value": value},
1403         )
1404 
1405     def pre_save(self, model_instance, add):
1406         if self.auto_now or (self.auto_now_add and add):
1407             value = datetime.date.today()
1408             setattr(model_instance, self.attname, value)
1409             return value
1410         else:
1411             return super().pre_save(model_instance, add)
1412 
1413     def contribute_to_class(self, cls, name, **kwargs):
1414         super().contribute_to_class(cls, name, **kwargs)
1415         if not self.null:
1416             setattr(
1417                 cls,
1418                 "get_next_by_%s" % self.name,
1419                 partialmethod(
1420                     cls._get_next_or_previous_by_FIELD, field=self, is_next=True
1421                 ),
1422             )
1423             setattr(
1424                 cls,
1425                 "get_previous_by_%s" % self.name,
1426                 partialmethod(
1427                     cls._get_next_or_previous_by_FIELD, field=self, is_next=False
1428                 ),
1429             )
1430 
1431     def get_prep_value(self, value):
1432         value = super().get_prep_value(value)
1433         return self.to_python(value)
1434 
1435     def get_db_prep_value(self, value, connection, prepared=False):
1436         # Casts dates into the format expected by the backend
1437         if not prepared:
1438             value = self.get_prep_value(value)
1439         return connection.ops.adapt_datefield_value(value)
1440 
1441     def value_to_string(self, obj):
1442         val = self.value_from_object(obj)
1443         return "" if val is None else val.isoformat()
1444 
1445     def formfield(self, **kwargs):
1446         return super().formfield(
1447             **{
1448                 "form_class": forms.DateField,
1449                 **kwargs,
1450             }
1451         )
1452 
1453 
1454 class DateTimeField(DateField):
1455     empty_strings_allowed = False
1456     default_error_messages = {
1457         "invalid": _(
1458             "“%(value)s” value has an invalid format. It must be in "
1459             "YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format."
1460         ),
1461         "invalid_date": _(
1462             "“%(value)s” value has the correct format "
1463             "(YYYY-MM-DD) but it is an invalid date."
1464         ),
1465         "invalid_datetime": _(
1466             "“%(value)s” value has the correct format "
1467             "(YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ]) "
1468             "but it is an invalid date/time."
1469         ),
1470     }
1471     description = _("Date (with time)")
1472 
1473     # __init__ is inherited from DateField
1474 
1475     def _check_fix_default_value(self):
1476         """
1477         Warn that using an actual date or datetime value is probably wrong;
1478         it's only evaluated on server startup.
1479         """
1480         if not self.has_default():
1481             return []
1482 
1483         value = self.default
1484         if isinstance(value, (datetime.datetime, datetime.date)):
1485             return self._check_if_value_fixed(value)
1486         # No explicit date / datetime value -- no checks necessary.
1487         return []
1488 
1489     def get_internal_type(self):
1490         return "DateTimeField"
1491 
1492     def to_python(self, value):
1493         if value is None:
1494             return value
1495         if isinstance(value, datetime.datetime):
1496             return value
1497         if isinstance(value, datetime.date):
1498             value = datetime.datetime(value.year, value.month, value.day)
1499             if settings.USE_TZ:
1500                 # For backwards compatibility, interpret naive datetimes in
1501                 # local time. This won't work during DST change, but we can't
1502                 # do much about it, so we let the exceptions percolate up the
1503                 # call stack.
1504                 warnings.warn(
1505                     "DateTimeField %s.%s received a naive datetime "
1506                     "(%s) while time zone support is active."
1507                     % (self.model.__name__, self.name, value),
1508                     RuntimeWarning,
1509                 )
1510                 default_timezone = timezone.get_default_timezone()
1511                 value = timezone.make_aware(value, default_timezone)
1512             return value
1513 
1514         try:
1515             parsed = parse_datetime(value)
1516             if parsed is not None:
1517                 return parsed
1518         except ValueError:
1519             raise exceptions.ValidationError(
1520                 self.error_messages["invalid_datetime"],
1521                 code="invalid_datetime",
1522                 params={"value": value},
1523             )
1524 
1525         try:
1526             parsed = parse_date(value)
1527             if parsed is not None:
1528                 return datetime.datetime(parsed.year, parsed.month, parsed.day)
1529         except ValueError:
1530             raise exceptions.ValidationError(
1531                 self.error_messages["invalid_date"],
1532                 code="invalid_date",
1533                 params={"value": value},
1534             )
1535 
1536         raise exceptions.ValidationError(
1537             self.error_messages["invalid"],
1538             code="invalid",
1539             params={"value": value},
1540         )
1541 
1542     def pre_save(self, model_instance, add):
1543         if self.auto_now or (self.auto_now_add and add):
1544             value = timezone.now()
1545             setattr(model_instance, self.attname, value)
1546             return value
1547         else:
1548             return super().pre_save(model_instance, add)
1549 
1550     # contribute_to_class is inherited from DateField, it registers
1551     # get_next_by_FOO and get_prev_by_FOO
1552 
1553     def get_prep_value(self, value):
1554         value = super().get_prep_value(value)
1555         value = self.to_python(value)
1556         if value is not None and settings.USE_TZ and timezone.is_naive(value):
1557             # For backwards compatibility, interpret naive datetimes in local
1558             # time. This won't work during DST change, but we can't do much
1559             # about it, so we let the exceptions percolate up the call stack.
1560             try:
1561                 name = "%s.%s" % (self.model.__name__, self.name)
1562             except AttributeError:
1563                 name = "(unbound)"
1564             warnings.warn(
1565                 "DateTimeField %s received a naive datetime (%s)"
1566                 " while time zone support is active." % (name, value),
1567                 RuntimeWarning,
1568             )
1569             default_timezone = timezone.get_default_timezone()
1570             value = timezone.make_aware(value, default_timezone)
1571         return value
1572 
1573     def get_db_prep_value(self, value, connection, prepared=False):
1574         # Casts datetimes into the format expected by the backend
1575         if not prepared:
1576             value = self.get_prep_value(value)
1577         return connection.ops.adapt_datetimefield_value(value)
1578 
1579     def value_to_string(self, obj):
1580         val = self.value_from_object(obj)
1581         return "" if val is None else val.isoformat()
1582 
1583     def formfield(self, **kwargs):
1584         return super().formfield(
1585             **{
1586                 "form_class": forms.DateTimeField,
1587                 **kwargs,
1588             }
1589         )
1590 
1591 
1592 class DecimalField(Field):
1593     empty_strings_allowed = False
1594     default_error_messages = {
1595         "invalid": _("“%(value)s” value must be a decimal number."),
1596     }
1597     description = _("Decimal number")
1598 
1599     def __init__(
1600         self,
1601         verbose_name=None,
1602         name=None,
1603         max_digits=None,
1604         decimal_places=None,
1605         **kwargs,
1606     ):
1607         self.max_digits, self.decimal_places = max_digits, decimal_places
1608         super().__init__(verbose_name, name, **kwargs)
1609 
1610     def check(self, **kwargs):
1611         errors = super().check(**kwargs)
1612 
1613         digits_errors = [
1614             *self._check_decimal_places(),
1615             *self._check_max_digits(),
1616         ]
1617         if not digits_errors:
1618             errors.extend(self._check_decimal_places_and_max_digits(**kwargs))
1619         else:
1620             errors.extend(digits_errors)
1621         return errors
1622 
1623     def _check_decimal_places(self):
1624         try:
1625             decimal_places = int(self.decimal_places)
1626             if decimal_places < 0:
1627                 raise ValueError()
1628         except TypeError:
1629             return [
1630                 checks.Error(
1631                     "DecimalFields must define a 'decimal_places' attribute.",
1632                     obj=self,
1633                     id="fields.E130",
1634                 )
1635             ]
1636         except ValueError:
1637             return [
1638                 checks.Error(
1639                     "'decimal_places' must be a non-negative integer.",
1640                     obj=self,
1641                     id="fields.E131",
1642                 )
1643             ]
1644         else:
1645             return []
1646 
1647     def _check_max_digits(self):
1648         try:
1649             max_digits = int(self.max_digits)
1650             if max_digits <= 0:
1651                 raise ValueError()
1652         except TypeError:
1653             return [
1654                 checks.Error(
1655                     "DecimalFields must define a 'max_digits' attribute.",
1656                     obj=self,
1657                     id="fields.E132",
1658                 )
1659             ]
1660         except ValueError:
1661             return [
1662                 checks.Error(
1663                     "'max_digits' must be a positive integer.",
1664                     obj=self,
1665                     id="fields.E133",
1666                 )
1667             ]
1668         else:
1669             return []
1670 
1671     def _check_decimal_places_and_max_digits(self, **kwargs):
1672         if int(self.decimal_places) > int(self.max_digits):
1673             return [
1674                 checks.Error(
1675                     "'max_digits' must be greater or equal to 'decimal_places'.",
1676                     obj=self,
1677                     id="fields.E134",
1678                 )
1679             ]
1680         return []
1681 
1682     @cached_property
1683     def validators(self):
1684         return super().validators + [
1685             validators.DecimalValidator(self.max_digits, self.decimal_places)
1686         ]
1687 
1688     @cached_property
1689     def context(self):
1690         return decimal.Context(prec=self.max_digits)
1691 
1692     def deconstruct(self):
1693         name, path, args, kwargs = super().deconstruct()
1694         if self.max_digits is not None:
1695             kwargs["max_digits"] = self.max_digits
1696         if self.decimal_places is not None:
1697             kwargs["decimal_places"] = self.decimal_places
1698         return name, path, args, kwargs
1699 
1700     def get_internal_type(self):
1701         return "DecimalField"
1702 
1703     def to_python(self, value):
1704         if value is None:
1705             return value
1706         if isinstance(value, float):
1707             if math.isnan(value):
1708                 raise exceptions.ValidationError(
1709                     self.error_messages["invalid"],
1710                     code="invalid",
1711                     params={"value": value},
1712                 )
1713             return self.context.create_decimal_from_float(value)
1714         try:
1715             return decimal.Decimal(value)
1716         except (decimal.InvalidOperation, TypeError, ValueError):
1717             raise exceptions.ValidationError(
1718                 self.error_messages["invalid"],
1719                 code="invalid",
1720                 params={"value": value},
1721             )
1722 
1723     def get_db_prep_save(self, value, connection):
1724         return connection.ops.adapt_decimalfield_value(
1725             self.to_python(value), self.max_digits, self.decimal_places
1726         )
1727 
1728     def get_prep_value(self, value):
1729         value = super().get_prep_value(value)
1730         return self.to_python(value)
1731 
1732     def formfield(self, **kwargs):
1733         return super().formfield(
1734             **{
1735                 "max_digits": self.max_digits,
1736                 "decimal_places": self.decimal_places,
1737                 "form_class": forms.DecimalField,
1738                 **kwargs,
1739             }
1740         )
1741 
1742 
1743 class DurationField(Field):
1744     """
1745     Store timedelta objects.
1746 
1747     Use interval on PostgreSQL, INTERVAL DAY TO SECOND on Oracle, and bigint
1748     of microseconds on other databases.
1749     """
1750 
1751     empty_strings_allowed = False
1752     default_error_messages = {
1753         "invalid": _(
1754             "“%(value)s” value has an invalid format. It must be in "
1755             "[DD] [[HH:]MM:]ss[.uuuuuu] format."
1756         )
1757     }
1758     description = _("Duration")
1759 
1760     def get_internal_type(self):
1761         return "DurationField"
1762 
1763     def to_python(self, value):
1764         if value is None:
1765             return value
1766         if isinstance(value, datetime.timedelta):
1767             return value
1768         try:
1769             parsed = parse_duration(value)
1770         except ValueError:
1771             pass
1772         else:
1773             if parsed is not None:
1774                 return parsed
1775 
1776         raise exceptions.ValidationError(
1777             self.error_messages["invalid"],
1778             code="invalid",
1779             params={"value": value},
1780         )
1781 
1782     def get_db_prep_value(self, value, connection, prepared=False):
1783         if connection.features.has_native_duration_field:
1784             return value
1785         if value is None:
1786             return None
1787         return duration_microseconds(value)
1788 
1789     def get_db_converters(self, connection):
1790         converters = []
1791         if not connection.features.has_native_duration_field:
1792             converters.append(connection.ops.convert_durationfield_value)
1793         return converters + super().get_db_converters(connection)
1794 
1795     def value_to_string(self, obj):
1796         val = self.value_from_object(obj)
1797         return "" if val is None else duration_string(val)
1798 
1799     def formfield(self, **kwargs):
1800         return super().formfield(
1801             **{
1802                 "form_class": forms.DurationField,
1803                 **kwargs,
1804             }
1805         )
1806 
1807 
1808 class EmailField(CharField):
1809     default_validators = [validators.validate_email]
1810     description = _("Email address")
1811 
1812     def __init__(self, *args, **kwargs):
1813         # max_length=254 to be compliant with RFCs 3696 and 5321
1814         kwargs.setdefault("max_length", 254)
1815         super().__init__(*args, **kwargs)
1816 
1817     def deconstruct(self):
1818         name, path, args, kwargs = super().deconstruct()
1819         # We do not exclude max_length if it matches default as we want to change
1820         # the default in future.
1821         return name, path, args, kwargs
1822 
1823     def formfield(self, **kwargs):
1824         # As with CharField, this will cause email validation to be performed
1825         # twice.
1826         return super().formfield(
1827             **{
1828                 "form_class": forms.EmailField,
1829                 **kwargs,
1830             }
1831         )
1832 
1833 
1834 class FilePathField(Field):
1835     description = _("File path")
1836 
1837     def __init__(
1838         self,
1839         verbose_name=None,
1840         name=None,
1841         path="",
1842         match=None,
1843         recursive=False,
1844         allow_files=True,
1845         allow_folders=False,
1846         **kwargs,
1847     ):
1848         self.path, self.match, self.recursive = path, match, recursive
1849         self.allow_files, self.allow_folders = allow_files, allow_folders
1850         kwargs.setdefault("max_length", 100)
1851         super().__init__(verbose_name, name, **kwargs)
1852 
1853     def check(self, **kwargs):
1854         return [
1855             *super().check(**kwargs),
1856             *self._check_allowing_files_or_folders(**kwargs),
1857         ]
1858 
1859     def _check_allowing_files_or_folders(self, **kwargs):
1860         if not self.allow_files and not self.allow_folders:
1861             return [
1862                 checks.Error(
1863                     "FilePathFields must have either 'allow_files' or 'allow_folders' "
1864                     "set to True.",
1865                     obj=self,
1866                     id="fields.E140",
1867                 )
1868             ]
1869         return []
1870 
1871     def deconstruct(self):
1872         name, path, args, kwargs = super().deconstruct()
1873         if self.path != "":
1874             kwargs["path"] = self.path
1875         if self.match is not None:
1876             kwargs["match"] = self.match
1877         if self.recursive is not False:
1878             kwargs["recursive"] = self.recursive
1879         if self.allow_files is not True:
1880             kwargs["allow_files"] = self.allow_files
1881         if self.allow_folders is not False:
1882             kwargs["allow_folders"] = self.allow_folders
1883         if kwargs.get("max_length") == 100:
1884             del kwargs["max_length"]
1885         return name, path, args, kwargs
1886 
1887     def get_prep_value(self, value):
1888         value = super().get_prep_value(value)
1889         if value is None:
1890             return None
1891         return str(value)
1892 
1893     def formfield(self, **kwargs):
1894         return super().formfield(
1895             **{
1896                 "path": self.path() if callable(self.path) else self.path,
1897                 "match": self.match,
1898                 "recursive": self.recursive,
1899                 "form_class": forms.FilePathField,
1900                 "allow_files": self.allow_files,
1901                 "allow_folders": self.allow_folders,
1902                 **kwargs,
1903             }
1904         )
1905 
1906     def get_internal_type(self):
1907         return "FilePathField"
1908 
1909 
1910 class FloatField(Field):
1911     empty_strings_allowed = False
1912     default_error_messages = {
1913         "invalid": _("“%(value)s” value must be a float."),
1914     }
1915     description = _("Floating point number")
1916 
1917     def get_prep_value(self, value):
1918         value = super().get_prep_value(value)
1919         if value is None:
1920             return None
1921         try:
1922             return float(value)
1923         except (TypeError, ValueError) as e:
1924             raise e.__class__(
1925                 "Field '%s' expected a number but got %r." % (self.name, value),
1926             ) from e
1927 
1928     def get_internal_type(self):
1929         return "FloatField"
1930 
1931     def to_python(self, value):
1932         if value is None:
1933             return value
1934         try:
1935             return float(value)
1936         except (TypeError, ValueError):
1937             raise exceptions.ValidationError(
1938                 self.error_messages["invalid"],
1939                 code="invalid",
1940                 params={"value": value},
1941             )
1942 
1943     def formfield(self, **kwargs):
1944         return super().formfield(
1945             **{
1946                 "form_class": forms.FloatField,
1947                 **kwargs,
1948             }
1949         )
1950 
1951 
1952 class IntegerField(Field):
1953     empty_strings_allowed = False
1954     default_error_messages = {
1955         "invalid": _("“%(value)s” value must be an integer."),
1956     }
1957     description = _("Integer")
1958 
1959     def check(self, **kwargs):
1960         return [
1961             *super().check(**kwargs),
1962             *self._check_max_length_warning(),
1963         ]
1964 
1965     def _check_max_length_warning(self):
1966         if self.max_length is not None:
1967             return [
1968                 checks.Warning(
1969                     "'max_length' is ignored when used with %s."
1970                     % self.__class__.__name__,
1971                     hint="Remove 'max_length' from field",
1972                     obj=self,
1973                     id="fields.W122",
1974                 )
1975             ]
1976         return []
1977 
1978     @cached_property
1979     def validators(self):
1980         # These validators can't be added at field initialization time since
1981         # they're based on values retrieved from `connection`.
1982         validators_ = super().validators
1983         internal_type = self.get_internal_type()
1984         min_value, max_value = connection.ops.integer_field_range(internal_type)
1985         if min_value is not None and not any(
1986             (
1987                 isinstance(validator, validators.MinValueValidator)
1988                 and (
1989                     validator.limit_value()
1990                     if callable(validator.limit_value)
1991                     else validator.limit_value
1992                 )
1993                 >= min_value
1994             )
1995             for validator in validators_
1996         ):
1997             validators_.append(validators.MinValueValidator(min_value))
1998         if max_value is not None and not any(
1999             (
2000                 isinstance(validator, validators.MaxValueValidator)
2001                 and (
2002                     validator.limit_value()
2003                     if callable(validator.limit_value)
2004                     else validator.limit_value
2005                 )
2006                 <= max_value
2007             )
2008             for validator in validators_
2009         ):
2010             validators_.append(validators.MaxValueValidator(max_value))
2011         return validators_
2012 
2013     def get_prep_value(self, value):
2014         value = super().get_prep_value(value)
2015         if value is None:
2016             return None
2017         try:
2018             return int(value)
2019         except (TypeError, ValueError) as e:
2020             raise e.__class__(
2021                 "Field '%s' expected a number but got %r." % (self.name, value),
2022             ) from e
2023 
2024     def get_internal_type(self):
2025         return "IntegerField"
2026 
2027     def to_python(self, value):
2028         if value is None:
2029             return value
2030         try:
2031             return int(value)
2032         except (TypeError, ValueError):
2033             raise exceptions.ValidationError(
2034                 self.error_messages["invalid"],
2035                 code="invalid",
2036                 params={"value": value},
2037             )
2038 
2039     def formfield(self, **kwargs):
2040         return super().formfield(
2041             **{
2042                 "form_class": forms.IntegerField,
2043                 **kwargs,
2044             }
2045         )
2046 
2047 
2048 class BigIntegerField(IntegerField):
2049     description = _("Big (8 byte) integer")
2050     MAX_BIGINT = 9223372036854775807
2051 
2052     def get_internal_type(self):
2053         return "BigIntegerField"
2054 
2055     def formfield(self, **kwargs):
2056         return super().formfield(
2057             **{
2058                 "min_value": -BigIntegerField.MAX_BIGINT - 1,
2059                 "max_value": BigIntegerField.MAX_BIGINT,
2060                 **kwargs,
2061             }
2062         )
2063 
2064 
2065 class SmallIntegerField(IntegerField):
2066     description = _("Small integer")
2067 
2068     def get_internal_type(self):
2069         return "SmallIntegerField"
2070 
2071 
2072 class IPAddressField(Field):
2073     empty_strings_allowed = False
2074     description = _("IPv4 address")
2075     system_check_removed_details = {
2076         "msg": (
2077             "IPAddressField has been removed except for support in "
2078             "historical migrations."
2079         ),
2080         "hint": "Use GenericIPAddressField instead.",
2081         "id": "fields.E900",
2082     }
2083 
2084     def __init__(self, *args, **kwargs):
2085         kwargs["max_length"] = 15
2086         super().__init__(*args, **kwargs)
2087 
2088     def deconstruct(self):
2089         name, path, args, kwargs = super().deconstruct()
2090         del kwargs["max_length"]
2091         return name, path, args, kwargs
2092 
2093     def get_prep_value(self, value):
2094         value = super().get_prep_value(value)
2095         if value is None:
2096             return None
2097         return str(value)
2098 
2099     def get_internal_type(self):
2100         return "IPAddressField"
2101 
2102 
2103 class GenericIPAddressField(Field):
2104     empty_strings_allowed = False
2105     description = _("IP address")
2106     default_error_messages = {}
2107 
2108     def __init__(
2109         self,
2110         verbose_name=None,
2111         name=None,
2112         protocol="both",
2113         unpack_ipv4=False,
2114         *args,
2115         **kwargs,
2116     ):
2117         self.unpack_ipv4 = unpack_ipv4
2118         self.protocol = protocol
2119         (
2120             self.default_validators,
2121             invalid_error_message,
2122         ) = validators.ip_address_validators(protocol, unpack_ipv4)
2123         self.default_error_messages["invalid"] = invalid_error_message
2124         kwargs["max_length"] = 39
2125         super().__init__(verbose_name, name, *args, **kwargs)
2126 
2127     def check(self, **kwargs):
2128         return [
2129             *super().check(**kwargs),
2130             *self._check_blank_and_null_values(**kwargs),
2131         ]
2132 
2133     def _check_blank_and_null_values(self, **kwargs):
2134         if not getattr(self, "null", False) and getattr(self, "blank", False):
2135             return [
2136                 checks.Error(
2137                     "GenericIPAddressFields cannot have blank=True if null=False, "
2138                     "as blank values are stored as nulls.",
2139                     obj=self,
2140                     id="fields.E150",
2141                 )
2142             ]
2143         return []
2144 
2145     def deconstruct(self):
2146         name, path, args, kwargs = super().deconstruct()
2147         if self.unpack_ipv4 is not False:
2148             kwargs["unpack_ipv4"] = self.unpack_ipv4
2149         if self.protocol != "both":
2150             kwargs["protocol"] = self.protocol
2151         if kwargs.get("max_length") == 39:
2152             del kwargs["max_length"]
2153         return name, path, args, kwargs
2154 
2155     def get_internal_type(self):
2156         return "GenericIPAddressField"
2157 
2158     def to_python(self, value):
2159         if value is None:
2160             return None
2161         if not isinstance(value, str):
2162             value = str(value)
2163         value = value.strip()
2164         if ":" in value:
2165             return clean_ipv6_address(
2166                 value, self.unpack_ipv4, self.error_messages["invalid"]
2167             )
2168         return value
2169 
2170     def get_db_prep_value(self, value, connection, prepared=False):
2171         if not prepared:
2172             value = self.get_prep_value(value)
2173         return connection.ops.adapt_ipaddressfield_value(value)
2174 
2175     def get_prep_value(self, value):
2176         value = super().get_prep_value(value)
2177         if value is None:
2178             return None
2179         if value and ":" in value:
2180             try:
2181                 return clean_ipv6_address(value, self.unpack_ipv4)
2182             except exceptions.ValidationError:
2183                 pass
2184         return str(value)
2185 
2186     def formfield(self, **kwargs):
2187         return super().formfield(
2188             **{
2189                 "protocol": self.protocol,
2190                 "form_class": forms.GenericIPAddressField,
2191                 **kwargs,
2192             }
2193         )
2194 
2195 
2196 class NullBooleanField(BooleanField):
2197     default_error_messages = {
2198         "invalid": _("“%(value)s” value must be either None, True or False."),
2199         "invalid_nullable": _("“%(value)s” value must be either None, True or False."),
2200     }
2201     description = _("Boolean (Either True, False or None)")
2202     system_check_removed_details = {
2203         "msg": (
2204             "NullBooleanField is removed except for support in historical "
2205             "migrations."
2206         ),
2207         "hint": "Use BooleanField(null=True) instead.",
2208         "id": "fields.E903",
2209     }
2210 
2211     def __init__(self, *args, **kwargs):
2212         kwargs["null"] = True
2213         kwargs["blank"] = True
2214         super().__init__(*args, **kwargs)
2215 
2216     def deconstruct(self):
2217         name, path, args, kwargs = super().deconstruct()
2218         del kwargs["null"]
2219         del kwargs["blank"]
2220         return name, path, args, kwargs
2221 
2222 
2223 class PositiveIntegerRelDbTypeMixin:
2224     def __init_subclass__(cls, **kwargs):
2225         super().__init_subclass__(**kwargs)
2226         if not hasattr(cls, "integer_field_class"):
2227             cls.integer_field_class = next(
2228                 (
2229                     parent
2230                     for parent in cls.__mro__[1:]
2231                     if issubclass(parent, IntegerField)
2232                 ),
2233                 None,
2234             )
2235 
2236     def rel_db_type(self, connection):
2237         """
2238         Return the data type that a related field pointing to this field should
2239         use. In most cases, a foreign key pointing to a positive integer
2240         primary key will have an integer column data type but some databases
2241         (e.g. MySQL) have an unsigned integer type. In that case
2242         (related_fields_match_type=True), the primary key should return its
2243         db_type.
2244         """
2245         if connection.features.related_fields_match_type:
2246             return self.db_type(connection)
2247         else:
2248             return self.integer_field_class().db_type(connection=connection)
2249 
2250 
2251 class PositiveBigIntegerField(PositiveIntegerRelDbTypeMixin, BigIntegerField):
2252     description = _("Positive big integer")
2253 
2254     def get_internal_type(self):
2255         return "PositiveBigIntegerField"
2256 
2257     def formfield(self, **kwargs):
2258         return super().formfield(
2259             **{
2260                 "min_value": 0,
2261                 **kwargs,
2262             }
2263         )
2264 
2265 
2266 class PositiveIntegerField(PositiveIntegerRelDbTypeMixin, IntegerField):
2267     description = _("Positive integer")
2268 
2269     def get_internal_type(self):
2270         return "PositiveIntegerField"
2271 
2272     def formfield(self, **kwargs):
2273         return super().formfield(
2274             **{
2275                 "min_value": 0,
2276                 **kwargs,
2277             }
2278         )
2279 
2280 
2281 class PositiveSmallIntegerField(PositiveIntegerRelDbTypeMixin, SmallIntegerField):
2282     description = _("Positive small integer")
2283 
2284     def get_internal_type(self):
2285         return "PositiveSmallIntegerField"
2286 
2287     def formfield(self, **kwargs):
2288         return super().formfield(
2289             **{
2290                 "min_value": 0,
2291                 **kwargs,
2292             }
2293         )
2294 
2295 
2296 class SlugField(CharField):
2297     default_validators = [validators.validate_slug]
2298     description = _("Slug (up to %(max_length)s)")
2299 
2300     def __init__(
2301         self, *args, max_length=50, db_index=True, allow_unicode=False, **kwargs
2302     ):
2303         self.allow_unicode = allow_unicode
2304         if self.allow_unicode:
2305             self.default_validators = [validators.validate_unicode_slug]
2306         super().__init__(*args, max_length=max_length, db_index=db_index, **kwargs)
2307 
2308     def deconstruct(self):
2309         name, path, args, kwargs = super().deconstruct()
2310         if kwargs.get("max_length") == 50:
2311             del kwargs["max_length"]
2312         if self.db_index is False:
2313             kwargs["db_index"] = False
2314         else:
2315             del kwargs["db_index"]
2316         if self.allow_unicode is not False:
2317             kwargs["allow_unicode"] = self.allow_unicode
2318         return name, path, args, kwargs
2319 
2320     def get_internal_type(self):
2321         return "SlugField"
2322 
2323     def formfield(self, **kwargs):
2324         return super().formfield(
2325             **{
2326                 "form_class": forms.SlugField,
2327                 "allow_unicode": self.allow_unicode,
2328                 **kwargs,
2329             }
2330         )
2331 
2332 
2333 class TextField(Field):
2334     description = _("Text")
2335 
2336     def __init__(self, *args, db_collation=None, **kwargs):
2337         super().__init__(*args, **kwargs)
2338         self.db_collation = db_collation
2339 
2340     def check(self, **kwargs):
2341         databases = kwargs.get("databases") or []
2342         return [
2343             *super().check(**kwargs),
2344             *self._check_db_collation(databases),
2345         ]
2346 
2347     def _check_db_collation(self, databases):
2348         errors = []
2349         for db in databases:
2350             if not router.allow_migrate_model(db, self.model):
2351                 continue
2352             connection = connections[db]
2353             if not (
2354                 self.db_collation is None
2355                 or "supports_collation_on_textfield"
2356                 in self.model._meta.required_db_features
2357                 or connection.features.supports_collation_on_textfield
2358             ):
2359                 errors.append(
2360                     checks.Error(
2361                         "%s does not support a database collation on "
2362                         "TextFields." % connection.display_name,
2363                         obj=self,
2364                         id="fields.E190",
2365                     ),
2366                 )
2367         return errors
2368 
2369     def db_parameters(self, connection):
2370         db_params = super().db_parameters(connection)
2371         db_params["collation"] = self.db_collation
2372         return db_params
2373 
2374     def get_internal_type(self):
2375         return "TextField"
2376 
2377     def to_python(self, value):
2378         if isinstance(value, str) or value is None:
2379             return value
2380         return str(value)
2381 
2382     def get_prep_value(self, value):
2383         value = super().get_prep_value(value)
2384         return self.to_python(value)
2385 
2386     def formfield(self, **kwargs):
2387         # Passing max_length to forms.CharField means that the value's length
2388         # will be validated twice. This is considered acceptable since we want
2389         # the value in the form field (to pass into widget for example).
2390         return super().formfield(
2391             **{
2392                 "max_length": self.max_length,
2393                 **({} if self.choices is not None else {"widget": forms.Textarea}),
2394                 **kwargs,
2395             }
2396         )
2397 
2398     def deconstruct(self):
2399         name, path, args, kwargs = super().deconstruct()
2400         if self.db_collation:
2401             kwargs["db_collation"] = self.db_collation
2402         return name, path, args, kwargs
2403 
2404 
2405 class TimeField(DateTimeCheckMixin, Field):
2406     empty_strings_allowed = False
2407     default_error_messages = {
2408         "invalid": _(
2409             "“%(value)s” value has an invalid format. It must be in "
2410             "HH:MM[:ss[.uuuuuu]] format."
2411         ),
2412         "invalid_time": _(
2413             "“%(value)s” value has the correct format "
2414             "(HH:MM[:ss[.uuuuuu]]) but it is an invalid time."
2415         ),
2416     }
2417     description = _("Time")
2418 
2419     def __init__(
2420         self, verbose_name=None, name=None, auto_now=False, auto_now_add=False, **kwargs
2421     ):
2422         self.auto_now, self.auto_now_add = auto_now, auto_now_add
2423         if auto_now or auto_now_add:
2424             kwargs["editable"] = False
2425             kwargs["blank"] = True
2426         super().__init__(verbose_name, name, **kwargs)
2427 
2428     def _check_fix_default_value(self):
2429         """
2430         Warn that using an actual date or datetime value is probably wrong;
2431         it's only evaluated on server startup.
2432         """
2433         if not self.has_default():
2434             return []
2435 
2436         value = self.default
2437         if isinstance(value, datetime.datetime):
2438             now = None
2439         elif isinstance(value, datetime.time):
2440             now = _get_naive_now()
2441             # This will not use the right date in the race condition where now
2442             # is just before the date change and value is just past 0:00.
2443             value = datetime.datetime.combine(now.date(), value)
2444         else:
2445             # No explicit time / datetime value -- no checks necessary
2446             return []
2447         # At this point, value is a datetime object.
2448         return self._check_if_value_fixed(value, now=now)
2449 
2450     def deconstruct(self):
2451         name, path, args, kwargs = super().deconstruct()
2452         if self.auto_now is not False:
2453             kwargs["auto_now"] = self.auto_now
2454         if self.auto_now_add is not False:
2455             kwargs["auto_now_add"] = self.auto_now_add
2456         if self.auto_now or self.auto_now_add:
2457             del kwargs["blank"]
2458             del kwargs["editable"]
2459         return name, path, args, kwargs
2460 
2461     def get_internal_type(self):
2462         return "TimeField"
2463 
2464     def to_python(self, value):
2465         if value is None:
2466             return None
2467         if isinstance(value, datetime.time):
2468             return value
2469         if isinstance(value, datetime.datetime):
2470             # Not usually a good idea to pass in a datetime here (it loses
2471             # information), but this can be a side-effect of interacting with a
2472             # database backend (e.g. Oracle), so we'll be accommodating.
2473             return value.time()
2474 
2475         try:
2476             parsed = parse_time(value)
2477             if parsed is not None:
2478                 return parsed
2479         except ValueError:
2480             raise exceptions.ValidationError(
2481                 self.error_messages["invalid_time"],
2482                 code="invalid_time",
2483                 params={"value": value},
2484             )
2485 
2486         raise exceptions.ValidationError(
2487             self.error_messages["invalid"],
2488             code="invalid",
2489             params={"value": value},
2490         )
2491 
2492     def pre_save(self, model_instance, add):
2493         if self.auto_now or (self.auto_now_add and add):
2494             value = datetime.datetime.now().time()
2495             setattr(model_instance, self.attname, value)
2496             return value
2497         else:
2498             return super().pre_save(model_instance, add)
2499 
2500     def get_prep_value(self, value):
2501         value = super().get_prep_value(value)
2502         return self.to_python(value)
2503 
2504     def get_db_prep_value(self, value, connection, prepared=False):
2505         # Casts times into the format expected by the backend
2506         if not prepared:
2507             value = self.get_prep_value(value)
2508         return connection.ops.adapt_timefield_value(value)
2509 
2510     def value_to_string(self, obj):
2511         val = self.value_from_object(obj)
2512         return "" if val is None else val.isoformat()
2513 
2514     def formfield(self, **kwargs):
2515         return super().formfield(
2516             **{
2517                 "form_class": forms.TimeField,
2518                 **kwargs,
2519             }
2520         )
2521 
2522 
2523 class URLField(CharField):
2524     default_validators = [validators.URLValidator()]
2525     description = _("URL")
2526 
2527     def __init__(self, verbose_name=None, name=None, **kwargs):
2528         kwargs.setdefault("max_length", 200)
2529         super().__init__(verbose_name, name, **kwargs)
2530 
2531     def deconstruct(self):
2532         name, path, args, kwargs = super().deconstruct()
2533         if kwargs.get("max_length") == 200:
2534             del kwargs["max_length"]
2535         return name, path, args, kwargs
2536 
2537     def formfield(self, **kwargs):
2538         # As with CharField, this will cause URL validation to be performed
2539         # twice.
2540         return super().formfield(
2541             **{
2542                 "form_class": forms.URLField,
2543                 **kwargs,
2544             }
2545         )
2546 
2547 
2548 class BinaryField(Field):
2549     description = _("Raw binary data")
2550     empty_values = [None, b""]
2551 
2552     def __init__(self, *args, **kwargs):
2553         kwargs.setdefault("editable", False)
2554         super().__init__(*args, **kwargs)
2555         if self.max_length is not None:
2556             self.validators.append(validators.MaxLengthValidator(self.max_length))
2557 
2558     def check(self, **kwargs):
2559         return [*super().check(**kwargs), *self._check_str_default_value()]
2560 
2561     def _check_str_default_value(self):
2562         if self.has_default() and isinstance(self.default, str):
2563             return [
2564                 checks.Error(
2565                     "BinaryField's default cannot be a string. Use bytes "
2566                     "content instead.",
2567                     obj=self,
2568                     id="fields.E170",
2569                 )
2570             ]
2571         return []
2572 
2573     def deconstruct(self):
2574         name, path, args, kwargs = super().deconstruct()
2575         if self.editable:
2576             kwargs["editable"] = True
2577         else:
2578             del kwargs["editable"]
2579         return name, path, args, kwargs
2580 
2581     def get_internal_type(self):
2582         return "BinaryField"
2583 
2584     def get_placeholder(self, value, compiler, connection):
2585         return connection.ops.binary_placeholder_sql(value)
2586 
2587     def get_default(self):
2588         if self.has_default() and not callable(self.default):
2589             return self.default
2590         default = super().get_default()
2591         if default == "":
2592             return b""
2593         return default
2594 
2595     def get_db_prep_value(self, value, connection, prepared=False):
2596         value = super().get_db_prep_value(value, connection, prepared)
2597         if value is not None:
2598             return connection.Database.Binary(value)
2599         return value
2600 
2601     def value_to_string(self, obj):
2602         """Binary data is serialized as base64"""
2603         return b64encode(self.value_from_object(obj)).decode("ascii")
2604 
2605     def to_python(self, value):
2606         # If it's a string, it should be base64-encoded data
2607         if isinstance(value, str):
2608             return memoryview(b64decode(value.encode("ascii")))
2609         return value
2610 
2611 
2612 class UUIDField(Field):
2613     default_error_messages = {
2614         "invalid": _("“%(value)s” is not a valid UUID."),
2615     }
2616     description = _("Universally unique identifier")
2617     empty_strings_allowed = False
2618 
2619     def __init__(self, verbose_name=None, **kwargs):
2620         kwargs["max_length"] = 32
2621         super().__init__(verbose_name, **kwargs)
2622 
2623     def deconstruct(self):
2624         name, path, args, kwargs = super().deconstruct()
2625         del kwargs["max_length"]
2626         return name, path, args, kwargs
2627 
2628     def get_internal_type(self):
2629         return "UUIDField"
2630 
2631     def get_prep_value(self, value):
2632         value = super().get_prep_value(value)
2633         return self.to_python(value)
2634 
2635     def get_db_prep_value(self, value, connection, prepared=False):
2636         if value is None:
2637             return None
2638         if not isinstance(value, uuid.UUID):
2639             value = self.to_python(value)
2640 
2641         if connection.features.has_native_uuid_field:
2642             return value
2643         return value.hex
2644 
2645     def to_python(self, value):
2646         if value is not None and not isinstance(value, uuid.UUID):
2647             input_form = "int" if isinstance(value, int) else "hex"
2648             try:
2649                 return uuid.UUID(**{input_form: value})
2650             except (AttributeError, ValueError):
2651                 raise exceptions.ValidationError(
2652                     self.error_messages["invalid"],
2653                     code="invalid",
2654                     params={"value": value},
2655                 )
2656         return value
2657 
2658     def formfield(self, **kwargs):
2659         return super().formfield(
2660             **{
2661                 "form_class": forms.UUIDField,
2662                 **kwargs,
2663             }
2664         )
2665 
2666 
2667 class AutoFieldMixin:
2668     db_returning = True
2669 
2670     def __init__(self, *args, **kwargs):
2671         kwargs["blank"] = True
2672         super().__init__(*args, **kwargs)
2673 
2674     def check(self, **kwargs):
2675         return [
2676             *super().check(**kwargs),
2677             *self._check_primary_key(),
2678         ]
2679 
2680     def _check_primary_key(self):
2681         if not self.primary_key:
2682             return [
2683                 checks.Error(
2684                     "AutoFields must set primary_key=True.",
2685                     obj=self,
2686                     id="fields.E100",
2687                 ),
2688             ]
2689         else:
2690             return []
2691 
2692     def deconstruct(self):
2693         name, path, args, kwargs = super().deconstruct()
2694         del kwargs["blank"]
2695         kwargs["primary_key"] = True
2696         return name, path, args, kwargs
2697 
2698     def validate(self, value, model_instance):
2699         pass
2700 
2701     def get_db_prep_value(self, value, connection, prepared=False):
2702         if not prepared:
2703             value = self.get_prep_value(value)
2704             value = connection.ops.validate_autopk_value(value)
2705         return value
2706 
2707     def contribute_to_class(self, cls, name, **kwargs):
2708         if cls._meta.auto_field:
2709             raise ValueError(
2710                 "Model %s can't have more than one auto-generated field."
2711                 % cls._meta.label
2712             )
2713         super().contribute_to_class(cls, name, **kwargs)
2714         cls._meta.auto_field = self
2715 
2716     def formfield(self, **kwargs):
2717         return None
2718 
2719 
2720 class AutoFieldMeta(type):
2721     """
2722     Metaclass to maintain backward inheritance compatibility for AutoField.
2723 
2724     It is intended that AutoFieldMixin become public API when it is possible to
2725     create a non-integer automatically-generated field using column defaults
2726     stored in the database.
2727 
2728     In many areas Django also relies on using isinstance() to check for an
2729     automatically-generated field as a subclass of AutoField. A new flag needs
2730     to be implemented on Field to be used instead.
2731 
2732     When these issues have been addressed, this metaclass could be used to
2733     deprecate inheritance from AutoField and use of isinstance() with AutoField
2734     for detecting automatically-generated fields.
2735     """
2736 
2737     @property
2738     def _subclasses(self):
2739         return (BigAutoField, SmallAutoField)
2740 
2741     def __instancecheck__(self, instance):
2742         return isinstance(instance, self._subclasses) or super().__instancecheck__(
2743             instance
2744         )
2745 
2746     def __subclasscheck__(self, subclass):
2747         return issubclass(subclass, self._subclasses) or super().__subclasscheck__(
2748             subclass
2749         )
2750 
2751 
2752 class AutoField(AutoFieldMixin, IntegerField, metaclass=AutoFieldMeta):
2753     def get_internal_type(self):
2754         return "AutoField"
2755 
2756     def rel_db_type(self, connection):
2757         return IntegerField().db_type(connection=connection)
2758 
2759 
2760 class BigAutoField(AutoFieldMixin, BigIntegerField):
2761     def get_internal_type(self):
2762         return "BigAutoField"
2763 
2764     def rel_db_type(self, connection):
2765         return BigIntegerField().db_type(connection=connection)
2766 
2767 
2768 class SmallAutoField(AutoFieldMixin, SmallIntegerField):
2769     def get_internal_type(self):
2770         return "SmallAutoField"
2771 
2772     def rel_db_type(self, connection):
2773         return SmallIntegerField().db_type(connection=connection)

</code><intended_behavior>Ensure consistent handling and documentation around `db_collation` attribute, so it is clear how it should be propagated in the context of model relationships and migrations.</intended_behavior>]
2025-10-17 23:31:27.484 | INFO     | Overall retry 0 succeeded; ending workflow
2025-10-17 23:31:27.484 | INFO     | Search-only: skipping patch selection
2025-10-17 23:31:27.653 | INFO     | Task django__django-15629 completed successfully.
2025-10-17 23:31:27.654 | INFO     | No patch generated. You can try running ACR again.
