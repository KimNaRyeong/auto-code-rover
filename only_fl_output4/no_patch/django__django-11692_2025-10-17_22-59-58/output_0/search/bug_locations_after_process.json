[
    {
        "rel_file_path": "django/db/models/expressions.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__4.1/django/db/models/expressions.py",
        "start": 1,
        "end": 1492,
        "class_name": null,
        "method_name": null,
        "code": "1 import copy\n2 import datetime\n3 import functools\n4 import inspect\n5 from decimal import Decimal\n6 from uuid import UUID\n7 \n8 from django.core.exceptions import EmptyResultSet, FieldError\n9 from django.db import DatabaseError, NotSupportedError, connection\n10 from django.db.models import fields\n11 from django.db.models.constants import LOOKUP_SEP\n12 from django.db.models.query_utils import Q\n13 from django.utils.deconstruct import deconstructible\n14 from django.utils.functional import cached_property\n15 from django.utils.hashable import make_hashable\n16 \n17 \n18 class SQLiteNumericMixin:\n19     \"\"\"\n20     Some expressions with output_field=DecimalField() must be cast to\n21     numeric to be properly filtered.\n22     \"\"\"\n23     def as_sqlite(self, compiler, connection, **extra_context):\n24         sql, params = self.as_sql(compiler, connection, **extra_context)\n25         try:\n26             if self.output_field.get_internal_type() == 'DecimalField':\n27                 sql = 'CAST(%s AS NUMERIC)' % sql\n28         except FieldError:\n29             pass\n30         return sql, params\n31 \n32 \n33 class Combinable:\n34     \"\"\"\n35     Provide the ability to combine one or two objects with\n36     some connector. For example F('foo') + F('bar').\n37     \"\"\"\n38 \n39     # Arithmetic connectors\n40     ADD = '+'\n41     SUB = '-'\n42     MUL = '*'\n43     DIV = '/'\n44     POW = '^'\n45     # The following is a quoted % operator - it is quoted because it can be\n46     # used in strings that also have parameter substitution.\n47     MOD = '%%'\n48 \n49     # Bitwise operators - note that these are generated by .bitand()\n50     # and .bitor(), the '&' and '|' are reserved for boolean operator\n51     # usage.\n52     BITAND = '&'\n53     BITOR = '|'\n54     BITLEFTSHIFT = '<<'\n55     BITRIGHTSHIFT = '>>'\n56     BITXOR = '#'\n57 \n58     def _combine(self, other, connector, reversed):\n59         if not hasattr(other, 'resolve_expression'):\n60             # everything must be resolvable to an expression\n61             other = Value(other)\n62 \n63         if reversed:\n64             return CombinedExpression(other, connector, self)\n65         return CombinedExpression(self, connector, other)\n66 \n67     #############\n68     # OPERATORS #\n69     #############\n70 \n71     def __neg__(self):\n72         return self._combine(-1, self.MUL, False)\n73 \n74     def __add__(self, other):\n75         return self._combine(other, self.ADD, False)\n76 \n77     def __sub__(self, other):\n78         return self._combine(other, self.SUB, False)\n79 \n80     def __mul__(self, other):\n81         return self._combine(other, self.MUL, False)\n82 \n83     def __truediv__(self, other):\n84         return self._combine(other, self.DIV, False)\n85 \n86     def __mod__(self, other):\n87         return self._combine(other, self.MOD, False)\n88 \n89     def __pow__(self, other):\n90         return self._combine(other, self.POW, False)\n91 \n92     def __and__(self, other):\n93         if getattr(self, 'conditional', False) and getattr(other, 'conditional', False):\n94             return Q(self) & Q(other)\n95         raise NotImplementedError(\n96             \"Use .bitand() and .bitor() for bitwise logical operations.\"\n97         )\n98 \n99     def bitand(self, other):\n100         return self._combine(other, self.BITAND, False)\n101 \n102     def bitleftshift(self, other):\n103         return self._combine(other, self.BITLEFTSHIFT, False)\n104 \n105     def bitrightshift(self, other):\n106         return self._combine(other, self.BITRIGHTSHIFT, False)\n107 \n108     def bitxor(self, other):\n109         return self._combine(other, self.BITXOR, False)\n110 \n111     def __or__(self, other):\n112         if getattr(self, 'conditional', False) and getattr(other, 'conditional', False):\n113             return Q(self) | Q(other)\n114         raise NotImplementedError(\n115             \"Use .bitand() and .bitor() for bitwise logical operations.\"\n116         )\n117 \n118     def bitor(self, other):\n119         return self._combine(other, self.BITOR, False)\n120 \n121     def __radd__(self, other):\n122         return self._combine(other, self.ADD, True)\n123 \n124     def __rsub__(self, other):\n125         return self._combine(other, self.SUB, True)\n126 \n127     def __rmul__(self, other):\n128         return self._combine(other, self.MUL, True)\n129 \n130     def __rtruediv__(self, other):\n131         return self._combine(other, self.DIV, True)\n132 \n133     def __rmod__(self, other):\n134         return self._combine(other, self.MOD, True)\n135 \n136     def __rpow__(self, other):\n137         return self._combine(other, self.POW, True)\n138 \n139     def __rand__(self, other):\n140         raise NotImplementedError(\n141             \"Use .bitand() and .bitor() for bitwise logical operations.\"\n142         )\n143 \n144     def __ror__(self, other):\n145         raise NotImplementedError(\n146             \"Use .bitand() and .bitor() for bitwise logical operations.\"\n147         )\n148 \n149 \n150 class BaseExpression:\n151     \"\"\"Base class for all query expressions.\"\"\"\n152 \n153     empty_result_set_value = NotImplemented\n154     # aggregate specific fields\n155     is_summary = False\n156     _output_field_resolved_to_none = False\n157     # Can the expression be used in a WHERE clause?\n158     filterable = True\n159     # Can the expression can be used as a source expression in Window?\n160     window_compatible = False\n161 \n162     def __init__(self, output_field=None):\n163         if output_field is not None:\n164             self.output_field = output_field\n165 \n166     def __getstate__(self):\n167         state = self.__dict__.copy()\n168         state.pop('convert_value', None)\n169         return state\n170 \n171     def get_db_converters(self, connection):\n172         return (\n173             []\n174             if self.convert_value is self._convert_value_noop else\n175             [self.convert_value]\n176         ) + self.output_field.get_db_converters(connection)\n177 \n178     def get_source_expressions(self):\n179         return []\n180 \n181     def set_source_expressions(self, exprs):\n182         assert not exprs\n183 \n184     def _parse_expressions(self, *expressions):\n185         return [\n186             arg if hasattr(arg, 'resolve_expression') else (\n187                 F(arg) if isinstance(arg, str) else Value(arg)\n188             ) for arg in expressions\n189         ]\n190 \n191     def as_sql(self, compiler, connection):\n192         \"\"\"\n193         Responsible for returning a (sql, [params]) tuple to be included\n194         in the current query.\n195 \n196         Different backends can provide their own implementation, by\n197         providing an `as_{vendor}` method and patching the Expression:\n198 \n199         ```\n200         def override_as_sql(self, compiler, connection):\n201             # custom logic\n202             return super().as_sql(compiler, connection)\n203         setattr(Expression, 'as_' + connection.vendor, override_as_sql)\n204         ```\n205 \n206         Arguments:\n207          * compiler: the query compiler responsible for generating the query.\n208            Must have a compile method, returning a (sql, [params]) tuple.\n209            Calling compiler(value) will return a quoted `value`.\n210 \n211          * connection: the database connection used for the current query.\n212 \n213         Return: (sql, params)\n214           Where `sql` is a string containing ordered sql parameters to be\n215           replaced with the elements of the list `params`.\n216         \"\"\"\n217         raise NotImplementedError(\"Subclasses must implement as_sql()\")\n218 \n219     @cached_property\n220     def contains_aggregate(self):\n221         return any(expr and expr.contains_aggregate for expr in self.get_source_expressions())\n222 \n223     @cached_property\n224     def contains_over_clause(self):\n225         return any(expr and expr.contains_over_clause for expr in self.get_source_expressions())\n226 \n227     @cached_property\n228     def contains_column_references(self):\n229         return any(expr and expr.contains_column_references for expr in self.get_source_expressions())\n230 \n231     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n232         \"\"\"\n233         Provide the chance to do any preprocessing or validation before being\n234         added to the query.\n235 \n236         Arguments:\n237          * query: the backend query implementation\n238          * allow_joins: boolean allowing or denying use of joins\n239            in this query\n240          * reuse: a set of reusable joins for multijoins\n241          * summarize: a terminal aggregate clause\n242          * for_save: whether this expression about to be used in a save or update\n243 \n244         Return: an Expression to be added to the query.\n245         \"\"\"\n246         c = self.copy()\n247         c.is_summary = summarize\n248         c.set_source_expressions([\n249             expr.resolve_expression(query, allow_joins, reuse, summarize)\n250             if expr else None\n251             for expr in c.get_source_expressions()\n252         ])\n253         return c\n254 \n255     @property\n256     def conditional(self):\n257         return isinstance(self.output_field, fields.BooleanField)\n258 \n259     @property\n260     def field(self):\n261         return self.output_field\n262 \n263     @cached_property\n264     def output_field(self):\n265         \"\"\"Return the output type of this expressions.\"\"\"\n266         output_field = self._resolve_output_field()\n267         if output_field is None:\n268             self._output_field_resolved_to_none = True\n269             raise FieldError('Cannot resolve expression type, unknown output_field')\n270         return output_field\n271 \n272     @cached_property\n273     def _output_field_or_none(self):\n274         \"\"\"\n275         Return the output field of this expression, or None if\n276         _resolve_output_field() didn't return an output type.\n277         \"\"\"\n278         try:\n279             return self.output_field\n280         except FieldError:\n281             if not self._output_field_resolved_to_none:\n282                 raise\n283 \n284     def _resolve_output_field(self):\n285         \"\"\"\n286         Attempt to infer the output type of the expression. If the output\n287         fields of all source fields match then, simply infer the same type\n288         here. This isn't always correct, but it makes sense most of the time.\n289 \n290         Consider the difference between `2 + 2` and `2 / 3`. Inferring\n291         the type here is a convenience for the common case. The user should\n292         supply their own output_field with more complex computations.\n293 \n294         If a source's output field resolves to None, exclude it from this check.\n295         If all sources are None, then an error is raised higher up the stack in\n296         the output_field property.\n297         \"\"\"\n298         sources_iter = (source for source in self.get_source_fields() if source is not None)\n299         for output_field in sources_iter:\n300             for source in sources_iter:\n301                 if not isinstance(output_field, source.__class__):\n302                     raise FieldError(\n303                         'Expression contains mixed types: %s, %s. You must '\n304                         'set output_field.' % (\n305                             output_field.__class__.__name__,\n306                             source.__class__.__name__,\n307                         )\n308                     )\n309             return output_field\n310 \n311     @staticmethod\n312     def _convert_value_noop(value, expression, connection):\n313         return value\n314 \n315     @cached_property\n316     def convert_value(self):\n317         \"\"\"\n318         Expressions provide their own converters because users have the option\n319         of manually specifying the output_field which may be a different type\n320         from the one the database returns.\n321         \"\"\"\n322         field = self.output_field\n323         internal_type = field.get_internal_type()\n324         if internal_type == 'FloatField':\n325             return lambda value, expression, connection: None if value is None else float(value)\n326         elif internal_type.endswith('IntegerField'):\n327             return lambda value, expression, connection: None if value is None else int(value)\n328         elif internal_type == 'DecimalField':\n329             return lambda value, expression, connection: None if value is None else Decimal(value)\n330         return self._convert_value_noop\n331 \n332     def get_lookup(self, lookup):\n333         return self.output_field.get_lookup(lookup)\n334 \n335     def get_transform(self, name):\n336         return self.output_field.get_transform(name)\n337 \n338     def relabeled_clone(self, change_map):\n339         clone = self.copy()\n340         clone.set_source_expressions([\n341             e.relabeled_clone(change_map) if e is not None else None\n342             for e in self.get_source_expressions()\n343         ])\n344         return clone\n345 \n346     def copy(self):\n347         return copy.copy(self)\n348 \n349     def get_group_by_cols(self, alias=None):\n350         if not self.contains_aggregate:\n351             return [self]\n352         cols = []\n353         for source in self.get_source_expressions():\n354             cols.extend(source.get_group_by_cols())\n355         return cols\n356 \n357     def get_source_fields(self):\n358         \"\"\"Return the underlying field types used by this aggregate.\"\"\"\n359         return [e._output_field_or_none for e in self.get_source_expressions()]\n360 \n361     def asc(self, **kwargs):\n362         return OrderBy(self, **kwargs)\n363 \n364     def desc(self, **kwargs):\n365         return OrderBy(self, descending=True, **kwargs)\n366 \n367     def reverse_ordering(self):\n368         return self\n369 \n370     def flatten(self):\n371         \"\"\"\n372         Recursively yield this expression and all subexpressions, in\n373         depth-first order.\n374         \"\"\"\n375         yield self\n376         for expr in self.get_source_expressions():\n377             if expr:\n378                 if hasattr(expr, 'flatten'):\n379                     yield from expr.flatten()\n380                 else:\n381                     yield expr\n382 \n383     def select_format(self, compiler, sql, params):\n384         \"\"\"\n385         Custom format for select clauses. For example, EXISTS expressions need\n386         to be wrapped in CASE WHEN on Oracle.\n387         \"\"\"\n388         if hasattr(self.output_field, 'select_format'):\n389             return self.output_field.select_format(compiler, sql, params)\n390         return sql, params\n391 \n392 \n393 @deconstructible\n394 class Expression(BaseExpression, Combinable):\n395     \"\"\"An expression that can be combined with other expressions.\"\"\"\n396 \n397     @cached_property\n398     def identity(self):\n399         constructor_signature = inspect.signature(self.__init__)\n400         args, kwargs = self._constructor_args\n401         signature = constructor_signature.bind_partial(*args, **kwargs)\n402         signature.apply_defaults()\n403         arguments = signature.arguments.items()\n404         identity = [self.__class__]\n405         for arg, value in arguments:\n406             if isinstance(value, fields.Field):\n407                 if value.name and value.model:\n408                     value = (value.model._meta.label, value.name)\n409                 else:\n410                     value = type(value)\n411             else:\n412                 value = make_hashable(value)\n413             identity.append((arg, value))\n414         return tuple(identity)\n415 \n416     def __eq__(self, other):\n417         if not isinstance(other, Expression):\n418             return NotImplemented\n419         return other.identity == self.identity\n420 \n421     def __hash__(self):\n422         return hash(self.identity)\n423 \n424 \n425 _connector_combinators = {\n426     connector: [\n427         (fields.IntegerField, fields.IntegerField, fields.IntegerField),\n428         (fields.IntegerField, fields.DecimalField, fields.DecimalField),\n429         (fields.DecimalField, fields.IntegerField, fields.DecimalField),\n430         (fields.IntegerField, fields.FloatField, fields.FloatField),\n431         (fields.FloatField, fields.IntegerField, fields.FloatField),\n432     ]\n433     for connector in (Combinable.ADD, Combinable.SUB, Combinable.MUL, Combinable.DIV)\n434 }\n435 \n436 \n437 @functools.lru_cache(maxsize=128)\n438 def _resolve_combined_type(connector, lhs_type, rhs_type):\n439     combinators = _connector_combinators.get(connector, ())\n440     for combinator_lhs_type, combinator_rhs_type, combined_type in combinators:\n441         if issubclass(lhs_type, combinator_lhs_type) and issubclass(rhs_type, combinator_rhs_type):\n442             return combined_type\n443 \n444 \n445 class CombinedExpression(SQLiteNumericMixin, Expression):\n446 \n447     def __init__(self, lhs, connector, rhs, output_field=None):\n448         super().__init__(output_field=output_field)\n449         self.connector = connector\n450         self.lhs = lhs\n451         self.rhs = rhs\n452 \n453     def __repr__(self):\n454         return \"<{}: {}>\".format(self.__class__.__name__, self)\n455 \n456     def __str__(self):\n457         return \"{} {} {}\".format(self.lhs, self.connector, self.rhs)\n458 \n459     def get_source_expressions(self):\n460         return [self.lhs, self.rhs]\n461 \n462     def set_source_expressions(self, exprs):\n463         self.lhs, self.rhs = exprs\n464 \n465     def _resolve_output_field(self):\n466         try:\n467             return super()._resolve_output_field()\n468         except FieldError:\n469             combined_type = _resolve_combined_type(\n470                 self.connector,\n471                 type(self.lhs.output_field),\n472                 type(self.rhs.output_field),\n473             )\n474             if combined_type is None:\n475                 raise\n476             return combined_type()\n477 \n478     def as_sql(self, compiler, connection):\n479         expressions = []\n480         expression_params = []\n481         sql, params = compiler.compile(self.lhs)\n482         expressions.append(sql)\n483         expression_params.extend(params)\n484         sql, params = compiler.compile(self.rhs)\n485         expressions.append(sql)\n486         expression_params.extend(params)\n487         # order of precedence\n488         expression_wrapper = '(%s)'\n489         sql = connection.ops.combine_expression(self.connector, expressions)\n490         return expression_wrapper % sql, expression_params\n491 \n492     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n493         lhs = self.lhs.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n494         rhs = self.rhs.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n495         if not isinstance(self, (DurationExpression, TemporalSubtraction)):\n496             try:\n497                 lhs_type = lhs.output_field.get_internal_type()\n498             except (AttributeError, FieldError):\n499                 lhs_type = None\n500             try:\n501                 rhs_type = rhs.output_field.get_internal_type()\n502             except (AttributeError, FieldError):\n503                 rhs_type = None\n504             if 'DurationField' in {lhs_type, rhs_type} and lhs_type != rhs_type:\n505                 return DurationExpression(self.lhs, self.connector, self.rhs).resolve_expression(\n506                     query, allow_joins, reuse, summarize, for_save,\n507                 )\n508             datetime_fields = {'DateField', 'DateTimeField', 'TimeField'}\n509             if self.connector == self.SUB and lhs_type in datetime_fields and lhs_type == rhs_type:\n510                 return TemporalSubtraction(self.lhs, self.rhs).resolve_expression(\n511                     query, allow_joins, reuse, summarize, for_save,\n512                 )\n513         c = self.copy()\n514         c.is_summary = summarize\n515         c.lhs = lhs\n516         c.rhs = rhs\n517         return c\n518 \n519 \n520 class DurationExpression(CombinedExpression):\n521     def compile(self, side, compiler, connection):\n522         try:\n523             output = side.output_field\n524         except FieldError:\n525             pass\n526         else:\n527             if output.get_internal_type() == 'DurationField':\n528                 sql, params = compiler.compile(side)\n529                 return connection.ops.format_for_duration_arithmetic(sql), params\n530         return compiler.compile(side)\n531 \n532     def as_sql(self, compiler, connection):\n533         if connection.features.has_native_duration_field:\n534             return super().as_sql(compiler, connection)\n535         connection.ops.check_expression_support(self)\n536         expressions = []\n537         expression_params = []\n538         sql, params = self.compile(self.lhs, compiler, connection)\n539         expressions.append(sql)\n540         expression_params.extend(params)\n541         sql, params = self.compile(self.rhs, compiler, connection)\n542         expressions.append(sql)\n543         expression_params.extend(params)\n544         # order of precedence\n545         expression_wrapper = '(%s)'\n546         sql = connection.ops.combine_duration_expression(self.connector, expressions)\n547         return expression_wrapper % sql, expression_params\n548 \n549     def as_sqlite(self, compiler, connection, **extra_context):\n550         sql, params = self.as_sql(compiler, connection, **extra_context)\n551         if self.connector in {Combinable.MUL, Combinable.DIV}:\n552             try:\n553                 lhs_type = self.lhs.output_field.get_internal_type()\n554                 rhs_type = self.rhs.output_field.get_internal_type()\n555             except (AttributeError, FieldError):\n556                 pass\n557             else:\n558                 allowed_fields = {\n559                     'DecimalField', 'DurationField', 'FloatField', 'IntegerField',\n560                 }\n561                 if lhs_type not in allowed_fields or rhs_type not in allowed_fields:\n562                     raise DatabaseError(\n563                         f'Invalid arguments for operator {self.connector}.'\n564                     )\n565         return sql, params\n566 \n567 \n568 class TemporalSubtraction(CombinedExpression):\n569     output_field = fields.DurationField()\n570 \n571     def __init__(self, lhs, rhs):\n572         super().__init__(lhs, self.SUB, rhs)\n573 \n574     def as_sql(self, compiler, connection):\n575         connection.ops.check_expression_support(self)\n576         lhs = compiler.compile(self.lhs)\n577         rhs = compiler.compile(self.rhs)\n578         return connection.ops.subtract_temporals(self.lhs.output_field.get_internal_type(), lhs, rhs)\n579 \n580 \n581 @deconstructible(path='django.db.models.F')\n582 class F(Combinable):\n583     \"\"\"An object capable of resolving references to existing query objects.\"\"\"\n584 \n585     def __init__(self, name):\n586         \"\"\"\n587         Arguments:\n588          * name: the name of the field this expression references\n589         \"\"\"\n590         self.name = name\n591 \n592     def __repr__(self):\n593         return \"{}({})\".format(self.__class__.__name__, self.name)\n594 \n595     def resolve_expression(self, query=None, allow_joins=True, reuse=None,\n596                            summarize=False, for_save=False):\n597         return query.resolve_ref(self.name, allow_joins, reuse, summarize)\n598 \n599     def asc(self, **kwargs):\n600         return OrderBy(self, **kwargs)\n601 \n602     def desc(self, **kwargs):\n603         return OrderBy(self, descending=True, **kwargs)\n604 \n605     def __eq__(self, other):\n606         return self.__class__ == other.__class__ and self.name == other.name\n607 \n608     def __hash__(self):\n609         return hash(self.name)\n610 \n611 \n612 class ResolvedOuterRef(F):\n613     \"\"\"\n614     An object that contains a reference to an outer query.\n615 \n616     In this case, the reference to the outer query has been resolved because\n617     the inner query has been used as a subquery.\n618     \"\"\"\n619     contains_aggregate = False\n620 \n621     def as_sql(self, *args, **kwargs):\n622         raise ValueError(\n623             'This queryset contains a reference to an outer query and may '\n624             'only be used in a subquery.'\n625         )\n626 \n627     def resolve_expression(self, *args, **kwargs):\n628         col = super().resolve_expression(*args, **kwargs)\n629         # FIXME: Rename possibly_multivalued to multivalued and fix detection\n630         # for non-multivalued JOINs (e.g. foreign key fields). This should take\n631         # into account\u00a0only many-to-many and one-to-many relationships.\n632         col.possibly_multivalued = LOOKUP_SEP in self.name\n633         return col\n634 \n635     def relabeled_clone(self, relabels):\n636         return self\n637 \n638     def get_group_by_cols(self, alias=None):\n639         return []\n640 \n641 \n642 class OuterRef(F):\n643     contains_aggregate = False\n644 \n645     def resolve_expression(self, *args, **kwargs):\n646         if isinstance(self.name, self.__class__):\n647             return self.name\n648         return ResolvedOuterRef(self.name)\n649 \n650     def relabeled_clone(self, relabels):\n651         return self\n652 \n653 \n654 @deconstructible(path='django.db.models.Func')\n655 class Func(SQLiteNumericMixin, Expression):\n656     \"\"\"An SQL function call.\"\"\"\n657     function = None\n658     template = '%(function)s(%(expressions)s)'\n659     arg_joiner = ', '\n660     arity = None  # The number of arguments the function accepts.\n661 \n662     def __init__(self, *expressions, output_field=None, **extra):\n663         if self.arity is not None and len(expressions) != self.arity:\n664             raise TypeError(\n665                 \"'%s' takes exactly %s %s (%s given)\" % (\n666                     self.__class__.__name__,\n667                     self.arity,\n668                     \"argument\" if self.arity == 1 else \"arguments\",\n669                     len(expressions),\n670                 )\n671             )\n672         super().__init__(output_field=output_field)\n673         self.source_expressions = self._parse_expressions(*expressions)\n674         self.extra = extra\n675 \n676     def __repr__(self):\n677         args = self.arg_joiner.join(str(arg) for arg in self.source_expressions)\n678         extra = {**self.extra, **self._get_repr_options()}\n679         if extra:\n680             extra = ', '.join(str(key) + '=' + str(val) for key, val in sorted(extra.items()))\n681             return \"{}({}, {})\".format(self.__class__.__name__, args, extra)\n682         return \"{}({})\".format(self.__class__.__name__, args)\n683 \n684     def _get_repr_options(self):\n685         \"\"\"Return a dict of extra __init__() options to include in the repr.\"\"\"\n686         return {}\n687 \n688     def get_source_expressions(self):\n689         return self.source_expressions\n690 \n691     def set_source_expressions(self, exprs):\n692         self.source_expressions = exprs\n693 \n694     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n695         c = self.copy()\n696         c.is_summary = summarize\n697         for pos, arg in enumerate(c.source_expressions):\n698             c.source_expressions[pos] = arg.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n699         return c\n700 \n701     def as_sql(self, compiler, connection, function=None, template=None, arg_joiner=None, **extra_context):\n702         connection.ops.check_expression_support(self)\n703         sql_parts = []\n704         params = []\n705         for arg in self.source_expressions:\n706             try:\n707                 arg_sql, arg_params = compiler.compile(arg)\n708             except EmptyResultSet:\n709                 empty_result_set_value = getattr(arg, 'empty_result_set_value', NotImplemented)\n710                 if empty_result_set_value is NotImplemented:\n711                     raise\n712                 arg_sql, arg_params = compiler.compile(Value(empty_result_set_value))\n713             sql_parts.append(arg_sql)\n714             params.extend(arg_params)\n715         data = {**self.extra, **extra_context}\n716         # Use the first supplied value in this order: the parameter to this\n717         # method, a value supplied in __init__()'s **extra (the value in\n718         # `data`), or the value defined on the class.\n719         if function is not None:\n720             data['function'] = function\n721         else:\n722             data.setdefault('function', self.function)\n723         template = template or data.get('template', self.template)\n724         arg_joiner = arg_joiner or data.get('arg_joiner', self.arg_joiner)\n725         data['expressions'] = data['field'] = arg_joiner.join(sql_parts)\n726         return template % data, params\n727 \n728     def copy(self):\n729         copy = super().copy()\n730         copy.source_expressions = self.source_expressions[:]\n731         copy.extra = self.extra.copy()\n732         return copy\n733 \n734 \n735 @deconstructible(path='django.db.models.Value')\n736 class Value(SQLiteNumericMixin, Expression):\n737     \"\"\"Represent a wrapped value as a node within an expression.\"\"\"\n738     # Provide a default value for `for_save` in order to allow unresolved\n739     # instances to be compiled until a decision is taken in #25425.\n740     for_save = False\n741 \n742     def __init__(self, value, output_field=None):\n743         \"\"\"\n744         Arguments:\n745          * value: the value this expression represents. The value will be\n746            added into the sql parameter list and properly quoted.\n747 \n748          * output_field: an instance of the model field type that this\n749            expression will return, such as IntegerField() or CharField().\n750         \"\"\"\n751         super().__init__(output_field=output_field)\n752         self.value = value\n753 \n754     def __repr__(self):\n755         return f'{self.__class__.__name__}({self.value!r})'\n756 \n757     def as_sql(self, compiler, connection):\n758         connection.ops.check_expression_support(self)\n759         val = self.value\n760         output_field = self._output_field_or_none\n761         if output_field is not None:\n762             if self.for_save:\n763                 val = output_field.get_db_prep_save(val, connection=connection)\n764             else:\n765                 val = output_field.get_db_prep_value(val, connection=connection)\n766             if hasattr(output_field, 'get_placeholder'):\n767                 return output_field.get_placeholder(val, compiler, connection), [val]\n768         if val is None:\n769             # cx_Oracle does not always convert None to the appropriate\n770             # NULL type (like in case expressions using numbers), so we\n771             # use a literal SQL NULL\n772             return 'NULL', []\n773         return '%s', [val]\n774 \n775     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n776         c = super().resolve_expression(query, allow_joins, reuse, summarize, for_save)\n777         c.for_save = for_save\n778         return c\n779 \n780     def get_group_by_cols(self, alias=None):\n781         return []\n782 \n783     def _resolve_output_field(self):\n784         if isinstance(self.value, str):\n785             return fields.CharField()\n786         if isinstance(self.value, bool):\n787             return fields.BooleanField()\n788         if isinstance(self.value, int):\n789             return fields.IntegerField()\n790         if isinstance(self.value, float):\n791             return fields.FloatField()\n792         if isinstance(self.value, datetime.datetime):\n793             return fields.DateTimeField()\n794         if isinstance(self.value, datetime.date):\n795             return fields.DateField()\n796         if isinstance(self.value, datetime.time):\n797             return fields.TimeField()\n798         if isinstance(self.value, datetime.timedelta):\n799             return fields.DurationField()\n800         if isinstance(self.value, Decimal):\n801             return fields.DecimalField()\n802         if isinstance(self.value, bytes):\n803             return fields.BinaryField()\n804         if isinstance(self.value, UUID):\n805             return fields.UUIDField()\n806 \n807     @property\n808     def empty_result_set_value(self):\n809         return self.value\n810 \n811 \n812 class RawSQL(Expression):\n813     def __init__(self, sql, params, output_field=None):\n814         if output_field is None:\n815             output_field = fields.Field()\n816         self.sql, self.params = sql, params\n817         super().__init__(output_field=output_field)\n818 \n819     def __repr__(self):\n820         return \"{}({}, {})\".format(self.__class__.__name__, self.sql, self.params)\n821 \n822     def as_sql(self, compiler, connection):\n823         return '(%s)' % self.sql, self.params\n824 \n825     def get_group_by_cols(self, alias=None):\n826         return [self]\n827 \n828     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n829         # Resolve parents fields used in raw SQL.\n830         for parent in query.model._meta.get_parent_list():\n831             for parent_field in parent._meta.local_fields:\n832                 _, column_name = parent_field.get_attname_column()\n833                 if column_name.lower() in self.sql.lower():\n834                     query.resolve_ref(parent_field.name, allow_joins, reuse, summarize)\n835                     break\n836         return super().resolve_expression(query, allow_joins, reuse, summarize, for_save)\n837 \n838 \n839 class Star(Expression):\n840     def __repr__(self):\n841         return \"'*'\"\n842 \n843     def as_sql(self, compiler, connection):\n844         return '*', []\n845 \n846 \n847 class Col(Expression):\n848 \n849     contains_column_references = True\n850     possibly_multivalued = False\n851 \n852     def __init__(self, alias, target, output_field=None):\n853         if output_field is None:\n854             output_field = target\n855         super().__init__(output_field=output_field)\n856         self.alias, self.target = alias, target\n857 \n858     def __repr__(self):\n859         alias, target = self.alias, self.target\n860         identifiers = (alias, str(target)) if alias else (str(target),)\n861         return '{}({})'.format(self.__class__.__name__, ', '.join(identifiers))\n862 \n863     def as_sql(self, compiler, connection):\n864         alias, column = self.alias, self.target.column\n865         identifiers = (alias, column) if alias else (column,)\n866         sql = '.'.join(map(compiler.quote_name_unless_alias, identifiers))\n867         return sql, []\n868 \n869     def relabeled_clone(self, relabels):\n870         if self.alias is None:\n871             return self\n872         return self.__class__(relabels.get(self.alias, self.alias), self.target, self.output_field)\n873 \n874     def get_group_by_cols(self, alias=None):\n875         return [self]\n876 \n877     def get_db_converters(self, connection):\n878         if self.target == self.output_field:\n879             return self.output_field.get_db_converters(connection)\n880         return (self.output_field.get_db_converters(connection) +\n881                 self.target.get_db_converters(connection))\n882 \n883 \n884 class Ref(Expression):\n885     \"\"\"\n886     Reference to column alias of the query. For example, Ref('sum_cost') in\n887     qs.annotate(sum_cost=Sum('cost')) query.\n888     \"\"\"\n889     def __init__(self, refs, source):\n890         super().__init__()\n891         self.refs, self.source = refs, source\n892 \n893     def __repr__(self):\n894         return \"{}({}, {})\".format(self.__class__.__name__, self.refs, self.source)\n895 \n896     def get_source_expressions(self):\n897         return [self.source]\n898 \n899     def set_source_expressions(self, exprs):\n900         self.source, = exprs\n901 \n902     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n903         # The sub-expression `source` has already been resolved, as this is\n904         # just a reference to the name of `source`.\n905         return self\n906 \n907     def relabeled_clone(self, relabels):\n908         return self\n909 \n910     def as_sql(self, compiler, connection):\n911         return connection.ops.quote_name(self.refs), []\n912 \n913     def get_group_by_cols(self, alias=None):\n914         return [self]\n915 \n916 \n917 class ExpressionList(Func):\n918     \"\"\"\n919     An expression containing multiple expressions. Can be used to provide a\n920     list of expressions as an argument to another expression, like a partition\n921     clause.\n922     \"\"\"\n923     template = '%(expressions)s'\n924 \n925     def __init__(self, *expressions, **extra):\n926         if not expressions:\n927             raise ValueError('%s requires at least one expression.' % self.__class__.__name__)\n928         super().__init__(*expressions, **extra)\n929 \n930     def __str__(self):\n931         return self.arg_joiner.join(str(arg) for arg in self.source_expressions)\n932 \n933     def as_sqlite(self, compiler, connection, **extra_context):\n934         # Casting to numeric is unnecessary.\n935         return self.as_sql(compiler, connection, **extra_context)\n936 \n937 \n938 class OrderByList(Func):\n939     template = 'ORDER BY %(expressions)s'\n940 \n941     def __init__(self, *expressions, **extra):\n942         expressions = (\n943             (\n944                 OrderBy(F(expr[1:]), descending=True)\n945                 if isinstance(expr, str) and expr[0] == '-'\n946                 else expr\n947             )\n948             for expr in expressions\n949         )\n950         super().__init__(*expressions, **extra)\n951 \n952     def as_sql(self, *args, **kwargs):\n953         if not self.source_expressions:\n954             return '', ()\n955         return super().as_sql(*args, **kwargs)\n956 \n957 \n958 @deconstructible(path='django.db.models.ExpressionWrapper')\n959 class ExpressionWrapper(SQLiteNumericMixin, Expression):\n960     \"\"\"\n961     An expression that can wrap another expression so that it can provide\n962     extra context to the inner expression, such as the output_field.\n963     \"\"\"\n964 \n965     def __init__(self, expression, output_field):\n966         super().__init__(output_field=output_field)\n967         self.expression = expression\n968 \n969     def set_source_expressions(self, exprs):\n970         self.expression = exprs[0]\n971 \n972     def get_source_expressions(self):\n973         return [self.expression]\n974 \n975     def get_group_by_cols(self, alias=None):\n976         if isinstance(self.expression, Expression):\n977             expression = self.expression.copy()\n978             expression.output_field = self.output_field\n979             return expression.get_group_by_cols(alias=alias)\n980         # For non-expressions e.g. an SQL WHERE clause, the entire\n981         # `expression` must be included in the GROUP BY clause.\n982         return super().get_group_by_cols()\n983 \n984     def as_sql(self, compiler, connection):\n985         return compiler.compile(self.expression)\n986 \n987     def __repr__(self):\n988         return \"{}({})\".format(self.__class__.__name__, self.expression)\n989 \n990 \n991 @deconstructible(path='django.db.models.When')\n992 class When(Expression):\n993     template = 'WHEN %(condition)s THEN %(result)s'\n994     # This isn't a complete conditional expression, must be used in Case().\n995     conditional = False\n996 \n997     def __init__(self, condition=None, then=None, **lookups):\n998         if lookups:\n999             if condition is None:\n1000                 condition, lookups = Q(**lookups), None\n1001             elif getattr(condition, 'conditional', False):\n1002                 condition, lookups = Q(condition, **lookups), None\n1003         if condition is None or not getattr(condition, 'conditional', False) or lookups:\n1004             raise TypeError(\n1005                 'When() supports a Q object, a boolean expression, or lookups '\n1006                 'as a condition.'\n1007             )\n1008         if isinstance(condition, Q) and not condition:\n1009             raise ValueError(\"An empty Q() can't be used as a When() condition.\")\n1010         super().__init__(output_field=None)\n1011         self.condition = condition\n1012         self.result = self._parse_expressions(then)[0]\n1013 \n1014     def __str__(self):\n1015         return \"WHEN %r THEN %r\" % (self.condition, self.result)\n1016 \n1017     def __repr__(self):\n1018         return \"<%s: %s>\" % (self.__class__.__name__, self)\n1019 \n1020     def get_source_expressions(self):\n1021         return [self.condition, self.result]\n1022 \n1023     def set_source_expressions(self, exprs):\n1024         self.condition, self.result = exprs\n1025 \n1026     def get_source_fields(self):\n1027         # We're only interested in the fields of the result expressions.\n1028         return [self.result._output_field_or_none]\n1029 \n1030     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n1031         c = self.copy()\n1032         c.is_summary = summarize\n1033         if hasattr(c.condition, 'resolve_expression'):\n1034             c.condition = c.condition.resolve_expression(query, allow_joins, reuse, summarize, False)\n1035         c.result = c.result.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n1036         return c\n1037 \n1038     def as_sql(self, compiler, connection, template=None, **extra_context):\n1039         connection.ops.check_expression_support(self)\n1040         template_params = extra_context\n1041         sql_params = []\n1042         condition_sql, condition_params = compiler.compile(self.condition)\n1043         template_params['condition'] = condition_sql\n1044         sql_params.extend(condition_params)\n1045         result_sql, result_params = compiler.compile(self.result)\n1046         template_params['result'] = result_sql\n1047         sql_params.extend(result_params)\n1048         template = template or self.template\n1049         return template % template_params, sql_params\n1050 \n1051     def get_group_by_cols(self, alias=None):\n1052         # This is not a complete expression and cannot be used in GROUP BY.\n1053         cols = []\n1054         for source in self.get_source_expressions():\n1055             cols.extend(source.get_group_by_cols())\n1056         return cols\n1057 \n1058 \n1059 @deconstructible(path='django.db.models.Case')\n1060 class Case(SQLiteNumericMixin, Expression):\n1061     \"\"\"\n1062     An SQL searched CASE expression:\n1063 \n1064         CASE\n1065             WHEN n > 0\n1066                 THEN 'positive'\n1067             WHEN n < 0\n1068                 THEN 'negative'\n1069             ELSE 'zero'\n1070         END\n1071     \"\"\"\n1072     template = 'CASE %(cases)s ELSE %(default)s END'\n1073     case_joiner = ' '\n1074 \n1075     def __init__(self, *cases, default=None, output_field=None, **extra):\n1076         if not all(isinstance(case, When) for case in cases):\n1077             raise TypeError(\"Positional arguments must all be When objects.\")\n1078         super().__init__(output_field)\n1079         self.cases = list(cases)\n1080         self.default = self._parse_expressions(default)[0]\n1081         self.extra = extra\n1082 \n1083     def __str__(self):\n1084         return \"CASE %s, ELSE %r\" % (', '.join(str(c) for c in self.cases), self.default)\n1085 \n1086     def __repr__(self):\n1087         return \"<%s: %s>\" % (self.__class__.__name__, self)\n1088 \n1089     def get_source_expressions(self):\n1090         return self.cases + [self.default]\n1091 \n1092     def set_source_expressions(self, exprs):\n1093         *self.cases, self.default = exprs\n1094 \n1095     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n1096         c = self.copy()\n1097         c.is_summary = summarize\n1098         for pos, case in enumerate(c.cases):\n1099             c.cases[pos] = case.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n1100         c.default = c.default.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n1101         return c\n1102 \n1103     def copy(self):\n1104         c = super().copy()\n1105         c.cases = c.cases[:]\n1106         return c\n1107 \n1108     def as_sql(self, compiler, connection, template=None, case_joiner=None, **extra_context):\n1109         connection.ops.check_expression_support(self)\n1110         if not self.cases:\n1111             return compiler.compile(self.default)\n1112         template_params = {**self.extra, **extra_context}\n1113         case_parts = []\n1114         sql_params = []\n1115         for case in self.cases:\n1116             try:\n1117                 case_sql, case_params = compiler.compile(case)\n1118             except EmptyResultSet:\n1119                 continue\n1120             case_parts.append(case_sql)\n1121             sql_params.extend(case_params)\n1122         default_sql, default_params = compiler.compile(self.default)\n1123         if not case_parts:\n1124             return default_sql, default_params\n1125         case_joiner = case_joiner or self.case_joiner\n1126         template_params['cases'] = case_joiner.join(case_parts)\n1127         template_params['default'] = default_sql\n1128         sql_params.extend(default_params)\n1129         template = template or template_params.get('template', self.template)\n1130         sql = template % template_params\n1131         if self._output_field_or_none is not None:\n1132             sql = connection.ops.unification_cast_sql(self.output_field) % sql\n1133         return sql, sql_params\n1134 \n1135     def get_group_by_cols(self, alias=None):\n1136         if not self.cases:\n1137             return self.default.get_group_by_cols(alias)\n1138         return super().get_group_by_cols(alias)\n1139 \n1140 \n1141 class Subquery(BaseExpression, Combinable):\n1142     \"\"\"\n1143     An explicit subquery. It may contain OuterRef() references to the outer\n1144     query which will be resolved when it is applied to that query.\n1145     \"\"\"\n1146     template = '(%(subquery)s)'\n1147     contains_aggregate = False\n1148     empty_result_set_value = None\n1149 \n1150     def __init__(self, queryset, output_field=None, **extra):\n1151         # Allow the usage of both QuerySet and sql.Query objects.\n1152         self.query = getattr(queryset, 'query', queryset).clone()\n1153         self.query.subquery = True\n1154         self.extra = extra\n1155         super().__init__(output_field)\n1156 \n1157     def get_source_expressions(self):\n1158         return [self.query]\n1159 \n1160     def set_source_expressions(self, exprs):\n1161         self.query = exprs[0]\n1162 \n1163     def _resolve_output_field(self):\n1164         return self.query.output_field\n1165 \n1166     def copy(self):\n1167         clone = super().copy()\n1168         clone.query = clone.query.clone()\n1169         return clone\n1170 \n1171     @property\n1172     def external_aliases(self):\n1173         return self.query.external_aliases\n1174 \n1175     def get_external_cols(self):\n1176         return self.query.get_external_cols()\n1177 \n1178     def as_sql(self, compiler, connection, template=None, query=None, **extra_context):\n1179         connection.ops.check_expression_support(self)\n1180         template_params = {**self.extra, **extra_context}\n1181         query = query or self.query\n1182         subquery_sql, sql_params = query.as_sql(compiler, connection)\n1183         template_params['subquery'] = subquery_sql[1:-1]\n1184 \n1185         template = template or template_params.get('template', self.template)\n1186         sql = template % template_params\n1187         return sql, sql_params\n1188 \n1189     def get_group_by_cols(self, alias=None):\n1190         # If this expression is referenced by an alias for an explicit GROUP BY\n1191         # through values() a reference to this expression and not the\n1192         # underlying .query must be returned to ensure external column\n1193         # references are not grouped against as well.\n1194         if alias:\n1195             return [Ref(alias, self)]\n1196         return self.query.get_group_by_cols()\n1197 \n1198 \n1199 class Exists(Subquery):\n1200     template = 'EXISTS(%(subquery)s)'\n1201     output_field = fields.BooleanField()\n1202 \n1203     def __init__(self, queryset, negated=False, **kwargs):\n1204         self.negated = negated\n1205         super().__init__(queryset, **kwargs)\n1206 \n1207     def __invert__(self):\n1208         clone = self.copy()\n1209         clone.negated = not self.negated\n1210         return clone\n1211 \n1212     def as_sql(self, compiler, connection, template=None, **extra_context):\n1213         query = self.query.exists(using=connection.alias)\n1214         sql, params = super().as_sql(\n1215             compiler,\n1216             connection,\n1217             template=template,\n1218             query=query,\n1219             **extra_context,\n1220         )\n1221         if self.negated:\n1222             sql = 'NOT {}'.format(sql)\n1223         return sql, params\n1224 \n1225     def select_format(self, compiler, sql, params):\n1226         # Wrap EXISTS() with a CASE WHEN expression if a database backend\n1227         # (e.g. Oracle) doesn't support boolean expression in SELECT or GROUP\n1228         # BY list.\n1229         if not compiler.connection.features.supports_boolean_expr_in_select_clause:\n1230             sql = 'CASE WHEN {} THEN 1 ELSE 0 END'.format(sql)\n1231         return sql, params\n1232 \n1233 \n1234 @deconstructible(path='django.db.models.OrderBy')\n1235 class OrderBy(Expression):\n1236     template = '%(expression)s %(ordering)s'\n1237     conditional = False\n1238 \n1239     def __init__(self, expression, descending=False, nulls_first=False, nulls_last=False):\n1240         if nulls_first and nulls_last:\n1241             raise ValueError('nulls_first and nulls_last are mutually exclusive')\n1242         self.nulls_first = nulls_first\n1243         self.nulls_last = nulls_last\n1244         self.descending = descending\n1245         if not hasattr(expression, 'resolve_expression'):\n1246             raise ValueError('expression must be an expression type')\n1247         self.expression = expression\n1248 \n1249     def __repr__(self):\n1250         return \"{}({}, descending={})\".format(\n1251             self.__class__.__name__, self.expression, self.descending)\n1252 \n1253     def set_source_expressions(self, exprs):\n1254         self.expression = exprs[0]\n1255 \n1256     def get_source_expressions(self):\n1257         return [self.expression]\n1258 \n1259     def as_sql(self, compiler, connection, template=None, **extra_context):\n1260         template = template or self.template\n1261         if connection.features.supports_order_by_nulls_modifier:\n1262             if self.nulls_last:\n1263                 template = '%s NULLS LAST' % template\n1264             elif self.nulls_first:\n1265                 template = '%s NULLS FIRST' % template\n1266         else:\n1267             if self.nulls_last and not (\n1268                 self.descending and connection.features.order_by_nulls_first\n1269             ):\n1270                 template = '%%(expression)s IS NULL, %s' % template\n1271             elif self.nulls_first and not (\n1272                 not self.descending and connection.features.order_by_nulls_first\n1273             ):\n1274                 template = '%%(expression)s IS NOT NULL, %s' % template\n1275         connection.ops.check_expression_support(self)\n1276         expression_sql, params = compiler.compile(self.expression)\n1277         placeholders = {\n1278             'expression': expression_sql,\n1279             'ordering': 'DESC' if self.descending else 'ASC',\n1280             **extra_context,\n1281         }\n1282         params *= template.count('%(expression)s')\n1283         return (template % placeholders).rstrip(), params\n1284 \n1285     def as_oracle(self, compiler, connection):\n1286         # Oracle doesn't allow ORDER BY EXISTS() or filters unless it's wrapped\n1287         # in a CASE WHEN.\n1288         if connection.ops.conditional_expression_supported_in_where_clause(self.expression):\n1289             copy = self.copy()\n1290             copy.expression = Case(\n1291                 When(self.expression, then=True),\n1292                 default=False,\n1293             )\n1294             return copy.as_sql(compiler, connection)\n1295         return self.as_sql(compiler, connection)\n1296 \n1297     def get_group_by_cols(self, alias=None):\n1298         cols = []\n1299         for source in self.get_source_expressions():\n1300             cols.extend(source.get_group_by_cols())\n1301         return cols\n1302 \n1303     def reverse_ordering(self):\n1304         self.descending = not self.descending\n1305         if self.nulls_first or self.nulls_last:\n1306             self.nulls_first = not self.nulls_first\n1307             self.nulls_last = not self.nulls_last\n1308         return self\n1309 \n1310     def asc(self):\n1311         self.descending = False\n1312 \n1313     def desc(self):\n1314         self.descending = True\n1315 \n1316 \n1317 class Window(SQLiteNumericMixin, Expression):\n1318     template = '%(expression)s OVER (%(window)s)'\n1319     # Although the main expression may either be an aggregate or an\n1320     # expression with an aggregate function, the GROUP BY that will\n1321     # be introduced in the query as a result is not desired.\n1322     contains_aggregate = False\n1323     contains_over_clause = True\n1324     filterable = False\n1325 \n1326     def __init__(self, expression, partition_by=None, order_by=None, frame=None, output_field=None):\n1327         self.partition_by = partition_by\n1328         self.order_by = order_by\n1329         self.frame = frame\n1330 \n1331         if not getattr(expression, 'window_compatible', False):\n1332             raise ValueError(\n1333                 \"Expression '%s' isn't compatible with OVER clauses.\" %\n1334                 expression.__class__.__name__\n1335             )\n1336 \n1337         if self.partition_by is not None:\n1338             if not isinstance(self.partition_by, (tuple, list)):\n1339                 self.partition_by = (self.partition_by,)\n1340             self.partition_by = ExpressionList(*self.partition_by)\n1341 \n1342         if self.order_by is not None:\n1343             if isinstance(self.order_by, (list, tuple)):\n1344                 self.order_by = OrderByList(*self.order_by)\n1345             elif isinstance(self.order_by, (BaseExpression, str)):\n1346                 self.order_by = OrderByList(self.order_by)\n1347             else:\n1348                 raise ValueError(\n1349                     'Window.order_by must be either a string reference to a '\n1350                     'field, an expression, or a list or tuple of them.'\n1351                 )\n1352         super().__init__(output_field=output_field)\n1353         self.source_expression = self._parse_expressions(expression)[0]\n1354 \n1355     def _resolve_output_field(self):\n1356         return self.source_expression.output_field\n1357 \n1358     def get_source_expressions(self):\n1359         return [self.source_expression, self.partition_by, self.order_by, self.frame]\n1360 \n1361     def set_source_expressions(self, exprs):\n1362         self.source_expression, self.partition_by, self.order_by, self.frame = exprs\n1363 \n1364     def as_sql(self, compiler, connection, template=None):\n1365         connection.ops.check_expression_support(self)\n1366         if not connection.features.supports_over_clause:\n1367             raise NotSupportedError('This backend does not support window expressions.')\n1368         expr_sql, params = compiler.compile(self.source_expression)\n1369         window_sql, window_params = [], []\n1370 \n1371         if self.partition_by is not None:\n1372             sql_expr, sql_params = self.partition_by.as_sql(\n1373                 compiler=compiler, connection=connection,\n1374                 template='PARTITION BY %(expressions)s',\n1375             )\n1376             window_sql.append(sql_expr)\n1377             window_params.extend(sql_params)\n1378 \n1379         if self.order_by is not None:\n1380             order_sql, order_params = compiler.compile(self.order_by)\n1381             window_sql.append(order_sql)\n1382             window_params.extend(order_params)\n1383 \n1384         if self.frame:\n1385             frame_sql, frame_params = compiler.compile(self.frame)\n1386             window_sql.append(frame_sql)\n1387             window_params.extend(frame_params)\n1388 \n1389         params.extend(window_params)\n1390         template = template or self.template\n1391 \n1392         return template % {\n1393             'expression': expr_sql,\n1394             'window': ' '.join(window_sql).strip()\n1395         }, params\n1396 \n1397     def as_sqlite(self, compiler, connection):\n1398         if isinstance(self.output_field, fields.DecimalField):\n1399             # Casting to numeric must be outside of the window expression.\n1400             copy = self.copy()\n1401             source_expressions = copy.get_source_expressions()\n1402             source_expressions[0].output_field = fields.FloatField()\n1403             copy.set_source_expressions(source_expressions)\n1404             return super(Window, copy).as_sqlite(compiler, connection)\n1405         return self.as_sql(compiler, connection)\n1406 \n1407     def __str__(self):\n1408         return '{} OVER ({}{}{})'.format(\n1409             str(self.source_expression),\n1410             'PARTITION BY ' + str(self.partition_by) if self.partition_by else '',\n1411             str(self.order_by or ''),\n1412             str(self.frame or ''),\n1413         )\n1414 \n1415     def __repr__(self):\n1416         return '<%s: %s>' % (self.__class__.__name__, self)\n1417 \n1418     def get_group_by_cols(self, alias=None):\n1419         return []\n1420 \n1421 \n1422 class WindowFrame(Expression):\n1423     \"\"\"\n1424     Model the frame clause in window expressions. There are two types of frame\n1425     clauses which are subclasses, however, all processing and validation (by no\n1426     means intended to be complete) is done here. Thus, providing an end for a\n1427     frame is optional (the default is UNBOUNDED FOLLOWING, which is the last\n1428     row in the frame).\n1429     \"\"\"\n1430     template = '%(frame_type)s BETWEEN %(start)s AND %(end)s'\n1431 \n1432     def __init__(self, start=None, end=None):\n1433         self.start = Value(start)\n1434         self.end = Value(end)\n1435 \n1436     def set_source_expressions(self, exprs):\n1437         self.start, self.end = exprs\n1438 \n1439     def get_source_expressions(self):\n1440         return [self.start, self.end]\n1441 \n1442     def as_sql(self, compiler, connection):\n1443         connection.ops.check_expression_support(self)\n1444         start, end = self.window_frame_start_end(connection, self.start.value, self.end.value)\n1445         return self.template % {\n1446             'frame_type': self.frame_type,\n1447             'start': start,\n1448             'end': end,\n1449         }, []\n1450 \n1451     def __repr__(self):\n1452         return '<%s: %s>' % (self.__class__.__name__, self)\n1453 \n1454     def get_group_by_cols(self, alias=None):\n1455         return []\n1456 \n1457     def __str__(self):\n1458         if self.start.value is not None and self.start.value < 0:\n1459             start = '%d %s' % (abs(self.start.value), connection.ops.PRECEDING)\n1460         elif self.start.value is not None and self.start.value == 0:\n1461             start = connection.ops.CURRENT_ROW\n1462         else:\n1463             start = connection.ops.UNBOUNDED_PRECEDING\n1464 \n1465         if self.end.value is not None and self.end.value > 0:\n1466             end = '%d %s' % (self.end.value, connection.ops.FOLLOWING)\n1467         elif self.end.value is not None and self.end.value == 0:\n1468             end = connection.ops.CURRENT_ROW\n1469         else:\n1470             end = connection.ops.UNBOUNDED_FOLLOWING\n1471         return self.template % {\n1472             'frame_type': self.frame_type,\n1473             'start': start,\n1474             'end': end,\n1475         }\n1476 \n1477     def window_frame_start_end(self, connection, start, end):\n1478         raise NotImplementedError('Subclasses must implement window_frame_start_end().')\n1479 \n1480 \n1481 class RowRange(WindowFrame):\n1482     frame_type = 'ROWS'\n1483 \n1484     def window_frame_start_end(self, connection, start, end):\n1485         return connection.ops.window_frame_rows_start_end(start, end)\n1486 \n1487 \n1488 class ValueRange(WindowFrame):\n1489     frame_type = 'RANGE'\n1490 \n1491     def window_frame_start_end(self, connection, start, end):\n1492         return connection.ops.window_frame_range_start_end(start, end)\n",
        "intended_behavior": "This file likely contains the implementation of `Subquery` and possibly how expressions involving `OuterRef` are treated when used in complex queries, such as with `union` or the `|` operator. A detailed examination is needed to pinpoint the exact locations."
    },
    {
        "rel_file_path": "django/db/models/sql/compiler.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__4.1/django/db/models/sql/compiler.py",
        "start": 1,
        "end": 1690,
        "class_name": null,
        "method_name": null,
        "code": "1 import collections\n2 import json\n3 import re\n4 from functools import partial\n5 from itertools import chain\n6 \n7 from django.core.exceptions import EmptyResultSet, FieldError\n8 from django.db import DatabaseError, NotSupportedError\n9 from django.db.models.constants import LOOKUP_SEP\n10 from django.db.models.expressions import F, OrderBy, RawSQL, Ref, Value\n11 from django.db.models.functions import Cast, Random\n12 from django.db.models.query_utils import select_related_descend\n13 from django.db.models.sql.constants import (\n14     CURSOR, GET_ITERATOR_CHUNK_SIZE, MULTI, NO_RESULTS, ORDER_DIR, SINGLE,\n15 )\n16 from django.db.models.sql.query import Query, get_order_dir\n17 from django.db.transaction import TransactionManagementError\n18 from django.utils.functional import cached_property\n19 from django.utils.hashable import make_hashable\n20 from django.utils.regex_helper import _lazy_re_compile\n21 \n22 \n23 class SQLCompiler:\n24     # Multiline ordering SQL clause may appear from RawSQL.\n25     ordering_parts = _lazy_re_compile(\n26         r'^(.*)\\s(?:ASC|DESC).*',\n27         re.MULTILINE | re.DOTALL,\n28     )\n29 \n30     def __init__(self, query, connection, using, elide_empty=True):\n31         self.query = query\n32         self.connection = connection\n33         self.using = using\n34         # Some queries, e.g. coalesced aggregation, need to be executed even if\n35         # they would return an empty result set.\n36         self.elide_empty = elide_empty\n37         self.quote_cache = {'*': '*'}\n38         # The select, klass_info, and annotations are needed by QuerySet.iterator()\n39         # these are set as a side-effect of executing the query. Note that we calculate\n40         # separately a list of extra select columns needed for grammatical correctness\n41         # of the query, but these columns are not included in self.select.\n42         self.select = None\n43         self.annotation_col_map = None\n44         self.klass_info = None\n45         self._meta_ordering = None\n46 \n47     def __repr__(self):\n48         return (\n49             f'<{self.__class__.__qualname__} '\n50             f'model={self.query.model.__qualname__} '\n51             f'connection={self.connection!r} using={self.using!r}>'\n52         )\n53 \n54     def setup_query(self):\n55         if all(self.query.alias_refcount[a] == 0 for a in self.query.alias_map):\n56             self.query.get_initial_alias()\n57         self.select, self.klass_info, self.annotation_col_map = self.get_select()\n58         self.col_count = len(self.select)\n59 \n60     def pre_sql_setup(self):\n61         \"\"\"\n62         Do any necessary class setup immediately prior to producing SQL. This\n63         is for things that can't necessarily be done in __init__ because we\n64         might not have all the pieces in place at that time.\n65         \"\"\"\n66         self.setup_query()\n67         order_by = self.get_order_by()\n68         self.where, self.having = self.query.where.split_having()\n69         extra_select = self.get_extra_select(order_by, self.select)\n70         self.has_extra_select = bool(extra_select)\n71         group_by = self.get_group_by(self.select + extra_select, order_by)\n72         return extra_select, order_by, group_by\n73 \n74     def get_group_by(self, select, order_by):\n75         \"\"\"\n76         Return a list of 2-tuples of form (sql, params).\n77 \n78         The logic of what exactly the GROUP BY clause contains is hard\n79         to describe in other words than \"if it passes the test suite,\n80         then it is correct\".\n81         \"\"\"\n82         # Some examples:\n83         #     SomeModel.objects.annotate(Count('somecol'))\n84         #     GROUP BY: all fields of the model\n85         #\n86         #    SomeModel.objects.values('name').annotate(Count('somecol'))\n87         #    GROUP BY: name\n88         #\n89         #    SomeModel.objects.annotate(Count('somecol')).values('name')\n90         #    GROUP BY: all cols of the model\n91         #\n92         #    SomeModel.objects.values('name', 'pk').annotate(Count('somecol')).values('pk')\n93         #    GROUP BY: name, pk\n94         #\n95         #    SomeModel.objects.values('name').annotate(Count('somecol')).values('pk')\n96         #    GROUP BY: name, pk\n97         #\n98         # In fact, the self.query.group_by is the minimal set to GROUP BY. It\n99         # can't be ever restricted to a smaller set, but additional columns in\n100         # HAVING, ORDER BY, and SELECT clauses are added to it. Unfortunately\n101         # the end result is that it is impossible to force the query to have\n102         # a chosen GROUP BY clause - you can almost do this by using the form:\n103         #     .values(*wanted_cols).annotate(AnAggregate())\n104         # but any later annotations, extra selects, values calls that\n105         # refer some column outside of the wanted_cols, order_by, or even\n106         # filter calls can alter the GROUP BY clause.\n107 \n108         # The query.group_by is either None (no GROUP BY at all), True\n109         # (group by select fields), or a list of expressions to be added\n110         # to the group by.\n111         if self.query.group_by is None:\n112             return []\n113         expressions = []\n114         if self.query.group_by is not True:\n115             # If the group by is set to a list (by .values() call most likely),\n116             # then we need to add everything in it to the GROUP BY clause.\n117             # Backwards compatibility hack for setting query.group_by. Remove\n118             # when  we have public API way of forcing the GROUP BY clause.\n119             # Converts string references to expressions.\n120             for expr in self.query.group_by:\n121                 if not hasattr(expr, 'as_sql'):\n122                     expressions.append(self.query.resolve_ref(expr))\n123                 else:\n124                     expressions.append(expr)\n125         # Note that even if the group_by is set, it is only the minimal\n126         # set to group by. So, we need to add cols in select, order_by, and\n127         # having into the select in any case.\n128         ref_sources = {\n129             expr.source for expr in expressions if isinstance(expr, Ref)\n130         }\n131         for expr, _, _ in select:\n132             # Skip members of the select clause that are already included\n133             # by reference.\n134             if expr in ref_sources:\n135                 continue\n136             cols = expr.get_group_by_cols()\n137             for col in cols:\n138                 expressions.append(col)\n139         if not self._meta_ordering:\n140             for expr, (sql, params, is_ref) in order_by:\n141                 # Skip references to the SELECT clause, as all expressions in\n142                 # the SELECT clause are already part of the GROUP BY.\n143                 if not is_ref:\n144                     expressions.extend(expr.get_group_by_cols())\n145         having_group_by = self.having.get_group_by_cols() if self.having else ()\n146         for expr in having_group_by:\n147             expressions.append(expr)\n148         result = []\n149         seen = set()\n150         expressions = self.collapse_group_by(expressions, having_group_by)\n151 \n152         for expr in expressions:\n153             sql, params = self.compile(expr)\n154             sql, params = expr.select_format(self, sql, params)\n155             params_hash = make_hashable(params)\n156             if (sql, params_hash) not in seen:\n157                 result.append((sql, params))\n158                 seen.add((sql, params_hash))\n159         return result\n160 \n161     def collapse_group_by(self, expressions, having):\n162         # If the DB can group by primary key, then group by the primary key of\n163         # query's main model. Note that for PostgreSQL the GROUP BY clause must\n164         # include the primary key of every table, but for MySQL it is enough to\n165         # have the main table's primary key.\n166         if self.connection.features.allows_group_by_pk:\n167             # Determine if the main model's primary key is in the query.\n168             pk = None\n169             for expr in expressions:\n170                 # Is this a reference to query's base table primary key? If the\n171                 # expression isn't a Col-like, then skip the expression.\n172                 if (getattr(expr, 'target', None) == self.query.model._meta.pk and\n173                         getattr(expr, 'alias', None) == self.query.base_table):\n174                     pk = expr\n175                     break\n176             # If the main model's primary key is in the query, group by that\n177             # field, HAVING expressions, and expressions associated with tables\n178             # that don't have a primary key included in the grouped columns.\n179             if pk:\n180                 pk_aliases = {\n181                     expr.alias for expr in expressions\n182                     if hasattr(expr, 'target') and expr.target.primary_key\n183                 }\n184                 expressions = [pk] + [\n185                     expr for expr in expressions\n186                     if expr in having or (\n187                         getattr(expr, 'alias', None) is not None and expr.alias not in pk_aliases\n188                     )\n189                 ]\n190         elif self.connection.features.allows_group_by_selected_pks:\n191             # Filter out all expressions associated with a table's primary key\n192             # present in the grouped columns. This is done by identifying all\n193             # tables that have their primary key included in the grouped\n194             # columns and removing non-primary key columns referring to them.\n195             # Unmanaged models are excluded because they could be representing\n196             # database views on which the optimization might not be allowed.\n197             pks = {\n198                 expr for expr in expressions\n199                 if (\n200                     hasattr(expr, 'target') and\n201                     expr.target.primary_key and\n202                     self.connection.features.allows_group_by_selected_pks_on_model(expr.target.model)\n203                 )\n204             }\n205             aliases = {expr.alias for expr in pks}\n206             expressions = [\n207                 expr for expr in expressions if expr in pks or getattr(expr, 'alias', None) not in aliases\n208             ]\n209         return expressions\n210 \n211     def get_select(self):\n212         \"\"\"\n213         Return three values:\n214         - a list of 3-tuples of (expression, (sql, params), alias)\n215         - a klass_info structure,\n216         - a dictionary of annotations\n217 \n218         The (sql, params) is what the expression will produce, and alias is the\n219         \"AS alias\" for the column (possibly None).\n220 \n221         The klass_info structure contains the following information:\n222         - The base model of the query.\n223         - Which columns for that model are present in the query (by\n224           position of the select clause).\n225         - related_klass_infos: [f, klass_info] to descent into\n226 \n227         The annotations is a dictionary of {'attname': column position} values.\n228         \"\"\"\n229         select = []\n230         klass_info = None\n231         annotations = {}\n232         select_idx = 0\n233         for alias, (sql, params) in self.query.extra_select.items():\n234             annotations[alias] = select_idx\n235             select.append((RawSQL(sql, params), alias))\n236             select_idx += 1\n237         assert not (self.query.select and self.query.default_cols)\n238         if self.query.default_cols:\n239             cols = self.get_default_columns()\n240         else:\n241             # self.query.select is a special case. These columns never go to\n242             # any model.\n243             cols = self.query.select\n244         if cols:\n245             select_list = []\n246             for col in cols:\n247                 select_list.append(select_idx)\n248                 select.append((col, None))\n249                 select_idx += 1\n250             klass_info = {\n251                 'model': self.query.model,\n252                 'select_fields': select_list,\n253             }\n254         for alias, annotation in self.query.annotation_select.items():\n255             annotations[alias] = select_idx\n256             select.append((annotation, alias))\n257             select_idx += 1\n258 \n259         if self.query.select_related:\n260             related_klass_infos = self.get_related_selections(select)\n261             klass_info['related_klass_infos'] = related_klass_infos\n262 \n263             def get_select_from_parent(klass_info):\n264                 for ki in klass_info['related_klass_infos']:\n265                     if ki['from_parent']:\n266                         ki['select_fields'] = (klass_info['select_fields'] +\n267                                                ki['select_fields'])\n268                     get_select_from_parent(ki)\n269             get_select_from_parent(klass_info)\n270 \n271         ret = []\n272         for col, alias in select:\n273             try:\n274                 sql, params = self.compile(col)\n275             except EmptyResultSet:\n276                 empty_result_set_value = getattr(col, 'empty_result_set_value', NotImplemented)\n277                 if empty_result_set_value is NotImplemented:\n278                     # Select a predicate that's always False.\n279                     sql, params = '0', ()\n280                 else:\n281                     sql, params = self.compile(Value(empty_result_set_value))\n282             else:\n283                 sql, params = col.select_format(self, sql, params)\n284             ret.append((col, (sql, params), alias))\n285         return ret, klass_info, annotations\n286 \n287     def _order_by_pairs(self):\n288         if self.query.extra_order_by:\n289             ordering = self.query.extra_order_by\n290         elif not self.query.default_ordering:\n291             ordering = self.query.order_by\n292         elif self.query.order_by:\n293             ordering = self.query.order_by\n294         elif self.query.get_meta().ordering:\n295             ordering = self.query.get_meta().ordering\n296             self._meta_ordering = ordering\n297         else:\n298             ordering = []\n299         if self.query.standard_ordering:\n300             default_order, _ = ORDER_DIR['ASC']\n301         else:\n302             default_order, _ = ORDER_DIR['DESC']\n303 \n304         for field in ordering:\n305             if hasattr(field, 'resolve_expression'):\n306                 if isinstance(field, Value):\n307                     # output_field must be resolved for constants.\n308                     field = Cast(field, field.output_field)\n309                 if not isinstance(field, OrderBy):\n310                     field = field.asc()\n311                 if not self.query.standard_ordering:\n312                     field = field.copy()\n313                     field.reverse_ordering()\n314                 yield field, False\n315                 continue\n316             if field == '?':  # random\n317                 yield OrderBy(Random()), False\n318                 continue\n319 \n320             col, order = get_order_dir(field, default_order)\n321             descending = order == 'DESC'\n322 \n323             if col in self.query.annotation_select:\n324                 # Reference to expression in SELECT clause\n325                 yield (\n326                     OrderBy(\n327                         Ref(col, self.query.annotation_select[col]),\n328                         descending=descending,\n329                     ),\n330                     True,\n331                 )\n332                 continue\n333             if col in self.query.annotations:\n334                 # References to an expression which is masked out of the SELECT\n335                 # clause.\n336                 if self.query.combinator and self.select:\n337                     # Don't use the resolved annotation because other\n338                     # combinated queries might define it differently.\n339                     expr = F(col)\n340                 else:\n341                     expr = self.query.annotations[col]\n342                     if isinstance(expr, Value):\n343                         # output_field must be resolved for constants.\n344                         expr = Cast(expr, expr.output_field)\n345                 yield OrderBy(expr, descending=descending), False\n346                 continue\n347 \n348             if '.' in field:\n349                 # This came in through an extra(order_by=...) addition. Pass it\n350                 # on verbatim.\n351                 table, col = col.split('.', 1)\n352                 yield (\n353                     OrderBy(\n354                         RawSQL('%s.%s' % (self.quote_name_unless_alias(table), col), []),\n355                         descending=descending,\n356                     ),\n357                     False,\n358                 )\n359                 continue\n360 \n361             if self.query.extra and col in self.query.extra:\n362                 if col in self.query.extra_select:\n363                     yield (\n364                         OrderBy(Ref(col, RawSQL(*self.query.extra[col])), descending=descending),\n365                         True,\n366                     )\n367                 else:\n368                     yield (\n369                         OrderBy(RawSQL(*self.query.extra[col]), descending=descending),\n370                         False,\n371                     )\n372             else:\n373                 if self.query.combinator and self.select:\n374                     # Don't use the first model's field because other\n375                     # combinated queries might define it differently.\n376                     yield OrderBy(F(col), descending=descending), False\n377                 else:\n378                     # 'col' is of the form 'field' or 'field1__field2' or\n379                     # '-field1__field2__field', etc.\n380                     yield from self.find_ordering_name(\n381                         field, self.query.get_meta(), default_order=default_order,\n382                     )\n383 \n384     def get_order_by(self):\n385         \"\"\"\n386         Return a list of 2-tuples of the form (expr, (sql, params, is_ref)) for\n387         the ORDER BY clause.\n388 \n389         The order_by clause can alter the select clause (for example it can add\n390         aliases to clauses that do not yet have one, or it can add totally new\n391         select clauses).\n392         \"\"\"\n393         result = []\n394         seen = set()\n395 \n396         for expr, is_ref in self._order_by_pairs():\n397             resolved = expr.resolve_expression(self.query, allow_joins=True, reuse=None)\n398             if self.query.combinator and self.select:\n399                 src = resolved.get_source_expressions()[0]\n400                 expr_src = expr.get_source_expressions()[0]\n401                 # Relabel order by columns to raw numbers if this is a combined\n402                 # query; necessary since the columns can't be referenced by the\n403                 # fully qualified name and the simple column names may collide.\n404                 for idx, (sel_expr, _, col_alias) in enumerate(self.select):\n405                     if is_ref and col_alias == src.refs:\n406                         src = src.source\n407                     elif col_alias and not (\n408                         isinstance(expr_src, F) and col_alias == expr_src.name\n409                     ):\n410                         continue\n411                     if src == sel_expr:\n412                         resolved.set_source_expressions([RawSQL('%d' % (idx + 1), ())])\n413                         break\n414                 else:\n415                     if col_alias:\n416                         raise DatabaseError('ORDER BY term does not match any column in the result set.')\n417                     # Add column used in ORDER BY clause to the selected\n418                     # columns and to each combined query.\n419                     order_by_idx = len(self.query.select) + 1\n420                     col_name = f'__orderbycol{order_by_idx}'\n421                     for q in self.query.combined_queries:\n422                         q.add_annotation(expr_src, col_name)\n423                     self.query.add_select_col(resolved, col_name)\n424                     resolved.set_source_expressions([RawSQL(f'{order_by_idx}', ())])\n425             sql, params = self.compile(resolved)\n426             # Don't add the same column twice, but the order direction is\n427             # not taken into account so we strip it. When this entire method\n428             # is refactored into expressions, then we can check each part as we\n429             # generate it.\n430             without_ordering = self.ordering_parts.search(sql)[1]\n431             params_hash = make_hashable(params)\n432             if (without_ordering, params_hash) in seen:\n433                 continue\n434             seen.add((without_ordering, params_hash))\n435             result.append((resolved, (sql, params, is_ref)))\n436         return result\n437 \n438     def get_extra_select(self, order_by, select):\n439         extra_select = []\n440         if self.query.distinct and not self.query.distinct_fields:\n441             select_sql = [t[1] for t in select]\n442             for expr, (sql, params, is_ref) in order_by:\n443                 without_ordering = self.ordering_parts.search(sql)[1]\n444                 if not is_ref and (without_ordering, params) not in select_sql:\n445                     extra_select.append((expr, (without_ordering, params), None))\n446         return extra_select\n447 \n448     def quote_name_unless_alias(self, name):\n449         \"\"\"\n450         A wrapper around connection.ops.quote_name that doesn't quote aliases\n451         for table names. This avoids problems with some SQL dialects that treat\n452         quoted strings specially (e.g. PostgreSQL).\n453         \"\"\"\n454         if name in self.quote_cache:\n455             return self.quote_cache[name]\n456         if ((name in self.query.alias_map and name not in self.query.table_map) or\n457                 name in self.query.extra_select or (\n458                     self.query.external_aliases.get(name) and name not in self.query.table_map)):\n459             self.quote_cache[name] = name\n460             return name\n461         r = self.connection.ops.quote_name(name)\n462         self.quote_cache[name] = r\n463         return r\n464 \n465     def compile(self, node):\n466         vendor_impl = getattr(node, 'as_' + self.connection.vendor, None)\n467         if vendor_impl:\n468             sql, params = vendor_impl(self, self.connection)\n469         else:\n470             sql, params = node.as_sql(self, self.connection)\n471         return sql, params\n472 \n473     def get_combinator_sql(self, combinator, all):\n474         features = self.connection.features\n475         compilers = [\n476             query.get_compiler(self.using, self.connection, self.elide_empty)\n477             for query in self.query.combined_queries if not query.is_empty()\n478         ]\n479         if not features.supports_slicing_ordering_in_compound:\n480             for query, compiler in zip(self.query.combined_queries, compilers):\n481                 if query.low_mark or query.high_mark:\n482                     raise DatabaseError('LIMIT/OFFSET not allowed in subqueries of compound statements.')\n483                 if compiler.get_order_by():\n484                     raise DatabaseError('ORDER BY not allowed in subqueries of compound statements.')\n485         parts = ()\n486         for compiler in compilers:\n487             try:\n488                 # If the columns list is limited, then all combined queries\n489                 # must have the same columns list. Set the selects defined on\n490                 # the query on all combined queries, if not already set.\n491                 if not compiler.query.values_select and self.query.values_select:\n492                     compiler.query = compiler.query.clone()\n493                     compiler.query.set_values((\n494                         *self.query.extra_select,\n495                         *self.query.values_select,\n496                         *self.query.annotation_select,\n497                     ))\n498                 part_sql, part_args = compiler.as_sql()\n499                 if compiler.query.combinator:\n500                     # Wrap in a subquery if wrapping in parentheses isn't\n501                     # supported.\n502                     if not features.supports_parentheses_in_compound:\n503                         part_sql = 'SELECT * FROM ({})'.format(part_sql)\n504                     # Add parentheses when combining with compound query if not\n505                     # already added for all compound queries.\n506                     elif not features.supports_slicing_ordering_in_compound:\n507                         part_sql = '({})'.format(part_sql)\n508                 parts += ((part_sql, part_args),)\n509             except EmptyResultSet:\n510                 # Omit the empty queryset with UNION and with DIFFERENCE if the\n511                 # first queryset is nonempty.\n512                 if combinator == 'union' or (combinator == 'difference' and parts):\n513                     continue\n514                 raise\n515         if not parts:\n516             raise EmptyResultSet\n517         combinator_sql = self.connection.ops.set_operators[combinator]\n518         if all and combinator == 'union':\n519             combinator_sql += ' ALL'\n520         braces = '({})' if features.supports_slicing_ordering_in_compound else '{}'\n521         sql_parts, args_parts = zip(*((braces.format(sql), args) for sql, args in parts))\n522         result = [' {} '.format(combinator_sql).join(sql_parts)]\n523         params = []\n524         for part in args_parts:\n525             params.extend(part)\n526         return result, params\n527 \n528     def as_sql(self, with_limits=True, with_col_aliases=False):\n529         \"\"\"\n530         Create the SQL for this query. Return the SQL string and list of\n531         parameters.\n532 \n533         If 'with_limits' is False, any limit/offset information is not included\n534         in the query.\n535         \"\"\"\n536         refcounts_before = self.query.alias_refcount.copy()\n537         try:\n538             extra_select, order_by, group_by = self.pre_sql_setup()\n539             for_update_part = None\n540             # Is a LIMIT/OFFSET clause needed?\n541             with_limit_offset = with_limits and (self.query.high_mark is not None or self.query.low_mark)\n542             combinator = self.query.combinator\n543             features = self.connection.features\n544             if combinator:\n545                 if not getattr(features, 'supports_select_{}'.format(combinator)):\n546                     raise NotSupportedError('{} is not supported on this database backend.'.format(combinator))\n547                 result, params = self.get_combinator_sql(combinator, self.query.combinator_all)\n548             else:\n549                 distinct_fields, distinct_params = self.get_distinct()\n550                 # This must come after 'select', 'ordering', and 'distinct'\n551                 # (see docstring of get_from_clause() for details).\n552                 from_, f_params = self.get_from_clause()\n553                 try:\n554                     where, w_params = self.compile(self.where) if self.where is not None else ('', [])\n555                 except EmptyResultSet:\n556                     if self.elide_empty:\n557                         raise\n558                     # Use a predicate that's always False.\n559                     where, w_params = '0 = 1', []\n560                 having, h_params = self.compile(self.having) if self.having is not None else (\"\", [])\n561                 result = ['SELECT']\n562                 params = []\n563 \n564                 if self.query.distinct:\n565                     distinct_result, distinct_params = self.connection.ops.distinct_sql(\n566                         distinct_fields,\n567                         distinct_params,\n568                     )\n569                     result += distinct_result\n570                     params += distinct_params\n571 \n572                 out_cols = []\n573                 col_idx = 1\n574                 for _, (s_sql, s_params), alias in self.select + extra_select:\n575                     if alias:\n576                         s_sql = '%s AS %s' % (s_sql, self.connection.ops.quote_name(alias))\n577                     elif with_col_aliases:\n578                         s_sql = '%s AS %s' % (\n579                             s_sql,\n580                             self.connection.ops.quote_name('col%d' % col_idx),\n581                         )\n582                         col_idx += 1\n583                     params.extend(s_params)\n584                     out_cols.append(s_sql)\n585 \n586                 result += [', '.join(out_cols), 'FROM', *from_]\n587                 params.extend(f_params)\n588 \n589                 if self.query.select_for_update and self.connection.features.has_select_for_update:\n590                     if self.connection.get_autocommit():\n591                         raise TransactionManagementError('select_for_update cannot be used outside of a transaction.')\n592 \n593                     if with_limit_offset and not self.connection.features.supports_select_for_update_with_limit:\n594                         raise NotSupportedError(\n595                             'LIMIT/OFFSET is not supported with '\n596                             'select_for_update on this database backend.'\n597                         )\n598                     nowait = self.query.select_for_update_nowait\n599                     skip_locked = self.query.select_for_update_skip_locked\n600                     of = self.query.select_for_update_of\n601                     no_key = self.query.select_for_no_key_update\n602                     # If it's a NOWAIT/SKIP LOCKED/OF/NO KEY query but the\n603                     # backend doesn't support it, raise NotSupportedError to\n604                     # prevent a possible deadlock.\n605                     if nowait and not self.connection.features.has_select_for_update_nowait:\n606                         raise NotSupportedError('NOWAIT is not supported on this database backend.')\n607                     elif skip_locked and not self.connection.features.has_select_for_update_skip_locked:\n608                         raise NotSupportedError('SKIP LOCKED is not supported on this database backend.')\n609                     elif of and not self.connection.features.has_select_for_update_of:\n610                         raise NotSupportedError('FOR UPDATE OF is not supported on this database backend.')\n611                     elif no_key and not self.connection.features.has_select_for_no_key_update:\n612                         raise NotSupportedError(\n613                             'FOR NO KEY UPDATE is not supported on this '\n614                             'database backend.'\n615                         )\n616                     for_update_part = self.connection.ops.for_update_sql(\n617                         nowait=nowait,\n618                         skip_locked=skip_locked,\n619                         of=self.get_select_for_update_of_arguments(),\n620                         no_key=no_key,\n621                     )\n622 \n623                 if for_update_part and self.connection.features.for_update_after_from:\n624                     result.append(for_update_part)\n625 \n626                 if where:\n627                     result.append('WHERE %s' % where)\n628                     params.extend(w_params)\n629 \n630                 grouping = []\n631                 for g_sql, g_params in group_by:\n632                     grouping.append(g_sql)\n633                     params.extend(g_params)\n634                 if grouping:\n635                     if distinct_fields:\n636                         raise NotImplementedError('annotate() + distinct(fields) is not implemented.')\n637                     order_by = order_by or self.connection.ops.force_no_ordering()\n638                     result.append('GROUP BY %s' % ', '.join(grouping))\n639                     if self._meta_ordering:\n640                         order_by = None\n641                 if having:\n642                     result.append('HAVING %s' % having)\n643                     params.extend(h_params)\n644 \n645             if self.query.explain_info:\n646                 result.insert(0, self.connection.ops.explain_query_prefix(\n647                     self.query.explain_info.format,\n648                     **self.query.explain_info.options\n649                 ))\n650 \n651             if order_by:\n652                 ordering = []\n653                 for _, (o_sql, o_params, _) in order_by:\n654                     ordering.append(o_sql)\n655                     params.extend(o_params)\n656                 result.append('ORDER BY %s' % ', '.join(ordering))\n657 \n658             if with_limit_offset:\n659                 result.append(self.connection.ops.limit_offset_sql(self.query.low_mark, self.query.high_mark))\n660 \n661             if for_update_part and not self.connection.features.for_update_after_from:\n662                 result.append(for_update_part)\n663 \n664             if self.query.subquery and extra_select:\n665                 # If the query is used as a subquery, the extra selects would\n666                 # result in more columns than the left-hand side expression is\n667                 # expecting. This can happen when a subquery uses a combination\n668                 # of order_by() and distinct(), forcing the ordering expressions\n669                 # to be selected as well. Wrap the query in another subquery\n670                 # to exclude extraneous selects.\n671                 sub_selects = []\n672                 sub_params = []\n673                 for index, (select, _, alias) in enumerate(self.select, start=1):\n674                     if not alias and with_col_aliases:\n675                         alias = 'col%d' % index\n676                     if alias:\n677                         sub_selects.append(\"%s.%s\" % (\n678                             self.connection.ops.quote_name('subquery'),\n679                             self.connection.ops.quote_name(alias),\n680                         ))\n681                     else:\n682                         select_clone = select.relabeled_clone({select.alias: 'subquery'})\n683                         subselect, subparams = select_clone.as_sql(self, self.connection)\n684                         sub_selects.append(subselect)\n685                         sub_params.extend(subparams)\n686                 return 'SELECT %s FROM (%s) subquery' % (\n687                     ', '.join(sub_selects),\n688                     ' '.join(result),\n689                 ), tuple(sub_params + params)\n690 \n691             return ' '.join(result), tuple(params)\n692         finally:\n693             # Finally do cleanup - get rid of the joins we created above.\n694             self.query.reset_refcounts(refcounts_before)\n695 \n696     def get_default_columns(self, start_alias=None, opts=None, from_parent=None):\n697         \"\"\"\n698         Compute the default columns for selecting every field in the base\n699         model. Will sometimes be called to pull in related models (e.g. via\n700         select_related), in which case \"opts\" and \"start_alias\" will be given\n701         to provide a starting point for the traversal.\n702 \n703         Return a list of strings, quoted appropriately for use in SQL\n704         directly, as well as a set of aliases used in the select statement (if\n705         'as_pairs' is True, return a list of (alias, col_name) pairs instead\n706         of strings as the first component and None as the second component).\n707         \"\"\"\n708         result = []\n709         if opts is None:\n710             opts = self.query.get_meta()\n711         only_load = self.deferred_to_columns()\n712         start_alias = start_alias or self.query.get_initial_alias()\n713         # The 'seen_models' is used to optimize checking the needed parent\n714         # alias for a given field. This also includes None -> start_alias to\n715         # be used by local fields.\n716         seen_models = {None: start_alias}\n717 \n718         for field in opts.concrete_fields:\n719             model = field.model._meta.concrete_model\n720             # A proxy model will have a different model and concrete_model. We\n721             # will assign None if the field belongs to this model.\n722             if model == opts.model:\n723                 model = None\n724             if from_parent and model is not None and issubclass(\n725                     from_parent._meta.concrete_model, model._meta.concrete_model):\n726                 # Avoid loading data for already loaded parents.\n727                 # We end up here in the case select_related() resolution\n728                 # proceeds from parent model to child model. In that case the\n729                 # parent model data is already present in the SELECT clause,\n730                 # and we want to avoid reloading the same data again.\n731                 continue\n732             if field.model in only_load and field.attname not in only_load[field.model]:\n733                 continue\n734             alias = self.query.join_parent_model(opts, model, start_alias,\n735                                                  seen_models)\n736             column = field.get_col(alias)\n737             result.append(column)\n738         return result\n739 \n740     def get_distinct(self):\n741         \"\"\"\n742         Return a quoted list of fields to use in DISTINCT ON part of the query.\n743 \n744         This method can alter the tables in the query, and thus it must be\n745         called before get_from_clause().\n746         \"\"\"\n747         result = []\n748         params = []\n749         opts = self.query.get_meta()\n750 \n751         for name in self.query.distinct_fields:\n752             parts = name.split(LOOKUP_SEP)\n753             _, targets, alias, joins, path, _, transform_function = self._setup_joins(parts, opts, None)\n754             targets, alias, _ = self.query.trim_joins(targets, joins, path)\n755             for target in targets:\n756                 if name in self.query.annotation_select:\n757                     result.append(self.connection.ops.quote_name(name))\n758                 else:\n759                     r, p = self.compile(transform_function(target, alias))\n760                     result.append(r)\n761                     params.append(p)\n762         return result, params\n763 \n764     def find_ordering_name(self, name, opts, alias=None, default_order='ASC',\n765                            already_seen=None):\n766         \"\"\"\n767         Return the table alias (the name might be ambiguous, the alias will\n768         not be) and column name for ordering by the given 'name' parameter.\n769         The 'name' is of the form 'field1__field2__...__fieldN'.\n770         \"\"\"\n771         name, order = get_order_dir(name, default_order)\n772         descending = order == 'DESC'\n773         pieces = name.split(LOOKUP_SEP)\n774         field, targets, alias, joins, path, opts, transform_function = self._setup_joins(pieces, opts, alias)\n775 \n776         # If we get to this point and the field is a relation to another model,\n777         # append the default ordering for that model unless it is the pk\n778         # shortcut or the attribute name of the field that is specified.\n779         if (\n780             field.is_relation and\n781             opts.ordering and\n782             getattr(field, 'attname', None) != pieces[-1] and\n783             name != 'pk'\n784         ):\n785             # Firstly, avoid infinite loops.\n786             already_seen = already_seen or set()\n787             join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)\n788             if join_tuple in already_seen:\n789                 raise FieldError('Infinite loop caused by ordering.')\n790             already_seen.add(join_tuple)\n791 \n792             results = []\n793             for item in opts.ordering:\n794                 if hasattr(item, 'resolve_expression') and not isinstance(item, OrderBy):\n795                     item = item.desc() if descending else item.asc()\n796                 if isinstance(item, OrderBy):\n797                     results.append((item, False))\n798                     continue\n799                 results.extend(self.find_ordering_name(item, opts, alias,\n800                                                        order, already_seen))\n801             return results\n802         targets, alias, _ = self.query.trim_joins(targets, joins, path)\n803         return [(OrderBy(transform_function(t, alias), descending=descending), False) for t in targets]\n804 \n805     def _setup_joins(self, pieces, opts, alias):\n806         \"\"\"\n807         Helper method for get_order_by() and get_distinct().\n808 \n809         get_ordering() and get_distinct() must produce same target columns on\n810         same input, as the prefixes of get_ordering() and get_distinct() must\n811         match. Executing SQL where this is not true is an error.\n812         \"\"\"\n813         alias = alias or self.query.get_initial_alias()\n814         field, targets, opts, joins, path, transform_function = self.query.setup_joins(pieces, opts, alias)\n815         alias = joins[-1]\n816         return field, targets, alias, joins, path, opts, transform_function\n817 \n818     def get_from_clause(self):\n819         \"\"\"\n820         Return a list of strings that are joined together to go after the\n821         \"FROM\" part of the query, as well as a list any extra parameters that\n822         need to be included. Subclasses, can override this to create a\n823         from-clause via a \"select\".\n824 \n825         This should only be called after any SQL construction methods that\n826         might change the tables that are needed. This means the select columns,\n827         ordering, and distinct must be done first.\n828         \"\"\"\n829         result = []\n830         params = []\n831         for alias in tuple(self.query.alias_map):\n832             if not self.query.alias_refcount[alias]:\n833                 continue\n834             try:\n835                 from_clause = self.query.alias_map[alias]\n836             except KeyError:\n837                 # Extra tables can end up in self.tables, but not in the\n838                 # alias_map if they aren't in a join. That's OK. We skip them.\n839                 continue\n840             clause_sql, clause_params = self.compile(from_clause)\n841             result.append(clause_sql)\n842             params.extend(clause_params)\n843         for t in self.query.extra_tables:\n844             alias, _ = self.query.table_alias(t)\n845             # Only add the alias if it's not already present (the table_alias()\n846             # call increments the refcount, so an alias refcount of one means\n847             # this is the only reference).\n848             if alias not in self.query.alias_map or self.query.alias_refcount[alias] == 1:\n849                 result.append(', %s' % self.quote_name_unless_alias(alias))\n850         return result, params\n851 \n852     def get_related_selections(self, select, opts=None, root_alias=None, cur_depth=1,\n853                                requested=None, restricted=None):\n854         \"\"\"\n855         Fill in the information needed for a select_related query. The current\n856         depth is measured as the number of connections away from the root model\n857         (for example, cur_depth=1 means we are looking at models with direct\n858         connections to the root model).\n859         \"\"\"\n860         def _get_field_choices():\n861             direct_choices = (f.name for f in opts.fields if f.is_relation)\n862             reverse_choices = (\n863                 f.field.related_query_name()\n864                 for f in opts.related_objects if f.field.unique\n865             )\n866             return chain(direct_choices, reverse_choices, self.query._filtered_relations)\n867 \n868         related_klass_infos = []\n869         if not restricted and cur_depth > self.query.max_depth:\n870             # We've recursed far enough; bail out.\n871             return related_klass_infos\n872 \n873         if not opts:\n874             opts = self.query.get_meta()\n875             root_alias = self.query.get_initial_alias()\n876         only_load = self.query.get_loaded_field_names()\n877 \n878         # Setup for the case when only particular related fields should be\n879         # included in the related selection.\n880         fields_found = set()\n881         if requested is None:\n882             restricted = isinstance(self.query.select_related, dict)\n883             if restricted:\n884                 requested = self.query.select_related\n885 \n886         def get_related_klass_infos(klass_info, related_klass_infos):\n887             klass_info['related_klass_infos'] = related_klass_infos\n888 \n889         for f in opts.fields:\n890             field_model = f.model._meta.concrete_model\n891             fields_found.add(f.name)\n892 \n893             if restricted:\n894                 next = requested.get(f.name, {})\n895                 if not f.is_relation:\n896                     # If a non-related field is used like a relation,\n897                     # or if a single non-relational field is given.\n898                     if next or f.name in requested:\n899                         raise FieldError(\n900                             \"Non-relational field given in select_related: '%s'. \"\n901                             \"Choices are: %s\" % (\n902                                 f.name,\n903                                 \", \".join(_get_field_choices()) or '(none)',\n904                             )\n905                         )\n906             else:\n907                 next = False\n908 \n909             if not select_related_descend(f, restricted, requested,\n910                                           only_load.get(field_model)):\n911                 continue\n912             klass_info = {\n913                 'model': f.remote_field.model,\n914                 'field': f,\n915                 'reverse': False,\n916                 'local_setter': f.set_cached_value,\n917                 'remote_setter': f.remote_field.set_cached_value if f.unique else lambda x, y: None,\n918                 'from_parent': False,\n919             }\n920             related_klass_infos.append(klass_info)\n921             select_fields = []\n922             _, _, _, joins, _, _ = self.query.setup_joins(\n923                 [f.name], opts, root_alias)\n924             alias = joins[-1]\n925             columns = self.get_default_columns(start_alias=alias, opts=f.remote_field.model._meta)\n926             for col in columns:\n927                 select_fields.append(len(select))\n928                 select.append((col, None))\n929             klass_info['select_fields'] = select_fields\n930             next_klass_infos = self.get_related_selections(\n931                 select, f.remote_field.model._meta, alias, cur_depth + 1, next, restricted)\n932             get_related_klass_infos(klass_info, next_klass_infos)\n933 \n934         if restricted:\n935             related_fields = [\n936                 (o.field, o.related_model)\n937                 for o in opts.related_objects\n938                 if o.field.unique and not o.many_to_many\n939             ]\n940             for f, model in related_fields:\n941                 if not select_related_descend(f, restricted, requested,\n942                                               only_load.get(model), reverse=True):\n943                     continue\n944 \n945                 related_field_name = f.related_query_name()\n946                 fields_found.add(related_field_name)\n947 \n948                 join_info = self.query.setup_joins([related_field_name], opts, root_alias)\n949                 alias = join_info.joins[-1]\n950                 from_parent = issubclass(model, opts.model) and model is not opts.model\n951                 klass_info = {\n952                     'model': model,\n953                     'field': f,\n954                     'reverse': True,\n955                     'local_setter': f.remote_field.set_cached_value,\n956                     'remote_setter': f.set_cached_value,\n957                     'from_parent': from_parent,\n958                 }\n959                 related_klass_infos.append(klass_info)\n960                 select_fields = []\n961                 columns = self.get_default_columns(\n962                     start_alias=alias, opts=model._meta, from_parent=opts.model)\n963                 for col in columns:\n964                     select_fields.append(len(select))\n965                     select.append((col, None))\n966                 klass_info['select_fields'] = select_fields\n967                 next = requested.get(f.related_query_name(), {})\n968                 next_klass_infos = self.get_related_selections(\n969                     select, model._meta, alias, cur_depth + 1,\n970                     next, restricted)\n971                 get_related_klass_infos(klass_info, next_klass_infos)\n972 \n973             def local_setter(obj, from_obj):\n974                 # Set a reverse fk object when relation is non-empty.\n975                 if from_obj:\n976                     f.remote_field.set_cached_value(from_obj, obj)\n977 \n978             def remote_setter(name, obj, from_obj):\n979                 setattr(from_obj, name, obj)\n980 \n981             for name in list(requested):\n982                 # Filtered relations work only on the topmost level.\n983                 if cur_depth > 1:\n984                     break\n985                 if name in self.query._filtered_relations:\n986                     fields_found.add(name)\n987                     f, _, join_opts, joins, _, _ = self.query.setup_joins([name], opts, root_alias)\n988                     model = join_opts.model\n989                     alias = joins[-1]\n990                     from_parent = issubclass(model, opts.model) and model is not opts.model\n991                     klass_info = {\n992                         'model': model,\n993                         'field': f,\n994                         'reverse': True,\n995                         'local_setter': local_setter,\n996                         'remote_setter': partial(remote_setter, name),\n997                         'from_parent': from_parent,\n998                     }\n999                     related_klass_infos.append(klass_info)\n1000                     select_fields = []\n1001                     columns = self.get_default_columns(\n1002                         start_alias=alias, opts=model._meta,\n1003                         from_parent=opts.model,\n1004                     )\n1005                     for col in columns:\n1006                         select_fields.append(len(select))\n1007                         select.append((col, None))\n1008                     klass_info['select_fields'] = select_fields\n1009                     next_requested = requested.get(name, {})\n1010                     next_klass_infos = self.get_related_selections(\n1011                         select, opts=model._meta, root_alias=alias,\n1012                         cur_depth=cur_depth + 1, requested=next_requested,\n1013                         restricted=restricted,\n1014                     )\n1015                     get_related_klass_infos(klass_info, next_klass_infos)\n1016             fields_not_found = set(requested).difference(fields_found)\n1017             if fields_not_found:\n1018                 invalid_fields = (\"'%s'\" % s for s in fields_not_found)\n1019                 raise FieldError(\n1020                     'Invalid field name(s) given in select_related: %s. '\n1021                     'Choices are: %s' % (\n1022                         ', '.join(invalid_fields),\n1023                         ', '.join(_get_field_choices()) or '(none)',\n1024                     )\n1025                 )\n1026         return related_klass_infos\n1027 \n1028     def get_select_for_update_of_arguments(self):\n1029         \"\"\"\n1030         Return a quoted list of arguments for the SELECT FOR UPDATE OF part of\n1031         the query.\n1032         \"\"\"\n1033         def _get_parent_klass_info(klass_info):\n1034             concrete_model = klass_info['model']._meta.concrete_model\n1035             for parent_model, parent_link in concrete_model._meta.parents.items():\n1036                 parent_list = parent_model._meta.get_parent_list()\n1037                 yield {\n1038                     'model': parent_model,\n1039                     'field': parent_link,\n1040                     'reverse': False,\n1041                     'select_fields': [\n1042                         select_index\n1043                         for select_index in klass_info['select_fields']\n1044                         # Selected columns from a model or its parents.\n1045                         if (\n1046                             self.select[select_index][0].target.model == parent_model or\n1047                             self.select[select_index][0].target.model in parent_list\n1048                         )\n1049                     ],\n1050                 }\n1051 \n1052         def _get_first_selected_col_from_model(klass_info):\n1053             \"\"\"\n1054             Find the first selected column from a model. If it doesn't exist,\n1055             don't lock a model.\n1056 \n1057             select_fields is filled recursively, so it also contains fields\n1058             from the parent models.\n1059             \"\"\"\n1060             concrete_model = klass_info['model']._meta.concrete_model\n1061             for select_index in klass_info['select_fields']:\n1062                 if self.select[select_index][0].target.model == concrete_model:\n1063                     return self.select[select_index][0]\n1064 \n1065         def _get_field_choices():\n1066             \"\"\"Yield all allowed field paths in breadth-first search order.\"\"\"\n1067             queue = collections.deque([(None, self.klass_info)])\n1068             while queue:\n1069                 parent_path, klass_info = queue.popleft()\n1070                 if parent_path is None:\n1071                     path = []\n1072                     yield 'self'\n1073                 else:\n1074                     field = klass_info['field']\n1075                     if klass_info['reverse']:\n1076                         field = field.remote_field\n1077                     path = parent_path + [field.name]\n1078                     yield LOOKUP_SEP.join(path)\n1079                 queue.extend(\n1080                     (path, klass_info)\n1081                     for klass_info in _get_parent_klass_info(klass_info)\n1082                 )\n1083                 queue.extend(\n1084                     (path, klass_info)\n1085                     for klass_info in klass_info.get('related_klass_infos', [])\n1086                 )\n1087         if not self.klass_info:\n1088             return []\n1089         result = []\n1090         invalid_names = []\n1091         for name in self.query.select_for_update_of:\n1092             klass_info = self.klass_info\n1093             if name == 'self':\n1094                 col = _get_first_selected_col_from_model(klass_info)\n1095             else:\n1096                 for part in name.split(LOOKUP_SEP):\n1097                     klass_infos = (\n1098                         *klass_info.get('related_klass_infos', []),\n1099                         *_get_parent_klass_info(klass_info),\n1100                     )\n1101                     for related_klass_info in klass_infos:\n1102                         field = related_klass_info['field']\n1103                         if related_klass_info['reverse']:\n1104                             field = field.remote_field\n1105                         if field.name == part:\n1106                             klass_info = related_klass_info\n1107                             break\n1108                     else:\n1109                         klass_info = None\n1110                         break\n1111                 if klass_info is None:\n1112                     invalid_names.append(name)\n1113                     continue\n1114                 col = _get_first_selected_col_from_model(klass_info)\n1115             if col is not None:\n1116                 if self.connection.features.select_for_update_of_column:\n1117                     result.append(self.compile(col)[0])\n1118                 else:\n1119                     result.append(self.quote_name_unless_alias(col.alias))\n1120         if invalid_names:\n1121             raise FieldError(\n1122                 'Invalid field name(s) given in select_for_update(of=(...)): %s. '\n1123                 'Only relational fields followed in the query are allowed. '\n1124                 'Choices are: %s.' % (\n1125                     ', '.join(invalid_names),\n1126                     ', '.join(_get_field_choices()),\n1127                 )\n1128             )\n1129         return result\n1130 \n1131     def deferred_to_columns(self):\n1132         \"\"\"\n1133         Convert the self.deferred_loading data structure to mapping of table\n1134         names to sets of column names which are to be loaded. Return the\n1135         dictionary.\n1136         \"\"\"\n1137         columns = {}\n1138         self.query.deferred_to_data(columns, self.query.get_loaded_field_names_cb)\n1139         return columns\n1140 \n1141     def get_converters(self, expressions):\n1142         converters = {}\n1143         for i, expression in enumerate(expressions):\n1144             if expression:\n1145                 backend_converters = self.connection.ops.get_db_converters(expression)\n1146                 field_converters = expression.get_db_converters(self.connection)\n1147                 if backend_converters or field_converters:\n1148                     converters[i] = (backend_converters + field_converters, expression)\n1149         return converters\n1150 \n1151     def apply_converters(self, rows, converters):\n1152         connection = self.connection\n1153         converters = list(converters.items())\n1154         for row in map(list, rows):\n1155             for pos, (convs, expression) in converters:\n1156                 value = row[pos]\n1157                 for converter in convs:\n1158                     value = converter(value, expression, connection)\n1159                 row[pos] = value\n1160             yield row\n1161 \n1162     def results_iter(self, results=None, tuple_expected=False, chunked_fetch=False,\n1163                      chunk_size=GET_ITERATOR_CHUNK_SIZE):\n1164         \"\"\"Return an iterator over the results from executing this query.\"\"\"\n1165         if results is None:\n1166             results = self.execute_sql(MULTI, chunked_fetch=chunked_fetch, chunk_size=chunk_size)\n1167         fields = [s[0] for s in self.select[0:self.col_count]]\n1168         converters = self.get_converters(fields)\n1169         rows = chain.from_iterable(results)\n1170         if converters:\n1171             rows = self.apply_converters(rows, converters)\n1172             if tuple_expected:\n1173                 rows = map(tuple, rows)\n1174         return rows\n1175 \n1176     def has_results(self):\n1177         \"\"\"\n1178         Backends (e.g. NoSQL) can override this in order to use optimized\n1179         versions of \"query has any results.\"\n1180         \"\"\"\n1181         return bool(self.execute_sql(SINGLE))\n1182 \n1183     def execute_sql(self, result_type=MULTI, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE):\n1184         \"\"\"\n1185         Run the query against the database and return the result(s). The\n1186         return value is a single data item if result_type is SINGLE, or an\n1187         iterator over the results if the result_type is MULTI.\n1188 \n1189         result_type is either MULTI (use fetchmany() to retrieve all rows),\n1190         SINGLE (only retrieve a single row), or None. In this last case, the\n1191         cursor is returned if any query is executed, since it's used by\n1192         subclasses such as InsertQuery). It's possible, however, that no query\n1193         is needed, as the filters describe an empty set. In that case, None is\n1194         returned, to avoid any unnecessary database interaction.\n1195         \"\"\"\n1196         result_type = result_type or NO_RESULTS\n1197         try:\n1198             sql, params = self.as_sql()\n1199             if not sql:\n1200                 raise EmptyResultSet\n1201         except EmptyResultSet:\n1202             if result_type == MULTI:\n1203                 return iter([])\n1204             else:\n1205                 return\n1206         if chunked_fetch:\n1207             cursor = self.connection.chunked_cursor()\n1208         else:\n1209             cursor = self.connection.cursor()\n1210         try:\n1211             cursor.execute(sql, params)\n1212         except Exception:\n1213             # Might fail for server-side cursors (e.g. connection closed)\n1214             cursor.close()\n1215             raise\n1216 \n1217         if result_type == CURSOR:\n1218             # Give the caller the cursor to process and close.\n1219             return cursor\n1220         if result_type == SINGLE:\n1221             try:\n1222                 val = cursor.fetchone()\n1223                 if val:\n1224                     return val[0:self.col_count]\n1225                 return val\n1226             finally:\n1227                 # done with the cursor\n1228                 cursor.close()\n1229         if result_type == NO_RESULTS:\n1230             cursor.close()\n1231             return\n1232 \n1233         result = cursor_iter(\n1234             cursor, self.connection.features.empty_fetchmany_value,\n1235             self.col_count if self.has_extra_select else None,\n1236             chunk_size,\n1237         )\n1238         if not chunked_fetch or not self.connection.features.can_use_chunked_reads:\n1239             # If we are using non-chunked reads, we return the same data\n1240             # structure as normally, but ensure it is all read into memory\n1241             # before going any further. Use chunked_fetch if requested,\n1242             # unless the database doesn't support it.\n1243             return list(result)\n1244         return result\n1245 \n1246     def as_subquery_condition(self, alias, columns, compiler):\n1247         qn = compiler.quote_name_unless_alias\n1248         qn2 = self.connection.ops.quote_name\n1249 \n1250         for index, select_col in enumerate(self.query.select):\n1251             lhs_sql, lhs_params = self.compile(select_col)\n1252             rhs = '%s.%s' % (qn(alias), qn2(columns[index]))\n1253             self.query.where.add(\n1254                 RawSQL('%s = %s' % (lhs_sql, rhs), lhs_params), 'AND')\n1255 \n1256         sql, params = self.as_sql()\n1257         return 'EXISTS (%s)' % sql, params\n1258 \n1259     def explain_query(self):\n1260         result = list(self.execute_sql())\n1261         # Some backends return 1 item tuples with strings, and others return\n1262         # tuples with integers and strings. Flatten them out into strings.\n1263         output_formatter = json.dumps if self.query.explain_info.format == 'json' else str\n1264         for row in result[0]:\n1265             if not isinstance(row, str):\n1266                 yield ' '.join(output_formatter(c) for c in row)\n1267             else:\n1268                 yield row\n1269 \n1270 \n1271 class SQLInsertCompiler(SQLCompiler):\n1272     returning_fields = None\n1273     returning_params = tuple()\n1274 \n1275     def field_as_sql(self, field, val):\n1276         \"\"\"\n1277         Take a field and a value intended to be saved on that field, and\n1278         return placeholder SQL and accompanying params. Check for raw values,\n1279         expressions, and fields with get_placeholder() defined in that order.\n1280 \n1281         When field is None, consider the value raw and use it as the\n1282         placeholder, with no corresponding parameters returned.\n1283         \"\"\"\n1284         if field is None:\n1285             # A field value of None means the value is raw.\n1286             sql, params = val, []\n1287         elif hasattr(val, 'as_sql'):\n1288             # This is an expression, let's compile it.\n1289             sql, params = self.compile(val)\n1290         elif hasattr(field, 'get_placeholder'):\n1291             # Some fields (e.g. geo fields) need special munging before\n1292             # they can be inserted.\n1293             sql, params = field.get_placeholder(val, self, self.connection), [val]\n1294         else:\n1295             # Return the common case for the placeholder\n1296             sql, params = '%s', [val]\n1297 \n1298         # The following hook is only used by Oracle Spatial, which sometimes\n1299         # needs to yield 'NULL' and [] as its placeholder and params instead\n1300         # of '%s' and [None]. The 'NULL' placeholder is produced earlier by\n1301         # OracleOperations.get_geom_placeholder(). The following line removes\n1302         # the corresponding None parameter. See ticket #10888.\n1303         params = self.connection.ops.modify_insert_params(sql, params)\n1304 \n1305         return sql, params\n1306 \n1307     def prepare_value(self, field, value):\n1308         \"\"\"\n1309         Prepare a value to be used in a query by resolving it if it is an\n1310         expression and otherwise calling the field's get_db_prep_save().\n1311         \"\"\"\n1312         if hasattr(value, 'resolve_expression'):\n1313             value = value.resolve_expression(self.query, allow_joins=False, for_save=True)\n1314             # Don't allow values containing Col expressions. They refer to\n1315             # existing columns on a row, but in the case of insert the row\n1316             # doesn't exist yet.\n1317             if value.contains_column_references:\n1318                 raise ValueError(\n1319                     'Failed to insert expression \"%s\" on %s. F() expressions '\n1320                     'can only be used to update, not to insert.' % (value, field)\n1321                 )\n1322             if value.contains_aggregate:\n1323                 raise FieldError(\n1324                     'Aggregate functions are not allowed in this query '\n1325                     '(%s=%r).' % (field.name, value)\n1326                 )\n1327             if value.contains_over_clause:\n1328                 raise FieldError(\n1329                     'Window expressions are not allowed in this query (%s=%r).'\n1330                     % (field.name, value)\n1331                 )\n1332         else:\n1333             value = field.get_db_prep_save(value, connection=self.connection)\n1334         return value\n1335 \n1336     def pre_save_val(self, field, obj):\n1337         \"\"\"\n1338         Get the given field's value off the given obj. pre_save() is used for\n1339         things like auto_now on DateTimeField. Skip it if this is a raw query.\n1340         \"\"\"\n1341         if self.query.raw:\n1342             return getattr(obj, field.attname)\n1343         return field.pre_save(obj, add=True)\n1344 \n1345     def assemble_as_sql(self, fields, value_rows):\n1346         \"\"\"\n1347         Take a sequence of N fields and a sequence of M rows of values, and\n1348         generate placeholder SQL and parameters for each field and value.\n1349         Return a pair containing:\n1350          * a sequence of M rows of N SQL placeholder strings, and\n1351          * a sequence of M rows of corresponding parameter values.\n1352 \n1353         Each placeholder string may contain any number of '%s' interpolation\n1354         strings, and each parameter row will contain exactly as many params\n1355         as the total number of '%s's in the corresponding placeholder row.\n1356         \"\"\"\n1357         if not value_rows:\n1358             return [], []\n1359 \n1360         # list of (sql, [params]) tuples for each object to be saved\n1361         # Shape: [n_objs][n_fields][2]\n1362         rows_of_fields_as_sql = (\n1363             (self.field_as_sql(field, v) for field, v in zip(fields, row))\n1364             for row in value_rows\n1365         )\n1366 \n1367         # tuple like ([sqls], [[params]s]) for each object to be saved\n1368         # Shape: [n_objs][2][n_fields]\n1369         sql_and_param_pair_rows = (zip(*row) for row in rows_of_fields_as_sql)\n1370 \n1371         # Extract separate lists for placeholders and params.\n1372         # Each of these has shape [n_objs][n_fields]\n1373         placeholder_rows, param_rows = zip(*sql_and_param_pair_rows)\n1374 \n1375         # Params for each field are still lists, and need to be flattened.\n1376         param_rows = [[p for ps in row for p in ps] for row in param_rows]\n1377 \n1378         return placeholder_rows, param_rows\n1379 \n1380     def as_sql(self):\n1381         # We don't need quote_name_unless_alias() here, since these are all\n1382         # going to be column names (so we can avoid the extra overhead).\n1383         qn = self.connection.ops.quote_name\n1384         opts = self.query.get_meta()\n1385         insert_statement = self.connection.ops.insert_statement(ignore_conflicts=self.query.ignore_conflicts)\n1386         result = ['%s %s' % (insert_statement, qn(opts.db_table))]\n1387         fields = self.query.fields or [opts.pk]\n1388         result.append('(%s)' % ', '.join(qn(f.column) for f in fields))\n1389 \n1390         if self.query.fields:\n1391             value_rows = [\n1392                 [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]\n1393                 for obj in self.query.objs\n1394             ]\n1395         else:\n1396             # An empty object.\n1397             value_rows = [[self.connection.ops.pk_default_value()] for _ in self.query.objs]\n1398             fields = [None]\n1399 \n1400         # Currently the backends just accept values when generating bulk\n1401         # queries and generate their own placeholders. Doing that isn't\n1402         # necessary and it should be possible to use placeholders and\n1403         # expressions in bulk inserts too.\n1404         can_bulk = (not self.returning_fields and self.connection.features.has_bulk_insert)\n1405 \n1406         placeholder_rows, param_rows = self.assemble_as_sql(fields, value_rows)\n1407 \n1408         ignore_conflicts_suffix_sql = self.connection.ops.ignore_conflicts_suffix_sql(\n1409             ignore_conflicts=self.query.ignore_conflicts\n1410         )\n1411         if self.returning_fields and self.connection.features.can_return_columns_from_insert:\n1412             if self.connection.features.can_return_rows_from_bulk_insert:\n1413                 result.append(self.connection.ops.bulk_insert_sql(fields, placeholder_rows))\n1414                 params = param_rows\n1415             else:\n1416                 result.append(\"VALUES (%s)\" % \", \".join(placeholder_rows[0]))\n1417                 params = [param_rows[0]]\n1418             if ignore_conflicts_suffix_sql:\n1419                 result.append(ignore_conflicts_suffix_sql)\n1420             # Skip empty r_sql to allow subclasses to customize behavior for\n1421             # 3rd party backends. Refs #19096.\n1422             r_sql, self.returning_params = self.connection.ops.return_insert_columns(self.returning_fields)\n1423             if r_sql:\n1424                 result.append(r_sql)\n1425                 params += [self.returning_params]\n1426             return [(\" \".join(result), tuple(chain.from_iterable(params)))]\n1427 \n1428         if can_bulk:\n1429             result.append(self.connection.ops.bulk_insert_sql(fields, placeholder_rows))\n1430             if ignore_conflicts_suffix_sql:\n1431                 result.append(ignore_conflicts_suffix_sql)\n1432             return [(\" \".join(result), tuple(p for ps in param_rows for p in ps))]\n1433         else:\n1434             if ignore_conflicts_suffix_sql:\n1435                 result.append(ignore_conflicts_suffix_sql)\n1436             return [\n1437                 (\" \".join(result + [\"VALUES (%s)\" % \", \".join(p)]), vals)\n1438                 for p, vals in zip(placeholder_rows, param_rows)\n1439             ]\n1440 \n1441     def execute_sql(self, returning_fields=None):\n1442         assert not (\n1443             returning_fields and len(self.query.objs) != 1 and\n1444             not self.connection.features.can_return_rows_from_bulk_insert\n1445         )\n1446         opts = self.query.get_meta()\n1447         self.returning_fields = returning_fields\n1448         with self.connection.cursor() as cursor:\n1449             for sql, params in self.as_sql():\n1450                 cursor.execute(sql, params)\n1451             if not self.returning_fields:\n1452                 return []\n1453             if self.connection.features.can_return_rows_from_bulk_insert and len(self.query.objs) > 1:\n1454                 rows = self.connection.ops.fetch_returned_insert_rows(cursor)\n1455             elif self.connection.features.can_return_columns_from_insert:\n1456                 assert len(self.query.objs) == 1\n1457                 rows = [self.connection.ops.fetch_returned_insert_columns(\n1458                     cursor, self.returning_params,\n1459                 )]\n1460             else:\n1461                 rows = [(self.connection.ops.last_insert_id(\n1462                     cursor, opts.db_table, opts.pk.column,\n1463                 ),)]\n1464         cols = [field.get_col(opts.db_table) for field in self.returning_fields]\n1465         converters = self.get_converters(cols)\n1466         if converters:\n1467             rows = list(self.apply_converters(rows, converters))\n1468         return rows\n1469 \n1470 \n1471 class SQLDeleteCompiler(SQLCompiler):\n1472     @cached_property\n1473     def single_alias(self):\n1474         # Ensure base table is in aliases.\n1475         self.query.get_initial_alias()\n1476         return sum(self.query.alias_refcount[t] > 0 for t in self.query.alias_map) == 1\n1477 \n1478     @classmethod\n1479     def _expr_refs_base_model(cls, expr, base_model):\n1480         if isinstance(expr, Query):\n1481             return expr.model == base_model\n1482         if not hasattr(expr, 'get_source_expressions'):\n1483             return False\n1484         return any(\n1485             cls._expr_refs_base_model(source_expr, base_model)\n1486             for source_expr in expr.get_source_expressions()\n1487         )\n1488 \n1489     @cached_property\n1490     def contains_self_reference_subquery(self):\n1491         return any(\n1492             self._expr_refs_base_model(expr, self.query.model)\n1493             for expr in chain(self.query.annotations.values(), self.query.where.children)\n1494         )\n1495 \n1496     def _as_sql(self, query):\n1497         result = [\n1498             'DELETE FROM %s' % self.quote_name_unless_alias(query.base_table)\n1499         ]\n1500         where, params = self.compile(query.where)\n1501         if where:\n1502             result.append('WHERE %s' % where)\n1503         return ' '.join(result), tuple(params)\n1504 \n1505     def as_sql(self):\n1506         \"\"\"\n1507         Create the SQL for this query. Return the SQL string and list of\n1508         parameters.\n1509         \"\"\"\n1510         if self.single_alias and not self.contains_self_reference_subquery:\n1511             return self._as_sql(self.query)\n1512         innerq = self.query.clone()\n1513         innerq.__class__ = Query\n1514         innerq.clear_select_clause()\n1515         pk = self.query.model._meta.pk\n1516         innerq.select = [\n1517             pk.get_col(self.query.get_initial_alias())\n1518         ]\n1519         outerq = Query(self.query.model)\n1520         if not self.connection.features.update_can_self_select:\n1521             # Force the materialization of the inner query to allow reference\n1522             # to the target table on MySQL.\n1523             sql, params = innerq.get_compiler(connection=self.connection).as_sql()\n1524             innerq = RawSQL('SELECT * FROM (%s) subquery' % sql, params)\n1525         outerq.add_filter('pk__in', innerq)\n1526         return self._as_sql(outerq)\n1527 \n1528 \n1529 class SQLUpdateCompiler(SQLCompiler):\n1530     def as_sql(self):\n1531         \"\"\"\n1532         Create the SQL for this query. Return the SQL string and list of\n1533         parameters.\n1534         \"\"\"\n1535         self.pre_sql_setup()\n1536         if not self.query.values:\n1537             return '', ()\n1538         qn = self.quote_name_unless_alias\n1539         values, update_params = [], []\n1540         for field, model, val in self.query.values:\n1541             if hasattr(val, 'resolve_expression'):\n1542                 val = val.resolve_expression(self.query, allow_joins=False, for_save=True)\n1543                 if val.contains_aggregate:\n1544                     raise FieldError(\n1545                         'Aggregate functions are not allowed in this query '\n1546                         '(%s=%r).' % (field.name, val)\n1547                     )\n1548                 if val.contains_over_clause:\n1549                     raise FieldError(\n1550                         'Window expressions are not allowed in this query '\n1551                         '(%s=%r).' % (field.name, val)\n1552                     )\n1553             elif hasattr(val, 'prepare_database_save'):\n1554                 if field.remote_field:\n1555                     val = field.get_db_prep_save(\n1556                         val.prepare_database_save(field),\n1557                         connection=self.connection,\n1558                     )\n1559                 else:\n1560                     raise TypeError(\n1561                         \"Tried to update field %s with a model instance, %r. \"\n1562                         \"Use a value compatible with %s.\"\n1563                         % (field, val, field.__class__.__name__)\n1564                     )\n1565             else:\n1566                 val = field.get_db_prep_save(val, connection=self.connection)\n1567 \n1568             # Getting the placeholder for the field.\n1569             if hasattr(field, 'get_placeholder'):\n1570                 placeholder = field.get_placeholder(val, self, self.connection)\n1571             else:\n1572                 placeholder = '%s'\n1573             name = field.column\n1574             if hasattr(val, 'as_sql'):\n1575                 sql, params = self.compile(val)\n1576                 values.append('%s = %s' % (qn(name), placeholder % sql))\n1577                 update_params.extend(params)\n1578             elif val is not None:\n1579                 values.append('%s = %s' % (qn(name), placeholder))\n1580                 update_params.append(val)\n1581             else:\n1582                 values.append('%s = NULL' % qn(name))\n1583         table = self.query.base_table\n1584         result = [\n1585             'UPDATE %s SET' % qn(table),\n1586             ', '.join(values),\n1587         ]\n1588         where, params = self.compile(self.query.where)\n1589         if where:\n1590             result.append('WHERE %s' % where)\n1591         return ' '.join(result), tuple(update_params + params)\n1592 \n1593     def execute_sql(self, result_type):\n1594         \"\"\"\n1595         Execute the specified update. Return the number of rows affected by\n1596         the primary update query. The \"primary update query\" is the first\n1597         non-empty query that is executed. Row counts for any subsequent,\n1598         related queries are not available.\n1599         \"\"\"\n1600         cursor = super().execute_sql(result_type)\n1601         try:\n1602             rows = cursor.rowcount if cursor else 0\n1603             is_empty = cursor is None\n1604         finally:\n1605             if cursor:\n1606                 cursor.close()\n1607         for query in self.query.get_related_updates():\n1608             aux_rows = query.get_compiler(self.using).execute_sql(result_type)\n1609             if is_empty and aux_rows:\n1610                 rows = aux_rows\n1611                 is_empty = False\n1612         return rows\n1613 \n1614     def pre_sql_setup(self):\n1615         \"\"\"\n1616         If the update depends on results from other tables, munge the \"where\"\n1617         conditions to match the format required for (portable) SQL updates.\n1618 \n1619         If multiple updates are required, pull out the id values to update at\n1620         this point so that they don't change as a result of the progressive\n1621         updates.\n1622         \"\"\"\n1623         refcounts_before = self.query.alias_refcount.copy()\n1624         # Ensure base table is in the query\n1625         self.query.get_initial_alias()\n1626         count = self.query.count_active_tables()\n1627         if not self.query.related_updates and count == 1:\n1628             return\n1629         query = self.query.chain(klass=Query)\n1630         query.select_related = False\n1631         query.clear_ordering(force=True)\n1632         query.extra = {}\n1633         query.select = []\n1634         query.add_fields([query.get_meta().pk.name])\n1635         super().pre_sql_setup()\n1636 \n1637         must_pre_select = count > 1 and not self.connection.features.update_can_self_select\n1638 \n1639         # Now we adjust the current query: reset the where clause and get rid\n1640         # of all the tables we don't need (since they're in the sub-select).\n1641         self.query.clear_where()\n1642         if self.query.related_updates or must_pre_select:\n1643             # Either we're using the idents in multiple update queries (so\n1644             # don't want them to change), or the db backend doesn't support\n1645             # selecting from the updating table (e.g. MySQL).\n1646             idents = []\n1647             for rows in query.get_compiler(self.using).execute_sql(MULTI):\n1648                 idents.extend(r[0] for r in rows)\n1649             self.query.add_filter('pk__in', idents)\n1650             self.query.related_ids = idents\n1651         else:\n1652             # The fast path. Filters and updates in one query.\n1653             self.query.add_filter('pk__in', query)\n1654         self.query.reset_refcounts(refcounts_before)\n1655 \n1656 \n1657 class SQLAggregateCompiler(SQLCompiler):\n1658     def as_sql(self):\n1659         \"\"\"\n1660         Create the SQL for this query. Return the SQL string and list of\n1661         parameters.\n1662         \"\"\"\n1663         sql, params = [], []\n1664         for annotation in self.query.annotation_select.values():\n1665             ann_sql, ann_params = self.compile(annotation)\n1666             ann_sql, ann_params = annotation.select_format(self, ann_sql, ann_params)\n1667             sql.append(ann_sql)\n1668             params.extend(ann_params)\n1669         self.col_count = len(self.query.annotation_select)\n1670         sql = ', '.join(sql)\n1671         params = tuple(params)\n1672 \n1673         inner_query_sql, inner_query_params = self.query.inner_query.get_compiler(\n1674             self.using, elide_empty=self.elide_empty,\n1675         ).as_sql(with_col_aliases=True)\n1676         sql = 'SELECT %s FROM (%s) subquery' % (sql, inner_query_sql)\n1677         params = params + inner_query_params\n1678         return sql, params\n1679 \n1680 \n1681 def cursor_iter(cursor, sentinel, col_count, itersize):\n1682     \"\"\"\n1683     Yield blocks of rows from a cursor and ensure the cursor is closed when\n1684     done.\n1685     \"\"\"\n1686     try:\n1687         for rows in iter((lambda: cursor.fetchmany(itersize)), sentinel):\n1688             yield rows if col_count is None else [r[:col_count] for r in rows]\n1689     finally:\n1690         cursor.close()\n",
        "intended_behavior": "The issue could stem from how combined queries (union or bitwise OR) are compiled when they include references to `OuterRef`. This file's method(s) responsible for compiling these queries needs to be reviewed for potential adjustments."
    }
]