[
    {
        "rel_file_path": "astropy/table/serialize.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/astropy__astropy/setup_astropy__astropy__5.0/astropy/table/serialize.py",
        "start": 1,
        "end": 408,
        "class_name": null,
        "method_name": null,
        "code": "1 # Licensed under a 3-clause BSD style license - see LICENSE.rst\n2 from importlib import import_module\n3 from copy import deepcopy\n4 from collections import OrderedDict\n5 \n6 import numpy as np\n7 \n8 from astropy.utils.data_info import MixinInfo\n9 from .column import Column, MaskedColumn\n10 from .table import Table, QTable, has_info_class\n11 from astropy.units.quantity import QuantityInfo\n12 \n13 \n14 # TODO: some of this might be better done programmatically, through\n15 # code like\n16 # __construct_mixin_classes += tuple(\n17 #        f'astropy.coordinates.representation.{cls.__name__}'\n18 #        for cls in (list(coorep.REPRESENTATION_CLASSES.values())\n19 #                    + list(coorep.DIFFERENTIAL_CLASSES.values()))\n20 #        if cls.__name__ in coorep.__all__)\n21 # However, to avoid very hard to track import issues, the definition\n22 # should then be done at the point where it is actually needed,\n23 # using local imports.  See also\n24 # https://github.com/astropy/astropy/pull/10210#discussion_r419087286\n25 __construct_mixin_classes = (\n26     'astropy.time.core.Time',\n27     'astropy.time.core.TimeDelta',\n28     'astropy.units.quantity.Quantity',\n29     'astropy.units.function.logarithmic.Magnitude',\n30     'astropy.units.function.logarithmic.Decibel',\n31     'astropy.units.function.logarithmic.Dex',\n32     'astropy.coordinates.angles.Latitude',\n33     'astropy.coordinates.angles.Longitude',\n34     'astropy.coordinates.angles.Angle',\n35     'astropy.coordinates.distances.Distance',\n36     'astropy.coordinates.earth.EarthLocation',\n37     'astropy.coordinates.sky_coordinate.SkyCoord',\n38     'astropy.table.ndarray_mixin.NdarrayMixin',\n39     'astropy.table.table_helpers.ArrayWrapper',\n40     'astropy.table.column.Column',\n41     'astropy.table.column.MaskedColumn',\n42     'astropy.coordinates.representation.CartesianRepresentation',\n43     'astropy.coordinates.representation.UnitSphericalRepresentation',\n44     'astropy.coordinates.representation.RadialRepresentation',\n45     'astropy.coordinates.representation.SphericalRepresentation',\n46     'astropy.coordinates.representation.PhysicsSphericalRepresentation',\n47     'astropy.coordinates.representation.CylindricalRepresentation',\n48     'astropy.coordinates.representation.CartesianDifferential',\n49     'astropy.coordinates.representation.UnitSphericalDifferential',\n50     'astropy.coordinates.representation.SphericalDifferential',\n51     'astropy.coordinates.representation.UnitSphericalCosLatDifferential',\n52     'astropy.coordinates.representation.SphericalCosLatDifferential',\n53     'astropy.coordinates.representation.RadialDifferential',\n54     'astropy.coordinates.representation.PhysicsSphericalDifferential',\n55     'astropy.coordinates.representation.CylindricalDifferential',\n56     'astropy.utils.masked.core.MaskedNDArray',\n57 )\n58 \n59 \n60 class SerializedColumnInfo(MixinInfo):\n61     \"\"\"\n62     Minimal info to allow SerializedColumn to be recognized as a mixin Column.\n63 \n64     Used to help create a dict of columns in ColumnInfo for structured data.\n65     \"\"\"\n66     def _represent_as_dict(self):\n67         # SerializedColumn is already a `dict`, so we can return it directly.\n68         return self._parent\n69 \n70 \n71 class SerializedColumn(dict):\n72     \"\"\"Subclass of dict used to serialize  mixin columns.\n73 \n74     It is used in the representation to contain the name and possible\n75     other info for a mixin column or attribute (either primary data or an\n76     array-like attribute) that is serialized as a column in the table.\n77 \n78     \"\"\"\n79     info = SerializedColumnInfo()\n80 \n81     @property\n82     def shape(self):\n83         \"\"\"Minimal shape implementation to allow use as a mixin column.\n84 \n85         Returns the shape of the first item that has a shape at all,\n86         or ``()`` if none of the values has a shape attribute.\n87         \"\"\"\n88         return next((value.shape for value in self.values()\n89                      if hasattr(value, 'shape')), ())\n90 \n91 \n92 def _represent_mixin_as_column(col, name, new_cols, mixin_cols,\n93                                exclude_classes=()):\n94     \"\"\"Carry out processing needed to serialize ``col`` in an output table\n95     consisting purely of plain ``Column`` or ``MaskedColumn`` columns.  This\n96     relies on the object determine if any transformation is required and may\n97     depend on the ``serialize_method`` and ``serialize_context`` context\n98     variables.  For instance a ``MaskedColumn`` may be stored directly to\n99     FITS, but can also be serialized as separate data and mask columns.\n100 \n101     This function builds up a list of plain columns in the ``new_cols`` arg (which\n102     is passed as a persistent list).  This includes both plain columns from the\n103     original table and plain columns that represent data from serialized columns\n104     (e.g. ``jd1`` and ``jd2`` arrays from a ``Time`` column).\n105 \n106     For serialized columns the ``mixin_cols`` dict is updated with required\n107     attributes and information to subsequently reconstruct the table.\n108 \n109     Table mixin columns are always serialized and get represented by one\n110     or more data columns.  In earlier versions of the code *only* mixin\n111     columns were serialized, hence the use within this code of \"mixin\"\n112     to imply serialization.  Starting with version 3.1, the non-mixin\n113     ``MaskedColumn`` can also be serialized.\n114     \"\"\"\n115     obj_attrs = col.info._represent_as_dict()\n116 \n117     # If serialization is not required (see function docstring above)\n118     # or explicitly specified as excluded, then treat as a normal column.\n119     if not obj_attrs or col.__class__ in exclude_classes:\n120         new_cols.append(col)\n121         return\n122 \n123     # Subtlety here is handling mixin info attributes.  The basic list of such\n124     # attributes is: 'name', 'unit', 'dtype', 'format', 'description', 'meta'.\n125     # - name: handled directly [DON'T store]\n126     # - unit: DON'T store if this is a parent attribute\n127     # - dtype: captured in plain Column if relevant [DON'T store]\n128     # - format: possibly irrelevant but settable post-object creation [DO store]\n129     # - description: DO store\n130     # - meta: DO store\n131     info = {}\n132     for attr, nontrivial in (('unit', lambda x: x is not None and x != ''),\n133                              ('format', lambda x: x is not None),\n134                              ('description', lambda x: x is not None),\n135                              ('meta', lambda x: x)):\n136         col_attr = getattr(col.info, attr)\n137         if nontrivial(col_attr):\n138             info[attr] = col_attr\n139 \n140     # Find column attributes that have the same length as the column itself.\n141     # These will be stored in the table as new columns (aka \"data attributes\").\n142     # Examples include SkyCoord.ra (what is typically considered the data and is\n143     # always an array) and Skycoord.obs_time (which can be a scalar or an\n144     # array).\n145     data_attrs = [key for key, value in obj_attrs.items() if\n146                   getattr(value, 'shape', ())[:1] == col.shape[:1]]\n147 \n148     for data_attr in data_attrs:\n149         data = obj_attrs[data_attr]\n150 \n151         # New column name combines the old name and attribute\n152         # (e.g. skycoord.ra, skycoord.dec).unless it is the primary data\n153         # attribute for the column (e.g. value for Quantity or data for\n154         # MaskedColumn).  For primary data, we attempt to store any info on\n155         # the format, etc., on the column, but not for ancillary data (e.g.,\n156         # no sense to use a float format for a mask).\n157         is_primary = data_attr == col.info._represent_as_dict_primary_data\n158         if is_primary:\n159             new_name = name\n160             new_info = info\n161         else:\n162             new_name = name + '.' + data_attr\n163             new_info = {}\n164 \n165         if not has_info_class(data, MixinInfo):\n166             col_cls = MaskedColumn if (hasattr(data, 'mask')\n167                                        and np.any(data.mask)) else Column\n168             data = col_cls(data, name=new_name, **new_info)\n169             if is_primary:\n170                 # Don't store info in the __serialized_columns__ dict for this column\n171                 # since this is redundant with info stored on the new column.\n172                 info = {}\n173 \n174         # Recurse. If this is anything that needs further serialization (i.e.,\n175         # a Mixin column, a structured Column, a MaskedColumn for which mask is\n176         # stored, etc.), it will define obj_attrs[new_name]. Otherwise, it will\n177         # just add to new_cols and all we have to do is to link to the new name.\n178         _represent_mixin_as_column(data, new_name, new_cols, obj_attrs)\n179         obj_attrs[data_attr] = SerializedColumn(obj_attrs.pop(new_name,\n180                                                               {'name': new_name}))\n181 \n182     # Strip out from info any attributes defined by the parent,\n183     # and store whatever remains.\n184     for attr in col.info.attrs_from_parent:\n185         if attr in info:\n186             del info[attr]\n187     if info:\n188         obj_attrs['__info__'] = info\n189 \n190     # Store the fully qualified class name\n191     if not isinstance(col, SerializedColumn):\n192         obj_attrs.setdefault('__class__',\n193                              col.__module__ + '.' + col.__class__.__name__)\n194 \n195     mixin_cols[name] = obj_attrs\n196 \n197 \n198 def represent_mixins_as_columns(tbl, exclude_classes=()):\n199     \"\"\"Represent input Table ``tbl`` using only `~astropy.table.Column`\n200     or  `~astropy.table.MaskedColumn` objects.\n201 \n202     This function represents any mixin columns like `~astropy.time.Time` in\n203     ``tbl`` to one or more plain ``~astropy.table.Column`` objects and returns\n204     a new Table.  A single mixin column may be split into multiple column\n205     components as needed for fully representing the column.  This includes the\n206     possibility of recursive splitting, as shown in the example below.  The\n207     new column names are formed as ``<column_name>.<component>``, e.g.\n208     ``sc.ra`` for a `~astropy.coordinates.SkyCoord` column named ``sc``.\n209 \n210     In addition to splitting columns, this function updates the table ``meta``\n211     dictionary to include a dict named ``__serialized_columns__`` which provides\n212     additional information needed to construct the original mixin columns from\n213     the split columns.\n214 \n215     This function is used by astropy I/O when writing tables to ECSV, FITS,\n216     HDF5 formats.\n217 \n218     Note that if the table does not include any mixin columns then the original\n219     table is returned with no update to ``meta``.\n220 \n221     Parameters\n222     ----------\n223     tbl : `~astropy.table.Table` or subclass\n224         Table to represent mixins as Columns\n225     exclude_classes : tuple of class\n226         Exclude any mixin columns which are instannces of any classes in the tuple\n227 \n228     Returns\n229     -------\n230     tbl : `~astropy.table.Table`\n231         New Table with updated columns, or else the original input ``tbl``\n232 \n233     Examples\n234     --------\n235     >>> from astropy.table import Table, represent_mixins_as_columns\n236     >>> from astropy.time import Time\n237     >>> from astropy.coordinates import SkyCoord\n238 \n239     >>> x = [100.0, 200.0]\n240     >>> obstime = Time([1999.0, 2000.0], format='jyear')\n241     >>> sc = SkyCoord([1, 2], [3, 4], unit='deg', obstime=obstime)\n242     >>> tbl = Table([sc, x], names=['sc', 'x'])\n243     >>> represent_mixins_as_columns(tbl)\n244     <Table length=2>\n245      sc.ra   sc.dec sc.obstime.jd1 sc.obstime.jd2    x\n246       deg     deg\n247     float64 float64    float64        float64     float64\n248     ------- ------- -------------- -------------- -------\n249         1.0     3.0      2451180.0          -0.25   100.0\n250         2.0     4.0      2451545.0            0.0   200.0\n251 \n252     \"\"\"\n253     # Dict of metadata for serializing each column, keyed by column name.\n254     # Gets filled in place by _represent_mixin_as_column().\n255     mixin_cols = {}\n256 \n257     # List of columns for the output table.  For plain Column objects\n258     # this will just be the original column object.\n259     new_cols = []\n260 \n261     # Go through table columns and represent each column as one or more\n262     # plain Column objects (in new_cols) + metadata (in mixin_cols).\n263     for col in tbl.itercols():\n264         _represent_mixin_as_column(col, col.info.name, new_cols, mixin_cols,\n265                                    exclude_classes=exclude_classes)\n266 \n267     # If no metadata was created then just return the original table.\n268     if mixin_cols:\n269         meta = deepcopy(tbl.meta)\n270         meta['__serialized_columns__'] = mixin_cols\n271         out = Table(new_cols, meta=meta, copy=False)\n272     else:\n273         out = tbl\n274 \n275     for col in out.itercols():\n276         if not isinstance(col, Column) and col.__class__ not in exclude_classes:\n277             # This catches columns for which info has not been set up right and\n278             # therefore were not converted. See the corresponding test in\n279             # test_mixin.py for an example.\n280             raise TypeError(\n281                 'failed to represent column '\n282                 f'{col.info.name!r} ({col.__class__.__name__}) as one '\n283                 'or more Column subclasses. This looks like a mixin class '\n284                 'that does not have the correct _represent_as_dict() method '\n285                 'in the class `info` attribute.')\n286 \n287     return out\n288 \n289 \n290 def _construct_mixin_from_obj_attrs_and_info(obj_attrs, info):\n291     # If this is a supported class then import the class and run\n292     # the _construct_from_col method.  Prevent accidentally running\n293     # untrusted code by only importing known astropy classes.\n294     cls_full_name = obj_attrs.pop('__class__', None)\n295     if cls_full_name is None:\n296         cls = SerializedColumn\n297     elif cls_full_name not in __construct_mixin_classes:\n298         raise ValueError(f'unsupported class for construct {cls_full_name}')\n299     else:\n300         mod_name, _, cls_name = cls_full_name.rpartition('.')\n301         module = import_module(mod_name)\n302         cls = getattr(module, cls_name)\n303 \n304     for attr, value in info.items():\n305         if attr in cls.info.attrs_from_parent:\n306             obj_attrs[attr] = value\n307     mixin = cls.info._construct_from_dict(obj_attrs)\n308     for attr, value in info.items():\n309         if attr not in obj_attrs:\n310             setattr(mixin.info, attr, value)\n311     return mixin\n312 \n313 \n314 class _TableLite(OrderedDict):\n315     \"\"\"\n316     Minimal table-like object for _construct_mixin_from_columns.  This allows\n317     manipulating the object like a Table but without the actual overhead\n318     for a full Table.\n319 \n320     More pressing, there is an issue with constructing MaskedColumn, where the\n321     encoded Column components (data, mask) are turned into a MaskedColumn.\n322     When this happens in a real table then all other columns are immediately\n323     Masked and a warning is issued. This is not desirable.\n324     \"\"\"\n325 \n326     def add_column(self, col, index=0):\n327         colnames = self.colnames\n328         self[col.info.name] = col\n329         for ii, name in enumerate(colnames):\n330             if ii >= index:\n331                 self.move_to_end(name)\n332 \n333     @property\n334     def colnames(self):\n335         return list(self.keys())\n336 \n337     def itercols(self):\n338         return self.values()\n339 \n340 \n341 def _construct_mixin_from_columns(new_name, obj_attrs, out):\n342     data_attrs_map = {}\n343     for name, val in obj_attrs.items():\n344         if isinstance(val, SerializedColumn):\n345             if 'name' in val:\n346                 data_attrs_map[val['name']] = name\n347             else:\n348                 out_name = f'{new_name}.{name}'\n349                 _construct_mixin_from_columns(out_name, val, out)\n350                 data_attrs_map[out_name] = name\n351 \n352     for name in data_attrs_map.values():\n353         del obj_attrs[name]\n354 \n355     # Get the index where to add new column\n356     idx = min(out.colnames.index(name) for name in data_attrs_map)\n357 \n358     # Name is the column name in the table (e.g. \"coord.ra\") and\n359     # data_attr is the object attribute name  (e.g. \"ra\").  A different\n360     # example would be a formatted time object that would have (e.g.)\n361     # \"time_col\" and \"value\", respectively.\n362     for name, data_attr in data_attrs_map.items():\n363         obj_attrs[data_attr] = out[name]\n364         del out[name]\n365 \n366     info = obj_attrs.pop('__info__', {})\n367     if len(data_attrs_map) == 1:\n368         # col is the first and only serialized column; in that case, use info\n369         # stored on the column. First step is to get that first column which\n370         # has been moved from `out` to `obj_attrs` above.\n371         data_attr = next(iter(data_attrs_map.values()))\n372         col = obj_attrs[data_attr]\n373 \n374         # Now copy the relevant attributes\n375         for attr, nontrivial in (('unit', lambda x: x not in (None, '')),\n376                                  ('format', lambda x: x is not None),\n377                                  ('description', lambda x: x is not None),\n378                                  ('meta', lambda x: x)):\n379             col_attr = getattr(col.info, attr)\n380             if nontrivial(col_attr):\n381                 info[attr] = col_attr\n382 \n383     info['name'] = new_name\n384     col = _construct_mixin_from_obj_attrs_and_info(obj_attrs, info)\n385     out.add_column(col, index=idx)\n386 \n387 \n388 def _construct_mixins_from_columns(tbl):\n389     if '__serialized_columns__' not in tbl.meta:\n390         return tbl\n391 \n392     meta = tbl.meta.copy()\n393     mixin_cols = meta.pop('__serialized_columns__')\n394 \n395     out = _TableLite(tbl.columns)\n396 \n397     for new_name, obj_attrs in mixin_cols.items():\n398         _construct_mixin_from_columns(new_name, obj_attrs, out)\n399 \n400     # If no quantity subclasses are in the output then output as Table.\n401     # For instance ascii.read(file, format='ecsv') doesn't specify an\n402     # output class and should return the minimal table class that\n403     # represents the table file.\n404     has_quantities = any(isinstance(col.info, QuantityInfo)\n405                          for col in out.itercols())\n406     out_cls = QTable if has_quantities else Table\n407 \n408     return out_cls(list(out.values()), names=out.colnames, copy=False, meta=meta)\n",
        "intended_behavior": "Update or refine the logic to handle the special case where a field name coincides with reserved or special terms (e.g., 'name'). This could involve checking for such names and applying a naming convention or escaping mechanism during serialization, ensuring that they are correctly unescaped or converted back during deserialization. The key is to preserve the semantics of the original table, including all column names, without losing information or causing errors due to name clashes."
    },
    {
        "rel_file_path": "astropy/io/misc/yaml.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/astropy__astropy/setup_astropy__astropy__5.0/astropy/io/misc/yaml.py",
        "start": 1,
        "end": 356,
        "class_name": null,
        "method_name": null,
        "code": "1 # Licensed under a 3-clause BSD style license - see LICENSE.rst\n2 \n3 \"\"\"\n4 This module contains functions for serializing core astropy objects via the\n5 YAML protocol.\n6 It provides functions `~astropy.io.misc.yaml.dump`,\n7 `~astropy.io.misc.yaml.load`, and `~astropy.io.misc.yaml.load_all` which\n8 call the corresponding functions in `PyYaml <https://pyyaml.org>`_ but use the\n9 `~astropy.io.misc.yaml.AstropyDumper` and `~astropy.io.misc.yaml.AstropyLoader`\n10 classes to define custom YAML tags for the following astropy classes:\n11 - `astropy.units.Unit`\n12 - `astropy.units.Quantity`\n13 - `astropy.time.Time`\n14 - `astropy.time.TimeDelta`\n15 - `astropy.coordinates.SkyCoord`\n16 - `astropy.coordinates.Angle`\n17 - `astropy.coordinates.Latitude`\n18 - `astropy.coordinates.Longitude`\n19 - `astropy.coordinates.EarthLocation`\n20 - `astropy.table.SerializedColumn`\n21 \n22 Example\n23 =======\n24 ::\n25   >>> from astropy.io.misc import yaml\n26   >>> import astropy.units as u\n27   >>> from astropy.time import Time\n28   >>> from astropy.coordinates import EarthLocation\n29   >>> t = Time(2457389.0, format='mjd',\n30   ...          location=EarthLocation(1000, 2000, 3000, unit=u.km))\n31   >>> td = yaml.dump(t)\n32   >>> print(td)\n33   !astropy.time.Time\n34   format: mjd\n35   in_subfmt: '*'\n36   jd1: 4857390.0\n37   jd2: -0.5\n38   location: !astropy.coordinates.earth.EarthLocation\n39     ellipsoid: WGS84\n40     x: !astropy.units.Quantity\n41       unit: &id001 !astropy.units.Unit {unit: km}\n42       value: 1000.0\n43     y: !astropy.units.Quantity\n44       unit: *id001\n45       value: 2000.0\n46     z: !astropy.units.Quantity\n47       unit: *id001\n48       value: 3000.0\n49   out_subfmt: '*'\n50   precision: 3\n51   scale: utc\n52   >>> ty = yaml.load(td)\n53   >>> ty\n54   <Time object: scale='utc' format='mjd' value=2457389.0>\n55   >>> ty.location  # doctest: +FLOAT_CMP\n56   <EarthLocation (1000., 2000., 3000.) km>\n57 \"\"\"\n58 \n59 import base64\n60 \n61 import numpy as np\n62 import yaml\n63 \n64 from astropy.time import Time, TimeDelta\n65 from astropy import units as u\n66 from astropy import coordinates as coords\n67 from astropy.table import SerializedColumn\n68 \n69 \n70 __all__ = ['AstropyLoader', 'AstropyDumper', 'load', 'load_all', 'dump']\n71 \n72 \n73 def _unit_representer(dumper, obj):\n74     out = {'unit': str(obj.to_string())}\n75     return dumper.represent_mapping('!astropy.units.Unit', out)\n76 \n77 \n78 def _unit_constructor(loader, node):\n79     map = loader.construct_mapping(node)\n80     return u.Unit(map['unit'], parse_strict='warn')\n81 \n82 \n83 def _serialized_column_representer(dumper, obj):\n84     out = dumper.represent_mapping('!astropy.table.SerializedColumn', obj)\n85     return out\n86 \n87 \n88 def _serialized_column_constructor(loader, node):\n89     map = loader.construct_mapping(node)\n90     return SerializedColumn(map)\n91 \n92 \n93 def _time_representer(dumper, obj):\n94     out = obj.info._represent_as_dict()\n95     return dumper.represent_mapping('!astropy.time.Time', out)\n96 \n97 \n98 def _time_constructor(loader, node):\n99     map = loader.construct_mapping(node)\n100     out = Time.info._construct_from_dict(map)\n101     return out\n102 \n103 \n104 def _timedelta_representer(dumper, obj):\n105     out = obj.info._represent_as_dict()\n106     return dumper.represent_mapping('!astropy.time.TimeDelta', out)\n107 \n108 \n109 def _timedelta_constructor(loader, node):\n110     map = loader.construct_mapping(node)\n111     out = TimeDelta.info._construct_from_dict(map)\n112     return out\n113 \n114 \n115 def _ndarray_representer(dumper, obj):\n116     if not (obj.flags['C_CONTIGUOUS'] or obj.flags['F_CONTIGUOUS']):\n117         obj = np.ascontiguousarray(obj)\n118 \n119     if np.isfortran(obj):\n120         obj = obj.T\n121         order = 'F'\n122     else:\n123         order = 'C'\n124 \n125     data_b64 = base64.b64encode(obj.tobytes())\n126 \n127     out = dict(buffer=data_b64,\n128                dtype=str(obj.dtype) if not obj.dtype.fields else obj.dtype.descr,\n129                shape=obj.shape,\n130                order=order)\n131 \n132     return dumper.represent_mapping('!numpy.ndarray', out)\n133 \n134 \n135 def _ndarray_constructor(loader, node):\n136     # Convert mapping to a dict useful for initializing ndarray.\n137     # Need deep=True since for structured dtype, the contents\n138     # include lists and tuples, which need recursion via\n139     # construct_sequence.\n140     map = loader.construct_mapping(node, deep=True)\n141     map['buffer'] = base64.b64decode(map['buffer'])\n142     return np.ndarray(**map)\n143 \n144 \n145 def _void_representer(dumper, obj):\n146     data_b64 = base64.b64encode(obj.tobytes())\n147     out = dict(buffer=data_b64,\n148                dtype=str(obj.dtype) if not obj.dtype.fields else obj.dtype.descr)\n149     return dumper.represent_mapping('!numpy.void', out)\n150 \n151 \n152 def _void_constructor(loader, node):\n153     # Interpret as node as an array scalar and then index to change to void.\n154     map = loader.construct_mapping(node, deep=True)\n155     map['buffer'] = base64.b64decode(map['buffer'])\n156     return np.ndarray(shape=(), **map)[()]\n157 \n158 \n159 def _quantity_representer(tag):\n160     def representer(dumper, obj):\n161         out = obj.info._represent_as_dict()\n162         return dumper.represent_mapping(tag, out)\n163     return representer\n164 \n165 \n166 def _quantity_constructor(cls):\n167     def constructor(loader, node):\n168         map = loader.construct_mapping(node)\n169         return cls.info._construct_from_dict(map)\n170     return constructor\n171 \n172 \n173 def _skycoord_representer(dumper, obj):\n174     map = obj.info._represent_as_dict()\n175     out = dumper.represent_mapping('!astropy.coordinates.sky_coordinate.SkyCoord',\n176                                    map)\n177     return out\n178 \n179 \n180 def _skycoord_constructor(loader, node):\n181     map = loader.construct_mapping(node)\n182     out = coords.SkyCoord.info._construct_from_dict(map)\n183     return out\n184 \n185 \n186 # Straight from yaml's Representer\n187 def _complex_representer(self, data):\n188     if data.imag == 0.0:\n189         data = f'{data.real!r}'\n190     elif data.real == 0.0:\n191         data = f'{data.imag!r}j'\n192     elif data.imag > 0:\n193         data = f'{data.real!r}+{data.imag!r}j'\n194     else:\n195         data = f'{data.real!r}{data.imag!r}j'\n196     return self.represent_scalar('tag:yaml.org,2002:python/complex', data)\n197 \n198 \n199 def _complex_constructor(loader, node):\n200     map = loader.construct_scalar(node)\n201     return complex(map)\n202 \n203 \n204 class AstropyLoader(yaml.SafeLoader):\n205     \"\"\"\n206     Custom SafeLoader that constructs astropy core objects as well\n207     as Python tuple and unicode objects.\n208 \n209     This class is not directly instantiated by user code, but instead is\n210     used to maintain the available constructor functions that are\n211     called when parsing a YAML stream.  See the `PyYaml documentation\n212     <https://pyyaml.org/wiki/PyYAMLDocumentation>`_ for details of the\n213     class signature.\n214     \"\"\"\n215 \n216     def _construct_python_tuple(self, node):\n217         return tuple(self.construct_sequence(node))\n218 \n219     def _construct_python_unicode(self, node):\n220         return self.construct_scalar(node)\n221 \n222 \n223 class AstropyDumper(yaml.SafeDumper):\n224     \"\"\"\n225     Custom SafeDumper that represents astropy core objects as well\n226     as Python tuple and unicode objects.\n227 \n228     This class is not directly instantiated by user code, but instead is\n229     used to maintain the available representer functions that are\n230     called when generating a YAML stream from an object.  See the\n231     `PyYaml documentation <https://pyyaml.org/wiki/PyYAMLDocumentation>`_\n232     for details of the class signature.\n233     \"\"\"\n234 \n235     def _represent_tuple(self, data):\n236         return self.represent_sequence('tag:yaml.org,2002:python/tuple', data)\n237 \n238 \n239 AstropyDumper.add_multi_representer(u.UnitBase, _unit_representer)\n240 AstropyDumper.add_multi_representer(u.FunctionUnitBase, _unit_representer)\n241 AstropyDumper.add_multi_representer(u.StructuredUnit, _unit_representer)\n242 AstropyDumper.add_representer(tuple, AstropyDumper._represent_tuple)\n243 AstropyDumper.add_representer(np.ndarray, _ndarray_representer)\n244 AstropyDumper.add_representer(np.void, _void_representer)\n245 AstropyDumper.add_representer(Time, _time_representer)\n246 AstropyDumper.add_representer(TimeDelta, _timedelta_representer)\n247 AstropyDumper.add_representer(coords.SkyCoord, _skycoord_representer)\n248 AstropyDumper.add_representer(SerializedColumn, _serialized_column_representer)\n249 \n250 # Numpy dtypes\n251 AstropyDumper.add_representer(np.bool_, yaml.representer.SafeRepresenter.represent_bool)\n252 for np_type in [np.int_, np.intc, np.intp, np.int8, np.int16, np.int32,\n253                 np.int64, np.uint8, np.uint16, np.uint32, np.uint64]:\n254     AstropyDumper.add_representer(np_type,\n255                                     yaml.representer.SafeRepresenter.represent_int)\n256 for np_type in [np.float_, np.float16, np.float32, np.float64,\n257                 np.longdouble]:\n258     AstropyDumper.add_representer(np_type,\n259                                     yaml.representer.SafeRepresenter.represent_float)\n260 for np_type in [np.complex_, complex, np.complex64, np.complex128]:\n261     AstropyDumper.add_representer(np_type, _complex_representer)\n262 \n263 AstropyLoader.add_constructor('tag:yaml.org,2002:python/complex',\n264                                 _complex_constructor)\n265 AstropyLoader.add_constructor('tag:yaml.org,2002:python/tuple',\n266                                 AstropyLoader._construct_python_tuple)\n267 AstropyLoader.add_constructor('tag:yaml.org,2002:python/unicode',\n268                                 AstropyLoader._construct_python_unicode)\n269 AstropyLoader.add_constructor('!astropy.units.Unit', _unit_constructor)\n270 AstropyLoader.add_constructor('!numpy.ndarray', _ndarray_constructor)\n271 AstropyLoader.add_constructor('!numpy.void', _void_constructor)\n272 AstropyLoader.add_constructor('!astropy.time.Time', _time_constructor)\n273 AstropyLoader.add_constructor('!astropy.time.TimeDelta', _timedelta_constructor)\n274 AstropyLoader.add_constructor('!astropy.coordinates.sky_coordinate.SkyCoord',\n275                                 _skycoord_constructor)\n276 AstropyLoader.add_constructor('!astropy.table.SerializedColumn',\n277                                 _serialized_column_constructor)\n278 \n279 for cls, tag in ((u.Quantity, '!astropy.units.Quantity'),\n280                     (u.Magnitude, '!astropy.units.Magnitude'),\n281                     (u.Dex, '!astropy.units.Dex'),\n282                     (u.Decibel, '!astropy.units.Decibel'),\n283                     (coords.Angle, '!astropy.coordinates.Angle'),\n284                     (coords.Latitude, '!astropy.coordinates.Latitude'),\n285                     (coords.Longitude, '!astropy.coordinates.Longitude'),\n286                     (coords.EarthLocation, '!astropy.coordinates.earth.EarthLocation')):\n287     AstropyDumper.add_multi_representer(cls, _quantity_representer(tag))\n288     AstropyLoader.add_constructor(tag, _quantity_constructor(cls))\n289 \n290 for cls in (list(coords.representation.REPRESENTATION_CLASSES.values())\n291             + list(coords.representation.DIFFERENTIAL_CLASSES.values())):\n292     name = cls.__name__\n293     # Add representations/differentials defined in astropy.\n294     if name in coords.representation.__all__:\n295         tag = '!astropy.coordinates.' + name\n296         AstropyDumper.add_multi_representer(cls, _quantity_representer(tag))\n297         AstropyLoader.add_constructor(tag, _quantity_constructor(cls))\n298 \n299 \n300 def load(stream):\n301     \"\"\"Parse the first YAML document in a stream using the AstropyLoader and\n302     produce the corresponding Python object.\n303 \n304     Parameters\n305     ----------\n306     stream : str or file-like\n307         YAML input\n308 \n309     Returns\n310     -------\n311     obj : object\n312         Object corresponding to YAML document\n313     \"\"\"\n314     return yaml.load(stream, Loader=AstropyLoader)\n315 \n316 \n317 def load_all(stream):\n318     \"\"\"Parse the all YAML documents in a stream using the AstropyLoader class and\n319     produce the corresponding Python object.\n320 \n321     Parameters\n322     ----------\n323     stream : str or file-like\n324         YAML input\n325 \n326     Returns\n327     -------\n328     obj : object\n329         Object corresponding to YAML document\n330 \n331     \"\"\"\n332     return yaml.load_all(stream, Loader=AstropyLoader)\n333 \n334 \n335 def dump(data, stream=None, **kwargs):\n336     \"\"\"Serialize a Python object into a YAML stream using the AstropyDumper class.\n337     If stream is None, return the produced string instead.\n338 \n339     Parameters\n340     ----------\n341     data : object\n342         Object to serialize to YAML\n343     stream : file-like, optional\n344         YAML output (if not supplied a string is returned)\n345     **kwargs\n346         Other keyword arguments that get passed to yaml.dump()\n347 \n348     Returns\n349     -------\n350     out : str or None\n351         If no ``stream`` is supplied then YAML output is returned as str\n352 \n353     \"\"\"\n354     kwargs['Dumper'] = AstropyDumper\n355     kwargs.setdefault('default_flow_style', None)\n356     return yaml.dump(data, stream=stream, **kwargs)\n",
        "intended_behavior": "Ensure that the serialization process uniquely represents structured column names, including handling edge cases like 'name'. During deserialization, it should accurately interpret these representations, reconstructing the original structure without misinterpreting special names. This might entail modifying how 'SerializedColumn' objects are output to YAML and ensuring consistent handling upon reading them back."
    }
]