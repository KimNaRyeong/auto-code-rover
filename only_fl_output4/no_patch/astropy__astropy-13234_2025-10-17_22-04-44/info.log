2025-10-17 22:04:44.889 | INFO     | Starting overall retry 0 with model gpt-4-0125-preview
2025-10-17 22:04:48.142 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=1355, output_tokens=13, cost=0.013940
2025-10-17 22:04:59.770 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=1535, output_tokens=418, cost=0.027890
2025-10-17 22:05:00.763 | INFO     | registered non reproducing test 0
2025-10-17 22:05:14.025 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=2328, output_tokens=550, cost=0.039780
2025-10-17 22:05:14.996 | INFO     | registered non reproducing test 1
2025-10-17 22:05:29.907 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=2463, output_tokens=596, cost=0.042510
2025-10-17 22:05:29.934 | WARNING  | Failed to write a reproducer test; skipping reproducer tracing
2025-10-17 22:05:29.940 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-17 22:05:36.817 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=1263, output_tokens=323, cost=0.022320
2025-10-17 22:05:36.825 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-17 22:05:40.209 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=677, output_tokens=112, cost=0.010130
2025-10-17 22:05:40.211 | DEBUG    | the API call 'search_method("write", "Table")' has wrong number of arguments. Will retry.
2025-10-17 22:05:40.216 | DEBUG    | Trying to convert API calls/bug locations into json. Try 2 of 5.
2025-10-17 22:05:45.217 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=677, output_tokens=112, cost=0.010130
2025-10-17 22:05:45.218 | DEBUG    | the API call 'search_method("write", "Table")' has wrong number of arguments. Will retry.
2025-10-17 22:05:45.224 | DEBUG    | Trying to convert API calls/bug locations into json. Try 3 of 5.
2025-10-17 22:05:48.949 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=677, output_tokens=116, cost=0.010250
2025-10-17 22:05:48.951 | DEBUG    | Extracted a valid json.
2025-10-17 22:05:48.951 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_class(\"Table\")",
        "search_class(\"Column\")",
        "search_method_in_class(\"write\", \"Table\")",
        "search_method_in_class(\"read\", \"Table\")",
        "search_code(\"!astropy.table.SerializedColumn\")",
        "search_method(\"serialize\")",
        "search_method_in_class(\"_construct_mixins_from_columns\", \"Table\")",
        "search_method_in_class(\"_construct_mixin_from_columns\", \"Table\")"
    ],
    "bug_locations": []
}
2025-10-17 22:05:49.084 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-17 22:05:49.084 | DEBUG    | <Agent search> Analyzing search results.
2025-10-17 22:06:05.672 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=5316, output_tokens=737, cost=0.075270
2025-10-17 22:06:05.686 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-17 22:06:18.288 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=6269, output_tokens=546, cost=0.079070
2025-10-17 22:06:18.298 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-17 22:06:24.418 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=900, output_tokens=292, cost=0.017760
2025-10-17 22:06:24.420 | DEBUG    | Extracted a valid json.
2025-10-17 22:06:24.420 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_method_in_file(\"write\", \"astropy/table/connect.py\")",
        "search_method_in_file(\"read\", \"astropy/table/connect.py\")",
        "search_code_in_file(\"UnifiedReadWrite\", \"astropy/table/table.py\")",
        "search_method(\"UnifiedReadWriteMethod\")",
        "search_code(\"SerializedColumn\")"
    ],
    "bug_locations": [
        {
            "file": "astropy/io/ascii/ecsv.py",
            "class": "",
            "method": "",
            "intended_behavior": "Ensure that structured column names, like 'name', are correctly serialized into the ECSV format without causing the 'TypeError: unhashable type: 'SerializedColumn''. This includes handling special cases or reserved names appropriately to maintain serialization/deserialization for all valid column names and ensuring compatibility with various types of data in 'Table' objects."
        },
        {
            "file": "astropy/io/misc/yaml.py",
            "class": "",
            "method": "",
            "intended_behavior": "Ensure that structured column names, like 'name', are correctly serialized into the ECSV format without causing the 'TypeError: unhashable type: 'SerializedColumn''. This includes handling special cases or reserved names appropriately to maintain serialization/deserialization for all valid column names and ensuring compatibility with various types of data in 'Table' objects."
        }
    ]
}
2025-10-17 22:06:24.503 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-17 22:06:24.503 | DEBUG    | <Agent search> Analyzing search results.
2025-10-17 22:06:42.708 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=7435, output_tokens=745, cost=0.096700
2025-10-17 22:06:42.715 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-17 22:06:52.968 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=8396, output_tokens=409, cost=0.096230
2025-10-17 22:06:52.976 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-17 22:07:01.267 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=763, output_tokens=236, cost=0.014710
2025-10-17 22:07:01.268 | DEBUG    | Extracted a valid json.
2025-10-17 22:07:01.268 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [],
    "bug_locations": [
        {
            "file": "astropy/table/serialize.py",
            "class": "",
            "method": "",
            "intended_behavior": "Update or refine the logic to handle the special case where a field name coincides with reserved or special terms (e.g., 'name'). This could involve checking for such names and applying a naming convention or escaping mechanism during serialization, ensuring that they are correctly unescaped or converted back during deserialization. The key is to preserve the semantics of the original table, including all column names, without losing information or causing errors due to name clashes."
        },
        {
            "file": "astropy/io/misc/yaml.py",
            "class": "",
            "method": "",
            "intended_behavior": "Ensure that the serialization process uniquely represents structured column names, including handling edge cases like 'name'. During deserialization, it should accurately interpret these representations, reconstructing the original structure without misinterpreting special names. This might entail modifying how 'SerializedColumn' objects are output to YAML and ensuring consistent handling upon reading them back."
        }
    ]
}
2025-10-17 22:07:01.273 | DEBUG    | Bug location extracted successfully: [<file>astropy/table/serialize.py</file>
<class>None</class>
<method>None</method>
<code>
1 # Licensed under a 3-clause BSD style license - see LICENSE.rst
2 from importlib import import_module
3 from copy import deepcopy
4 from collections import OrderedDict
5 
6 import numpy as np
7 
8 from astropy.utils.data_info import MixinInfo
9 from .column import Column, MaskedColumn
10 from .table import Table, QTable, has_info_class
11 from astropy.units.quantity import QuantityInfo
12 
13 
14 # TODO: some of this might be better done programmatically, through
15 # code like
16 # __construct_mixin_classes += tuple(
17 #        f'astropy.coordinates.representation.{cls.__name__}'
18 #        for cls in (list(coorep.REPRESENTATION_CLASSES.values())
19 #                    + list(coorep.DIFFERENTIAL_CLASSES.values()))
20 #        if cls.__name__ in coorep.__all__)
21 # However, to avoid very hard to track import issues, the definition
22 # should then be done at the point where it is actually needed,
23 # using local imports.  See also
24 # https://github.com/astropy/astropy/pull/10210#discussion_r419087286
25 __construct_mixin_classes = (
26     'astropy.time.core.Time',
27     'astropy.time.core.TimeDelta',
28     'astropy.units.quantity.Quantity',
29     'astropy.units.function.logarithmic.Magnitude',
30     'astropy.units.function.logarithmic.Decibel',
31     'astropy.units.function.logarithmic.Dex',
32     'astropy.coordinates.angles.Latitude',
33     'astropy.coordinates.angles.Longitude',
34     'astropy.coordinates.angles.Angle',
35     'astropy.coordinates.distances.Distance',
36     'astropy.coordinates.earth.EarthLocation',
37     'astropy.coordinates.sky_coordinate.SkyCoord',
38     'astropy.table.ndarray_mixin.NdarrayMixin',
39     'astropy.table.table_helpers.ArrayWrapper',
40     'astropy.table.column.Column',
41     'astropy.table.column.MaskedColumn',
42     'astropy.coordinates.representation.CartesianRepresentation',
43     'astropy.coordinates.representation.UnitSphericalRepresentation',
44     'astropy.coordinates.representation.RadialRepresentation',
45     'astropy.coordinates.representation.SphericalRepresentation',
46     'astropy.coordinates.representation.PhysicsSphericalRepresentation',
47     'astropy.coordinates.representation.CylindricalRepresentation',
48     'astropy.coordinates.representation.CartesianDifferential',
49     'astropy.coordinates.representation.UnitSphericalDifferential',
50     'astropy.coordinates.representation.SphericalDifferential',
51     'astropy.coordinates.representation.UnitSphericalCosLatDifferential',
52     'astropy.coordinates.representation.SphericalCosLatDifferential',
53     'astropy.coordinates.representation.RadialDifferential',
54     'astropy.coordinates.representation.PhysicsSphericalDifferential',
55     'astropy.coordinates.representation.CylindricalDifferential',
56     'astropy.utils.masked.core.MaskedNDArray',
57 )
58 
59 
60 class SerializedColumnInfo(MixinInfo):
61     """
62     Minimal info to allow SerializedColumn to be recognized as a mixin Column.
63 
64     Used to help create a dict of columns in ColumnInfo for structured data.
65     """
66     def _represent_as_dict(self):
67         # SerializedColumn is already a `dict`, so we can return it directly.
68         return self._parent
69 
70 
71 class SerializedColumn(dict):
72     """Subclass of dict used to serialize  mixin columns.
73 
74     It is used in the representation to contain the name and possible
75     other info for a mixin column or attribute (either primary data or an
76     array-like attribute) that is serialized as a column in the table.
77 
78     """
79     info = SerializedColumnInfo()
80 
81     @property
82     def shape(self):
83         """Minimal shape implementation to allow use as a mixin column.
84 
85         Returns the shape of the first item that has a shape at all,
86         or ``()`` if none of the values has a shape attribute.
87         """
88         return next((value.shape for value in self.values()
89                      if hasattr(value, 'shape')), ())
90 
91 
92 def _represent_mixin_as_column(col, name, new_cols, mixin_cols,
93                                exclude_classes=()):
94     """Carry out processing needed to serialize ``col`` in an output table
95     consisting purely of plain ``Column`` or ``MaskedColumn`` columns.  This
96     relies on the object determine if any transformation is required and may
97     depend on the ``serialize_method`` and ``serialize_context`` context
98     variables.  For instance a ``MaskedColumn`` may be stored directly to
99     FITS, but can also be serialized as separate data and mask columns.
100 
101     This function builds up a list of plain columns in the ``new_cols`` arg (which
102     is passed as a persistent list).  This includes both plain columns from the
103     original table and plain columns that represent data from serialized columns
104     (e.g. ``jd1`` and ``jd2`` arrays from a ``Time`` column).
105 
106     For serialized columns the ``mixin_cols`` dict is updated with required
107     attributes and information to subsequently reconstruct the table.
108 
109     Table mixin columns are always serialized and get represented by one
110     or more data columns.  In earlier versions of the code *only* mixin
111     columns were serialized, hence the use within this code of "mixin"
112     to imply serialization.  Starting with version 3.1, the non-mixin
113     ``MaskedColumn`` can also be serialized.
114     """
115     obj_attrs = col.info._represent_as_dict()
116 
117     # If serialization is not required (see function docstring above)
118     # or explicitly specified as excluded, then treat as a normal column.
119     if not obj_attrs or col.__class__ in exclude_classes:
120         new_cols.append(col)
121         return
122 
123     # Subtlety here is handling mixin info attributes.  The basic list of such
124     # attributes is: 'name', 'unit', 'dtype', 'format', 'description', 'meta'.
125     # - name: handled directly [DON'T store]
126     # - unit: DON'T store if this is a parent attribute
127     # - dtype: captured in plain Column if relevant [DON'T store]
128     # - format: possibly irrelevant but settable post-object creation [DO store]
129     # - description: DO store
130     # - meta: DO store
131     info = {}
132     for attr, nontrivial in (('unit', lambda x: x is not None and x != ''),
133                              ('format', lambda x: x is not None),
134                              ('description', lambda x: x is not None),
135                              ('meta', lambda x: x)):
136         col_attr = getattr(col.info, attr)
137         if nontrivial(col_attr):
138             info[attr] = col_attr
139 
140     # Find column attributes that have the same length as the column itself.
141     # These will be stored in the table as new columns (aka "data attributes").
142     # Examples include SkyCoord.ra (what is typically considered the data and is
143     # always an array) and Skycoord.obs_time (which can be a scalar or an
144     # array).
145     data_attrs = [key for key, value in obj_attrs.items() if
146                   getattr(value, 'shape', ())[:1] == col.shape[:1]]
147 
148     for data_attr in data_attrs:
149         data = obj_attrs[data_attr]
150 
151         # New column name combines the old name and attribute
152         # (e.g. skycoord.ra, skycoord.dec).unless it is the primary data
153         # attribute for the column (e.g. value for Quantity or data for
154         # MaskedColumn).  For primary data, we attempt to store any info on
155         # the format, etc., on the column, but not for ancillary data (e.g.,
156         # no sense to use a float format for a mask).
157         is_primary = data_attr == col.info._represent_as_dict_primary_data
158         if is_primary:
159             new_name = name
160             new_info = info
161         else:
162             new_name = name + '.' + data_attr
163             new_info = {}
164 
165         if not has_info_class(data, MixinInfo):
166             col_cls = MaskedColumn if (hasattr(data, 'mask')
167                                        and np.any(data.mask)) else Column
168             data = col_cls(data, name=new_name, **new_info)
169             if is_primary:
170                 # Don't store info in the __serialized_columns__ dict for this column
171                 # since this is redundant with info stored on the new column.
172                 info = {}
173 
174         # Recurse. If this is anything that needs further serialization (i.e.,
175         # a Mixin column, a structured Column, a MaskedColumn for which mask is
176         # stored, etc.), it will define obj_attrs[new_name]. Otherwise, it will
177         # just add to new_cols and all we have to do is to link to the new name.
178         _represent_mixin_as_column(data, new_name, new_cols, obj_attrs)
179         obj_attrs[data_attr] = SerializedColumn(obj_attrs.pop(new_name,
180                                                               {'name': new_name}))
181 
182     # Strip out from info any attributes defined by the parent,
183     # and store whatever remains.
184     for attr in col.info.attrs_from_parent:
185         if attr in info:
186             del info[attr]
187     if info:
188         obj_attrs['__info__'] = info
189 
190     # Store the fully qualified class name
191     if not isinstance(col, SerializedColumn):
192         obj_attrs.setdefault('__class__',
193                              col.__module__ + '.' + col.__class__.__name__)
194 
195     mixin_cols[name] = obj_attrs
196 
197 
198 def represent_mixins_as_columns(tbl, exclude_classes=()):
199     """Represent input Table ``tbl`` using only `~astropy.table.Column`
200     or  `~astropy.table.MaskedColumn` objects.
201 
202     This function represents any mixin columns like `~astropy.time.Time` in
203     ``tbl`` to one or more plain ``~astropy.table.Column`` objects and returns
204     a new Table.  A single mixin column may be split into multiple column
205     components as needed for fully representing the column.  This includes the
206     possibility of recursive splitting, as shown in the example below.  The
207     new column names are formed as ``<column_name>.<component>``, e.g.
208     ``sc.ra`` for a `~astropy.coordinates.SkyCoord` column named ``sc``.
209 
210     In addition to splitting columns, this function updates the table ``meta``
211     dictionary to include a dict named ``__serialized_columns__`` which provides
212     additional information needed to construct the original mixin columns from
213     the split columns.
214 
215     This function is used by astropy I/O when writing tables to ECSV, FITS,
216     HDF5 formats.
217 
218     Note that if the table does not include any mixin columns then the original
219     table is returned with no update to ``meta``.
220 
221     Parameters
222     ----------
223     tbl : `~astropy.table.Table` or subclass
224         Table to represent mixins as Columns
225     exclude_classes : tuple of class
226         Exclude any mixin columns which are instannces of any classes in the tuple
227 
228     Returns
229     -------
230     tbl : `~astropy.table.Table`
231         New Table with updated columns, or else the original input ``tbl``
232 
233     Examples
234     --------
235     >>> from astropy.table import Table, represent_mixins_as_columns
236     >>> from astropy.time import Time
237     >>> from astropy.coordinates import SkyCoord
238 
239     >>> x = [100.0, 200.0]
240     >>> obstime = Time([1999.0, 2000.0], format='jyear')
241     >>> sc = SkyCoord([1, 2], [3, 4], unit='deg', obstime=obstime)
242     >>> tbl = Table([sc, x], names=['sc', 'x'])
243     >>> represent_mixins_as_columns(tbl)
244     <Table length=2>
245      sc.ra   sc.dec sc.obstime.jd1 sc.obstime.jd2    x
246       deg     deg
247     float64 float64    float64        float64     float64
248     ------- ------- -------------- -------------- -------
249         1.0     3.0      2451180.0          -0.25   100.0
250         2.0     4.0      2451545.0            0.0   200.0
251 
252     """
253     # Dict of metadata for serializing each column, keyed by column name.
254     # Gets filled in place by _represent_mixin_as_column().
255     mixin_cols = {}
256 
257     # List of columns for the output table.  For plain Column objects
258     # this will just be the original column object.
259     new_cols = []
260 
261     # Go through table columns and represent each column as one or more
262     # plain Column objects (in new_cols) + metadata (in mixin_cols).
263     for col in tbl.itercols():
264         _represent_mixin_as_column(col, col.info.name, new_cols, mixin_cols,
265                                    exclude_classes=exclude_classes)
266 
267     # If no metadata was created then just return the original table.
268     if mixin_cols:
269         meta = deepcopy(tbl.meta)
270         meta['__serialized_columns__'] = mixin_cols
271         out = Table(new_cols, meta=meta, copy=False)
272     else:
273         out = tbl
274 
275     for col in out.itercols():
276         if not isinstance(col, Column) and col.__class__ not in exclude_classes:
277             # This catches columns for which info has not been set up right and
278             # therefore were not converted. See the corresponding test in
279             # test_mixin.py for an example.
280             raise TypeError(
281                 'failed to represent column '
282                 f'{col.info.name!r} ({col.__class__.__name__}) as one '
283                 'or more Column subclasses. This looks like a mixin class '
284                 'that does not have the correct _represent_as_dict() method '
285                 'in the class `info` attribute.')
286 
287     return out
288 
289 
290 def _construct_mixin_from_obj_attrs_and_info(obj_attrs, info):
291     # If this is a supported class then import the class and run
292     # the _construct_from_col method.  Prevent accidentally running
293     # untrusted code by only importing known astropy classes.
294     cls_full_name = obj_attrs.pop('__class__', None)
295     if cls_full_name is None:
296         cls = SerializedColumn
297     elif cls_full_name not in __construct_mixin_classes:
298         raise ValueError(f'unsupported class for construct {cls_full_name}')
299     else:
300         mod_name, _, cls_name = cls_full_name.rpartition('.')
301         module = import_module(mod_name)
302         cls = getattr(module, cls_name)
303 
304     for attr, value in info.items():
305         if attr in cls.info.attrs_from_parent:
306             obj_attrs[attr] = value
307     mixin = cls.info._construct_from_dict(obj_attrs)
308     for attr, value in info.items():
309         if attr not in obj_attrs:
310             setattr(mixin.info, attr, value)
311     return mixin
312 
313 
314 class _TableLite(OrderedDict):
315     """
316     Minimal table-like object for _construct_mixin_from_columns.  This allows
317     manipulating the object like a Table but without the actual overhead
318     for a full Table.
319 
320     More pressing, there is an issue with constructing MaskedColumn, where the
321     encoded Column components (data, mask) are turned into a MaskedColumn.
322     When this happens in a real table then all other columns are immediately
323     Masked and a warning is issued. This is not desirable.
324     """
325 
326     def add_column(self, col, index=0):
327         colnames = self.colnames
328         self[col.info.name] = col
329         for ii, name in enumerate(colnames):
330             if ii >= index:
331                 self.move_to_end(name)
332 
333     @property
334     def colnames(self):
335         return list(self.keys())
336 
337     def itercols(self):
338         return self.values()
339 
340 
341 def _construct_mixin_from_columns(new_name, obj_attrs, out):
342     data_attrs_map = {}
343     for name, val in obj_attrs.items():
344         if isinstance(val, SerializedColumn):
345             if 'name' in val:
346                 data_attrs_map[val['name']] = name
347             else:
348                 out_name = f'{new_name}.{name}'
349                 _construct_mixin_from_columns(out_name, val, out)
350                 data_attrs_map[out_name] = name
351 
352     for name in data_attrs_map.values():
353         del obj_attrs[name]
354 
355     # Get the index where to add new column
356     idx = min(out.colnames.index(name) for name in data_attrs_map)
357 
358     # Name is the column name in the table (e.g. "coord.ra") and
359     # data_attr is the object attribute name  (e.g. "ra").  A different
360     # example would be a formatted time object that would have (e.g.)
361     # "time_col" and "value", respectively.
362     for name, data_attr in data_attrs_map.items():
363         obj_attrs[data_attr] = out[name]
364         del out[name]
365 
366     info = obj_attrs.pop('__info__', {})
367     if len(data_attrs_map) == 1:
368         # col is the first and only serialized column; in that case, use info
369         # stored on the column. First step is to get that first column which
370         # has been moved from `out` to `obj_attrs` above.
371         data_attr = next(iter(data_attrs_map.values()))
372         col = obj_attrs[data_attr]
373 
374         # Now copy the relevant attributes
375         for attr, nontrivial in (('unit', lambda x: x not in (None, '')),
376                                  ('format', lambda x: x is not None),
377                                  ('description', lambda x: x is not None),
378                                  ('meta', lambda x: x)):
379             col_attr = getattr(col.info, attr)
380             if nontrivial(col_attr):
381                 info[attr] = col_attr
382 
383     info['name'] = new_name
384     col = _construct_mixin_from_obj_attrs_and_info(obj_attrs, info)
385     out.add_column(col, index=idx)
386 
387 
388 def _construct_mixins_from_columns(tbl):
389     if '__serialized_columns__' not in tbl.meta:
390         return tbl
391 
392     meta = tbl.meta.copy()
393     mixin_cols = meta.pop('__serialized_columns__')
394 
395     out = _TableLite(tbl.columns)
396 
397     for new_name, obj_attrs in mixin_cols.items():
398         _construct_mixin_from_columns(new_name, obj_attrs, out)
399 
400     # If no quantity subclasses are in the output then output as Table.
401     # For instance ascii.read(file, format='ecsv') doesn't specify an
402     # output class and should return the minimal table class that
403     # represents the table file.
404     has_quantities = any(isinstance(col.info, QuantityInfo)
405                          for col in out.itercols())
406     out_cls = QTable if has_quantities else Table
407 
408     return out_cls(list(out.values()), names=out.colnames, copy=False, meta=meta)

</code><intended_behavior>Update or refine the logic to handle the special case where a field name coincides with reserved or special terms (e.g., 'name'). This could involve checking for such names and applying a naming convention or escaping mechanism during serialization, ensuring that they are correctly unescaped or converted back during deserialization. The key is to preserve the semantics of the original table, including all column names, without losing information or causing errors due to name clashes.</intended_behavior>, <file>astropy/io/misc/yaml.py</file>
<class>None</class>
<method>None</method>
<code>
1 # Licensed under a 3-clause BSD style license - see LICENSE.rst
2 
3 """
4 This module contains functions for serializing core astropy objects via the
5 YAML protocol.
6 It provides functions `~astropy.io.misc.yaml.dump`,
7 `~astropy.io.misc.yaml.load`, and `~astropy.io.misc.yaml.load_all` which
8 call the corresponding functions in `PyYaml <https://pyyaml.org>`_ but use the
9 `~astropy.io.misc.yaml.AstropyDumper` and `~astropy.io.misc.yaml.AstropyLoader`
10 classes to define custom YAML tags for the following astropy classes:
11 - `astropy.units.Unit`
12 - `astropy.units.Quantity`
13 - `astropy.time.Time`
14 - `astropy.time.TimeDelta`
15 - `astropy.coordinates.SkyCoord`
16 - `astropy.coordinates.Angle`
17 - `astropy.coordinates.Latitude`
18 - `astropy.coordinates.Longitude`
19 - `astropy.coordinates.EarthLocation`
20 - `astropy.table.SerializedColumn`
21 
22 Example
23 =======
24 ::
25   >>> from astropy.io.misc import yaml
26   >>> import astropy.units as u
27   >>> from astropy.time import Time
28   >>> from astropy.coordinates import EarthLocation
29   >>> t = Time(2457389.0, format='mjd',
30   ...          location=EarthLocation(1000, 2000, 3000, unit=u.km))
31   >>> td = yaml.dump(t)
32   >>> print(td)
33   !astropy.time.Time
34   format: mjd
35   in_subfmt: '*'
36   jd1: 4857390.0
37   jd2: -0.5
38   location: !astropy.coordinates.earth.EarthLocation
39     ellipsoid: WGS84
40     x: !astropy.units.Quantity
41       unit: &id001 !astropy.units.Unit {unit: km}
42       value: 1000.0
43     y: !astropy.units.Quantity
44       unit: *id001
45       value: 2000.0
46     z: !astropy.units.Quantity
47       unit: *id001
48       value: 3000.0
49   out_subfmt: '*'
50   precision: 3
51   scale: utc
52   >>> ty = yaml.load(td)
53   >>> ty
54   <Time object: scale='utc' format='mjd' value=2457389.0>
55   >>> ty.location  # doctest: +FLOAT_CMP
56   <EarthLocation (1000., 2000., 3000.) km>
57 """
58 
59 import base64
60 
61 import numpy as np
62 import yaml
63 
64 from astropy.time import Time, TimeDelta
65 from astropy import units as u
66 from astropy import coordinates as coords
67 from astropy.table import SerializedColumn
68 
69 
70 __all__ = ['AstropyLoader', 'AstropyDumper', 'load', 'load_all', 'dump']
71 
72 
73 def _unit_representer(dumper, obj):
74     out = {'unit': str(obj.to_string())}
75     return dumper.represent_mapping('!astropy.units.Unit', out)
76 
77 
78 def _unit_constructor(loader, node):
79     map = loader.construct_mapping(node)
80     return u.Unit(map['unit'], parse_strict='warn')
81 
82 
83 def _serialized_column_representer(dumper, obj):
84     out = dumper.represent_mapping('!astropy.table.SerializedColumn', obj)
85     return out
86 
87 
88 def _serialized_column_constructor(loader, node):
89     map = loader.construct_mapping(node)
90     return SerializedColumn(map)
91 
92 
93 def _time_representer(dumper, obj):
94     out = obj.info._represent_as_dict()
95     return dumper.represent_mapping('!astropy.time.Time', out)
96 
97 
98 def _time_constructor(loader, node):
99     map = loader.construct_mapping(node)
100     out = Time.info._construct_from_dict(map)
101     return out
102 
103 
104 def _timedelta_representer(dumper, obj):
105     out = obj.info._represent_as_dict()
106     return dumper.represent_mapping('!astropy.time.TimeDelta', out)
107 
108 
109 def _timedelta_constructor(loader, node):
110     map = loader.construct_mapping(node)
111     out = TimeDelta.info._construct_from_dict(map)
112     return out
113 
114 
115 def _ndarray_representer(dumper, obj):
116     if not (obj.flags['C_CONTIGUOUS'] or obj.flags['F_CONTIGUOUS']):
117         obj = np.ascontiguousarray(obj)
118 
119     if np.isfortran(obj):
120         obj = obj.T
121         order = 'F'
122     else:
123         order = 'C'
124 
125     data_b64 = base64.b64encode(obj.tobytes())
126 
127     out = dict(buffer=data_b64,
128                dtype=str(obj.dtype) if not obj.dtype.fields else obj.dtype.descr,
129                shape=obj.shape,
130                order=order)
131 
132     return dumper.represent_mapping('!numpy.ndarray', out)
133 
134 
135 def _ndarray_constructor(loader, node):
136     # Convert mapping to a dict useful for initializing ndarray.
137     # Need deep=True since for structured dtype, the contents
138     # include lists and tuples, which need recursion via
139     # construct_sequence.
140     map = loader.construct_mapping(node, deep=True)
141     map['buffer'] = base64.b64decode(map['buffer'])
142     return np.ndarray(**map)
143 
144 
145 def _void_representer(dumper, obj):
146     data_b64 = base64.b64encode(obj.tobytes())
147     out = dict(buffer=data_b64,
148                dtype=str(obj.dtype) if not obj.dtype.fields else obj.dtype.descr)
149     return dumper.represent_mapping('!numpy.void', out)
150 
151 
152 def _void_constructor(loader, node):
153     # Interpret as node as an array scalar and then index to change to void.
154     map = loader.construct_mapping(node, deep=True)
155     map['buffer'] = base64.b64decode(map['buffer'])
156     return np.ndarray(shape=(), **map)[()]
157 
158 
159 def _quantity_representer(tag):
160     def representer(dumper, obj):
161         out = obj.info._represent_as_dict()
162         return dumper.represent_mapping(tag, out)
163     return representer
164 
165 
166 def _quantity_constructor(cls):
167     def constructor(loader, node):
168         map = loader.construct_mapping(node)
169         return cls.info._construct_from_dict(map)
170     return constructor
171 
172 
173 def _skycoord_representer(dumper, obj):
174     map = obj.info._represent_as_dict()
175     out = dumper.represent_mapping('!astropy.coordinates.sky_coordinate.SkyCoord',
176                                    map)
177     return out
178 
179 
180 def _skycoord_constructor(loader, node):
181     map = loader.construct_mapping(node)
182     out = coords.SkyCoord.info._construct_from_dict(map)
183     return out
184 
185 
186 # Straight from yaml's Representer
187 def _complex_representer(self, data):
188     if data.imag == 0.0:
189         data = f'{data.real!r}'
190     elif data.real == 0.0:
191         data = f'{data.imag!r}j'
192     elif data.imag > 0:
193         data = f'{data.real!r}+{data.imag!r}j'
194     else:
195         data = f'{data.real!r}{data.imag!r}j'
196     return self.represent_scalar('tag:yaml.org,2002:python/complex', data)
197 
198 
199 def _complex_constructor(loader, node):
200     map = loader.construct_scalar(node)
201     return complex(map)
202 
203 
204 class AstropyLoader(yaml.SafeLoader):
205     """
206     Custom SafeLoader that constructs astropy core objects as well
207     as Python tuple and unicode objects.
208 
209     This class is not directly instantiated by user code, but instead is
210     used to maintain the available constructor functions that are
211     called when parsing a YAML stream.  See the `PyYaml documentation
212     <https://pyyaml.org/wiki/PyYAMLDocumentation>`_ for details of the
213     class signature.
214     """
215 
216     def _construct_python_tuple(self, node):
217         return tuple(self.construct_sequence(node))
218 
219     def _construct_python_unicode(self, node):
220         return self.construct_scalar(node)
221 
222 
223 class AstropyDumper(yaml.SafeDumper):
224     """
225     Custom SafeDumper that represents astropy core objects as well
226     as Python tuple and unicode objects.
227 
228     This class is not directly instantiated by user code, but instead is
229     used to maintain the available representer functions that are
230     called when generating a YAML stream from an object.  See the
231     `PyYaml documentation <https://pyyaml.org/wiki/PyYAMLDocumentation>`_
232     for details of the class signature.
233     """
234 
235     def _represent_tuple(self, data):
236         return self.represent_sequence('tag:yaml.org,2002:python/tuple', data)
237 
238 
239 AstropyDumper.add_multi_representer(u.UnitBase, _unit_representer)
240 AstropyDumper.add_multi_representer(u.FunctionUnitBase, _unit_representer)
241 AstropyDumper.add_multi_representer(u.StructuredUnit, _unit_representer)
242 AstropyDumper.add_representer(tuple, AstropyDumper._represent_tuple)
243 AstropyDumper.add_representer(np.ndarray, _ndarray_representer)
244 AstropyDumper.add_representer(np.void, _void_representer)
245 AstropyDumper.add_representer(Time, _time_representer)
246 AstropyDumper.add_representer(TimeDelta, _timedelta_representer)
247 AstropyDumper.add_representer(coords.SkyCoord, _skycoord_representer)
248 AstropyDumper.add_representer(SerializedColumn, _serialized_column_representer)
249 
250 # Numpy dtypes
251 AstropyDumper.add_representer(np.bool_, yaml.representer.SafeRepresenter.represent_bool)
252 for np_type in [np.int_, np.intc, np.intp, np.int8, np.int16, np.int32,
253                 np.int64, np.uint8, np.uint16, np.uint32, np.uint64]:
254     AstropyDumper.add_representer(np_type,
255                                     yaml.representer.SafeRepresenter.represent_int)
256 for np_type in [np.float_, np.float16, np.float32, np.float64,
257                 np.longdouble]:
258     AstropyDumper.add_representer(np_type,
259                                     yaml.representer.SafeRepresenter.represent_float)
260 for np_type in [np.complex_, complex, np.complex64, np.complex128]:
261     AstropyDumper.add_representer(np_type, _complex_representer)
262 
263 AstropyLoader.add_constructor('tag:yaml.org,2002:python/complex',
264                                 _complex_constructor)
265 AstropyLoader.add_constructor('tag:yaml.org,2002:python/tuple',
266                                 AstropyLoader._construct_python_tuple)
267 AstropyLoader.add_constructor('tag:yaml.org,2002:python/unicode',
268                                 AstropyLoader._construct_python_unicode)
269 AstropyLoader.add_constructor('!astropy.units.Unit', _unit_constructor)
270 AstropyLoader.add_constructor('!numpy.ndarray', _ndarray_constructor)
271 AstropyLoader.add_constructor('!numpy.void', _void_constructor)
272 AstropyLoader.add_constructor('!astropy.time.Time', _time_constructor)
273 AstropyLoader.add_constructor('!astropy.time.TimeDelta', _timedelta_constructor)
274 AstropyLoader.add_constructor('!astropy.coordinates.sky_coordinate.SkyCoord',
275                                 _skycoord_constructor)
276 AstropyLoader.add_constructor('!astropy.table.SerializedColumn',
277                                 _serialized_column_constructor)
278 
279 for cls, tag in ((u.Quantity, '!astropy.units.Quantity'),
280                     (u.Magnitude, '!astropy.units.Magnitude'),
281                     (u.Dex, '!astropy.units.Dex'),
282                     (u.Decibel, '!astropy.units.Decibel'),
283                     (coords.Angle, '!astropy.coordinates.Angle'),
284                     (coords.Latitude, '!astropy.coordinates.Latitude'),
285                     (coords.Longitude, '!astropy.coordinates.Longitude'),
286                     (coords.EarthLocation, '!astropy.coordinates.earth.EarthLocation')):
287     AstropyDumper.add_multi_representer(cls, _quantity_representer(tag))
288     AstropyLoader.add_constructor(tag, _quantity_constructor(cls))
289 
290 for cls in (list(coords.representation.REPRESENTATION_CLASSES.values())
291             + list(coords.representation.DIFFERENTIAL_CLASSES.values())):
292     name = cls.__name__
293     # Add representations/differentials defined in astropy.
294     if name in coords.representation.__all__:
295         tag = '!astropy.coordinates.' + name
296         AstropyDumper.add_multi_representer(cls, _quantity_representer(tag))
297         AstropyLoader.add_constructor(tag, _quantity_constructor(cls))
298 
299 
300 def load(stream):
301     """Parse the first YAML document in a stream using the AstropyLoader and
302     produce the corresponding Python object.
303 
304     Parameters
305     ----------
306     stream : str or file-like
307         YAML input
308 
309     Returns
310     -------
311     obj : object
312         Object corresponding to YAML document
313     """
314     return yaml.load(stream, Loader=AstropyLoader)
315 
316 
317 def load_all(stream):
318     """Parse the all YAML documents in a stream using the AstropyLoader class and
319     produce the corresponding Python object.
320 
321     Parameters
322     ----------
323     stream : str or file-like
324         YAML input
325 
326     Returns
327     -------
328     obj : object
329         Object corresponding to YAML document
330 
331     """
332     return yaml.load_all(stream, Loader=AstropyLoader)
333 
334 
335 def dump(data, stream=None, **kwargs):
336     """Serialize a Python object into a YAML stream using the AstropyDumper class.
337     If stream is None, return the produced string instead.
338 
339     Parameters
340     ----------
341     data : object
342         Object to serialize to YAML
343     stream : file-like, optional
344         YAML output (if not supplied a string is returned)
345     **kwargs
346         Other keyword arguments that get passed to yaml.dump()
347 
348     Returns
349     -------
350     out : str or None
351         If no ``stream`` is supplied then YAML output is returned as str
352 
353     """
354     kwargs['Dumper'] = AstropyDumper
355     kwargs.setdefault('default_flow_style', None)
356     return yaml.dump(data, stream=stream, **kwargs)

</code><intended_behavior>Ensure that the serialization process uniquely represents structured column names, including handling edge cases like 'name'. During deserialization, it should accurately interpret these representations, reconstructing the original structure without misinterpreting special names. This might entail modifying how 'SerializedColumn' objects are output to YAML and ensuring consistent handling upon reading them back.</intended_behavior>]
2025-10-17 22:07:01.273 | INFO     | Search completed. Bug locations: [<file>astropy/table/serialize.py</file>
<class>None</class>
<method>None</method>
<code>
1 # Licensed under a 3-clause BSD style license - see LICENSE.rst
2 from importlib import import_module
3 from copy import deepcopy
4 from collections import OrderedDict
5 
6 import numpy as np
7 
8 from astropy.utils.data_info import MixinInfo
9 from .column import Column, MaskedColumn
10 from .table import Table, QTable, has_info_class
11 from astropy.units.quantity import QuantityInfo
12 
13 
14 # TODO: some of this might be better done programmatically, through
15 # code like
16 # __construct_mixin_classes += tuple(
17 #        f'astropy.coordinates.representation.{cls.__name__}'
18 #        for cls in (list(coorep.REPRESENTATION_CLASSES.values())
19 #                    + list(coorep.DIFFERENTIAL_CLASSES.values()))
20 #        if cls.__name__ in coorep.__all__)
21 # However, to avoid very hard to track import issues, the definition
22 # should then be done at the point where it is actually needed,
23 # using local imports.  See also
24 # https://github.com/astropy/astropy/pull/10210#discussion_r419087286
25 __construct_mixin_classes = (
26     'astropy.time.core.Time',
27     'astropy.time.core.TimeDelta',
28     'astropy.units.quantity.Quantity',
29     'astropy.units.function.logarithmic.Magnitude',
30     'astropy.units.function.logarithmic.Decibel',
31     'astropy.units.function.logarithmic.Dex',
32     'astropy.coordinates.angles.Latitude',
33     'astropy.coordinates.angles.Longitude',
34     'astropy.coordinates.angles.Angle',
35     'astropy.coordinates.distances.Distance',
36     'astropy.coordinates.earth.EarthLocation',
37     'astropy.coordinates.sky_coordinate.SkyCoord',
38     'astropy.table.ndarray_mixin.NdarrayMixin',
39     'astropy.table.table_helpers.ArrayWrapper',
40     'astropy.table.column.Column',
41     'astropy.table.column.MaskedColumn',
42     'astropy.coordinates.representation.CartesianRepresentation',
43     'astropy.coordinates.representation.UnitSphericalRepresentation',
44     'astropy.coordinates.representation.RadialRepresentation',
45     'astropy.coordinates.representation.SphericalRepresentation',
46     'astropy.coordinates.representation.PhysicsSphericalRepresentation',
47     'astropy.coordinates.representation.CylindricalRepresentation',
48     'astropy.coordinates.representation.CartesianDifferential',
49     'astropy.coordinates.representation.UnitSphericalDifferential',
50     'astropy.coordinates.representation.SphericalDifferential',
51     'astropy.coordinates.representation.UnitSphericalCosLatDifferential',
52     'astropy.coordinates.representation.SphericalCosLatDifferential',
53     'astropy.coordinates.representation.RadialDifferential',
54     'astropy.coordinates.representation.PhysicsSphericalDifferential',
55     'astropy.coordinates.representation.CylindricalDifferential',
56     'astropy.utils.masked.core.MaskedNDArray',
57 )
58 
59 
60 class SerializedColumnInfo(MixinInfo):
61     """
62     Minimal info to allow SerializedColumn to be recognized as a mixin Column.
63 
64     Used to help create a dict of columns in ColumnInfo for structured data.
65     """
66     def _represent_as_dict(self):
67         # SerializedColumn is already a `dict`, so we can return it directly.
68         return self._parent
69 
70 
71 class SerializedColumn(dict):
72     """Subclass of dict used to serialize  mixin columns.
73 
74     It is used in the representation to contain the name and possible
75     other info for a mixin column or attribute (either primary data or an
76     array-like attribute) that is serialized as a column in the table.
77 
78     """
79     info = SerializedColumnInfo()
80 
81     @property
82     def shape(self):
83         """Minimal shape implementation to allow use as a mixin column.
84 
85         Returns the shape of the first item that has a shape at all,
86         or ``()`` if none of the values has a shape attribute.
87         """
88         return next((value.shape for value in self.values()
89                      if hasattr(value, 'shape')), ())
90 
91 
92 def _represent_mixin_as_column(col, name, new_cols, mixin_cols,
93                                exclude_classes=()):
94     """Carry out processing needed to serialize ``col`` in an output table
95     consisting purely of plain ``Column`` or ``MaskedColumn`` columns.  This
96     relies on the object determine if any transformation is required and may
97     depend on the ``serialize_method`` and ``serialize_context`` context
98     variables.  For instance a ``MaskedColumn`` may be stored directly to
99     FITS, but can also be serialized as separate data and mask columns.
100 
101     This function builds up a list of plain columns in the ``new_cols`` arg (which
102     is passed as a persistent list).  This includes both plain columns from the
103     original table and plain columns that represent data from serialized columns
104     (e.g. ``jd1`` and ``jd2`` arrays from a ``Time`` column).
105 
106     For serialized columns the ``mixin_cols`` dict is updated with required
107     attributes and information to subsequently reconstruct the table.
108 
109     Table mixin columns are always serialized and get represented by one
110     or more data columns.  In earlier versions of the code *only* mixin
111     columns were serialized, hence the use within this code of "mixin"
112     to imply serialization.  Starting with version 3.1, the non-mixin
113     ``MaskedColumn`` can also be serialized.
114     """
115     obj_attrs = col.info._represent_as_dict()
116 
117     # If serialization is not required (see function docstring above)
118     # or explicitly specified as excluded, then treat as a normal column.
119     if not obj_attrs or col.__class__ in exclude_classes:
120         new_cols.append(col)
121         return
122 
123     # Subtlety here is handling mixin info attributes.  The basic list of such
124     # attributes is: 'name', 'unit', 'dtype', 'format', 'description', 'meta'.
125     # - name: handled directly [DON'T store]
126     # - unit: DON'T store if this is a parent attribute
127     # - dtype: captured in plain Column if relevant [DON'T store]
128     # - format: possibly irrelevant but settable post-object creation [DO store]
129     # - description: DO store
130     # - meta: DO store
131     info = {}
132     for attr, nontrivial in (('unit', lambda x: x is not None and x != ''),
133                              ('format', lambda x: x is not None),
134                              ('description', lambda x: x is not None),
135                              ('meta', lambda x: x)):
136         col_attr = getattr(col.info, attr)
137         if nontrivial(col_attr):
138             info[attr] = col_attr
139 
140     # Find column attributes that have the same length as the column itself.
141     # These will be stored in the table as new columns (aka "data attributes").
142     # Examples include SkyCoord.ra (what is typically considered the data and is
143     # always an array) and Skycoord.obs_time (which can be a scalar or an
144     # array).
145     data_attrs = [key for key, value in obj_attrs.items() if
146                   getattr(value, 'shape', ())[:1] == col.shape[:1]]
147 
148     for data_attr in data_attrs:
149         data = obj_attrs[data_attr]
150 
151         # New column name combines the old name and attribute
152         # (e.g. skycoord.ra, skycoord.dec).unless it is the primary data
153         # attribute for the column (e.g. value for Quantity or data for
154         # MaskedColumn).  For primary data, we attempt to store any info on
155         # the format, etc., on the column, but not for ancillary data (e.g.,
156         # no sense to use a float format for a mask).
157         is_primary = data_attr == col.info._represent_as_dict_primary_data
158         if is_primary:
159             new_name = name
160             new_info = info
161         else:
162             new_name = name + '.' + data_attr
163             new_info = {}
164 
165         if not has_info_class(data, MixinInfo):
166             col_cls = MaskedColumn if (hasattr(data, 'mask')
167                                        and np.any(data.mask)) else Column
168             data = col_cls(data, name=new_name, **new_info)
169             if is_primary:
170                 # Don't store info in the __serialized_columns__ dict for this column
171                 # since this is redundant with info stored on the new column.
172                 info = {}
173 
174         # Recurse. If this is anything that needs further serialization (i.e.,
175         # a Mixin column, a structured Column, a MaskedColumn for which mask is
176         # stored, etc.), it will define obj_attrs[new_name]. Otherwise, it will
177         # just add to new_cols and all we have to do is to link to the new name.
178         _represent_mixin_as_column(data, new_name, new_cols, obj_attrs)
179         obj_attrs[data_attr] = SerializedColumn(obj_attrs.pop(new_name,
180                                                               {'name': new_name}))
181 
182     # Strip out from info any attributes defined by the parent,
183     # and store whatever remains.
184     for attr in col.info.attrs_from_parent:
185         if attr in info:
186             del info[attr]
187     if info:
188         obj_attrs['__info__'] = info
189 
190     # Store the fully qualified class name
191     if not isinstance(col, SerializedColumn):
192         obj_attrs.setdefault('__class__',
193                              col.__module__ + '.' + col.__class__.__name__)
194 
195     mixin_cols[name] = obj_attrs
196 
197 
198 def represent_mixins_as_columns(tbl, exclude_classes=()):
199     """Represent input Table ``tbl`` using only `~astropy.table.Column`
200     or  `~astropy.table.MaskedColumn` objects.
201 
202     This function represents any mixin columns like `~astropy.time.Time` in
203     ``tbl`` to one or more plain ``~astropy.table.Column`` objects and returns
204     a new Table.  A single mixin column may be split into multiple column
205     components as needed for fully representing the column.  This includes the
206     possibility of recursive splitting, as shown in the example below.  The
207     new column names are formed as ``<column_name>.<component>``, e.g.
208     ``sc.ra`` for a `~astropy.coordinates.SkyCoord` column named ``sc``.
209 
210     In addition to splitting columns, this function updates the table ``meta``
211     dictionary to include a dict named ``__serialized_columns__`` which provides
212     additional information needed to construct the original mixin columns from
213     the split columns.
214 
215     This function is used by astropy I/O when writing tables to ECSV, FITS,
216     HDF5 formats.
217 
218     Note that if the table does not include any mixin columns then the original
219     table is returned with no update to ``meta``.
220 
221     Parameters
222     ----------
223     tbl : `~astropy.table.Table` or subclass
224         Table to represent mixins as Columns
225     exclude_classes : tuple of class
226         Exclude any mixin columns which are instannces of any classes in the tuple
227 
228     Returns
229     -------
230     tbl : `~astropy.table.Table`
231         New Table with updated columns, or else the original input ``tbl``
232 
233     Examples
234     --------
235     >>> from astropy.table import Table, represent_mixins_as_columns
236     >>> from astropy.time import Time
237     >>> from astropy.coordinates import SkyCoord
238 
239     >>> x = [100.0, 200.0]
240     >>> obstime = Time([1999.0, 2000.0], format='jyear')
241     >>> sc = SkyCoord([1, 2], [3, 4], unit='deg', obstime=obstime)
242     >>> tbl = Table([sc, x], names=['sc', 'x'])
243     >>> represent_mixins_as_columns(tbl)
244     <Table length=2>
245      sc.ra   sc.dec sc.obstime.jd1 sc.obstime.jd2    x
246       deg     deg
247     float64 float64    float64        float64     float64
248     ------- ------- -------------- -------------- -------
249         1.0     3.0      2451180.0          -0.25   100.0
250         2.0     4.0      2451545.0            0.0   200.0
251 
252     """
253     # Dict of metadata for serializing each column, keyed by column name.
254     # Gets filled in place by _represent_mixin_as_column().
255     mixin_cols = {}
256 
257     # List of columns for the output table.  For plain Column objects
258     # this will just be the original column object.
259     new_cols = []
260 
261     # Go through table columns and represent each column as one or more
262     # plain Column objects (in new_cols) + metadata (in mixin_cols).
263     for col in tbl.itercols():
264         _represent_mixin_as_column(col, col.info.name, new_cols, mixin_cols,
265                                    exclude_classes=exclude_classes)
266 
267     # If no metadata was created then just return the original table.
268     if mixin_cols:
269         meta = deepcopy(tbl.meta)
270         meta['__serialized_columns__'] = mixin_cols
271         out = Table(new_cols, meta=meta, copy=False)
272     else:
273         out = tbl
274 
275     for col in out.itercols():
276         if not isinstance(col, Column) and col.__class__ not in exclude_classes:
277             # This catches columns for which info has not been set up right and
278             # therefore were not converted. See the corresponding test in
279             # test_mixin.py for an example.
280             raise TypeError(
281                 'failed to represent column '
282                 f'{col.info.name!r} ({col.__class__.__name__}) as one '
283                 'or more Column subclasses. This looks like a mixin class '
284                 'that does not have the correct _represent_as_dict() method '
285                 'in the class `info` attribute.')
286 
287     return out
288 
289 
290 def _construct_mixin_from_obj_attrs_and_info(obj_attrs, info):
291     # If this is a supported class then import the class and run
292     # the _construct_from_col method.  Prevent accidentally running
293     # untrusted code by only importing known astropy classes.
294     cls_full_name = obj_attrs.pop('__class__', None)
295     if cls_full_name is None:
296         cls = SerializedColumn
297     elif cls_full_name not in __construct_mixin_classes:
298         raise ValueError(f'unsupported class for construct {cls_full_name}')
299     else:
300         mod_name, _, cls_name = cls_full_name.rpartition('.')
301         module = import_module(mod_name)
302         cls = getattr(module, cls_name)
303 
304     for attr, value in info.items():
305         if attr in cls.info.attrs_from_parent:
306             obj_attrs[attr] = value
307     mixin = cls.info._construct_from_dict(obj_attrs)
308     for attr, value in info.items():
309         if attr not in obj_attrs:
310             setattr(mixin.info, attr, value)
311     return mixin
312 
313 
314 class _TableLite(OrderedDict):
315     """
316     Minimal table-like object for _construct_mixin_from_columns.  This allows
317     manipulating the object like a Table but without the actual overhead
318     for a full Table.
319 
320     More pressing, there is an issue with constructing MaskedColumn, where the
321     encoded Column components (data, mask) are turned into a MaskedColumn.
322     When this happens in a real table then all other columns are immediately
323     Masked and a warning is issued. This is not desirable.
324     """
325 
326     def add_column(self, col, index=0):
327         colnames = self.colnames
328         self[col.info.name] = col
329         for ii, name in enumerate(colnames):
330             if ii >= index:
331                 self.move_to_end(name)
332 
333     @property
334     def colnames(self):
335         return list(self.keys())
336 
337     def itercols(self):
338         return self.values()
339 
340 
341 def _construct_mixin_from_columns(new_name, obj_attrs, out):
342     data_attrs_map = {}
343     for name, val in obj_attrs.items():
344         if isinstance(val, SerializedColumn):
345             if 'name' in val:
346                 data_attrs_map[val['name']] = name
347             else:
348                 out_name = f'{new_name}.{name}'
349                 _construct_mixin_from_columns(out_name, val, out)
350                 data_attrs_map[out_name] = name
351 
352     for name in data_attrs_map.values():
353         del obj_attrs[name]
354 
355     # Get the index where to add new column
356     idx = min(out.colnames.index(name) for name in data_attrs_map)
357 
358     # Name is the column name in the table (e.g. "coord.ra") and
359     # data_attr is the object attribute name  (e.g. "ra").  A different
360     # example would be a formatted time object that would have (e.g.)
361     # "time_col" and "value", respectively.
362     for name, data_attr in data_attrs_map.items():
363         obj_attrs[data_attr] = out[name]
364         del out[name]
365 
366     info = obj_attrs.pop('__info__', {})
367     if len(data_attrs_map) == 1:
368         # col is the first and only serialized column; in that case, use info
369         # stored on the column. First step is to get that first column which
370         # has been moved from `out` to `obj_attrs` above.
371         data_attr = next(iter(data_attrs_map.values()))
372         col = obj_attrs[data_attr]
373 
374         # Now copy the relevant attributes
375         for attr, nontrivial in (('unit', lambda x: x not in (None, '')),
376                                  ('format', lambda x: x is not None),
377                                  ('description', lambda x: x is not None),
378                                  ('meta', lambda x: x)):
379             col_attr = getattr(col.info, attr)
380             if nontrivial(col_attr):
381                 info[attr] = col_attr
382 
383     info['name'] = new_name
384     col = _construct_mixin_from_obj_attrs_and_info(obj_attrs, info)
385     out.add_column(col, index=idx)
386 
387 
388 def _construct_mixins_from_columns(tbl):
389     if '__serialized_columns__' not in tbl.meta:
390         return tbl
391 
392     meta = tbl.meta.copy()
393     mixin_cols = meta.pop('__serialized_columns__')
394 
395     out = _TableLite(tbl.columns)
396 
397     for new_name, obj_attrs in mixin_cols.items():
398         _construct_mixin_from_columns(new_name, obj_attrs, out)
399 
400     # If no quantity subclasses are in the output then output as Table.
401     # For instance ascii.read(file, format='ecsv') doesn't specify an
402     # output class and should return the minimal table class that
403     # represents the table file.
404     has_quantities = any(isinstance(col.info, QuantityInfo)
405                          for col in out.itercols())
406     out_cls = QTable if has_quantities else Table
407 
408     return out_cls(list(out.values()), names=out.colnames, copy=False, meta=meta)

</code><intended_behavior>Update or refine the logic to handle the special case where a field name coincides with reserved or special terms (e.g., 'name'). This could involve checking for such names and applying a naming convention or escaping mechanism during serialization, ensuring that they are correctly unescaped or converted back during deserialization. The key is to preserve the semantics of the original table, including all column names, without losing information or causing errors due to name clashes.</intended_behavior>, <file>astropy/io/misc/yaml.py</file>
<class>None</class>
<method>None</method>
<code>
1 # Licensed under a 3-clause BSD style license - see LICENSE.rst
2 
3 """
4 This module contains functions for serializing core astropy objects via the
5 YAML protocol.
6 It provides functions `~astropy.io.misc.yaml.dump`,
7 `~astropy.io.misc.yaml.load`, and `~astropy.io.misc.yaml.load_all` which
8 call the corresponding functions in `PyYaml <https://pyyaml.org>`_ but use the
9 `~astropy.io.misc.yaml.AstropyDumper` and `~astropy.io.misc.yaml.AstropyLoader`
10 classes to define custom YAML tags for the following astropy classes:
11 - `astropy.units.Unit`
12 - `astropy.units.Quantity`
13 - `astropy.time.Time`
14 - `astropy.time.TimeDelta`
15 - `astropy.coordinates.SkyCoord`
16 - `astropy.coordinates.Angle`
17 - `astropy.coordinates.Latitude`
18 - `astropy.coordinates.Longitude`
19 - `astropy.coordinates.EarthLocation`
20 - `astropy.table.SerializedColumn`
21 
22 Example
23 =======
24 ::
25   >>> from astropy.io.misc import yaml
26   >>> import astropy.units as u
27   >>> from astropy.time import Time
28   >>> from astropy.coordinates import EarthLocation
29   >>> t = Time(2457389.0, format='mjd',
30   ...          location=EarthLocation(1000, 2000, 3000, unit=u.km))
31   >>> td = yaml.dump(t)
32   >>> print(td)
33   !astropy.time.Time
34   format: mjd
35   in_subfmt: '*'
36   jd1: 4857390.0
37   jd2: -0.5
38   location: !astropy.coordinates.earth.EarthLocation
39     ellipsoid: WGS84
40     x: !astropy.units.Quantity
41       unit: &id001 !astropy.units.Unit {unit: km}
42       value: 1000.0
43     y: !astropy.units.Quantity
44       unit: *id001
45       value: 2000.0
46     z: !astropy.units.Quantity
47       unit: *id001
48       value: 3000.0
49   out_subfmt: '*'
50   precision: 3
51   scale: utc
52   >>> ty = yaml.load(td)
53   >>> ty
54   <Time object: scale='utc' format='mjd' value=2457389.0>
55   >>> ty.location  # doctest: +FLOAT_CMP
56   <EarthLocation (1000., 2000., 3000.) km>
57 """
58 
59 import base64
60 
61 import numpy as np
62 import yaml
63 
64 from astropy.time import Time, TimeDelta
65 from astropy import units as u
66 from astropy import coordinates as coords
67 from astropy.table import SerializedColumn
68 
69 
70 __all__ = ['AstropyLoader', 'AstropyDumper', 'load', 'load_all', 'dump']
71 
72 
73 def _unit_representer(dumper, obj):
74     out = {'unit': str(obj.to_string())}
75     return dumper.represent_mapping('!astropy.units.Unit', out)
76 
77 
78 def _unit_constructor(loader, node):
79     map = loader.construct_mapping(node)
80     return u.Unit(map['unit'], parse_strict='warn')
81 
82 
83 def _serialized_column_representer(dumper, obj):
84     out = dumper.represent_mapping('!astropy.table.SerializedColumn', obj)
85     return out
86 
87 
88 def _serialized_column_constructor(loader, node):
89     map = loader.construct_mapping(node)
90     return SerializedColumn(map)
91 
92 
93 def _time_representer(dumper, obj):
94     out = obj.info._represent_as_dict()
95     return dumper.represent_mapping('!astropy.time.Time', out)
96 
97 
98 def _time_constructor(loader, node):
99     map = loader.construct_mapping(node)
100     out = Time.info._construct_from_dict(map)
101     return out
102 
103 
104 def _timedelta_representer(dumper, obj):
105     out = obj.info._represent_as_dict()
106     return dumper.represent_mapping('!astropy.time.TimeDelta', out)
107 
108 
109 def _timedelta_constructor(loader, node):
110     map = loader.construct_mapping(node)
111     out = TimeDelta.info._construct_from_dict(map)
112     return out
113 
114 
115 def _ndarray_representer(dumper, obj):
116     if not (obj.flags['C_CONTIGUOUS'] or obj.flags['F_CONTIGUOUS']):
117         obj = np.ascontiguousarray(obj)
118 
119     if np.isfortran(obj):
120         obj = obj.T
121         order = 'F'
122     else:
123         order = 'C'
124 
125     data_b64 = base64.b64encode(obj.tobytes())
126 
127     out = dict(buffer=data_b64,
128                dtype=str(obj.dtype) if not obj.dtype.fields else obj.dtype.descr,
129                shape=obj.shape,
130                order=order)
131 
132     return dumper.represent_mapping('!numpy.ndarray', out)
133 
134 
135 def _ndarray_constructor(loader, node):
136     # Convert mapping to a dict useful for initializing ndarray.
137     # Need deep=True since for structured dtype, the contents
138     # include lists and tuples, which need recursion via
139     # construct_sequence.
140     map = loader.construct_mapping(node, deep=True)
141     map['buffer'] = base64.b64decode(map['buffer'])
142     return np.ndarray(**map)
143 
144 
145 def _void_representer(dumper, obj):
146     data_b64 = base64.b64encode(obj.tobytes())
147     out = dict(buffer=data_b64,
148                dtype=str(obj.dtype) if not obj.dtype.fields else obj.dtype.descr)
149     return dumper.represent_mapping('!numpy.void', out)
150 
151 
152 def _void_constructor(loader, node):
153     # Interpret as node as an array scalar and then index to change to void.
154     map = loader.construct_mapping(node, deep=True)
155     map['buffer'] = base64.b64decode(map['buffer'])
156     return np.ndarray(shape=(), **map)[()]
157 
158 
159 def _quantity_representer(tag):
160     def representer(dumper, obj):
161         out = obj.info._represent_as_dict()
162         return dumper.represent_mapping(tag, out)
163     return representer
164 
165 
166 def _quantity_constructor(cls):
167     def constructor(loader, node):
168         map = loader.construct_mapping(node)
169         return cls.info._construct_from_dict(map)
170     return constructor
171 
172 
173 def _skycoord_representer(dumper, obj):
174     map = obj.info._represent_as_dict()
175     out = dumper.represent_mapping('!astropy.coordinates.sky_coordinate.SkyCoord',
176                                    map)
177     return out
178 
179 
180 def _skycoord_constructor(loader, node):
181     map = loader.construct_mapping(node)
182     out = coords.SkyCoord.info._construct_from_dict(map)
183     return out
184 
185 
186 # Straight from yaml's Representer
187 def _complex_representer(self, data):
188     if data.imag == 0.0:
189         data = f'{data.real!r}'
190     elif data.real == 0.0:
191         data = f'{data.imag!r}j'
192     elif data.imag > 0:
193         data = f'{data.real!r}+{data.imag!r}j'
194     else:
195         data = f'{data.real!r}{data.imag!r}j'
196     return self.represent_scalar('tag:yaml.org,2002:python/complex', data)
197 
198 
199 def _complex_constructor(loader, node):
200     map = loader.construct_scalar(node)
201     return complex(map)
202 
203 
204 class AstropyLoader(yaml.SafeLoader):
205     """
206     Custom SafeLoader that constructs astropy core objects as well
207     as Python tuple and unicode objects.
208 
209     This class is not directly instantiated by user code, but instead is
210     used to maintain the available constructor functions that are
211     called when parsing a YAML stream.  See the `PyYaml documentation
212     <https://pyyaml.org/wiki/PyYAMLDocumentation>`_ for details of the
213     class signature.
214     """
215 
216     def _construct_python_tuple(self, node):
217         return tuple(self.construct_sequence(node))
218 
219     def _construct_python_unicode(self, node):
220         return self.construct_scalar(node)
221 
222 
223 class AstropyDumper(yaml.SafeDumper):
224     """
225     Custom SafeDumper that represents astropy core objects as well
226     as Python tuple and unicode objects.
227 
228     This class is not directly instantiated by user code, but instead is
229     used to maintain the available representer functions that are
230     called when generating a YAML stream from an object.  See the
231     `PyYaml documentation <https://pyyaml.org/wiki/PyYAMLDocumentation>`_
232     for details of the class signature.
233     """
234 
235     def _represent_tuple(self, data):
236         return self.represent_sequence('tag:yaml.org,2002:python/tuple', data)
237 
238 
239 AstropyDumper.add_multi_representer(u.UnitBase, _unit_representer)
240 AstropyDumper.add_multi_representer(u.FunctionUnitBase, _unit_representer)
241 AstropyDumper.add_multi_representer(u.StructuredUnit, _unit_representer)
242 AstropyDumper.add_representer(tuple, AstropyDumper._represent_tuple)
243 AstropyDumper.add_representer(np.ndarray, _ndarray_representer)
244 AstropyDumper.add_representer(np.void, _void_representer)
245 AstropyDumper.add_representer(Time, _time_representer)
246 AstropyDumper.add_representer(TimeDelta, _timedelta_representer)
247 AstropyDumper.add_representer(coords.SkyCoord, _skycoord_representer)
248 AstropyDumper.add_representer(SerializedColumn, _serialized_column_representer)
249 
250 # Numpy dtypes
251 AstropyDumper.add_representer(np.bool_, yaml.representer.SafeRepresenter.represent_bool)
252 for np_type in [np.int_, np.intc, np.intp, np.int8, np.int16, np.int32,
253                 np.int64, np.uint8, np.uint16, np.uint32, np.uint64]:
254     AstropyDumper.add_representer(np_type,
255                                     yaml.representer.SafeRepresenter.represent_int)
256 for np_type in [np.float_, np.float16, np.float32, np.float64,
257                 np.longdouble]:
258     AstropyDumper.add_representer(np_type,
259                                     yaml.representer.SafeRepresenter.represent_float)
260 for np_type in [np.complex_, complex, np.complex64, np.complex128]:
261     AstropyDumper.add_representer(np_type, _complex_representer)
262 
263 AstropyLoader.add_constructor('tag:yaml.org,2002:python/complex',
264                                 _complex_constructor)
265 AstropyLoader.add_constructor('tag:yaml.org,2002:python/tuple',
266                                 AstropyLoader._construct_python_tuple)
267 AstropyLoader.add_constructor('tag:yaml.org,2002:python/unicode',
268                                 AstropyLoader._construct_python_unicode)
269 AstropyLoader.add_constructor('!astropy.units.Unit', _unit_constructor)
270 AstropyLoader.add_constructor('!numpy.ndarray', _ndarray_constructor)
271 AstropyLoader.add_constructor('!numpy.void', _void_constructor)
272 AstropyLoader.add_constructor('!astropy.time.Time', _time_constructor)
273 AstropyLoader.add_constructor('!astropy.time.TimeDelta', _timedelta_constructor)
274 AstropyLoader.add_constructor('!astropy.coordinates.sky_coordinate.SkyCoord',
275                                 _skycoord_constructor)
276 AstropyLoader.add_constructor('!astropy.table.SerializedColumn',
277                                 _serialized_column_constructor)
278 
279 for cls, tag in ((u.Quantity, '!astropy.units.Quantity'),
280                     (u.Magnitude, '!astropy.units.Magnitude'),
281                     (u.Dex, '!astropy.units.Dex'),
282                     (u.Decibel, '!astropy.units.Decibel'),
283                     (coords.Angle, '!astropy.coordinates.Angle'),
284                     (coords.Latitude, '!astropy.coordinates.Latitude'),
285                     (coords.Longitude, '!astropy.coordinates.Longitude'),
286                     (coords.EarthLocation, '!astropy.coordinates.earth.EarthLocation')):
287     AstropyDumper.add_multi_representer(cls, _quantity_representer(tag))
288     AstropyLoader.add_constructor(tag, _quantity_constructor(cls))
289 
290 for cls in (list(coords.representation.REPRESENTATION_CLASSES.values())
291             + list(coords.representation.DIFFERENTIAL_CLASSES.values())):
292     name = cls.__name__
293     # Add representations/differentials defined in astropy.
294     if name in coords.representation.__all__:
295         tag = '!astropy.coordinates.' + name
296         AstropyDumper.add_multi_representer(cls, _quantity_representer(tag))
297         AstropyLoader.add_constructor(tag, _quantity_constructor(cls))
298 
299 
300 def load(stream):
301     """Parse the first YAML document in a stream using the AstropyLoader and
302     produce the corresponding Python object.
303 
304     Parameters
305     ----------
306     stream : str or file-like
307         YAML input
308 
309     Returns
310     -------
311     obj : object
312         Object corresponding to YAML document
313     """
314     return yaml.load(stream, Loader=AstropyLoader)
315 
316 
317 def load_all(stream):
318     """Parse the all YAML documents in a stream using the AstropyLoader class and
319     produce the corresponding Python object.
320 
321     Parameters
322     ----------
323     stream : str or file-like
324         YAML input
325 
326     Returns
327     -------
328     obj : object
329         Object corresponding to YAML document
330 
331     """
332     return yaml.load_all(stream, Loader=AstropyLoader)
333 
334 
335 def dump(data, stream=None, **kwargs):
336     """Serialize a Python object into a YAML stream using the AstropyDumper class.
337     If stream is None, return the produced string instead.
338 
339     Parameters
340     ----------
341     data : object
342         Object to serialize to YAML
343     stream : file-like, optional
344         YAML output (if not supplied a string is returned)
345     **kwargs
346         Other keyword arguments that get passed to yaml.dump()
347 
348     Returns
349     -------
350     out : str or None
351         If no ``stream`` is supplied then YAML output is returned as str
352 
353     """
354     kwargs['Dumper'] = AstropyDumper
355     kwargs.setdefault('default_flow_style', None)
356     return yaml.dump(data, stream=stream, **kwargs)

</code><intended_behavior>Ensure that the serialization process uniquely represents structured column names, including handling edge cases like 'name'. During deserialization, it should accurately interpret these representations, reconstructing the original structure without misinterpreting special names. This might entail modifying how 'SerializedColumn' objects are output to YAML and ensuring consistent handling upon reading them back.</intended_behavior>]
2025-10-17 22:07:01.274 | INFO     | Overall retry 0 succeeded; ending workflow
2025-10-17 22:07:01.274 | INFO     | Search-only: skipping patch selection
2025-10-17 22:07:01.468 | INFO     | Task astropy__astropy-13234 completed successfully.
2025-10-17 22:07:01.469 | INFO     | No patch generated. You can try running ACR again.
