[
    {
        "rel_file_path": "requests/sessions.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/psf__requests/setup_psf__requests__2.12/requests/sessions.py",
        "start": 1,
        "end": 725,
        "class_name": null,
        "method_name": null,
        "code": "1 # -*- coding: utf-8 -*-\n2 \n3 \"\"\"\n4 requests.session\n5 ~~~~~~~~~~~~~~~~\n6 \n7 This module provides a Session object to manage and persist settings across\n8 requests (cookies, auth, proxies).\n9 \"\"\"\n10 import os\n11 from collections import Mapping\n12 from datetime import datetime\n13 \n14 from .auth import _basic_auth_str\n15 from .compat import cookielib, OrderedDict, urljoin, urlparse\n16 from .cookies import (\n17     cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar, merge_cookies)\n18 from .models import Request, PreparedRequest, DEFAULT_REDIRECT_LIMIT\n19 from .hooks import default_hooks, dispatch_hook\n20 from ._internal_utils import to_native_string\n21 from .utils import to_key_val_list, default_headers\n22 from .exceptions import (\n23     TooManyRedirects, InvalidSchema, ChunkedEncodingError, ContentDecodingError)\n24 from .packages.urllib3._collections import RecentlyUsedContainer\n25 from .structures import CaseInsensitiveDict\n26 \n27 from .adapters import HTTPAdapter\n28 \n29 from .utils import (\n30     requote_uri, get_environ_proxies, get_netrc_auth, should_bypass_proxies,\n31     get_auth_from_url, rewind_body\n32 )\n33 \n34 from .status_codes import codes\n35 \n36 # formerly defined here, reexposed here for backward compatibility\n37 from .models import REDIRECT_STATI\n38 \n39 REDIRECT_CACHE_SIZE = 1000\n40 \n41 \n42 def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n43     \"\"\"Determines appropriate setting for a given request, taking into account\n44     the explicit setting on that request, and the setting in the session. If a\n45     setting is a dictionary, they will be merged together using `dict_class`\n46     \"\"\"\n47 \n48     if session_setting is None:\n49         return request_setting\n50 \n51     if request_setting is None:\n52         return session_setting\n53 \n54     # Bypass if not a dictionary (e.g. verify)\n55     if not (\n56             isinstance(session_setting, Mapping) and\n57             isinstance(request_setting, Mapping)\n58     ):\n59         return request_setting\n60 \n61     merged_setting = dict_class(to_key_val_list(session_setting))\n62     merged_setting.update(to_key_val_list(request_setting))\n63 \n64     # Remove keys that are set to None. Extract keys first to avoid altering\n65     # the dictionary during iteration.\n66     none_keys = [k for (k, v) in merged_setting.items() if v is None]\n67     for key in none_keys:\n68         del merged_setting[key]\n69 \n70     return merged_setting\n71 \n72 \n73 def merge_hooks(request_hooks, session_hooks, dict_class=OrderedDict):\n74     \"\"\"Properly merges both requests and session hooks.\n75 \n76     This is necessary because when request_hooks == {'response': []}, the\n77     merge breaks Session hooks entirely.\n78     \"\"\"\n79     if session_hooks is None or session_hooks.get('response') == []:\n80         return request_hooks\n81 \n82     if request_hooks is None or request_hooks.get('response') == []:\n83         return session_hooks\n84 \n85     return merge_setting(request_hooks, session_hooks, dict_class)\n86 \n87 \n88 class SessionRedirectMixin(object):\n89     def resolve_redirects(self, resp, req, stream=False, timeout=None,\n90                           verify=True, cert=None, proxies=None, **adapter_kwargs):\n91         \"\"\"Receives a Response. Returns a generator of Responses.\"\"\"\n92 \n93         i = 0\n94         hist = [] # keep track of history\n95 \n96         while resp.is_redirect:\n97             prepared_request = req.copy()\n98 \n99             if i > 0:\n100                 # Update history and keep track of redirects.\n101                 hist.append(resp)\n102                 new_hist = list(hist)\n103                 resp.history = new_hist\n104 \n105             try:\n106                 resp.content  # Consume socket so it can be released\n107             except (ChunkedEncodingError, ContentDecodingError, RuntimeError):\n108                 resp.raw.read(decode_content=False)\n109 \n110             if i >= self.max_redirects:\n111                 raise TooManyRedirects('Exceeded %s redirects.' % self.max_redirects, response=resp)\n112 \n113             # Release the connection back into the pool.\n114             resp.close()\n115 \n116             url = resp.headers['location']\n117 \n118             # Handle redirection without scheme (see: RFC 1808 Section 4)\n119             if url.startswith('//'):\n120                 parsed_rurl = urlparse(resp.url)\n121                 url = '%s:%s' % (parsed_rurl.scheme, url)\n122 \n123             # The scheme should be lower case...\n124             parsed = urlparse(url)\n125             url = parsed.geturl()\n126 \n127             # Facilitate relative 'location' headers, as allowed by RFC 7231.\n128             # (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')\n129             # Compliant with RFC3986, we percent encode the url.\n130             if not parsed.netloc:\n131                 url = urljoin(resp.url, requote_uri(url))\n132             else:\n133                 url = requote_uri(url)\n134 \n135             prepared_request.url = to_native_string(url)\n136             # Cache the url, unless it redirects to itself.\n137             if resp.is_permanent_redirect and req.url != prepared_request.url:\n138                 self.redirect_cache[req.url] = prepared_request.url\n139 \n140             self.rebuild_method(prepared_request, resp)\n141 \n142             # https://github.com/kennethreitz/requests/issues/1084\n143             if resp.status_code not in (codes.temporary_redirect, codes.permanent_redirect):\n144                 # https://github.com/kennethreitz/requests/issues/3490\n145                 purged_headers = ('Content-Length', 'Content-Type', 'Transfer-Encoding')\n146                 for header in purged_headers:\n147                     prepared_request.headers.pop(header, None)\n148                 prepared_request.body = None\n149 \n150             headers = prepared_request.headers\n151             try:\n152                 del headers['Cookie']\n153             except KeyError:\n154                 pass\n155 \n156             # Extract any cookies sent on the response to the cookiejar\n157             # in the new request. Because we've mutated our copied prepared\n158             # request, use the old one that we haven't yet touched.\n159             extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)\n160             merge_cookies(prepared_request._cookies, self.cookies)\n161             prepared_request.prepare_cookies(prepared_request._cookies)\n162 \n163             # Rebuild auth and proxy information.\n164             proxies = self.rebuild_proxies(prepared_request, proxies)\n165             self.rebuild_auth(prepared_request, resp)\n166 \n167             # A failed tell() sets `_body_position` to `object()`. This non-None\n168             # value ensures `rewindable` will be True, allowing us to raise an\n169             # UnrewindableBodyError, instead of hanging the connection.\n170             rewindable = (\n171                 prepared_request._body_position is not None and\n172                 ('Content-Length' in headers or 'Transfer-Encoding' in headers)\n173             )\n174 \n175             # Attempt to rewind consumed file-like object.\n176             if rewindable:\n177                 rewind_body(prepared_request)\n178 \n179             # Override the original request.\n180             req = prepared_request\n181 \n182             resp = self.send(\n183                 req,\n184                 stream=stream,\n185                 timeout=timeout,\n186                 verify=verify,\n187                 cert=cert,\n188                 proxies=proxies,\n189                 allow_redirects=False,\n190                 **adapter_kwargs\n191             )\n192 \n193             extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)\n194 \n195             i += 1\n196             yield resp\n197 \n198     def rebuild_auth(self, prepared_request, response):\n199         \"\"\"When being redirected we may want to strip authentication from the\n200         request to avoid leaking credentials. This method intelligently removes\n201         and reapplies authentication where possible to avoid credential loss.\n202         \"\"\"\n203         headers = prepared_request.headers\n204         url = prepared_request.url\n205 \n206         if 'Authorization' in headers:\n207             # If we get redirected to a new host, we should strip out any\n208             # authentication headers.\n209             original_parsed = urlparse(response.request.url)\n210             redirect_parsed = urlparse(url)\n211 \n212             if (original_parsed.hostname != redirect_parsed.hostname):\n213                 del headers['Authorization']\n214 \n215         # .netrc might have more auth for us on our new host.\n216         new_auth = get_netrc_auth(url) if self.trust_env else None\n217         if new_auth is not None:\n218             prepared_request.prepare_auth(new_auth)\n219 \n220         return\n221 \n222     def rebuild_proxies(self, prepared_request, proxies):\n223         \"\"\"This method re-evaluates the proxy configuration by considering the\n224         environment variables. If we are redirected to a URL covered by\n225         NO_PROXY, we strip the proxy configuration. Otherwise, we set missing\n226         proxy keys for this URL (in case they were stripped by a previous\n227         redirect).\n228 \n229         This method also replaces the Proxy-Authorization header where\n230         necessary.\n231 \n232         :rtype: dict\n233         \"\"\"\n234         headers = prepared_request.headers\n235         url = prepared_request.url\n236         scheme = urlparse(url).scheme\n237         new_proxies = proxies.copy() if proxies is not None else {}\n238 \n239         if self.trust_env and not should_bypass_proxies(url):\n240             environ_proxies = get_environ_proxies(url)\n241 \n242             proxy = environ_proxies.get(scheme, environ_proxies.get('all'))\n243 \n244             if proxy:\n245                 new_proxies.setdefault(scheme, proxy)\n246 \n247         if 'Proxy-Authorization' in headers:\n248             del headers['Proxy-Authorization']\n249 \n250         try:\n251             username, password = get_auth_from_url(new_proxies[scheme])\n252         except KeyError:\n253             username, password = None, None\n254 \n255         if username and password:\n256             headers['Proxy-Authorization'] = _basic_auth_str(username, password)\n257 \n258         return new_proxies\n259 \n260     def rebuild_method(self, prepared_request, response):\n261         \"\"\"When being redirected we may want to change the method of the request\n262         based on certain specs or browser behavior.\n263         \"\"\"\n264         method = prepared_request.method\n265 \n266         # http://tools.ietf.org/html/rfc7231#section-6.4.4\n267         if response.status_code == codes.see_other and method != 'HEAD':\n268             method = 'GET'\n269 \n270         # Do what the browsers do, despite standards...\n271         # First, turn 302s into GETs.\n272         if response.status_code == codes.found and method != 'HEAD':\n273             method = 'GET'\n274 \n275         # Second, if a POST is responded to with a 301, turn it into a GET.\n276         # This bizarre behaviour is explained in Issue 1704.\n277         if response.status_code == codes.moved and method == 'POST':\n278             method = 'GET'\n279 \n280         prepared_request.method = method\n281 \n282 \n283 class Session(SessionRedirectMixin):\n284     \"\"\"A Requests session.\n285 \n286     Provides cookie persistence, connection-pooling, and configuration.\n287 \n288     Basic Usage::\n289 \n290       >>> import requests\n291       >>> s = requests.Session()\n292       >>> s.get('http://httpbin.org/get')\n293       <Response [200]>\n294 \n295     Or as a context manager::\n296 \n297       >>> with requests.Session() as s:\n298       >>>     s.get('http://httpbin.org/get')\n299       <Response [200]>\n300     \"\"\"\n301 \n302     __attrs__ = [\n303         'headers', 'cookies', 'auth', 'proxies', 'hooks', 'params', 'verify',\n304         'cert', 'prefetch', 'adapters', 'stream', 'trust_env',\n305         'max_redirects',\n306     ]\n307 \n308     def __init__(self):\n309 \n310         #: A case-insensitive dictionary of headers to be sent on each\n311         #: :class:`Request <Request>` sent from this\n312         #: :class:`Session <Session>`.\n313         self.headers = default_headers()\n314 \n315         #: Default Authentication tuple or object to attach to\n316         #: :class:`Request <Request>`.\n317         self.auth = None\n318 \n319         #: Dictionary mapping protocol or protocol and host to the URL of the proxy\n320         #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to\n321         #: be used on each :class:`Request <Request>`.\n322         self.proxies = {}\n323 \n324         #: Event-handling hooks.\n325         self.hooks = default_hooks()\n326 \n327         #: Dictionary of querystring data to attach to each\n328         #: :class:`Request <Request>`. The dictionary values may be lists for\n329         #: representing multivalued query parameters.\n330         self.params = {}\n331 \n332         #: Stream response content default.\n333         self.stream = False\n334 \n335         #: SSL Verification default.\n336         self.verify = True\n337 \n338         #: SSL client certificate default.\n339         self.cert = None\n340 \n341         #: Maximum number of redirects allowed. If the request exceeds this\n342         #: limit, a :class:`TooManyRedirects` exception is raised.\n343         #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is\n344         #: 30.\n345         self.max_redirects = DEFAULT_REDIRECT_LIMIT\n346 \n347         #: Trust environment settings for proxy configuration, default\n348         #: authentication and similar.\n349         self.trust_env = True\n350 \n351         #: A CookieJar containing all currently outstanding cookies set on this\n352         #: session. By default it is a\n353         #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but\n354         #: may be any other ``cookielib.CookieJar`` compatible object.\n355         self.cookies = cookiejar_from_dict({})\n356 \n357         # Default connection adapters.\n358         self.adapters = OrderedDict()\n359         self.mount('https://', HTTPAdapter())\n360         self.mount('http://', HTTPAdapter())\n361 \n362         # Only store 1000 redirects to prevent using infinite memory\n363         self.redirect_cache = RecentlyUsedContainer(REDIRECT_CACHE_SIZE)\n364 \n365     def __enter__(self):\n366         return self\n367 \n368     def __exit__(self, *args):\n369         self.close()\n370 \n371     def prepare_request(self, request):\n372         \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\n373         transmission and returns it. The :class:`PreparedRequest` has settings\n374         merged from the :class:`Request <Request>` instance and those of the\n375         :class:`Session`.\n376 \n377         :param request: :class:`Request` instance to prepare with this\n378             session's settings.\n379         :rtype: requests.PreparedRequest\n380         \"\"\"\n381         cookies = request.cookies or {}\n382 \n383         # Bootstrap CookieJar.\n384         if not isinstance(cookies, cookielib.CookieJar):\n385             cookies = cookiejar_from_dict(cookies)\n386 \n387         # Merge with session cookies\n388         merged_cookies = merge_cookies(\n389             merge_cookies(RequestsCookieJar(), self.cookies), cookies)\n390 \n391         # Set environment's basic authentication if not explicitly set.\n392         auth = request.auth\n393         if self.trust_env and not auth and not self.auth:\n394             auth = get_netrc_auth(request.url)\n395 \n396         p = PreparedRequest()\n397         p.prepare(\n398             method=request.method.upper(),\n399             url=request.url,\n400             files=request.files,\n401             data=request.data,\n402             json=request.json,\n403             headers=merge_setting(request.headers, self.headers, dict_class=CaseInsensitiveDict),\n404             params=merge_setting(request.params, self.params),\n405             auth=merge_setting(auth, self.auth),\n406             cookies=merged_cookies,\n407             hooks=merge_hooks(request.hooks, self.hooks),\n408         )\n409         return p\n410 \n411     def request(self, method, url,\n412         params=None,\n413         data=None,\n414         headers=None,\n415         cookies=None,\n416         files=None,\n417         auth=None,\n418         timeout=None,\n419         allow_redirects=True,\n420         proxies=None,\n421         hooks=None,\n422         stream=None,\n423         verify=None,\n424         cert=None,\n425         json=None):\n426         \"\"\"Constructs a :class:`Request <Request>`, prepares it and sends it.\n427         Returns :class:`Response <Response>` object.\n428 \n429         :param method: method for the new :class:`Request` object.\n430         :param url: URL for the new :class:`Request` object.\n431         :param params: (optional) Dictionary or bytes to be sent in the query\n432             string for the :class:`Request`.\n433         :param data: (optional) Dictionary, bytes, or file-like object to send\n434             in the body of the :class:`Request`.\n435         :param json: (optional) json to send in the body of the\n436             :class:`Request`.\n437         :param headers: (optional) Dictionary of HTTP Headers to send with the\n438             :class:`Request`.\n439         :param cookies: (optional) Dict or CookieJar object to send with the\n440             :class:`Request`.\n441         :param files: (optional) Dictionary of ``'filename': file-like-objects``\n442             for multipart encoding upload.\n443         :param auth: (optional) Auth tuple or callable to enable\n444             Basic/Digest/Custom HTTP Auth.\n445         :param timeout: (optional) How long to wait for the server to send\n446             data before giving up, as a float, or a :ref:`(connect timeout,\n447             read timeout) <timeouts>` tuple.\n448         :type timeout: float or tuple\n449         :param allow_redirects: (optional) Set to True by default.\n450         :type allow_redirects: bool\n451         :param proxies: (optional) Dictionary mapping protocol or protocol and\n452             hostname to the URL of the proxy.\n453         :param stream: (optional) whether to immediately download the response\n454             content. Defaults to ``False``.\n455         :param verify: (optional) whether the SSL cert will be verified.\n456             A CA_BUNDLE path can also be provided. Defaults to ``True``.\n457         :param cert: (optional) if String, path to ssl client cert file (.pem).\n458             If Tuple, ('cert', 'key') pair.\n459         :rtype: requests.Response\n460         \"\"\"\n461         # Create the Request.\n462         req = Request(\n463             method = method.upper(),\n464             url = url,\n465             headers = headers,\n466             files = files,\n467             data = data or {},\n468             json = json,\n469             params = params or {},\n470             auth = auth,\n471             cookies = cookies,\n472             hooks = hooks,\n473         )\n474         prep = self.prepare_request(req)\n475 \n476         proxies = proxies or {}\n477 \n478         settings = self.merge_environment_settings(\n479             prep.url, proxies, stream, verify, cert\n480         )\n481 \n482         # Send the request.\n483         send_kwargs = {\n484             'timeout': timeout,\n485             'allow_redirects': allow_redirects,\n486         }\n487         send_kwargs.update(settings)\n488         resp = self.send(prep, **send_kwargs)\n489 \n490         return resp\n491 \n492     def get(self, url, **kwargs):\n493         \"\"\"Sends a GET request. Returns :class:`Response` object.\n494 \n495         :param url: URL for the new :class:`Request` object.\n496         :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n497         :rtype: requests.Response\n498         \"\"\"\n499 \n500         kwargs.setdefault('allow_redirects', True)\n501         return self.request('GET', url, **kwargs)\n502 \n503     def options(self, url, **kwargs):\n504         \"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\n505 \n506         :param url: URL for the new :class:`Request` object.\n507         :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n508         :rtype: requests.Response\n509         \"\"\"\n510 \n511         kwargs.setdefault('allow_redirects', True)\n512         return self.request('OPTIONS', url, **kwargs)\n513 \n514     def head(self, url, **kwargs):\n515         \"\"\"Sends a HEAD request. Returns :class:`Response` object.\n516 \n517         :param url: URL for the new :class:`Request` object.\n518         :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n519         :rtype: requests.Response\n520         \"\"\"\n521 \n522         kwargs.setdefault('allow_redirects', False)\n523         return self.request('HEAD', url, **kwargs)\n524 \n525     def post(self, url, data=None, json=None, **kwargs):\n526         \"\"\"Sends a POST request. Returns :class:`Response` object.\n527 \n528         :param url: URL for the new :class:`Request` object.\n529         :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.\n530         :param json: (optional) json to send in the body of the :class:`Request`.\n531         :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n532         :rtype: requests.Response\n533         \"\"\"\n534 \n535         return self.request('POST', url, data=data, json=json, **kwargs)\n536 \n537     def put(self, url, data=None, **kwargs):\n538         \"\"\"Sends a PUT request. Returns :class:`Response` object.\n539 \n540         :param url: URL for the new :class:`Request` object.\n541         :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.\n542         :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n543         :rtype: requests.Response\n544         \"\"\"\n545 \n546         return self.request('PUT', url, data=data, **kwargs)\n547 \n548     def patch(self, url, data=None, **kwargs):\n549         \"\"\"Sends a PATCH request. Returns :class:`Response` object.\n550 \n551         :param url: URL for the new :class:`Request` object.\n552         :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.\n553         :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n554         :rtype: requests.Response\n555         \"\"\"\n556 \n557         return self.request('PATCH', url,  data=data, **kwargs)\n558 \n559     def delete(self, url, **kwargs):\n560         \"\"\"Sends a DELETE request. Returns :class:`Response` object.\n561 \n562         :param url: URL for the new :class:`Request` object.\n563         :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n564         :rtype: requests.Response\n565         \"\"\"\n566 \n567         return self.request('DELETE', url, **kwargs)\n568 \n569     def send(self, request, **kwargs):\n570         \"\"\"\n571         Send a given PreparedRequest.\n572 \n573         :rtype: requests.Response\n574         \"\"\"\n575         # Set defaults that the hooks can utilize to ensure they always have\n576         # the correct parameters to reproduce the previous request.\n577         kwargs.setdefault('stream', self.stream)\n578         kwargs.setdefault('verify', self.verify)\n579         kwargs.setdefault('cert', self.cert)\n580         kwargs.setdefault('proxies', self.proxies)\n581 \n582         # It's possible that users might accidentally send a Request object.\n583         # Guard against that specific failure case.\n584         if isinstance(request, Request):\n585             raise ValueError('You can only send PreparedRequests.')\n586 \n587         # Set up variables needed for resolve_redirects and dispatching of hooks\n588         allow_redirects = kwargs.pop('allow_redirects', True)\n589         stream = kwargs.get('stream')\n590         hooks = request.hooks\n591 \n592         # Resolve URL in redirect cache, if available.\n593         if allow_redirects:\n594             checked_urls = set()\n595             while request.url in self.redirect_cache:\n596                 checked_urls.add(request.url)\n597                 new_url = self.redirect_cache.get(request.url)\n598                 if new_url in checked_urls:\n599                     break\n600                 request.url = new_url\n601 \n602         # Get the appropriate adapter to use\n603         adapter = self.get_adapter(url=request.url)\n604 \n605         # Start time (approximately) of the request\n606         start = datetime.utcnow()\n607 \n608         # Send the request\n609         r = adapter.send(request, **kwargs)\n610 \n611         # Total elapsed time of the request (approximately)\n612         r.elapsed = datetime.utcnow() - start\n613 \n614         # Response manipulation hooks\n615         r = dispatch_hook('response', hooks, r, **kwargs)\n616 \n617         # Persist cookies\n618         if r.history:\n619 \n620             # If the hooks create history then we want those cookies too\n621             for resp in r.history:\n622                 extract_cookies_to_jar(self.cookies, resp.request, resp.raw)\n623 \n624         extract_cookies_to_jar(self.cookies, request, r.raw)\n625 \n626         # Redirect resolving generator.\n627         gen = self.resolve_redirects(r, request, **kwargs)\n628 \n629         # Resolve redirects if allowed.\n630         history = [resp for resp in gen] if allow_redirects else []\n631 \n632         # Shuffle things around if there's history.\n633         if history:\n634             # Insert the first (original) request at the start\n635             history.insert(0, r)\n636             # Get the last request made\n637             r = history.pop()\n638             r.history = history\n639 \n640         if not stream:\n641             r.content\n642 \n643         return r\n644 \n645     def merge_environment_settings(self, url, proxies, stream, verify, cert):\n646         \"\"\"\n647         Check the environment and merge it with some settings.\n648 \n649         :rtype: dict\n650         \"\"\"\n651         # Gather clues from the surrounding environment.\n652         if self.trust_env:\n653             # Set environment's proxies.\n654             env_proxies = get_environ_proxies(url) or {}\n655             for (k, v) in env_proxies.items():\n656                 proxies.setdefault(k, v)\n657 \n658             # Look for requests environment configuration and be compatible\n659             # with cURL.\n660             if verify is True or verify is None:\n661                 verify = (os.environ.get('REQUESTS_CA_BUNDLE') or\n662                           os.environ.get('CURL_CA_BUNDLE'))\n663 \n664         # Merge all the kwargs.\n665         proxies = merge_setting(proxies, self.proxies)\n666         stream = merge_setting(stream, self.stream)\n667         verify = merge_setting(verify, self.verify)\n668         cert = merge_setting(cert, self.cert)\n669 \n670         return {'verify': verify, 'proxies': proxies, 'stream': stream,\n671                 'cert': cert}\n672 \n673     def get_adapter(self, url):\n674         \"\"\"\n675         Returns the appropriate connection adapter for the given URL.\n676 \n677         :rtype: requests.adapters.BaseAdapter\n678         \"\"\"\n679         for (prefix, adapter) in self.adapters.items():\n680 \n681             if url.lower().startswith(prefix):\n682                 return adapter\n683 \n684         # Nothing matches :-/\n685         raise InvalidSchema(\"No connection adapters were found for '%s'\" % url)\n686 \n687     def close(self):\n688         \"\"\"Closes all adapters and as such the session\"\"\"\n689         for v in self.adapters.values():\n690             v.close()\n691 \n692     def mount(self, prefix, adapter):\n693         \"\"\"Registers a connection adapter to a prefix.\n694 \n695         Adapters are sorted in descending order by key length.\n696         \"\"\"\n697         self.adapters[prefix] = adapter\n698         keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n699 \n700         for key in keys_to_move:\n701             self.adapters[key] = self.adapters.pop(key)\n702 \n703     def __getstate__(self):\n704         state = dict((attr, getattr(self, attr, None)) for attr in self.__attrs__)\n705         state['redirect_cache'] = dict(self.redirect_cache)\n706         return state\n707 \n708     def __setstate__(self, state):\n709         redirect_cache = state.pop('redirect_cache', {})\n710         for attr, value in state.items():\n711             setattr(self, attr, value)\n712 \n713         self.redirect_cache = RecentlyUsedContainer(REDIRECT_CACHE_SIZE)\n714         for redirect, to in redirect_cache.items():\n715             self.redirect_cache[redirect] = to\n716 \n717 \n718 def session():\n719     \"\"\"\n720     Returns a :class:`Session` for context-management.\n721 \n722     :rtype: Session\n723     \"\"\"\n724 \n725     return Session()\n",
        "intended_behavior": "Ensure Non-`None` Response Before Access: Add explicit checks around the `requests` call to confirm the presence of a valid response."
    },
    {
        "rel_file_path": "requests/models.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/psf__requests/setup_psf__requests__2.12/requests/models.py",
        "start": 1,
        "end": 900,
        "class_name": null,
        "method_name": null,
        "code": "1 # -*- coding: utf-8 -*-\n2 \n3 \"\"\"\n4 requests.models\n5 ~~~~~~~~~~~~~~~\n6 \n7 This module contains the primary objects that power Requests.\n8 \"\"\"\n9 \n10 import collections\n11 import datetime\n12 \n13 # Import encoding now, to avoid implicit import later.\n14 # Implicit import within threads may cause LookupError when standard library is in a ZIP,\n15 # such as in Embedded Python. See https://github.com/kennethreitz/requests/issues/3578.\n16 import encodings.idna\n17 \n18 from io import BytesIO, UnsupportedOperation\n19 from .hooks import default_hooks\n20 from .structures import CaseInsensitiveDict\n21 \n22 from .auth import HTTPBasicAuth\n23 from .cookies import cookiejar_from_dict, get_cookie_header, _copy_cookie_jar\n24 from .packages import idna\n25 from .packages.urllib3.fields import RequestField\n26 from .packages.urllib3.filepost import encode_multipart_formdata\n27 from .packages.urllib3.util import parse_url\n28 from .packages.urllib3.exceptions import (\n29     DecodeError, ReadTimeoutError, ProtocolError, LocationParseError)\n30 from .exceptions import (\n31     HTTPError, MissingSchema, InvalidURL, ChunkedEncodingError,\n32     ContentDecodingError, ConnectionError, StreamConsumedError)\n33 from ._internal_utils import to_native_string\n34 from .utils import (\n35     guess_filename, get_auth_from_url, requote_uri,\n36     stream_decode_response_unicode, to_key_val_list, parse_header_links,\n37     iter_slices, guess_json_utf, super_len, check_header_validity)\n38 from .compat import (\n39     cookielib, urlunparse, urlsplit, urlencode, str, bytes, StringIO,\n40     is_py2, chardet, builtin_str, basestring)\n41 from .compat import json as complexjson\n42 from .status_codes import codes\n43 \n44 #: The set of HTTP status codes that indicate an automatically\n45 #: processable redirect.\n46 REDIRECT_STATI = (\n47     codes.moved,               # 301\n48     codes.found,               # 302\n49     codes.other,               # 303\n50     codes.temporary_redirect,  # 307\n51     codes.permanent_redirect,  # 308\n52 )\n53 \n54 DEFAULT_REDIRECT_LIMIT = 30\n55 CONTENT_CHUNK_SIZE = 10 * 1024\n56 ITER_CHUNK_SIZE = 512\n57 \n58 \n59 class RequestEncodingMixin(object):\n60     @property\n61     def path_url(self):\n62         \"\"\"Build the path URL to use.\"\"\"\n63 \n64         url = []\n65 \n66         p = urlsplit(self.url)\n67 \n68         path = p.path\n69         if not path:\n70             path = '/'\n71 \n72         url.append(path)\n73 \n74         query = p.query\n75         if query:\n76             url.append('?')\n77             url.append(query)\n78 \n79         return ''.join(url)\n80 \n81     @staticmethod\n82     def _encode_params(data):\n83         \"\"\"Encode parameters in a piece of data.\n84 \n85         Will successfully encode parameters when passed as a dict or a list of\n86         2-tuples. Order is retained if data is a list of 2-tuples but arbitrary\n87         if parameters are supplied as a dict.\n88         \"\"\"\n89 \n90         if isinstance(data, (str, bytes)):\n91             return data\n92         elif hasattr(data, 'read'):\n93             return data\n94         elif hasattr(data, '__iter__'):\n95             result = []\n96             for k, vs in to_key_val_list(data):\n97                 if isinstance(vs, basestring) or not hasattr(vs, '__iter__'):\n98                     vs = [vs]\n99                 for v in vs:\n100                     if v is not None:\n101                         result.append(\n102                             (k.encode('utf-8') if isinstance(k, str) else k,\n103                              v.encode('utf-8') if isinstance(v, str) else v))\n104             return urlencode(result, doseq=True)\n105         else:\n106             return data\n107 \n108     @staticmethod\n109     def _encode_files(files, data):\n110         \"\"\"Build the body for a multipart/form-data request.\n111 \n112         Will successfully encode files when passed as a dict or a list of\n113         tuples. Order is retained if data is a list of tuples but arbitrary\n114         if parameters are supplied as a dict.\n115         The tuples may be 2-tuples (filename, fileobj), 3-tuples (filename, fileobj, contentype)\n116         or 4-tuples (filename, fileobj, contentype, custom_headers).\n117         \"\"\"\n118         if (not files):\n119             raise ValueError(\"Files must be provided.\")\n120         elif isinstance(data, basestring):\n121             raise ValueError(\"Data must not be a string.\")\n122 \n123         new_fields = []\n124         fields = to_key_val_list(data or {})\n125         files = to_key_val_list(files or {})\n126 \n127         for field, val in fields:\n128             if isinstance(val, basestring) or not hasattr(val, '__iter__'):\n129                 val = [val]\n130             for v in val:\n131                 if v is not None:\n132                     # Don't call str() on bytestrings: in Py3 it all goes wrong.\n133                     if not isinstance(v, bytes):\n134                         v = str(v)\n135 \n136                     new_fields.append(\n137                         (field.decode('utf-8') if isinstance(field, bytes) else field,\n138                          v.encode('utf-8') if isinstance(v, str) else v))\n139 \n140         for (k, v) in files:\n141             # support for explicit filename\n142             ft = None\n143             fh = None\n144             if isinstance(v, (tuple, list)):\n145                 if len(v) == 2:\n146                     fn, fp = v\n147                 elif len(v) == 3:\n148                     fn, fp, ft = v\n149                 else:\n150                     fn, fp, ft, fh = v\n151             else:\n152                 fn = guess_filename(v) or k\n153                 fp = v\n154 \n155             if isinstance(fp, (str, bytes, bytearray)):\n156                 fdata = fp\n157             else:\n158                 fdata = fp.read()\n159 \n160             rf = RequestField(name=k, data=fdata, filename=fn, headers=fh)\n161             rf.make_multipart(content_type=ft)\n162             new_fields.append(rf)\n163 \n164         body, content_type = encode_multipart_formdata(new_fields)\n165 \n166         return body, content_type\n167 \n168 \n169 class RequestHooksMixin(object):\n170     def register_hook(self, event, hook):\n171         \"\"\"Properly register a hook.\"\"\"\n172 \n173         if event not in self.hooks:\n174             raise ValueError('Unsupported event specified, with event name \"%s\"' % (event))\n175 \n176         if isinstance(hook, collections.Callable):\n177             self.hooks[event].append(hook)\n178         elif hasattr(hook, '__iter__'):\n179             self.hooks[event].extend(h for h in hook if isinstance(h, collections.Callable))\n180 \n181     def deregister_hook(self, event, hook):\n182         \"\"\"Deregister a previously registered hook.\n183         Returns True if the hook existed, False if not.\n184         \"\"\"\n185 \n186         try:\n187             self.hooks[event].remove(hook)\n188             return True\n189         except ValueError:\n190             return False\n191 \n192 \n193 class Request(RequestHooksMixin):\n194     \"\"\"A user-created :class:`Request <Request>` object.\n195 \n196     Used to prepare a :class:`PreparedRequest <PreparedRequest>`, which is sent to the server.\n197 \n198     :param method: HTTP method to use.\n199     :param url: URL to send.\n200     :param headers: dictionary of headers to send.\n201     :param files: dictionary of {filename: fileobject} files to multipart upload.\n202     :param data: the body to attach to the request. If a dictionary is provided, form-encoding will take place.\n203     :param json: json for the body to attach to the request (if files or data is not specified).\n204     :param params: dictionary of URL parameters to append to the URL.\n205     :param auth: Auth handler or (user, pass) tuple.\n206     :param cookies: dictionary or CookieJar of cookies to attach to this request.\n207     :param hooks: dictionary of callback hooks, for internal usage.\n208 \n209     Usage::\n210 \n211       >>> import requests\n212       >>> req = requests.Request('GET', 'http://httpbin.org/get')\n213       >>> req.prepare()\n214       <PreparedRequest [GET]>\n215     \"\"\"\n216 \n217     def __init__(self, method=None, url=None, headers=None, files=None,\n218         data=None, params=None, auth=None, cookies=None, hooks=None, json=None):\n219 \n220         # Default empty dicts for dict params.\n221         data = [] if data is None else data\n222         files = [] if files is None else files\n223         headers = {} if headers is None else headers\n224         params = {} if params is None else params\n225         hooks = {} if hooks is None else hooks\n226 \n227         self.hooks = default_hooks()\n228         for (k, v) in list(hooks.items()):\n229             self.register_hook(event=k, hook=v)\n230 \n231         self.method = method\n232         self.url = url\n233         self.headers = headers\n234         self.files = files\n235         self.data = data\n236         self.json = json\n237         self.params = params\n238         self.auth = auth\n239         self.cookies = cookies\n240 \n241     def __repr__(self):\n242         return '<Request [%s]>' % (self.method)\n243 \n244     def prepare(self):\n245         \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it.\"\"\"\n246         p = PreparedRequest()\n247         p.prepare(\n248             method=self.method,\n249             url=self.url,\n250             headers=self.headers,\n251             files=self.files,\n252             data=self.data,\n253             json=self.json,\n254             params=self.params,\n255             auth=self.auth,\n256             cookies=self.cookies,\n257             hooks=self.hooks,\n258         )\n259         return p\n260 \n261 \n262 class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):\n263     \"\"\"The fully mutable :class:`PreparedRequest <PreparedRequest>` object,\n264     containing the exact bytes that will be sent to the server.\n265 \n266     Generated from either a :class:`Request <Request>` object or manually.\n267 \n268     Usage::\n269 \n270       >>> import requests\n271       >>> req = requests.Request('GET', 'http://httpbin.org/get')\n272       >>> r = req.prepare()\n273       <PreparedRequest [GET]>\n274 \n275       >>> s = requests.Session()\n276       >>> s.send(r)\n277       <Response [200]>\n278     \"\"\"\n279 \n280     def __init__(self):\n281         #: HTTP verb to send to the server.\n282         self.method = None\n283         #: HTTP URL to send the request to.\n284         self.url = None\n285         #: dictionary of HTTP headers.\n286         self.headers = None\n287         # The `CookieJar` used to create the Cookie header will be stored here\n288         # after prepare_cookies is called\n289         self._cookies = None\n290         #: request body to send to the server.\n291         self.body = None\n292         #: dictionary of callback hooks, for internal usage.\n293         self.hooks = default_hooks()\n294         #: integer denoting starting position of a readable file-like body.\n295         self._body_position = None\n296 \n297     def prepare(self, method=None, url=None, headers=None, files=None,\n298         data=None, params=None, auth=None, cookies=None, hooks=None, json=None):\n299         \"\"\"Prepares the entire request with the given parameters.\"\"\"\n300 \n301         self.prepare_method(method)\n302         self.prepare_url(url, params)\n303         self.prepare_headers(headers)\n304         self.prepare_cookies(cookies)\n305         self.prepare_body(data, files, json)\n306         self.prepare_auth(auth, url)\n307 \n308         # Note that prepare_auth must be last to enable authentication schemes\n309         # such as OAuth to work on a fully prepared request.\n310 \n311         # This MUST go after prepare_auth. Authenticators could add a hook\n312         self.prepare_hooks(hooks)\n313 \n314     def __repr__(self):\n315         return '<PreparedRequest [%s]>' % (self.method)\n316 \n317     def copy(self):\n318         p = PreparedRequest()\n319         p.method = self.method\n320         p.url = self.url\n321         p.headers = self.headers.copy() if self.headers is not None else None\n322         p._cookies = _copy_cookie_jar(self._cookies)\n323         p.body = self.body\n324         p.hooks = self.hooks\n325         p._body_position = self._body_position\n326         return p\n327 \n328     def prepare_method(self, method):\n329         \"\"\"Prepares the given HTTP method.\"\"\"\n330         self.method = method\n331         if self.method is not None:\n332             self.method = to_native_string(self.method.upper())\n333 \n334     def prepare_url(self, url, params):\n335         \"\"\"Prepares the given HTTP URL.\"\"\"\n336         #: Accept objects that have string representations.\n337         #: We're unable to blindly call unicode/str functions\n338         #: as this will include the bytestring indicator (b'')\n339         #: on python 3.x.\n340         #: https://github.com/kennethreitz/requests/pull/2238\n341         if isinstance(url, bytes):\n342             url = url.decode('utf8')\n343         else:\n344             url = unicode(url) if is_py2 else str(url)\n345 \n346         # Remove leading whitespaces from url\n347         url = url.lstrip()\n348 \n349         # Don't do any URL preparation for non-HTTP schemes like `mailto`,\n350         # `data`, `http+unix` etc to work around exceptions from `url_parse`,\n351         # which handles RFC 3986 only.\n352         if ':' in url and not url.lower().startswith(('http://', 'https://')):\n353             self.url = url\n354             return\n355 \n356         # Support for unicode domain names and paths.\n357         try:\n358             scheme, auth, host, port, path, query, fragment = parse_url(url)\n359         except LocationParseError as e:\n360             raise InvalidURL(*e.args)\n361 \n362         if not scheme:\n363             error = (\"Invalid URL {0!r}: No schema supplied. Perhaps you meant http://{0}?\")\n364             error = error.format(to_native_string(url, 'utf8'))\n365 \n366             raise MissingSchema(error)\n367 \n368         if not host:\n369             raise InvalidURL(\"Invalid URL %r: No host supplied\" % url)\n370 \n371         # Only want to apply IDNA to the hostname\n372         try:\n373             host = idna.encode(host, uts46=True).decode('utf-8')\n374         except (UnicodeError, idna.IDNAError):\n375             raise InvalidURL('URL has an invalid label.')\n376 \n377         # Carefully reconstruct the network location\n378         netloc = auth or ''\n379         if netloc:\n380             netloc += '@'\n381         netloc += host\n382         if port:\n383             netloc += ':' + str(port)\n384 \n385         # Bare domains aren't valid URLs.\n386         if not path:\n387             path = '/'\n388 \n389         if is_py2:\n390             if isinstance(scheme, str):\n391                 scheme = scheme.encode('utf-8')\n392             if isinstance(netloc, str):\n393                 netloc = netloc.encode('utf-8')\n394             if isinstance(path, str):\n395                 path = path.encode('utf-8')\n396             if isinstance(query, str):\n397                 query = query.encode('utf-8')\n398             if isinstance(fragment, str):\n399                 fragment = fragment.encode('utf-8')\n400 \n401         if isinstance(params, (str, bytes)):\n402             params = to_native_string(params)\n403 \n404         enc_params = self._encode_params(params)\n405         if enc_params:\n406             if query:\n407                 query = '%s&%s' % (query, enc_params)\n408             else:\n409                 query = enc_params\n410 \n411         url = requote_uri(urlunparse([scheme, netloc, path, None, query, fragment]))\n412         self.url = url\n413 \n414     def prepare_headers(self, headers):\n415         \"\"\"Prepares the given HTTP headers.\"\"\"\n416 \n417         self.headers = CaseInsensitiveDict()\n418         if headers:\n419             for header in headers.items():\n420                 # Raise exception on invalid header value.\n421                 check_header_validity(header)\n422                 name, value = header\n423                 self.headers[to_native_string(name)] = value\n424 \n425     def prepare_body(self, data, files, json=None):\n426         \"\"\"Prepares the given HTTP body data.\"\"\"\n427 \n428         # Check if file, fo, generator, iterator.\n429         # If not, run through normal process.\n430 \n431         # Nottin' on you.\n432         body = None\n433         content_type = None\n434 \n435         if not data and json is not None:\n436             # urllib3 requires a bytes-like body. Python 2's json.dumps\n437             # provides this natively, but Python 3 gives a Unicode string.\n438             content_type = 'application/json'\n439             body = complexjson.dumps(json)\n440             if not isinstance(body, bytes):\n441                 body = body.encode('utf-8')\n442 \n443         is_stream = all([\n444             hasattr(data, '__iter__'),\n445             not isinstance(data, (basestring, list, tuple, collections.Mapping))\n446         ])\n447 \n448         try:\n449             length = super_len(data)\n450         except (TypeError, AttributeError, UnsupportedOperation):\n451             length = None\n452 \n453         if is_stream:\n454             body = data\n455 \n456             if getattr(body, 'tell', None) is not None:\n457                 # Record the current file position before reading.\n458                 # This will allow us to rewind a file in the event\n459                 # of a redirect.\n460                 try:\n461                     self._body_position = body.tell()\n462                 except (IOError, OSError):\n463                     # This differentiates from None, allowing us to catch\n464                     # a failed `tell()` later when trying to rewind the body\n465                     self._body_position = object()\n466 \n467             if files:\n468                 raise NotImplementedError('Streamed bodies and files are mutually exclusive.')\n469 \n470             if length:\n471                 self.headers['Content-Length'] = builtin_str(length)\n472             else:\n473                 self.headers['Transfer-Encoding'] = 'chunked'\n474         else:\n475             # Multi-part file uploads.\n476             if files:\n477                 (body, content_type) = self._encode_files(files, data)\n478             else:\n479                 if data:\n480                     body = self._encode_params(data)\n481                     if isinstance(data, basestring) or hasattr(data, 'read'):\n482                         content_type = None\n483                     else:\n484                         content_type = 'application/x-www-form-urlencoded'\n485 \n486             self.prepare_content_length(body)\n487 \n488             # Add content-type if it wasn't explicitly provided.\n489             if content_type and ('content-type' not in self.headers):\n490                 self.headers['Content-Type'] = content_type\n491 \n492         self.body = body\n493 \n494     def prepare_content_length(self, body):\n495         \"\"\"Prepare Content-Length header based on request method and body\"\"\"\n496         if body is not None:\n497             length = super_len(body)\n498             if length:\n499                 # If length exists, set it. Otherwise, we fallback\n500                 # to Transfer-Encoding: chunked.\n501                 self.headers['Content-Length'] = builtin_str(length)\n502         elif self.method not in ('GET', 'HEAD') and self.headers.get('Content-Length') is None:\n503             # Set Content-Length to 0 for methods that can have a body\n504             # but don't provide one. (i.e. not GET or HEAD)\n505             self.headers['Content-Length'] = '0'\n506 \n507     def prepare_auth(self, auth, url=''):\n508         \"\"\"Prepares the given HTTP auth data.\"\"\"\n509 \n510         # If no Auth is explicitly provided, extract it from the URL first.\n511         if auth is None:\n512             url_auth = get_auth_from_url(self.url)\n513             auth = url_auth if any(url_auth) else None\n514 \n515         if auth:\n516             if isinstance(auth, tuple) and len(auth) == 2:\n517                 # special-case basic HTTP auth\n518                 auth = HTTPBasicAuth(*auth)\n519 \n520             # Allow auth to make its changes.\n521             r = auth(self)\n522 \n523             # Update self to reflect the auth changes.\n524             self.__dict__.update(r.__dict__)\n525 \n526             # Recompute Content-Length\n527             self.prepare_content_length(self.body)\n528 \n529     def prepare_cookies(self, cookies):\n530         \"\"\"Prepares the given HTTP cookie data.\n531 \n532         This function eventually generates a ``Cookie`` header from the\n533         given cookies using cookielib. Due to cookielib's design, the header\n534         will not be regenerated if it already exists, meaning this function\n535         can only be called once for the life of the\n536         :class:`PreparedRequest <PreparedRequest>` object. Any subsequent calls\n537         to ``prepare_cookies`` will have no actual effect, unless the \"Cookie\"\n538         header is removed beforehand.\n539         \"\"\"\n540         if isinstance(cookies, cookielib.CookieJar):\n541             self._cookies = cookies\n542         else:\n543             self._cookies = cookiejar_from_dict(cookies)\n544 \n545         cookie_header = get_cookie_header(self._cookies, self)\n546         if cookie_header is not None:\n547             self.headers['Cookie'] = cookie_header\n548 \n549     def prepare_hooks(self, hooks):\n550         \"\"\"Prepares the given hooks.\"\"\"\n551         # hooks can be passed as None to the prepare method and to this\n552         # method. To prevent iterating over None, simply use an empty list\n553         # if hooks is False-y\n554         hooks = hooks or []\n555         for event in hooks:\n556             self.register_hook(event, hooks[event])\n557 \n558 \n559 class Response(object):\n560     \"\"\"The :class:`Response <Response>` object, which contains a\n561     server's response to an HTTP request.\n562     \"\"\"\n563 \n564     __attrs__ = [\n565         '_content', 'status_code', 'headers', 'url', 'history',\n566         'encoding', 'reason', 'cookies', 'elapsed', 'request'\n567     ]\n568 \n569     def __init__(self):\n570         super(Response, self).__init__()\n571 \n572         self._content = False\n573         self._content_consumed = False\n574 \n575         #: Integer Code of responded HTTP Status, e.g. 404 or 200.\n576         self.status_code = None\n577 \n578         #: Case-insensitive Dictionary of Response Headers.\n579         #: For example, ``headers['content-encoding']`` will return the\n580         #: value of a ``'Content-Encoding'`` response header.\n581         self.headers = CaseInsensitiveDict()\n582 \n583         #: File-like object representation of response (for advanced usage).\n584         #: Use of ``raw`` requires that ``stream=True`` be set on the request.\n585         # This requirement does not apply for use internally to Requests.\n586         self.raw = None\n587 \n588         #: Final URL location of Response.\n589         self.url = None\n590 \n591         #: Encoding to decode with when accessing r.text.\n592         self.encoding = None\n593 \n594         #: A list of :class:`Response <Response>` objects from\n595         #: the history of the Request. Any redirect responses will end\n596         #: up here. The list is sorted from the oldest to the most recent request.\n597         self.history = []\n598 \n599         #: Textual reason of responded HTTP Status, e.g. \"Not Found\" or \"OK\".\n600         self.reason = None\n601 \n602         #: A CookieJar of Cookies the server sent back.\n603         self.cookies = cookiejar_from_dict({})\n604 \n605         #: The amount of time elapsed between sending the request\n606         #: and the arrival of the response (as a timedelta).\n607         #: This property specifically measures the time taken between sending\n608         #: the first byte of the request and finishing parsing the headers. It\n609         #: is therefore unaffected by consuming the response content or the\n610         #: value of the ``stream`` keyword argument.\n611         self.elapsed = datetime.timedelta(0)\n612 \n613         #: The :class:`PreparedRequest <PreparedRequest>` object to which this\n614         #: is a response.\n615         self.request = None\n616 \n617     def __getstate__(self):\n618         # Consume everything; accessing the content attribute makes\n619         # sure the content has been fully read.\n620         if not self._content_consumed:\n621             self.content\n622 \n623         return dict(\n624             (attr, getattr(self, attr, None))\n625             for attr in self.__attrs__\n626         )\n627 \n628     def __setstate__(self, state):\n629         for name, value in state.items():\n630             setattr(self, name, value)\n631 \n632         # pickled objects do not have .raw\n633         setattr(self, '_content_consumed', True)\n634         setattr(self, 'raw', None)\n635 \n636     def __repr__(self):\n637         return '<Response [%s]>' % (self.status_code)\n638 \n639     def __bool__(self):\n640         \"\"\"Returns true if :attr:`status_code` is 'OK'.\"\"\"\n641         return self.ok\n642 \n643     def __nonzero__(self):\n644         \"\"\"Returns true if :attr:`status_code` is 'OK'.\"\"\"\n645         return self.ok\n646 \n647     def __iter__(self):\n648         \"\"\"Allows you to use a response as an iterator.\"\"\"\n649         return self.iter_content(128)\n650 \n651     @property\n652     def ok(self):\n653         try:\n654             self.raise_for_status()\n655         except HTTPError:\n656             return False\n657         return True\n658 \n659     @property\n660     def is_redirect(self):\n661         \"\"\"True if this Response is a well-formed HTTP redirect that could have\n662         been processed automatically (by :meth:`Session.resolve_redirects`).\n663         \"\"\"\n664         return ('location' in self.headers and self.status_code in REDIRECT_STATI)\n665 \n666     @property\n667     def is_permanent_redirect(self):\n668         \"\"\"True if this Response one of the permanent versions of redirect\"\"\"\n669         return ('location' in self.headers and self.status_code in (codes.moved_permanently, codes.permanent_redirect))\n670 \n671     @property\n672     def apparent_encoding(self):\n673         \"\"\"The apparent encoding, provided by the chardet library\"\"\"\n674         return chardet.detect(self.content)['encoding']\n675 \n676     def iter_content(self, chunk_size=1, decode_unicode=False):\n677         \"\"\"Iterates over the response data.  When stream=True is set on the\n678         request, this avoids reading the content at once into memory for\n679         large responses.  The chunk size is the number of bytes it should\n680         read into memory.  This is not necessarily the length of each item\n681         returned as decoding can take place.\n682 \n683         chunk_size must be of type int or None. A value of None will\n684         function differently depending on the value of `stream`.\n685         stream=True will read data as it arrives in whatever size the\n686         chunks are received. If stream=False, data is returned as\n687         a single chunk.\n688 \n689         If decode_unicode is True, content will be decoded using the best\n690         available encoding based on the response.\n691         \"\"\"\n692 \n693         def generate():\n694             # Special case for urllib3.\n695             if hasattr(self.raw, 'stream'):\n696                 try:\n697                     for chunk in self.raw.stream(chunk_size, decode_content=True):\n698                         yield chunk\n699                 except ProtocolError as e:\n700                     raise ChunkedEncodingError(e)\n701                 except DecodeError as e:\n702                     raise ContentDecodingError(e)\n703                 except ReadTimeoutError as e:\n704                     raise ConnectionError(e)\n705             else:\n706                 # Standard file-like object.\n707                 while True:\n708                     chunk = self.raw.read(chunk_size)\n709                     if not chunk:\n710                         break\n711                     yield chunk\n712 \n713             self._content_consumed = True\n714 \n715         if self._content_consumed and isinstance(self._content, bool):\n716             raise StreamConsumedError()\n717         elif chunk_size is not None and not isinstance(chunk_size, int):\n718             raise TypeError(\"chunk_size must be an int, it is instead a %s.\" % type(chunk_size))\n719         # simulate reading small chunks of the content\n720         reused_chunks = iter_slices(self._content, chunk_size)\n721 \n722         stream_chunks = generate()\n723 \n724         chunks = reused_chunks if self._content_consumed else stream_chunks\n725 \n726         if decode_unicode:\n727             chunks = stream_decode_response_unicode(chunks, self)\n728 \n729         return chunks\n730 \n731     def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=None, delimiter=None):\n732         \"\"\"Iterates over the response data, one line at a time.  When\n733         stream=True is set on the request, this avoids reading the\n734         content at once into memory for large responses.\n735 \n736         .. note:: This method is not reentrant safe.\n737         \"\"\"\n738 \n739         pending = None\n740 \n741         for chunk in self.iter_content(chunk_size=chunk_size, decode_unicode=decode_unicode):\n742 \n743             if pending is not None:\n744                 chunk = pending + chunk\n745 \n746             if delimiter:\n747                 lines = chunk.split(delimiter)\n748             else:\n749                 lines = chunk.splitlines()\n750 \n751             if lines and lines[-1] and chunk and lines[-1][-1] == chunk[-1]:\n752                 pending = lines.pop()\n753             else:\n754                 pending = None\n755 \n756             for line in lines:\n757                 yield line\n758 \n759         if pending is not None:\n760             yield pending\n761 \n762     @property\n763     def content(self):\n764         \"\"\"Content of the response, in bytes.\"\"\"\n765 \n766         if self._content is False:\n767             # Read the contents.\n768             if self._content_consumed:\n769                 raise RuntimeError(\n770                     'The content for this response was already consumed')\n771 \n772             if self.status_code == 0:\n773                 self._content = None\n774             else:\n775                 self._content = bytes().join(self.iter_content(CONTENT_CHUNK_SIZE)) or bytes()\n776 \n777         self._content_consumed = True\n778         # don't need to release the connection; that's been handled by urllib3\n779         # since we exhausted the data.\n780         return self._content\n781 \n782     @property\n783     def text(self):\n784         \"\"\"Content of the response, in unicode.\n785 \n786         If Response.encoding is None, encoding will be guessed using\n787         ``chardet``.\n788 \n789         The encoding of the response content is determined based solely on HTTP\n790         headers, following RFC 2616 to the letter. If you can take advantage of\n791         non-HTTP knowledge to make a better guess at the encoding, you should\n792         set ``r.encoding`` appropriately before accessing this property.\n793         \"\"\"\n794 \n795         # Try charset from content-type\n796         content = None\n797         encoding = self.encoding\n798 \n799         if not self.content:\n800             return str('')\n801 \n802         # Fallback to auto-detected encoding.\n803         if self.encoding is None:\n804             encoding = self.apparent_encoding\n805 \n806         # Decode unicode from given encoding.\n807         try:\n808             content = str(self.content, encoding, errors='replace')\n809         except (LookupError, TypeError):\n810             # A LookupError is raised if the encoding was not found which could\n811             # indicate a misspelling or similar mistake.\n812             #\n813             # A TypeError can be raised if encoding is None\n814             #\n815             # So we try blindly encoding.\n816             content = str(self.content, errors='replace')\n817 \n818         return content\n819 \n820     def json(self, **kwargs):\n821         \"\"\"Returns the json-encoded content of a response, if any.\n822 \n823         :param \\*\\*kwargs: Optional arguments that ``json.loads`` takes.\n824         :raises ValueError: If the response body does not contain valid json.\n825         \"\"\"\n826 \n827         if not self.encoding and self.content and len(self.content) > 3:\n828             # No encoding set. JSON RFC 4627 section 3 states we should expect\n829             # UTF-8, -16 or -32. Detect which one to use; If the detection or\n830             # decoding fails, fall back to `self.text` (using chardet to make\n831             # a best guess).\n832             encoding = guess_json_utf(self.content)\n833             if encoding is not None:\n834                 try:\n835                     return complexjson.loads(\n836                         self.content.decode(encoding), **kwargs\n837                     )\n838                 except UnicodeDecodeError:\n839                     # Wrong UTF codec detected; usually because it's not UTF-8\n840                     # but some other 8-bit codec.  This is an RFC violation,\n841                     # and the server didn't bother to tell us what codec *was*\n842                     # used.\n843                     pass\n844         return complexjson.loads(self.text, **kwargs)\n845 \n846     @property\n847     def links(self):\n848         \"\"\"Returns the parsed header links of the response, if any.\"\"\"\n849 \n850         header = self.headers.get('link')\n851 \n852         # l = MultiDict()\n853         l = {}\n854 \n855         if header:\n856             links = parse_header_links(header)\n857 \n858             for link in links:\n859                 key = link.get('rel') or link.get('url')\n860                 l[key] = link\n861 \n862         return l\n863 \n864     def raise_for_status(self):\n865         \"\"\"Raises stored :class:`HTTPError`, if one occurred.\"\"\"\n866 \n867         http_error_msg = ''\n868         if isinstance(self.reason, bytes):\n869             # We attempt to decode utf-8 first because some servers\n870             # choose to localize their reason strings. If the string\n871             # isn't utf-8, we fall back to iso-8859-1 for all other\n872             # encodings. (See PR #3538)\n873             try:\n874                 reason = self.reason.decode('utf-8')\n875             except UnicodeDecodeError:\n876                 reason = self.reason.decode('iso-8859-1')\n877         else:\n878             reason = self.reason\n879 \n880         if 400 <= self.status_code < 500:\n881             http_error_msg = u'%s Client Error: %s for url: %s' % (self.status_code, reason, self.url)\n882 \n883         elif 500 <= self.status_code < 600:\n884             http_error_msg = u'%s Server Error: %s for url: %s' % (self.status_code, reason, self.url)\n885 \n886         if http_error_msg:\n887             raise HTTPError(http_error_msg, response=self)\n888 \n889     def close(self):\n890         \"\"\"Releases the connection back to the pool. Once this method has been\n891         called the underlying ``raw`` object must not be accessed again.\n892 \n893         *Note: Should not normally need to be called explicitly.*\n894         \"\"\"\n895         if not self._content_consumed:\n896             self.raw.close()\n897 \n898         release_conn = getattr(self.raw, 'release_conn', None)\n899         if release_conn is not None:\n900             release_conn()\n",
        "intended_behavior": "Ensure Non-`None` Response Before Access: Add explicit checks around the `requests` call to confirm the presence of a valid response."
    },
    {
        "rel_file_path": "requests/adapters.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/psf__requests/setup_psf__requests__2.12/requests/adapters.py",
        "start": 1,
        "end": 503,
        "class_name": null,
        "method_name": null,
        "code": "1 # -*- coding: utf-8 -*-\n2 \n3 \"\"\"\n4 requests.adapters\n5 ~~~~~~~~~~~~~~~~~\n6 \n7 This module contains the transport adapters that Requests uses to define\n8 and maintain connections.\n9 \"\"\"\n10 \n11 import os.path\n12 import socket\n13 \n14 from .models import Response\n15 from .packages.urllib3.poolmanager import PoolManager, proxy_from_url\n16 from .packages.urllib3.response import HTTPResponse\n17 from .packages.urllib3.util import Timeout as TimeoutSauce\n18 from .packages.urllib3.util.retry import Retry\n19 from .compat import urlparse, basestring\n20 from .utils import (DEFAULT_CA_BUNDLE_PATH, get_encoding_from_headers,\n21                     prepend_scheme_if_needed, get_auth_from_url, urldefragauth,\n22                     select_proxy, to_native_string)\n23 from .structures import CaseInsensitiveDict\n24 from .packages.urllib3.exceptions import ClosedPoolError\n25 from .packages.urllib3.exceptions import ConnectTimeoutError\n26 from .packages.urllib3.exceptions import HTTPError as _HTTPError\n27 from .packages.urllib3.exceptions import MaxRetryError\n28 from .packages.urllib3.exceptions import NewConnectionError\n29 from .packages.urllib3.exceptions import ProxyError as _ProxyError\n30 from .packages.urllib3.exceptions import ProtocolError\n31 from .packages.urllib3.exceptions import ReadTimeoutError\n32 from .packages.urllib3.exceptions import SSLError as _SSLError\n33 from .packages.urllib3.exceptions import ResponseError\n34 from .cookies import extract_cookies_to_jar\n35 from .exceptions import (ConnectionError, ConnectTimeout, ReadTimeout, SSLError,\n36                          ProxyError, RetryError, InvalidSchema)\n37 from .auth import _basic_auth_str\n38 \n39 try:\n40     from .packages.urllib3.contrib.socks import SOCKSProxyManager\n41 except ImportError:\n42     def SOCKSProxyManager(*args, **kwargs):\n43         raise InvalidSchema(\"Missing dependencies for SOCKS support.\")\n44 \n45 DEFAULT_POOLBLOCK = False\n46 DEFAULT_POOLSIZE = 10\n47 DEFAULT_RETRIES = 0\n48 DEFAULT_POOL_TIMEOUT = None\n49 \n50 \n51 class BaseAdapter(object):\n52     \"\"\"The Base Transport Adapter\"\"\"\n53 \n54     def __init__(self):\n55         super(BaseAdapter, self).__init__()\n56 \n57     def send(self, request, stream=False, timeout=None, verify=True,\n58              cert=None, proxies=None):\n59         \"\"\"Sends PreparedRequest object. Returns Response object.\n60 \n61         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n62         :param stream: (optional) Whether to stream the request content.\n63         :param timeout: (optional) How long to wait for the server to send\n64             data before giving up, as a float, or a :ref:`(connect timeout,\n65             read timeout) <timeouts>` tuple.\n66         :type timeout: float or tuple\n67         :param verify: (optional) Whether to verify SSL certificates.\n68         :param cert: (optional) Any user-provided SSL certificate to be trusted.\n69         :param proxies: (optional) The proxies dictionary to apply to the request.\n70         \"\"\"\n71         raise NotImplementedError\n72 \n73     def close(self):\n74         \"\"\"Cleans up adapter specific items.\"\"\"\n75         raise NotImplementedError\n76 \n77 \n78 class HTTPAdapter(BaseAdapter):\n79     \"\"\"The built-in HTTP Adapter for urllib3.\n80 \n81     Provides a general-case interface for Requests sessions to contact HTTP and\n82     HTTPS urls by implementing the Transport Adapter interface. This class will\n83     usually be created by the :class:`Session <Session>` class under the\n84     covers.\n85 \n86     :param pool_connections: The number of urllib3 connection pools to cache.\n87     :param pool_maxsize: The maximum number of connections to save in the pool.\n88     :param max_retries: The maximum number of retries each connection\n89         should attempt. Note, this applies only to failed DNS lookups, socket\n90         connections and connection timeouts, never to requests where data has\n91         made it to the server. By default, Requests does not retry failed\n92         connections. If you need granular control over the conditions under\n93         which we retry a request, import urllib3's ``Retry`` class and pass\n94         that instead.\n95     :param pool_block: Whether the connection pool should block for connections.\n96 \n97     Usage::\n98 \n99       >>> import requests\n100       >>> s = requests.Session()\n101       >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n102       >>> s.mount('http://', a)\n103     \"\"\"\n104     __attrs__ = ['max_retries', 'config', '_pool_connections', '_pool_maxsize',\n105                  '_pool_block']\n106 \n107     def __init__(self, pool_connections=DEFAULT_POOLSIZE,\n108                  pool_maxsize=DEFAULT_POOLSIZE, max_retries=DEFAULT_RETRIES,\n109                  pool_block=DEFAULT_POOLBLOCK):\n110         if max_retries == DEFAULT_RETRIES:\n111             self.max_retries = Retry(0, read=False)\n112         else:\n113             self.max_retries = Retry.from_int(max_retries)\n114         self.config = {}\n115         self.proxy_manager = {}\n116 \n117         super(HTTPAdapter, self).__init__()\n118 \n119         self._pool_connections = pool_connections\n120         self._pool_maxsize = pool_maxsize\n121         self._pool_block = pool_block\n122 \n123         self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n124 \n125     def __getstate__(self):\n126         return dict((attr, getattr(self, attr, None)) for attr in\n127                     self.__attrs__)\n128 \n129     def __setstate__(self, state):\n130         # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n131         # self.poolmanager uses a lambda function, which isn't pickleable.\n132         self.proxy_manager = {}\n133         self.config = {}\n134 \n135         for attr, value in state.items():\n136             setattr(self, attr, value)\n137 \n138         self.init_poolmanager(self._pool_connections, self._pool_maxsize,\n139                               block=self._pool_block)\n140 \n141     def init_poolmanager(self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs):\n142         \"\"\"Initializes a urllib3 PoolManager.\n143 \n144         This method should not be called from user code, and is only\n145         exposed for use when subclassing the\n146         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n147 \n148         :param connections: The number of urllib3 connection pools to cache.\n149         :param maxsize: The maximum number of connections to save in the pool.\n150         :param block: Block when no free connections are available.\n151         :param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.\n152         \"\"\"\n153         # save these values for pickling\n154         self._pool_connections = connections\n155         self._pool_maxsize = maxsize\n156         self._pool_block = block\n157 \n158         self.poolmanager = PoolManager(num_pools=connections, maxsize=maxsize,\n159                                        block=block, strict=True, **pool_kwargs)\n160 \n161     def proxy_manager_for(self, proxy, **proxy_kwargs):\n162         \"\"\"Return urllib3 ProxyManager for the given proxy.\n163 \n164         This method should not be called from user code, and is only\n165         exposed for use when subclassing the\n166         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n167 \n168         :param proxy: The proxy to return a urllib3 ProxyManager for.\n169         :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.\n170         :returns: ProxyManager\n171         :rtype: requests.packages.urllib3.ProxyManager\n172         \"\"\"\n173         if proxy in self.proxy_manager:\n174             manager = self.proxy_manager[proxy]\n175         elif proxy.lower().startswith('socks'):\n176             username, password = get_auth_from_url(proxy)\n177             manager = self.proxy_manager[proxy] = SOCKSProxyManager(\n178                 proxy,\n179                 username=username,\n180                 password=password,\n181                 num_pools=self._pool_connections,\n182                 maxsize=self._pool_maxsize,\n183                 block=self._pool_block,\n184                 **proxy_kwargs\n185             )\n186         else:\n187             proxy_headers = self.proxy_headers(proxy)\n188             manager = self.proxy_manager[proxy] = proxy_from_url(\n189                 proxy,\n190                 proxy_headers=proxy_headers,\n191                 num_pools=self._pool_connections,\n192                 maxsize=self._pool_maxsize,\n193                 block=self._pool_block,\n194                 **proxy_kwargs)\n195 \n196         return manager\n197 \n198     def cert_verify(self, conn, url, verify, cert):\n199         \"\"\"Verify a SSL certificate. This method should not be called from user\n200         code, and is only exposed for use when subclassing the\n201         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n202 \n203         :param conn: The urllib3 connection object associated with the cert.\n204         :param url: The requested URL.\n205         :param verify: Whether we should actually verify the certificate.\n206         :param cert: The SSL certificate to verify.\n207         \"\"\"\n208         if url.lower().startswith('https') and verify:\n209 \n210             cert_loc = None\n211 \n212             # Allow self-specified cert location.\n213             if verify is not True:\n214                 cert_loc = verify\n215 \n216             if not cert_loc:\n217                 cert_loc = DEFAULT_CA_BUNDLE_PATH\n218 \n219             if not cert_loc:\n220                 raise Exception(\"Could not find a suitable SSL CA certificate bundle.\")\n221 \n222             conn.cert_reqs = 'CERT_REQUIRED'\n223 \n224             if not os.path.isdir(cert_loc):\n225                 conn.ca_certs = cert_loc\n226             else:\n227                 conn.ca_cert_dir = cert_loc\n228         else:\n229             conn.cert_reqs = 'CERT_NONE'\n230             conn.ca_certs = None\n231             conn.ca_cert_dir = None\n232 \n233         if cert:\n234             if not isinstance(cert, basestring):\n235                 conn.cert_file = cert[0]\n236                 conn.key_file = cert[1]\n237             else:\n238                 conn.cert_file = cert\n239 \n240     def build_response(self, req, resp):\n241         \"\"\"Builds a :class:`Response <requests.Response>` object from a urllib3\n242         response. This should not be called from user code, and is only exposed\n243         for use when subclassing the\n244         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`\n245 \n246         :param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.\n247         :param resp: The urllib3 response object.\n248         :rtype: requests.Response\n249         \"\"\"\n250         response = Response()\n251 \n252         # Fallback to None if there's no status_code, for whatever reason.\n253         response.status_code = getattr(resp, 'status', None)\n254 \n255         # Make headers case-insensitive.\n256         response.headers = CaseInsensitiveDict(getattr(resp, 'headers', {}))\n257 \n258         # Set encoding.\n259         response.encoding = get_encoding_from_headers(response.headers)\n260         response.raw = resp\n261         response.reason = response.raw.reason\n262 \n263         if isinstance(req.url, bytes):\n264             response.url = req.url.decode('utf-8')\n265         else:\n266             response.url = req.url\n267 \n268         # Add new cookies from the server.\n269         extract_cookies_to_jar(response.cookies, req, resp)\n270 \n271         # Give the Response some context.\n272         response.request = req\n273         response.connection = self\n274 \n275         return response\n276 \n277     def get_connection(self, url, proxies=None):\n278         \"\"\"Returns a urllib3 connection for the given URL. This should not be\n279         called from user code, and is only exposed for use when subclassing the\n280         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n281 \n282         :param url: The URL to connect to.\n283         :param proxies: (optional) A Requests-style dictionary of proxies used on this request.\n284         :rtype: requests.packages.urllib3.ConnectionPool\n285         \"\"\"\n286         proxy = select_proxy(url, proxies)\n287 \n288         if proxy:\n289             proxy = prepend_scheme_if_needed(proxy, 'http')\n290             proxy_manager = self.proxy_manager_for(proxy)\n291             conn = proxy_manager.connection_from_url(url)\n292         else:\n293             # Only scheme should be lower case\n294             parsed = urlparse(url)\n295             url = parsed.geturl()\n296             conn = self.poolmanager.connection_from_url(url)\n297 \n298         return conn\n299 \n300     def close(self):\n301         \"\"\"Disposes of any internal state.\n302 \n303         Currently, this closes the PoolManager and any active ProxyManager,\n304         which closes any pooled connections.\n305         \"\"\"\n306         self.poolmanager.clear()\n307         for proxy in self.proxy_manager.values():\n308             proxy.clear()\n309 \n310     def request_url(self, request, proxies):\n311         \"\"\"Obtain the url to use when making the final request.\n312 \n313         If the message is being sent through a HTTP proxy, the full URL has to\n314         be used. Otherwise, we should only use the path portion of the URL.\n315 \n316         This should not be called from user code, and is only exposed for use\n317         when subclassing the\n318         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n319 \n320         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n321         :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.\n322         :rtype: str\n323         \"\"\"\n324         proxy = select_proxy(request.url, proxies)\n325         scheme = urlparse(request.url).scheme\n326 \n327         is_proxied_http_request = (proxy and scheme != 'https')\n328         using_socks_proxy = False\n329         if proxy:\n330             proxy_scheme = urlparse(proxy).scheme.lower()\n331             using_socks_proxy = proxy_scheme.startswith('socks')\n332 \n333         url = request.path_url\n334         if is_proxied_http_request and not using_socks_proxy:\n335             url = urldefragauth(request.url)\n336 \n337         return url\n338 \n339     def add_headers(self, request, **kwargs):\n340         \"\"\"Add any headers needed by the connection. As of v2.0 this does\n341         nothing by default, but is left for overriding by users that subclass\n342         the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n343 \n344         This should not be called from user code, and is only exposed for use\n345         when subclassing the\n346         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n347 \n348         :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.\n349         :param kwargs: The keyword arguments from the call to send().\n350         \"\"\"\n351         pass\n352 \n353     def proxy_headers(self, proxy):\n354         \"\"\"Returns a dictionary of the headers to add to any request sent\n355         through a proxy. This works with urllib3 magic to ensure that they are\n356         correctly sent to the proxy, rather than in a tunnelled request if\n357         CONNECT is being used.\n358 \n359         This should not be called from user code, and is only exposed for use\n360         when subclassing the\n361         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n362 \n363         :param proxies: The url of the proxy being used for this request.\n364         :rtype: dict\n365         \"\"\"\n366         headers = {}\n367         username, password = get_auth_from_url(proxy)\n368 \n369         if username:\n370             headers['Proxy-Authorization'] = _basic_auth_str(username,\n371                                                              password)\n372 \n373         return headers\n374 \n375     def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n376         \"\"\"Sends PreparedRequest object. Returns Response object.\n377 \n378         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n379         :param stream: (optional) Whether to stream the request content.\n380         :param timeout: (optional) How long to wait for the server to send\n381             data before giving up, as a float, or a :ref:`(connect timeout,\n382             read timeout) <timeouts>` tuple.\n383         :type timeout: float or tuple\n384         :param verify: (optional) Whether to verify SSL certificates.\n385         :param cert: (optional) Any user-provided SSL certificate to be trusted.\n386         :param proxies: (optional) The proxies dictionary to apply to the request.\n387         :rtype: requests.Response\n388         \"\"\"\n389 \n390         conn = self.get_connection(request.url, proxies)\n391 \n392         self.cert_verify(conn, request.url, verify, cert)\n393         url = self.request_url(request, proxies)\n394         self.add_headers(request)\n395 \n396         chunked = not (request.body is None or 'Content-Length' in request.headers)\n397 \n398         if isinstance(timeout, tuple):\n399             try:\n400                 connect, read = timeout\n401                 timeout = TimeoutSauce(connect=connect, read=read)\n402             except ValueError as e:\n403                 # this may raise a string formatting error.\n404                 err = (\"Invalid timeout {0}. Pass a (connect, read) \"\n405                        \"timeout tuple, or a single float to set \"\n406                        \"both timeouts to the same value\".format(timeout))\n407                 raise ValueError(err)\n408         else:\n409             timeout = TimeoutSauce(connect=timeout, read=timeout)\n410 \n411         try:\n412             if not chunked:\n413                 resp = conn.urlopen(\n414                     method=request.method,\n415                     url=url,\n416                     body=request.body,\n417                     headers=request.headers,\n418                     redirect=False,\n419                     assert_same_host=False,\n420                     preload_content=False,\n421                     decode_content=False,\n422                     retries=self.max_retries,\n423                     timeout=timeout\n424                 )\n425 \n426             # Send the request.\n427             else:\n428                 if hasattr(conn, 'proxy_pool'):\n429                     conn = conn.proxy_pool\n430 \n431                 low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)\n432 \n433                 try:\n434                     low_conn.putrequest(request.method,\n435                                         url,\n436                                         skip_accept_encoding=True)\n437 \n438                     for header, value in request.headers.items():\n439                         low_conn.putheader(header, value)\n440 \n441                     low_conn.endheaders()\n442 \n443                     for i in request.body:\n444                         low_conn.send(hex(len(i))[2:].encode('utf-8'))\n445                         low_conn.send(b'\\r\\n')\n446                         low_conn.send(i)\n447                         low_conn.send(b'\\r\\n')\n448                     low_conn.send(b'0\\r\\n\\r\\n')\n449 \n450                     # Receive the response from the server\n451                     try:\n452                         # For Python 2.7+ versions, use buffering of HTTP\n453                         # responses\n454                         r = low_conn.getresponse(buffering=True)\n455                     except TypeError:\n456                         # For compatibility with Python 2.6 versions and back\n457                         r = low_conn.getresponse()\n458 \n459                     resp = HTTPResponse.from_httplib(\n460                         r,\n461                         pool=conn,\n462                         connection=low_conn,\n463                         preload_content=False,\n464                         decode_content=False\n465                     )\n466                 except:\n467                     # If we hit any problems here, clean up the connection.\n468                     # Then, reraise so that we can handle the actual exception.\n469                     low_conn.close()\n470                     raise\n471 \n472         except (ProtocolError, socket.error) as err:\n473             raise ConnectionError(err, request=request)\n474 \n475         except MaxRetryError as e:\n476             if isinstance(e.reason, ConnectTimeoutError):\n477                 # TODO: Remove this in 3.0.0: see #2811\n478                 if not isinstance(e.reason, NewConnectionError):\n479                     raise ConnectTimeout(e, request=request)\n480 \n481             if isinstance(e.reason, ResponseError):\n482                 raise RetryError(e, request=request)\n483 \n484             if isinstance(e.reason, _ProxyError):\n485                 raise ProxyError(e, request=request)\n486 \n487             raise ConnectionError(e, request=request)\n488 \n489         except ClosedPoolError as e:\n490             raise ConnectionError(e, request=request)\n491 \n492         except _ProxyError as e:\n493             raise ProxyError(e)\n494 \n495         except (_SSLError, _HTTPError) as e:\n496             if isinstance(e, _SSLError):\n497                 raise SSLError(e, request=request)\n498             elif isinstance(e, ReadTimeoutError):\n499                 raise ReadTimeout(e, request=request)\n500             else:\n501                 raise\n502 \n503         return self.build_response(request, resp)\n",
        "intended_behavior": "Ensure Non-`None` Response Before Access: Add explicit checks around the `requests` call to confirm the presence of a valid response."
    },
    {
        "rel_file_path": "requests/api.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/psf__requests/setup_psf__requests__2.12/requests/api.py",
        "start": 86,
        "end": 96,
        "class_name": null,
        "method_name": "head",
        "code": "86 def head(url, **kwargs):\n87     \"\"\"Sends a HEAD request.\n88 \n89     :param url: URL for the new :class:`Request` object.\n90     :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n91     :return: :class:`Response <Response>` object\n92     :rtype: requests.Response\n93     \"\"\"\n94 \n95     kwargs.setdefault('allow_redirects', False)\n96     return request('head', url, **kwargs)\n",
        "intended_behavior": "Robust Exception Handling for `requests` Calls: Enhance error handling around `requests` library calls to catch exceptions such as `requests.exceptions.RequestException`."
    },
    {
        "rel_file_path": "requests/sessions.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/psf__requests/setup_psf__requests__2.12/requests/sessions.py",
        "start": 514,
        "end": 523,
        "class_name": null,
        "method_name": "head",
        "code": "514     def head(self, url, **kwargs):\n515         \"\"\"Sends a HEAD request. Returns :class:`Response` object.\n516 \n517         :param url: URL for the new :class:`Request` object.\n518         :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n519         :rtype: requests.Response\n520         \"\"\"\n521 \n522         kwargs.setdefault('allow_redirects', False)\n523         return self.request('HEAD', url, **kwargs)\n",
        "intended_behavior": "Robust Exception Handling for `requests` Calls: Enhance error handling around `requests` library calls to catch exceptions such as `requests.exceptions.RequestException`."
    },
    {
        "rel_file_path": "requests/sessions.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/psf__requests/setup_psf__requests__2.12/requests/sessions.py",
        "start": 514,
        "end": 523,
        "class_name": "Session",
        "method_name": "head",
        "code": "514     def head(self, url, **kwargs):\n515         \"\"\"Sends a HEAD request. Returns :class:`Response` object.\n516 \n517         :param url: URL for the new :class:`Request` object.\n518         :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n519         :rtype: requests.Response\n520         \"\"\"\n521 \n522         kwargs.setdefault('allow_redirects', False)\n523         return self.request('HEAD', url, **kwargs)\n",
        "intended_behavior": "Robust Exception Handling for `requests` Calls: Enhance error handling around `requests` library calls to catch exceptions such as `requests.exceptions.RequestException`."
    }
]