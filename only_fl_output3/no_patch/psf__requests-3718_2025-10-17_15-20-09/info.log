2025-10-17 15:20:10.044 | INFO     | Starting overall retry 0 with model gpt-4-0125-preview
2025-10-17 15:20:11.946 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=886, output_tokens=12, cost=0.009220
2025-10-17 15:20:11.947 | INFO     | Test agent decides that the issue statement does not contain reproduction steps; skipping reproducer tracing
2025-10-17 15:20:11.952 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-17 15:20:20.321 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=1152, output_tokens=319, cost=0.021090
2025-10-17 15:20:20.327 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-17 15:20:23.097 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=673, output_tokens=78, cost=0.009070
2025-10-17 15:20:23.099 | INFO     | Refactored invocation argument parsing gives different result on 'get_code_around_line("C:/Python34/lib/site-packages/requests/models.py", 705, 10)': old result is ['C:/Python34/lib/site-packages/requests/models.py', '705', '10'], new result  is ['C:/Python34/lib/site-packages/requests/models.py', 705, 10]
2025-10-17 15:20:23.100 | DEBUG    | Extracted a valid json.
2025-10-17 15:20:23.100 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_class(\"InvalidLinkBear\")",
        "search_method_in_class(\"get_status_code\", \"InvalidLinkBear\")",
        "search_code(\"requests.head\")",
        "get_code_around_line(\"C:/Python34/lib/site-packages/requests/models.py\", 705, 10)"
    ],
    "bug_locations": []
}
2025-10-17 15:20:23.109 | INFO     | Refactored invocation argument parsing gives different result on 'get_code_around_line("C:/Python34/lib/site-packages/requests/models.py", 705, 10)': old result is ['C:/Python34/lib/site-packages/requests/models.py', '705', '10'], new result  is ['C:/Python34/lib/site-packages/requests/models.py', 705, 10]
2025-10-17 15:20:23.113 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-17 15:20:23.114 | DEBUG    | <Agent search> Analyzing search results.
2025-10-17 15:20:35.652 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=1699, output_tokens=507, cost=0.032200
2025-10-17 15:20:35.665 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-17 15:20:46.582 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=2422, output_tokens=472, cost=0.038380
2025-10-17 15:20:46.591 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-17 15:20:47.621 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=826, output_tokens=14, cost=0.008680
2025-10-17 15:20:47.622 | DEBUG    | Both API_calls and bug_locations are empty. Will retry.
2025-10-17 15:20:47.623 | DEBUG    | Trying to convert API calls/bug locations into json. Try 2 of 5.
2025-10-17 15:20:51.398 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=826, output_tokens=120, cost=0.011860
2025-10-17 15:20:51.399 | DEBUG    | Bug location not detailed enough. Each location must contain at least a class or a method or a file.. Will retry.
2025-10-17 15:20:51.399 | DEBUG    | Trying to convert API calls/bug locations into json. Try 3 of 5.
2025-10-17 15:20:55.873 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=826, output_tokens=105, cost=0.011410
2025-10-17 15:20:55.874 | DEBUG    | Bug location not detailed enough. Each location must contain at least a class or a method or a file.. Will retry.
2025-10-17 15:20:55.874 | DEBUG    | Trying to convert API calls/bug locations into json. Try 4 of 5.
2025-10-17 15:20:57.086 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=826, output_tokens=14, cost=0.008680
2025-10-17 15:20:57.087 | DEBUG    | Both API_calls and bug_locations are empty. Will retry.
2025-10-17 15:20:57.087 | DEBUG    | Trying to convert API calls/bug locations into json. Try 5 of 5.
2025-10-17 15:21:04.649 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=826, output_tokens=208, cost=0.014500
2025-10-17 15:21:04.650 | DEBUG    | Bug location not detailed enough. Each location must contain at least a class or a method or a file.. Will retry.
2025-10-17 15:21:04.650 | DEBUG    | Agent proxy return the following json: None
2025-10-17 15:21:04.651 | DEBUG    | Could not extract API calls from agent search response, asking search agent to re-generate response.
2025-10-17 15:21:04.652 | DEBUG    | <Agent search> Downstream could not consume our last response. Will retry.
2025-10-17 15:21:04.652 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-17 15:21:12.497 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=2921, output_tokens=294, cost=0.038030
2025-10-17 15:21:12.504 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-17 15:21:15.256 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=648, output_tokens=44, cost=0.007800
2025-10-17 15:21:15.258 | DEBUG    | Extracted a valid json.
2025-10-17 15:21:15.258 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_code(\"InvalidLinkBear\")",
        "search_code(\"requests.\")",
        "search_code(\"requests_mock\")"
    ],
    "bug_locations": []
}
2025-10-17 15:21:15.301 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-17 15:21:15.302 | DEBUG    | <Agent search> Analyzing search results.
2025-10-17 15:21:30.460 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=3676, output_tokens=636, cost=0.055840
2025-10-17 15:21:30.473 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-17 15:21:42.406 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=4528, output_tokens=516, cost=0.060760
2025-10-17 15:21:42.415 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-17 15:21:43.612 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=870, output_tokens=14, cost=0.009120
2025-10-17 15:21:43.613 | DEBUG    | Both API_calls and bug_locations are empty. Will retry.
2025-10-17 15:21:43.613 | DEBUG    | Trying to convert API calls/bug locations into json. Try 2 of 5.
2025-10-17 15:21:49.941 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=870, output_tokens=249, cost=0.016170
2025-10-17 15:21:49.942 | DEBUG    | Extracted a valid json.
2025-10-17 15:21:49.942 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [],
    "bug_locations": [
        {
            "file": "sessions.py",
            "class": "",
            "method": "",
            "intended_behavior": "Ensure Non-`None` Response Before Access: Add explicit checks around the `requests` call to confirm the presence of a valid response."
        },
        {
            "file": "models.py",
            "class": "",
            "method": "",
            "intended_behavior": "Ensure Non-`None` Response Before Access: Add explicit checks around the `requests` call to confirm the presence of a valid response."
        },
        {
            "file": "adapters.py",
            "class": "",
            "method": "",
            "intended_behavior": "Ensure Non-`None` Response Before Access: Add explicit checks around the `requests` call to confirm the presence of a valid response."
        },
        {
            "file": "",
            "class": "",
            "method": "requests.head",
            "intended_behavior": "Robust Exception Handling for `requests` Calls: Enhance error handling around `requests` library calls to catch exceptions such as `requests.exceptions.RequestException`."
        }
    ]
}
2025-10-17 15:21:49.949 | WARNING  | Successfully split requests and head
2025-10-17 15:21:49.951 | DEBUG    | Bug location extracted successfully: [<file>requests/sessions.py</file>
<class>None</class>
<method>None</method>
<code>
1 # -*- coding: utf-8 -*-
2 
3 """
4 requests.session
5 ~~~~~~~~~~~~~~~~
6 
7 This module provides a Session object to manage and persist settings across
8 requests (cookies, auth, proxies).
9 """
10 import os
11 from collections import Mapping
12 from datetime import datetime
13 
14 from .auth import _basic_auth_str
15 from .compat import cookielib, OrderedDict, urljoin, urlparse
16 from .cookies import (
17     cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar, merge_cookies)
18 from .models import Request, PreparedRequest, DEFAULT_REDIRECT_LIMIT
19 from .hooks import default_hooks, dispatch_hook
20 from ._internal_utils import to_native_string
21 from .utils import to_key_val_list, default_headers
22 from .exceptions import (
23     TooManyRedirects, InvalidSchema, ChunkedEncodingError, ContentDecodingError)
24 from .packages.urllib3._collections import RecentlyUsedContainer
25 from .structures import CaseInsensitiveDict
26 
27 from .adapters import HTTPAdapter
28 
29 from .utils import (
30     requote_uri, get_environ_proxies, get_netrc_auth, should_bypass_proxies,
31     get_auth_from_url, rewind_body
32 )
33 
34 from .status_codes import codes
35 
36 # formerly defined here, reexposed here for backward compatibility
37 from .models import REDIRECT_STATI
38 
39 REDIRECT_CACHE_SIZE = 1000
40 
41 
42 def merge_setting(request_setting, session_setting, dict_class=OrderedDict):
43     """Determines appropriate setting for a given request, taking into account
44     the explicit setting on that request, and the setting in the session. If a
45     setting is a dictionary, they will be merged together using `dict_class`
46     """
47 
48     if session_setting is None:
49         return request_setting
50 
51     if request_setting is None:
52         return session_setting
53 
54     # Bypass if not a dictionary (e.g. verify)
55     if not (
56             isinstance(session_setting, Mapping) and
57             isinstance(request_setting, Mapping)
58     ):
59         return request_setting
60 
61     merged_setting = dict_class(to_key_val_list(session_setting))
62     merged_setting.update(to_key_val_list(request_setting))
63 
64     # Remove keys that are set to None. Extract keys first to avoid altering
65     # the dictionary during iteration.
66     none_keys = [k for (k, v) in merged_setting.items() if v is None]
67     for key in none_keys:
68         del merged_setting[key]
69 
70     return merged_setting
71 
72 
73 def merge_hooks(request_hooks, session_hooks, dict_class=OrderedDict):
74     """Properly merges both requests and session hooks.
75 
76     This is necessary because when request_hooks == {'response': []}, the
77     merge breaks Session hooks entirely.
78     """
79     if session_hooks is None or session_hooks.get('response') == []:
80         return request_hooks
81 
82     if request_hooks is None or request_hooks.get('response') == []:
83         return session_hooks
84 
85     return merge_setting(request_hooks, session_hooks, dict_class)
86 
87 
88 class SessionRedirectMixin(object):
89     def resolve_redirects(self, resp, req, stream=False, timeout=None,
90                           verify=True, cert=None, proxies=None, **adapter_kwargs):
91         """Receives a Response. Returns a generator of Responses."""
92 
93         i = 0
94         hist = [] # keep track of history
95 
96         while resp.is_redirect:
97             prepared_request = req.copy()
98 
99             if i > 0:
100                 # Update history and keep track of redirects.
101                 hist.append(resp)
102                 new_hist = list(hist)
103                 resp.history = new_hist
104 
105             try:
106                 resp.content  # Consume socket so it can be released
107             except (ChunkedEncodingError, ContentDecodingError, RuntimeError):
108                 resp.raw.read(decode_content=False)
109 
110             if i >= self.max_redirects:
111                 raise TooManyRedirects('Exceeded %s redirects.' % self.max_redirects, response=resp)
112 
113             # Release the connection back into the pool.
114             resp.close()
115 
116             url = resp.headers['location']
117 
118             # Handle redirection without scheme (see: RFC 1808 Section 4)
119             if url.startswith('//'):
120                 parsed_rurl = urlparse(resp.url)
121                 url = '%s:%s' % (parsed_rurl.scheme, url)
122 
123             # The scheme should be lower case...
124             parsed = urlparse(url)
125             url = parsed.geturl()
126 
127             # Facilitate relative 'location' headers, as allowed by RFC 7231.
128             # (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')
129             # Compliant with RFC3986, we percent encode the url.
130             if not parsed.netloc:
131                 url = urljoin(resp.url, requote_uri(url))
132             else:
133                 url = requote_uri(url)
134 
135             prepared_request.url = to_native_string(url)
136             # Cache the url, unless it redirects to itself.
137             if resp.is_permanent_redirect and req.url != prepared_request.url:
138                 self.redirect_cache[req.url] = prepared_request.url
139 
140             self.rebuild_method(prepared_request, resp)
141 
142             # https://github.com/kennethreitz/requests/issues/1084
143             if resp.status_code not in (codes.temporary_redirect, codes.permanent_redirect):
144                 # https://github.com/kennethreitz/requests/issues/3490
145                 purged_headers = ('Content-Length', 'Content-Type', 'Transfer-Encoding')
146                 for header in purged_headers:
147                     prepared_request.headers.pop(header, None)
148                 prepared_request.body = None
149 
150             headers = prepared_request.headers
151             try:
152                 del headers['Cookie']
153             except KeyError:
154                 pass
155 
156             # Extract any cookies sent on the response to the cookiejar
157             # in the new request. Because we've mutated our copied prepared
158             # request, use the old one that we haven't yet touched.
159             extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)
160             merge_cookies(prepared_request._cookies, self.cookies)
161             prepared_request.prepare_cookies(prepared_request._cookies)
162 
163             # Rebuild auth and proxy information.
164             proxies = self.rebuild_proxies(prepared_request, proxies)
165             self.rebuild_auth(prepared_request, resp)
166 
167             # A failed tell() sets `_body_position` to `object()`. This non-None
168             # value ensures `rewindable` will be True, allowing us to raise an
169             # UnrewindableBodyError, instead of hanging the connection.
170             rewindable = (
171                 prepared_request._body_position is not None and
172                 ('Content-Length' in headers or 'Transfer-Encoding' in headers)
173             )
174 
175             # Attempt to rewind consumed file-like object.
176             if rewindable:
177                 rewind_body(prepared_request)
178 
179             # Override the original request.
180             req = prepared_request
181 
182             resp = self.send(
183                 req,
184                 stream=stream,
185                 timeout=timeout,
186                 verify=verify,
187                 cert=cert,
188                 proxies=proxies,
189                 allow_redirects=False,
190                 **adapter_kwargs
191             )
192 
193             extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)
194 
195             i += 1
196             yield resp
197 
198     def rebuild_auth(self, prepared_request, response):
199         """When being redirected we may want to strip authentication from the
200         request to avoid leaking credentials. This method intelligently removes
201         and reapplies authentication where possible to avoid credential loss.
202         """
203         headers = prepared_request.headers
204         url = prepared_request.url
205 
206         if 'Authorization' in headers:
207             # If we get redirected to a new host, we should strip out any
208             # authentication headers.
209             original_parsed = urlparse(response.request.url)
210             redirect_parsed = urlparse(url)
211 
212             if (original_parsed.hostname != redirect_parsed.hostname):
213                 del headers['Authorization']
214 
215         # .netrc might have more auth for us on our new host.
216         new_auth = get_netrc_auth(url) if self.trust_env else None
217         if new_auth is not None:
218             prepared_request.prepare_auth(new_auth)
219 
220         return
221 
222     def rebuild_proxies(self, prepared_request, proxies):
223         """This method re-evaluates the proxy configuration by considering the
224         environment variables. If we are redirected to a URL covered by
225         NO_PROXY, we strip the proxy configuration. Otherwise, we set missing
226         proxy keys for this URL (in case they were stripped by a previous
227         redirect).
228 
229         This method also replaces the Proxy-Authorization header where
230         necessary.
231 
232         :rtype: dict
233         """
234         headers = prepared_request.headers
235         url = prepared_request.url
236         scheme = urlparse(url).scheme
237         new_proxies = proxies.copy() if proxies is not None else {}
238 
239         if self.trust_env and not should_bypass_proxies(url):
240             environ_proxies = get_environ_proxies(url)
241 
242             proxy = environ_proxies.get(scheme, environ_proxies.get('all'))
243 
244             if proxy:
245                 new_proxies.setdefault(scheme, proxy)
246 
247         if 'Proxy-Authorization' in headers:
248             del headers['Proxy-Authorization']
249 
250         try:
251             username, password = get_auth_from_url(new_proxies[scheme])
252         except KeyError:
253             username, password = None, None
254 
255         if username and password:
256             headers['Proxy-Authorization'] = _basic_auth_str(username, password)
257 
258         return new_proxies
259 
260     def rebuild_method(self, prepared_request, response):
261         """When being redirected we may want to change the method of the request
262         based on certain specs or browser behavior.
263         """
264         method = prepared_request.method
265 
266         # http://tools.ietf.org/html/rfc7231#section-6.4.4
267         if response.status_code == codes.see_other and method != 'HEAD':
268             method = 'GET'
269 
270         # Do what the browsers do, despite standards...
271         # First, turn 302s into GETs.
272         if response.status_code == codes.found and method != 'HEAD':
273             method = 'GET'
274 
275         # Second, if a POST is responded to with a 301, turn it into a GET.
276         # This bizarre behaviour is explained in Issue 1704.
277         if response.status_code == codes.moved and method == 'POST':
278             method = 'GET'
279 
280         prepared_request.method = method
281 
282 
283 class Session(SessionRedirectMixin):
284     """A Requests session.
285 
286     Provides cookie persistence, connection-pooling, and configuration.
287 
288     Basic Usage::
289 
290       >>> import requests
291       >>> s = requests.Session()
292       >>> s.get('http://httpbin.org/get')
293       <Response [200]>
294 
295     Or as a context manager::
296 
297       >>> with requests.Session() as s:
298       >>>     s.get('http://httpbin.org/get')
299       <Response [200]>
300     """
301 
302     __attrs__ = [
303         'headers', 'cookies', 'auth', 'proxies', 'hooks', 'params', 'verify',
304         'cert', 'prefetch', 'adapters', 'stream', 'trust_env',
305         'max_redirects',
306     ]
307 
308     def __init__(self):
309 
310         #: A case-insensitive dictionary of headers to be sent on each
311         #: :class:`Request <Request>` sent from this
312         #: :class:`Session <Session>`.
313         self.headers = default_headers()
314 
315         #: Default Authentication tuple or object to attach to
316         #: :class:`Request <Request>`.
317         self.auth = None
318 
319         #: Dictionary mapping protocol or protocol and host to the URL of the proxy
320         #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to
321         #: be used on each :class:`Request <Request>`.
322         self.proxies = {}
323 
324         #: Event-handling hooks.
325         self.hooks = default_hooks()
326 
327         #: Dictionary of querystring data to attach to each
328         #: :class:`Request <Request>`. The dictionary values may be lists for
329         #: representing multivalued query parameters.
330         self.params = {}
331 
332         #: Stream response content default.
333         self.stream = False
334 
335         #: SSL Verification default.
336         self.verify = True
337 
338         #: SSL client certificate default.
339         self.cert = None
340 
341         #: Maximum number of redirects allowed. If the request exceeds this
342         #: limit, a :class:`TooManyRedirects` exception is raised.
343         #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is
344         #: 30.
345         self.max_redirects = DEFAULT_REDIRECT_LIMIT
346 
347         #: Trust environment settings for proxy configuration, default
348         #: authentication and similar.
349         self.trust_env = True
350 
351         #: A CookieJar containing all currently outstanding cookies set on this
352         #: session. By default it is a
353         #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but
354         #: may be any other ``cookielib.CookieJar`` compatible object.
355         self.cookies = cookiejar_from_dict({})
356 
357         # Default connection adapters.
358         self.adapters = OrderedDict()
359         self.mount('https://', HTTPAdapter())
360         self.mount('http://', HTTPAdapter())
361 
362         # Only store 1000 redirects to prevent using infinite memory
363         self.redirect_cache = RecentlyUsedContainer(REDIRECT_CACHE_SIZE)
364 
365     def __enter__(self):
366         return self
367 
368     def __exit__(self, *args):
369         self.close()
370 
371     def prepare_request(self, request):
372         """Constructs a :class:`PreparedRequest <PreparedRequest>` for
373         transmission and returns it. The :class:`PreparedRequest` has settings
374         merged from the :class:`Request <Request>` instance and those of the
375         :class:`Session`.
376 
377         :param request: :class:`Request` instance to prepare with this
378             session's settings.
379         :rtype: requests.PreparedRequest
380         """
381         cookies = request.cookies or {}
382 
383         # Bootstrap CookieJar.
384         if not isinstance(cookies, cookielib.CookieJar):
385             cookies = cookiejar_from_dict(cookies)
386 
387         # Merge with session cookies
388         merged_cookies = merge_cookies(
389             merge_cookies(RequestsCookieJar(), self.cookies), cookies)
390 
391         # Set environment's basic authentication if not explicitly set.
392         auth = request.auth
393         if self.trust_env and not auth and not self.auth:
394             auth = get_netrc_auth(request.url)
395 
396         p = PreparedRequest()
397         p.prepare(
398             method=request.method.upper(),
399             url=request.url,
400             files=request.files,
401             data=request.data,
402             json=request.json,
403             headers=merge_setting(request.headers, self.headers, dict_class=CaseInsensitiveDict),
404             params=merge_setting(request.params, self.params),
405             auth=merge_setting(auth, self.auth),
406             cookies=merged_cookies,
407             hooks=merge_hooks(request.hooks, self.hooks),
408         )
409         return p
410 
411     def request(self, method, url,
412         params=None,
413         data=None,
414         headers=None,
415         cookies=None,
416         files=None,
417         auth=None,
418         timeout=None,
419         allow_redirects=True,
420         proxies=None,
421         hooks=None,
422         stream=None,
423         verify=None,
424         cert=None,
425         json=None):
426         """Constructs a :class:`Request <Request>`, prepares it and sends it.
427         Returns :class:`Response <Response>` object.
428 
429         :param method: method for the new :class:`Request` object.
430         :param url: URL for the new :class:`Request` object.
431         :param params: (optional) Dictionary or bytes to be sent in the query
432             string for the :class:`Request`.
433         :param data: (optional) Dictionary, bytes, or file-like object to send
434             in the body of the :class:`Request`.
435         :param json: (optional) json to send in the body of the
436             :class:`Request`.
437         :param headers: (optional) Dictionary of HTTP Headers to send with the
438             :class:`Request`.
439         :param cookies: (optional) Dict or CookieJar object to send with the
440             :class:`Request`.
441         :param files: (optional) Dictionary of ``'filename': file-like-objects``
442             for multipart encoding upload.
443         :param auth: (optional) Auth tuple or callable to enable
444             Basic/Digest/Custom HTTP Auth.
445         :param timeout: (optional) How long to wait for the server to send
446             data before giving up, as a float, or a :ref:`(connect timeout,
447             read timeout) <timeouts>` tuple.
448         :type timeout: float or tuple
449         :param allow_redirects: (optional) Set to True by default.
450         :type allow_redirects: bool
451         :param proxies: (optional) Dictionary mapping protocol or protocol and
452             hostname to the URL of the proxy.
453         :param stream: (optional) whether to immediately download the response
454             content. Defaults to ``False``.
455         :param verify: (optional) whether the SSL cert will be verified.
456             A CA_BUNDLE path can also be provided. Defaults to ``True``.
457         :param cert: (optional) if String, path to ssl client cert file (.pem).
458             If Tuple, ('cert', 'key') pair.
459         :rtype: requests.Response
460         """
461         # Create the Request.
462         req = Request(
463             method = method.upper(),
464             url = url,
465             headers = headers,
466             files = files,
467             data = data or {},
468             json = json,
469             params = params or {},
470             auth = auth,
471             cookies = cookies,
472             hooks = hooks,
473         )
474         prep = self.prepare_request(req)
475 
476         proxies = proxies or {}
477 
478         settings = self.merge_environment_settings(
479             prep.url, proxies, stream, verify, cert
480         )
481 
482         # Send the request.
483         send_kwargs = {
484             'timeout': timeout,
485             'allow_redirects': allow_redirects,
486         }
487         send_kwargs.update(settings)
488         resp = self.send(prep, **send_kwargs)
489 
490         return resp
491 
492     def get(self, url, **kwargs):
493         """Sends a GET request. Returns :class:`Response` object.
494 
495         :param url: URL for the new :class:`Request` object.
496         :param \*\*kwargs: Optional arguments that ``request`` takes.
497         :rtype: requests.Response
498         """
499 
500         kwargs.setdefault('allow_redirects', True)
501         return self.request('GET', url, **kwargs)
502 
503     def options(self, url, **kwargs):
504         """Sends a OPTIONS request. Returns :class:`Response` object.
505 
506         :param url: URL for the new :class:`Request` object.
507         :param \*\*kwargs: Optional arguments that ``request`` takes.
508         :rtype: requests.Response
509         """
510 
511         kwargs.setdefault('allow_redirects', True)
512         return self.request('OPTIONS', url, **kwargs)
513 
514     def head(self, url, **kwargs):
515         """Sends a HEAD request. Returns :class:`Response` object.
516 
517         :param url: URL for the new :class:`Request` object.
518         :param \*\*kwargs: Optional arguments that ``request`` takes.
519         :rtype: requests.Response
520         """
521 
522         kwargs.setdefault('allow_redirects', False)
523         return self.request('HEAD', url, **kwargs)
524 
525     def post(self, url, data=None, json=None, **kwargs):
526         """Sends a POST request. Returns :class:`Response` object.
527 
528         :param url: URL for the new :class:`Request` object.
529         :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
530         :param json: (optional) json to send in the body of the :class:`Request`.
531         :param \*\*kwargs: Optional arguments that ``request`` takes.
532         :rtype: requests.Response
533         """
534 
535         return self.request('POST', url, data=data, json=json, **kwargs)
536 
537     def put(self, url, data=None, **kwargs):
538         """Sends a PUT request. Returns :class:`Response` object.
539 
540         :param url: URL for the new :class:`Request` object.
541         :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
542         :param \*\*kwargs: Optional arguments that ``request`` takes.
543         :rtype: requests.Response
544         """
545 
546         return self.request('PUT', url, data=data, **kwargs)
547 
548     def patch(self, url, data=None, **kwargs):
549         """Sends a PATCH request. Returns :class:`Response` object.
550 
551         :param url: URL for the new :class:`Request` object.
552         :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
553         :param \*\*kwargs: Optional arguments that ``request`` takes.
554         :rtype: requests.Response
555         """
556 
557         return self.request('PATCH', url,  data=data, **kwargs)
558 
559     def delete(self, url, **kwargs):
560         """Sends a DELETE request. Returns :class:`Response` object.
561 
562         :param url: URL for the new :class:`Request` object.
563         :param \*\*kwargs: Optional arguments that ``request`` takes.
564         :rtype: requests.Response
565         """
566 
567         return self.request('DELETE', url, **kwargs)
568 
569     def send(self, request, **kwargs):
570         """
571         Send a given PreparedRequest.
572 
573         :rtype: requests.Response
574         """
575         # Set defaults that the hooks can utilize to ensure they always have
576         # the correct parameters to reproduce the previous request.
577         kwargs.setdefault('stream', self.stream)
578         kwargs.setdefault('verify', self.verify)
579         kwargs.setdefault('cert', self.cert)
580         kwargs.setdefault('proxies', self.proxies)
581 
582         # It's possible that users might accidentally send a Request object.
583         # Guard against that specific failure case.
584         if isinstance(request, Request):
585             raise ValueError('You can only send PreparedRequests.')
586 
587         # Set up variables needed for resolve_redirects and dispatching of hooks
588         allow_redirects = kwargs.pop('allow_redirects', True)
589         stream = kwargs.get('stream')
590         hooks = request.hooks
591 
592         # Resolve URL in redirect cache, if available.
593         if allow_redirects:
594             checked_urls = set()
595             while request.url in self.redirect_cache:
596                 checked_urls.add(request.url)
597                 new_url = self.redirect_cache.get(request.url)
598                 if new_url in checked_urls:
599                     break
600                 request.url = new_url
601 
602         # Get the appropriate adapter to use
603         adapter = self.get_adapter(url=request.url)
604 
605         # Start time (approximately) of the request
606         start = datetime.utcnow()
607 
608         # Send the request
609         r = adapter.send(request, **kwargs)
610 
611         # Total elapsed time of the request (approximately)
612         r.elapsed = datetime.utcnow() - start
613 
614         # Response manipulation hooks
615         r = dispatch_hook('response', hooks, r, **kwargs)
616 
617         # Persist cookies
618         if r.history:
619 
620             # If the hooks create history then we want those cookies too
621             for resp in r.history:
622                 extract_cookies_to_jar(self.cookies, resp.request, resp.raw)
623 
624         extract_cookies_to_jar(self.cookies, request, r.raw)
625 
626         # Redirect resolving generator.
627         gen = self.resolve_redirects(r, request, **kwargs)
628 
629         # Resolve redirects if allowed.
630         history = [resp for resp in gen] if allow_redirects else []
631 
632         # Shuffle things around if there's history.
633         if history:
634             # Insert the first (original) request at the start
635             history.insert(0, r)
636             # Get the last request made
637             r = history.pop()
638             r.history = history
639 
640         if not stream:
641             r.content
642 
643         return r
644 
645     def merge_environment_settings(self, url, proxies, stream, verify, cert):
646         """
647         Check the environment and merge it with some settings.
648 
649         :rtype: dict
650         """
651         # Gather clues from the surrounding environment.
652         if self.trust_env:
653             # Set environment's proxies.
654             env_proxies = get_environ_proxies(url) or {}
655             for (k, v) in env_proxies.items():
656                 proxies.setdefault(k, v)
657 
658             # Look for requests environment configuration and be compatible
659             # with cURL.
660             if verify is True or verify is None:
661                 verify = (os.environ.get('REQUESTS_CA_BUNDLE') or
662                           os.environ.get('CURL_CA_BUNDLE'))
663 
664         # Merge all the kwargs.
665         proxies = merge_setting(proxies, self.proxies)
666         stream = merge_setting(stream, self.stream)
667         verify = merge_setting(verify, self.verify)
668         cert = merge_setting(cert, self.cert)
669 
670         return {'verify': verify, 'proxies': proxies, 'stream': stream,
671                 'cert': cert}
672 
673     def get_adapter(self, url):
674         """
675         Returns the appropriate connection adapter for the given URL.
676 
677         :rtype: requests.adapters.BaseAdapter
678         """
679         for (prefix, adapter) in self.adapters.items():
680 
681             if url.lower().startswith(prefix):
682                 return adapter
683 
684         # Nothing matches :-/
685         raise InvalidSchema("No connection adapters were found for '%s'" % url)
686 
687     def close(self):
688         """Closes all adapters and as such the session"""
689         for v in self.adapters.values():
690             v.close()
691 
692     def mount(self, prefix, adapter):
693         """Registers a connection adapter to a prefix.
694 
695         Adapters are sorted in descending order by key length.
696         """
697         self.adapters[prefix] = adapter
698         keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]
699 
700         for key in keys_to_move:
701             self.adapters[key] = self.adapters.pop(key)
702 
703     def __getstate__(self):
704         state = dict((attr, getattr(self, attr, None)) for attr in self.__attrs__)
705         state['redirect_cache'] = dict(self.redirect_cache)
706         return state
707 
708     def __setstate__(self, state):
709         redirect_cache = state.pop('redirect_cache', {})
710         for attr, value in state.items():
711             setattr(self, attr, value)
712 
713         self.redirect_cache = RecentlyUsedContainer(REDIRECT_CACHE_SIZE)
714         for redirect, to in redirect_cache.items():
715             self.redirect_cache[redirect] = to
716 
717 
718 def session():
719     """
720     Returns a :class:`Session` for context-management.
721 
722     :rtype: Session
723     """
724 
725     return Session()

</code><intended_behavior>Ensure Non-`None` Response Before Access: Add explicit checks around the `requests` call to confirm the presence of a valid response.</intended_behavior>, <file>requests/models.py</file>
<class>None</class>
<method>None</method>
<code>
1 # -*- coding: utf-8 -*-
2 
3 """
4 requests.models
5 ~~~~~~~~~~~~~~~
6 
7 This module contains the primary objects that power Requests.
8 """
9 
10 import collections
11 import datetime
12 
13 # Import encoding now, to avoid implicit import later.
14 # Implicit import within threads may cause LookupError when standard library is in a ZIP,
15 # such as in Embedded Python. See https://github.com/kennethreitz/requests/issues/3578.
16 import encodings.idna
17 
18 from io import BytesIO, UnsupportedOperation
19 from .hooks import default_hooks
20 from .structures import CaseInsensitiveDict
21 
22 from .auth import HTTPBasicAuth
23 from .cookies import cookiejar_from_dict, get_cookie_header, _copy_cookie_jar
24 from .packages import idna
25 from .packages.urllib3.fields import RequestField
26 from .packages.urllib3.filepost import encode_multipart_formdata
27 from .packages.urllib3.util import parse_url
28 from .packages.urllib3.exceptions import (
29     DecodeError, ReadTimeoutError, ProtocolError, LocationParseError)
30 from .exceptions import (
31     HTTPError, MissingSchema, InvalidURL, ChunkedEncodingError,
32     ContentDecodingError, ConnectionError, StreamConsumedError)
33 from ._internal_utils import to_native_string
34 from .utils import (
35     guess_filename, get_auth_from_url, requote_uri,
36     stream_decode_response_unicode, to_key_val_list, parse_header_links,
37     iter_slices, guess_json_utf, super_len, check_header_validity)
38 from .compat import (
39     cookielib, urlunparse, urlsplit, urlencode, str, bytes, StringIO,
40     is_py2, chardet, builtin_str, basestring)
41 from .compat import json as complexjson
42 from .status_codes import codes
43 
44 #: The set of HTTP status codes that indicate an automatically
45 #: processable redirect.
46 REDIRECT_STATI = (
47     codes.moved,               # 301
48     codes.found,               # 302
49     codes.other,               # 303
50     codes.temporary_redirect,  # 307
51     codes.permanent_redirect,  # 308
52 )
53 
54 DEFAULT_REDIRECT_LIMIT = 30
55 CONTENT_CHUNK_SIZE = 10 * 1024
56 ITER_CHUNK_SIZE = 512
57 
58 
59 class RequestEncodingMixin(object):
60     @property
61     def path_url(self):
62         """Build the path URL to use."""
63 
64         url = []
65 
66         p = urlsplit(self.url)
67 
68         path = p.path
69         if not path:
70             path = '/'
71 
72         url.append(path)
73 
74         query = p.query
75         if query:
76             url.append('?')
77             url.append(query)
78 
79         return ''.join(url)
80 
81     @staticmethod
82     def _encode_params(data):
83         """Encode parameters in a piece of data.
84 
85         Will successfully encode parameters when passed as a dict or a list of
86         2-tuples. Order is retained if data is a list of 2-tuples but arbitrary
87         if parameters are supplied as a dict.
88         """
89 
90         if isinstance(data, (str, bytes)):
91             return data
92         elif hasattr(data, 'read'):
93             return data
94         elif hasattr(data, '__iter__'):
95             result = []
96             for k, vs in to_key_val_list(data):
97                 if isinstance(vs, basestring) or not hasattr(vs, '__iter__'):
98                     vs = [vs]
99                 for v in vs:
100                     if v is not None:
101                         result.append(
102                             (k.encode('utf-8') if isinstance(k, str) else k,
103                              v.encode('utf-8') if isinstance(v, str) else v))
104             return urlencode(result, doseq=True)
105         else:
106             return data
107 
108     @staticmethod
109     def _encode_files(files, data):
110         """Build the body for a multipart/form-data request.
111 
112         Will successfully encode files when passed as a dict or a list of
113         tuples. Order is retained if data is a list of tuples but arbitrary
114         if parameters are supplied as a dict.
115         The tuples may be 2-tuples (filename, fileobj), 3-tuples (filename, fileobj, contentype)
116         or 4-tuples (filename, fileobj, contentype, custom_headers).
117         """
118         if (not files):
119             raise ValueError("Files must be provided.")
120         elif isinstance(data, basestring):
121             raise ValueError("Data must not be a string.")
122 
123         new_fields = []
124         fields = to_key_val_list(data or {})
125         files = to_key_val_list(files or {})
126 
127         for field, val in fields:
128             if isinstance(val, basestring) or not hasattr(val, '__iter__'):
129                 val = [val]
130             for v in val:
131                 if v is not None:
132                     # Don't call str() on bytestrings: in Py3 it all goes wrong.
133                     if not isinstance(v, bytes):
134                         v = str(v)
135 
136                     new_fields.append(
137                         (field.decode('utf-8') if isinstance(field, bytes) else field,
138                          v.encode('utf-8') if isinstance(v, str) else v))
139 
140         for (k, v) in files:
141             # support for explicit filename
142             ft = None
143             fh = None
144             if isinstance(v, (tuple, list)):
145                 if len(v) == 2:
146                     fn, fp = v
147                 elif len(v) == 3:
148                     fn, fp, ft = v
149                 else:
150                     fn, fp, ft, fh = v
151             else:
152                 fn = guess_filename(v) or k
153                 fp = v
154 
155             if isinstance(fp, (str, bytes, bytearray)):
156                 fdata = fp
157             else:
158                 fdata = fp.read()
159 
160             rf = RequestField(name=k, data=fdata, filename=fn, headers=fh)
161             rf.make_multipart(content_type=ft)
162             new_fields.append(rf)
163 
164         body, content_type = encode_multipart_formdata(new_fields)
165 
166         return body, content_type
167 
168 
169 class RequestHooksMixin(object):
170     def register_hook(self, event, hook):
171         """Properly register a hook."""
172 
173         if event not in self.hooks:
174             raise ValueError('Unsupported event specified, with event name "%s"' % (event))
175 
176         if isinstance(hook, collections.Callable):
177             self.hooks[event].append(hook)
178         elif hasattr(hook, '__iter__'):
179             self.hooks[event].extend(h for h in hook if isinstance(h, collections.Callable))
180 
181     def deregister_hook(self, event, hook):
182         """Deregister a previously registered hook.
183         Returns True if the hook existed, False if not.
184         """
185 
186         try:
187             self.hooks[event].remove(hook)
188             return True
189         except ValueError:
190             return False
191 
192 
193 class Request(RequestHooksMixin):
194     """A user-created :class:`Request <Request>` object.
195 
196     Used to prepare a :class:`PreparedRequest <PreparedRequest>`, which is sent to the server.
197 
198     :param method: HTTP method to use.
199     :param url: URL to send.
200     :param headers: dictionary of headers to send.
201     :param files: dictionary of {filename: fileobject} files to multipart upload.
202     :param data: the body to attach to the request. If a dictionary is provided, form-encoding will take place.
203     :param json: json for the body to attach to the request (if files or data is not specified).
204     :param params: dictionary of URL parameters to append to the URL.
205     :param auth: Auth handler or (user, pass) tuple.
206     :param cookies: dictionary or CookieJar of cookies to attach to this request.
207     :param hooks: dictionary of callback hooks, for internal usage.
208 
209     Usage::
210 
211       >>> import requests
212       >>> req = requests.Request('GET', 'http://httpbin.org/get')
213       >>> req.prepare()
214       <PreparedRequest [GET]>
215     """
216 
217     def __init__(self, method=None, url=None, headers=None, files=None,
218         data=None, params=None, auth=None, cookies=None, hooks=None, json=None):
219 
220         # Default empty dicts for dict params.
221         data = [] if data is None else data
222         files = [] if files is None else files
223         headers = {} if headers is None else headers
224         params = {} if params is None else params
225         hooks = {} if hooks is None else hooks
226 
227         self.hooks = default_hooks()
228         for (k, v) in list(hooks.items()):
229             self.register_hook(event=k, hook=v)
230 
231         self.method = method
232         self.url = url
233         self.headers = headers
234         self.files = files
235         self.data = data
236         self.json = json
237         self.params = params
238         self.auth = auth
239         self.cookies = cookies
240 
241     def __repr__(self):
242         return '<Request [%s]>' % (self.method)
243 
244     def prepare(self):
245         """Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it."""
246         p = PreparedRequest()
247         p.prepare(
248             method=self.method,
249             url=self.url,
250             headers=self.headers,
251             files=self.files,
252             data=self.data,
253             json=self.json,
254             params=self.params,
255             auth=self.auth,
256             cookies=self.cookies,
257             hooks=self.hooks,
258         )
259         return p
260 
261 
262 class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):
263     """The fully mutable :class:`PreparedRequest <PreparedRequest>` object,
264     containing the exact bytes that will be sent to the server.
265 
266     Generated from either a :class:`Request <Request>` object or manually.
267 
268     Usage::
269 
270       >>> import requests
271       >>> req = requests.Request('GET', 'http://httpbin.org/get')
272       >>> r = req.prepare()
273       <PreparedRequest [GET]>
274 
275       >>> s = requests.Session()
276       >>> s.send(r)
277       <Response [200]>
278     """
279 
280     def __init__(self):
281         #: HTTP verb to send to the server.
282         self.method = None
283         #: HTTP URL to send the request to.
284         self.url = None
285         #: dictionary of HTTP headers.
286         self.headers = None
287         # The `CookieJar` used to create the Cookie header will be stored here
288         # after prepare_cookies is called
289         self._cookies = None
290         #: request body to send to the server.
291         self.body = None
292         #: dictionary of callback hooks, for internal usage.
293         self.hooks = default_hooks()
294         #: integer denoting starting position of a readable file-like body.
295         self._body_position = None
296 
297     def prepare(self, method=None, url=None, headers=None, files=None,
298         data=None, params=None, auth=None, cookies=None, hooks=None, json=None):
299         """Prepares the entire request with the given parameters."""
300 
301         self.prepare_method(method)
302         self.prepare_url(url, params)
303         self.prepare_headers(headers)
304         self.prepare_cookies(cookies)
305         self.prepare_body(data, files, json)
306         self.prepare_auth(auth, url)
307 
308         # Note that prepare_auth must be last to enable authentication schemes
309         # such as OAuth to work on a fully prepared request.
310 
311         # This MUST go after prepare_auth. Authenticators could add a hook
312         self.prepare_hooks(hooks)
313 
314     def __repr__(self):
315         return '<PreparedRequest [%s]>' % (self.method)
316 
317     def copy(self):
318         p = PreparedRequest()
319         p.method = self.method
320         p.url = self.url
321         p.headers = self.headers.copy() if self.headers is not None else None
322         p._cookies = _copy_cookie_jar(self._cookies)
323         p.body = self.body
324         p.hooks = self.hooks
325         p._body_position = self._body_position
326         return p
327 
328     def prepare_method(self, method):
329         """Prepares the given HTTP method."""
330         self.method = method
331         if self.method is not None:
332             self.method = to_native_string(self.method.upper())
333 
334     def prepare_url(self, url, params):
335         """Prepares the given HTTP URL."""
336         #: Accept objects that have string representations.
337         #: We're unable to blindly call unicode/str functions
338         #: as this will include the bytestring indicator (b'')
339         #: on python 3.x.
340         #: https://github.com/kennethreitz/requests/pull/2238
341         if isinstance(url, bytes):
342             url = url.decode('utf8')
343         else:
344             url = unicode(url) if is_py2 else str(url)
345 
346         # Remove leading whitespaces from url
347         url = url.lstrip()
348 
349         # Don't do any URL preparation for non-HTTP schemes like `mailto`,
350         # `data`, `http+unix` etc to work around exceptions from `url_parse`,
351         # which handles RFC 3986 only.
352         if ':' in url and not url.lower().startswith(('http://', 'https://')):
353             self.url = url
354             return
355 
356         # Support for unicode domain names and paths.
357         try:
358             scheme, auth, host, port, path, query, fragment = parse_url(url)
359         except LocationParseError as e:
360             raise InvalidURL(*e.args)
361 
362         if not scheme:
363             error = ("Invalid URL {0!r}: No schema supplied. Perhaps you meant http://{0}?")
364             error = error.format(to_native_string(url, 'utf8'))
365 
366             raise MissingSchema(error)
367 
368         if not host:
369             raise InvalidURL("Invalid URL %r: No host supplied" % url)
370 
371         # Only want to apply IDNA to the hostname
372         try:
373             host = idna.encode(host, uts46=True).decode('utf-8')
374         except (UnicodeError, idna.IDNAError):
375             raise InvalidURL('URL has an invalid label.')
376 
377         # Carefully reconstruct the network location
378         netloc = auth or ''
379         if netloc:
380             netloc += '@'
381         netloc += host
382         if port:
383             netloc += ':' + str(port)
384 
385         # Bare domains aren't valid URLs.
386         if not path:
387             path = '/'
388 
389         if is_py2:
390             if isinstance(scheme, str):
391                 scheme = scheme.encode('utf-8')
392             if isinstance(netloc, str):
393                 netloc = netloc.encode('utf-8')
394             if isinstance(path, str):
395                 path = path.encode('utf-8')
396             if isinstance(query, str):
397                 query = query.encode('utf-8')
398             if isinstance(fragment, str):
399                 fragment = fragment.encode('utf-8')
400 
401         if isinstance(params, (str, bytes)):
402             params = to_native_string(params)
403 
404         enc_params = self._encode_params(params)
405         if enc_params:
406             if query:
407                 query = '%s&%s' % (query, enc_params)
408             else:
409                 query = enc_params
410 
411         url = requote_uri(urlunparse([scheme, netloc, path, None, query, fragment]))
412         self.url = url
413 
414     def prepare_headers(self, headers):
415         """Prepares the given HTTP headers."""
416 
417         self.headers = CaseInsensitiveDict()
418         if headers:
419             for header in headers.items():
420                 # Raise exception on invalid header value.
421                 check_header_validity(header)
422                 name, value = header
423                 self.headers[to_native_string(name)] = value
424 
425     def prepare_body(self, data, files, json=None):
426         """Prepares the given HTTP body data."""
427 
428         # Check if file, fo, generator, iterator.
429         # If not, run through normal process.
430 
431         # Nottin' on you.
432         body = None
433         content_type = None
434 
435         if not data and json is not None:
436             # urllib3 requires a bytes-like body. Python 2's json.dumps
437             # provides this natively, but Python 3 gives a Unicode string.
438             content_type = 'application/json'
439             body = complexjson.dumps(json)
440             if not isinstance(body, bytes):
441                 body = body.encode('utf-8')
442 
443         is_stream = all([
444             hasattr(data, '__iter__'),
445             not isinstance(data, (basestring, list, tuple, collections.Mapping))
446         ])
447 
448         try:
449             length = super_len(data)
450         except (TypeError, AttributeError, UnsupportedOperation):
451             length = None
452 
453         if is_stream:
454             body = data
455 
456             if getattr(body, 'tell', None) is not None:
457                 # Record the current file position before reading.
458                 # This will allow us to rewind a file in the event
459                 # of a redirect.
460                 try:
461                     self._body_position = body.tell()
462                 except (IOError, OSError):
463                     # This differentiates from None, allowing us to catch
464                     # a failed `tell()` later when trying to rewind the body
465                     self._body_position = object()
466 
467             if files:
468                 raise NotImplementedError('Streamed bodies and files are mutually exclusive.')
469 
470             if length:
471                 self.headers['Content-Length'] = builtin_str(length)
472             else:
473                 self.headers['Transfer-Encoding'] = 'chunked'
474         else:
475             # Multi-part file uploads.
476             if files:
477                 (body, content_type) = self._encode_files(files, data)
478             else:
479                 if data:
480                     body = self._encode_params(data)
481                     if isinstance(data, basestring) or hasattr(data, 'read'):
482                         content_type = None
483                     else:
484                         content_type = 'application/x-www-form-urlencoded'
485 
486             self.prepare_content_length(body)
487 
488             # Add content-type if it wasn't explicitly provided.
489             if content_type and ('content-type' not in self.headers):
490                 self.headers['Content-Type'] = content_type
491 
492         self.body = body
493 
494     def prepare_content_length(self, body):
495         """Prepare Content-Length header based on request method and body"""
496         if body is not None:
497             length = super_len(body)
498             if length:
499                 # If length exists, set it. Otherwise, we fallback
500                 # to Transfer-Encoding: chunked.
501                 self.headers['Content-Length'] = builtin_str(length)
502         elif self.method not in ('GET', 'HEAD') and self.headers.get('Content-Length') is None:
503             # Set Content-Length to 0 for methods that can have a body
504             # but don't provide one. (i.e. not GET or HEAD)
505             self.headers['Content-Length'] = '0'
506 
507     def prepare_auth(self, auth, url=''):
508         """Prepares the given HTTP auth data."""
509 
510         # If no Auth is explicitly provided, extract it from the URL first.
511         if auth is None:
512             url_auth = get_auth_from_url(self.url)
513             auth = url_auth if any(url_auth) else None
514 
515         if auth:
516             if isinstance(auth, tuple) and len(auth) == 2:
517                 # special-case basic HTTP auth
518                 auth = HTTPBasicAuth(*auth)
519 
520             # Allow auth to make its changes.
521             r = auth(self)
522 
523             # Update self to reflect the auth changes.
524             self.__dict__.update(r.__dict__)
525 
526             # Recompute Content-Length
527             self.prepare_content_length(self.body)
528 
529     def prepare_cookies(self, cookies):
530         """Prepares the given HTTP cookie data.
531 
532         This function eventually generates a ``Cookie`` header from the
533         given cookies using cookielib. Due to cookielib's design, the header
534         will not be regenerated if it already exists, meaning this function
535         can only be called once for the life of the
536         :class:`PreparedRequest <PreparedRequest>` object. Any subsequent calls
537         to ``prepare_cookies`` will have no actual effect, unless the "Cookie"
538         header is removed beforehand.
539         """
540         if isinstance(cookies, cookielib.CookieJar):
541             self._cookies = cookies
542         else:
543             self._cookies = cookiejar_from_dict(cookies)
544 
545         cookie_header = get_cookie_header(self._cookies, self)
546         if cookie_header is not None:
547             self.headers['Cookie'] = cookie_header
548 
549     def prepare_hooks(self, hooks):
550         """Prepares the given hooks."""
551         # hooks can be passed as None to the prepare method and to this
552         # method. To prevent iterating over None, simply use an empty list
553         # if hooks is False-y
554         hooks = hooks or []
555         for event in hooks:
556             self.register_hook(event, hooks[event])
557 
558 
559 class Response(object):
560     """The :class:`Response <Response>` object, which contains a
561     server's response to an HTTP request.
562     """
563 
564     __attrs__ = [
565         '_content', 'status_code', 'headers', 'url', 'history',
566         'encoding', 'reason', 'cookies', 'elapsed', 'request'
567     ]
568 
569     def __init__(self):
570         super(Response, self).__init__()
571 
572         self._content = False
573         self._content_consumed = False
574 
575         #: Integer Code of responded HTTP Status, e.g. 404 or 200.
576         self.status_code = None
577 
578         #: Case-insensitive Dictionary of Response Headers.
579         #: For example, ``headers['content-encoding']`` will return the
580         #: value of a ``'Content-Encoding'`` response header.
581         self.headers = CaseInsensitiveDict()
582 
583         #: File-like object representation of response (for advanced usage).
584         #: Use of ``raw`` requires that ``stream=True`` be set on the request.
585         # This requirement does not apply for use internally to Requests.
586         self.raw = None
587 
588         #: Final URL location of Response.
589         self.url = None
590 
591         #: Encoding to decode with when accessing r.text.
592         self.encoding = None
593 
594         #: A list of :class:`Response <Response>` objects from
595         #: the history of the Request. Any redirect responses will end
596         #: up here. The list is sorted from the oldest to the most recent request.
597         self.history = []
598 
599         #: Textual reason of responded HTTP Status, e.g. "Not Found" or "OK".
600         self.reason = None
601 
602         #: A CookieJar of Cookies the server sent back.
603         self.cookies = cookiejar_from_dict({})
604 
605         #: The amount of time elapsed between sending the request
606         #: and the arrival of the response (as a timedelta).
607         #: This property specifically measures the time taken between sending
608         #: the first byte of the request and finishing parsing the headers. It
609         #: is therefore unaffected by consuming the response content or the
610         #: value of the ``stream`` keyword argument.
611         self.elapsed = datetime.timedelta(0)
612 
613         #: The :class:`PreparedRequest <PreparedRequest>` object to which this
614         #: is a response.
615         self.request = None
616 
617     def __getstate__(self):
618         # Consume everything; accessing the content attribute makes
619         # sure the content has been fully read.
620         if not self._content_consumed:
621             self.content
622 
623         return dict(
624             (attr, getattr(self, attr, None))
625             for attr in self.__attrs__
626         )
627 
628     def __setstate__(self, state):
629         for name, value in state.items():
630             setattr(self, name, value)
631 
632         # pickled objects do not have .raw
633         setattr(self, '_content_consumed', True)
634         setattr(self, 'raw', None)
635 
636     def __repr__(self):
637         return '<Response [%s]>' % (self.status_code)
638 
639     def __bool__(self):
640         """Returns true if :attr:`status_code` is 'OK'."""
641         return self.ok
642 
643     def __nonzero__(self):
644         """Returns true if :attr:`status_code` is 'OK'."""
645         return self.ok
646 
647     def __iter__(self):
648         """Allows you to use a response as an iterator."""
649         return self.iter_content(128)
650 
651     @property
652     def ok(self):
653         try:
654             self.raise_for_status()
655         except HTTPError:
656             return False
657         return True
658 
659     @property
660     def is_redirect(self):
661         """True if this Response is a well-formed HTTP redirect that could have
662         been processed automatically (by :meth:`Session.resolve_redirects`).
663         """
664         return ('location' in self.headers and self.status_code in REDIRECT_STATI)
665 
666     @property
667     def is_permanent_redirect(self):
668         """True if this Response one of the permanent versions of redirect"""
669         return ('location' in self.headers and self.status_code in (codes.moved_permanently, codes.permanent_redirect))
670 
671     @property
672     def apparent_encoding(self):
673         """The apparent encoding, provided by the chardet library"""
674         return chardet.detect(self.content)['encoding']
675 
676     def iter_content(self, chunk_size=1, decode_unicode=False):
677         """Iterates over the response data.  When stream=True is set on the
678         request, this avoids reading the content at once into memory for
679         large responses.  The chunk size is the number of bytes it should
680         read into memory.  This is not necessarily the length of each item
681         returned as decoding can take place.
682 
683         chunk_size must be of type int or None. A value of None will
684         function differently depending on the value of `stream`.
685         stream=True will read data as it arrives in whatever size the
686         chunks are received. If stream=False, data is returned as
687         a single chunk.
688 
689         If decode_unicode is True, content will be decoded using the best
690         available encoding based on the response.
691         """
692 
693         def generate():
694             # Special case for urllib3.
695             if hasattr(self.raw, 'stream'):
696                 try:
697                     for chunk in self.raw.stream(chunk_size, decode_content=True):
698                         yield chunk
699                 except ProtocolError as e:
700                     raise ChunkedEncodingError(e)
701                 except DecodeError as e:
702                     raise ContentDecodingError(e)
703                 except ReadTimeoutError as e:
704                     raise ConnectionError(e)
705             else:
706                 # Standard file-like object.
707                 while True:
708                     chunk = self.raw.read(chunk_size)
709                     if not chunk:
710                         break
711                     yield chunk
712 
713             self._content_consumed = True
714 
715         if self._content_consumed and isinstance(self._content, bool):
716             raise StreamConsumedError()
717         elif chunk_size is not None and not isinstance(chunk_size, int):
718             raise TypeError("chunk_size must be an int, it is instead a %s." % type(chunk_size))
719         # simulate reading small chunks of the content
720         reused_chunks = iter_slices(self._content, chunk_size)
721 
722         stream_chunks = generate()
723 
724         chunks = reused_chunks if self._content_consumed else stream_chunks
725 
726         if decode_unicode:
727             chunks = stream_decode_response_unicode(chunks, self)
728 
729         return chunks
730 
731     def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=None, delimiter=None):
732         """Iterates over the response data, one line at a time.  When
733         stream=True is set on the request, this avoids reading the
734         content at once into memory for large responses.
735 
736         .. note:: This method is not reentrant safe.
737         """
738 
739         pending = None
740 
741         for chunk in self.iter_content(chunk_size=chunk_size, decode_unicode=decode_unicode):
742 
743             if pending is not None:
744                 chunk = pending + chunk
745 
746             if delimiter:
747                 lines = chunk.split(delimiter)
748             else:
749                 lines = chunk.splitlines()
750 
751             if lines and lines[-1] and chunk and lines[-1][-1] == chunk[-1]:
752                 pending = lines.pop()
753             else:
754                 pending = None
755 
756             for line in lines:
757                 yield line
758 
759         if pending is not None:
760             yield pending
761 
762     @property
763     def content(self):
764         """Content of the response, in bytes."""
765 
766         if self._content is False:
767             # Read the contents.
768             if self._content_consumed:
769                 raise RuntimeError(
770                     'The content for this response was already consumed')
771 
772             if self.status_code == 0:
773                 self._content = None
774             else:
775                 self._content = bytes().join(self.iter_content(CONTENT_CHUNK_SIZE)) or bytes()
776 
777         self._content_consumed = True
778         # don't need to release the connection; that's been handled by urllib3
779         # since we exhausted the data.
780         return self._content
781 
782     @property
783     def text(self):
784         """Content of the response, in unicode.
785 
786         If Response.encoding is None, encoding will be guessed using
787         ``chardet``.
788 
789         The encoding of the response content is determined based solely on HTTP
790         headers, following RFC 2616 to the letter. If you can take advantage of
791         non-HTTP knowledge to make a better guess at the encoding, you should
792         set ``r.encoding`` appropriately before accessing this property.
793         """
794 
795         # Try charset from content-type
796         content = None
797         encoding = self.encoding
798 
799         if not self.content:
800             return str('')
801 
802         # Fallback to auto-detected encoding.
803         if self.encoding is None:
804             encoding = self.apparent_encoding
805 
806         # Decode unicode from given encoding.
807         try:
808             content = str(self.content, encoding, errors='replace')
809         except (LookupError, TypeError):
810             # A LookupError is raised if the encoding was not found which could
811             # indicate a misspelling or similar mistake.
812             #
813             # A TypeError can be raised if encoding is None
814             #
815             # So we try blindly encoding.
816             content = str(self.content, errors='replace')
817 
818         return content
819 
820     def json(self, **kwargs):
821         """Returns the json-encoded content of a response, if any.
822 
823         :param \*\*kwargs: Optional arguments that ``json.loads`` takes.
824         :raises ValueError: If the response body does not contain valid json.
825         """
826 
827         if not self.encoding and self.content and len(self.content) > 3:
828             # No encoding set. JSON RFC 4627 section 3 states we should expect
829             # UTF-8, -16 or -32. Detect which one to use; If the detection or
830             # decoding fails, fall back to `self.text` (using chardet to make
831             # a best guess).
832             encoding = guess_json_utf(self.content)
833             if encoding is not None:
834                 try:
835                     return complexjson.loads(
836                         self.content.decode(encoding), **kwargs
837                     )
838                 except UnicodeDecodeError:
839                     # Wrong UTF codec detected; usually because it's not UTF-8
840                     # but some other 8-bit codec.  This is an RFC violation,
841                     # and the server didn't bother to tell us what codec *was*
842                     # used.
843                     pass
844         return complexjson.loads(self.text, **kwargs)
845 
846     @property
847     def links(self):
848         """Returns the parsed header links of the response, if any."""
849 
850         header = self.headers.get('link')
851 
852         # l = MultiDict()
853         l = {}
854 
855         if header:
856             links = parse_header_links(header)
857 
858             for link in links:
859                 key = link.get('rel') or link.get('url')
860                 l[key] = link
861 
862         return l
863 
864     def raise_for_status(self):
865         """Raises stored :class:`HTTPError`, if one occurred."""
866 
867         http_error_msg = ''
868         if isinstance(self.reason, bytes):
869             # We attempt to decode utf-8 first because some servers
870             # choose to localize their reason strings. If the string
871             # isn't utf-8, we fall back to iso-8859-1 for all other
872             # encodings. (See PR #3538)
873             try:
874                 reason = self.reason.decode('utf-8')
875             except UnicodeDecodeError:
876                 reason = self.reason.decode('iso-8859-1')
877         else:
878             reason = self.reason
879 
880         if 400 <= self.status_code < 500:
881             http_error_msg = u'%s Client Error: %s for url: %s' % (self.status_code, reason, self.url)
882 
883         elif 500 <= self.status_code < 600:
884             http_error_msg = u'%s Server Error: %s for url: %s' % (self.status_code, reason, self.url)
885 
886         if http_error_msg:
887             raise HTTPError(http_error_msg, response=self)
888 
889     def close(self):
890         """Releases the connection back to the pool. Once this method has been
891         called the underlying ``raw`` object must not be accessed again.
892 
893         *Note: Should not normally need to be called explicitly.*
894         """
895         if not self._content_consumed:
896             self.raw.close()
897 
898         release_conn = getattr(self.raw, 'release_conn', None)
899         if release_conn is not None:
900             release_conn()

</code><intended_behavior>Ensure Non-`None` Response Before Access: Add explicit checks around the `requests` call to confirm the presence of a valid response.</intended_behavior>, <file>requests/adapters.py</file>
<class>None</class>
<method>None</method>
<code>
1 # -*- coding: utf-8 -*-
2 
3 """
4 requests.adapters
5 ~~~~~~~~~~~~~~~~~
6 
7 This module contains the transport adapters that Requests uses to define
8 and maintain connections.
9 """
10 
11 import os.path
12 import socket
13 
14 from .models import Response
15 from .packages.urllib3.poolmanager import PoolManager, proxy_from_url
16 from .packages.urllib3.response import HTTPResponse
17 from .packages.urllib3.util import Timeout as TimeoutSauce
18 from .packages.urllib3.util.retry import Retry
19 from .compat import urlparse, basestring
20 from .utils import (DEFAULT_CA_BUNDLE_PATH, get_encoding_from_headers,
21                     prepend_scheme_if_needed, get_auth_from_url, urldefragauth,
22                     select_proxy, to_native_string)
23 from .structures import CaseInsensitiveDict
24 from .packages.urllib3.exceptions import ClosedPoolError
25 from .packages.urllib3.exceptions import ConnectTimeoutError
26 from .packages.urllib3.exceptions import HTTPError as _HTTPError
27 from .packages.urllib3.exceptions import MaxRetryError
28 from .packages.urllib3.exceptions import NewConnectionError
29 from .packages.urllib3.exceptions import ProxyError as _ProxyError
30 from .packages.urllib3.exceptions import ProtocolError
31 from .packages.urllib3.exceptions import ReadTimeoutError
32 from .packages.urllib3.exceptions import SSLError as _SSLError
33 from .packages.urllib3.exceptions import ResponseError
34 from .cookies import extract_cookies_to_jar
35 from .exceptions import (ConnectionError, ConnectTimeout, ReadTimeout, SSLError,
36                          ProxyError, RetryError, InvalidSchema)
37 from .auth import _basic_auth_str
38 
39 try:
40     from .packages.urllib3.contrib.socks import SOCKSProxyManager
41 except ImportError:
42     def SOCKSProxyManager(*args, **kwargs):
43         raise InvalidSchema("Missing dependencies for SOCKS support.")
44 
45 DEFAULT_POOLBLOCK = False
46 DEFAULT_POOLSIZE = 10
47 DEFAULT_RETRIES = 0
48 DEFAULT_POOL_TIMEOUT = None
49 
50 
51 class BaseAdapter(object):
52     """The Base Transport Adapter"""
53 
54     def __init__(self):
55         super(BaseAdapter, self).__init__()
56 
57     def send(self, request, stream=False, timeout=None, verify=True,
58              cert=None, proxies=None):
59         """Sends PreparedRequest object. Returns Response object.
60 
61         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
62         :param stream: (optional) Whether to stream the request content.
63         :param timeout: (optional) How long to wait for the server to send
64             data before giving up, as a float, or a :ref:`(connect timeout,
65             read timeout) <timeouts>` tuple.
66         :type timeout: float or tuple
67         :param verify: (optional) Whether to verify SSL certificates.
68         :param cert: (optional) Any user-provided SSL certificate to be trusted.
69         :param proxies: (optional) The proxies dictionary to apply to the request.
70         """
71         raise NotImplementedError
72 
73     def close(self):
74         """Cleans up adapter specific items."""
75         raise NotImplementedError
76 
77 
78 class HTTPAdapter(BaseAdapter):
79     """The built-in HTTP Adapter for urllib3.
80 
81     Provides a general-case interface for Requests sessions to contact HTTP and
82     HTTPS urls by implementing the Transport Adapter interface. This class will
83     usually be created by the :class:`Session <Session>` class under the
84     covers.
85 
86     :param pool_connections: The number of urllib3 connection pools to cache.
87     :param pool_maxsize: The maximum number of connections to save in the pool.
88     :param max_retries: The maximum number of retries each connection
89         should attempt. Note, this applies only to failed DNS lookups, socket
90         connections and connection timeouts, never to requests where data has
91         made it to the server. By default, Requests does not retry failed
92         connections. If you need granular control over the conditions under
93         which we retry a request, import urllib3's ``Retry`` class and pass
94         that instead.
95     :param pool_block: Whether the connection pool should block for connections.
96 
97     Usage::
98 
99       >>> import requests
100       >>> s = requests.Session()
101       >>> a = requests.adapters.HTTPAdapter(max_retries=3)
102       >>> s.mount('http://', a)
103     """
104     __attrs__ = ['max_retries', 'config', '_pool_connections', '_pool_maxsize',
105                  '_pool_block']
106 
107     def __init__(self, pool_connections=DEFAULT_POOLSIZE,
108                  pool_maxsize=DEFAULT_POOLSIZE, max_retries=DEFAULT_RETRIES,
109                  pool_block=DEFAULT_POOLBLOCK):
110         if max_retries == DEFAULT_RETRIES:
111             self.max_retries = Retry(0, read=False)
112         else:
113             self.max_retries = Retry.from_int(max_retries)
114         self.config = {}
115         self.proxy_manager = {}
116 
117         super(HTTPAdapter, self).__init__()
118 
119         self._pool_connections = pool_connections
120         self._pool_maxsize = pool_maxsize
121         self._pool_block = pool_block
122 
123         self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)
124 
125     def __getstate__(self):
126         return dict((attr, getattr(self, attr, None)) for attr in
127                     self.__attrs__)
128 
129     def __setstate__(self, state):
130         # Can't handle by adding 'proxy_manager' to self.__attrs__ because
131         # self.poolmanager uses a lambda function, which isn't pickleable.
132         self.proxy_manager = {}
133         self.config = {}
134 
135         for attr, value in state.items():
136             setattr(self, attr, value)
137 
138         self.init_poolmanager(self._pool_connections, self._pool_maxsize,
139                               block=self._pool_block)
140 
141     def init_poolmanager(self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs):
142         """Initializes a urllib3 PoolManager.
143 
144         This method should not be called from user code, and is only
145         exposed for use when subclassing the
146         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
147 
148         :param connections: The number of urllib3 connection pools to cache.
149         :param maxsize: The maximum number of connections to save in the pool.
150         :param block: Block when no free connections are available.
151         :param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.
152         """
153         # save these values for pickling
154         self._pool_connections = connections
155         self._pool_maxsize = maxsize
156         self._pool_block = block
157 
158         self.poolmanager = PoolManager(num_pools=connections, maxsize=maxsize,
159                                        block=block, strict=True, **pool_kwargs)
160 
161     def proxy_manager_for(self, proxy, **proxy_kwargs):
162         """Return urllib3 ProxyManager for the given proxy.
163 
164         This method should not be called from user code, and is only
165         exposed for use when subclassing the
166         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
167 
168         :param proxy: The proxy to return a urllib3 ProxyManager for.
169         :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.
170         :returns: ProxyManager
171         :rtype: requests.packages.urllib3.ProxyManager
172         """
173         if proxy in self.proxy_manager:
174             manager = self.proxy_manager[proxy]
175         elif proxy.lower().startswith('socks'):
176             username, password = get_auth_from_url(proxy)
177             manager = self.proxy_manager[proxy] = SOCKSProxyManager(
178                 proxy,
179                 username=username,
180                 password=password,
181                 num_pools=self._pool_connections,
182                 maxsize=self._pool_maxsize,
183                 block=self._pool_block,
184                 **proxy_kwargs
185             )
186         else:
187             proxy_headers = self.proxy_headers(proxy)
188             manager = self.proxy_manager[proxy] = proxy_from_url(
189                 proxy,
190                 proxy_headers=proxy_headers,
191                 num_pools=self._pool_connections,
192                 maxsize=self._pool_maxsize,
193                 block=self._pool_block,
194                 **proxy_kwargs)
195 
196         return manager
197 
198     def cert_verify(self, conn, url, verify, cert):
199         """Verify a SSL certificate. This method should not be called from user
200         code, and is only exposed for use when subclassing the
201         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
202 
203         :param conn: The urllib3 connection object associated with the cert.
204         :param url: The requested URL.
205         :param verify: Whether we should actually verify the certificate.
206         :param cert: The SSL certificate to verify.
207         """
208         if url.lower().startswith('https') and verify:
209 
210             cert_loc = None
211 
212             # Allow self-specified cert location.
213             if verify is not True:
214                 cert_loc = verify
215 
216             if not cert_loc:
217                 cert_loc = DEFAULT_CA_BUNDLE_PATH
218 
219             if not cert_loc:
220                 raise Exception("Could not find a suitable SSL CA certificate bundle.")
221 
222             conn.cert_reqs = 'CERT_REQUIRED'
223 
224             if not os.path.isdir(cert_loc):
225                 conn.ca_certs = cert_loc
226             else:
227                 conn.ca_cert_dir = cert_loc
228         else:
229             conn.cert_reqs = 'CERT_NONE'
230             conn.ca_certs = None
231             conn.ca_cert_dir = None
232 
233         if cert:
234             if not isinstance(cert, basestring):
235                 conn.cert_file = cert[0]
236                 conn.key_file = cert[1]
237             else:
238                 conn.cert_file = cert
239 
240     def build_response(self, req, resp):
241         """Builds a :class:`Response <requests.Response>` object from a urllib3
242         response. This should not be called from user code, and is only exposed
243         for use when subclassing the
244         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`
245 
246         :param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.
247         :param resp: The urllib3 response object.
248         :rtype: requests.Response
249         """
250         response = Response()
251 
252         # Fallback to None if there's no status_code, for whatever reason.
253         response.status_code = getattr(resp, 'status', None)
254 
255         # Make headers case-insensitive.
256         response.headers = CaseInsensitiveDict(getattr(resp, 'headers', {}))
257 
258         # Set encoding.
259         response.encoding = get_encoding_from_headers(response.headers)
260         response.raw = resp
261         response.reason = response.raw.reason
262 
263         if isinstance(req.url, bytes):
264             response.url = req.url.decode('utf-8')
265         else:
266             response.url = req.url
267 
268         # Add new cookies from the server.
269         extract_cookies_to_jar(response.cookies, req, resp)
270 
271         # Give the Response some context.
272         response.request = req
273         response.connection = self
274 
275         return response
276 
277     def get_connection(self, url, proxies=None):
278         """Returns a urllib3 connection for the given URL. This should not be
279         called from user code, and is only exposed for use when subclassing the
280         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
281 
282         :param url: The URL to connect to.
283         :param proxies: (optional) A Requests-style dictionary of proxies used on this request.
284         :rtype: requests.packages.urllib3.ConnectionPool
285         """
286         proxy = select_proxy(url, proxies)
287 
288         if proxy:
289             proxy = prepend_scheme_if_needed(proxy, 'http')
290             proxy_manager = self.proxy_manager_for(proxy)
291             conn = proxy_manager.connection_from_url(url)
292         else:
293             # Only scheme should be lower case
294             parsed = urlparse(url)
295             url = parsed.geturl()
296             conn = self.poolmanager.connection_from_url(url)
297 
298         return conn
299 
300     def close(self):
301         """Disposes of any internal state.
302 
303         Currently, this closes the PoolManager and any active ProxyManager,
304         which closes any pooled connections.
305         """
306         self.poolmanager.clear()
307         for proxy in self.proxy_manager.values():
308             proxy.clear()
309 
310     def request_url(self, request, proxies):
311         """Obtain the url to use when making the final request.
312 
313         If the message is being sent through a HTTP proxy, the full URL has to
314         be used. Otherwise, we should only use the path portion of the URL.
315 
316         This should not be called from user code, and is only exposed for use
317         when subclassing the
318         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
319 
320         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
321         :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.
322         :rtype: str
323         """
324         proxy = select_proxy(request.url, proxies)
325         scheme = urlparse(request.url).scheme
326 
327         is_proxied_http_request = (proxy and scheme != 'https')
328         using_socks_proxy = False
329         if proxy:
330             proxy_scheme = urlparse(proxy).scheme.lower()
331             using_socks_proxy = proxy_scheme.startswith('socks')
332 
333         url = request.path_url
334         if is_proxied_http_request and not using_socks_proxy:
335             url = urldefragauth(request.url)
336 
337         return url
338 
339     def add_headers(self, request, **kwargs):
340         """Add any headers needed by the connection. As of v2.0 this does
341         nothing by default, but is left for overriding by users that subclass
342         the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
343 
344         This should not be called from user code, and is only exposed for use
345         when subclassing the
346         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
347 
348         :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.
349         :param kwargs: The keyword arguments from the call to send().
350         """
351         pass
352 
353     def proxy_headers(self, proxy):
354         """Returns a dictionary of the headers to add to any request sent
355         through a proxy. This works with urllib3 magic to ensure that they are
356         correctly sent to the proxy, rather than in a tunnelled request if
357         CONNECT is being used.
358 
359         This should not be called from user code, and is only exposed for use
360         when subclassing the
361         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
362 
363         :param proxies: The url of the proxy being used for this request.
364         :rtype: dict
365         """
366         headers = {}
367         username, password = get_auth_from_url(proxy)
368 
369         if username:
370             headers['Proxy-Authorization'] = _basic_auth_str(username,
371                                                              password)
372 
373         return headers
374 
375     def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
376         """Sends PreparedRequest object. Returns Response object.
377 
378         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
379         :param stream: (optional) Whether to stream the request content.
380         :param timeout: (optional) How long to wait for the server to send
381             data before giving up, as a float, or a :ref:`(connect timeout,
382             read timeout) <timeouts>` tuple.
383         :type timeout: float or tuple
384         :param verify: (optional) Whether to verify SSL certificates.
385         :param cert: (optional) Any user-provided SSL certificate to be trusted.
386         :param proxies: (optional) The proxies dictionary to apply to the request.
387         :rtype: requests.Response
388         """
389 
390         conn = self.get_connection(request.url, proxies)
391 
392         self.cert_verify(conn, request.url, verify, cert)
393         url = self.request_url(request, proxies)
394         self.add_headers(request)
395 
396         chunked = not (request.body is None or 'Content-Length' in request.headers)
397 
398         if isinstance(timeout, tuple):
399             try:
400                 connect, read = timeout
401                 timeout = TimeoutSauce(connect=connect, read=read)
402             except ValueError as e:
403                 # this may raise a string formatting error.
404                 err = ("Invalid timeout {0}. Pass a (connect, read) "
405                        "timeout tuple, or a single float to set "
406                        "both timeouts to the same value".format(timeout))
407                 raise ValueError(err)
408         else:
409             timeout = TimeoutSauce(connect=timeout, read=timeout)
410 
411         try:
412             if not chunked:
413                 resp = conn.urlopen(
414                     method=request.method,
415                     url=url,
416                     body=request.body,
417                     headers=request.headers,
418                     redirect=False,
419                     assert_same_host=False,
420                     preload_content=False,
421                     decode_content=False,
422                     retries=self.max_retries,
423                     timeout=timeout
424                 )
425 
426             # Send the request.
427             else:
428                 if hasattr(conn, 'proxy_pool'):
429                     conn = conn.proxy_pool
430 
431                 low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)
432 
433                 try:
434                     low_conn.putrequest(request.method,
435                                         url,
436                                         skip_accept_encoding=True)
437 
438                     for header, value in request.headers.items():
439                         low_conn.putheader(header, value)
440 
441                     low_conn.endheaders()
442 
443                     for i in request.body:
444                         low_conn.send(hex(len(i))[2:].encode('utf-8'))
445                         low_conn.send(b'\r\n')
446                         low_conn.send(i)
447                         low_conn.send(b'\r\n')
448                     low_conn.send(b'0\r\n\r\n')
449 
450                     # Receive the response from the server
451                     try:
452                         # For Python 2.7+ versions, use buffering of HTTP
453                         # responses
454                         r = low_conn.getresponse(buffering=True)
455                     except TypeError:
456                         # For compatibility with Python 2.6 versions and back
457                         r = low_conn.getresponse()
458 
459                     resp = HTTPResponse.from_httplib(
460                         r,
461                         pool=conn,
462                         connection=low_conn,
463                         preload_content=False,
464                         decode_content=False
465                     )
466                 except:
467                     # If we hit any problems here, clean up the connection.
468                     # Then, reraise so that we can handle the actual exception.
469                     low_conn.close()
470                     raise
471 
472         except (ProtocolError, socket.error) as err:
473             raise ConnectionError(err, request=request)
474 
475         except MaxRetryError as e:
476             if isinstance(e.reason, ConnectTimeoutError):
477                 # TODO: Remove this in 3.0.0: see #2811
478                 if not isinstance(e.reason, NewConnectionError):
479                     raise ConnectTimeout(e, request=request)
480 
481             if isinstance(e.reason, ResponseError):
482                 raise RetryError(e, request=request)
483 
484             if isinstance(e.reason, _ProxyError):
485                 raise ProxyError(e, request=request)
486 
487             raise ConnectionError(e, request=request)
488 
489         except ClosedPoolError as e:
490             raise ConnectionError(e, request=request)
491 
492         except _ProxyError as e:
493             raise ProxyError(e)
494 
495         except (_SSLError, _HTTPError) as e:
496             if isinstance(e, _SSLError):
497                 raise SSLError(e, request=request)
498             elif isinstance(e, ReadTimeoutError):
499                 raise ReadTimeout(e, request=request)
500             else:
501                 raise
502 
503         return self.build_response(request, resp)

</code><intended_behavior>Ensure Non-`None` Response Before Access: Add explicit checks around the `requests` call to confirm the presence of a valid response.</intended_behavior>, <file>requests/api.py</file>
<class>None</class>
<method>head</method>
<code>
86 def head(url, **kwargs):
87     """Sends a HEAD request.
88 
89     :param url: URL for the new :class:`Request` object.
90     :param \*\*kwargs: Optional arguments that ``request`` takes.
91     :return: :class:`Response <Response>` object
92     :rtype: requests.Response
93     """
94 
95     kwargs.setdefault('allow_redirects', False)
96     return request('head', url, **kwargs)

</code><intended_behavior>Robust Exception Handling for `requests` Calls: Enhance error handling around `requests` library calls to catch exceptions such as `requests.exceptions.RequestException`.</intended_behavior>, <file>requests/sessions.py</file>
<class>None</class>
<method>head</method>
<code>
514     def head(self, url, **kwargs):
515         """Sends a HEAD request. Returns :class:`Response` object.
516 
517         :param url: URL for the new :class:`Request` object.
518         :param \*\*kwargs: Optional arguments that ``request`` takes.
519         :rtype: requests.Response
520         """
521 
522         kwargs.setdefault('allow_redirects', False)
523         return self.request('HEAD', url, **kwargs)

</code><intended_behavior>Robust Exception Handling for `requests` Calls: Enhance error handling around `requests` library calls to catch exceptions such as `requests.exceptions.RequestException`.</intended_behavior>, <file>requests/sessions.py</file>
<class>Session</class>
<method>head</method>
<code>
514     def head(self, url, **kwargs):
515         """Sends a HEAD request. Returns :class:`Response` object.
516 
517         :param url: URL for the new :class:`Request` object.
518         :param \*\*kwargs: Optional arguments that ``request`` takes.
519         :rtype: requests.Response
520         """
521 
522         kwargs.setdefault('allow_redirects', False)
523         return self.request('HEAD', url, **kwargs)

</code><intended_behavior>Robust Exception Handling for `requests` Calls: Enhance error handling around `requests` library calls to catch exceptions such as `requests.exceptions.RequestException`.</intended_behavior>]
2025-10-17 15:21:49.952 | INFO     | Search completed. Bug locations: [<file>requests/sessions.py</file>
<class>None</class>
<method>None</method>
<code>
1 # -*- coding: utf-8 -*-
2 
3 """
4 requests.session
5 ~~~~~~~~~~~~~~~~
6 
7 This module provides a Session object to manage and persist settings across
8 requests (cookies, auth, proxies).
9 """
10 import os
11 from collections import Mapping
12 from datetime import datetime
13 
14 from .auth import _basic_auth_str
15 from .compat import cookielib, OrderedDict, urljoin, urlparse
16 from .cookies import (
17     cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar, merge_cookies)
18 from .models import Request, PreparedRequest, DEFAULT_REDIRECT_LIMIT
19 from .hooks import default_hooks, dispatch_hook
20 from ._internal_utils import to_native_string
21 from .utils import to_key_val_list, default_headers
22 from .exceptions import (
23     TooManyRedirects, InvalidSchema, ChunkedEncodingError, ContentDecodingError)
24 from .packages.urllib3._collections import RecentlyUsedContainer
25 from .structures import CaseInsensitiveDict
26 
27 from .adapters import HTTPAdapter
28 
29 from .utils import (
30     requote_uri, get_environ_proxies, get_netrc_auth, should_bypass_proxies,
31     get_auth_from_url, rewind_body
32 )
33 
34 from .status_codes import codes
35 
36 # formerly defined here, reexposed here for backward compatibility
37 from .models import REDIRECT_STATI
38 
39 REDIRECT_CACHE_SIZE = 1000
40 
41 
42 def merge_setting(request_setting, session_setting, dict_class=OrderedDict):
43     """Determines appropriate setting for a given request, taking into account
44     the explicit setting on that request, and the setting in the session. If a
45     setting is a dictionary, they will be merged together using `dict_class`
46     """
47 
48     if session_setting is None:
49         return request_setting
50 
51     if request_setting is None:
52         return session_setting
53 
54     # Bypass if not a dictionary (e.g. verify)
55     if not (
56             isinstance(session_setting, Mapping) and
57             isinstance(request_setting, Mapping)
58     ):
59         return request_setting
60 
61     merged_setting = dict_class(to_key_val_list(session_setting))
62     merged_setting.update(to_key_val_list(request_setting))
63 
64     # Remove keys that are set to None. Extract keys first to avoid altering
65     # the dictionary during iteration.
66     none_keys = [k for (k, v) in merged_setting.items() if v is None]
67     for key in none_keys:
68         del merged_setting[key]
69 
70     return merged_setting
71 
72 
73 def merge_hooks(request_hooks, session_hooks, dict_class=OrderedDict):
74     """Properly merges both requests and session hooks.
75 
76     This is necessary because when request_hooks == {'response': []}, the
77     merge breaks Session hooks entirely.
78     """
79     if session_hooks is None or session_hooks.get('response') == []:
80         return request_hooks
81 
82     if request_hooks is None or request_hooks.get('response') == []:
83         return session_hooks
84 
85     return merge_setting(request_hooks, session_hooks, dict_class)
86 
87 
88 class SessionRedirectMixin(object):
89     def resolve_redirects(self, resp, req, stream=False, timeout=None,
90                           verify=True, cert=None, proxies=None, **adapter_kwargs):
91         """Receives a Response. Returns a generator of Responses."""
92 
93         i = 0
94         hist = [] # keep track of history
95 
96         while resp.is_redirect:
97             prepared_request = req.copy()
98 
99             if i > 0:
100                 # Update history and keep track of redirects.
101                 hist.append(resp)
102                 new_hist = list(hist)
103                 resp.history = new_hist
104 
105             try:
106                 resp.content  # Consume socket so it can be released
107             except (ChunkedEncodingError, ContentDecodingError, RuntimeError):
108                 resp.raw.read(decode_content=False)
109 
110             if i >= self.max_redirects:
111                 raise TooManyRedirects('Exceeded %s redirects.' % self.max_redirects, response=resp)
112 
113             # Release the connection back into the pool.
114             resp.close()
115 
116             url = resp.headers['location']
117 
118             # Handle redirection without scheme (see: RFC 1808 Section 4)
119             if url.startswith('//'):
120                 parsed_rurl = urlparse(resp.url)
121                 url = '%s:%s' % (parsed_rurl.scheme, url)
122 
123             # The scheme should be lower case...
124             parsed = urlparse(url)
125             url = parsed.geturl()
126 
127             # Facilitate relative 'location' headers, as allowed by RFC 7231.
128             # (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')
129             # Compliant with RFC3986, we percent encode the url.
130             if not parsed.netloc:
131                 url = urljoin(resp.url, requote_uri(url))
132             else:
133                 url = requote_uri(url)
134 
135             prepared_request.url = to_native_string(url)
136             # Cache the url, unless it redirects to itself.
137             if resp.is_permanent_redirect and req.url != prepared_request.url:
138                 self.redirect_cache[req.url] = prepared_request.url
139 
140             self.rebuild_method(prepared_request, resp)
141 
142             # https://github.com/kennethreitz/requests/issues/1084
143             if resp.status_code not in (codes.temporary_redirect, codes.permanent_redirect):
144                 # https://github.com/kennethreitz/requests/issues/3490
145                 purged_headers = ('Content-Length', 'Content-Type', 'Transfer-Encoding')
146                 for header in purged_headers:
147                     prepared_request.headers.pop(header, None)
148                 prepared_request.body = None
149 
150             headers = prepared_request.headers
151             try:
152                 del headers['Cookie']
153             except KeyError:
154                 pass
155 
156             # Extract any cookies sent on the response to the cookiejar
157             # in the new request. Because we've mutated our copied prepared
158             # request, use the old one that we haven't yet touched.
159             extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)
160             merge_cookies(prepared_request._cookies, self.cookies)
161             prepared_request.prepare_cookies(prepared_request._cookies)
162 
163             # Rebuild auth and proxy information.
164             proxies = self.rebuild_proxies(prepared_request, proxies)
165             self.rebuild_auth(prepared_request, resp)
166 
167             # A failed tell() sets `_body_position` to `object()`. This non-None
168             # value ensures `rewindable` will be True, allowing us to raise an
169             # UnrewindableBodyError, instead of hanging the connection.
170             rewindable = (
171                 prepared_request._body_position is not None and
172                 ('Content-Length' in headers or 'Transfer-Encoding' in headers)
173             )
174 
175             # Attempt to rewind consumed file-like object.
176             if rewindable:
177                 rewind_body(prepared_request)
178 
179             # Override the original request.
180             req = prepared_request
181 
182             resp = self.send(
183                 req,
184                 stream=stream,
185                 timeout=timeout,
186                 verify=verify,
187                 cert=cert,
188                 proxies=proxies,
189                 allow_redirects=False,
190                 **adapter_kwargs
191             )
192 
193             extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)
194 
195             i += 1
196             yield resp
197 
198     def rebuild_auth(self, prepared_request, response):
199         """When being redirected we may want to strip authentication from the
200         request to avoid leaking credentials. This method intelligently removes
201         and reapplies authentication where possible to avoid credential loss.
202         """
203         headers = prepared_request.headers
204         url = prepared_request.url
205 
206         if 'Authorization' in headers:
207             # If we get redirected to a new host, we should strip out any
208             # authentication headers.
209             original_parsed = urlparse(response.request.url)
210             redirect_parsed = urlparse(url)
211 
212             if (original_parsed.hostname != redirect_parsed.hostname):
213                 del headers['Authorization']
214 
215         # .netrc might have more auth for us on our new host.
216         new_auth = get_netrc_auth(url) if self.trust_env else None
217         if new_auth is not None:
218             prepared_request.prepare_auth(new_auth)
219 
220         return
221 
222     def rebuild_proxies(self, prepared_request, proxies):
223         """This method re-evaluates the proxy configuration by considering the
224         environment variables. If we are redirected to a URL covered by
225         NO_PROXY, we strip the proxy configuration. Otherwise, we set missing
226         proxy keys for this URL (in case they were stripped by a previous
227         redirect).
228 
229         This method also replaces the Proxy-Authorization header where
230         necessary.
231 
232         :rtype: dict
233         """
234         headers = prepared_request.headers
235         url = prepared_request.url
236         scheme = urlparse(url).scheme
237         new_proxies = proxies.copy() if proxies is not None else {}
238 
239         if self.trust_env and not should_bypass_proxies(url):
240             environ_proxies = get_environ_proxies(url)
241 
242             proxy = environ_proxies.get(scheme, environ_proxies.get('all'))
243 
244             if proxy:
245                 new_proxies.setdefault(scheme, proxy)
246 
247         if 'Proxy-Authorization' in headers:
248             del headers['Proxy-Authorization']
249 
250         try:
251             username, password = get_auth_from_url(new_proxies[scheme])
252         except KeyError:
253             username, password = None, None
254 
255         if username and password:
256             headers['Proxy-Authorization'] = _basic_auth_str(username, password)
257 
258         return new_proxies
259 
260     def rebuild_method(self, prepared_request, response):
261         """When being redirected we may want to change the method of the request
262         based on certain specs or browser behavior.
263         """
264         method = prepared_request.method
265 
266         # http://tools.ietf.org/html/rfc7231#section-6.4.4
267         if response.status_code == codes.see_other and method != 'HEAD':
268             method = 'GET'
269 
270         # Do what the browsers do, despite standards...
271         # First, turn 302s into GETs.
272         if response.status_code == codes.found and method != 'HEAD':
273             method = 'GET'
274 
275         # Second, if a POST is responded to with a 301, turn it into a GET.
276         # This bizarre behaviour is explained in Issue 1704.
277         if response.status_code == codes.moved and method == 'POST':
278             method = 'GET'
279 
280         prepared_request.method = method
281 
282 
283 class Session(SessionRedirectMixin):
284     """A Requests session.
285 
286     Provides cookie persistence, connection-pooling, and configuration.
287 
288     Basic Usage::
289 
290       >>> import requests
291       >>> s = requests.Session()
292       >>> s.get('http://httpbin.org/get')
293       <Response [200]>
294 
295     Or as a context manager::
296 
297       >>> with requests.Session() as s:
298       >>>     s.get('http://httpbin.org/get')
299       <Response [200]>
300     """
301 
302     __attrs__ = [
303         'headers', 'cookies', 'auth', 'proxies', 'hooks', 'params', 'verify',
304         'cert', 'prefetch', 'adapters', 'stream', 'trust_env',
305         'max_redirects',
306     ]
307 
308     def __init__(self):
309 
310         #: A case-insensitive dictionary of headers to be sent on each
311         #: :class:`Request <Request>` sent from this
312         #: :class:`Session <Session>`.
313         self.headers = default_headers()
314 
315         #: Default Authentication tuple or object to attach to
316         #: :class:`Request <Request>`.
317         self.auth = None
318 
319         #: Dictionary mapping protocol or protocol and host to the URL of the proxy
320         #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to
321         #: be used on each :class:`Request <Request>`.
322         self.proxies = {}
323 
324         #: Event-handling hooks.
325         self.hooks = default_hooks()
326 
327         #: Dictionary of querystring data to attach to each
328         #: :class:`Request <Request>`. The dictionary values may be lists for
329         #: representing multivalued query parameters.
330         self.params = {}
331 
332         #: Stream response content default.
333         self.stream = False
334 
335         #: SSL Verification default.
336         self.verify = True
337 
338         #: SSL client certificate default.
339         self.cert = None
340 
341         #: Maximum number of redirects allowed. If the request exceeds this
342         #: limit, a :class:`TooManyRedirects` exception is raised.
343         #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is
344         #: 30.
345         self.max_redirects = DEFAULT_REDIRECT_LIMIT
346 
347         #: Trust environment settings for proxy configuration, default
348         #: authentication and similar.
349         self.trust_env = True
350 
351         #: A CookieJar containing all currently outstanding cookies set on this
352         #: session. By default it is a
353         #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but
354         #: may be any other ``cookielib.CookieJar`` compatible object.
355         self.cookies = cookiejar_from_dict({})
356 
357         # Default connection adapters.
358         self.adapters = OrderedDict()
359         self.mount('https://', HTTPAdapter())
360         self.mount('http://', HTTPAdapter())
361 
362         # Only store 1000 redirects to prevent using infinite memory
363         self.redirect_cache = RecentlyUsedContainer(REDIRECT_CACHE_SIZE)
364 
365     def __enter__(self):
366         return self
367 
368     def __exit__(self, *args):
369         self.close()
370 
371     def prepare_request(self, request):
372         """Constructs a :class:`PreparedRequest <PreparedRequest>` for
373         transmission and returns it. The :class:`PreparedRequest` has settings
374         merged from the :class:`Request <Request>` instance and those of the
375         :class:`Session`.
376 
377         :param request: :class:`Request` instance to prepare with this
378             session's settings.
379         :rtype: requests.PreparedRequest
380         """
381         cookies = request.cookies or {}
382 
383         # Bootstrap CookieJar.
384         if not isinstance(cookies, cookielib.CookieJar):
385             cookies = cookiejar_from_dict(cookies)
386 
387         # Merge with session cookies
388         merged_cookies = merge_cookies(
389             merge_cookies(RequestsCookieJar(), self.cookies), cookies)
390 
391         # Set environment's basic authentication if not explicitly set.
392         auth = request.auth
393         if self.trust_env and not auth and not self.auth:
394             auth = get_netrc_auth(request.url)
395 
396         p = PreparedRequest()
397         p.prepare(
398             method=request.method.upper(),
399             url=request.url,
400             files=request.files,
401             data=request.data,
402             json=request.json,
403             headers=merge_setting(request.headers, self.headers, dict_class=CaseInsensitiveDict),
404             params=merge_setting(request.params, self.params),
405             auth=merge_setting(auth, self.auth),
406             cookies=merged_cookies,
407             hooks=merge_hooks(request.hooks, self.hooks),
408         )
409         return p
410 
411     def request(self, method, url,
412         params=None,
413         data=None,
414         headers=None,
415         cookies=None,
416         files=None,
417         auth=None,
418         timeout=None,
419         allow_redirects=True,
420         proxies=None,
421         hooks=None,
422         stream=None,
423         verify=None,
424         cert=None,
425         json=None):
426         """Constructs a :class:`Request <Request>`, prepares it and sends it.
427         Returns :class:`Response <Response>` object.
428 
429         :param method: method for the new :class:`Request` object.
430         :param url: URL for the new :class:`Request` object.
431         :param params: (optional) Dictionary or bytes to be sent in the query
432             string for the :class:`Request`.
433         :param data: (optional) Dictionary, bytes, or file-like object to send
434             in the body of the :class:`Request`.
435         :param json: (optional) json to send in the body of the
436             :class:`Request`.
437         :param headers: (optional) Dictionary of HTTP Headers to send with the
438             :class:`Request`.
439         :param cookies: (optional) Dict or CookieJar object to send with the
440             :class:`Request`.
441         :param files: (optional) Dictionary of ``'filename': file-like-objects``
442             for multipart encoding upload.
443         :param auth: (optional) Auth tuple or callable to enable
444             Basic/Digest/Custom HTTP Auth.
445         :param timeout: (optional) How long to wait for the server to send
446             data before giving up, as a float, or a :ref:`(connect timeout,
447             read timeout) <timeouts>` tuple.
448         :type timeout: float or tuple
449         :param allow_redirects: (optional) Set to True by default.
450         :type allow_redirects: bool
451         :param proxies: (optional) Dictionary mapping protocol or protocol and
452             hostname to the URL of the proxy.
453         :param stream: (optional) whether to immediately download the response
454             content. Defaults to ``False``.
455         :param verify: (optional) whether the SSL cert will be verified.
456             A CA_BUNDLE path can also be provided. Defaults to ``True``.
457         :param cert: (optional) if String, path to ssl client cert file (.pem).
458             If Tuple, ('cert', 'key') pair.
459         :rtype: requests.Response
460         """
461         # Create the Request.
462         req = Request(
463             method = method.upper(),
464             url = url,
465             headers = headers,
466             files = files,
467             data = data or {},
468             json = json,
469             params = params or {},
470             auth = auth,
471             cookies = cookies,
472             hooks = hooks,
473         )
474         prep = self.prepare_request(req)
475 
476         proxies = proxies or {}
477 
478         settings = self.merge_environment_settings(
479             prep.url, proxies, stream, verify, cert
480         )
481 
482         # Send the request.
483         send_kwargs = {
484             'timeout': timeout,
485             'allow_redirects': allow_redirects,
486         }
487         send_kwargs.update(settings)
488         resp = self.send(prep, **send_kwargs)
489 
490         return resp
491 
492     def get(self, url, **kwargs):
493         """Sends a GET request. Returns :class:`Response` object.
494 
495         :param url: URL for the new :class:`Request` object.
496         :param \*\*kwargs: Optional arguments that ``request`` takes.
497         :rtype: requests.Response
498         """
499 
500         kwargs.setdefault('allow_redirects', True)
501         return self.request('GET', url, **kwargs)
502 
503     def options(self, url, **kwargs):
504         """Sends a OPTIONS request. Returns :class:`Response` object.
505 
506         :param url: URL for the new :class:`Request` object.
507         :param \*\*kwargs: Optional arguments that ``request`` takes.
508         :rtype: requests.Response
509         """
510 
511         kwargs.setdefault('allow_redirects', True)
512         return self.request('OPTIONS', url, **kwargs)
513 
514     def head(self, url, **kwargs):
515         """Sends a HEAD request. Returns :class:`Response` object.
516 
517         :param url: URL for the new :class:`Request` object.
518         :param \*\*kwargs: Optional arguments that ``request`` takes.
519         :rtype: requests.Response
520         """
521 
522         kwargs.setdefault('allow_redirects', False)
523         return self.request('HEAD', url, **kwargs)
524 
525     def post(self, url, data=None, json=None, **kwargs):
526         """Sends a POST request. Returns :class:`Response` object.
527 
528         :param url: URL for the new :class:`Request` object.
529         :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
530         :param json: (optional) json to send in the body of the :class:`Request`.
531         :param \*\*kwargs: Optional arguments that ``request`` takes.
532         :rtype: requests.Response
533         """
534 
535         return self.request('POST', url, data=data, json=json, **kwargs)
536 
537     def put(self, url, data=None, **kwargs):
538         """Sends a PUT request. Returns :class:`Response` object.
539 
540         :param url: URL for the new :class:`Request` object.
541         :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
542         :param \*\*kwargs: Optional arguments that ``request`` takes.
543         :rtype: requests.Response
544         """
545 
546         return self.request('PUT', url, data=data, **kwargs)
547 
548     def patch(self, url, data=None, **kwargs):
549         """Sends a PATCH request. Returns :class:`Response` object.
550 
551         :param url: URL for the new :class:`Request` object.
552         :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
553         :param \*\*kwargs: Optional arguments that ``request`` takes.
554         :rtype: requests.Response
555         """
556 
557         return self.request('PATCH', url,  data=data, **kwargs)
558 
559     def delete(self, url, **kwargs):
560         """Sends a DELETE request. Returns :class:`Response` object.
561 
562         :param url: URL for the new :class:`Request` object.
563         :param \*\*kwargs: Optional arguments that ``request`` takes.
564         :rtype: requests.Response
565         """
566 
567         return self.request('DELETE', url, **kwargs)
568 
569     def send(self, request, **kwargs):
570         """
571         Send a given PreparedRequest.
572 
573         :rtype: requests.Response
574         """
575         # Set defaults that the hooks can utilize to ensure they always have
576         # the correct parameters to reproduce the previous request.
577         kwargs.setdefault('stream', self.stream)
578         kwargs.setdefault('verify', self.verify)
579         kwargs.setdefault('cert', self.cert)
580         kwargs.setdefault('proxies', self.proxies)
581 
582         # It's possible that users might accidentally send a Request object.
583         # Guard against that specific failure case.
584         if isinstance(request, Request):
585             raise ValueError('You can only send PreparedRequests.')
586 
587         # Set up variables needed for resolve_redirects and dispatching of hooks
588         allow_redirects = kwargs.pop('allow_redirects', True)
589         stream = kwargs.get('stream')
590         hooks = request.hooks
591 
592         # Resolve URL in redirect cache, if available.
593         if allow_redirects:
594             checked_urls = set()
595             while request.url in self.redirect_cache:
596                 checked_urls.add(request.url)
597                 new_url = self.redirect_cache.get(request.url)
598                 if new_url in checked_urls:
599                     break
600                 request.url = new_url
601 
602         # Get the appropriate adapter to use
603         adapter = self.get_adapter(url=request.url)
604 
605         # Start time (approximately) of the request
606         start = datetime.utcnow()
607 
608         # Send the request
609         r = adapter.send(request, **kwargs)
610 
611         # Total elapsed time of the request (approximately)
612         r.elapsed = datetime.utcnow() - start
613 
614         # Response manipulation hooks
615         r = dispatch_hook('response', hooks, r, **kwargs)
616 
617         # Persist cookies
618         if r.history:
619 
620             # If the hooks create history then we want those cookies too
621             for resp in r.history:
622                 extract_cookies_to_jar(self.cookies, resp.request, resp.raw)
623 
624         extract_cookies_to_jar(self.cookies, request, r.raw)
625 
626         # Redirect resolving generator.
627         gen = self.resolve_redirects(r, request, **kwargs)
628 
629         # Resolve redirects if allowed.
630         history = [resp for resp in gen] if allow_redirects else []
631 
632         # Shuffle things around if there's history.
633         if history:
634             # Insert the first (original) request at the start
635             history.insert(0, r)
636             # Get the last request made
637             r = history.pop()
638             r.history = history
639 
640         if not stream:
641             r.content
642 
643         return r
644 
645     def merge_environment_settings(self, url, proxies, stream, verify, cert):
646         """
647         Check the environment and merge it with some settings.
648 
649         :rtype: dict
650         """
651         # Gather clues from the surrounding environment.
652         if self.trust_env:
653             # Set environment's proxies.
654             env_proxies = get_environ_proxies(url) or {}
655             for (k, v) in env_proxies.items():
656                 proxies.setdefault(k, v)
657 
658             # Look for requests environment configuration and be compatible
659             # with cURL.
660             if verify is True or verify is None:
661                 verify = (os.environ.get('REQUESTS_CA_BUNDLE') or
662                           os.environ.get('CURL_CA_BUNDLE'))
663 
664         # Merge all the kwargs.
665         proxies = merge_setting(proxies, self.proxies)
666         stream = merge_setting(stream, self.stream)
667         verify = merge_setting(verify, self.verify)
668         cert = merge_setting(cert, self.cert)
669 
670         return {'verify': verify, 'proxies': proxies, 'stream': stream,
671                 'cert': cert}
672 
673     def get_adapter(self, url):
674         """
675         Returns the appropriate connection adapter for the given URL.
676 
677         :rtype: requests.adapters.BaseAdapter
678         """
679         for (prefix, adapter) in self.adapters.items():
680 
681             if url.lower().startswith(prefix):
682                 return adapter
683 
684         # Nothing matches :-/
685         raise InvalidSchema("No connection adapters were found for '%s'" % url)
686 
687     def close(self):
688         """Closes all adapters and as such the session"""
689         for v in self.adapters.values():
690             v.close()
691 
692     def mount(self, prefix, adapter):
693         """Registers a connection adapter to a prefix.
694 
695         Adapters are sorted in descending order by key length.
696         """
697         self.adapters[prefix] = adapter
698         keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]
699 
700         for key in keys_to_move:
701             self.adapters[key] = self.adapters.pop(key)
702 
703     def __getstate__(self):
704         state = dict((attr, getattr(self, attr, None)) for attr in self.__attrs__)
705         state['redirect_cache'] = dict(self.redirect_cache)
706         return state
707 
708     def __setstate__(self, state):
709         redirect_cache = state.pop('redirect_cache', {})
710         for attr, value in state.items():
711             setattr(self, attr, value)
712 
713         self.redirect_cache = RecentlyUsedContainer(REDIRECT_CACHE_SIZE)
714         for redirect, to in redirect_cache.items():
715             self.redirect_cache[redirect] = to
716 
717 
718 def session():
719     """
720     Returns a :class:`Session` for context-management.
721 
722     :rtype: Session
723     """
724 
725     return Session()

</code><intended_behavior>Ensure Non-`None` Response Before Access: Add explicit checks around the `requests` call to confirm the presence of a valid response.</intended_behavior>, <file>requests/models.py</file>
<class>None</class>
<method>None</method>
<code>
1 # -*- coding: utf-8 -*-
2 
3 """
4 requests.models
5 ~~~~~~~~~~~~~~~
6 
7 This module contains the primary objects that power Requests.
8 """
9 
10 import collections
11 import datetime
12 
13 # Import encoding now, to avoid implicit import later.
14 # Implicit import within threads may cause LookupError when standard library is in a ZIP,
15 # such as in Embedded Python. See https://github.com/kennethreitz/requests/issues/3578.
16 import encodings.idna
17 
18 from io import BytesIO, UnsupportedOperation
19 from .hooks import default_hooks
20 from .structures import CaseInsensitiveDict
21 
22 from .auth import HTTPBasicAuth
23 from .cookies import cookiejar_from_dict, get_cookie_header, _copy_cookie_jar
24 from .packages import idna
25 from .packages.urllib3.fields import RequestField
26 from .packages.urllib3.filepost import encode_multipart_formdata
27 from .packages.urllib3.util import parse_url
28 from .packages.urllib3.exceptions import (
29     DecodeError, ReadTimeoutError, ProtocolError, LocationParseError)
30 from .exceptions import (
31     HTTPError, MissingSchema, InvalidURL, ChunkedEncodingError,
32     ContentDecodingError, ConnectionError, StreamConsumedError)
33 from ._internal_utils import to_native_string
34 from .utils import (
35     guess_filename, get_auth_from_url, requote_uri,
36     stream_decode_response_unicode, to_key_val_list, parse_header_links,
37     iter_slices, guess_json_utf, super_len, check_header_validity)
38 from .compat import (
39     cookielib, urlunparse, urlsplit, urlencode, str, bytes, StringIO,
40     is_py2, chardet, builtin_str, basestring)
41 from .compat import json as complexjson
42 from .status_codes import codes
43 
44 #: The set of HTTP status codes that indicate an automatically
45 #: processable redirect.
46 REDIRECT_STATI = (
47     codes.moved,               # 301
48     codes.found,               # 302
49     codes.other,               # 303
50     codes.temporary_redirect,  # 307
51     codes.permanent_redirect,  # 308
52 )
53 
54 DEFAULT_REDIRECT_LIMIT = 30
55 CONTENT_CHUNK_SIZE = 10 * 1024
56 ITER_CHUNK_SIZE = 512
57 
58 
59 class RequestEncodingMixin(object):
60     @property
61     def path_url(self):
62         """Build the path URL to use."""
63 
64         url = []
65 
66         p = urlsplit(self.url)
67 
68         path = p.path
69         if not path:
70             path = '/'
71 
72         url.append(path)
73 
74         query = p.query
75         if query:
76             url.append('?')
77             url.append(query)
78 
79         return ''.join(url)
80 
81     @staticmethod
82     def _encode_params(data):
83         """Encode parameters in a piece of data.
84 
85         Will successfully encode parameters when passed as a dict or a list of
86         2-tuples. Order is retained if data is a list of 2-tuples but arbitrary
87         if parameters are supplied as a dict.
88         """
89 
90         if isinstance(data, (str, bytes)):
91             return data
92         elif hasattr(data, 'read'):
93             return data
94         elif hasattr(data, '__iter__'):
95             result = []
96             for k, vs in to_key_val_list(data):
97                 if isinstance(vs, basestring) or not hasattr(vs, '__iter__'):
98                     vs = [vs]
99                 for v in vs:
100                     if v is not None:
101                         result.append(
102                             (k.encode('utf-8') if isinstance(k, str) else k,
103                              v.encode('utf-8') if isinstance(v, str) else v))
104             return urlencode(result, doseq=True)
105         else:
106             return data
107 
108     @staticmethod
109     def _encode_files(files, data):
110         """Build the body for a multipart/form-data request.
111 
112         Will successfully encode files when passed as a dict or a list of
113         tuples. Order is retained if data is a list of tuples but arbitrary
114         if parameters are supplied as a dict.
115         The tuples may be 2-tuples (filename, fileobj), 3-tuples (filename, fileobj, contentype)
116         or 4-tuples (filename, fileobj, contentype, custom_headers).
117         """
118         if (not files):
119             raise ValueError("Files must be provided.")
120         elif isinstance(data, basestring):
121             raise ValueError("Data must not be a string.")
122 
123         new_fields = []
124         fields = to_key_val_list(data or {})
125         files = to_key_val_list(files or {})
126 
127         for field, val in fields:
128             if isinstance(val, basestring) or not hasattr(val, '__iter__'):
129                 val = [val]
130             for v in val:
131                 if v is not None:
132                     # Don't call str() on bytestrings: in Py3 it all goes wrong.
133                     if not isinstance(v, bytes):
134                         v = str(v)
135 
136                     new_fields.append(
137                         (field.decode('utf-8') if isinstance(field, bytes) else field,
138                          v.encode('utf-8') if isinstance(v, str) else v))
139 
140         for (k, v) in files:
141             # support for explicit filename
142             ft = None
143             fh = None
144             if isinstance(v, (tuple, list)):
145                 if len(v) == 2:
146                     fn, fp = v
147                 elif len(v) == 3:
148                     fn, fp, ft = v
149                 else:
150                     fn, fp, ft, fh = v
151             else:
152                 fn = guess_filename(v) or k
153                 fp = v
154 
155             if isinstance(fp, (str, bytes, bytearray)):
156                 fdata = fp
157             else:
158                 fdata = fp.read()
159 
160             rf = RequestField(name=k, data=fdata, filename=fn, headers=fh)
161             rf.make_multipart(content_type=ft)
162             new_fields.append(rf)
163 
164         body, content_type = encode_multipart_formdata(new_fields)
165 
166         return body, content_type
167 
168 
169 class RequestHooksMixin(object):
170     def register_hook(self, event, hook):
171         """Properly register a hook."""
172 
173         if event not in self.hooks:
174             raise ValueError('Unsupported event specified, with event name "%s"' % (event))
175 
176         if isinstance(hook, collections.Callable):
177             self.hooks[event].append(hook)
178         elif hasattr(hook, '__iter__'):
179             self.hooks[event].extend(h for h in hook if isinstance(h, collections.Callable))
180 
181     def deregister_hook(self, event, hook):
182         """Deregister a previously registered hook.
183         Returns True if the hook existed, False if not.
184         """
185 
186         try:
187             self.hooks[event].remove(hook)
188             return True
189         except ValueError:
190             return False
191 
192 
193 class Request(RequestHooksMixin):
194     """A user-created :class:`Request <Request>` object.
195 
196     Used to prepare a :class:`PreparedRequest <PreparedRequest>`, which is sent to the server.
197 
198     :param method: HTTP method to use.
199     :param url: URL to send.
200     :param headers: dictionary of headers to send.
201     :param files: dictionary of {filename: fileobject} files to multipart upload.
202     :param data: the body to attach to the request. If a dictionary is provided, form-encoding will take place.
203     :param json: json for the body to attach to the request (if files or data is not specified).
204     :param params: dictionary of URL parameters to append to the URL.
205     :param auth: Auth handler or (user, pass) tuple.
206     :param cookies: dictionary or CookieJar of cookies to attach to this request.
207     :param hooks: dictionary of callback hooks, for internal usage.
208 
209     Usage::
210 
211       >>> import requests
212       >>> req = requests.Request('GET', 'http://httpbin.org/get')
213       >>> req.prepare()
214       <PreparedRequest [GET]>
215     """
216 
217     def __init__(self, method=None, url=None, headers=None, files=None,
218         data=None, params=None, auth=None, cookies=None, hooks=None, json=None):
219 
220         # Default empty dicts for dict params.
221         data = [] if data is None else data
222         files = [] if files is None else files
223         headers = {} if headers is None else headers
224         params = {} if params is None else params
225         hooks = {} if hooks is None else hooks
226 
227         self.hooks = default_hooks()
228         for (k, v) in list(hooks.items()):
229             self.register_hook(event=k, hook=v)
230 
231         self.method = method
232         self.url = url
233         self.headers = headers
234         self.files = files
235         self.data = data
236         self.json = json
237         self.params = params
238         self.auth = auth
239         self.cookies = cookies
240 
241     def __repr__(self):
242         return '<Request [%s]>' % (self.method)
243 
244     def prepare(self):
245         """Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it."""
246         p = PreparedRequest()
247         p.prepare(
248             method=self.method,
249             url=self.url,
250             headers=self.headers,
251             files=self.files,
252             data=self.data,
253             json=self.json,
254             params=self.params,
255             auth=self.auth,
256             cookies=self.cookies,
257             hooks=self.hooks,
258         )
259         return p
260 
261 
262 class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):
263     """The fully mutable :class:`PreparedRequest <PreparedRequest>` object,
264     containing the exact bytes that will be sent to the server.
265 
266     Generated from either a :class:`Request <Request>` object or manually.
267 
268     Usage::
269 
270       >>> import requests
271       >>> req = requests.Request('GET', 'http://httpbin.org/get')
272       >>> r = req.prepare()
273       <PreparedRequest [GET]>
274 
275       >>> s = requests.Session()
276       >>> s.send(r)
277       <Response [200]>
278     """
279 
280     def __init__(self):
281         #: HTTP verb to send to the server.
282         self.method = None
283         #: HTTP URL to send the request to.
284         self.url = None
285         #: dictionary of HTTP headers.
286         self.headers = None
287         # The `CookieJar` used to create the Cookie header will be stored here
288         # after prepare_cookies is called
289         self._cookies = None
290         #: request body to send to the server.
291         self.body = None
292         #: dictionary of callback hooks, for internal usage.
293         self.hooks = default_hooks()
294         #: integer denoting starting position of a readable file-like body.
295         self._body_position = None
296 
297     def prepare(self, method=None, url=None, headers=None, files=None,
298         data=None, params=None, auth=None, cookies=None, hooks=None, json=None):
299         """Prepares the entire request with the given parameters."""
300 
301         self.prepare_method(method)
302         self.prepare_url(url, params)
303         self.prepare_headers(headers)
304         self.prepare_cookies(cookies)
305         self.prepare_body(data, files, json)
306         self.prepare_auth(auth, url)
307 
308         # Note that prepare_auth must be last to enable authentication schemes
309         # such as OAuth to work on a fully prepared request.
310 
311         # This MUST go after prepare_auth. Authenticators could add a hook
312         self.prepare_hooks(hooks)
313 
314     def __repr__(self):
315         return '<PreparedRequest [%s]>' % (self.method)
316 
317     def copy(self):
318         p = PreparedRequest()
319         p.method = self.method
320         p.url = self.url
321         p.headers = self.headers.copy() if self.headers is not None else None
322         p._cookies = _copy_cookie_jar(self._cookies)
323         p.body = self.body
324         p.hooks = self.hooks
325         p._body_position = self._body_position
326         return p
327 
328     def prepare_method(self, method):
329         """Prepares the given HTTP method."""
330         self.method = method
331         if self.method is not None:
332             self.method = to_native_string(self.method.upper())
333 
334     def prepare_url(self, url, params):
335         """Prepares the given HTTP URL."""
336         #: Accept objects that have string representations.
337         #: We're unable to blindly call unicode/str functions
338         #: as this will include the bytestring indicator (b'')
339         #: on python 3.x.
340         #: https://github.com/kennethreitz/requests/pull/2238
341         if isinstance(url, bytes):
342             url = url.decode('utf8')
343         else:
344             url = unicode(url) if is_py2 else str(url)
345 
346         # Remove leading whitespaces from url
347         url = url.lstrip()
348 
349         # Don't do any URL preparation for non-HTTP schemes like `mailto`,
350         # `data`, `http+unix` etc to work around exceptions from `url_parse`,
351         # which handles RFC 3986 only.
352         if ':' in url and not url.lower().startswith(('http://', 'https://')):
353             self.url = url
354             return
355 
356         # Support for unicode domain names and paths.
357         try:
358             scheme, auth, host, port, path, query, fragment = parse_url(url)
359         except LocationParseError as e:
360             raise InvalidURL(*e.args)
361 
362         if not scheme:
363             error = ("Invalid URL {0!r}: No schema supplied. Perhaps you meant http://{0}?")
364             error = error.format(to_native_string(url, 'utf8'))
365 
366             raise MissingSchema(error)
367 
368         if not host:
369             raise InvalidURL("Invalid URL %r: No host supplied" % url)
370 
371         # Only want to apply IDNA to the hostname
372         try:
373             host = idna.encode(host, uts46=True).decode('utf-8')
374         except (UnicodeError, idna.IDNAError):
375             raise InvalidURL('URL has an invalid label.')
376 
377         # Carefully reconstruct the network location
378         netloc = auth or ''
379         if netloc:
380             netloc += '@'
381         netloc += host
382         if port:
383             netloc += ':' + str(port)
384 
385         # Bare domains aren't valid URLs.
386         if not path:
387             path = '/'
388 
389         if is_py2:
390             if isinstance(scheme, str):
391                 scheme = scheme.encode('utf-8')
392             if isinstance(netloc, str):
393                 netloc = netloc.encode('utf-8')
394             if isinstance(path, str):
395                 path = path.encode('utf-8')
396             if isinstance(query, str):
397                 query = query.encode('utf-8')
398             if isinstance(fragment, str):
399                 fragment = fragment.encode('utf-8')
400 
401         if isinstance(params, (str, bytes)):
402             params = to_native_string(params)
403 
404         enc_params = self._encode_params(params)
405         if enc_params:
406             if query:
407                 query = '%s&%s' % (query, enc_params)
408             else:
409                 query = enc_params
410 
411         url = requote_uri(urlunparse([scheme, netloc, path, None, query, fragment]))
412         self.url = url
413 
414     def prepare_headers(self, headers):
415         """Prepares the given HTTP headers."""
416 
417         self.headers = CaseInsensitiveDict()
418         if headers:
419             for header in headers.items():
420                 # Raise exception on invalid header value.
421                 check_header_validity(header)
422                 name, value = header
423                 self.headers[to_native_string(name)] = value
424 
425     def prepare_body(self, data, files, json=None):
426         """Prepares the given HTTP body data."""
427 
428         # Check if file, fo, generator, iterator.
429         # If not, run through normal process.
430 
431         # Nottin' on you.
432         body = None
433         content_type = None
434 
435         if not data and json is not None:
436             # urllib3 requires a bytes-like body. Python 2's json.dumps
437             # provides this natively, but Python 3 gives a Unicode string.
438             content_type = 'application/json'
439             body = complexjson.dumps(json)
440             if not isinstance(body, bytes):
441                 body = body.encode('utf-8')
442 
443         is_stream = all([
444             hasattr(data, '__iter__'),
445             not isinstance(data, (basestring, list, tuple, collections.Mapping))
446         ])
447 
448         try:
449             length = super_len(data)
450         except (TypeError, AttributeError, UnsupportedOperation):
451             length = None
452 
453         if is_stream:
454             body = data
455 
456             if getattr(body, 'tell', None) is not None:
457                 # Record the current file position before reading.
458                 # This will allow us to rewind a file in the event
459                 # of a redirect.
460                 try:
461                     self._body_position = body.tell()
462                 except (IOError, OSError):
463                     # This differentiates from None, allowing us to catch
464                     # a failed `tell()` later when trying to rewind the body
465                     self._body_position = object()
466 
467             if files:
468                 raise NotImplementedError('Streamed bodies and files are mutually exclusive.')
469 
470             if length:
471                 self.headers['Content-Length'] = builtin_str(length)
472             else:
473                 self.headers['Transfer-Encoding'] = 'chunked'
474         else:
475             # Multi-part file uploads.
476             if files:
477                 (body, content_type) = self._encode_files(files, data)
478             else:
479                 if data:
480                     body = self._encode_params(data)
481                     if isinstance(data, basestring) or hasattr(data, 'read'):
482                         content_type = None
483                     else:
484                         content_type = 'application/x-www-form-urlencoded'
485 
486             self.prepare_content_length(body)
487 
488             # Add content-type if it wasn't explicitly provided.
489             if content_type and ('content-type' not in self.headers):
490                 self.headers['Content-Type'] = content_type
491 
492         self.body = body
493 
494     def prepare_content_length(self, body):
495         """Prepare Content-Length header based on request method and body"""
496         if body is not None:
497             length = super_len(body)
498             if length:
499                 # If length exists, set it. Otherwise, we fallback
500                 # to Transfer-Encoding: chunked.
501                 self.headers['Content-Length'] = builtin_str(length)
502         elif self.method not in ('GET', 'HEAD') and self.headers.get('Content-Length') is None:
503             # Set Content-Length to 0 for methods that can have a body
504             # but don't provide one. (i.e. not GET or HEAD)
505             self.headers['Content-Length'] = '0'
506 
507     def prepare_auth(self, auth, url=''):
508         """Prepares the given HTTP auth data."""
509 
510         # If no Auth is explicitly provided, extract it from the URL first.
511         if auth is None:
512             url_auth = get_auth_from_url(self.url)
513             auth = url_auth if any(url_auth) else None
514 
515         if auth:
516             if isinstance(auth, tuple) and len(auth) == 2:
517                 # special-case basic HTTP auth
518                 auth = HTTPBasicAuth(*auth)
519 
520             # Allow auth to make its changes.
521             r = auth(self)
522 
523             # Update self to reflect the auth changes.
524             self.__dict__.update(r.__dict__)
525 
526             # Recompute Content-Length
527             self.prepare_content_length(self.body)
528 
529     def prepare_cookies(self, cookies):
530         """Prepares the given HTTP cookie data.
531 
532         This function eventually generates a ``Cookie`` header from the
533         given cookies using cookielib. Due to cookielib's design, the header
534         will not be regenerated if it already exists, meaning this function
535         can only be called once for the life of the
536         :class:`PreparedRequest <PreparedRequest>` object. Any subsequent calls
537         to ``prepare_cookies`` will have no actual effect, unless the "Cookie"
538         header is removed beforehand.
539         """
540         if isinstance(cookies, cookielib.CookieJar):
541             self._cookies = cookies
542         else:
543             self._cookies = cookiejar_from_dict(cookies)
544 
545         cookie_header = get_cookie_header(self._cookies, self)
546         if cookie_header is not None:
547             self.headers['Cookie'] = cookie_header
548 
549     def prepare_hooks(self, hooks):
550         """Prepares the given hooks."""
551         # hooks can be passed as None to the prepare method and to this
552         # method. To prevent iterating over None, simply use an empty list
553         # if hooks is False-y
554         hooks = hooks or []
555         for event in hooks:
556             self.register_hook(event, hooks[event])
557 
558 
559 class Response(object):
560     """The :class:`Response <Response>` object, which contains a
561     server's response to an HTTP request.
562     """
563 
564     __attrs__ = [
565         '_content', 'status_code', 'headers', 'url', 'history',
566         'encoding', 'reason', 'cookies', 'elapsed', 'request'
567     ]
568 
569     def __init__(self):
570         super(Response, self).__init__()
571 
572         self._content = False
573         self._content_consumed = False
574 
575         #: Integer Code of responded HTTP Status, e.g. 404 or 200.
576         self.status_code = None
577 
578         #: Case-insensitive Dictionary of Response Headers.
579         #: For example, ``headers['content-encoding']`` will return the
580         #: value of a ``'Content-Encoding'`` response header.
581         self.headers = CaseInsensitiveDict()
582 
583         #: File-like object representation of response (for advanced usage).
584         #: Use of ``raw`` requires that ``stream=True`` be set on the request.
585         # This requirement does not apply for use internally to Requests.
586         self.raw = None
587 
588         #: Final URL location of Response.
589         self.url = None
590 
591         #: Encoding to decode with when accessing r.text.
592         self.encoding = None
593 
594         #: A list of :class:`Response <Response>` objects from
595         #: the history of the Request. Any redirect responses will end
596         #: up here. The list is sorted from the oldest to the most recent request.
597         self.history = []
598 
599         #: Textual reason of responded HTTP Status, e.g. "Not Found" or "OK".
600         self.reason = None
601 
602         #: A CookieJar of Cookies the server sent back.
603         self.cookies = cookiejar_from_dict({})
604 
605         #: The amount of time elapsed between sending the request
606         #: and the arrival of the response (as a timedelta).
607         #: This property specifically measures the time taken between sending
608         #: the first byte of the request and finishing parsing the headers. It
609         #: is therefore unaffected by consuming the response content or the
610         #: value of the ``stream`` keyword argument.
611         self.elapsed = datetime.timedelta(0)
612 
613         #: The :class:`PreparedRequest <PreparedRequest>` object to which this
614         #: is a response.
615         self.request = None
616 
617     def __getstate__(self):
618         # Consume everything; accessing the content attribute makes
619         # sure the content has been fully read.
620         if not self._content_consumed:
621             self.content
622 
623         return dict(
624             (attr, getattr(self, attr, None))
625             for attr in self.__attrs__
626         )
627 
628     def __setstate__(self, state):
629         for name, value in state.items():
630             setattr(self, name, value)
631 
632         # pickled objects do not have .raw
633         setattr(self, '_content_consumed', True)
634         setattr(self, 'raw', None)
635 
636     def __repr__(self):
637         return '<Response [%s]>' % (self.status_code)
638 
639     def __bool__(self):
640         """Returns true if :attr:`status_code` is 'OK'."""
641         return self.ok
642 
643     def __nonzero__(self):
644         """Returns true if :attr:`status_code` is 'OK'."""
645         return self.ok
646 
647     def __iter__(self):
648         """Allows you to use a response as an iterator."""
649         return self.iter_content(128)
650 
651     @property
652     def ok(self):
653         try:
654             self.raise_for_status()
655         except HTTPError:
656             return False
657         return True
658 
659     @property
660     def is_redirect(self):
661         """True if this Response is a well-formed HTTP redirect that could have
662         been processed automatically (by :meth:`Session.resolve_redirects`).
663         """
664         return ('location' in self.headers and self.status_code in REDIRECT_STATI)
665 
666     @property
667     def is_permanent_redirect(self):
668         """True if this Response one of the permanent versions of redirect"""
669         return ('location' in self.headers and self.status_code in (codes.moved_permanently, codes.permanent_redirect))
670 
671     @property
672     def apparent_encoding(self):
673         """The apparent encoding, provided by the chardet library"""
674         return chardet.detect(self.content)['encoding']
675 
676     def iter_content(self, chunk_size=1, decode_unicode=False):
677         """Iterates over the response data.  When stream=True is set on the
678         request, this avoids reading the content at once into memory for
679         large responses.  The chunk size is the number of bytes it should
680         read into memory.  This is not necessarily the length of each item
681         returned as decoding can take place.
682 
683         chunk_size must be of type int or None. A value of None will
684         function differently depending on the value of `stream`.
685         stream=True will read data as it arrives in whatever size the
686         chunks are received. If stream=False, data is returned as
687         a single chunk.
688 
689         If decode_unicode is True, content will be decoded using the best
690         available encoding based on the response.
691         """
692 
693         def generate():
694             # Special case for urllib3.
695             if hasattr(self.raw, 'stream'):
696                 try:
697                     for chunk in self.raw.stream(chunk_size, decode_content=True):
698                         yield chunk
699                 except ProtocolError as e:
700                     raise ChunkedEncodingError(e)
701                 except DecodeError as e:
702                     raise ContentDecodingError(e)
703                 except ReadTimeoutError as e:
704                     raise ConnectionError(e)
705             else:
706                 # Standard file-like object.
707                 while True:
708                     chunk = self.raw.read(chunk_size)
709                     if not chunk:
710                         break
711                     yield chunk
712 
713             self._content_consumed = True
714 
715         if self._content_consumed and isinstance(self._content, bool):
716             raise StreamConsumedError()
717         elif chunk_size is not None and not isinstance(chunk_size, int):
718             raise TypeError("chunk_size must be an int, it is instead a %s." % type(chunk_size))
719         # simulate reading small chunks of the content
720         reused_chunks = iter_slices(self._content, chunk_size)
721 
722         stream_chunks = generate()
723 
724         chunks = reused_chunks if self._content_consumed else stream_chunks
725 
726         if decode_unicode:
727             chunks = stream_decode_response_unicode(chunks, self)
728 
729         return chunks
730 
731     def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=None, delimiter=None):
732         """Iterates over the response data, one line at a time.  When
733         stream=True is set on the request, this avoids reading the
734         content at once into memory for large responses.
735 
736         .. note:: This method is not reentrant safe.
737         """
738 
739         pending = None
740 
741         for chunk in self.iter_content(chunk_size=chunk_size, decode_unicode=decode_unicode):
742 
743             if pending is not None:
744                 chunk = pending + chunk
745 
746             if delimiter:
747                 lines = chunk.split(delimiter)
748             else:
749                 lines = chunk.splitlines()
750 
751             if lines and lines[-1] and chunk and lines[-1][-1] == chunk[-1]:
752                 pending = lines.pop()
753             else:
754                 pending = None
755 
756             for line in lines:
757                 yield line
758 
759         if pending is not None:
760             yield pending
761 
762     @property
763     def content(self):
764         """Content of the response, in bytes."""
765 
766         if self._content is False:
767             # Read the contents.
768             if self._content_consumed:
769                 raise RuntimeError(
770                     'The content for this response was already consumed')
771 
772             if self.status_code == 0:
773                 self._content = None
774             else:
775                 self._content = bytes().join(self.iter_content(CONTENT_CHUNK_SIZE)) or bytes()
776 
777         self._content_consumed = True
778         # don't need to release the connection; that's been handled by urllib3
779         # since we exhausted the data.
780         return self._content
781 
782     @property
783     def text(self):
784         """Content of the response, in unicode.
785 
786         If Response.encoding is None, encoding will be guessed using
787         ``chardet``.
788 
789         The encoding of the response content is determined based solely on HTTP
790         headers, following RFC 2616 to the letter. If you can take advantage of
791         non-HTTP knowledge to make a better guess at the encoding, you should
792         set ``r.encoding`` appropriately before accessing this property.
793         """
794 
795         # Try charset from content-type
796         content = None
797         encoding = self.encoding
798 
799         if not self.content:
800             return str('')
801 
802         # Fallback to auto-detected encoding.
803         if self.encoding is None:
804             encoding = self.apparent_encoding
805 
806         # Decode unicode from given encoding.
807         try:
808             content = str(self.content, encoding, errors='replace')
809         except (LookupError, TypeError):
810             # A LookupError is raised if the encoding was not found which could
811             # indicate a misspelling or similar mistake.
812             #
813             # A TypeError can be raised if encoding is None
814             #
815             # So we try blindly encoding.
816             content = str(self.content, errors='replace')
817 
818         return content
819 
820     def json(self, **kwargs):
821         """Returns the json-encoded content of a response, if any.
822 
823         :param \*\*kwargs: Optional arguments that ``json.loads`` takes.
824         :raises ValueError: If the response body does not contain valid json.
825         """
826 
827         if not self.encoding and self.content and len(self.content) > 3:
828             # No encoding set. JSON RFC 4627 section 3 states we should expect
829             # UTF-8, -16 or -32. Detect which one to use; If the detection or
830             # decoding fails, fall back to `self.text` (using chardet to make
831             # a best guess).
832             encoding = guess_json_utf(self.content)
833             if encoding is not None:
834                 try:
835                     return complexjson.loads(
836                         self.content.decode(encoding), **kwargs
837                     )
838                 except UnicodeDecodeError:
839                     # Wrong UTF codec detected; usually because it's not UTF-8
840                     # but some other 8-bit codec.  This is an RFC violation,
841                     # and the server didn't bother to tell us what codec *was*
842                     # used.
843                     pass
844         return complexjson.loads(self.text, **kwargs)
845 
846     @property
847     def links(self):
848         """Returns the parsed header links of the response, if any."""
849 
850         header = self.headers.get('link')
851 
852         # l = MultiDict()
853         l = {}
854 
855         if header:
856             links = parse_header_links(header)
857 
858             for link in links:
859                 key = link.get('rel') or link.get('url')
860                 l[key] = link
861 
862         return l
863 
864     def raise_for_status(self):
865         """Raises stored :class:`HTTPError`, if one occurred."""
866 
867         http_error_msg = ''
868         if isinstance(self.reason, bytes):
869             # We attempt to decode utf-8 first because some servers
870             # choose to localize their reason strings. If the string
871             # isn't utf-8, we fall back to iso-8859-1 for all other
872             # encodings. (See PR #3538)
873             try:
874                 reason = self.reason.decode('utf-8')
875             except UnicodeDecodeError:
876                 reason = self.reason.decode('iso-8859-1')
877         else:
878             reason = self.reason
879 
880         if 400 <= self.status_code < 500:
881             http_error_msg = u'%s Client Error: %s for url: %s' % (self.status_code, reason, self.url)
882 
883         elif 500 <= self.status_code < 600:
884             http_error_msg = u'%s Server Error: %s for url: %s' % (self.status_code, reason, self.url)
885 
886         if http_error_msg:
887             raise HTTPError(http_error_msg, response=self)
888 
889     def close(self):
890         """Releases the connection back to the pool. Once this method has been
891         called the underlying ``raw`` object must not be accessed again.
892 
893         *Note: Should not normally need to be called explicitly.*
894         """
895         if not self._content_consumed:
896             self.raw.close()
897 
898         release_conn = getattr(self.raw, 'release_conn', None)
899         if release_conn is not None:
900             release_conn()

</code><intended_behavior>Ensure Non-`None` Response Before Access: Add explicit checks around the `requests` call to confirm the presence of a valid response.</intended_behavior>, <file>requests/adapters.py</file>
<class>None</class>
<method>None</method>
<code>
1 # -*- coding: utf-8 -*-
2 
3 """
4 requests.adapters
5 ~~~~~~~~~~~~~~~~~
6 
7 This module contains the transport adapters that Requests uses to define
8 and maintain connections.
9 """
10 
11 import os.path
12 import socket
13 
14 from .models import Response
15 from .packages.urllib3.poolmanager import PoolManager, proxy_from_url
16 from .packages.urllib3.response import HTTPResponse
17 from .packages.urllib3.util import Timeout as TimeoutSauce
18 from .packages.urllib3.util.retry import Retry
19 from .compat import urlparse, basestring
20 from .utils import (DEFAULT_CA_BUNDLE_PATH, get_encoding_from_headers,
21                     prepend_scheme_if_needed, get_auth_from_url, urldefragauth,
22                     select_proxy, to_native_string)
23 from .structures import CaseInsensitiveDict
24 from .packages.urllib3.exceptions import ClosedPoolError
25 from .packages.urllib3.exceptions import ConnectTimeoutError
26 from .packages.urllib3.exceptions import HTTPError as _HTTPError
27 from .packages.urllib3.exceptions import MaxRetryError
28 from .packages.urllib3.exceptions import NewConnectionError
29 from .packages.urllib3.exceptions import ProxyError as _ProxyError
30 from .packages.urllib3.exceptions import ProtocolError
31 from .packages.urllib3.exceptions import ReadTimeoutError
32 from .packages.urllib3.exceptions import SSLError as _SSLError
33 from .packages.urllib3.exceptions import ResponseError
34 from .cookies import extract_cookies_to_jar
35 from .exceptions import (ConnectionError, ConnectTimeout, ReadTimeout, SSLError,
36                          ProxyError, RetryError, InvalidSchema)
37 from .auth import _basic_auth_str
38 
39 try:
40     from .packages.urllib3.contrib.socks import SOCKSProxyManager
41 except ImportError:
42     def SOCKSProxyManager(*args, **kwargs):
43         raise InvalidSchema("Missing dependencies for SOCKS support.")
44 
45 DEFAULT_POOLBLOCK = False
46 DEFAULT_POOLSIZE = 10
47 DEFAULT_RETRIES = 0
48 DEFAULT_POOL_TIMEOUT = None
49 
50 
51 class BaseAdapter(object):
52     """The Base Transport Adapter"""
53 
54     def __init__(self):
55         super(BaseAdapter, self).__init__()
56 
57     def send(self, request, stream=False, timeout=None, verify=True,
58              cert=None, proxies=None):
59         """Sends PreparedRequest object. Returns Response object.
60 
61         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
62         :param stream: (optional) Whether to stream the request content.
63         :param timeout: (optional) How long to wait for the server to send
64             data before giving up, as a float, or a :ref:`(connect timeout,
65             read timeout) <timeouts>` tuple.
66         :type timeout: float or tuple
67         :param verify: (optional) Whether to verify SSL certificates.
68         :param cert: (optional) Any user-provided SSL certificate to be trusted.
69         :param proxies: (optional) The proxies dictionary to apply to the request.
70         """
71         raise NotImplementedError
72 
73     def close(self):
74         """Cleans up adapter specific items."""
75         raise NotImplementedError
76 
77 
78 class HTTPAdapter(BaseAdapter):
79     """The built-in HTTP Adapter for urllib3.
80 
81     Provides a general-case interface for Requests sessions to contact HTTP and
82     HTTPS urls by implementing the Transport Adapter interface. This class will
83     usually be created by the :class:`Session <Session>` class under the
84     covers.
85 
86     :param pool_connections: The number of urllib3 connection pools to cache.
87     :param pool_maxsize: The maximum number of connections to save in the pool.
88     :param max_retries: The maximum number of retries each connection
89         should attempt. Note, this applies only to failed DNS lookups, socket
90         connections and connection timeouts, never to requests where data has
91         made it to the server. By default, Requests does not retry failed
92         connections. If you need granular control over the conditions under
93         which we retry a request, import urllib3's ``Retry`` class and pass
94         that instead.
95     :param pool_block: Whether the connection pool should block for connections.
96 
97     Usage::
98 
99       >>> import requests
100       >>> s = requests.Session()
101       >>> a = requests.adapters.HTTPAdapter(max_retries=3)
102       >>> s.mount('http://', a)
103     """
104     __attrs__ = ['max_retries', 'config', '_pool_connections', '_pool_maxsize',
105                  '_pool_block']
106 
107     def __init__(self, pool_connections=DEFAULT_POOLSIZE,
108                  pool_maxsize=DEFAULT_POOLSIZE, max_retries=DEFAULT_RETRIES,
109                  pool_block=DEFAULT_POOLBLOCK):
110         if max_retries == DEFAULT_RETRIES:
111             self.max_retries = Retry(0, read=False)
112         else:
113             self.max_retries = Retry.from_int(max_retries)
114         self.config = {}
115         self.proxy_manager = {}
116 
117         super(HTTPAdapter, self).__init__()
118 
119         self._pool_connections = pool_connections
120         self._pool_maxsize = pool_maxsize
121         self._pool_block = pool_block
122 
123         self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)
124 
125     def __getstate__(self):
126         return dict((attr, getattr(self, attr, None)) for attr in
127                     self.__attrs__)
128 
129     def __setstate__(self, state):
130         # Can't handle by adding 'proxy_manager' to self.__attrs__ because
131         # self.poolmanager uses a lambda function, which isn't pickleable.
132         self.proxy_manager = {}
133         self.config = {}
134 
135         for attr, value in state.items():
136             setattr(self, attr, value)
137 
138         self.init_poolmanager(self._pool_connections, self._pool_maxsize,
139                               block=self._pool_block)
140 
141     def init_poolmanager(self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs):
142         """Initializes a urllib3 PoolManager.
143 
144         This method should not be called from user code, and is only
145         exposed for use when subclassing the
146         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
147 
148         :param connections: The number of urllib3 connection pools to cache.
149         :param maxsize: The maximum number of connections to save in the pool.
150         :param block: Block when no free connections are available.
151         :param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.
152         """
153         # save these values for pickling
154         self._pool_connections = connections
155         self._pool_maxsize = maxsize
156         self._pool_block = block
157 
158         self.poolmanager = PoolManager(num_pools=connections, maxsize=maxsize,
159                                        block=block, strict=True, **pool_kwargs)
160 
161     def proxy_manager_for(self, proxy, **proxy_kwargs):
162         """Return urllib3 ProxyManager for the given proxy.
163 
164         This method should not be called from user code, and is only
165         exposed for use when subclassing the
166         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
167 
168         :param proxy: The proxy to return a urllib3 ProxyManager for.
169         :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.
170         :returns: ProxyManager
171         :rtype: requests.packages.urllib3.ProxyManager
172         """
173         if proxy in self.proxy_manager:
174             manager = self.proxy_manager[proxy]
175         elif proxy.lower().startswith('socks'):
176             username, password = get_auth_from_url(proxy)
177             manager = self.proxy_manager[proxy] = SOCKSProxyManager(
178                 proxy,
179                 username=username,
180                 password=password,
181                 num_pools=self._pool_connections,
182                 maxsize=self._pool_maxsize,
183                 block=self._pool_block,
184                 **proxy_kwargs
185             )
186         else:
187             proxy_headers = self.proxy_headers(proxy)
188             manager = self.proxy_manager[proxy] = proxy_from_url(
189                 proxy,
190                 proxy_headers=proxy_headers,
191                 num_pools=self._pool_connections,
192                 maxsize=self._pool_maxsize,
193                 block=self._pool_block,
194                 **proxy_kwargs)
195 
196         return manager
197 
198     def cert_verify(self, conn, url, verify, cert):
199         """Verify a SSL certificate. This method should not be called from user
200         code, and is only exposed for use when subclassing the
201         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
202 
203         :param conn: The urllib3 connection object associated with the cert.
204         :param url: The requested URL.
205         :param verify: Whether we should actually verify the certificate.
206         :param cert: The SSL certificate to verify.
207         """
208         if url.lower().startswith('https') and verify:
209 
210             cert_loc = None
211 
212             # Allow self-specified cert location.
213             if verify is not True:
214                 cert_loc = verify
215 
216             if not cert_loc:
217                 cert_loc = DEFAULT_CA_BUNDLE_PATH
218 
219             if not cert_loc:
220                 raise Exception("Could not find a suitable SSL CA certificate bundle.")
221 
222             conn.cert_reqs = 'CERT_REQUIRED'
223 
224             if not os.path.isdir(cert_loc):
225                 conn.ca_certs = cert_loc
226             else:
227                 conn.ca_cert_dir = cert_loc
228         else:
229             conn.cert_reqs = 'CERT_NONE'
230             conn.ca_certs = None
231             conn.ca_cert_dir = None
232 
233         if cert:
234             if not isinstance(cert, basestring):
235                 conn.cert_file = cert[0]
236                 conn.key_file = cert[1]
237             else:
238                 conn.cert_file = cert
239 
240     def build_response(self, req, resp):
241         """Builds a :class:`Response <requests.Response>` object from a urllib3
242         response. This should not be called from user code, and is only exposed
243         for use when subclassing the
244         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`
245 
246         :param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.
247         :param resp: The urllib3 response object.
248         :rtype: requests.Response
249         """
250         response = Response()
251 
252         # Fallback to None if there's no status_code, for whatever reason.
253         response.status_code = getattr(resp, 'status', None)
254 
255         # Make headers case-insensitive.
256         response.headers = CaseInsensitiveDict(getattr(resp, 'headers', {}))
257 
258         # Set encoding.
259         response.encoding = get_encoding_from_headers(response.headers)
260         response.raw = resp
261         response.reason = response.raw.reason
262 
263         if isinstance(req.url, bytes):
264             response.url = req.url.decode('utf-8')
265         else:
266             response.url = req.url
267 
268         # Add new cookies from the server.
269         extract_cookies_to_jar(response.cookies, req, resp)
270 
271         # Give the Response some context.
272         response.request = req
273         response.connection = self
274 
275         return response
276 
277     def get_connection(self, url, proxies=None):
278         """Returns a urllib3 connection for the given URL. This should not be
279         called from user code, and is only exposed for use when subclassing the
280         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
281 
282         :param url: The URL to connect to.
283         :param proxies: (optional) A Requests-style dictionary of proxies used on this request.
284         :rtype: requests.packages.urllib3.ConnectionPool
285         """
286         proxy = select_proxy(url, proxies)
287 
288         if proxy:
289             proxy = prepend_scheme_if_needed(proxy, 'http')
290             proxy_manager = self.proxy_manager_for(proxy)
291             conn = proxy_manager.connection_from_url(url)
292         else:
293             # Only scheme should be lower case
294             parsed = urlparse(url)
295             url = parsed.geturl()
296             conn = self.poolmanager.connection_from_url(url)
297 
298         return conn
299 
300     def close(self):
301         """Disposes of any internal state.
302 
303         Currently, this closes the PoolManager and any active ProxyManager,
304         which closes any pooled connections.
305         """
306         self.poolmanager.clear()
307         for proxy in self.proxy_manager.values():
308             proxy.clear()
309 
310     def request_url(self, request, proxies):
311         """Obtain the url to use when making the final request.
312 
313         If the message is being sent through a HTTP proxy, the full URL has to
314         be used. Otherwise, we should only use the path portion of the URL.
315 
316         This should not be called from user code, and is only exposed for use
317         when subclassing the
318         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
319 
320         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
321         :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.
322         :rtype: str
323         """
324         proxy = select_proxy(request.url, proxies)
325         scheme = urlparse(request.url).scheme
326 
327         is_proxied_http_request = (proxy and scheme != 'https')
328         using_socks_proxy = False
329         if proxy:
330             proxy_scheme = urlparse(proxy).scheme.lower()
331             using_socks_proxy = proxy_scheme.startswith('socks')
332 
333         url = request.path_url
334         if is_proxied_http_request and not using_socks_proxy:
335             url = urldefragauth(request.url)
336 
337         return url
338 
339     def add_headers(self, request, **kwargs):
340         """Add any headers needed by the connection. As of v2.0 this does
341         nothing by default, but is left for overriding by users that subclass
342         the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
343 
344         This should not be called from user code, and is only exposed for use
345         when subclassing the
346         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
347 
348         :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.
349         :param kwargs: The keyword arguments from the call to send().
350         """
351         pass
352 
353     def proxy_headers(self, proxy):
354         """Returns a dictionary of the headers to add to any request sent
355         through a proxy. This works with urllib3 magic to ensure that they are
356         correctly sent to the proxy, rather than in a tunnelled request if
357         CONNECT is being used.
358 
359         This should not be called from user code, and is only exposed for use
360         when subclassing the
361         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
362 
363         :param proxies: The url of the proxy being used for this request.
364         :rtype: dict
365         """
366         headers = {}
367         username, password = get_auth_from_url(proxy)
368 
369         if username:
370             headers['Proxy-Authorization'] = _basic_auth_str(username,
371                                                              password)
372 
373         return headers
374 
375     def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
376         """Sends PreparedRequest object. Returns Response object.
377 
378         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
379         :param stream: (optional) Whether to stream the request content.
380         :param timeout: (optional) How long to wait for the server to send
381             data before giving up, as a float, or a :ref:`(connect timeout,
382             read timeout) <timeouts>` tuple.
383         :type timeout: float or tuple
384         :param verify: (optional) Whether to verify SSL certificates.
385         :param cert: (optional) Any user-provided SSL certificate to be trusted.
386         :param proxies: (optional) The proxies dictionary to apply to the request.
387         :rtype: requests.Response
388         """
389 
390         conn = self.get_connection(request.url, proxies)
391 
392         self.cert_verify(conn, request.url, verify, cert)
393         url = self.request_url(request, proxies)
394         self.add_headers(request)
395 
396         chunked = not (request.body is None or 'Content-Length' in request.headers)
397 
398         if isinstance(timeout, tuple):
399             try:
400                 connect, read = timeout
401                 timeout = TimeoutSauce(connect=connect, read=read)
402             except ValueError as e:
403                 # this may raise a string formatting error.
404                 err = ("Invalid timeout {0}. Pass a (connect, read) "
405                        "timeout tuple, or a single float to set "
406                        "both timeouts to the same value".format(timeout))
407                 raise ValueError(err)
408         else:
409             timeout = TimeoutSauce(connect=timeout, read=timeout)
410 
411         try:
412             if not chunked:
413                 resp = conn.urlopen(
414                     method=request.method,
415                     url=url,
416                     body=request.body,
417                     headers=request.headers,
418                     redirect=False,
419                     assert_same_host=False,
420                     preload_content=False,
421                     decode_content=False,
422                     retries=self.max_retries,
423                     timeout=timeout
424                 )
425 
426             # Send the request.
427             else:
428                 if hasattr(conn, 'proxy_pool'):
429                     conn = conn.proxy_pool
430 
431                 low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)
432 
433                 try:
434                     low_conn.putrequest(request.method,
435                                         url,
436                                         skip_accept_encoding=True)
437 
438                     for header, value in request.headers.items():
439                         low_conn.putheader(header, value)
440 
441                     low_conn.endheaders()
442 
443                     for i in request.body:
444                         low_conn.send(hex(len(i))[2:].encode('utf-8'))
445                         low_conn.send(b'\r\n')
446                         low_conn.send(i)
447                         low_conn.send(b'\r\n')
448                     low_conn.send(b'0\r\n\r\n')
449 
450                     # Receive the response from the server
451                     try:
452                         # For Python 2.7+ versions, use buffering of HTTP
453                         # responses
454                         r = low_conn.getresponse(buffering=True)
455                     except TypeError:
456                         # For compatibility with Python 2.6 versions and back
457                         r = low_conn.getresponse()
458 
459                     resp = HTTPResponse.from_httplib(
460                         r,
461                         pool=conn,
462                         connection=low_conn,
463                         preload_content=False,
464                         decode_content=False
465                     )
466                 except:
467                     # If we hit any problems here, clean up the connection.
468                     # Then, reraise so that we can handle the actual exception.
469                     low_conn.close()
470                     raise
471 
472         except (ProtocolError, socket.error) as err:
473             raise ConnectionError(err, request=request)
474 
475         except MaxRetryError as e:
476             if isinstance(e.reason, ConnectTimeoutError):
477                 # TODO: Remove this in 3.0.0: see #2811
478                 if not isinstance(e.reason, NewConnectionError):
479                     raise ConnectTimeout(e, request=request)
480 
481             if isinstance(e.reason, ResponseError):
482                 raise RetryError(e, request=request)
483 
484             if isinstance(e.reason, _ProxyError):
485                 raise ProxyError(e, request=request)
486 
487             raise ConnectionError(e, request=request)
488 
489         except ClosedPoolError as e:
490             raise ConnectionError(e, request=request)
491 
492         except _ProxyError as e:
493             raise ProxyError(e)
494 
495         except (_SSLError, _HTTPError) as e:
496             if isinstance(e, _SSLError):
497                 raise SSLError(e, request=request)
498             elif isinstance(e, ReadTimeoutError):
499                 raise ReadTimeout(e, request=request)
500             else:
501                 raise
502 
503         return self.build_response(request, resp)

</code><intended_behavior>Ensure Non-`None` Response Before Access: Add explicit checks around the `requests` call to confirm the presence of a valid response.</intended_behavior>, <file>requests/api.py</file>
<class>None</class>
<method>head</method>
<code>
86 def head(url, **kwargs):
87     """Sends a HEAD request.
88 
89     :param url: URL for the new :class:`Request` object.
90     :param \*\*kwargs: Optional arguments that ``request`` takes.
91     :return: :class:`Response <Response>` object
92     :rtype: requests.Response
93     """
94 
95     kwargs.setdefault('allow_redirects', False)
96     return request('head', url, **kwargs)

</code><intended_behavior>Robust Exception Handling for `requests` Calls: Enhance error handling around `requests` library calls to catch exceptions such as `requests.exceptions.RequestException`.</intended_behavior>, <file>requests/sessions.py</file>
<class>None</class>
<method>head</method>
<code>
514     def head(self, url, **kwargs):
515         """Sends a HEAD request. Returns :class:`Response` object.
516 
517         :param url: URL for the new :class:`Request` object.
518         :param \*\*kwargs: Optional arguments that ``request`` takes.
519         :rtype: requests.Response
520         """
521 
522         kwargs.setdefault('allow_redirects', False)
523         return self.request('HEAD', url, **kwargs)

</code><intended_behavior>Robust Exception Handling for `requests` Calls: Enhance error handling around `requests` library calls to catch exceptions such as `requests.exceptions.RequestException`.</intended_behavior>, <file>requests/sessions.py</file>
<class>Session</class>
<method>head</method>
<code>
514     def head(self, url, **kwargs):
515         """Sends a HEAD request. Returns :class:`Response` object.
516 
517         :param url: URL for the new :class:`Request` object.
518         :param \*\*kwargs: Optional arguments that ``request`` takes.
519         :rtype: requests.Response
520         """
521 
522         kwargs.setdefault('allow_redirects', False)
523         return self.request('HEAD', url, **kwargs)

</code><intended_behavior>Robust Exception Handling for `requests` Calls: Enhance error handling around `requests` library calls to catch exceptions such as `requests.exceptions.RequestException`.</intended_behavior>]
2025-10-17 15:21:49.952 | INFO     | Overall retry 0 succeeded; ending workflow
2025-10-17 15:21:49.952 | INFO     | Search-only: skipping patch selection
2025-10-17 15:21:50.015 | INFO     | Task psf__requests-3718 completed successfully.
2025-10-17 15:21:50.016 | INFO     | No patch generated. You can try running ACR again.
