[
    {
        "rel_file_path": "requests/sessions.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/psf__requests/setup_psf__requests__3.0/requests/sessions.py",
        "start": 89,
        "end": 205,
        "class_name": null,
        "method_name": "resolve_redirects",
        "code": "89     def resolve_redirects(self, response, stream=False, timeout=None,\n90                           verify=True, cert=None, proxies=None, **adapter_kwargs):\n91         \"\"\"Given a Response, yields Responses until 'Location' header-based\n92         redirection ceases, or the Session.max_redirects limit has been\n93         reached.\n94         \"\"\"\n95 \n96         redirect_count = 0\n97         history = [] # keep track of history\n98         request = response.request\n99 \n100         while response.is_redirect:\n101             prepared_request = request.copy()\n102 \n103             if redirect_count > 0:\n104 \n105                 # Store this Response in local history.\n106                 history.append(response)\n107 \n108                 # Copy local history to Response.history.\n109                 response.history = list(history)\n110 \n111             try:\n112                 response.content  # Consume socket so it can be released\n113             except (ChunkedEncodingError, ContentDecodingError, RuntimeError):\n114                 response.raw.read(decode_content=False)\n115 \n116             # Don't exceed configured Session.max_redirects.\n117             if redirect_count >= self.max_redirects:\n118                 raise TooManyRedirects('Exceeded %s redirects.' % self.max_redirects, response=response)\n119 \n120             # Release the connection back into the pool.\n121             response.close()\n122 \n123             location_url = response.headers['location']\n124             method = request.method\n125 \n126             # Handle redirection without scheme (see: RFC 1808 Section 4)\n127             if location_url.startswith('//'):\n128                 parsed_rurl = urlparse(response.url)\n129                 location_url = '%s:%s' % (parsed_rurl.scheme, location_url)\n130 \n131             # The scheme should be lower case...\n132             parsed = urlparse(location_url)\n133             location_url = parsed.geturl()\n134 \n135             # Facilitate relative 'location' headers, as allowed by RFC 7231.\n136             # (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')\n137             # Compliant with RFC3986, we percent encode the url.\n138             if not parsed.netloc:\n139                 location_url = urljoin(response.url, requote_uri(location_url))\n140             else:\n141                 location_url = requote_uri(location_url)\n142 \n143             prepared_request.url = to_native_string(location_url)\n144             # Cache the url, unless it redirects to itself.\n145             if response.is_permanent_redirect and request.url != prepared_request.url:\n146                 self.redirect_cache[request.url] = prepared_request.url\n147 \n148             # http://tools.ietf.org/html/rfc7231#section-6.4.4\n149             if (response.status_code == codes.see_other and method != 'HEAD'):\n150                 method = 'GET'\n151 \n152             # Do what the browsers do, despite standards...\n153             # First, turn 302s into GETs.\n154             if response.status_code == codes.found and method != 'HEAD':\n155                 method = 'GET'\n156 \n157             # Second, if a POST is responded to with a 301, turn it into a GET.\n158             # This bizarre behaviour is explained in Issue 1704.\n159             if response.status_code == codes.moved and method == 'POST':\n160                 method = 'GET'\n161 \n162             prepared_request.method = method\n163 \n164             # https://github.com/kennethreitz/requests/issues/1084\n165             if response.status_code not in (codes.temporary_redirect, codes.permanent_redirect):\n166                 if 'Content-Length' in prepared_request.headers:\n167                     del prepared_request.headers['Content-Length']\n168 \n169                 prepared_request.body = None\n170 \n171             headers = prepared_request.headers\n172             try:\n173                 del headers['Cookie']\n174             except KeyError:\n175                 pass\n176 \n177             # Extract any cookies sent on the response to the cookiejar\n178             # in the new request. Because we've mutated our copied prepared\n179             # request, use the old one that we haven't yet touched.\n180             extract_cookies_to_jar(prepared_request._cookies, request, response.raw)\n181             prepared_request._cookies.update(self.cookies)\n182             prepared_request.prepare_cookies(prepared_request._cookies)\n183 \n184             # Rebuild auth and proxy information.\n185             proxies = self.rebuild_proxies(prepared_request, proxies)\n186             self.rebuild_auth(prepared_request, response)\n187 \n188             # Override the original request.\n189             request = prepared_request\n190 \n191             response = self.send(\n192                 request,\n193                 stream=stream,\n194                 timeout=timeout,\n195                 verify=verify,\n196                 cert=cert,\n197                 proxies=proxies,\n198                 allow_redirects=False,\n199                 **adapter_kwargs\n200             )\n201 \n202             extract_cookies_to_jar(self.cookies, prepared_request, response.raw)\n203 \n204             redirect_count += 1\n205             yield response\n",
        "intended_behavior": "The method(s) involved in handling redirects need to ensure the correct encoding and decoding of URLs, especially those containing non-ASCII characters. When receiving a redirect response, the method should accurately encode the URL to its proper form before following the redirect. This is crucial for handling internationalized domain names and URLs that contain characters outside the ASCII range. Additionally, this behavior should be consistent across different environments and not lead to errors like 404 Not Found when the redirected URL is valid. The enhancement should be made while ensuring that the original functionality for handling ASCII-based URLs remains unaffected and that redirects are followed according to the HTTP standards and requests library's policies (like max redirects)."
    },
    {
        "rel_file_path": "requests/sessions.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/psf__requests/setup_psf__requests__3.0/requests/sessions.py",
        "start": 89,
        "end": 205,
        "class_name": "SessionRedirectMixin",
        "method_name": "resolve_redirects",
        "code": "89     def resolve_redirects(self, response, stream=False, timeout=None,\n90                           verify=True, cert=None, proxies=None, **adapter_kwargs):\n91         \"\"\"Given a Response, yields Responses until 'Location' header-based\n92         redirection ceases, or the Session.max_redirects limit has been\n93         reached.\n94         \"\"\"\n95 \n96         redirect_count = 0\n97         history = [] # keep track of history\n98         request = response.request\n99 \n100         while response.is_redirect:\n101             prepared_request = request.copy()\n102 \n103             if redirect_count > 0:\n104 \n105                 # Store this Response in local history.\n106                 history.append(response)\n107 \n108                 # Copy local history to Response.history.\n109                 response.history = list(history)\n110 \n111             try:\n112                 response.content  # Consume socket so it can be released\n113             except (ChunkedEncodingError, ContentDecodingError, RuntimeError):\n114                 response.raw.read(decode_content=False)\n115 \n116             # Don't exceed configured Session.max_redirects.\n117             if redirect_count >= self.max_redirects:\n118                 raise TooManyRedirects('Exceeded %s redirects.' % self.max_redirects, response=response)\n119 \n120             # Release the connection back into the pool.\n121             response.close()\n122 \n123             location_url = response.headers['location']\n124             method = request.method\n125 \n126             # Handle redirection without scheme (see: RFC 1808 Section 4)\n127             if location_url.startswith('//'):\n128                 parsed_rurl = urlparse(response.url)\n129                 location_url = '%s:%s' % (parsed_rurl.scheme, location_url)\n130 \n131             # The scheme should be lower case...\n132             parsed = urlparse(location_url)\n133             location_url = parsed.geturl()\n134 \n135             # Facilitate relative 'location' headers, as allowed by RFC 7231.\n136             # (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')\n137             # Compliant with RFC3986, we percent encode the url.\n138             if not parsed.netloc:\n139                 location_url = urljoin(response.url, requote_uri(location_url))\n140             else:\n141                 location_url = requote_uri(location_url)\n142 \n143             prepared_request.url = to_native_string(location_url)\n144             # Cache the url, unless it redirects to itself.\n145             if response.is_permanent_redirect and request.url != prepared_request.url:\n146                 self.redirect_cache[request.url] = prepared_request.url\n147 \n148             # http://tools.ietf.org/html/rfc7231#section-6.4.4\n149             if (response.status_code == codes.see_other and method != 'HEAD'):\n150                 method = 'GET'\n151 \n152             # Do what the browsers do, despite standards...\n153             # First, turn 302s into GETs.\n154             if response.status_code == codes.found and method != 'HEAD':\n155                 method = 'GET'\n156 \n157             # Second, if a POST is responded to with a 301, turn it into a GET.\n158             # This bizarre behaviour is explained in Issue 1704.\n159             if response.status_code == codes.moved and method == 'POST':\n160                 method = 'GET'\n161 \n162             prepared_request.method = method\n163 \n164             # https://github.com/kennethreitz/requests/issues/1084\n165             if response.status_code not in (codes.temporary_redirect, codes.permanent_redirect):\n166                 if 'Content-Length' in prepared_request.headers:\n167                     del prepared_request.headers['Content-Length']\n168 \n169                 prepared_request.body = None\n170 \n171             headers = prepared_request.headers\n172             try:\n173                 del headers['Cookie']\n174             except KeyError:\n175                 pass\n176 \n177             # Extract any cookies sent on the response to the cookiejar\n178             # in the new request. Because we've mutated our copied prepared\n179             # request, use the old one that we haven't yet touched.\n180             extract_cookies_to_jar(prepared_request._cookies, request, response.raw)\n181             prepared_request._cookies.update(self.cookies)\n182             prepared_request.prepare_cookies(prepared_request._cookies)\n183 \n184             # Rebuild auth and proxy information.\n185             proxies = self.rebuild_proxies(prepared_request, proxies)\n186             self.rebuild_auth(prepared_request, response)\n187 \n188             # Override the original request.\n189             request = prepared_request\n190 \n191             response = self.send(\n192                 request,\n193                 stream=stream,\n194                 timeout=timeout,\n195                 verify=verify,\n196                 cert=cert,\n197                 proxies=proxies,\n198                 allow_redirects=False,\n199                 **adapter_kwargs\n200             )\n201 \n202             extract_cookies_to_jar(self.cookies, prepared_request, response.raw)\n203 \n204             redirect_count += 1\n205             yield response\n",
        "intended_behavior": "The method(s) involved in handling redirects need to ensure the correct encoding and decoding of URLs, especially those containing non-ASCII characters. When receiving a redirect response, the method should accurately encode the URL to its proper form before following the redirect. This is crucial for handling internationalized domain names and URLs that contain characters outside the ASCII range. Additionally, this behavior should be consistent across different environments and not lead to errors like 404 Not Found when the redirected URL is valid. The enhancement should be made while ensuring that the original functionality for handling ASCII-based URLs remains unaffected and that redirects are followed according to the HTTP standards and requests library's policies (like max redirects)."
    },
    {
        "rel_file_path": "requests/adapters.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/psf__requests/setup_psf__requests__3.0/requests/adapters.py",
        "start": 1,
        "end": 456,
        "class_name": null,
        "method_name": null,
        "code": "1 # -*- coding: utf-8 -*-\n2 \n3 \"\"\"\n4 requests.adapters\n5 ~~~~~~~~~~~~~~~~~\n6 \n7 This module contains the transport adapters that Requests uses to define\n8 and maintain connections.\n9 \"\"\"\n10 \n11 import os.path\n12 import socket\n13 \n14 from .models import Response\n15 from .packages.urllib3.poolmanager import PoolManager, proxy_from_url\n16 from .packages.urllib3.response import HTTPResponse\n17 from .packages.urllib3.util import Timeout as TimeoutSauce\n18 from .packages.urllib3.util.retry import Retry\n19 from .compat import urlparse, basestring\n20 from .utils import (DEFAULT_CA_BUNDLE_PATH, get_encoding_from_headers,\n21                     prepend_scheme_if_needed, get_auth_from_url, urldefragauth,\n22                     select_proxy)\n23 from .structures import CaseInsensitiveDict\n24 from .packages.urllib3.exceptions import ClosedPoolError\n25 from .packages.urllib3.exceptions import ConnectTimeoutError\n26 from .packages.urllib3.exceptions import HTTPError as _HTTPError\n27 from .packages.urllib3.exceptions import MaxRetryError\n28 from .packages.urllib3.exceptions import NewConnectionError\n29 from .packages.urllib3.exceptions import ProxyError as _ProxyError\n30 from .packages.urllib3.exceptions import ProtocolError\n31 from .packages.urllib3.exceptions import ReadTimeoutError\n32 from .packages.urllib3.exceptions import SSLError as _SSLError\n33 from .packages.urllib3.exceptions import ResponseError\n34 from .cookies import extract_cookies_to_jar\n35 from .exceptions import (ConnectionError, ConnectTimeout, ReadTimeout, SSLError,\n36                          ProxyError, RetryError)\n37 from .auth import _basic_auth_str\n38 \n39 DEFAULT_POOLBLOCK = False\n40 DEFAULT_POOLSIZE = 10\n41 DEFAULT_RETRIES = 0\n42 DEFAULT_POOL_TIMEOUT = None\n43 \n44 \n45 class BaseAdapter(object):\n46     \"\"\"The Base Transport Adapter\"\"\"\n47 \n48     def __init__(self):\n49         super(BaseAdapter, self).__init__()\n50 \n51     def send(self):\n52         raise NotImplementedError\n53 \n54     def close(self):\n55         raise NotImplementedError\n56 \n57 \n58 class HTTPAdapter(BaseAdapter):\n59     \"\"\"The built-in HTTP Adapter for urllib3.\n60 \n61     Provides a general-case interface for Requests sessions to contact HTTP and\n62     HTTPS urls by implementing the Transport Adapter interface. This class will\n63     usually be created by the :class:`Session <Session>` class under the\n64     covers.\n65 \n66     :param pool_connections: The number of urllib3 connection pools to cache.\n67     :param pool_maxsize: The maximum number of connections to save in the pool.\n68     :param max_retries: The maximum number of retries each connection\n69         should attempt. Note, this applies only to failed DNS lookups, socket\n70         connections and connection timeouts, never to requests where data has\n71         made it to the server. By default, Requests does not retry failed\n72         connections. If you need granular control over the conditions under\n73         which we retry a request, import urllib3's ``Retry`` class and pass\n74         that instead.\n75     :param pool_block: Whether the connection pool should block for connections.\n76 \n77     Usage::\n78 \n79       >>> import requests\n80       >>> s = requests.Session()\n81       >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n82       >>> s.mount('http://', a)\n83     \"\"\"\n84     __attrs__ = ['max_retries', 'config', '_pool_connections', '_pool_maxsize',\n85                  '_pool_block']\n86 \n87     def __init__(self, pool_connections=DEFAULT_POOLSIZE,\n88                  pool_maxsize=DEFAULT_POOLSIZE, max_retries=DEFAULT_RETRIES,\n89                  pool_block=DEFAULT_POOLBLOCK):\n90         if max_retries == DEFAULT_RETRIES:\n91             self.max_retries = Retry(0, read=False)\n92         else:\n93             self.max_retries = Retry.from_int(max_retries)\n94         self.config = {}\n95         self.proxy_manager = {}\n96 \n97         super(HTTPAdapter, self).__init__()\n98 \n99         self._pool_connections = pool_connections\n100         self._pool_maxsize = pool_maxsize\n101         self._pool_block = pool_block\n102 \n103         self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n104 \n105     def __getstate__(self):\n106         return dict((attr, getattr(self, attr, None)) for attr in\n107                     self.__attrs__)\n108 \n109     def __setstate__(self, state):\n110         # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n111         # self.poolmanager uses a lambda function, which isn't pickleable.\n112         self.proxy_manager = {}\n113         self.config = {}\n114 \n115         for attr, value in state.items():\n116             setattr(self, attr, value)\n117 \n118         self.init_poolmanager(self._pool_connections, self._pool_maxsize,\n119                               block=self._pool_block)\n120 \n121     def init_poolmanager(self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs):\n122         \"\"\"Initializes a urllib3 PoolManager.\n123 \n124         This method should not be called from user code, and is only\n125         exposed for use when subclassing the\n126         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n127 \n128         :param connections: The number of urllib3 connection pools to cache.\n129         :param maxsize: The maximum number of connections to save in the pool.\n130         :param block: Block when no free connections are available.\n131         :param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.\n132         \"\"\"\n133         # save these values for pickling\n134         self._pool_connections = connections\n135         self._pool_maxsize = maxsize\n136         self._pool_block = block\n137 \n138         self.poolmanager = PoolManager(num_pools=connections, maxsize=maxsize,\n139                                        block=block, strict=True, **pool_kwargs)\n140 \n141     def proxy_manager_for(self, proxy, **proxy_kwargs):\n142         \"\"\"Return urllib3 ProxyManager for the given proxy.\n143 \n144         This method should not be called from user code, and is only\n145         exposed for use when subclassing the\n146         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n147 \n148         :param proxy: The proxy to return a urllib3 ProxyManager for.\n149         :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.\n150         :returns: ProxyManager\n151         \"\"\"\n152         if not proxy in self.proxy_manager:\n153             proxy_headers = self.proxy_headers(proxy)\n154             self.proxy_manager[proxy] = proxy_from_url(\n155                 proxy,\n156                 proxy_headers=proxy_headers,\n157                 num_pools=self._pool_connections,\n158                 maxsize=self._pool_maxsize,\n159                 block=self._pool_block,\n160                 **proxy_kwargs)\n161 \n162         return self.proxy_manager[proxy]\n163 \n164     def cert_verify(self, conn, url, verify, cert):\n165         \"\"\"Verify a SSL certificate. This method should not be called from user\n166         code, and is only exposed for use when subclassing the\n167         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n168 \n169         :param conn: The urllib3 connection object associated with the cert.\n170         :param url: The requested URL.\n171         :param verify: Whether we should actually verify the certificate.\n172         :param cert: The SSL certificate to verify.\n173         \"\"\"\n174         if url.lower().startswith('https') and verify:\n175 \n176             cert_loc = None\n177 \n178             # Allow self-specified cert location.\n179             if verify is not True:\n180                 cert_loc = verify\n181 \n182             if not cert_loc:\n183                 cert_loc = DEFAULT_CA_BUNDLE_PATH\n184 \n185             if not cert_loc:\n186                 raise Exception(\"Could not find a suitable SSL CA certificate bundle.\")\n187 \n188             conn.cert_reqs = 'CERT_REQUIRED'\n189 \n190             if not os.path.isdir(cert_loc):\n191                 conn.ca_certs = cert_loc\n192             else:\n193                 conn.ca_cert_dir = cert_loc\n194         else:\n195             conn.cert_reqs = 'CERT_NONE'\n196             conn.ca_certs = None\n197             conn.ca_cert_dir = None\n198 \n199         if cert:\n200             if not isinstance(cert, basestring):\n201                 conn.cert_file = cert[0]\n202                 conn.key_file = cert[1]\n203             else:\n204                 conn.cert_file = cert\n205 \n206     def build_response(self, req, resp):\n207         \"\"\"Builds a :class:`Response <requests.Response>` object from a urllib3\n208         response. This should not be called from user code, and is only exposed\n209         for use when subclassing the\n210         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`\n211 \n212         :param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.\n213         :param resp: The urllib3 response object.\n214         \"\"\"\n215         response = Response()\n216 \n217         # Fallback to None if there's no status_code, for whatever reason.\n218         response.status_code = getattr(resp, 'status', None)\n219 \n220         # Make headers case-insensitive.\n221         response.headers = CaseInsensitiveDict(getattr(resp, 'headers', {}))\n222 \n223         # Set encoding.\n224         response.encoding = get_encoding_from_headers(response.headers)\n225         response.raw = resp\n226         response.reason = response.raw.reason\n227 \n228         if isinstance(req.url, bytes):\n229             response.url = req.url.decode('utf-8')\n230         else:\n231             response.url = req.url\n232 \n233         # Add new cookies from the server.\n234         extract_cookies_to_jar(response.cookies, req, resp)\n235 \n236         # Give the Response some context.\n237         response.request = req\n238         response.connection = self\n239 \n240         return response\n241 \n242     def get_connection(self, url, proxies=None):\n243         \"\"\"Returns a urllib3 connection for the given URL. This should not be\n244         called from user code, and is only exposed for use when subclassing the\n245         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n246 \n247         :param url: The URL to connect to.\n248         :param proxies: (optional) A Requests-style dictionary of proxies used on this request.\n249         \"\"\"\n250         proxy = select_proxy(url, proxies)\n251 \n252         if proxy:\n253             proxy = prepend_scheme_if_needed(proxy, 'http')\n254             proxy_manager = self.proxy_manager_for(proxy)\n255             conn = proxy_manager.connection_from_url(url)\n256         else:\n257             # Only scheme should be lower case\n258             parsed = urlparse(url)\n259             url = parsed.geturl()\n260             conn = self.poolmanager.connection_from_url(url)\n261 \n262         return conn\n263 \n264     def close(self):\n265         \"\"\"Disposes of any internal state.\n266 \n267         Currently, this just closes the PoolManager, which closes pooled\n268         connections.\n269         \"\"\"\n270         self.poolmanager.clear()\n271 \n272     def request_url(self, request, proxies):\n273         \"\"\"Obtain the url to use when making the final request.\n274 \n275         If the message is being sent through a HTTP proxy, the full URL has to\n276         be used. Otherwise, we should only use the path portion of the URL.\n277 \n278         This should not be called from user code, and is only exposed for use\n279         when subclassing the\n280         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n281 \n282         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n283         :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.\n284         \"\"\"\n285         proxy = select_proxy(request.url, proxies)\n286         scheme = urlparse(request.url).scheme\n287         if proxy and scheme != 'https':\n288             url = urldefragauth(request.url)\n289         else:\n290             url = request.path_url\n291 \n292         return url\n293 \n294     def add_headers(self, request, **kwargs):\n295         \"\"\"Add any headers needed by the connection. As of v2.0 this does\n296         nothing by default, but is left for overriding by users that subclass\n297         the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n298 \n299         This should not be called from user code, and is only exposed for use\n300         when subclassing the\n301         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n302 \n303         :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.\n304         :param kwargs: The keyword arguments from the call to send().\n305         \"\"\"\n306         pass\n307 \n308     def proxy_headers(self, proxy):\n309         \"\"\"Returns a dictionary of the headers to add to any request sent\n310         through a proxy. This works with urllib3 magic to ensure that they are\n311         correctly sent to the proxy, rather than in a tunnelled request if\n312         CONNECT is being used.\n313 \n314         This should not be called from user code, and is only exposed for use\n315         when subclassing the\n316         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n317 \n318         :param proxies: The url of the proxy being used for this request.\n319         \"\"\"\n320         headers = {}\n321         username, password = get_auth_from_url(proxy)\n322 \n323         if username and password:\n324             headers['Proxy-Authorization'] = _basic_auth_str(username,\n325                                                              password)\n326 \n327         return headers\n328 \n329     def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n330         \"\"\"Sends PreparedRequest object. Returns Response object.\n331 \n332         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n333         :param stream: (optional) Whether to stream the request content.\n334         :param timeout: (optional) How long to wait for the server to send\n335             data before giving up, as a float, or a :ref:`(connect timeout,\n336             read timeout) <timeouts>` tuple.\n337         :type timeout: float or tuple\n338         :param verify: (optional) Whether to verify SSL certificates.\n339         :param cert: (optional) Any user-provided SSL certificate to be trusted.\n340         :param proxies: (optional) The proxies dictionary to apply to the request.\n341         \"\"\"\n342 \n343         conn = self.get_connection(request.url, proxies)\n344 \n345         self.cert_verify(conn, request.url, verify, cert)\n346         url = self.request_url(request, proxies)\n347         self.add_headers(request)\n348 \n349         chunked = not (request.body is None or 'Content-Length' in request.headers)\n350 \n351         if isinstance(timeout, tuple):\n352             try:\n353                 connect, read = timeout\n354                 timeout = TimeoutSauce(connect=connect, read=read)\n355             except ValueError as e:\n356                 # this may raise a string formatting error.\n357                 err = (\"Invalid timeout {0}. Pass a (connect, read) \"\n358                        \"timeout tuple, or a single float to set \"\n359                        \"both timeouts to the same value\".format(timeout))\n360                 raise ValueError(err)\n361         else:\n362             timeout = TimeoutSauce(connect=timeout, read=timeout)\n363 \n364         try:\n365             if not chunked:\n366                 resp = conn.urlopen(\n367                     method=request.method,\n368                     url=url,\n369                     body=request.body,\n370                     headers=request.headers,\n371                     redirect=False,\n372                     assert_same_host=False,\n373                     preload_content=False,\n374                     decode_content=False,\n375                     retries=self.max_retries,\n376                     timeout=timeout\n377                 )\n378 \n379             # Send the request.\n380             else:\n381                 if hasattr(conn, 'proxy_pool'):\n382                     conn = conn.proxy_pool\n383 \n384                 low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)\n385 \n386                 try:\n387                     low_conn.putrequest(request.method,\n388                                         url,\n389                                         skip_accept_encoding=True)\n390 \n391                     for header, value in request.headers.items():\n392                         low_conn.putheader(header, value)\n393 \n394                     low_conn.endheaders()\n395 \n396                     for i in request.body:\n397                         chunk_size = len(i)\n398                         if chunk_size == 0:\n399                             continue\n400                         low_conn.send(hex(chunk_size)[2:].encode('utf-8'))\n401                         low_conn.send(b'\\r\\n')\n402                         low_conn.send(i)\n403                         low_conn.send(b'\\r\\n')\n404                     low_conn.send(b'0\\r\\n\\r\\n')\n405 \n406                     # Receive the response from the server\n407                     try:\n408                         # For Python 2.7+ versions, use buffering of HTTP\n409                         # responses\n410                         r = low_conn.getresponse(buffering=True)\n411                     except TypeError:\n412                         # For compatibility with Python 2.6 versions and back\n413                         r = low_conn.getresponse()\n414 \n415                     resp = HTTPResponse.from_httplib(\n416                         r,\n417                         pool=conn,\n418                         connection=low_conn,\n419                         preload_content=False,\n420                         decode_content=False\n421                     )\n422                 except:\n423                     # If we hit any problems here, clean up the connection.\n424                     # Then, reraise so that we can handle the actual exception.\n425                     low_conn.close()\n426                     raise\n427 \n428         except (ProtocolError, socket.error) as err:\n429             raise ConnectionError(err, request=request)\n430 \n431         except MaxRetryError as e:\n432             if isinstance(e.reason, ConnectTimeoutError):\n433                 # TODO: Remove this in 3.0.0: see #2811\n434                 if not isinstance(e.reason, NewConnectionError):\n435                     raise ConnectTimeout(e, request=request)\n436 \n437             if isinstance(e.reason, ResponseError):\n438                 raise RetryError(e, request=request)\n439 \n440             raise ConnectionError(e, request=request)\n441 \n442         except ClosedPoolError as e:\n443             raise ConnectionError(e, request=request)\n444 \n445         except _ProxyError as e:\n446             raise ProxyError(e)\n447 \n448         except (_SSLError, _HTTPError) as e:\n449             if isinstance(e, _SSLError):\n450                 raise SSLError(e, request=request)\n451             elif isinstance(e, ReadTimeoutError):\n452                 raise ReadTimeout(e, request=request)\n453             else:\n454                 raise\n455 \n456         return self.build_response(request, resp)\n",
        "intended_behavior": "This component should be capable of correctly encoding the redirected URL, ensuring that any non-ASCII characters are appropriately handled per the specifications of the URI and IRI standards, before the request is sent. If a redirection occurs, the method should verify and encode the URL's non-ASCII parts, like the path and query strings, ensuring that the request is directed to the correct resource. This behavior must preserve the functionality of being able to handle standard ASCII URLs and maintain compatibility with various web servers and encoding formats."
    }
]