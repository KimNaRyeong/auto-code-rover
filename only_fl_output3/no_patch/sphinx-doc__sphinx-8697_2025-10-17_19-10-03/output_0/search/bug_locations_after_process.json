[
    {
        "rel_file_path": "sphinx/directives/__init__.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/sphinx-doc__sphinx/setup_sphinx-doc__sphinx__3.5/sphinx/directives/__init__.py",
        "start": 1,
        "end": 340,
        "class_name": null,
        "method_name": null,
        "code": "1 \"\"\"\n2     sphinx.directives\n3     ~~~~~~~~~~~~~~~~~\n4 \n5     Handlers for additional ReST directives.\n6 \n7     :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.\n8     :license: BSD, see LICENSE for details.\n9 \"\"\"\n10 \n11 import re\n12 from typing import Any, Dict, Generic, List, Tuple, TypeVar, cast\n13 \n14 from docutils import nodes\n15 from docutils.nodes import Node\n16 from docutils.parsers.rst import directives, roles\n17 \n18 from sphinx import addnodes\n19 from sphinx.addnodes import desc_signature\n20 from sphinx.deprecation import (RemovedInSphinx40Warning, RemovedInSphinx50Warning,\n21                                 deprecated_alias)\n22 from sphinx.util import docutils\n23 from sphinx.util.docfields import DocFieldTransformer, Field, TypedField\n24 from sphinx.util.docutils import SphinxDirective\n25 from sphinx.util.typing import DirectiveOption\n26 \n27 if False:\n28     # For type annotation\n29     from sphinx.application import Sphinx\n30 \n31 \n32 # RE to strip backslash escapes\n33 nl_escape_re = re.compile(r'\\\\\\n')\n34 strip_backslash_re = re.compile(r'\\\\(.)')\n35 \n36 T = TypeVar('T')\n37 \n38 \n39 def optional_int(argument: str) -> int:\n40     \"\"\"\n41     Check for an integer argument or None value; raise ``ValueError`` if not.\n42     \"\"\"\n43     if argument is None:\n44         return None\n45     else:\n46         value = int(argument)\n47         if value < 0:\n48             raise ValueError('negative value; must be positive or zero')\n49         return value\n50 \n51 \n52 class ObjectDescription(SphinxDirective, Generic[T]):\n53     \"\"\"\n54     Directive to describe a class, function or similar object.  Not used\n55     directly, but subclassed (in domain-specific directives) to add custom\n56     behavior.\n57     \"\"\"\n58 \n59     has_content = True\n60     required_arguments = 1\n61     optional_arguments = 0\n62     final_argument_whitespace = True\n63     option_spec = {\n64         'noindex': directives.flag,\n65     }  # type: Dict[str, DirectiveOption]\n66 \n67     # types of doc fields that this directive handles, see sphinx.util.docfields\n68     doc_field_types = []    # type: List[Field]\n69     domain = None           # type: str\n70     objtype = None          # type: str\n71     indexnode = None        # type: addnodes.index\n72 \n73     # Warning: this might be removed in future version. Don't touch this from extensions.\n74     _doc_field_type_map = {}  # type: Dict[str, Tuple[Field, bool]]\n75 \n76     def get_field_type_map(self) -> Dict[str, Tuple[Field, bool]]:\n77         if self._doc_field_type_map == {}:\n78             self._doc_field_type_map = {}\n79             for field in self.doc_field_types:\n80                 for name in field.names:\n81                     self._doc_field_type_map[name] = (field, False)\n82 \n83                 if field.is_typed:\n84                     typed_field = cast(TypedField, field)\n85                     for name in typed_field.typenames:\n86                         self._doc_field_type_map[name] = (field, True)\n87 \n88         return self._doc_field_type_map\n89 \n90     def get_signatures(self) -> List[str]:\n91         \"\"\"\n92         Retrieve the signatures to document from the directive arguments.  By\n93         default, signatures are given as arguments, one per line.\n94         \"\"\"\n95         lines = nl_escape_re.sub('', self.arguments[0]).split('\\n')\n96         if self.config.strip_signature_backslash:\n97             # remove backslashes to support (dummy) escapes; helps Vim highlighting\n98             return [strip_backslash_re.sub(r'\\1', line.strip()) for line in lines]\n99         else:\n100             return [line.strip() for line in lines]\n101 \n102     def handle_signature(self, sig: str, signode: desc_signature) -> T:\n103         \"\"\"\n104         Parse the signature *sig* into individual nodes and append them to\n105         *signode*. If ValueError is raised, parsing is aborted and the whole\n106         *sig* is put into a single desc_name node.\n107 \n108         The return value should be a value that identifies the object.  It is\n109         passed to :meth:`add_target_and_index()` unchanged, and otherwise only\n110         used to skip duplicates.\n111         \"\"\"\n112         raise ValueError\n113 \n114     def add_target_and_index(self, name: T, sig: str, signode: desc_signature) -> None:\n115         \"\"\"\n116         Add cross-reference IDs and entries to self.indexnode, if applicable.\n117 \n118         *name* is whatever :meth:`handle_signature()` returned.\n119         \"\"\"\n120         return  # do nothing by default\n121 \n122     def before_content(self) -> None:\n123         \"\"\"\n124         Called before parsing content. Used to set information about the current\n125         directive context on the build environment.\n126         \"\"\"\n127         pass\n128 \n129     def transform_content(self, contentnode: addnodes.desc_content) -> None:\n130         \"\"\"\n131         Called after creating the content through nested parsing,\n132         but before the ``object-description-transform`` event is emitted,\n133         and before the info-fields are transformed.\n134         Can be used to manipulate the content.\n135         \"\"\"\n136         pass\n137 \n138     def after_content(self) -> None:\n139         \"\"\"\n140         Called after parsing content. Used to reset information about the\n141         current directive context on the build environment.\n142         \"\"\"\n143         pass\n144 \n145     def run(self) -> List[Node]:\n146         \"\"\"\n147         Main directive entry function, called by docutils upon encountering the\n148         directive.\n149 \n150         This directive is meant to be quite easily subclassable, so it delegates\n151         to several additional methods.  What it does:\n152 \n153         * find out if called as a domain-specific directive, set self.domain\n154         * create a `desc` node to fit all description inside\n155         * parse standard options, currently `noindex`\n156         * create an index node if needed as self.indexnode\n157         * parse all given signatures (as returned by self.get_signatures())\n158           using self.handle_signature(), which should either return a name\n159           or raise ValueError\n160         * add index entries using self.add_target_and_index()\n161         * parse the content and handle doc fields in it\n162         \"\"\"\n163         if ':' in self.name:\n164             self.domain, self.objtype = self.name.split(':', 1)\n165         else:\n166             self.domain, self.objtype = '', self.name\n167         self.indexnode = addnodes.index(entries=[])\n168 \n169         node = addnodes.desc()\n170         node.document = self.state.document\n171         node['domain'] = self.domain\n172         # 'desctype' is a backwards compatible attribute\n173         node['objtype'] = node['desctype'] = self.objtype\n174         node['noindex'] = noindex = ('noindex' in self.options)\n175         if self.domain:\n176             node['classes'].append(self.domain)\n177 \n178         self.names = []  # type: List[T]\n179         signatures = self.get_signatures()\n180         for i, sig in enumerate(signatures):\n181             # add a signature node for each signature in the current unit\n182             # and add a reference target for it\n183             signode = addnodes.desc_signature(sig, '')\n184             self.set_source_info(signode)\n185             node.append(signode)\n186             try:\n187                 # name can also be a tuple, e.g. (classname, objname);\n188                 # this is strictly domain-specific (i.e. no assumptions may\n189                 # be made in this base class)\n190                 name = self.handle_signature(sig, signode)\n191             except ValueError:\n192                 # signature parsing failed\n193                 signode.clear()\n194                 signode += addnodes.desc_name(sig, sig)\n195                 continue  # we don't want an index entry here\n196             if name not in self.names:\n197                 self.names.append(name)\n198                 if not noindex:\n199                     # only add target and index entry if this is the first\n200                     # description of the object with this name in this desc block\n201                     self.add_target_and_index(name, sig, signode)\n202 \n203         contentnode = addnodes.desc_content()\n204         node.append(contentnode)\n205         if self.names:\n206             # needed for association of version{added,changed} directives\n207             self.env.temp_data['object'] = self.names[0]\n208         self.before_content()\n209         self.state.nested_parse(self.content, self.content_offset, contentnode)\n210         self.transform_content(contentnode)\n211         self.env.app.emit('object-description-transform',\n212                           self.domain, self.objtype, contentnode)\n213         DocFieldTransformer(self).transform_all(contentnode)\n214         self.env.temp_data['object'] = None\n215         self.after_content()\n216         return [self.indexnode, node]\n217 \n218 \n219 class DefaultRole(SphinxDirective):\n220     \"\"\"\n221     Set the default interpreted text role.  Overridden from docutils.\n222     \"\"\"\n223 \n224     optional_arguments = 1\n225     final_argument_whitespace = False\n226 \n227     def run(self) -> List[Node]:\n228         if not self.arguments:\n229             docutils.unregister_role('')\n230             return []\n231         role_name = self.arguments[0]\n232         role, messages = roles.role(role_name, self.state_machine.language,\n233                                     self.lineno, self.state.reporter)\n234         if role:\n235             docutils.register_role('', role)\n236             self.env.temp_data['default_role'] = role_name\n237         else:\n238             literal_block = nodes.literal_block(self.block_text, self.block_text)\n239             reporter = self.state.reporter\n240             error = reporter.error('Unknown interpreted text role \"%s\".' % role_name,\n241                                    literal_block, line=self.lineno)\n242             messages += [error]\n243 \n244         return cast(List[nodes.Node], messages)\n245 \n246 \n247 class DefaultDomain(SphinxDirective):\n248     \"\"\"\n249     Directive to (re-)set the default domain for this source file.\n250     \"\"\"\n251 \n252     has_content = False\n253     required_arguments = 1\n254     optional_arguments = 0\n255     final_argument_whitespace = False\n256     option_spec = {}  # type: Dict\n257 \n258     def run(self) -> List[Node]:\n259         domain_name = self.arguments[0].lower()\n260         # if domain_name not in env.domains:\n261         #     # try searching by label\n262         #     for domain in env.domains.values():\n263         #         if domain.label.lower() == domain_name:\n264         #             domain_name = domain.name\n265         #             break\n266         self.env.temp_data['default_domain'] = self.env.domains.get(domain_name)\n267         return []\n268 \n269 from sphinx.directives.code import CodeBlock, Highlight, LiteralInclude  # noqa\n270 from sphinx.directives.other import (Acks, Author, Centered, Class, HList, Include,  # noqa\n271                                      Only, SeeAlso, TabularColumns, TocTree, VersionChange)\n272 from sphinx.directives.patches import Figure, Meta  # noqa\n273 from sphinx.domains.index import IndexDirective  # noqa\n274 \n275 deprecated_alias('sphinx.directives',\n276                  {\n277                      'Highlight': Highlight,\n278                      'CodeBlock': CodeBlock,\n279                      'LiteralInclude': LiteralInclude,\n280                      'TocTree': TocTree,\n281                      'Author': Author,\n282                      'Index': IndexDirective,\n283                      'VersionChange': VersionChange,\n284                      'SeeAlso': SeeAlso,\n285                      'TabularColumns': TabularColumns,\n286                      'Centered': Centered,\n287                      'Acks': Acks,\n288                      'HList': HList,\n289                      'Only': Only,\n290                      'Include': Include,\n291                      'Class': Class,\n292                      'Figure': Figure,\n293                      'Meta': Meta,\n294                  },\n295                  RemovedInSphinx40Warning,\n296                  {\n297                      'Highlight': 'sphinx.directives.code.Highlight',\n298                      'CodeBlock': 'sphinx.directives.code.CodeBlock',\n299                      'LiteralInclude': 'sphinx.directives.code.LiteralInclude',\n300                      'TocTree': 'sphinx.directives.other.TocTree',\n301                      'Author': 'sphinx.directives.other.Author',\n302                      'Index': 'sphinx.directives.other.IndexDirective',\n303                      'VersionChange': 'sphinx.directives.other.VersionChange',\n304                      'SeeAlso': 'sphinx.directives.other.SeeAlso',\n305                      'TabularColumns': 'sphinx.directives.other.TabularColumns',\n306                      'Centered': 'sphinx.directives.other.Centered',\n307                      'Acks': 'sphinx.directives.other.Acks',\n308                      'HList': 'sphinx.directives.other.HList',\n309                      'Only': 'sphinx.directives.other.Only',\n310                      'Include': 'sphinx.directives.other.Include',\n311                      'Class': 'sphinx.directives.other.Class',\n312                      'Figure': 'sphinx.directives.patches.Figure',\n313                      'Meta': 'sphinx.directives.patches.Meta',\n314                  })\n315 \n316 deprecated_alias('sphinx.directives',\n317                  {\n318                      'DescDirective': ObjectDescription,\n319                  },\n320                  RemovedInSphinx50Warning,\n321                  {\n322                      'DescDirective': 'sphinx.directives.ObjectDescription',\n323                  })\n324 \n325 \n326 def setup(app: \"Sphinx\") -> Dict[str, Any]:\n327     app.add_config_value(\"strip_signature_backslash\", False, 'env')\n328     directives.register_directive('default-role', DefaultRole)\n329     directives.register_directive('default-domain', DefaultDomain)\n330     directives.register_directive('describe', ObjectDescription)\n331     # new, more consistent, name\n332     directives.register_directive('object', ObjectDescription)\n333 \n334     app.add_event('object-description-transform')\n335 \n336     return {\n337         'version': 'builtin',\n338         'parallel_read_safe': True,\n339         'parallel_write_safe': True,\n340     }\n",
        "intended_behavior": "The processing of file paths in directives, specifically the `:download:` directive and potentially figure directives as well, needs to include a normalization step. By applying `os.path.normpath()` or a similar approach to the file paths as they are processed, Sphinx can ensure that different string representations of the same path are recognized as the same file. This will prevent the generation of duplicate files in the build output. The normalization should occur before any path comparison or file handling operation to ensure that the intended resources are uniquely identified and managed across the documentation build process."
    },
    {
        "rel_file_path": "sphinx/directives/other.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/sphinx-doc__sphinx/setup_sphinx-doc__sphinx__3.5/sphinx/directives/other.py",
        "start": 1,
        "end": 399,
        "class_name": null,
        "method_name": null,
        "code": "1 \"\"\"\n2     sphinx.directives.other\n3     ~~~~~~~~~~~~~~~~~~~~~~~\n4 \n5     :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.\n6     :license: BSD, see LICENSE for details.\n7 \"\"\"\n8 \n9 import re\n10 from typing import Any, Dict, List, cast\n11 \n12 from docutils import nodes\n13 from docutils.nodes import Element, Node\n14 from docutils.parsers.rst import directives\n15 from docutils.parsers.rst.directives.admonitions import BaseAdmonition\n16 from docutils.parsers.rst.directives.misc import Class\n17 from docutils.parsers.rst.directives.misc import Include as BaseInclude\n18 \n19 from sphinx import addnodes\n20 from sphinx.deprecation import RemovedInSphinx40Warning, deprecated_alias\n21 from sphinx.domains.changeset import VersionChange  # NOQA  # for compatibility\n22 from sphinx.locale import _\n23 from sphinx.util import docname_join, url_re\n24 from sphinx.util.docutils import SphinxDirective\n25 from sphinx.util.matching import Matcher, patfilter\n26 from sphinx.util.nodes import explicit_title_re\n27 \n28 if False:\n29     # For type annotation\n30     from sphinx.application import Sphinx\n31 \n32 \n33 glob_re = re.compile(r'.*[*?\\[].*')\n34 \n35 \n36 def int_or_nothing(argument: str) -> int:\n37     if not argument:\n38         return 999\n39     return int(argument)\n40 \n41 \n42 class TocTree(SphinxDirective):\n43     \"\"\"\n44     Directive to notify Sphinx about the hierarchical structure of the docs,\n45     and to include a table-of-contents like tree in the current document.\n46     \"\"\"\n47     has_content = True\n48     required_arguments = 0\n49     optional_arguments = 0\n50     final_argument_whitespace = False\n51     option_spec = {\n52         'maxdepth': int,\n53         'name': directives.unchanged,\n54         'caption': directives.unchanged_required,\n55         'glob': directives.flag,\n56         'hidden': directives.flag,\n57         'includehidden': directives.flag,\n58         'numbered': int_or_nothing,\n59         'titlesonly': directives.flag,\n60         'reversed': directives.flag,\n61     }\n62 \n63     def run(self) -> List[Node]:\n64         subnode = addnodes.toctree()\n65         subnode['parent'] = self.env.docname\n66 \n67         # (title, ref) pairs, where ref may be a document, or an external link,\n68         # and title may be None if the document's title is to be used\n69         subnode['entries'] = []\n70         subnode['includefiles'] = []\n71         subnode['maxdepth'] = self.options.get('maxdepth', -1)\n72         subnode['caption'] = self.options.get('caption')\n73         subnode['glob'] = 'glob' in self.options\n74         subnode['hidden'] = 'hidden' in self.options\n75         subnode['includehidden'] = 'includehidden' in self.options\n76         subnode['numbered'] = self.options.get('numbered', 0)\n77         subnode['titlesonly'] = 'titlesonly' in self.options\n78         self.set_source_info(subnode)\n79         wrappernode = nodes.compound(classes=['toctree-wrapper'])\n80         wrappernode.append(subnode)\n81         self.add_name(wrappernode)\n82 \n83         ret = self.parse_content(subnode)\n84         ret.append(wrappernode)\n85         return ret\n86 \n87     def parse_content(self, toctree: addnodes.toctree) -> List[Node]:\n88         suffixes = self.config.source_suffix\n89 \n90         # glob target documents\n91         all_docnames = self.env.found_docs.copy()\n92         all_docnames.remove(self.env.docname)  # remove current document\n93 \n94         ret = []  # type: List[Node]\n95         excluded = Matcher(self.config.exclude_patterns)\n96         for entry in self.content:\n97             if not entry:\n98                 continue\n99             # look for explicit titles (\"Some Title <document>\")\n100             explicit = explicit_title_re.match(entry)\n101             if (toctree['glob'] and glob_re.match(entry) and\n102                     not explicit and not url_re.match(entry)):\n103                 patname = docname_join(self.env.docname, entry)\n104                 docnames = sorted(patfilter(all_docnames, patname))\n105                 for docname in docnames:\n106                     all_docnames.remove(docname)  # don't include it again\n107                     toctree['entries'].append((None, docname))\n108                     toctree['includefiles'].append(docname)\n109                 if not docnames:\n110                     ret.append(self.state.document.reporter.warning(\n111                         'toctree glob pattern %r didn\\'t match any documents'\n112                         % entry, line=self.lineno))\n113             else:\n114                 if explicit:\n115                     ref = explicit.group(2)\n116                     title = explicit.group(1)\n117                     docname = ref\n118                 else:\n119                     ref = docname = entry\n120                     title = None\n121                 # remove suffixes (backwards compatibility)\n122                 for suffix in suffixes:\n123                     if docname.endswith(suffix):\n124                         docname = docname[:-len(suffix)]\n125                         break\n126                 # absolutize filenames\n127                 docname = docname_join(self.env.docname, docname)\n128                 if url_re.match(ref) or ref == 'self':\n129                     toctree['entries'].append((title, ref))\n130                 elif docname not in self.env.found_docs:\n131                     if excluded(self.env.doc2path(docname, None)):\n132                         message = 'toctree contains reference to excluded document %r'\n133                     else:\n134                         message = 'toctree contains reference to nonexisting document %r'\n135 \n136                     ret.append(self.state.document.reporter.warning(message % docname,\n137                                                                     line=self.lineno))\n138                     self.env.note_reread()\n139                 else:\n140                     all_docnames.discard(docname)\n141                     toctree['entries'].append((title, docname))\n142                     toctree['includefiles'].append(docname)\n143 \n144         # entries contains all entries (self references, external links etc.)\n145         if 'reversed' in self.options:\n146             toctree['entries'] = list(reversed(toctree['entries']))\n147             toctree['includefiles'] = list(reversed(toctree['includefiles']))\n148 \n149         return ret\n150 \n151 \n152 class Author(SphinxDirective):\n153     \"\"\"\n154     Directive to give the name of the author of the current document\n155     or section. Shown in the output only if the show_authors option is on.\n156     \"\"\"\n157     has_content = False\n158     required_arguments = 1\n159     optional_arguments = 0\n160     final_argument_whitespace = True\n161     option_spec = {}  # type: Dict\n162 \n163     def run(self) -> List[Node]:\n164         if not self.config.show_authors:\n165             return []\n166         para = nodes.paragraph(translatable=False)  # type: Element\n167         emph = nodes.emphasis()\n168         para += emph\n169         if self.name == 'sectionauthor':\n170             text = _('Section author: ')\n171         elif self.name == 'moduleauthor':\n172             text = _('Module author: ')\n173         elif self.name == 'codeauthor':\n174             text = _('Code author: ')\n175         else:\n176             text = _('Author: ')\n177         emph += nodes.Text(text, text)\n178         inodes, messages = self.state.inline_text(self.arguments[0], self.lineno)\n179         emph.extend(inodes)\n180 \n181         ret = [para]  # type: List[Node]\n182         ret += messages\n183         return ret\n184 \n185 \n186 class SeeAlso(BaseAdmonition):\n187     \"\"\"\n188     An admonition mentioning things to look at as reference.\n189     \"\"\"\n190     node_class = addnodes.seealso\n191 \n192 \n193 class TabularColumns(SphinxDirective):\n194     \"\"\"\n195     Directive to give an explicit tabulary column definition to LaTeX.\n196     \"\"\"\n197     has_content = False\n198     required_arguments = 1\n199     optional_arguments = 0\n200     final_argument_whitespace = True\n201     option_spec = {}  # type: Dict\n202 \n203     def run(self) -> List[Node]:\n204         node = addnodes.tabular_col_spec()\n205         node['spec'] = self.arguments[0]\n206         self.set_source_info(node)\n207         return [node]\n208 \n209 \n210 class Centered(SphinxDirective):\n211     \"\"\"\n212     Directive to create a centered line of bold text.\n213     \"\"\"\n214     has_content = False\n215     required_arguments = 1\n216     optional_arguments = 0\n217     final_argument_whitespace = True\n218     option_spec = {}  # type: Dict\n219 \n220     def run(self) -> List[Node]:\n221         if not self.arguments:\n222             return []\n223         subnode = addnodes.centered()  # type: Element\n224         inodes, messages = self.state.inline_text(self.arguments[0], self.lineno)\n225         subnode.extend(inodes)\n226 \n227         ret = [subnode]  # type: List[Node]\n228         ret += messages\n229         return ret\n230 \n231 \n232 class Acks(SphinxDirective):\n233     \"\"\"\n234     Directive for a list of names.\n235     \"\"\"\n236     has_content = True\n237     required_arguments = 0\n238     optional_arguments = 0\n239     final_argument_whitespace = False\n240     option_spec = {}  # type: Dict\n241 \n242     def run(self) -> List[Node]:\n243         node = addnodes.acks()\n244         node.document = self.state.document\n245         self.state.nested_parse(self.content, self.content_offset, node)\n246         if len(node.children) != 1 or not isinstance(node.children[0],\n247                                                      nodes.bullet_list):\n248             reporter = self.state.document.reporter\n249             return [reporter.warning('.. acks content is not a list', line=self.lineno)]\n250         return [node]\n251 \n252 \n253 class HList(SphinxDirective):\n254     \"\"\"\n255     Directive for a list that gets compacted horizontally.\n256     \"\"\"\n257     has_content = True\n258     required_arguments = 0\n259     optional_arguments = 0\n260     final_argument_whitespace = False\n261     option_spec = {\n262         'columns': int,\n263     }\n264 \n265     def run(self) -> List[Node]:\n266         ncolumns = self.options.get('columns', 2)\n267         node = nodes.paragraph()\n268         node.document = self.state.document\n269         self.state.nested_parse(self.content, self.content_offset, node)\n270         if len(node.children) != 1 or not isinstance(node.children[0],\n271                                                      nodes.bullet_list):\n272             reporter = self.state.document.reporter\n273             return [reporter.warning('.. hlist content is not a list', line=self.lineno)]\n274         fulllist = node.children[0]\n275         # create a hlist node where the items are distributed\n276         npercol, nmore = divmod(len(fulllist), ncolumns)\n277         index = 0\n278         newnode = addnodes.hlist()\n279         for column in range(ncolumns):\n280             endindex = index + ((npercol + 1) if column < nmore else npercol)\n281             bullet_list = nodes.bullet_list()\n282             bullet_list += fulllist.children[index:endindex]\n283             newnode += addnodes.hlistcol('', bullet_list)\n284             index = endindex\n285         return [newnode]\n286 \n287 \n288 class Only(SphinxDirective):\n289     \"\"\"\n290     Directive to only include text if the given tag(s) are enabled.\n291     \"\"\"\n292     has_content = True\n293     required_arguments = 1\n294     optional_arguments = 0\n295     final_argument_whitespace = True\n296     option_spec = {}  # type: Dict\n297 \n298     def run(self) -> List[Node]:\n299         node = addnodes.only()\n300         node.document = self.state.document\n301         self.set_source_info(node)\n302         node['expr'] = self.arguments[0]\n303 \n304         # Same as util.nested_parse_with_titles but try to handle nested\n305         # sections which should be raised higher up the doctree.\n306         memo = self.state.memo  # type: Any\n307         surrounding_title_styles = memo.title_styles\n308         surrounding_section_level = memo.section_level\n309         memo.title_styles = []\n310         memo.section_level = 0\n311         try:\n312             self.state.nested_parse(self.content, self.content_offset,\n313                                     node, match_titles=True)\n314             title_styles = memo.title_styles\n315             if (not surrounding_title_styles or\n316                     not title_styles or\n317                     title_styles[0] not in surrounding_title_styles or\n318                     not self.state.parent):\n319                 # No nested sections so no special handling needed.\n320                 return [node]\n321             # Calculate the depths of the current and nested sections.\n322             current_depth = 0\n323             parent = self.state.parent\n324             while parent:\n325                 current_depth += 1\n326                 parent = parent.parent\n327             current_depth -= 2\n328             title_style = title_styles[0]\n329             nested_depth = len(surrounding_title_styles)\n330             if title_style in surrounding_title_styles:\n331                 nested_depth = surrounding_title_styles.index(title_style)\n332             # Use these depths to determine where the nested sections should\n333             # be placed in the doctree.\n334             n_sects_to_raise = current_depth - nested_depth + 1\n335             parent = cast(nodes.Element, self.state.parent)\n336             for i in range(n_sects_to_raise):\n337                 if parent.parent:\n338                     parent = parent.parent\n339             parent.append(node)\n340             return []\n341         finally:\n342             memo.title_styles = surrounding_title_styles\n343             memo.section_level = surrounding_section_level\n344 \n345 \n346 class Include(BaseInclude, SphinxDirective):\n347     \"\"\"\n348     Like the standard \"Include\" directive, but interprets absolute paths\n349     \"correctly\", i.e. relative to source directory.\n350     \"\"\"\n351 \n352     def run(self) -> List[Node]:\n353         if self.arguments[0].startswith('<') and \\\n354            self.arguments[0].endswith('>'):\n355             # docutils \"standard\" includes, do not do path processing\n356             return super().run()\n357         rel_filename, filename = self.env.relfn2path(self.arguments[0])\n358         self.arguments[0] = filename\n359         self.env.note_included(filename)\n360         return super().run()\n361 \n362 \n363 # Import old modules here for compatibility\n364 from sphinx.domains.index import IndexDirective  # NOQA\n365 \n366 deprecated_alias('sphinx.directives.other',\n367                  {\n368                      'Index': IndexDirective,\n369                  },\n370                  RemovedInSphinx40Warning,\n371                  {\n372                      'Index': 'sphinx.domains.index.IndexDirective',\n373                  })\n374 \n375 \n376 def setup(app: \"Sphinx\") -> Dict[str, Any]:\n377     directives.register_directive('toctree', TocTree)\n378     directives.register_directive('sectionauthor', Author)\n379     directives.register_directive('moduleauthor', Author)\n380     directives.register_directive('codeauthor', Author)\n381     directives.register_directive('seealso', SeeAlso)\n382     directives.register_directive('tabularcolumns', TabularColumns)\n383     directives.register_directive('centered', Centered)\n384     directives.register_directive('acks', Acks)\n385     directives.register_directive('hlist', HList)\n386     directives.register_directive('only', Only)\n387     directives.register_directive('include', Include)\n388 \n389     # register the standard rst class directive under a different name\n390     # only for backwards compatibility now\n391     directives.register_directive('cssclass', Class)\n392     # new standard name when default-domain with \"class\" is in effect\n393     directives.register_directive('rst-class', Class)\n394 \n395     return {\n396         'version': 'builtin',\n397         'parallel_read_safe': True,\n398         'parallel_write_safe': True,\n399     }\n",
        "intended_behavior": "The processing of file paths in directives, specifically the `:download:` directive and potentially figure directives as well, needs to include a normalization step. By applying `os.path.normpath()` or a similar approach to the file paths as they are processed, Sphinx can ensure that different string representations of the same path are recognized as the same file. This will prevent the generation of duplicate files in the build output. The normalization should occur before any path comparison or file handling operation to ensure that the intended resources are uniquely identified and managed across the documentation build process."
    },
    {
        "rel_file_path": "sphinx/environment/__init__.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/sphinx-doc__sphinx/setup_sphinx-doc__sphinx__3.5/sphinx/environment/__init__.py",
        "start": 297,
        "end": 313,
        "class_name": "BuildEnvironment",
        "method_name": "merge_info_from",
        "code": "297     def merge_info_from(self, docnames: List[str], other: \"BuildEnvironment\",\n298                         app: \"Sphinx\") -> None:\n299         \"\"\"Merge global information gathered about *docnames* while reading them\n300         from the *other* environment.\n301 \n302         This possibly comes from a parallel build process.\n303         \"\"\"\n304         docnames = set(docnames)  # type: ignore\n305         for docname in docnames:\n306             self.all_docs[docname] = other.all_docs[docname]\n307             self.included[docname] = other.included[docname]\n308             if docname in other.reread_always:\n309                 self.reread_always.add(docname)\n310 \n311         for domainname, domain in self.domains.items():\n312             domain.merge_domaindata(docnames, other.domaindata[domainname])\n313         self.events.emit('env-merge-info', self, docnames, other)\n",
        "intended_behavior": "In the context of merging environment information, especially from documents processed in parallel, implement path normalization to ensure consistent path representation. This will aid in the accurate merging of document information and prevent the interpretation of identical file paths as different due to discrepancies in their string representations. The normalization process should be integrated into the handling of resource-related paths, ensuring that resources are uniquely referenced and preventing the creation of duplicates in the build output."
    },
    {
        "rel_file_path": "sphinx/environment/__init__.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/sphinx-doc__sphinx/setup_sphinx-doc__sphinx__3.5/sphinx/environment/__init__.py",
        "start": 83,
        "end": 659,
        "class_name": "BuildEnvironment",
        "method_name": null,
        "code": "83 class BuildEnvironment:\n84     \"\"\"\n85     The environment in which the ReST files are translated.\n86     Stores an inventory of cross-file targets and provides doctree\n87     transformations to resolve links to them.\n88     \"\"\"\n89 \n90     domains = None  # type: Dict[str, Domain]\n91 \n92     # --------- ENVIRONMENT INITIALIZATION -------------------------------------\n93 \n94     def __init__(self, app: \"Sphinx\" = None):\n95         self.app = None                  # type: Sphinx\n96         self.doctreedir = None           # type: str\n97         self.srcdir = None               # type: str\n98         self.config = None               # type: Config\n99         self.config_status = None        # type: int\n100         self.config_status_extra = None  # type: str\n101         self.events = None               # type: EventManager\n102         self.project = None              # type: Project\n103         self.version = None              # type: Dict[str, str]\n104 \n105         # the method of doctree versioning; see set_versioning_method\n106         self.versioning_condition = None  # type: Union[bool, Callable]\n107         self.versioning_compare = None  # type: bool\n108 \n109         # all the registered domains, set by the application\n110         self.domains = {}\n111 \n112         # the docutils settings for building\n113         self.settings = default_settings.copy()\n114         self.settings['env'] = self\n115 \n116         # All \"docnames\" here are /-separated and relative and exclude\n117         # the source suffix.\n118 \n119         self.all_docs = {}          # type: Dict[str, float]\n120                                     # docname -> mtime at the time of reading\n121                                     # contains all read docnames\n122         self.dependencies = defaultdict(set)    # type: Dict[str, Set[str]]\n123                                     # docname -> set of dependent file\n124                                     # names, relative to documentation root\n125         self.included = defaultdict(set)        # type: Dict[str, Set[str]]\n126                                     # docname -> set of included file\n127                                     # docnames included from other documents\n128         self.reread_always = set()  # type: Set[str]\n129                                     # docnames to re-read unconditionally on\n130                                     # next build\n131 \n132         # File metadata\n133         self.metadata = defaultdict(dict)       # type: Dict[str, Dict[str, Any]]\n134                                                 # docname -> dict of metadata items\n135 \n136         # TOC inventory\n137         self.titles = {}            # type: Dict[str, nodes.title]\n138                                     # docname -> title node\n139         self.longtitles = {}        # type: Dict[str, nodes.title]\n140                                     # docname -> title node; only different if\n141                                     # set differently with title directive\n142         self.tocs = {}              # type: Dict[str, nodes.bullet_list]\n143                                     # docname -> table of contents nodetree\n144         self.toc_num_entries = {}   # type: Dict[str, int]\n145                                     # docname -> number of real entries\n146 \n147         # used to determine when to show the TOC\n148         # in a sidebar (don't show if it's only one item)\n149         self.toc_secnumbers = {}    # type: Dict[str, Dict[str, Tuple[int, ...]]]\n150                                     # docname -> dict of sectionid -> number\n151         self.toc_fignumbers = {}    # type: Dict[str, Dict[str, Dict[str, Tuple[int, ...]]]]\n152                                     # docname -> dict of figtype ->\n153                                     # dict of figureid -> number\n154 \n155         self.toctree_includes = {}  # type: Dict[str, List[str]]\n156                                     # docname -> list of toctree includefiles\n157         self.files_to_rebuild = {}  # type: Dict[str, Set[str]]\n158                                     # docname -> set of files\n159                                     # (containing its TOCs) to rebuild too\n160         self.glob_toctrees = set()  # type: Set[str]\n161                                     # docnames that have :glob: toctrees\n162         self.numbered_toctrees = set()  # type: Set[str]\n163                                         # docnames that have :numbered: toctrees\n164 \n165         # domain-specific inventories, here to be pickled\n166         self.domaindata = {}        # type: Dict[str, Dict]\n167                                     # domainname -> domain-specific dict\n168 \n169         # these map absolute path -> (docnames, unique filename)\n170         self.images = FilenameUniqDict()    # type: FilenameUniqDict\n171         self.dlfiles = DownloadFiles()      # type: DownloadFiles\n172                                             # filename -> (set of docnames, destination)\n173 \n174         # the original URI for images\n175         self.original_image_uri = {}  # type: Dict[str, str]\n176 \n177         # temporary data storage while reading a document\n178         self.temp_data = {}         # type: Dict[str, Any]\n179         # context for cross-references (e.g. current module or class)\n180         # this is similar to temp_data, but will for example be copied to\n181         # attributes of \"any\" cross references\n182         self.ref_context = {}       # type: Dict[str, Any]\n183 \n184         # set up environment\n185         if app:\n186             self.setup(app)\n187 \n188     def __getstate__(self) -> Dict:\n189         \"\"\"Obtains serializable data for pickling.\"\"\"\n190         __dict__ = self.__dict__.copy()\n191         __dict__.update(app=None, domains={}, events=None)  # clear unpickable attributes\n192         return __dict__\n193 \n194     def __setstate__(self, state: Dict) -> None:\n195         self.__dict__.update(state)\n196 \n197     def setup(self, app: \"Sphinx\") -> None:\n198         \"\"\"Set up BuildEnvironment object.\"\"\"\n199         if self.version and self.version != app.registry.get_envversion(app):\n200             raise BuildEnvironmentError(__('build environment version not current'))\n201         elif self.srcdir and self.srcdir != app.srcdir:\n202             raise BuildEnvironmentError(__('source directory has changed'))\n203 \n204         if self.project:\n205             app.project.restore(self.project)\n206 \n207         self.app = app\n208         self.doctreedir = app.doctreedir\n209         self.events = app.events\n210         self.srcdir = app.srcdir\n211         self.project = app.project\n212         self.version = app.registry.get_envversion(app)\n213 \n214         # initialize domains\n215         self.domains = {}\n216         for domain in app.registry.create_domains(self):\n217             self.domains[domain.name] = domain\n218 \n219         # setup domains (must do after all initialization)\n220         for domain in self.domains.values():\n221             domain.setup()\n222 \n223         # initialize config\n224         self._update_config(app.config)\n225 \n226         # initialie settings\n227         self._update_settings(app.config)\n228 \n229     def _update_config(self, config: Config) -> None:\n230         \"\"\"Update configurations by new one.\"\"\"\n231         self.config_status = CONFIG_OK\n232         self.config_status_extra = ''\n233         if self.config is None:\n234             self.config_status = CONFIG_NEW\n235         elif self.config.extensions != config.extensions:\n236             self.config_status = CONFIG_EXTENSIONS_CHANGED\n237             extensions = sorted(\n238                 set(self.config.extensions) ^ set(config.extensions))\n239             if len(extensions) == 1:\n240                 extension = extensions[0]\n241             else:\n242                 extension = '%d' % (len(extensions),)\n243             self.config_status_extra = ' (%r)' % (extension,)\n244         else:\n245             # check if a config value was changed that affects how\n246             # doctrees are read\n247             for item in config.filter('env'):\n248                 if self.config[item.name] != item.value:\n249                     self.config_status = CONFIG_CHANGED\n250                     self.config_status_extra = ' (%r)' % (item.name,)\n251                     break\n252 \n253         self.config = config\n254 \n255     def _update_settings(self, config: Config) -> None:\n256         \"\"\"Update settings by new config.\"\"\"\n257         self.settings['input_encoding'] = config.source_encoding\n258         self.settings['trim_footnote_reference_space'] = config.trim_footnote_reference_space\n259         self.settings['language_code'] = config.language or 'en'\n260 \n261         # Allow to disable by 3rd party extension (workaround)\n262         self.settings.setdefault('smart_quotes', True)\n263 \n264     def set_versioning_method(self, method: Union[str, Callable], compare: bool) -> None:\n265         \"\"\"This sets the doctree versioning method for this environment.\n266 \n267         Versioning methods are a builder property; only builders with the same\n268         versioning method can share the same doctree directory.  Therefore, we\n269         raise an exception if the user tries to use an environment with an\n270         incompatible versioning method.\n271         \"\"\"\n272         condition = None  # type: Union[bool, Callable]\n273         if callable(method):\n274             condition = method\n275         else:\n276             if method not in versioning_conditions:\n277                 raise ValueError('invalid versioning method: %r' % method)\n278             condition = versioning_conditions[method]\n279 \n280         if self.versioning_condition not in (None, condition):\n281             raise SphinxError(__('This environment is incompatible with the '\n282                                  'selected builder, please choose another '\n283                                  'doctree directory.'))\n284         self.versioning_condition = condition\n285         self.versioning_compare = compare\n286 \n287     def clear_doc(self, docname: str) -> None:\n288         \"\"\"Remove all traces of a source file in the inventory.\"\"\"\n289         if docname in self.all_docs:\n290             self.all_docs.pop(docname, None)\n291             self.included.pop(docname, None)\n292             self.reread_always.discard(docname)\n293 \n294         for domain in self.domains.values():\n295             domain.clear_doc(docname)\n296 \n297     def merge_info_from(self, docnames: List[str], other: \"BuildEnvironment\",\n298                         app: \"Sphinx\") -> None:\n299         \"\"\"Merge global information gathered about *docnames* while reading them\n300         from the *other* environment.\n301 \n302         This possibly comes from a parallel build process.\n303         \"\"\"\n304         docnames = set(docnames)  # type: ignore\n305         for docname in docnames:\n306             self.all_docs[docname] = other.all_docs[docname]\n307             self.included[docname] = other.included[docname]\n308             if docname in other.reread_always:\n309                 self.reread_always.add(docname)\n310 \n311         for domainname, domain in self.domains.items():\n312             domain.merge_domaindata(docnames, other.domaindata[domainname])\n313         self.events.emit('env-merge-info', self, docnames, other)\n314 \n315     def path2doc(self, filename: str) -> str:\n316         \"\"\"Return the docname for the filename if the file is document.\n317 \n318         *filename* should be absolute or relative to the source directory.\n319         \"\"\"\n320         return self.project.path2doc(filename)\n321 \n322     def doc2path(self, docname: str, base: Union[bool, str] = True, suffix: str = None) -> str:\n323         \"\"\"Return the filename for the document name.\n324 \n325         If *base* is True, return absolute path under self.srcdir.\n326         If *base* is None, return relative path to self.srcdir.\n327         If *base* is a path string, return absolute path under that.\n328         If *suffix* is not None, add it instead of config.source_suffix.\n329         \"\"\"\n330         if suffix:\n331             warnings.warn('The suffix argument for doc2path() is deprecated.',\n332                           RemovedInSphinx40Warning, stacklevel=2)\n333         if base not in (True, False, None):\n334             warnings.warn('The string style base argument for doc2path() is deprecated.',\n335                           RemovedInSphinx40Warning, stacklevel=2)\n336 \n337         pathname = self.project.doc2path(docname, base is True)\n338         if suffix:\n339             filename, _ = path.splitext(pathname)\n340             pathname = filename + suffix\n341         if base and base is not True:\n342             pathname = path.join(base, pathname)  # type: ignore\n343         return pathname\n344 \n345     def relfn2path(self, filename: str, docname: str = None) -> Tuple[str, str]:\n346         \"\"\"Return paths to a file referenced from a document, relative to\n347         documentation root and absolute.\n348 \n349         In the input \"filename\", absolute filenames are taken as relative to the\n350         source dir, while relative filenames are relative to the dir of the\n351         containing document.\n352         \"\"\"\n353         if filename.startswith('/') or filename.startswith(os.sep):\n354             rel_fn = filename[1:]\n355         else:\n356             docdir = path.dirname(self.doc2path(docname or self.docname,\n357                                                 base=None))\n358             rel_fn = path.join(docdir, filename)\n359         # the path.abspath() might seem redundant, but otherwise artifacts\n360         # such as \"..\" will remain in the path\n361         return rel_fn, path.abspath(path.join(self.srcdir, rel_fn))\n362 \n363     @property\n364     def found_docs(self) -> Set[str]:\n365         \"\"\"contains all existing docnames.\"\"\"\n366         return self.project.docnames\n367 \n368     def find_files(self, config: Config, builder: \"Builder\") -> None:\n369         \"\"\"Find all source files in the source dir and put them in\n370         self.found_docs.\n371         \"\"\"\n372         try:\n373             exclude_paths = (self.config.exclude_patterns +\n374                              self.config.templates_path +\n375                              builder.get_asset_paths())\n376             self.project.discover(exclude_paths)\n377 \n378             # Current implementation is applying translated messages in the reading\n379             # phase.Therefore, in order to apply the updated message catalog, it is\n380             # necessary to re-process from the reading phase. Here, if dependency\n381             # is set for the doc source and the mo file, it is processed again from\n382             # the reading phase when mo is updated. In the future, we would like to\n383             # move i18n process into the writing phase, and remove these lines.\n384             if builder.use_message_catalog:\n385                 # add catalog mo file dependency\n386                 repo = CatalogRepository(self.srcdir, self.config.locale_dirs,\n387                                          self.config.language, self.config.source_encoding)\n388                 mo_paths = {c.domain: c.mo_path for c in repo.catalogs}\n389                 for docname in self.found_docs:\n390                     domain = docname_to_domain(docname, self.config.gettext_compact)\n391                     if domain in mo_paths:\n392                         self.dependencies[docname].add(mo_paths[domain])\n393         except OSError as exc:\n394             raise DocumentError(__('Failed to scan documents in %s: %r') %\n395                                 (self.srcdir, exc)) from exc\n396 \n397     def get_outdated_files(self, config_changed: bool) -> Tuple[Set[str], Set[str], Set[str]]:\n398         \"\"\"Return (added, changed, removed) sets.\"\"\"\n399         # clear all files no longer present\n400         removed = set(self.all_docs) - self.found_docs\n401 \n402         added = set()  # type: Set[str]\n403         changed = set()  # type: Set[str]\n404 \n405         if config_changed:\n406             # config values affect e.g. substitutions\n407             added = self.found_docs\n408         else:\n409             for docname in self.found_docs:\n410                 if docname not in self.all_docs:\n411                     added.add(docname)\n412                     continue\n413                 # if the doctree file is not there, rebuild\n414                 filename = path.join(self.doctreedir, docname + '.doctree')\n415                 if not path.isfile(filename):\n416                     changed.add(docname)\n417                     continue\n418                 # check the \"reread always\" list\n419                 if docname in self.reread_always:\n420                     changed.add(docname)\n421                     continue\n422                 # check the mtime of the document\n423                 mtime = self.all_docs[docname]\n424                 newmtime = path.getmtime(self.doc2path(docname))\n425                 if newmtime > mtime:\n426                     changed.add(docname)\n427                     continue\n428                 # finally, check the mtime of dependencies\n429                 for dep in self.dependencies[docname]:\n430                     try:\n431                         # this will do the right thing when dep is absolute too\n432                         deppath = path.join(self.srcdir, dep)\n433                         if not path.isfile(deppath):\n434                             changed.add(docname)\n435                             break\n436                         depmtime = path.getmtime(deppath)\n437                         if depmtime > mtime:\n438                             changed.add(docname)\n439                             break\n440                     except OSError:\n441                         # give it another chance\n442                         changed.add(docname)\n443                         break\n444 \n445         return added, changed, removed\n446 \n447     def check_dependents(self, app: \"Sphinx\", already: Set[str]) -> Generator[str, None, None]:\n448         to_rewrite = []  # type: List[str]\n449         for docnames in self.events.emit('env-get-updated', self):\n450             to_rewrite.extend(docnames)\n451         for docname in set(to_rewrite):\n452             if docname not in already:\n453                 yield docname\n454 \n455     # --------- SINGLE FILE READING --------------------------------------------\n456 \n457     def prepare_settings(self, docname: str) -> None:\n458         \"\"\"Prepare to set up environment for reading.\"\"\"\n459         self.temp_data['docname'] = docname\n460         # defaults to the global default, but can be re-set in a document\n461         self.temp_data['default_role'] = self.config.default_role\n462         self.temp_data['default_domain'] = \\\n463             self.domains.get(self.config.primary_domain)\n464 \n465     # utilities to use while reading a document\n466 \n467     @property\n468     def docname(self) -> str:\n469         \"\"\"Returns the docname of the document currently being parsed.\"\"\"\n470         return self.temp_data['docname']\n471 \n472     def new_serialno(self, category: str = '') -> int:\n473         \"\"\"Return a serial number, e.g. for index entry targets.\n474 \n475         The number is guaranteed to be unique in the current document.\n476         \"\"\"\n477         key = category + 'serialno'\n478         cur = self.temp_data.get(key, 0)\n479         self.temp_data[key] = cur + 1\n480         return cur\n481 \n482     def note_dependency(self, filename: str) -> None:\n483         \"\"\"Add *filename* as a dependency of the current document.\n484 \n485         This means that the document will be rebuilt if this file changes.\n486 \n487         *filename* should be absolute or relative to the source directory.\n488         \"\"\"\n489         self.dependencies[self.docname].add(filename)\n490 \n491     def note_included(self, filename: str) -> None:\n492         \"\"\"Add *filename* as a included from other document.\n493 \n494         This means the document is not orphaned.\n495 \n496         *filename* should be absolute or relative to the source directory.\n497         \"\"\"\n498         self.included[self.docname].add(self.path2doc(filename))\n499 \n500     def note_reread(self) -> None:\n501         \"\"\"Add the current document to the list of documents that will\n502         automatically be re-read at the next build.\n503         \"\"\"\n504         self.reread_always.add(self.docname)\n505 \n506     def get_domain(self, domainname: str) -> Domain:\n507         \"\"\"Return the domain instance with the specified name.\n508 \n509         Raises an ExtensionError if the domain is not registered.\n510         \"\"\"\n511         try:\n512             return self.domains[domainname]\n513         except KeyError as exc:\n514             raise ExtensionError(__('Domain %r is not registered') % domainname) from exc\n515 \n516     # --------- RESOLVING REFERENCES AND TOCTREES ------------------------------\n517 \n518     def get_doctree(self, docname: str) -> nodes.document:\n519         \"\"\"Read the doctree for a file from the pickle and return it.\"\"\"\n520         filename = path.join(self.doctreedir, docname + '.doctree')\n521         with open(filename, 'rb') as f:\n522             doctree = pickle.load(f)\n523         doctree.settings.env = self\n524         doctree.reporter = LoggingReporter(self.doc2path(docname))\n525         return doctree\n526 \n527     def get_and_resolve_doctree(self, docname: str, builder: \"Builder\",\n528                                 doctree: nodes.document = None, prune_toctrees: bool = True,\n529                                 includehidden: bool = False) -> nodes.document:\n530         \"\"\"Read the doctree from the pickle, resolve cross-references and\n531         toctrees and return it.\n532         \"\"\"\n533         if doctree is None:\n534             doctree = self.get_doctree(docname)\n535 \n536         # resolve all pending cross-references\n537         self.apply_post_transforms(doctree, docname)\n538 \n539         # now, resolve all toctree nodes\n540         for toctreenode in doctree.traverse(addnodes.toctree):\n541             result = TocTree(self).resolve(docname, builder, toctreenode,\n542                                            prune=prune_toctrees,\n543                                            includehidden=includehidden)\n544             if result is None:\n545                 toctreenode.replace_self([])\n546             else:\n547                 toctreenode.replace_self(result)\n548 \n549         return doctree\n550 \n551     def resolve_toctree(self, docname: str, builder: \"Builder\", toctree: addnodes.toctree,\n552                         prune: bool = True, maxdepth: int = 0, titles_only: bool = False,\n553                         collapse: bool = False, includehidden: bool = False) -> Node:\n554         \"\"\"Resolve a *toctree* node into individual bullet lists with titles\n555         as items, returning None (if no containing titles are found) or\n556         a new node.\n557 \n558         If *prune* is True, the tree is pruned to *maxdepth*, or if that is 0,\n559         to the value of the *maxdepth* option on the *toctree* node.\n560         If *titles_only* is True, only toplevel document titles will be in the\n561         resulting tree.\n562         If *collapse* is True, all branches not containing docname will\n563         be collapsed.\n564         \"\"\"\n565         return TocTree(self).resolve(docname, builder, toctree, prune,\n566                                      maxdepth, titles_only, collapse,\n567                                      includehidden)\n568 \n569     def resolve_references(self, doctree: nodes.document, fromdocname: str,\n570                            builder: \"Builder\") -> None:\n571         self.apply_post_transforms(doctree, fromdocname)\n572 \n573     def apply_post_transforms(self, doctree: nodes.document, docname: str) -> None:\n574         \"\"\"Apply all post-transforms.\"\"\"\n575         try:\n576             # set env.docname during applying post-transforms\n577             backup = copy(self.temp_data)\n578             self.temp_data['docname'] = docname\n579 \n580             transformer = SphinxTransformer(doctree)\n581             transformer.set_environment(self)\n582             transformer.add_transforms(self.app.registry.get_post_transforms())\n583             transformer.apply_transforms()\n584         finally:\n585             self.temp_data = backup\n586 \n587         # allow custom references to be resolved\n588         self.events.emit('doctree-resolved', doctree, docname)\n589 \n590     def collect_relations(self) -> Dict[str, List[str]]:\n591         traversed = set()\n592 \n593         def traverse_toctree(parent: str, docname: str) -> Iterator[Tuple[str, str]]:\n594             if parent == docname:\n595                 logger.warning(__('self referenced toctree found. Ignored.'),\n596                                location=docname, type='toc',\n597                                subtype='circular')\n598                 return\n599 \n600             # traverse toctree by pre-order\n601             yield parent, docname\n602             traversed.add(docname)\n603 \n604             for child in (self.toctree_includes.get(docname) or []):\n605                 for subparent, subdocname in traverse_toctree(docname, child):\n606                     if subdocname not in traversed:\n607                         yield subparent, subdocname\n608                         traversed.add(subdocname)\n609 \n610         relations = {}\n611         docnames = traverse_toctree(None, self.config.master_doc)\n612         prevdoc = None\n613         parent, docname = next(docnames)\n614         for nextparent, nextdoc in docnames:\n615             relations[docname] = [parent, prevdoc, nextdoc]\n616             prevdoc = docname\n617             docname = nextdoc\n618             parent = nextparent\n619 \n620         relations[docname] = [parent, prevdoc, None]\n621 \n622         return relations\n623 \n624     def check_consistency(self) -> None:\n625         \"\"\"Do consistency checks.\"\"\"\n626         included = set().union(*self.included.values())  # type: ignore\n627         for docname in sorted(self.all_docs):\n628             if docname not in self.files_to_rebuild:\n629                 if docname == self.config.master_doc:\n630                     # the master file is not included anywhere ;)\n631                     continue\n632                 if docname in included:\n633                     # the document is included from other documents\n634                     continue\n635                 if 'orphan' in self.metadata[docname]:\n636                     continue\n637                 logger.warning(__('document isn\\'t included in any toctree'),\n638                                location=docname)\n639 \n640         # call check-consistency for all extensions\n641         for domain in self.domains.values():\n642             domain.check_consistency()\n643         self.events.emit('env-check-consistency', self)\n644 \n645     @property\n646     def indexentries(self) -> Dict[str, List[Tuple[str, str, str, str, str]]]:\n647         warnings.warn('env.indexentries() is deprecated. Please use IndexDomain instead.',\n648                       RemovedInSphinx40Warning, stacklevel=2)\n649         from sphinx.domains.index import IndexDomain\n650         domain = cast(IndexDomain, self.get_domain('index'))\n651         return domain.entries\n652 \n653     @indexentries.setter\n654     def indexentries(self, entries: Dict[str, List[Tuple[str, str, str, str, str]]]) -> None:\n655         warnings.warn('env.indexentries() is deprecated. Please use IndexDomain instead.',\n656                       RemovedInSphinx40Warning, stacklevel=2)\n657         from sphinx.domains.index import IndexDomain\n658         domain = cast(IndexDomain, self.get_domain('index'))\n659         domain.data['entries'] = entries\n",
        "intended_behavior": "This class provides additional context to the issue."
    }
]