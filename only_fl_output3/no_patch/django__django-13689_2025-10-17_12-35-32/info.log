2025-10-17 12:35:32.242 | INFO     | Starting overall retry 0 with model gpt-4-0125-preview
2025-10-17 12:35:36.965 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=295, output_tokens=12, cost=0.003310
2025-10-17 12:35:36.972 | INFO     | Test agent decides that the issue statement does not contain reproduction steps; skipping reproducer tracing
2025-10-17 12:35:36.976 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-17 12:35:48.705 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=580, output_tokens=463, cost=0.019690
2025-10-17 12:35:48.714 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-17 12:35:51.537 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=817, output_tokens=59, cost=0.009940
2025-10-17 12:35:51.539 | DEBUG    | Extracted a valid json.
2025-10-17 12:35:51.539 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_class(\"SQLCompiler\")",
        "search_class(\"Query\")",
        "search_class(\"ExpressionWrapper\")",
        "search_method(\"Count\")",
        "search_code(\"GROUP BY\")"
    ],
    "bug_locations": []
}
2025-10-17 12:35:51.646 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-17 12:35:51.647 | DEBUG    | <Agent search> Analyzing search results.
2025-10-17 12:36:12.166 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=3149, output_tokens=852, cost=0.057050
2025-10-17 12:36:12.183 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-17 12:36:20.949 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=4217, output_tokens=377, cost=0.053480
2025-10-17 12:36:20.957 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-17 12:36:28.978 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=731, output_tokens=317, cost=0.016820
2025-10-17 12:36:28.979 | DEBUG    | Extracted a valid json.
2025-10-17 12:36:28.980 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [],
    "bug_locations":[
        {
            "file": "django/db/models/sql/compiler.py",
            "class": "SQLCompiler",
            "method": "get_group_by",
            "intended_behavior": "This method should ensure that when it compiles the GROUP BY clauses for SQL queries, it fully accounts for and includes expressions wrapped by ExpressionWrapper, especially those that transform field values, such as IS NULL checks or boolean evaluations. The intended behavior is to modify or ensure the method accurately represents all parts of the ORM query in the SQL command, especially expressions that might not directly map to a single database column or simple SQL expressions. This must maintain the current functionality for other use cases and only augment the handling of special cases like expression wrappers that evaluate to boolean conditions or perform null checks."
        },
        {
            "file": "django/db/models/expressions.py",
            "class": "ExpressionWrapper",
            "method": "get_group_by_cols",
            "intended_behavior": "The intended behavior for this method is to ensure that ExpressionWrapper correctly informs the SQL compiler about how its contained expressions should influence the GROUP BY clause in SQL queries. Specifically, for boolean expressions or null checks encapsulated by an ExpressionWrapper, the method must ensure that the SQL compiler can translate and include these expressions accurately in the GROUP BY clause. This might involve providing additional metadata or flags from ExpressionWrapper to the compiler or ensuring that ExpressionWrapper's as_sql method or similar methods provide the necessary SQL correctly for grouping purposes."
        }
    ]
}
2025-10-17 12:36:28.991 | DEBUG    | Found override of get_group_by_cols in BaseExpression
2025-10-17 12:36:28.991 | ERROR    | SearchBackend.search_method_in_class() missing 1 required positional argument: 'class_name'
Traceback (most recent call last):

  File "/home/kimnal0/auto-code-rover/app/main.py", line 656, in <module>
    main()
    └ <function main at 0x7ea0c4f22c00>

  File "/home/kimnal0/auto-code-rover/app/main.py", line 120, in main
    run_task_groups(groups, num_processes, organize_output=True)
    │               │       └ 1
    │               └ {'setup_astropy__astropy__4.3': [<app.raw_tasks.RawSweTask object at 0x7e9fd295fb00>, <app.raw_tasks.RawSweTask object at 0x7...
    └ <function run_task_groups at 0x7e9fd4b7b240>

  File "/home/kimnal0/auto-code-rover/app/main.py", line 396, in run_task_groups
    run_tasks_serial(all_tasks)
    │                └ [<app.raw_tasks.RawSweTask object at 0x7e9fd295fb00>, <app.raw_tasks.RawSweTask object at 0x7e9fd295fb30>, <app.raw_tasks.Raw...
    └ <function run_tasks_serial at 0x7e9fd4b7b2e0>

  File "/home/kimnal0/auto-code-rover/app/main.py", line 414, in run_tasks_serial
    run_task_in_subprocess(task)
    │                      └ <app.raw_tasks.RawSweTask object at 0x7e9fd26e2120>
    └ <function run_task_in_subprocess at 0x7e9fd4b7b4c0>

  File "/home/kimnal0/auto-code-rover/app/main.py", line 462, in run_task_in_subprocess
    executor.submit(run_raw_task, task)
    │        │      │             └ <app.raw_tasks.RawSweTask object at 0x7e9fd26e2120>
    │        │      └ <function run_raw_task at 0x7e9fd4b7b560>
    │        └ <function ProcessPoolExecutor.submit at 0x7ea0c4842020>
    └ <concurrent.futures.process.ProcessPoolExecutor object at 0x7e9fd5a2e120>

  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/concurrent/futures/process.py", line 831, in submit
    self._start_executor_manager_thread()
    │    └ <function ProcessPoolExecutor._start_executor_manager_thread at 0x7ea0c4841da0>
    └ <concurrent.futures.process.ProcessPoolExecutor object at 0x7e9fd5a2e120>
  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/concurrent/futures/process.py", line 770, in _start_executor_manager_thread
    self._launch_processes()
    │    └ <function ProcessPoolExecutor._launch_processes at 0x7ea0c4841ee0>
    └ <concurrent.futures.process.ProcessPoolExecutor object at 0x7e9fd5a2e120>
  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/concurrent/futures/process.py", line 797, in _launch_processes
    self._spawn_process()
    │    └ <function ProcessPoolExecutor._spawn_process at 0x7ea0c4841f80>
    └ <concurrent.futures.process.ProcessPoolExecutor object at 0x7e9fd5a2e120>
  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/concurrent/futures/process.py", line 807, in _spawn_process
    p.start()
    │ └ <function BaseProcess.start at 0x7ea0c4a04ea0>
    └ <ForkProcess name='ForkProcess-140' parent=307479 started>
  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
    │    │        │    │      └ <ForkProcess name='ForkProcess-140' parent=307479 started>
    │    │        │    └ <staticmethod(<function ForkProcess._Popen at 0x7ea0c4a760c0>)>
    │    │        └ <ForkProcess name='ForkProcess-140' parent=307479 started>
    │    └ None
    └ <ForkProcess name='ForkProcess-140' parent=307479 started>
  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/multiprocessing/context.py", line 282, in _Popen
    return Popen(process_obj)
           │     └ <ForkProcess name='ForkProcess-140' parent=307479 started>
           └ <class 'multiprocessing.popen_fork.Popen'>
  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
    │    │       └ <ForkProcess name='ForkProcess-140' parent=307479 started>
    │    └ <function Popen._launch at 0x7e9fd2ad4ea0>
    └ <multiprocessing.popen_fork.Popen object at 0x7e9fd314e450>
  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
           │           │                          └ 13
           │           └ <function BaseProcess._bootstrap at 0x7ea0c4a058a0>
           └ <ForkProcess name='ForkProcess-140' parent=307479 started>
  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
    │    └ <function BaseProcess.run at 0x7ea0c4a04e00>
    └ <ForkProcess name='ForkProcess-140' parent=307479 started>
  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <ForkProcess name='ForkProcess-140' parent=307479 started>
    │    │        │    └ (<concurrent.futures.process._SafeQueue object at 0x7e9fd3865070>, <multiprocessing.queues.SimpleQueue object at 0x7e9fd2b91f...
    │    │        └ <ForkProcess name='ForkProcess-140' parent=307479 started>
    │    └ <function _process_worker at 0x7ea0c48411c0>
    └ <ForkProcess name='ForkProcess-140' parent=307479 started>
  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/concurrent/futures/process.py", line 263, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
        │         │   │         │       │         └ {}
        │         │   │         │       └ <concurrent.futures.process._CallItem object at 0x7e9fd4fdd670>
        │         │   │         └ (<app.raw_tasks.RawSweTask object at 0x7e9fd314c650>,)
        │         │   └ <concurrent.futures.process._CallItem object at 0x7e9fd4fdd670>
        │         └ <function run_raw_task at 0x7e9fd4b7b560>
        └ <concurrent.futures.process._CallItem object at 0x7e9fd4fdd670>

  File "/home/kimnal0/auto-code-rover/app/main.py", line 494, in run_raw_task
    run_ok = do_inference(task.to_task(), task_output_dir)
             │            │    │          └ '/home/kimnal0/auto-code-rover/only_fl_output3/django__django-13689_2025-10-17_12-35-32'
             │            │    └ <function RawSweTask.to_task at 0x7e9fd4b7a520>
             │            └ <app.raw_tasks.RawSweTask object at 0x7e9fd314c650>
             └ <function do_inference at 0x7e9fd4b7b740>

  File "/home/kimnal0/auto-code-rover/app/main.py", line 590, in do_inference
    run_ok = inference.run_one_task(
             │         └ <function run_one_task at 0x7e9fd4bd5080>
             └ <module 'app.inference' from '/home/kimnal0/auto-code-rover/app/inference.py'>

  File "/home/kimnal0/auto-code-rover/app/inference.py", line 128, in run_one_task
    if _run_one_task(str(out_dir), api_manager, task.get_issue_statement()):
       │                 │         │            │    └ <function SweTask.get_issue_statement at 0x7e9fd5360ae0>
       │                 │         │            └ SweTask(task_id='django__django-13689', problem_statement='Aggregating when grouping on an ExpressionWrapper omits the expres...
       │                 │         └ <app.manage.ProjectApiManager object at 0x7e9fd314fd10>
       │                 └ Path('/home/kimnal0/auto-code-rover/only_fl_output3/django__django-13689_2025-10-17_12-35-32/output_0')
       └ <function _run_one_task at 0x7e9fd4bd6660>

  File "/home/kimnal0/auto-code-rover/app/inference.py", line 303, in _run_one_task
    bug_locs, search_msg_thread = api_manager.search_manager.search_iterative(
                                  │           │              └ <function SearchManager.search_iterative at 0x7e9fd4fea840>
                                  │           └ <app.search.search_manage.SearchManager object at 0x7e9fd314ff80>
                                  └ <app.manage.ProjectApiManager object at 0x7e9fd314fd10>

  File "/home/kimnal0/auto-code-rover/app/search/search_manage.py", line 125, in search_iterative
    new_bug_locations.extend(self.backend.get_bug_loc_snippets_new(loc))
    │                 │      │    │       │                        └ {'file': 'django/db/models/expressions.py', 'class': 'ExpressionWrapper', 'method': 'get_group_by_cols', 'intended_behavior':...
    │                 │      │    │       └ <function SearchBackend.get_bug_loc_snippets_new at 0x7e9fd4fea7a0>
    │                 │      │    └ <app.search.search_backend.SearchBackend object at 0x7e9fd532bf50>
    │                 │      └ <app.search.search_manage.SearchManager object at 0x7e9fd314ff80>
    │                 └ <method 'extend' of 'list' objects>
    └ [<file>django/db/models/sql/compiler.py</file>
      <class>SQLCompiler</class>
      <method>get_group_by</method>
      <code>
      63     def get...

  File "/home/kimnal0/auto-code-rover/app/search/search_backend.py", line 825, in get_bug_loc_snippets_new
    self._get_inherited_methods(res.class_name, res.func_name)
    │    │                      │   │           │   └ 'get_group_by_cols'
    │    │                      │   │           └ SearchResult(file_path='/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.2/django/db/mo...
    │    │                      │   └ 'ExpressionWrapper'
    │    │                      └ SearchResult(file_path='/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.2/django/db/mo...
    │    └ <function SearchBackend._get_inherited_methods at 0x7e9fd4fea700>
    └ <app.search.search_backend.SearchBackend object at 0x7e9fd532bf50>

  File "/home/kimnal0/auto-code-rover/app/search/search_backend.py", line 748, in _get_inherited_methods
    output, search_res, call_ok = self.search_method_in_class(super_call)
                                  │    │                      └ {'class_name': 'BaseExpression', 'method_name': 'get_group_by_cols'}
                                  │    └ <function SearchBackend.search_method_in_class at 0x7e9fd4fe9e40>
                                  └ <app.search.search_backend.SearchBackend object at 0x7e9fd532bf50>

> File "/home/kimnal0/auto-code-rover/app/utils.py", line 343, in wrapper
    return func(*args, **kwargs)
           │     │       └ {}
           │     └ (<app.search.search_backend.SearchBackend object at 0x7e9fd532bf50>, {'class_name': 'BaseExpression', 'method_name': 'get_gro...
           └ <function SearchBackend.search_method_in_class at 0x7e9fd4fe9da0>

TypeError: SearchBackend.search_method_in_class() missing 1 required positional argument: 'class_name'
2025-10-17 12:36:28.998 | DEBUG    | Bug location extracted successfully: [<file>django/db/models/sql/compiler.py</file>
<class>SQLCompiler</class>
<method>get_group_by</method>
<code>
63     def get_group_by(self, select, order_by):
64         """
65         Return a list of 2-tuples of form (sql, params).
66 
67         The logic of what exactly the GROUP BY clause contains is hard
68         to describe in other words than "if it passes the test suite,
69         then it is correct".
70         """
71         # Some examples:
72         #     SomeModel.objects.annotate(Count('somecol'))
73         #     GROUP BY: all fields of the model
74         #
75         #    SomeModel.objects.values('name').annotate(Count('somecol'))
76         #    GROUP BY: name
77         #
78         #    SomeModel.objects.annotate(Count('somecol')).values('name')
79         #    GROUP BY: all cols of the model
80         #
81         #    SomeModel.objects.values('name', 'pk').annotate(Count('somecol')).values('pk')
82         #    GROUP BY: name, pk
83         #
84         #    SomeModel.objects.values('name').annotate(Count('somecol')).values('pk')
85         #    GROUP BY: name, pk
86         #
87         # In fact, the self.query.group_by is the minimal set to GROUP BY. It
88         # can't be ever restricted to a smaller set, but additional columns in
89         # HAVING, ORDER BY, and SELECT clauses are added to it. Unfortunately
90         # the end result is that it is impossible to force the query to have
91         # a chosen GROUP BY clause - you can almost do this by using the form:
92         #     .values(*wanted_cols).annotate(AnAggregate())
93         # but any later annotations, extra selects, values calls that
94         # refer some column outside of the wanted_cols, order_by, or even
95         # filter calls can alter the GROUP BY clause.
96 
97         # The query.group_by is either None (no GROUP BY at all), True
98         # (group by select fields), or a list of expressions to be added
99         # to the group by.
100         if self.query.group_by is None:
101             return []
102         expressions = []
103         if self.query.group_by is not True:
104             # If the group by is set to a list (by .values() call most likely),
105             # then we need to add everything in it to the GROUP BY clause.
106             # Backwards compatibility hack for setting query.group_by. Remove
107             # when  we have public API way of forcing the GROUP BY clause.
108             # Converts string references to expressions.
109             for expr in self.query.group_by:
110                 if not hasattr(expr, 'as_sql'):
111                     expressions.append(self.query.resolve_ref(expr))
112                 else:
113                     expressions.append(expr)
114         # Note that even if the group_by is set, it is only the minimal
115         # set to group by. So, we need to add cols in select, order_by, and
116         # having into the select in any case.
117         ref_sources = {
118             expr.source for expr in expressions if isinstance(expr, Ref)
119         }
120         for expr, _, _ in select:
121             # Skip members of the select clause that are already included
122             # by reference.
123             if expr in ref_sources:
124                 continue
125             cols = expr.get_group_by_cols()
126             for col in cols:
127                 expressions.append(col)
128         for expr, (sql, params, is_ref) in order_by:
129             # Skip References to the select clause, as all expressions in the
130             # select clause are already part of the group by.
131             if not is_ref:
132                 expressions.extend(expr.get_group_by_cols())
133         having_group_by = self.having.get_group_by_cols() if self.having else ()
134         for expr in having_group_by:
135             expressions.append(expr)
136         result = []
137         seen = set()
138         expressions = self.collapse_group_by(expressions, having_group_by)
139 
140         for expr in expressions:
141             sql, params = self.compile(expr)
142             sql, params = expr.select_format(self, sql, params)
143             params_hash = make_hashable(params)
144             if (sql, params_hash) not in seen:
145                 result.append((sql, params))
146                 seen.add((sql, params_hash))
147         return result

</code><intended_behavior>This method should ensure that when it compiles the GROUP BY clauses for SQL queries, it fully accounts for and includes expressions wrapped by ExpressionWrapper, especially those that transform field values, such as IS NULL checks or boolean evaluations. The intended behavior is to modify or ensure the method accurately represents all parts of the ORM query in the SQL command, especially expressions that might not directly map to a single database column or simple SQL expressions. This must maintain the current functionality for other use cases and only augment the handling of special cases like expression wrappers that evaluate to boolean conditions or perform null checks.</intended_behavior>, <file>django/db/models/sql/compiler.py</file>
<class>SQLCompiler</class>
<method>None</method>
<code>
22 class SQLCompiler:
23     # Multiline ordering SQL clause may appear from RawSQL.
24     ordering_parts = _lazy_re_compile(
25         r'^(.*)\s(?:ASC|DESC).*',
26         re.MULTILINE | re.DOTALL,
27     )
28 
29     def __init__(self, query, connection, using):
30         self.query = query
31         self.connection = connection
32         self.using = using
33         self.quote_cache = {'*': '*'}
34         # The select, klass_info, and annotations are needed by QuerySet.iterator()
35         # these are set as a side-effect of executing the query. Note that we calculate
36         # separately a list of extra select columns needed for grammatical correctness
37         # of the query, but these columns are not included in self.select.
38         self.select = None
39         self.annotation_col_map = None
40         self.klass_info = None
41         self._meta_ordering = None
42 
43     def setup_query(self):
44         if all(self.query.alias_refcount[a] == 0 for a in self.query.alias_map):
45             self.query.get_initial_alias()
46         self.select, self.klass_info, self.annotation_col_map = self.get_select()
47         self.col_count = len(self.select)
48 
49     def pre_sql_setup(self):
50         """
51         Do any necessary class setup immediately prior to producing SQL. This
52         is for things that can't necessarily be done in __init__ because we
53         might not have all the pieces in place at that time.
54         """
55         self.setup_query()
56         order_by = self.get_order_by()
57         self.where, self.having = self.query.where.split_having()
58         extra_select = self.get_extra_select(order_by, self.select)
59         self.has_extra_select = bool(extra_select)
60         group_by = self.get_group_by(self.select + extra_select, order_by)
61         return extra_select, order_by, group_by
62 
63     def get_group_by(self, select, order_by):
64         """
65         Return a list of 2-tuples of form (sql, params).
66 
67         The logic of what exactly the GROUP BY clause contains is hard
68         to describe in other words than "if it passes the test suite,
69         then it is correct".
70         """
71         # Some examples:
72         #     SomeModel.objects.annotate(Count('somecol'))
73         #     GROUP BY: all fields of the model
74         #
75         #    SomeModel.objects.values('name').annotate(Count('somecol'))
76         #    GROUP BY: name
77         #
78         #    SomeModel.objects.annotate(Count('somecol')).values('name')
79         #    GROUP BY: all cols of the model
80         #
81         #    SomeModel.objects.values('name', 'pk').annotate(Count('somecol')).values('pk')
82         #    GROUP BY: name, pk
83         #
84         #    SomeModel.objects.values('name').annotate(Count('somecol')).values('pk')
85         #    GROUP BY: name, pk
86         #
87         # In fact, the self.query.group_by is the minimal set to GROUP BY. It
88         # can't be ever restricted to a smaller set, but additional columns in
89         # HAVING, ORDER BY, and SELECT clauses are added to it. Unfortunately
90         # the end result is that it is impossible to force the query to have
91         # a chosen GROUP BY clause - you can almost do this by using the form:
92         #     .values(*wanted_cols).annotate(AnAggregate())
93         # but any later annotations, extra selects, values calls that
94         # refer some column outside of the wanted_cols, order_by, or even
95         # filter calls can alter the GROUP BY clause.
96 
97         # The query.group_by is either None (no GROUP BY at all), True
98         # (group by select fields), or a list of expressions to be added
99         # to the group by.
100         if self.query.group_by is None:
101             return []
102         expressions = []
103         if self.query.group_by is not True:
104             # If the group by is set to a list (by .values() call most likely),
105             # then we need to add everything in it to the GROUP BY clause.
106             # Backwards compatibility hack for setting query.group_by. Remove
107             # when  we have public API way of forcing the GROUP BY clause.
108             # Converts string references to expressions.
109             for expr in self.query.group_by:
110                 if not hasattr(expr, 'as_sql'):
111                     expressions.append(self.query.resolve_ref(expr))
112                 else:
113                     expressions.append(expr)
114         # Note that even if the group_by is set, it is only the minimal
115         # set to group by. So, we need to add cols in select, order_by, and
116         # having into the select in any case.
117         ref_sources = {
118             expr.source for expr in expressions if isinstance(expr, Ref)
119         }
120         for expr, _, _ in select:
121             # Skip members of the select clause that are already included
122             # by reference.
123             if expr in ref_sources:
124                 continue
125             cols = expr.get_group_by_cols()
126             for col in cols:
127                 expressions.append(col)
128         for expr, (sql, params, is_ref) in order_by:
129             # Skip References to the select clause, as all expressions in the
130             # select clause are already part of the group by.
131             if not is_ref:
132                 expressions.extend(expr.get_group_by_cols())
133         having_group_by = self.having.get_group_by_cols() if self.having else ()
134         for expr in having_group_by:
135             expressions.append(expr)
136         result = []
137         seen = set()
138         expressions = self.collapse_group_by(expressions, having_group_by)
139 
140         for expr in expressions:
141             sql, params = self.compile(expr)
142             sql, params = expr.select_format(self, sql, params)
143             params_hash = make_hashable(params)
144             if (sql, params_hash) not in seen:
145                 result.append((sql, params))
146                 seen.add((sql, params_hash))
147         return result
148 
149     def collapse_group_by(self, expressions, having):
150         # If the DB can group by primary key, then group by the primary key of
151         # query's main model. Note that for PostgreSQL the GROUP BY clause must
152         # include the primary key of every table, but for MySQL it is enough to
153         # have the main table's primary key.
154         if self.connection.features.allows_group_by_pk:
155             # Determine if the main model's primary key is in the query.
156             pk = None
157             for expr in expressions:
158                 # Is this a reference to query's base table primary key? If the
159                 # expression isn't a Col-like, then skip the expression.
160                 if (getattr(expr, 'target', None) == self.query.model._meta.pk and
161                         getattr(expr, 'alias', None) == self.query.base_table):
162                     pk = expr
163                     break
164             # If the main model's primary key is in the query, group by that
165             # field, HAVING expressions, and expressions associated with tables
166             # that don't have a primary key included in the grouped columns.
167             if pk:
168                 pk_aliases = {
169                     expr.alias for expr in expressions
170                     if hasattr(expr, 'target') and expr.target.primary_key
171                 }
172                 expressions = [pk] + [
173                     expr for expr in expressions
174                     if expr in having or (
175                         getattr(expr, 'alias', None) is not None and expr.alias not in pk_aliases
176                     )
177                 ]
178         elif self.connection.features.allows_group_by_selected_pks:
179             # Filter out all expressions associated with a table's primary key
180             # present in the grouped columns. This is done by identifying all
181             # tables that have their primary key included in the grouped
182             # columns and removing non-primary key columns referring to them.
183             # Unmanaged models are excluded because they could be representing
184             # database views on which the optimization might not be allowed.
185             pks = {
186                 expr for expr in expressions
187                 if (
188                     hasattr(expr, 'target') and
189                     expr.target.primary_key and
190                     self.connection.features.allows_group_by_selected_pks_on_model(expr.target.model)
191                 )
192             }
193             aliases = {expr.alias for expr in pks}
194             expressions = [
195                 expr for expr in expressions if expr in pks or getattr(expr, 'alias', None) not in aliases
196             ]
197         return expressions
198 
199     def get_select(self):
200         """
201         Return three values:
202         - a list of 3-tuples of (expression, (sql, params), alias)
203         - a klass_info structure,
204         - a dictionary of annotations
205 
206         The (sql, params) is what the expression will produce, and alias is the
207         "AS alias" for the column (possibly None).
208 
209         The klass_info structure contains the following information:
210         - The base model of the query.
211         - Which columns for that model are present in the query (by
212           position of the select clause).
213         - related_klass_infos: [f, klass_info] to descent into
214 
215         The annotations is a dictionary of {'attname': column position} values.
216         """
217         select = []
218         klass_info = None
219         annotations = {}
220         select_idx = 0
221         for alias, (sql, params) in self.query.extra_select.items():
222             annotations[alias] = select_idx
223             select.append((RawSQL(sql, params), alias))
224             select_idx += 1
225         assert not (self.query.select and self.query.default_cols)
226         if self.query.default_cols:
227             cols = self.get_default_columns()
228         else:
229             # self.query.select is a special case. These columns never go to
230             # any model.
231             cols = self.query.select
232         if cols:
233             select_list = []
234             for col in cols:
235                 select_list.append(select_idx)
236                 select.append((col, None))
237                 select_idx += 1
238             klass_info = {
239                 'model': self.query.model,
240                 'select_fields': select_list,
241             }
242         for alias, annotation in self.query.annotation_select.items():
243             annotations[alias] = select_idx
244             select.append((annotation, alias))
245             select_idx += 1
246 
247         if self.query.select_related:
248             related_klass_infos = self.get_related_selections(select)
249             klass_info['related_klass_infos'] = related_klass_infos
250 
251             def get_select_from_parent(klass_info):
252                 for ki in klass_info['related_klass_infos']:
253                     if ki['from_parent']:
254                         ki['select_fields'] = (klass_info['select_fields'] +
255                                                ki['select_fields'])
256                     get_select_from_parent(ki)
257             get_select_from_parent(klass_info)
258 
259         ret = []
260         for col, alias in select:
261             try:
262                 sql, params = self.compile(col)
263             except EmptyResultSet:
264                 # Select a predicate that's always False.
265                 sql, params = '0', ()
266             else:
267                 sql, params = col.select_format(self, sql, params)
268             ret.append((col, (sql, params), alias))
269         return ret, klass_info, annotations
270 
271     def get_order_by(self):
272         """
273         Return a list of 2-tuples of form (expr, (sql, params, is_ref)) for the
274         ORDER BY clause.
275 
276         The order_by clause can alter the select clause (for example it
277         can add aliases to clauses that do not yet have one, or it can
278         add totally new select clauses).
279         """
280         if self.query.extra_order_by:
281             ordering = self.query.extra_order_by
282         elif not self.query.default_ordering:
283             ordering = self.query.order_by
284         elif self.query.order_by:
285             ordering = self.query.order_by
286         elif self.query.get_meta().ordering:
287             ordering = self.query.get_meta().ordering
288             self._meta_ordering = ordering
289         else:
290             ordering = []
291         if self.query.standard_ordering:
292             asc, desc = ORDER_DIR['ASC']
293         else:
294             asc, desc = ORDER_DIR['DESC']
295 
296         order_by = []
297         for field in ordering:
298             if hasattr(field, 'resolve_expression'):
299                 if isinstance(field, Value):
300                     # output_field must be resolved for constants.
301                     field = Cast(field, field.output_field)
302                 if not isinstance(field, OrderBy):
303                     field = field.asc()
304                 if not self.query.standard_ordering:
305                     field = field.copy()
306                     field.reverse_ordering()
307                 order_by.append((field, False))
308                 continue
309             if field == '?':  # random
310                 order_by.append((OrderBy(Random()), False))
311                 continue
312 
313             col, order = get_order_dir(field, asc)
314             descending = order == 'DESC'
315 
316             if col in self.query.annotation_select:
317                 # Reference to expression in SELECT clause
318                 order_by.append((
319                     OrderBy(Ref(col, self.query.annotation_select[col]), descending=descending),
320                     True))
321                 continue
322             if col in self.query.annotations:
323                 # References to an expression which is masked out of the SELECT
324                 # clause.
325                 if self.query.combinator and self.select:
326                     # Don't use the resolved annotation because other
327                     # combinated queries might define it differently.
328                     expr = F(col)
329                 else:
330                     expr = self.query.annotations[col]
331                     if isinstance(expr, Value):
332                         # output_field must be resolved for constants.
333                         expr = Cast(expr, expr.output_field)
334                 order_by.append((OrderBy(expr, descending=descending), False))
335                 continue
336 
337             if '.' in field:
338                 # This came in through an extra(order_by=...) addition. Pass it
339                 # on verbatim.
340                 table, col = col.split('.', 1)
341                 order_by.append((
342                     OrderBy(
343                         RawSQL('%s.%s' % (self.quote_name_unless_alias(table), col), []),
344                         descending=descending
345                     ), False))
346                 continue
347 
348             if not self.query.extra or col not in self.query.extra:
349                 # 'col' is of the form 'field' or 'field1__field2' or
350                 # '-field1__field2__field', etc.
351                 order_by.extend(self.find_ordering_name(
352                     field, self.query.get_meta(), default_order=asc))
353             else:
354                 if col not in self.query.extra_select:
355                     order_by.append((
356                         OrderBy(RawSQL(*self.query.extra[col]), descending=descending),
357                         False))
358                 else:
359                     order_by.append((
360                         OrderBy(Ref(col, RawSQL(*self.query.extra[col])), descending=descending),
361                         True))
362         result = []
363         seen = set()
364 
365         for expr, is_ref in order_by:
366             resolved = expr.resolve_expression(self.query, allow_joins=True, reuse=None)
367             if self.query.combinator and self.select:
368                 src = resolved.get_source_expressions()[0]
369                 expr_src = expr.get_source_expressions()[0]
370                 # Relabel order by columns to raw numbers if this is a combined
371                 # query; necessary since the columns can't be referenced by the
372                 # fully qualified name and the simple column names may collide.
373                 for idx, (sel_expr, _, col_alias) in enumerate(self.select):
374                     if is_ref and col_alias == src.refs:
375                         src = src.source
376                     elif col_alias and not (
377                         isinstance(expr_src, F) and col_alias == expr_src.name
378                     ):
379                         continue
380                     if src == sel_expr:
381                         resolved.set_source_expressions([RawSQL('%d' % (idx + 1), ())])
382                         break
383                 else:
384                     if col_alias:
385                         raise DatabaseError('ORDER BY term does not match any column in the result set.')
386                     # Add column used in ORDER BY clause to the selected
387                     # columns and to each combined query.
388                     order_by_idx = len(self.query.select) + 1
389                     col_name = f'__orderbycol{order_by_idx}'
390                     for q in self.query.combined_queries:
391                         q.add_annotation(expr_src, col_name)
392                     self.query.add_select_col(resolved, col_name)
393                     resolved.set_source_expressions([RawSQL(f'{order_by_idx}', ())])
394             sql, params = self.compile(resolved)
395             # Don't add the same column twice, but the order direction is
396             # not taken into account so we strip it. When this entire method
397             # is refactored into expressions, then we can check each part as we
398             # generate it.
399             without_ordering = self.ordering_parts.search(sql)[1]
400             params_hash = make_hashable(params)
401             if (without_ordering, params_hash) in seen:
402                 continue
403             seen.add((without_ordering, params_hash))
404             result.append((resolved, (sql, params, is_ref)))
405         return result
406 
407     def get_extra_select(self, order_by, select):
408         extra_select = []
409         if self.query.distinct and not self.query.distinct_fields:
410             select_sql = [t[1] for t in select]
411             for expr, (sql, params, is_ref) in order_by:
412                 without_ordering = self.ordering_parts.search(sql)[1]
413                 if not is_ref and (without_ordering, params) not in select_sql:
414                     extra_select.append((expr, (without_ordering, params), None))
415         return extra_select
416 
417     def quote_name_unless_alias(self, name):
418         """
419         A wrapper around connection.ops.quote_name that doesn't quote aliases
420         for table names. This avoids problems with some SQL dialects that treat
421         quoted strings specially (e.g. PostgreSQL).
422         """
423         if name in self.quote_cache:
424             return self.quote_cache[name]
425         if ((name in self.query.alias_map and name not in self.query.table_map) or
426                 name in self.query.extra_select or (
427                     self.query.external_aliases.get(name) and name not in self.query.table_map)):
428             self.quote_cache[name] = name
429             return name
430         r = self.connection.ops.quote_name(name)
431         self.quote_cache[name] = r
432         return r
433 
434     def compile(self, node):
435         vendor_impl = getattr(node, 'as_' + self.connection.vendor, None)
436         if vendor_impl:
437             sql, params = vendor_impl(self, self.connection)
438         else:
439             sql, params = node.as_sql(self, self.connection)
440         return sql, params
441 
442     def get_combinator_sql(self, combinator, all):
443         features = self.connection.features
444         compilers = [
445             query.get_compiler(self.using, self.connection)
446             for query in self.query.combined_queries if not query.is_empty()
447         ]
448         if not features.supports_slicing_ordering_in_compound:
449             for query, compiler in zip(self.query.combined_queries, compilers):
450                 if query.low_mark or query.high_mark:
451                     raise DatabaseError('LIMIT/OFFSET not allowed in subqueries of compound statements.')
452                 if compiler.get_order_by():
453                     raise DatabaseError('ORDER BY not allowed in subqueries of compound statements.')
454         parts = ()
455         for compiler in compilers:
456             try:
457                 # If the columns list is limited, then all combined queries
458                 # must have the same columns list. Set the selects defined on
459                 # the query on all combined queries, if not already set.
460                 if not compiler.query.values_select and self.query.values_select:
461                     compiler.query = compiler.query.clone()
462                     compiler.query.set_values((
463                         *self.query.extra_select,
464                         *self.query.values_select,
465                         *self.query.annotation_select,
466                     ))
467                 part_sql, part_args = compiler.as_sql()
468                 if compiler.query.combinator:
469                     # Wrap in a subquery if wrapping in parentheses isn't
470                     # supported.
471                     if not features.supports_parentheses_in_compound:
472                         part_sql = 'SELECT * FROM ({})'.format(part_sql)
473                     # Add parentheses when combining with compound query if not
474                     # already added for all compound queries.
475                     elif not features.supports_slicing_ordering_in_compound:
476                         part_sql = '({})'.format(part_sql)
477                 parts += ((part_sql, part_args),)
478             except EmptyResultSet:
479                 # Omit the empty queryset with UNION and with DIFFERENCE if the
480                 # first queryset is nonempty.
481                 if combinator == 'union' or (combinator == 'difference' and parts):
482                     continue
483                 raise
484         if not parts:
485             raise EmptyResultSet
486         combinator_sql = self.connection.ops.set_operators[combinator]
487         if all and combinator == 'union':
488             combinator_sql += ' ALL'
489         braces = '({})' if features.supports_slicing_ordering_in_compound else '{}'
490         sql_parts, args_parts = zip(*((braces.format(sql), args) for sql, args in parts))
491         result = [' {} '.format(combinator_sql).join(sql_parts)]
492         params = []
493         for part in args_parts:
494             params.extend(part)
495         return result, params
496 
497     def as_sql(self, with_limits=True, with_col_aliases=False):
498         """
499         Create the SQL for this query. Return the SQL string and list of
500         parameters.
501 
502         If 'with_limits' is False, any limit/offset information is not included
503         in the query.
504         """
505         refcounts_before = self.query.alias_refcount.copy()
506         try:
507             extra_select, order_by, group_by = self.pre_sql_setup()
508             for_update_part = None
509             # Is a LIMIT/OFFSET clause needed?
510             with_limit_offset = with_limits and (self.query.high_mark is not None or self.query.low_mark)
511             combinator = self.query.combinator
512             features = self.connection.features
513             if combinator:
514                 if not getattr(features, 'supports_select_{}'.format(combinator)):
515                     raise NotSupportedError('{} is not supported on this database backend.'.format(combinator))
516                 result, params = self.get_combinator_sql(combinator, self.query.combinator_all)
517             else:
518                 distinct_fields, distinct_params = self.get_distinct()
519                 # This must come after 'select', 'ordering', and 'distinct'
520                 # (see docstring of get_from_clause() for details).
521                 from_, f_params = self.get_from_clause()
522                 where, w_params = self.compile(self.where) if self.where is not None else ("", [])
523                 having, h_params = self.compile(self.having) if self.having is not None else ("", [])
524                 result = ['SELECT']
525                 params = []
526 
527                 if self.query.distinct:
528                     distinct_result, distinct_params = self.connection.ops.distinct_sql(
529                         distinct_fields,
530                         distinct_params,
531                     )
532                     result += distinct_result
533                     params += distinct_params
534 
535                 out_cols = []
536                 col_idx = 1
537                 for _, (s_sql, s_params), alias in self.select + extra_select:
538                     if alias:
539                         s_sql = '%s AS %s' % (s_sql, self.connection.ops.quote_name(alias))
540                     elif with_col_aliases:
541                         s_sql = '%s AS %s' % (s_sql, 'Col%d' % col_idx)
542                         col_idx += 1
543                     params.extend(s_params)
544                     out_cols.append(s_sql)
545 
546                 result += [', '.join(out_cols), 'FROM', *from_]
547                 params.extend(f_params)
548 
549                 if self.query.select_for_update and self.connection.features.has_select_for_update:
550                     if self.connection.get_autocommit():
551                         raise TransactionManagementError('select_for_update cannot be used outside of a transaction.')
552 
553                     if with_limit_offset and not self.connection.features.supports_select_for_update_with_limit:
554                         raise NotSupportedError(
555                             'LIMIT/OFFSET is not supported with '
556                             'select_for_update on this database backend.'
557                         )
558                     nowait = self.query.select_for_update_nowait
559                     skip_locked = self.query.select_for_update_skip_locked
560                     of = self.query.select_for_update_of
561                     no_key = self.query.select_for_no_key_update
562                     # If it's a NOWAIT/SKIP LOCKED/OF/NO KEY query but the
563                     # backend doesn't support it, raise NotSupportedError to
564                     # prevent a possible deadlock.
565                     if nowait and not self.connection.features.has_select_for_update_nowait:
566                         raise NotSupportedError('NOWAIT is not supported on this database backend.')
567                     elif skip_locked and not self.connection.features.has_select_for_update_skip_locked:
568                         raise NotSupportedError('SKIP LOCKED is not supported on this database backend.')
569                     elif of and not self.connection.features.has_select_for_update_of:
570                         raise NotSupportedError('FOR UPDATE OF is not supported on this database backend.')
571                     elif no_key and not self.connection.features.has_select_for_no_key_update:
572                         raise NotSupportedError(
573                             'FOR NO KEY UPDATE is not supported on this '
574                             'database backend.'
575                         )
576                     for_update_part = self.connection.ops.for_update_sql(
577                         nowait=nowait,
578                         skip_locked=skip_locked,
579                         of=self.get_select_for_update_of_arguments(),
580                         no_key=no_key,
581                     )
582 
583                 if for_update_part and self.connection.features.for_update_after_from:
584                     result.append(for_update_part)
585 
586                 if where:
587                     result.append('WHERE %s' % where)
588                     params.extend(w_params)
589 
590                 grouping = []
591                 for g_sql, g_params in group_by:
592                     grouping.append(g_sql)
593                     params.extend(g_params)
594                 if grouping:
595                     if distinct_fields:
596                         raise NotImplementedError('annotate() + distinct(fields) is not implemented.')
597                     order_by = order_by or self.connection.ops.force_no_ordering()
598                     result.append('GROUP BY %s' % ', '.join(grouping))
599                     if self._meta_ordering:
600                         order_by = None
601                 if having:
602                     result.append('HAVING %s' % having)
603                     params.extend(h_params)
604 
605             if self.query.explain_query:
606                 result.insert(0, self.connection.ops.explain_query_prefix(
607                     self.query.explain_format,
608                     **self.query.explain_options
609                 ))
610 
611             if order_by:
612                 ordering = []
613                 for _, (o_sql, o_params, _) in order_by:
614                     ordering.append(o_sql)
615                     params.extend(o_params)
616                 result.append('ORDER BY %s' % ', '.join(ordering))
617 
618             if with_limit_offset:
619                 result.append(self.connection.ops.limit_offset_sql(self.query.low_mark, self.query.high_mark))
620 
621             if for_update_part and not self.connection.features.for_update_after_from:
622                 result.append(for_update_part)
623 
624             if self.query.subquery and extra_select:
625                 # If the query is used as a subquery, the extra selects would
626                 # result in more columns than the left-hand side expression is
627                 # expecting. This can happen when a subquery uses a combination
628                 # of order_by() and distinct(), forcing the ordering expressions
629                 # to be selected as well. Wrap the query in another subquery
630                 # to exclude extraneous selects.
631                 sub_selects = []
632                 sub_params = []
633                 for index, (select, _, alias) in enumerate(self.select, start=1):
634                     if not alias and with_col_aliases:
635                         alias = 'col%d' % index
636                     if alias:
637                         sub_selects.append("%s.%s" % (
638                             self.connection.ops.quote_name('subquery'),
639                             self.connection.ops.quote_name(alias),
640                         ))
641                     else:
642                         select_clone = select.relabeled_clone({select.alias: 'subquery'})
643                         subselect, subparams = select_clone.as_sql(self, self.connection)
644                         sub_selects.append(subselect)
645                         sub_params.extend(subparams)
646                 return 'SELECT %s FROM (%s) subquery' % (
647                     ', '.join(sub_selects),
648                     ' '.join(result),
649                 ), tuple(sub_params + params)
650 
651             return ' '.join(result), tuple(params)
652         finally:
653             # Finally do cleanup - get rid of the joins we created above.
654             self.query.reset_refcounts(refcounts_before)
655 
656     def get_default_columns(self, start_alias=None, opts=None, from_parent=None):
657         """
658         Compute the default columns for selecting every field in the base
659         model. Will sometimes be called to pull in related models (e.g. via
660         select_related), in which case "opts" and "start_alias" will be given
661         to provide a starting point for the traversal.
662 
663         Return a list of strings, quoted appropriately for use in SQL
664         directly, as well as a set of aliases used in the select statement (if
665         'as_pairs' is True, return a list of (alias, col_name) pairs instead
666         of strings as the first component and None as the second component).
667         """
668         result = []
669         if opts is None:
670             opts = self.query.get_meta()
671         only_load = self.deferred_to_columns()
672         start_alias = start_alias or self.query.get_initial_alias()
673         # The 'seen_models' is used to optimize checking the needed parent
674         # alias for a given field. This also includes None -> start_alias to
675         # be used by local fields.
676         seen_models = {None: start_alias}
677 
678         for field in opts.concrete_fields:
679             model = field.model._meta.concrete_model
680             # A proxy model will have a different model and concrete_model. We
681             # will assign None if the field belongs to this model.
682             if model == opts.model:
683                 model = None
684             if from_parent and model is not None and issubclass(
685                     from_parent._meta.concrete_model, model._meta.concrete_model):
686                 # Avoid loading data for already loaded parents.
687                 # We end up here in the case select_related() resolution
688                 # proceeds from parent model to child model. In that case the
689                 # parent model data is already present in the SELECT clause,
690                 # and we want to avoid reloading the same data again.
691                 continue
692             if field.model in only_load and field.attname not in only_load[field.model]:
693                 continue
694             alias = self.query.join_parent_model(opts, model, start_alias,
695                                                  seen_models)
696             column = field.get_col(alias)
697             result.append(column)
698         return result
699 
700     def get_distinct(self):
701         """
702         Return a quoted list of fields to use in DISTINCT ON part of the query.
703 
704         This method can alter the tables in the query, and thus it must be
705         called before get_from_clause().
706         """
707         result = []
708         params = []
709         opts = self.query.get_meta()
710 
711         for name in self.query.distinct_fields:
712             parts = name.split(LOOKUP_SEP)
713             _, targets, alias, joins, path, _, transform_function = self._setup_joins(parts, opts, None)
714             targets, alias, _ = self.query.trim_joins(targets, joins, path)
715             for target in targets:
716                 if name in self.query.annotation_select:
717                     result.append(name)
718                 else:
719                     r, p = self.compile(transform_function(target, alias))
720                     result.append(r)
721                     params.append(p)
722         return result, params
723 
724     def find_ordering_name(self, name, opts, alias=None, default_order='ASC',
725                            already_seen=None):
726         """
727         Return the table alias (the name might be ambiguous, the alias will
728         not be) and column name for ordering by the given 'name' parameter.
729         The 'name' is of the form 'field1__field2__...__fieldN'.
730         """
731         name, order = get_order_dir(name, default_order)
732         descending = order == 'DESC'
733         pieces = name.split(LOOKUP_SEP)
734         field, targets, alias, joins, path, opts, transform_function = self._setup_joins(pieces, opts, alias)
735 
736         # If we get to this point and the field is a relation to another model,
737         # append the default ordering for that model unless it is the pk
738         # shortcut or the attribute name of the field that is specified.
739         if (
740             field.is_relation and
741             opts.ordering and
742             getattr(field, 'attname', None) != pieces[-1] and
743             name != 'pk'
744         ):
745             # Firstly, avoid infinite loops.
746             already_seen = already_seen or set()
747             join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)
748             if join_tuple in already_seen:
749                 raise FieldError('Infinite loop caused by ordering.')
750             already_seen.add(join_tuple)
751 
752             results = []
753             for item in opts.ordering:
754                 if hasattr(item, 'resolve_expression') and not isinstance(item, OrderBy):
755                     item = item.desc() if descending else item.asc()
756                 if isinstance(item, OrderBy):
757                     results.append((item, False))
758                     continue
759                 results.extend(self.find_ordering_name(item, opts, alias,
760                                                        order, already_seen))
761             return results
762         targets, alias, _ = self.query.trim_joins(targets, joins, path)
763         return [(OrderBy(transform_function(t, alias), descending=descending), False) for t in targets]
764 
765     def _setup_joins(self, pieces, opts, alias):
766         """
767         Helper method for get_order_by() and get_distinct().
768 
769         get_ordering() and get_distinct() must produce same target columns on
770         same input, as the prefixes of get_ordering() and get_distinct() must
771         match. Executing SQL where this is not true is an error.
772         """
773         alias = alias or self.query.get_initial_alias()
774         field, targets, opts, joins, path, transform_function = self.query.setup_joins(pieces, opts, alias)
775         alias = joins[-1]
776         return field, targets, alias, joins, path, opts, transform_function
777 
778     def get_from_clause(self):
779         """
780         Return a list of strings that are joined together to go after the
781         "FROM" part of the query, as well as a list any extra parameters that
782         need to be included. Subclasses, can override this to create a
783         from-clause via a "select".
784 
785         This should only be called after any SQL construction methods that
786         might change the tables that are needed. This means the select columns,
787         ordering, and distinct must be done first.
788         """
789         result = []
790         params = []
791         for alias in tuple(self.query.alias_map):
792             if not self.query.alias_refcount[alias]:
793                 continue
794             try:
795                 from_clause = self.query.alias_map[alias]
796             except KeyError:
797                 # Extra tables can end up in self.tables, but not in the
798                 # alias_map if they aren't in a join. That's OK. We skip them.
799                 continue
800             clause_sql, clause_params = self.compile(from_clause)
801             result.append(clause_sql)
802             params.extend(clause_params)
803         for t in self.query.extra_tables:
804             alias, _ = self.query.table_alias(t)
805             # Only add the alias if it's not already present (the table_alias()
806             # call increments the refcount, so an alias refcount of one means
807             # this is the only reference).
808             if alias not in self.query.alias_map or self.query.alias_refcount[alias] == 1:
809                 result.append(', %s' % self.quote_name_unless_alias(alias))
810         return result, params
811 
812     def get_related_selections(self, select, opts=None, root_alias=None, cur_depth=1,
813                                requested=None, restricted=None):
814         """
815         Fill in the information needed for a select_related query. The current
816         depth is measured as the number of connections away from the root model
817         (for example, cur_depth=1 means we are looking at models with direct
818         connections to the root model).
819         """
820         def _get_field_choices():
821             direct_choices = (f.name for f in opts.fields if f.is_relation)
822             reverse_choices = (
823                 f.field.related_query_name()
824                 for f in opts.related_objects if f.field.unique
825             )
826             return chain(direct_choices, reverse_choices, self.query._filtered_relations)
827 
828         related_klass_infos = []
829         if not restricted and cur_depth > self.query.max_depth:
830             # We've recursed far enough; bail out.
831             return related_klass_infos
832 
833         if not opts:
834             opts = self.query.get_meta()
835             root_alias = self.query.get_initial_alias()
836         only_load = self.query.get_loaded_field_names()
837 
838         # Setup for the case when only particular related fields should be
839         # included in the related selection.
840         fields_found = set()
841         if requested is None:
842             restricted = isinstance(self.query.select_related, dict)
843             if restricted:
844                 requested = self.query.select_related
845 
846         def get_related_klass_infos(klass_info, related_klass_infos):
847             klass_info['related_klass_infos'] = related_klass_infos
848 
849         for f in opts.fields:
850             field_model = f.model._meta.concrete_model
851             fields_found.add(f.name)
852 
853             if restricted:
854                 next = requested.get(f.name, {})
855                 if not f.is_relation:
856                     # If a non-related field is used like a relation,
857                     # or if a single non-relational field is given.
858                     if next or f.name in requested:
859                         raise FieldError(
860                             "Non-relational field given in select_related: '%s'. "
861                             "Choices are: %s" % (
862                                 f.name,
863                                 ", ".join(_get_field_choices()) or '(none)',
864                             )
865                         )
866             else:
867                 next = False
868 
869             if not select_related_descend(f, restricted, requested,
870                                           only_load.get(field_model)):
871                 continue
872             klass_info = {
873                 'model': f.remote_field.model,
874                 'field': f,
875                 'reverse': False,
876                 'local_setter': f.set_cached_value,
877                 'remote_setter': f.remote_field.set_cached_value if f.unique else lambda x, y: None,
878                 'from_parent': False,
879             }
880             related_klass_infos.append(klass_info)
881             select_fields = []
882             _, _, _, joins, _, _ = self.query.setup_joins(
883                 [f.name], opts, root_alias)
884             alias = joins[-1]
885             columns = self.get_default_columns(start_alias=alias, opts=f.remote_field.model._meta)
886             for col in columns:
887                 select_fields.append(len(select))
888                 select.append((col, None))
889             klass_info['select_fields'] = select_fields
890             next_klass_infos = self.get_related_selections(
891                 select, f.remote_field.model._meta, alias, cur_depth + 1, next, restricted)
892             get_related_klass_infos(klass_info, next_klass_infos)
893 
894         if restricted:
895             related_fields = [
896                 (o.field, o.related_model)
897                 for o in opts.related_objects
898                 if o.field.unique and not o.many_to_many
899             ]
900             for f, model in related_fields:
901                 if not select_related_descend(f, restricted, requested,
902                                               only_load.get(model), reverse=True):
903                     continue
904 
905                 related_field_name = f.related_query_name()
906                 fields_found.add(related_field_name)
907 
908                 join_info = self.query.setup_joins([related_field_name], opts, root_alias)
909                 alias = join_info.joins[-1]
910                 from_parent = issubclass(model, opts.model) and model is not opts.model
911                 klass_info = {
912                     'model': model,
913                     'field': f,
914                     'reverse': True,
915                     'local_setter': f.remote_field.set_cached_value,
916                     'remote_setter': f.set_cached_value,
917                     'from_parent': from_parent,
918                 }
919                 related_klass_infos.append(klass_info)
920                 select_fields = []
921                 columns = self.get_default_columns(
922                     start_alias=alias, opts=model._meta, from_parent=opts.model)
923                 for col in columns:
924                     select_fields.append(len(select))
925                     select.append((col, None))
926                 klass_info['select_fields'] = select_fields
927                 next = requested.get(f.related_query_name(), {})
928                 next_klass_infos = self.get_related_selections(
929                     select, model._meta, alias, cur_depth + 1,
930                     next, restricted)
931                 get_related_klass_infos(klass_info, next_klass_infos)
932 
933             def local_setter(obj, from_obj):
934                 # Set a reverse fk object when relation is non-empty.
935                 if from_obj:
936                     f.remote_field.set_cached_value(from_obj, obj)
937 
938             def remote_setter(name, obj, from_obj):
939                 setattr(from_obj, name, obj)
940 
941             for name in list(requested):
942                 # Filtered relations work only on the topmost level.
943                 if cur_depth > 1:
944                     break
945                 if name in self.query._filtered_relations:
946                     fields_found.add(name)
947                     f, _, join_opts, joins, _, _ = self.query.setup_joins([name], opts, root_alias)
948                     model = join_opts.model
949                     alias = joins[-1]
950                     from_parent = issubclass(model, opts.model) and model is not opts.model
951                     klass_info = {
952                         'model': model,
953                         'field': f,
954                         'reverse': True,
955                         'local_setter': local_setter,
956                         'remote_setter': partial(remote_setter, name),
957                         'from_parent': from_parent,
958                     }
959                     related_klass_infos.append(klass_info)
960                     select_fields = []
961                     columns = self.get_default_columns(
962                         start_alias=alias, opts=model._meta,
963                         from_parent=opts.model,
964                     )
965                     for col in columns:
966                         select_fields.append(len(select))
967                         select.append((col, None))
968                     klass_info['select_fields'] = select_fields
969                     next_requested = requested.get(name, {})
970                     next_klass_infos = self.get_related_selections(
971                         select, opts=model._meta, root_alias=alias,
972                         cur_depth=cur_depth + 1, requested=next_requested,
973                         restricted=restricted,
974                     )
975                     get_related_klass_infos(klass_info, next_klass_infos)
976             fields_not_found = set(requested).difference(fields_found)
977             if fields_not_found:
978                 invalid_fields = ("'%s'" % s for s in fields_not_found)
979                 raise FieldError(
980                     'Invalid field name(s) given in select_related: %s. '
981                     'Choices are: %s' % (
982                         ', '.join(invalid_fields),
983                         ', '.join(_get_field_choices()) or '(none)',
984                     )
985                 )
986         return related_klass_infos
987 
988     def get_select_for_update_of_arguments(self):
989         """
990         Return a quoted list of arguments for the SELECT FOR UPDATE OF part of
991         the query.
992         """
993         def _get_parent_klass_info(klass_info):
994             concrete_model = klass_info['model']._meta.concrete_model
995             for parent_model, parent_link in concrete_model._meta.parents.items():
996                 parent_list = parent_model._meta.get_parent_list()
997                 yield {
998                     'model': parent_model,
999                     'field': parent_link,
1000                     'reverse': False,
1001                     'select_fields': [
1002                         select_index
1003                         for select_index in klass_info['select_fields']
1004                         # Selected columns from a model or its parents.
1005                         if (
1006                             self.select[select_index][0].target.model == parent_model or
1007                             self.select[select_index][0].target.model in parent_list
1008                         )
1009                     ],
1010                 }
1011 
1012         def _get_first_selected_col_from_model(klass_info):
1013             """
1014             Find the first selected column from a model. If it doesn't exist,
1015             don't lock a model.
1016 
1017             select_fields is filled recursively, so it also contains fields
1018             from the parent models.
1019             """
1020             concrete_model = klass_info['model']._meta.concrete_model
1021             for select_index in klass_info['select_fields']:
1022                 if self.select[select_index][0].target.model == concrete_model:
1023                     return self.select[select_index][0]
1024 
1025         def _get_field_choices():
1026             """Yield all allowed field paths in breadth-first search order."""
1027             queue = collections.deque([(None, self.klass_info)])
1028             while queue:
1029                 parent_path, klass_info = queue.popleft()
1030                 if parent_path is None:
1031                     path = []
1032                     yield 'self'
1033                 else:
1034                     field = klass_info['field']
1035                     if klass_info['reverse']:
1036                         field = field.remote_field
1037                     path = parent_path + [field.name]
1038                     yield LOOKUP_SEP.join(path)
1039                 queue.extend(
1040                     (path, klass_info)
1041                     for klass_info in _get_parent_klass_info(klass_info)
1042                 )
1043                 queue.extend(
1044                     (path, klass_info)
1045                     for klass_info in klass_info.get('related_klass_infos', [])
1046                 )
1047         result = []
1048         invalid_names = []
1049         for name in self.query.select_for_update_of:
1050             klass_info = self.klass_info
1051             if name == 'self':
1052                 col = _get_first_selected_col_from_model(klass_info)
1053             else:
1054                 for part in name.split(LOOKUP_SEP):
1055                     klass_infos = (
1056                         *klass_info.get('related_klass_infos', []),
1057                         *_get_parent_klass_info(klass_info),
1058                     )
1059                     for related_klass_info in klass_infos:
1060                         field = related_klass_info['field']
1061                         if related_klass_info['reverse']:
1062                             field = field.remote_field
1063                         if field.name == part:
1064                             klass_info = related_klass_info
1065                             break
1066                     else:
1067                         klass_info = None
1068                         break
1069                 if klass_info is None:
1070                     invalid_names.append(name)
1071                     continue
1072                 col = _get_first_selected_col_from_model(klass_info)
1073             if col is not None:
1074                 if self.connection.features.select_for_update_of_column:
1075                     result.append(self.compile(col)[0])
1076                 else:
1077                     result.append(self.quote_name_unless_alias(col.alias))
1078         if invalid_names:
1079             raise FieldError(
1080                 'Invalid field name(s) given in select_for_update(of=(...)): %s. '
1081                 'Only relational fields followed in the query are allowed. '
1082                 'Choices are: %s.' % (
1083                     ', '.join(invalid_names),
1084                     ', '.join(_get_field_choices()),
1085                 )
1086             )
1087         return result
1088 
1089     def deferred_to_columns(self):
1090         """
1091         Convert the self.deferred_loading data structure to mapping of table
1092         names to sets of column names which are to be loaded. Return the
1093         dictionary.
1094         """
1095         columns = {}
1096         self.query.deferred_to_data(columns, self.query.get_loaded_field_names_cb)
1097         return columns
1098 
1099     def get_converters(self, expressions):
1100         converters = {}
1101         for i, expression in enumerate(expressions):
1102             if expression:
1103                 backend_converters = self.connection.ops.get_db_converters(expression)
1104                 field_converters = expression.get_db_converters(self.connection)
1105                 if backend_converters or field_converters:
1106                     converters[i] = (backend_converters + field_converters, expression)
1107         return converters
1108 
1109     def apply_converters(self, rows, converters):
1110         connection = self.connection
1111         converters = list(converters.items())
1112         for row in map(list, rows):
1113             for pos, (convs, expression) in converters:
1114                 value = row[pos]
1115                 for converter in convs:
1116                     value = converter(value, expression, connection)
1117                 row[pos] = value
1118             yield row
1119 
1120     def results_iter(self, results=None, tuple_expected=False, chunked_fetch=False,
1121                      chunk_size=GET_ITERATOR_CHUNK_SIZE):
1122         """Return an iterator over the results from executing this query."""
1123         if results is None:
1124             results = self.execute_sql(MULTI, chunked_fetch=chunked_fetch, chunk_size=chunk_size)
1125         fields = [s[0] for s in self.select[0:self.col_count]]
1126         converters = self.get_converters(fields)
1127         rows = chain.from_iterable(results)
1128         if converters:
1129             rows = self.apply_converters(rows, converters)
1130             if tuple_expected:
1131                 rows = map(tuple, rows)
1132         return rows
1133 
1134     def has_results(self):
1135         """
1136         Backends (e.g. NoSQL) can override this in order to use optimized
1137         versions of "query has any results."
1138         """
1139         return bool(self.execute_sql(SINGLE))
1140 
1141     def execute_sql(self, result_type=MULTI, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE):
1142         """
1143         Run the query against the database and return the result(s). The
1144         return value is a single data item if result_type is SINGLE, or an
1145         iterator over the results if the result_type is MULTI.
1146 
1147         result_type is either MULTI (use fetchmany() to retrieve all rows),
1148         SINGLE (only retrieve a single row), or None. In this last case, the
1149         cursor is returned if any query is executed, since it's used by
1150         subclasses such as InsertQuery). It's possible, however, that no query
1151         is needed, as the filters describe an empty set. In that case, None is
1152         returned, to avoid any unnecessary database interaction.
1153         """
1154         result_type = result_type or NO_RESULTS
1155         try:
1156             sql, params = self.as_sql()
1157             if not sql:
1158                 raise EmptyResultSet
1159         except EmptyResultSet:
1160             if result_type == MULTI:
1161                 return iter([])
1162             else:
1163                 return
1164         if chunked_fetch:
1165             cursor = self.connection.chunked_cursor()
1166         else:
1167             cursor = self.connection.cursor()
1168         try:
1169             cursor.execute(sql, params)
1170         except Exception:
1171             # Might fail for server-side cursors (e.g. connection closed)
1172             cursor.close()
1173             raise
1174 
1175         if result_type == CURSOR:
1176             # Give the caller the cursor to process and close.
1177             return cursor
1178         if result_type == SINGLE:
1179             try:
1180                 val = cursor.fetchone()
1181                 if val:
1182                     return val[0:self.col_count]
1183                 return val
1184             finally:
1185                 # done with the cursor
1186                 cursor.close()
1187         if result_type == NO_RESULTS:
1188             cursor.close()
1189             return
1190 
1191         result = cursor_iter(
1192             cursor, self.connection.features.empty_fetchmany_value,
1193             self.col_count if self.has_extra_select else None,
1194             chunk_size,
1195         )
1196         if not chunked_fetch or not self.connection.features.can_use_chunked_reads:
1197             try:
1198                 # If we are using non-chunked reads, we return the same data
1199                 # structure as normally, but ensure it is all read into memory
1200                 # before going any further. Use chunked_fetch if requested,
1201                 # unless the database doesn't support it.
1202                 return list(result)
1203             finally:
1204                 # done with the cursor
1205                 cursor.close()
1206         return result
1207 
1208     def as_subquery_condition(self, alias, columns, compiler):
1209         qn = compiler.quote_name_unless_alias
1210         qn2 = self.connection.ops.quote_name
1211 
1212         for index, select_col in enumerate(self.query.select):
1213             lhs_sql, lhs_params = self.compile(select_col)
1214             rhs = '%s.%s' % (qn(alias), qn2(columns[index]))
1215             self.query.where.add(
1216                 RawSQL('%s = %s' % (lhs_sql, rhs), lhs_params), 'AND')
1217 
1218         sql, params = self.as_sql()
1219         return 'EXISTS (%s)' % sql, params
1220 
1221     def explain_query(self):
1222         result = list(self.execute_sql())
1223         # Some backends return 1 item tuples with strings, and others return
1224         # tuples with integers and strings. Flatten them out into strings.
1225         for row in result[0]:
1226             if not isinstance(row, str):
1227                 yield ' '.join(str(c) for c in row)
1228             else:
1229                 yield row

</code><intended_behavior>This class provides additional context to the issue.</intended_behavior>, <file>django/db/models/expressions.py</file>
<class>ExpressionWrapper</class>
<method>get_group_by_cols</method>
<code>
917     def get_group_by_cols(self, alias=None):
918         expression = self.expression.copy()
919         expression.output_field = self.output_field
920         return expression.get_group_by_cols(alias=alias)

</code><intended_behavior>The intended behavior for this method is to ensure that ExpressionWrapper correctly informs the SQL compiler about how its contained expressions should influence the GROUP BY clause in SQL queries. Specifically, for boolean expressions or null checks encapsulated by an ExpressionWrapper, the method must ensure that the SQL compiler can translate and include these expressions accurately in the GROUP BY clause. This might involve providing additional metadata or flags from ExpressionWrapper to the compiler or ensuring that ExpressionWrapper's as_sql method or similar methods provide the necessary SQL correctly for grouping purposes.</intended_behavior>, <file>django/db/models/expressions.py</file>
<class>ExpressionWrapper</class>
<method>None</method>
<code>
901 class ExpressionWrapper(Expression):
902     """
903     An expression that can wrap another expression so that it can provide
904     extra context to the inner expression, such as the output_field.
905     """
906 
907     def __init__(self, expression, output_field):
908         super().__init__(output_field=output_field)
909         self.expression = expression
910 
911     def set_source_expressions(self, exprs):
912         self.expression = exprs[0]
913 
914     def get_source_expressions(self):
915         return [self.expression]
916 
917     def get_group_by_cols(self, alias=None):
918         expression = self.expression.copy()
919         expression.output_field = self.output_field
920         return expression.get_group_by_cols(alias=alias)
921 
922     def as_sql(self, compiler, connection):
923         return compiler.compile(self.expression)
924 
925     def __repr__(self):
926         return "{}({})".format(self.__class__.__name__, self.expression)

</code><intended_behavior>This class provides additional context to the issue.</intended_behavior>]
2025-10-17 12:36:28.998 | INFO     | Search completed. Bug locations: [<file>django/db/models/sql/compiler.py</file>
<class>SQLCompiler</class>
<method>get_group_by</method>
<code>
63     def get_group_by(self, select, order_by):
64         """
65         Return a list of 2-tuples of form (sql, params).
66 
67         The logic of what exactly the GROUP BY clause contains is hard
68         to describe in other words than "if it passes the test suite,
69         then it is correct".
70         """
71         # Some examples:
72         #     SomeModel.objects.annotate(Count('somecol'))
73         #     GROUP BY: all fields of the model
74         #
75         #    SomeModel.objects.values('name').annotate(Count('somecol'))
76         #    GROUP BY: name
77         #
78         #    SomeModel.objects.annotate(Count('somecol')).values('name')
79         #    GROUP BY: all cols of the model
80         #
81         #    SomeModel.objects.values('name', 'pk').annotate(Count('somecol')).values('pk')
82         #    GROUP BY: name, pk
83         #
84         #    SomeModel.objects.values('name').annotate(Count('somecol')).values('pk')
85         #    GROUP BY: name, pk
86         #
87         # In fact, the self.query.group_by is the minimal set to GROUP BY. It
88         # can't be ever restricted to a smaller set, but additional columns in
89         # HAVING, ORDER BY, and SELECT clauses are added to it. Unfortunately
90         # the end result is that it is impossible to force the query to have
91         # a chosen GROUP BY clause - you can almost do this by using the form:
92         #     .values(*wanted_cols).annotate(AnAggregate())
93         # but any later annotations, extra selects, values calls that
94         # refer some column outside of the wanted_cols, order_by, or even
95         # filter calls can alter the GROUP BY clause.
96 
97         # The query.group_by is either None (no GROUP BY at all), True
98         # (group by select fields), or a list of expressions to be added
99         # to the group by.
100         if self.query.group_by is None:
101             return []
102         expressions = []
103         if self.query.group_by is not True:
104             # If the group by is set to a list (by .values() call most likely),
105             # then we need to add everything in it to the GROUP BY clause.
106             # Backwards compatibility hack for setting query.group_by. Remove
107             # when  we have public API way of forcing the GROUP BY clause.
108             # Converts string references to expressions.
109             for expr in self.query.group_by:
110                 if not hasattr(expr, 'as_sql'):
111                     expressions.append(self.query.resolve_ref(expr))
112                 else:
113                     expressions.append(expr)
114         # Note that even if the group_by is set, it is only the minimal
115         # set to group by. So, we need to add cols in select, order_by, and
116         # having into the select in any case.
117         ref_sources = {
118             expr.source for expr in expressions if isinstance(expr, Ref)
119         }
120         for expr, _, _ in select:
121             # Skip members of the select clause that are already included
122             # by reference.
123             if expr in ref_sources:
124                 continue
125             cols = expr.get_group_by_cols()
126             for col in cols:
127                 expressions.append(col)
128         for expr, (sql, params, is_ref) in order_by:
129             # Skip References to the select clause, as all expressions in the
130             # select clause are already part of the group by.
131             if not is_ref:
132                 expressions.extend(expr.get_group_by_cols())
133         having_group_by = self.having.get_group_by_cols() if self.having else ()
134         for expr in having_group_by:
135             expressions.append(expr)
136         result = []
137         seen = set()
138         expressions = self.collapse_group_by(expressions, having_group_by)
139 
140         for expr in expressions:
141             sql, params = self.compile(expr)
142             sql, params = expr.select_format(self, sql, params)
143             params_hash = make_hashable(params)
144             if (sql, params_hash) not in seen:
145                 result.append((sql, params))
146                 seen.add((sql, params_hash))
147         return result

</code><intended_behavior>This method should ensure that when it compiles the GROUP BY clauses for SQL queries, it fully accounts for and includes expressions wrapped by ExpressionWrapper, especially those that transform field values, such as IS NULL checks or boolean evaluations. The intended behavior is to modify or ensure the method accurately represents all parts of the ORM query in the SQL command, especially expressions that might not directly map to a single database column or simple SQL expressions. This must maintain the current functionality for other use cases and only augment the handling of special cases like expression wrappers that evaluate to boolean conditions or perform null checks.</intended_behavior>, <file>django/db/models/sql/compiler.py</file>
<class>SQLCompiler</class>
<method>None</method>
<code>
22 class SQLCompiler:
23     # Multiline ordering SQL clause may appear from RawSQL.
24     ordering_parts = _lazy_re_compile(
25         r'^(.*)\s(?:ASC|DESC).*',
26         re.MULTILINE | re.DOTALL,
27     )
28 
29     def __init__(self, query, connection, using):
30         self.query = query
31         self.connection = connection
32         self.using = using
33         self.quote_cache = {'*': '*'}
34         # The select, klass_info, and annotations are needed by QuerySet.iterator()
35         # these are set as a side-effect of executing the query. Note that we calculate
36         # separately a list of extra select columns needed for grammatical correctness
37         # of the query, but these columns are not included in self.select.
38         self.select = None
39         self.annotation_col_map = None
40         self.klass_info = None
41         self._meta_ordering = None
42 
43     def setup_query(self):
44         if all(self.query.alias_refcount[a] == 0 for a in self.query.alias_map):
45             self.query.get_initial_alias()
46         self.select, self.klass_info, self.annotation_col_map = self.get_select()
47         self.col_count = len(self.select)
48 
49     def pre_sql_setup(self):
50         """
51         Do any necessary class setup immediately prior to producing SQL. This
52         is for things that can't necessarily be done in __init__ because we
53         might not have all the pieces in place at that time.
54         """
55         self.setup_query()
56         order_by = self.get_order_by()
57         self.where, self.having = self.query.where.split_having()
58         extra_select = self.get_extra_select(order_by, self.select)
59         self.has_extra_select = bool(extra_select)
60         group_by = self.get_group_by(self.select + extra_select, order_by)
61         return extra_select, order_by, group_by
62 
63     def get_group_by(self, select, order_by):
64         """
65         Return a list of 2-tuples of form (sql, params).
66 
67         The logic of what exactly the GROUP BY clause contains is hard
68         to describe in other words than "if it passes the test suite,
69         then it is correct".
70         """
71         # Some examples:
72         #     SomeModel.objects.annotate(Count('somecol'))
73         #     GROUP BY: all fields of the model
74         #
75         #    SomeModel.objects.values('name').annotate(Count('somecol'))
76         #    GROUP BY: name
77         #
78         #    SomeModel.objects.annotate(Count('somecol')).values('name')
79         #    GROUP BY: all cols of the model
80         #
81         #    SomeModel.objects.values('name', 'pk').annotate(Count('somecol')).values('pk')
82         #    GROUP BY: name, pk
83         #
84         #    SomeModel.objects.values('name').annotate(Count('somecol')).values('pk')
85         #    GROUP BY: name, pk
86         #
87         # In fact, the self.query.group_by is the minimal set to GROUP BY. It
88         # can't be ever restricted to a smaller set, but additional columns in
89         # HAVING, ORDER BY, and SELECT clauses are added to it. Unfortunately
90         # the end result is that it is impossible to force the query to have
91         # a chosen GROUP BY clause - you can almost do this by using the form:
92         #     .values(*wanted_cols).annotate(AnAggregate())
93         # but any later annotations, extra selects, values calls that
94         # refer some column outside of the wanted_cols, order_by, or even
95         # filter calls can alter the GROUP BY clause.
96 
97         # The query.group_by is either None (no GROUP BY at all), True
98         # (group by select fields), or a list of expressions to be added
99         # to the group by.
100         if self.query.group_by is None:
101             return []
102         expressions = []
103         if self.query.group_by is not True:
104             # If the group by is set to a list (by .values() call most likely),
105             # then we need to add everything in it to the GROUP BY clause.
106             # Backwards compatibility hack for setting query.group_by. Remove
107             # when  we have public API way of forcing the GROUP BY clause.
108             # Converts string references to expressions.
109             for expr in self.query.group_by:
110                 if not hasattr(expr, 'as_sql'):
111                     expressions.append(self.query.resolve_ref(expr))
112                 else:
113                     expressions.append(expr)
114         # Note that even if the group_by is set, it is only the minimal
115         # set to group by. So, we need to add cols in select, order_by, and
116         # having into the select in any case.
117         ref_sources = {
118             expr.source for expr in expressions if isinstance(expr, Ref)
119         }
120         for expr, _, _ in select:
121             # Skip members of the select clause that are already included
122             # by reference.
123             if expr in ref_sources:
124                 continue
125             cols = expr.get_group_by_cols()
126             for col in cols:
127                 expressions.append(col)
128         for expr, (sql, params, is_ref) in order_by:
129             # Skip References to the select clause, as all expressions in the
130             # select clause are already part of the group by.
131             if not is_ref:
132                 expressions.extend(expr.get_group_by_cols())
133         having_group_by = self.having.get_group_by_cols() if self.having else ()
134         for expr in having_group_by:
135             expressions.append(expr)
136         result = []
137         seen = set()
138         expressions = self.collapse_group_by(expressions, having_group_by)
139 
140         for expr in expressions:
141             sql, params = self.compile(expr)
142             sql, params = expr.select_format(self, sql, params)
143             params_hash = make_hashable(params)
144             if (sql, params_hash) not in seen:
145                 result.append((sql, params))
146                 seen.add((sql, params_hash))
147         return result
148 
149     def collapse_group_by(self, expressions, having):
150         # If the DB can group by primary key, then group by the primary key of
151         # query's main model. Note that for PostgreSQL the GROUP BY clause must
152         # include the primary key of every table, but for MySQL it is enough to
153         # have the main table's primary key.
154         if self.connection.features.allows_group_by_pk:
155             # Determine if the main model's primary key is in the query.
156             pk = None
157             for expr in expressions:
158                 # Is this a reference to query's base table primary key? If the
159                 # expression isn't a Col-like, then skip the expression.
160                 if (getattr(expr, 'target', None) == self.query.model._meta.pk and
161                         getattr(expr, 'alias', None) == self.query.base_table):
162                     pk = expr
163                     break
164             # If the main model's primary key is in the query, group by that
165             # field, HAVING expressions, and expressions associated with tables
166             # that don't have a primary key included in the grouped columns.
167             if pk:
168                 pk_aliases = {
169                     expr.alias for expr in expressions
170                     if hasattr(expr, 'target') and expr.target.primary_key
171                 }
172                 expressions = [pk] + [
173                     expr for expr in expressions
174                     if expr in having or (
175                         getattr(expr, 'alias', None) is not None and expr.alias not in pk_aliases
176                     )
177                 ]
178         elif self.connection.features.allows_group_by_selected_pks:
179             # Filter out all expressions associated with a table's primary key
180             # present in the grouped columns. This is done by identifying all
181             # tables that have their primary key included in the grouped
182             # columns and removing non-primary key columns referring to them.
183             # Unmanaged models are excluded because they could be representing
184             # database views on which the optimization might not be allowed.
185             pks = {
186                 expr for expr in expressions
187                 if (
188                     hasattr(expr, 'target') and
189                     expr.target.primary_key and
190                     self.connection.features.allows_group_by_selected_pks_on_model(expr.target.model)
191                 )
192             }
193             aliases = {expr.alias for expr in pks}
194             expressions = [
195                 expr for expr in expressions if expr in pks or getattr(expr, 'alias', None) not in aliases
196             ]
197         return expressions
198 
199     def get_select(self):
200         """
201         Return three values:
202         - a list of 3-tuples of (expression, (sql, params), alias)
203         - a klass_info structure,
204         - a dictionary of annotations
205 
206         The (sql, params) is what the expression will produce, and alias is the
207         "AS alias" for the column (possibly None).
208 
209         The klass_info structure contains the following information:
210         - The base model of the query.
211         - Which columns for that model are present in the query (by
212           position of the select clause).
213         - related_klass_infos: [f, klass_info] to descent into
214 
215         The annotations is a dictionary of {'attname': column position} values.
216         """
217         select = []
218         klass_info = None
219         annotations = {}
220         select_idx = 0
221         for alias, (sql, params) in self.query.extra_select.items():
222             annotations[alias] = select_idx
223             select.append((RawSQL(sql, params), alias))
224             select_idx += 1
225         assert not (self.query.select and self.query.default_cols)
226         if self.query.default_cols:
227             cols = self.get_default_columns()
228         else:
229             # self.query.select is a special case. These columns never go to
230             # any model.
231             cols = self.query.select
232         if cols:
233             select_list = []
234             for col in cols:
235                 select_list.append(select_idx)
236                 select.append((col, None))
237                 select_idx += 1
238             klass_info = {
239                 'model': self.query.model,
240                 'select_fields': select_list,
241             }
242         for alias, annotation in self.query.annotation_select.items():
243             annotations[alias] = select_idx
244             select.append((annotation, alias))
245             select_idx += 1
246 
247         if self.query.select_related:
248             related_klass_infos = self.get_related_selections(select)
249             klass_info['related_klass_infos'] = related_klass_infos
250 
251             def get_select_from_parent(klass_info):
252                 for ki in klass_info['related_klass_infos']:
253                     if ki['from_parent']:
254                         ki['select_fields'] = (klass_info['select_fields'] +
255                                                ki['select_fields'])
256                     get_select_from_parent(ki)
257             get_select_from_parent(klass_info)
258 
259         ret = []
260         for col, alias in select:
261             try:
262                 sql, params = self.compile(col)
263             except EmptyResultSet:
264                 # Select a predicate that's always False.
265                 sql, params = '0', ()
266             else:
267                 sql, params = col.select_format(self, sql, params)
268             ret.append((col, (sql, params), alias))
269         return ret, klass_info, annotations
270 
271     def get_order_by(self):
272         """
273         Return a list of 2-tuples of form (expr, (sql, params, is_ref)) for the
274         ORDER BY clause.
275 
276         The order_by clause can alter the select clause (for example it
277         can add aliases to clauses that do not yet have one, or it can
278         add totally new select clauses).
279         """
280         if self.query.extra_order_by:
281             ordering = self.query.extra_order_by
282         elif not self.query.default_ordering:
283             ordering = self.query.order_by
284         elif self.query.order_by:
285             ordering = self.query.order_by
286         elif self.query.get_meta().ordering:
287             ordering = self.query.get_meta().ordering
288             self._meta_ordering = ordering
289         else:
290             ordering = []
291         if self.query.standard_ordering:
292             asc, desc = ORDER_DIR['ASC']
293         else:
294             asc, desc = ORDER_DIR['DESC']
295 
296         order_by = []
297         for field in ordering:
298             if hasattr(field, 'resolve_expression'):
299                 if isinstance(field, Value):
300                     # output_field must be resolved for constants.
301                     field = Cast(field, field.output_field)
302                 if not isinstance(field, OrderBy):
303                     field = field.asc()
304                 if not self.query.standard_ordering:
305                     field = field.copy()
306                     field.reverse_ordering()
307                 order_by.append((field, False))
308                 continue
309             if field == '?':  # random
310                 order_by.append((OrderBy(Random()), False))
311                 continue
312 
313             col, order = get_order_dir(field, asc)
314             descending = order == 'DESC'
315 
316             if col in self.query.annotation_select:
317                 # Reference to expression in SELECT clause
318                 order_by.append((
319                     OrderBy(Ref(col, self.query.annotation_select[col]), descending=descending),
320                     True))
321                 continue
322             if col in self.query.annotations:
323                 # References to an expression which is masked out of the SELECT
324                 # clause.
325                 if self.query.combinator and self.select:
326                     # Don't use the resolved annotation because other
327                     # combinated queries might define it differently.
328                     expr = F(col)
329                 else:
330                     expr = self.query.annotations[col]
331                     if isinstance(expr, Value):
332                         # output_field must be resolved for constants.
333                         expr = Cast(expr, expr.output_field)
334                 order_by.append((OrderBy(expr, descending=descending), False))
335                 continue
336 
337             if '.' in field:
338                 # This came in through an extra(order_by=...) addition. Pass it
339                 # on verbatim.
340                 table, col = col.split('.', 1)
341                 order_by.append((
342                     OrderBy(
343                         RawSQL('%s.%s' % (self.quote_name_unless_alias(table), col), []),
344                         descending=descending
345                     ), False))
346                 continue
347 
348             if not self.query.extra or col not in self.query.extra:
349                 # 'col' is of the form 'field' or 'field1__field2' or
350                 # '-field1__field2__field', etc.
351                 order_by.extend(self.find_ordering_name(
352                     field, self.query.get_meta(), default_order=asc))
353             else:
354                 if col not in self.query.extra_select:
355                     order_by.append((
356                         OrderBy(RawSQL(*self.query.extra[col]), descending=descending),
357                         False))
358                 else:
359                     order_by.append((
360                         OrderBy(Ref(col, RawSQL(*self.query.extra[col])), descending=descending),
361                         True))
362         result = []
363         seen = set()
364 
365         for expr, is_ref in order_by:
366             resolved = expr.resolve_expression(self.query, allow_joins=True, reuse=None)
367             if self.query.combinator and self.select:
368                 src = resolved.get_source_expressions()[0]
369                 expr_src = expr.get_source_expressions()[0]
370                 # Relabel order by columns to raw numbers if this is a combined
371                 # query; necessary since the columns can't be referenced by the
372                 # fully qualified name and the simple column names may collide.
373                 for idx, (sel_expr, _, col_alias) in enumerate(self.select):
374                     if is_ref and col_alias == src.refs:
375                         src = src.source
376                     elif col_alias and not (
377                         isinstance(expr_src, F) and col_alias == expr_src.name
378                     ):
379                         continue
380                     if src == sel_expr:
381                         resolved.set_source_expressions([RawSQL('%d' % (idx + 1), ())])
382                         break
383                 else:
384                     if col_alias:
385                         raise DatabaseError('ORDER BY term does not match any column in the result set.')
386                     # Add column used in ORDER BY clause to the selected
387                     # columns and to each combined query.
388                     order_by_idx = len(self.query.select) + 1
389                     col_name = f'__orderbycol{order_by_idx}'
390                     for q in self.query.combined_queries:
391                         q.add_annotation(expr_src, col_name)
392                     self.query.add_select_col(resolved, col_name)
393                     resolved.set_source_expressions([RawSQL(f'{order_by_idx}', ())])
394             sql, params = self.compile(resolved)
395             # Don't add the same column twice, but the order direction is
396             # not taken into account so we strip it. When this entire method
397             # is refactored into expressions, then we can check each part as we
398             # generate it.
399             without_ordering = self.ordering_parts.search(sql)[1]
400             params_hash = make_hashable(params)
401             if (without_ordering, params_hash) in seen:
402                 continue
403             seen.add((without_ordering, params_hash))
404             result.append((resolved, (sql, params, is_ref)))
405         return result
406 
407     def get_extra_select(self, order_by, select):
408         extra_select = []
409         if self.query.distinct and not self.query.distinct_fields:
410             select_sql = [t[1] for t in select]
411             for expr, (sql, params, is_ref) in order_by:
412                 without_ordering = self.ordering_parts.search(sql)[1]
413                 if not is_ref and (without_ordering, params) not in select_sql:
414                     extra_select.append((expr, (without_ordering, params), None))
415         return extra_select
416 
417     def quote_name_unless_alias(self, name):
418         """
419         A wrapper around connection.ops.quote_name that doesn't quote aliases
420         for table names. This avoids problems with some SQL dialects that treat
421         quoted strings specially (e.g. PostgreSQL).
422         """
423         if name in self.quote_cache:
424             return self.quote_cache[name]
425         if ((name in self.query.alias_map and name not in self.query.table_map) or
426                 name in self.query.extra_select or (
427                     self.query.external_aliases.get(name) and name not in self.query.table_map)):
428             self.quote_cache[name] = name
429             return name
430         r = self.connection.ops.quote_name(name)
431         self.quote_cache[name] = r
432         return r
433 
434     def compile(self, node):
435         vendor_impl = getattr(node, 'as_' + self.connection.vendor, None)
436         if vendor_impl:
437             sql, params = vendor_impl(self, self.connection)
438         else:
439             sql, params = node.as_sql(self, self.connection)
440         return sql, params
441 
442     def get_combinator_sql(self, combinator, all):
443         features = self.connection.features
444         compilers = [
445             query.get_compiler(self.using, self.connection)
446             for query in self.query.combined_queries if not query.is_empty()
447         ]
448         if not features.supports_slicing_ordering_in_compound:
449             for query, compiler in zip(self.query.combined_queries, compilers):
450                 if query.low_mark or query.high_mark:
451                     raise DatabaseError('LIMIT/OFFSET not allowed in subqueries of compound statements.')
452                 if compiler.get_order_by():
453                     raise DatabaseError('ORDER BY not allowed in subqueries of compound statements.')
454         parts = ()
455         for compiler in compilers:
456             try:
457                 # If the columns list is limited, then all combined queries
458                 # must have the same columns list. Set the selects defined on
459                 # the query on all combined queries, if not already set.
460                 if not compiler.query.values_select and self.query.values_select:
461                     compiler.query = compiler.query.clone()
462                     compiler.query.set_values((
463                         *self.query.extra_select,
464                         *self.query.values_select,
465                         *self.query.annotation_select,
466                     ))
467                 part_sql, part_args = compiler.as_sql()
468                 if compiler.query.combinator:
469                     # Wrap in a subquery if wrapping in parentheses isn't
470                     # supported.
471                     if not features.supports_parentheses_in_compound:
472                         part_sql = 'SELECT * FROM ({})'.format(part_sql)
473                     # Add parentheses when combining with compound query if not
474                     # already added for all compound queries.
475                     elif not features.supports_slicing_ordering_in_compound:
476                         part_sql = '({})'.format(part_sql)
477                 parts += ((part_sql, part_args),)
478             except EmptyResultSet:
479                 # Omit the empty queryset with UNION and with DIFFERENCE if the
480                 # first queryset is nonempty.
481                 if combinator == 'union' or (combinator == 'difference' and parts):
482                     continue
483                 raise
484         if not parts:
485             raise EmptyResultSet
486         combinator_sql = self.connection.ops.set_operators[combinator]
487         if all and combinator == 'union':
488             combinator_sql += ' ALL'
489         braces = '({})' if features.supports_slicing_ordering_in_compound else '{}'
490         sql_parts, args_parts = zip(*((braces.format(sql), args) for sql, args in parts))
491         result = [' {} '.format(combinator_sql).join(sql_parts)]
492         params = []
493         for part in args_parts:
494             params.extend(part)
495         return result, params
496 
497     def as_sql(self, with_limits=True, with_col_aliases=False):
498         """
499         Create the SQL for this query. Return the SQL string and list of
500         parameters.
501 
502         If 'with_limits' is False, any limit/offset information is not included
503         in the query.
504         """
505         refcounts_before = self.query.alias_refcount.copy()
506         try:
507             extra_select, order_by, group_by = self.pre_sql_setup()
508             for_update_part = None
509             # Is a LIMIT/OFFSET clause needed?
510             with_limit_offset = with_limits and (self.query.high_mark is not None or self.query.low_mark)
511             combinator = self.query.combinator
512             features = self.connection.features
513             if combinator:
514                 if not getattr(features, 'supports_select_{}'.format(combinator)):
515                     raise NotSupportedError('{} is not supported on this database backend.'.format(combinator))
516                 result, params = self.get_combinator_sql(combinator, self.query.combinator_all)
517             else:
518                 distinct_fields, distinct_params = self.get_distinct()
519                 # This must come after 'select', 'ordering', and 'distinct'
520                 # (see docstring of get_from_clause() for details).
521                 from_, f_params = self.get_from_clause()
522                 where, w_params = self.compile(self.where) if self.where is not None else ("", [])
523                 having, h_params = self.compile(self.having) if self.having is not None else ("", [])
524                 result = ['SELECT']
525                 params = []
526 
527                 if self.query.distinct:
528                     distinct_result, distinct_params = self.connection.ops.distinct_sql(
529                         distinct_fields,
530                         distinct_params,
531                     )
532                     result += distinct_result
533                     params += distinct_params
534 
535                 out_cols = []
536                 col_idx = 1
537                 for _, (s_sql, s_params), alias in self.select + extra_select:
538                     if alias:
539                         s_sql = '%s AS %s' % (s_sql, self.connection.ops.quote_name(alias))
540                     elif with_col_aliases:
541                         s_sql = '%s AS %s' % (s_sql, 'Col%d' % col_idx)
542                         col_idx += 1
543                     params.extend(s_params)
544                     out_cols.append(s_sql)
545 
546                 result += [', '.join(out_cols), 'FROM', *from_]
547                 params.extend(f_params)
548 
549                 if self.query.select_for_update and self.connection.features.has_select_for_update:
550                     if self.connection.get_autocommit():
551                         raise TransactionManagementError('select_for_update cannot be used outside of a transaction.')
552 
553                     if with_limit_offset and not self.connection.features.supports_select_for_update_with_limit:
554                         raise NotSupportedError(
555                             'LIMIT/OFFSET is not supported with '
556                             'select_for_update on this database backend.'
557                         )
558                     nowait = self.query.select_for_update_nowait
559                     skip_locked = self.query.select_for_update_skip_locked
560                     of = self.query.select_for_update_of
561                     no_key = self.query.select_for_no_key_update
562                     # If it's a NOWAIT/SKIP LOCKED/OF/NO KEY query but the
563                     # backend doesn't support it, raise NotSupportedError to
564                     # prevent a possible deadlock.
565                     if nowait and not self.connection.features.has_select_for_update_nowait:
566                         raise NotSupportedError('NOWAIT is not supported on this database backend.')
567                     elif skip_locked and not self.connection.features.has_select_for_update_skip_locked:
568                         raise NotSupportedError('SKIP LOCKED is not supported on this database backend.')
569                     elif of and not self.connection.features.has_select_for_update_of:
570                         raise NotSupportedError('FOR UPDATE OF is not supported on this database backend.')
571                     elif no_key and not self.connection.features.has_select_for_no_key_update:
572                         raise NotSupportedError(
573                             'FOR NO KEY UPDATE is not supported on this '
574                             'database backend.'
575                         )
576                     for_update_part = self.connection.ops.for_update_sql(
577                         nowait=nowait,
578                         skip_locked=skip_locked,
579                         of=self.get_select_for_update_of_arguments(),
580                         no_key=no_key,
581                     )
582 
583                 if for_update_part and self.connection.features.for_update_after_from:
584                     result.append(for_update_part)
585 
586                 if where:
587                     result.append('WHERE %s' % where)
588                     params.extend(w_params)
589 
590                 grouping = []
591                 for g_sql, g_params in group_by:
592                     grouping.append(g_sql)
593                     params.extend(g_params)
594                 if grouping:
595                     if distinct_fields:
596                         raise NotImplementedError('annotate() + distinct(fields) is not implemented.')
597                     order_by = order_by or self.connection.ops.force_no_ordering()
598                     result.append('GROUP BY %s' % ', '.join(grouping))
599                     if self._meta_ordering:
600                         order_by = None
601                 if having:
602                     result.append('HAVING %s' % having)
603                     params.extend(h_params)
604 
605             if self.query.explain_query:
606                 result.insert(0, self.connection.ops.explain_query_prefix(
607                     self.query.explain_format,
608                     **self.query.explain_options
609                 ))
610 
611             if order_by:
612                 ordering = []
613                 for _, (o_sql, o_params, _) in order_by:
614                     ordering.append(o_sql)
615                     params.extend(o_params)
616                 result.append('ORDER BY %s' % ', '.join(ordering))
617 
618             if with_limit_offset:
619                 result.append(self.connection.ops.limit_offset_sql(self.query.low_mark, self.query.high_mark))
620 
621             if for_update_part and not self.connection.features.for_update_after_from:
622                 result.append(for_update_part)
623 
624             if self.query.subquery and extra_select:
625                 # If the query is used as a subquery, the extra selects would
626                 # result in more columns than the left-hand side expression is
627                 # expecting. This can happen when a subquery uses a combination
628                 # of order_by() and distinct(), forcing the ordering expressions
629                 # to be selected as well. Wrap the query in another subquery
630                 # to exclude extraneous selects.
631                 sub_selects = []
632                 sub_params = []
633                 for index, (select, _, alias) in enumerate(self.select, start=1):
634                     if not alias and with_col_aliases:
635                         alias = 'col%d' % index
636                     if alias:
637                         sub_selects.append("%s.%s" % (
638                             self.connection.ops.quote_name('subquery'),
639                             self.connection.ops.quote_name(alias),
640                         ))
641                     else:
642                         select_clone = select.relabeled_clone({select.alias: 'subquery'})
643                         subselect, subparams = select_clone.as_sql(self, self.connection)
644                         sub_selects.append(subselect)
645                         sub_params.extend(subparams)
646                 return 'SELECT %s FROM (%s) subquery' % (
647                     ', '.join(sub_selects),
648                     ' '.join(result),
649                 ), tuple(sub_params + params)
650 
651             return ' '.join(result), tuple(params)
652         finally:
653             # Finally do cleanup - get rid of the joins we created above.
654             self.query.reset_refcounts(refcounts_before)
655 
656     def get_default_columns(self, start_alias=None, opts=None, from_parent=None):
657         """
658         Compute the default columns for selecting every field in the base
659         model. Will sometimes be called to pull in related models (e.g. via
660         select_related), in which case "opts" and "start_alias" will be given
661         to provide a starting point for the traversal.
662 
663         Return a list of strings, quoted appropriately for use in SQL
664         directly, as well as a set of aliases used in the select statement (if
665         'as_pairs' is True, return a list of (alias, col_name) pairs instead
666         of strings as the first component and None as the second component).
667         """
668         result = []
669         if opts is None:
670             opts = self.query.get_meta()
671         only_load = self.deferred_to_columns()
672         start_alias = start_alias or self.query.get_initial_alias()
673         # The 'seen_models' is used to optimize checking the needed parent
674         # alias for a given field. This also includes None -> start_alias to
675         # be used by local fields.
676         seen_models = {None: start_alias}
677 
678         for field in opts.concrete_fields:
679             model = field.model._meta.concrete_model
680             # A proxy model will have a different model and concrete_model. We
681             # will assign None if the field belongs to this model.
682             if model == opts.model:
683                 model = None
684             if from_parent and model is not None and issubclass(
685                     from_parent._meta.concrete_model, model._meta.concrete_model):
686                 # Avoid loading data for already loaded parents.
687                 # We end up here in the case select_related() resolution
688                 # proceeds from parent model to child model. In that case the
689                 # parent model data is already present in the SELECT clause,
690                 # and we want to avoid reloading the same data again.
691                 continue
692             if field.model in only_load and field.attname not in only_load[field.model]:
693                 continue
694             alias = self.query.join_parent_model(opts, model, start_alias,
695                                                  seen_models)
696             column = field.get_col(alias)
697             result.append(column)
698         return result
699 
700     def get_distinct(self):
701         """
702         Return a quoted list of fields to use in DISTINCT ON part of the query.
703 
704         This method can alter the tables in the query, and thus it must be
705         called before get_from_clause().
706         """
707         result = []
708         params = []
709         opts = self.query.get_meta()
710 
711         for name in self.query.distinct_fields:
712             parts = name.split(LOOKUP_SEP)
713             _, targets, alias, joins, path, _, transform_function = self._setup_joins(parts, opts, None)
714             targets, alias, _ = self.query.trim_joins(targets, joins, path)
715             for target in targets:
716                 if name in self.query.annotation_select:
717                     result.append(name)
718                 else:
719                     r, p = self.compile(transform_function(target, alias))
720                     result.append(r)
721                     params.append(p)
722         return result, params
723 
724     def find_ordering_name(self, name, opts, alias=None, default_order='ASC',
725                            already_seen=None):
726         """
727         Return the table alias (the name might be ambiguous, the alias will
728         not be) and column name for ordering by the given 'name' parameter.
729         The 'name' is of the form 'field1__field2__...__fieldN'.
730         """
731         name, order = get_order_dir(name, default_order)
732         descending = order == 'DESC'
733         pieces = name.split(LOOKUP_SEP)
734         field, targets, alias, joins, path, opts, transform_function = self._setup_joins(pieces, opts, alias)
735 
736         # If we get to this point and the field is a relation to another model,
737         # append the default ordering for that model unless it is the pk
738         # shortcut or the attribute name of the field that is specified.
739         if (
740             field.is_relation and
741             opts.ordering and
742             getattr(field, 'attname', None) != pieces[-1] and
743             name != 'pk'
744         ):
745             # Firstly, avoid infinite loops.
746             already_seen = already_seen or set()
747             join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)
748             if join_tuple in already_seen:
749                 raise FieldError('Infinite loop caused by ordering.')
750             already_seen.add(join_tuple)
751 
752             results = []
753             for item in opts.ordering:
754                 if hasattr(item, 'resolve_expression') and not isinstance(item, OrderBy):
755                     item = item.desc() if descending else item.asc()
756                 if isinstance(item, OrderBy):
757                     results.append((item, False))
758                     continue
759                 results.extend(self.find_ordering_name(item, opts, alias,
760                                                        order, already_seen))
761             return results
762         targets, alias, _ = self.query.trim_joins(targets, joins, path)
763         return [(OrderBy(transform_function(t, alias), descending=descending), False) for t in targets]
764 
765     def _setup_joins(self, pieces, opts, alias):
766         """
767         Helper method for get_order_by() and get_distinct().
768 
769         get_ordering() and get_distinct() must produce same target columns on
770         same input, as the prefixes of get_ordering() and get_distinct() must
771         match. Executing SQL where this is not true is an error.
772         """
773         alias = alias or self.query.get_initial_alias()
774         field, targets, opts, joins, path, transform_function = self.query.setup_joins(pieces, opts, alias)
775         alias = joins[-1]
776         return field, targets, alias, joins, path, opts, transform_function
777 
778     def get_from_clause(self):
779         """
780         Return a list of strings that are joined together to go after the
781         "FROM" part of the query, as well as a list any extra parameters that
782         need to be included. Subclasses, can override this to create a
783         from-clause via a "select".
784 
785         This should only be called after any SQL construction methods that
786         might change the tables that are needed. This means the select columns,
787         ordering, and distinct must be done first.
788         """
789         result = []
790         params = []
791         for alias in tuple(self.query.alias_map):
792             if not self.query.alias_refcount[alias]:
793                 continue
794             try:
795                 from_clause = self.query.alias_map[alias]
796             except KeyError:
797                 # Extra tables can end up in self.tables, but not in the
798                 # alias_map if they aren't in a join. That's OK. We skip them.
799                 continue
800             clause_sql, clause_params = self.compile(from_clause)
801             result.append(clause_sql)
802             params.extend(clause_params)
803         for t in self.query.extra_tables:
804             alias, _ = self.query.table_alias(t)
805             # Only add the alias if it's not already present (the table_alias()
806             # call increments the refcount, so an alias refcount of one means
807             # this is the only reference).
808             if alias not in self.query.alias_map or self.query.alias_refcount[alias] == 1:
809                 result.append(', %s' % self.quote_name_unless_alias(alias))
810         return result, params
811 
812     def get_related_selections(self, select, opts=None, root_alias=None, cur_depth=1,
813                                requested=None, restricted=None):
814         """
815         Fill in the information needed for a select_related query. The current
816         depth is measured as the number of connections away from the root model
817         (for example, cur_depth=1 means we are looking at models with direct
818         connections to the root model).
819         """
820         def _get_field_choices():
821             direct_choices = (f.name for f in opts.fields if f.is_relation)
822             reverse_choices = (
823                 f.field.related_query_name()
824                 for f in opts.related_objects if f.field.unique
825             )
826             return chain(direct_choices, reverse_choices, self.query._filtered_relations)
827 
828         related_klass_infos = []
829         if not restricted and cur_depth > self.query.max_depth:
830             # We've recursed far enough; bail out.
831             return related_klass_infos
832 
833         if not opts:
834             opts = self.query.get_meta()
835             root_alias = self.query.get_initial_alias()
836         only_load = self.query.get_loaded_field_names()
837 
838         # Setup for the case when only particular related fields should be
839         # included in the related selection.
840         fields_found = set()
841         if requested is None:
842             restricted = isinstance(self.query.select_related, dict)
843             if restricted:
844                 requested = self.query.select_related
845 
846         def get_related_klass_infos(klass_info, related_klass_infos):
847             klass_info['related_klass_infos'] = related_klass_infos
848 
849         for f in opts.fields:
850             field_model = f.model._meta.concrete_model
851             fields_found.add(f.name)
852 
853             if restricted:
854                 next = requested.get(f.name, {})
855                 if not f.is_relation:
856                     # If a non-related field is used like a relation,
857                     # or if a single non-relational field is given.
858                     if next or f.name in requested:
859                         raise FieldError(
860                             "Non-relational field given in select_related: '%s'. "
861                             "Choices are: %s" % (
862                                 f.name,
863                                 ", ".join(_get_field_choices()) or '(none)',
864                             )
865                         )
866             else:
867                 next = False
868 
869             if not select_related_descend(f, restricted, requested,
870                                           only_load.get(field_model)):
871                 continue
872             klass_info = {
873                 'model': f.remote_field.model,
874                 'field': f,
875                 'reverse': False,
876                 'local_setter': f.set_cached_value,
877                 'remote_setter': f.remote_field.set_cached_value if f.unique else lambda x, y: None,
878                 'from_parent': False,
879             }
880             related_klass_infos.append(klass_info)
881             select_fields = []
882             _, _, _, joins, _, _ = self.query.setup_joins(
883                 [f.name], opts, root_alias)
884             alias = joins[-1]
885             columns = self.get_default_columns(start_alias=alias, opts=f.remote_field.model._meta)
886             for col in columns:
887                 select_fields.append(len(select))
888                 select.append((col, None))
889             klass_info['select_fields'] = select_fields
890             next_klass_infos = self.get_related_selections(
891                 select, f.remote_field.model._meta, alias, cur_depth + 1, next, restricted)
892             get_related_klass_infos(klass_info, next_klass_infos)
893 
894         if restricted:
895             related_fields = [
896                 (o.field, o.related_model)
897                 for o in opts.related_objects
898                 if o.field.unique and not o.many_to_many
899             ]
900             for f, model in related_fields:
901                 if not select_related_descend(f, restricted, requested,
902                                               only_load.get(model), reverse=True):
903                     continue
904 
905                 related_field_name = f.related_query_name()
906                 fields_found.add(related_field_name)
907 
908                 join_info = self.query.setup_joins([related_field_name], opts, root_alias)
909                 alias = join_info.joins[-1]
910                 from_parent = issubclass(model, opts.model) and model is not opts.model
911                 klass_info = {
912                     'model': model,
913                     'field': f,
914                     'reverse': True,
915                     'local_setter': f.remote_field.set_cached_value,
916                     'remote_setter': f.set_cached_value,
917                     'from_parent': from_parent,
918                 }
919                 related_klass_infos.append(klass_info)
920                 select_fields = []
921                 columns = self.get_default_columns(
922                     start_alias=alias, opts=model._meta, from_parent=opts.model)
923                 for col in columns:
924                     select_fields.append(len(select))
925                     select.append((col, None))
926                 klass_info['select_fields'] = select_fields
927                 next = requested.get(f.related_query_name(), {})
928                 next_klass_infos = self.get_related_selections(
929                     select, model._meta, alias, cur_depth + 1,
930                     next, restricted)
931                 get_related_klass_infos(klass_info, next_klass_infos)
932 
933             def local_setter(obj, from_obj):
934                 # Set a reverse fk object when relation is non-empty.
935                 if from_obj:
936                     f.remote_field.set_cached_value(from_obj, obj)
937 
938             def remote_setter(name, obj, from_obj):
939                 setattr(from_obj, name, obj)
940 
941             for name in list(requested):
942                 # Filtered relations work only on the topmost level.
943                 if cur_depth > 1:
944                     break
945                 if name in self.query._filtered_relations:
946                     fields_found.add(name)
947                     f, _, join_opts, joins, _, _ = self.query.setup_joins([name], opts, root_alias)
948                     model = join_opts.model
949                     alias = joins[-1]
950                     from_parent = issubclass(model, opts.model) and model is not opts.model
951                     klass_info = {
952                         'model': model,
953                         'field': f,
954                         'reverse': True,
955                         'local_setter': local_setter,
956                         'remote_setter': partial(remote_setter, name),
957                         'from_parent': from_parent,
958                     }
959                     related_klass_infos.append(klass_info)
960                     select_fields = []
961                     columns = self.get_default_columns(
962                         start_alias=alias, opts=model._meta,
963                         from_parent=opts.model,
964                     )
965                     for col in columns:
966                         select_fields.append(len(select))
967                         select.append((col, None))
968                     klass_info['select_fields'] = select_fields
969                     next_requested = requested.get(name, {})
970                     next_klass_infos = self.get_related_selections(
971                         select, opts=model._meta, root_alias=alias,
972                         cur_depth=cur_depth + 1, requested=next_requested,
973                         restricted=restricted,
974                     )
975                     get_related_klass_infos(klass_info, next_klass_infos)
976             fields_not_found = set(requested).difference(fields_found)
977             if fields_not_found:
978                 invalid_fields = ("'%s'" % s for s in fields_not_found)
979                 raise FieldError(
980                     'Invalid field name(s) given in select_related: %s. '
981                     'Choices are: %s' % (
982                         ', '.join(invalid_fields),
983                         ', '.join(_get_field_choices()) or '(none)',
984                     )
985                 )
986         return related_klass_infos
987 
988     def get_select_for_update_of_arguments(self):
989         """
990         Return a quoted list of arguments for the SELECT FOR UPDATE OF part of
991         the query.
992         """
993         def _get_parent_klass_info(klass_info):
994             concrete_model = klass_info['model']._meta.concrete_model
995             for parent_model, parent_link in concrete_model._meta.parents.items():
996                 parent_list = parent_model._meta.get_parent_list()
997                 yield {
998                     'model': parent_model,
999                     'field': parent_link,
1000                     'reverse': False,
1001                     'select_fields': [
1002                         select_index
1003                         for select_index in klass_info['select_fields']
1004                         # Selected columns from a model or its parents.
1005                         if (
1006                             self.select[select_index][0].target.model == parent_model or
1007                             self.select[select_index][0].target.model in parent_list
1008                         )
1009                     ],
1010                 }
1011 
1012         def _get_first_selected_col_from_model(klass_info):
1013             """
1014             Find the first selected column from a model. If it doesn't exist,
1015             don't lock a model.
1016 
1017             select_fields is filled recursively, so it also contains fields
1018             from the parent models.
1019             """
1020             concrete_model = klass_info['model']._meta.concrete_model
1021             for select_index in klass_info['select_fields']:
1022                 if self.select[select_index][0].target.model == concrete_model:
1023                     return self.select[select_index][0]
1024 
1025         def _get_field_choices():
1026             """Yield all allowed field paths in breadth-first search order."""
1027             queue = collections.deque([(None, self.klass_info)])
1028             while queue:
1029                 parent_path, klass_info = queue.popleft()
1030                 if parent_path is None:
1031                     path = []
1032                     yield 'self'
1033                 else:
1034                     field = klass_info['field']
1035                     if klass_info['reverse']:
1036                         field = field.remote_field
1037                     path = parent_path + [field.name]
1038                     yield LOOKUP_SEP.join(path)
1039                 queue.extend(
1040                     (path, klass_info)
1041                     for klass_info in _get_parent_klass_info(klass_info)
1042                 )
1043                 queue.extend(
1044                     (path, klass_info)
1045                     for klass_info in klass_info.get('related_klass_infos', [])
1046                 )
1047         result = []
1048         invalid_names = []
1049         for name in self.query.select_for_update_of:
1050             klass_info = self.klass_info
1051             if name == 'self':
1052                 col = _get_first_selected_col_from_model(klass_info)
1053             else:
1054                 for part in name.split(LOOKUP_SEP):
1055                     klass_infos = (
1056                         *klass_info.get('related_klass_infos', []),
1057                         *_get_parent_klass_info(klass_info),
1058                     )
1059                     for related_klass_info in klass_infos:
1060                         field = related_klass_info['field']
1061                         if related_klass_info['reverse']:
1062                             field = field.remote_field
1063                         if field.name == part:
1064                             klass_info = related_klass_info
1065                             break
1066                     else:
1067                         klass_info = None
1068                         break
1069                 if klass_info is None:
1070                     invalid_names.append(name)
1071                     continue
1072                 col = _get_first_selected_col_from_model(klass_info)
1073             if col is not None:
1074                 if self.connection.features.select_for_update_of_column:
1075                     result.append(self.compile(col)[0])
1076                 else:
1077                     result.append(self.quote_name_unless_alias(col.alias))
1078         if invalid_names:
1079             raise FieldError(
1080                 'Invalid field name(s) given in select_for_update(of=(...)): %s. '
1081                 'Only relational fields followed in the query are allowed. '
1082                 'Choices are: %s.' % (
1083                     ', '.join(invalid_names),
1084                     ', '.join(_get_field_choices()),
1085                 )
1086             )
1087         return result
1088 
1089     def deferred_to_columns(self):
1090         """
1091         Convert the self.deferred_loading data structure to mapping of table
1092         names to sets of column names which are to be loaded. Return the
1093         dictionary.
1094         """
1095         columns = {}
1096         self.query.deferred_to_data(columns, self.query.get_loaded_field_names_cb)
1097         return columns
1098 
1099     def get_converters(self, expressions):
1100         converters = {}
1101         for i, expression in enumerate(expressions):
1102             if expression:
1103                 backend_converters = self.connection.ops.get_db_converters(expression)
1104                 field_converters = expression.get_db_converters(self.connection)
1105                 if backend_converters or field_converters:
1106                     converters[i] = (backend_converters + field_converters, expression)
1107         return converters
1108 
1109     def apply_converters(self, rows, converters):
1110         connection = self.connection
1111         converters = list(converters.items())
1112         for row in map(list, rows):
1113             for pos, (convs, expression) in converters:
1114                 value = row[pos]
1115                 for converter in convs:
1116                     value = converter(value, expression, connection)
1117                 row[pos] = value
1118             yield row
1119 
1120     def results_iter(self, results=None, tuple_expected=False, chunked_fetch=False,
1121                      chunk_size=GET_ITERATOR_CHUNK_SIZE):
1122         """Return an iterator over the results from executing this query."""
1123         if results is None:
1124             results = self.execute_sql(MULTI, chunked_fetch=chunked_fetch, chunk_size=chunk_size)
1125         fields = [s[0] for s in self.select[0:self.col_count]]
1126         converters = self.get_converters(fields)
1127         rows = chain.from_iterable(results)
1128         if converters:
1129             rows = self.apply_converters(rows, converters)
1130             if tuple_expected:
1131                 rows = map(tuple, rows)
1132         return rows
1133 
1134     def has_results(self):
1135         """
1136         Backends (e.g. NoSQL) can override this in order to use optimized
1137         versions of "query has any results."
1138         """
1139         return bool(self.execute_sql(SINGLE))
1140 
1141     def execute_sql(self, result_type=MULTI, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE):
1142         """
1143         Run the query against the database and return the result(s). The
1144         return value is a single data item if result_type is SINGLE, or an
1145         iterator over the results if the result_type is MULTI.
1146 
1147         result_type is either MULTI (use fetchmany() to retrieve all rows),
1148         SINGLE (only retrieve a single row), or None. In this last case, the
1149         cursor is returned if any query is executed, since it's used by
1150         subclasses such as InsertQuery). It's possible, however, that no query
1151         is needed, as the filters describe an empty set. In that case, None is
1152         returned, to avoid any unnecessary database interaction.
1153         """
1154         result_type = result_type or NO_RESULTS
1155         try:
1156             sql, params = self.as_sql()
1157             if not sql:
1158                 raise EmptyResultSet
1159         except EmptyResultSet:
1160             if result_type == MULTI:
1161                 return iter([])
1162             else:
1163                 return
1164         if chunked_fetch:
1165             cursor = self.connection.chunked_cursor()
1166         else:
1167             cursor = self.connection.cursor()
1168         try:
1169             cursor.execute(sql, params)
1170         except Exception:
1171             # Might fail for server-side cursors (e.g. connection closed)
1172             cursor.close()
1173             raise
1174 
1175         if result_type == CURSOR:
1176             # Give the caller the cursor to process and close.
1177             return cursor
1178         if result_type == SINGLE:
1179             try:
1180                 val = cursor.fetchone()
1181                 if val:
1182                     return val[0:self.col_count]
1183                 return val
1184             finally:
1185                 # done with the cursor
1186                 cursor.close()
1187         if result_type == NO_RESULTS:
1188             cursor.close()
1189             return
1190 
1191         result = cursor_iter(
1192             cursor, self.connection.features.empty_fetchmany_value,
1193             self.col_count if self.has_extra_select else None,
1194             chunk_size,
1195         )
1196         if not chunked_fetch or not self.connection.features.can_use_chunked_reads:
1197             try:
1198                 # If we are using non-chunked reads, we return the same data
1199                 # structure as normally, but ensure it is all read into memory
1200                 # before going any further. Use chunked_fetch if requested,
1201                 # unless the database doesn't support it.
1202                 return list(result)
1203             finally:
1204                 # done with the cursor
1205                 cursor.close()
1206         return result
1207 
1208     def as_subquery_condition(self, alias, columns, compiler):
1209         qn = compiler.quote_name_unless_alias
1210         qn2 = self.connection.ops.quote_name
1211 
1212         for index, select_col in enumerate(self.query.select):
1213             lhs_sql, lhs_params = self.compile(select_col)
1214             rhs = '%s.%s' % (qn(alias), qn2(columns[index]))
1215             self.query.where.add(
1216                 RawSQL('%s = %s' % (lhs_sql, rhs), lhs_params), 'AND')
1217 
1218         sql, params = self.as_sql()
1219         return 'EXISTS (%s)' % sql, params
1220 
1221     def explain_query(self):
1222         result = list(self.execute_sql())
1223         # Some backends return 1 item tuples with strings, and others return
1224         # tuples with integers and strings. Flatten them out into strings.
1225         for row in result[0]:
1226             if not isinstance(row, str):
1227                 yield ' '.join(str(c) for c in row)
1228             else:
1229                 yield row

</code><intended_behavior>This class provides additional context to the issue.</intended_behavior>, <file>django/db/models/expressions.py</file>
<class>ExpressionWrapper</class>
<method>get_group_by_cols</method>
<code>
917     def get_group_by_cols(self, alias=None):
918         expression = self.expression.copy()
919         expression.output_field = self.output_field
920         return expression.get_group_by_cols(alias=alias)

</code><intended_behavior>The intended behavior for this method is to ensure that ExpressionWrapper correctly informs the SQL compiler about how its contained expressions should influence the GROUP BY clause in SQL queries. Specifically, for boolean expressions or null checks encapsulated by an ExpressionWrapper, the method must ensure that the SQL compiler can translate and include these expressions accurately in the GROUP BY clause. This might involve providing additional metadata or flags from ExpressionWrapper to the compiler or ensuring that ExpressionWrapper's as_sql method or similar methods provide the necessary SQL correctly for grouping purposes.</intended_behavior>, <file>django/db/models/expressions.py</file>
<class>ExpressionWrapper</class>
<method>None</method>
<code>
901 class ExpressionWrapper(Expression):
902     """
903     An expression that can wrap another expression so that it can provide
904     extra context to the inner expression, such as the output_field.
905     """
906 
907     def __init__(self, expression, output_field):
908         super().__init__(output_field=output_field)
909         self.expression = expression
910 
911     def set_source_expressions(self, exprs):
912         self.expression = exprs[0]
913 
914     def get_source_expressions(self):
915         return [self.expression]
916 
917     def get_group_by_cols(self, alias=None):
918         expression = self.expression.copy()
919         expression.output_field = self.output_field
920         return expression.get_group_by_cols(alias=alias)
921 
922     def as_sql(self, compiler, connection):
923         return compiler.compile(self.expression)
924 
925     def __repr__(self):
926         return "{}({})".format(self.__class__.__name__, self.expression)

</code><intended_behavior>This class provides additional context to the issue.</intended_behavior>]
2025-10-17 12:36:28.998 | INFO     | Overall retry 0 succeeded; ending workflow
2025-10-17 12:36:28.999 | INFO     | Search-only: skipping patch selection
2025-10-17 12:36:29.147 | INFO     | Task django__django-13689 completed successfully.
2025-10-17 12:36:29.148 | INFO     | No patch generated. You can try running ACR again.
