[
    {
        "rel_file_path": "sklearn/metrics/cluster/unsupervised.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/scikit-learn__scikit-learn/setup_scikit-learn__scikit-learn__0.21/sklearn/metrics/cluster/unsupervised.py",
        "start": 299,
        "end": 352,
        "class_name": null,
        "method_name": "davies_bouldin_score",
        "code": "299 def davies_bouldin_score(X, labels):\n300     \"\"\"Computes the Davies-Bouldin score.\n301 \n302     The score is defined as the ratio of within-cluster distances to\n303     between-cluster distances.\n304 \n305     Read more in the :ref:`User Guide <davies-bouldin_index>`.\n306 \n307     Parameters\n308     ----------\n309     X : array-like, shape (``n_samples``, ``n_features``)\n310         List of ``n_features``-dimensional data points. Each row corresponds\n311         to a single data point.\n312 \n313     labels : array-like, shape (``n_samples``,)\n314         Predicted labels for each sample.\n315 \n316     Returns\n317     -------\n318     score: float\n319         The resulting Davies-Bouldin score.\n320 \n321     References\n322     ----------\n323     .. [1] Davies, David L.; Bouldin, Donald W. (1979).\n324        `\"A Cluster Separation Measure\"\n325        <https://ieeexplore.ieee.org/document/4766909>`__.\n326        IEEE Transactions on Pattern Analysis and Machine Intelligence.\n327        PAMI-1 (2): 224-227\n328     \"\"\"\n329     X, labels = check_X_y(X, labels)\n330     le = LabelEncoder()\n331     labels = le.fit_transform(labels)\n332     n_samples, _ = X.shape\n333     n_labels = len(le.classes_)\n334     check_number_of_labels(n_labels, n_samples)\n335 \n336     intra_dists = np.zeros(n_labels)\n337     centroids = np.zeros((n_labels, len(X[0])), dtype=np.float)\n338     for k in range(n_labels):\n339         cluster_k = safe_indexing(X, labels == k)\n340         centroid = cluster_k.mean(axis=0)\n341         centroids[k] = centroid\n342         intra_dists[k] = np.average(pairwise_distances(\n343             cluster_k, [centroid]))\n344 \n345     centroid_distances = pairwise_distances(centroids)\n346 \n347     if np.allclose(intra_dists, 0) or np.allclose(centroid_distances, 0):\n348         return 0.0\n349 \n350     score = (intra_dists[:, None] + intra_dists) / centroid_distances\n351     score[score == np.inf] = np.nan\n352     return np.mean(np.nanmax(score, axis=1))\n",
        "intended_behavior": "The `score` computation within this method needs to be adjusted to handle cases where `centroid_distances` contain zeros, in order to avoid division by zero errors. A possible approach is to add a small epsilon value to the denominator to ensure it's never zero, or use `numpy.divide` with `where` parameter to selectively perform division only where `centroid_distances` is non-zero. This change should maintain the functionality of calculating the Davies-Bouldin score accurately while preventing runtime warnings or errors when encountering clusters located very close to each other (or at exactly the same location due to numerical rounding or clustering anomalies). Additionally, ensuring that `score[score == np.inf] = np.nan` effectively handles any infinite values resulting from the division could be a part of validating the score matrix before computing its mean."
    }
]