2025-10-17 13:12:35.799 | INFO     | Starting overall retry 0 with model gpt-4-0125-preview
2025-10-17 13:12:38.941 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=120, output_tokens=12, cost=0.001560
2025-10-17 13:12:38.942 | INFO     | Test agent decides that the issue statement does not contain reproduction steps; skipping reproducer tracing
2025-10-17 13:12:38.946 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-17 13:12:47.629 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=429, output_tokens=358, cost=0.015030
2025-10-17 13:12:47.654 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-17 13:12:50.255 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=712, output_tokens=53, cost=0.008710
2025-10-17 13:12:50.256 | DEBUG    | Extracted a valid json.
2025-10-17 13:12:50.256 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_code(\"index_together\")",
        "search_code(\"Meta: indexes\")",
        "search_class(\"Index\")",
        "search_code(\"models.Index\")"
    ],
    "bug_locations": []
}
2025-10-17 13:12:50.379 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-17 13:12:50.380 | DEBUG    | <Agent search> Analyzing search results.
2025-10-17 13:13:07.800 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=1486, output_tokens=695, cost=0.035710
2025-10-17 13:13:07.808 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-17 13:13:23.821 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=2397, output_tokens=548, cost=0.040410
2025-10-17 13:13:23.830 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-17 13:13:32.189 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=902, output_tokens=271, cost=0.017150
2025-10-17 13:13:32.190 | DEBUG    | Extracted a valid json.
2025-10-17 13:13:32.190 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [],
    "bug_locations": [
        {
            "file": "django/db/models/options.py",
            "class": "",
            "method": "",
            "intended_behavior": "Ensure functionality parsing or utilizing `index_together` supports or migrates to `Model.Meta.indexes` with `Index` class, possibly showing deprecation warnings for `index_together`."
        },
        {
            "file": "django/db/migrations/autodetector.py",
            "class": "",
            "method": "",
            "intended_behavior": "Correctly identify changes from `index_together` to `Model.Meta.indexes` for migration generation, ensuring error-free recognition and operation reflection."
        },
        {
            "file": "django/db/backends/base/schema.py",
            "class": "",
            "method": "",
            "intended_behavior": "Ensure schema generation logic translates `indexes` attributes into correct SQL statements, maintaining functionality equivalence with `index_together`."
        },
        {
            "file": "django/db/backends/sqlite3/schema.py",
            "class": "",
            "method": "",
            "intended_behavior": "Ensure compatibility or appropriate translation to use of `indexes`, ensuring backend-specific handling of `index_together` is updated."
        }
    ]
}
2025-10-17 13:13:32.210 | DEBUG    | Bug location extracted successfully: [<file>django/db/models/options.py</file>
<class>None</class>
<method>None</method>
<code>
1 import bisect
2 import copy
3 import inspect
4 from collections import defaultdict
5 
6 from django.apps import apps
7 from django.conf import settings
8 from django.core.exceptions import FieldDoesNotExist, ImproperlyConfigured
9 from django.db import connections
10 from django.db.models import AutoField, Manager, OrderWrt, UniqueConstraint
11 from django.db.models.query_utils import PathInfo
12 from django.utils.datastructures import ImmutableList, OrderedSet
13 from django.utils.functional import cached_property
14 from django.utils.module_loading import import_string
15 from django.utils.text import camel_case_to_spaces, format_lazy
16 from django.utils.translation import override
17 
18 PROXY_PARENTS = object()
19 
20 EMPTY_RELATION_TREE = ()
21 
22 IMMUTABLE_WARNING = (
23     "The return type of '%s' should never be mutated. If you want to manipulate this "
24     "list for your own use, make a copy first."
25 )
26 
27 DEFAULT_NAMES = (
28     "verbose_name",
29     "verbose_name_plural",
30     "db_table",
31     "ordering",
32     "unique_together",
33     "permissions",
34     "get_latest_by",
35     "order_with_respect_to",
36     "app_label",
37     "db_tablespace",
38     "abstract",
39     "managed",
40     "proxy",
41     "swappable",
42     "auto_created",
43     "index_together",
44     "apps",
45     "default_permissions",
46     "select_on_save",
47     "default_related_name",
48     "required_db_features",
49     "required_db_vendor",
50     "base_manager_name",
51     "default_manager_name",
52     "indexes",
53     "constraints",
54 )
55 
56 
57 def normalize_together(option_together):
58     """
59     option_together can be either a tuple of tuples, or a single
60     tuple of two strings. Normalize it to a tuple of tuples, so that
61     calling code can uniformly expect that.
62     """
63     try:
64         if not option_together:
65             return ()
66         if not isinstance(option_together, (tuple, list)):
67             raise TypeError
68         first_element = option_together[0]
69         if not isinstance(first_element, (tuple, list)):
70             option_together = (option_together,)
71         # Normalize everything to tuples
72         return tuple(tuple(ot) for ot in option_together)
73     except TypeError:
74         # If the value of option_together isn't valid, return it
75         # verbatim; this will be picked up by the check framework later.
76         return option_together
77 
78 
79 def make_immutable_fields_list(name, data):
80     return ImmutableList(data, warning=IMMUTABLE_WARNING % name)
81 
82 
83 class Options:
84     FORWARD_PROPERTIES = {
85         "fields",
86         "many_to_many",
87         "concrete_fields",
88         "local_concrete_fields",
89         "_forward_fields_map",
90         "managers",
91         "managers_map",
92         "base_manager",
93         "default_manager",
94     }
95     REVERSE_PROPERTIES = {"related_objects", "fields_map", "_relation_tree"}
96 
97     default_apps = apps
98 
99     def __init__(self, meta, app_label=None):
100         self._get_fields_cache = {}
101         self.local_fields = []
102         self.local_many_to_many = []
103         self.private_fields = []
104         self.local_managers = []
105         self.base_manager_name = None
106         self.default_manager_name = None
107         self.model_name = None
108         self.verbose_name = None
109         self.verbose_name_plural = None
110         self.db_table = ""
111         self.ordering = []
112         self._ordering_clash = False
113         self.indexes = []
114         self.constraints = []
115         self.unique_together = []
116         self.index_together = []
117         self.select_on_save = False
118         self.default_permissions = ("add", "change", "delete", "view")
119         self.permissions = []
120         self.object_name = None
121         self.app_label = app_label
122         self.get_latest_by = None
123         self.order_with_respect_to = None
124         self.db_tablespace = settings.DEFAULT_TABLESPACE
125         self.required_db_features = []
126         self.required_db_vendor = None
127         self.meta = meta
128         self.pk = None
129         self.auto_field = None
130         self.abstract = False
131         self.managed = True
132         self.proxy = False
133         # For any class that is a proxy (including automatically created
134         # classes for deferred object loading), proxy_for_model tells us
135         # which class this model is proxying. Note that proxy_for_model
136         # can create a chain of proxy models. For non-proxy models, the
137         # variable is always None.
138         self.proxy_for_model = None
139         # For any non-abstract class, the concrete class is the model
140         # in the end of the proxy_for_model chain. In particular, for
141         # concrete models, the concrete_model is always the class itself.
142         self.concrete_model = None
143         self.swappable = None
144         self.parents = {}
145         self.auto_created = False
146 
147         # List of all lookups defined in ForeignKey 'limit_choices_to' options
148         # from *other* models. Needed for some admin checks. Internal use only.
149         self.related_fkey_lookups = []
150 
151         # A custom app registry to use, if you're making a separate model set.
152         self.apps = self.default_apps
153 
154         self.default_related_name = None
155 
156     @property
157     def label(self):
158         return "%s.%s" % (self.app_label, self.object_name)
159 
160     @property
161     def label_lower(self):
162         return "%s.%s" % (self.app_label, self.model_name)
163 
164     @property
165     def app_config(self):
166         # Don't go through get_app_config to avoid triggering imports.
167         return self.apps.app_configs.get(self.app_label)
168 
169     def contribute_to_class(self, cls, name):
170         from django.db import connection
171         from django.db.backends.utils import truncate_name
172 
173         cls._meta = self
174         self.model = cls
175         # First, construct the default values for these options.
176         self.object_name = cls.__name__
177         self.model_name = self.object_name.lower()
178         self.verbose_name = camel_case_to_spaces(self.object_name)
179 
180         # Store the original user-defined values for each option,
181         # for use when serializing the model definition
182         self.original_attrs = {}
183 
184         # Next, apply any overridden values from 'class Meta'.
185         if self.meta:
186             meta_attrs = self.meta.__dict__.copy()
187             for name in self.meta.__dict__:
188                 # Ignore any private attributes that Django doesn't care about.
189                 # NOTE: We can't modify a dictionary's contents while looping
190                 # over it, so we loop over the *original* dictionary instead.
191                 if name.startswith("_"):
192                     del meta_attrs[name]
193             for attr_name in DEFAULT_NAMES:
194                 if attr_name in meta_attrs:
195                     setattr(self, attr_name, meta_attrs.pop(attr_name))
196                     self.original_attrs[attr_name] = getattr(self, attr_name)
197                 elif hasattr(self.meta, attr_name):
198                     setattr(self, attr_name, getattr(self.meta, attr_name))
199                     self.original_attrs[attr_name] = getattr(self, attr_name)
200 
201             self.unique_together = normalize_together(self.unique_together)
202             self.index_together = normalize_together(self.index_together)
203             # App label/class name interpolation for names of constraints and
204             # indexes.
205             if not getattr(cls._meta, "abstract", False):
206                 for attr_name in {"constraints", "indexes"}:
207                     objs = getattr(self, attr_name, [])
208                     setattr(self, attr_name, self._format_names_with_class(cls, objs))
209 
210             # verbose_name_plural is a special case because it uses a 's'
211             # by default.
212             if self.verbose_name_plural is None:
213                 self.verbose_name_plural = format_lazy("{}s", self.verbose_name)
214 
215             # order_with_respect_and ordering are mutually exclusive.
216             self._ordering_clash = bool(self.ordering and self.order_with_respect_to)
217 
218             # Any leftover attributes must be invalid.
219             if meta_attrs != {}:
220                 raise TypeError(
221                     "'class Meta' got invalid attribute(s): %s" % ",".join(meta_attrs)
222                 )
223         else:
224             self.verbose_name_plural = format_lazy("{}s", self.verbose_name)
225         del self.meta
226 
227         # If the db_table wasn't provided, use the app_label + model_name.
228         if not self.db_table:
229             self.db_table = "%s_%s" % (self.app_label, self.model_name)
230             self.db_table = truncate_name(
231                 self.db_table, connection.ops.max_name_length()
232             )
233 
234     def _format_names_with_class(self, cls, objs):
235         """App label/class name interpolation for object names."""
236         new_objs = []
237         for obj in objs:
238             obj = obj.clone()
239             obj.name = obj.name % {
240                 "app_label": cls._meta.app_label.lower(),
241                 "class": cls.__name__.lower(),
242             }
243             new_objs.append(obj)
244         return new_objs
245 
246     def _get_default_pk_class(self):
247         pk_class_path = getattr(
248             self.app_config,
249             "default_auto_field",
250             settings.DEFAULT_AUTO_FIELD,
251         )
252         if self.app_config and self.app_config._is_default_auto_field_overridden:
253             app_config_class = type(self.app_config)
254             source = (
255                 f"{app_config_class.__module__}."
256                 f"{app_config_class.__qualname__}.default_auto_field"
257             )
258         else:
259             source = "DEFAULT_AUTO_FIELD"
260         if not pk_class_path:
261             raise ImproperlyConfigured(f"{source} must not be empty.")
262         try:
263             pk_class = import_string(pk_class_path)
264         except ImportError as e:
265             msg = (
266                 f"{source} refers to the module '{pk_class_path}' that could "
267                 f"not be imported."
268             )
269             raise ImproperlyConfigured(msg) from e
270         if not issubclass(pk_class, AutoField):
271             raise ValueError(
272                 f"Primary key '{pk_class_path}' referred by {source} must "
273                 f"subclass AutoField."
274             )
275         return pk_class
276 
277     def _prepare(self, model):
278         if self.order_with_respect_to:
279             # The app registry will not be ready at this point, so we cannot
280             # use get_field().
281             query = self.order_with_respect_to
282             try:
283                 self.order_with_respect_to = next(
284                     f
285                     for f in self._get_fields(reverse=False)
286                     if f.name == query or f.attname == query
287                 )
288             except StopIteration:
289                 raise FieldDoesNotExist(
290                     "%s has no field named '%s'" % (self.object_name, query)
291                 )
292 
293             self.ordering = ("_order",)
294             if not any(
295                 isinstance(field, OrderWrt) for field in model._meta.local_fields
296             ):
297                 model.add_to_class("_order", OrderWrt())
298         else:
299             self.order_with_respect_to = None
300 
301         if self.pk is None:
302             if self.parents:
303                 # Promote the first parent link in lieu of adding yet another
304                 # field.
305                 field = next(iter(self.parents.values()))
306                 # Look for a local field with the same name as the
307                 # first parent link. If a local field has already been
308                 # created, use it instead of promoting the parent
309                 already_created = [
310                     fld for fld in self.local_fields if fld.name == field.name
311                 ]
312                 if already_created:
313                     field = already_created[0]
314                 field.primary_key = True
315                 self.setup_pk(field)
316             else:
317                 pk_class = self._get_default_pk_class()
318                 auto = pk_class(verbose_name="ID", primary_key=True, auto_created=True)
319                 model.add_to_class("id", auto)
320 
321     def add_manager(self, manager):
322         self.local_managers.append(manager)
323         self._expire_cache()
324 
325     def add_field(self, field, private=False):
326         # Insert the given field in the order in which it was created, using
327         # the "creation_counter" attribute of the field.
328         # Move many-to-many related fields from self.fields into
329         # self.many_to_many.
330         if private:
331             self.private_fields.append(field)
332         elif field.is_relation and field.many_to_many:
333             bisect.insort(self.local_many_to_many, field)
334         else:
335             bisect.insort(self.local_fields, field)
336             self.setup_pk(field)
337 
338         # If the field being added is a relation to another known field,
339         # expire the cache on this field and the forward cache on the field
340         # being referenced, because there will be new relationships in the
341         # cache. Otherwise, expire the cache of references *to* this field.
342         # The mechanism for getting at the related model is slightly odd -
343         # ideally, we'd just ask for field.related_model. However, related_model
344         # is a cached property, and all the models haven't been loaded yet, so
345         # we need to make sure we don't cache a string reference.
346         if (
347             field.is_relation
348             and hasattr(field.remote_field, "model")
349             and field.remote_field.model
350         ):
351             try:
352                 field.remote_field.model._meta._expire_cache(forward=False)
353             except AttributeError:
354                 pass
355             self._expire_cache()
356         else:
357             self._expire_cache(reverse=False)
358 
359     def setup_pk(self, field):
360         if not self.pk and field.primary_key:
361             self.pk = field
362             field.serialize = False
363 
364     def setup_proxy(self, target):
365         """
366         Do the internal setup so that the current model is a proxy for
367         "target".
368         """
369         self.pk = target._meta.pk
370         self.proxy_for_model = target
371         self.db_table = target._meta.db_table
372 
373     def __repr__(self):
374         return "<Options for %s>" % self.object_name
375 
376     def __str__(self):
377         return self.label_lower
378 
379     def can_migrate(self, connection):
380         """
381         Return True if the model can/should be migrated on the `connection`.
382         `connection` can be either a real connection or a connection alias.
383         """
384         if self.proxy or self.swapped or not self.managed:
385             return False
386         if isinstance(connection, str):
387             connection = connections[connection]
388         if self.required_db_vendor:
389             return self.required_db_vendor == connection.vendor
390         if self.required_db_features:
391             return all(
392                 getattr(connection.features, feat, False)
393                 for feat in self.required_db_features
394             )
395         return True
396 
397     @property
398     def verbose_name_raw(self):
399         """Return the untranslated verbose name."""
400         with override(None):
401             return str(self.verbose_name)
402 
403     @property
404     def swapped(self):
405         """
406         Has this model been swapped out for another? If so, return the model
407         name of the replacement; otherwise, return None.
408 
409         For historical reasons, model name lookups using get_model() are
410         case insensitive, so we make sure we are case insensitive here.
411         """
412         if self.swappable:
413             swapped_for = getattr(settings, self.swappable, None)
414             if swapped_for:
415                 try:
416                     swapped_label, swapped_object = swapped_for.split(".")
417                 except ValueError:
418                     # setting not in the format app_label.model_name
419                     # raising ImproperlyConfigured here causes problems with
420                     # test cleanup code - instead it is raised in get_user_model
421                     # or as part of validation.
422                     return swapped_for
423 
424                 if (
425                     "%s.%s" % (swapped_label, swapped_object.lower())
426                     != self.label_lower
427                 ):
428                     return swapped_for
429         return None
430 
431     @cached_property
432     def managers(self):
433         managers = []
434         seen_managers = set()
435         bases = (b for b in self.model.mro() if hasattr(b, "_meta"))
436         for depth, base in enumerate(bases):
437             for manager in base._meta.local_managers:
438                 if manager.name in seen_managers:
439                     continue
440 
441                 manager = copy.copy(manager)
442                 manager.model = self.model
443                 seen_managers.add(manager.name)
444                 managers.append((depth, manager.creation_counter, manager))
445 
446         return make_immutable_fields_list(
447             "managers",
448             (m[2] for m in sorted(managers)),
449         )
450 
451     @cached_property
452     def managers_map(self):
453         return {manager.name: manager for manager in self.managers}
454 
455     @cached_property
456     def base_manager(self):
457         base_manager_name = self.base_manager_name
458         if not base_manager_name:
459             # Get the first parent's base_manager_name if there's one.
460             for parent in self.model.mro()[1:]:
461                 if hasattr(parent, "_meta"):
462                     if parent._base_manager.name != "_base_manager":
463                         base_manager_name = parent._base_manager.name
464                     break
465 
466         if base_manager_name:
467             try:
468                 return self.managers_map[base_manager_name]
469             except KeyError:
470                 raise ValueError(
471                     "%s has no manager named %r"
472                     % (
473                         self.object_name,
474                         base_manager_name,
475                     )
476                 )
477 
478         manager = Manager()
479         manager.name = "_base_manager"
480         manager.model = self.model
481         manager.auto_created = True
482         return manager
483 
484     @cached_property
485     def default_manager(self):
486         default_manager_name = self.default_manager_name
487         if not default_manager_name and not self.local_managers:
488             # Get the first parent's default_manager_name if there's one.
489             for parent in self.model.mro()[1:]:
490                 if hasattr(parent, "_meta"):
491                     default_manager_name = parent._meta.default_manager_name
492                     break
493 
494         if default_manager_name:
495             try:
496                 return self.managers_map[default_manager_name]
497             except KeyError:
498                 raise ValueError(
499                     "%s has no manager named %r"
500                     % (
501                         self.object_name,
502                         default_manager_name,
503                     )
504                 )
505 
506         if self.managers:
507             return self.managers[0]
508 
509     @cached_property
510     def fields(self):
511         """
512         Return a list of all forward fields on the model and its parents,
513         excluding ManyToManyFields.
514 
515         Private API intended only to be used by Django itself; get_fields()
516         combined with filtering of field properties is the public API for
517         obtaining this field list.
518         """
519         # For legacy reasons, the fields property should only contain forward
520         # fields that are not private or with a m2m cardinality. Therefore we
521         # pass these three filters as filters to the generator.
522         # The third lambda is a longwinded way of checking f.related_model - we don't
523         # use that property directly because related_model is a cached property,
524         # and all the models may not have been loaded yet; we don't want to cache
525         # the string reference to the related_model.
526         def is_not_an_m2m_field(f):
527             return not (f.is_relation and f.many_to_many)
528 
529         def is_not_a_generic_relation(f):
530             return not (f.is_relation and f.one_to_many)
531 
532         def is_not_a_generic_foreign_key(f):
533             return not (
534                 f.is_relation
535                 and f.many_to_one
536                 and not (hasattr(f.remote_field, "model") and f.remote_field.model)
537             )
538 
539         return make_immutable_fields_list(
540             "fields",
541             (
542                 f
543                 for f in self._get_fields(reverse=False)
544                 if is_not_an_m2m_field(f)
545                 and is_not_a_generic_relation(f)
546                 and is_not_a_generic_foreign_key(f)
547             ),
548         )
549 
550     @cached_property
551     def concrete_fields(self):
552         """
553         Return a list of all concrete fields on the model and its parents.
554 
555         Private API intended only to be used by Django itself; get_fields()
556         combined with filtering of field properties is the public API for
557         obtaining this field list.
558         """
559         return make_immutable_fields_list(
560             "concrete_fields", (f for f in self.fields if f.concrete)
561         )
562 
563     @cached_property
564     def local_concrete_fields(self):
565         """
566         Return a list of all concrete fields on the model.
567 
568         Private API intended only to be used by Django itself; get_fields()
569         combined with filtering of field properties is the public API for
570         obtaining this field list.
571         """
572         return make_immutable_fields_list(
573             "local_concrete_fields", (f for f in self.local_fields if f.concrete)
574         )
575 
576     @cached_property
577     def many_to_many(self):
578         """
579         Return a list of all many to many fields on the model and its parents.
580 
581         Private API intended only to be used by Django itself; get_fields()
582         combined with filtering of field properties is the public API for
583         obtaining this list.
584         """
585         return make_immutable_fields_list(
586             "many_to_many",
587             (
588                 f
589                 for f in self._get_fields(reverse=False)
590                 if f.is_relation and f.many_to_many
591             ),
592         )
593 
594     @cached_property
595     def related_objects(self):
596         """
597         Return all related objects pointing to the current model. The related
598         objects can come from a one-to-one, one-to-many, or many-to-many field
599         relation type.
600 
601         Private API intended only to be used by Django itself; get_fields()
602         combined with filtering of field properties is the public API for
603         obtaining this field list.
604         """
605         all_related_fields = self._get_fields(
606             forward=False, reverse=True, include_hidden=True
607         )
608         return make_immutable_fields_list(
609             "related_objects",
610             (
611                 obj
612                 for obj in all_related_fields
613                 if not obj.hidden or obj.field.many_to_many
614             ),
615         )
616 
617     @cached_property
618     def _forward_fields_map(self):
619         res = {}
620         fields = self._get_fields(reverse=False)
621         for field in fields:
622             res[field.name] = field
623             # Due to the way Django's internals work, get_field() should also
624             # be able to fetch a field by attname. In the case of a concrete
625             # field with relation, includes the *_id name too
626             try:
627                 res[field.attname] = field
628             except AttributeError:
629                 pass
630         return res
631 
632     @cached_property
633     def fields_map(self):
634         res = {}
635         fields = self._get_fields(forward=False, include_hidden=True)
636         for field in fields:
637             res[field.name] = field
638             # Due to the way Django's internals work, get_field() should also
639             # be able to fetch a field by attname. In the case of a concrete
640             # field with relation, includes the *_id name too
641             try:
642                 res[field.attname] = field
643             except AttributeError:
644                 pass
645         return res
646 
647     def get_field(self, field_name):
648         """
649         Return a field instance given the name of a forward or reverse field.
650         """
651         try:
652             # In order to avoid premature loading of the relation tree
653             # (expensive) we prefer checking if the field is a forward field.
654             return self._forward_fields_map[field_name]
655         except KeyError:
656             # If the app registry is not ready, reverse fields are
657             # unavailable, therefore we throw a FieldDoesNotExist exception.
658             if not self.apps.models_ready:
659                 raise FieldDoesNotExist(
660                     "%s has no field named '%s'. The app cache isn't ready yet, "
661                     "so if this is an auto-created related field, it won't "
662                     "be available yet." % (self.object_name, field_name)
663                 )
664 
665         try:
666             # Retrieve field instance by name from cached or just-computed
667             # field map.
668             return self.fields_map[field_name]
669         except KeyError:
670             raise FieldDoesNotExist(
671                 "%s has no field named '%s'" % (self.object_name, field_name)
672             )
673 
674     def get_base_chain(self, model):
675         """
676         Return a list of parent classes leading to `model` (ordered from
677         closest to most distant ancestor). This has to handle the case where
678         `model` is a grandparent or even more distant relation.
679         """
680         if not self.parents:
681             return []
682         if model in self.parents:
683             return [model]
684         for parent in self.parents:
685             res = parent._meta.get_base_chain(model)
686             if res:
687                 res.insert(0, parent)
688                 return res
689         return []
690 
691     def get_parent_list(self):
692         """
693         Return all the ancestors of this model as a list ordered by MRO.
694         Useful for determining if something is an ancestor, regardless of lineage.
695         """
696         result = OrderedSet(self.parents)
697         for parent in self.parents:
698             for ancestor in parent._meta.get_parent_list():
699                 result.add(ancestor)
700         return list(result)
701 
702     def get_ancestor_link(self, ancestor):
703         """
704         Return the field on the current model which points to the given
705         "ancestor". This is possible an indirect link (a pointer to a parent
706         model, which points, eventually, to the ancestor). Used when
707         constructing table joins for model inheritance.
708 
709         Return None if the model isn't an ancestor of this one.
710         """
711         if ancestor in self.parents:
712             return self.parents[ancestor]
713         for parent in self.parents:
714             # Tries to get a link field from the immediate parent
715             parent_link = parent._meta.get_ancestor_link(ancestor)
716             if parent_link:
717                 # In case of a proxied model, the first link
718                 # of the chain to the ancestor is that parent
719                 # links
720                 return self.parents[parent] or parent_link
721 
722     def get_path_to_parent(self, parent):
723         """
724         Return a list of PathInfos containing the path from the current
725         model to the parent model, or an empty list if parent is not a
726         parent of the current model.
727         """
728         if self.model is parent:
729             return []
730         # Skip the chain of proxy to the concrete proxied model.
731         proxied_model = self.concrete_model
732         path = []
733         opts = self
734         for int_model in self.get_base_chain(parent):
735             if int_model is proxied_model:
736                 opts = int_model._meta
737             else:
738                 final_field = opts.parents[int_model]
739                 targets = (final_field.remote_field.get_related_field(),)
740                 opts = int_model._meta
741                 path.append(
742                     PathInfo(
743                         from_opts=final_field.model._meta,
744                         to_opts=opts,
745                         target_fields=targets,
746                         join_field=final_field,
747                         m2m=False,
748                         direct=True,
749                         filtered_relation=None,
750                     )
751                 )
752         return path
753 
754     def get_path_from_parent(self, parent):
755         """
756         Return a list of PathInfos containing the path from the parent
757         model to the current model, or an empty list if parent is not a
758         parent of the current model.
759         """
760         if self.model is parent:
761             return []
762         model = self.concrete_model
763         # Get a reversed base chain including both the current and parent
764         # models.
765         chain = model._meta.get_base_chain(parent)
766         chain.reverse()
767         chain.append(model)
768         # Construct a list of the PathInfos between models in chain.
769         path = []
770         for i, ancestor in enumerate(chain[:-1]):
771             child = chain[i + 1]
772             link = child._meta.get_ancestor_link(ancestor)
773             path.extend(link.reverse_path_infos)
774         return path
775 
776     def _populate_directed_relation_graph(self):
777         """
778         This method is used by each model to find its reverse objects. As this
779         method is very expensive and is accessed frequently (it looks up every
780         field in a model, in every app), it is computed on first access and then
781         is set as a property on every model.
782         """
783         related_objects_graph = defaultdict(list)
784 
785         all_models = self.apps.get_models(include_auto_created=True)
786         for model in all_models:
787             opts = model._meta
788             # Abstract model's fields are copied to child models, hence we will
789             # see the fields from the child models.
790             if opts.abstract:
791                 continue
792             fields_with_relations = (
793                 f
794                 for f in opts._get_fields(reverse=False, include_parents=False)
795                 if f.is_relation and f.related_model is not None
796             )
797             for f in fields_with_relations:
798                 if not isinstance(f.remote_field.model, str):
799                     remote_label = f.remote_field.model._meta.concrete_model._meta.label
800                     related_objects_graph[remote_label].append(f)
801 
802         for model in all_models:
803             # Set the relation_tree using the internal __dict__. In this way
804             # we avoid calling the cached property. In attribute lookup,
805             # __dict__ takes precedence over a data descriptor (such as
806             # @cached_property). This means that the _meta._relation_tree is
807             # only called if related_objects is not in __dict__.
808             related_objects = related_objects_graph[
809                 model._meta.concrete_model._meta.label
810             ]
811             model._meta.__dict__["_relation_tree"] = related_objects
812         # It seems it is possible that self is not in all_models, so guard
813         # against that with default for get().
814         return self.__dict__.get("_relation_tree", EMPTY_RELATION_TREE)
815 
816     @cached_property
817     def _relation_tree(self):
818         return self._populate_directed_relation_graph()
819 
820     def _expire_cache(self, forward=True, reverse=True):
821         # This method is usually called by apps.cache_clear(), when the
822         # registry is finalized, or when a new field is added.
823         if forward:
824             for cache_key in self.FORWARD_PROPERTIES:
825                 if cache_key in self.__dict__:
826                     delattr(self, cache_key)
827         if reverse and not self.abstract:
828             for cache_key in self.REVERSE_PROPERTIES:
829                 if cache_key in self.__dict__:
830                     delattr(self, cache_key)
831         self._get_fields_cache = {}
832 
833     def get_fields(self, include_parents=True, include_hidden=False):
834         """
835         Return a list of fields associated to the model. By default, include
836         forward and reverse fields, fields derived from inheritance, but not
837         hidden fields. The returned fields can be changed using the parameters:
838 
839         - include_parents: include fields derived from inheritance
840         - include_hidden:  include fields that have a related_name that
841                            starts with a "+"
842         """
843         if include_parents is False:
844             include_parents = PROXY_PARENTS
845         return self._get_fields(
846             include_parents=include_parents, include_hidden=include_hidden
847         )
848 
849     def _get_fields(
850         self,
851         forward=True,
852         reverse=True,
853         include_parents=True,
854         include_hidden=False,
855         seen_models=None,
856     ):
857         """
858         Internal helper function to return fields of the model.
859         * If forward=True, then fields defined on this model are returned.
860         * If reverse=True, then relations pointing to this model are returned.
861         * If include_hidden=True, then fields with is_hidden=True are returned.
862         * The include_parents argument toggles if fields from parent models
863           should be included. It has three values: True, False, and
864           PROXY_PARENTS. When set to PROXY_PARENTS, the call will return all
865           fields defined for the current model or any of its parents in the
866           parent chain to the model's concrete model.
867         """
868         if include_parents not in (True, False, PROXY_PARENTS):
869             raise TypeError(
870                 "Invalid argument for include_parents: %s" % (include_parents,)
871             )
872         # This helper function is used to allow recursion in ``get_fields()``
873         # implementation and to provide a fast way for Django's internals to
874         # access specific subsets of fields.
875 
876         # We must keep track of which models we have already seen. Otherwise we
877         # could include the same field multiple times from different models.
878         topmost_call = seen_models is None
879         if topmost_call:
880             seen_models = set()
881         seen_models.add(self.model)
882 
883         # Creates a cache key composed of all arguments
884         cache_key = (forward, reverse, include_parents, include_hidden, topmost_call)
885 
886         try:
887             # In order to avoid list manipulation. Always return a shallow copy
888             # of the results.
889             return self._get_fields_cache[cache_key]
890         except KeyError:
891             pass
892 
893         fields = []
894         # Recursively call _get_fields() on each parent, with the same
895         # options provided in this call.
896         if include_parents is not False:
897             for parent in self.parents:
898                 # In diamond inheritance it is possible that we see the same
899                 # model from two different routes. In that case, avoid adding
900                 # fields from the same parent again.
901                 if parent in seen_models:
902                     continue
903                 if (
904                     parent._meta.concrete_model != self.concrete_model
905                     and include_parents == PROXY_PARENTS
906                 ):
907                     continue
908                 for obj in parent._meta._get_fields(
909                     forward=forward,
910                     reverse=reverse,
911                     include_parents=include_parents,
912                     include_hidden=include_hidden,
913                     seen_models=seen_models,
914                 ):
915                     if (
916                         not getattr(obj, "parent_link", False)
917                         or obj.model == self.concrete_model
918                     ):
919                         fields.append(obj)
920         if reverse and not self.proxy:
921             # Tree is computed once and cached until the app cache is expired.
922             # It is composed of a list of fields pointing to the current model
923             # from other models.
924             all_fields = self._relation_tree
925             for field in all_fields:
926                 # If hidden fields should be included or the relation is not
927                 # intentionally hidden, add to the fields dict.
928                 if include_hidden or not field.remote_field.hidden:
929                     fields.append(field.remote_field)
930 
931         if forward:
932             fields += self.local_fields
933             fields += self.local_many_to_many
934             # Private fields are recopied to each child model, and they get a
935             # different model as field.model in each child. Hence we have to
936             # add the private fields separately from the topmost call. If we
937             # did this recursively similar to local_fields, we would get field
938             # instances with field.model != self.model.
939             if topmost_call:
940                 fields += self.private_fields
941 
942         # In order to avoid list manipulation. Always
943         # return a shallow copy of the results
944         fields = make_immutable_fields_list("get_fields()", fields)
945 
946         # Store result into cache for later access
947         self._get_fields_cache[cache_key] = fields
948         return fields
949 
950     @cached_property
951     def total_unique_constraints(self):
952         """
953         Return a list of total unique constraints. Useful for determining set
954         of fields guaranteed to be unique for all rows.
955         """
956         return [
957             constraint
958             for constraint in self.constraints
959             if (
960                 isinstance(constraint, UniqueConstraint)
961                 and constraint.condition is None
962                 and not constraint.contains_expressions
963             )
964         ]
965 
966     @cached_property
967     def _property_names(self):
968         """Return a set of the names of the properties defined on the model."""
969         names = []
970         for name in dir(self.model):
971             attr = inspect.getattr_static(self.model, name)
972             if isinstance(attr, property):
973                 names.append(name)
974         return frozenset(names)
975 
976     @cached_property
977     def db_returning_fields(self):
978         """
979         Private API intended only to be used by Django itself.
980         Fields to be returned after a database insert.
981         """
982         return [
983             field
984             for field in self._get_fields(
985                 forward=True, reverse=False, include_parents=PROXY_PARENTS
986             )
987             if getattr(field, "db_returning", False)
988         ]

</code><intended_behavior>Ensure functionality parsing or utilizing `index_together` supports or migrates to `Model.Meta.indexes` with `Index` class, possibly showing deprecation warnings for `index_together`.</intended_behavior>, <file>django/db/migrations/autodetector.py</file>
<class>None</class>
<method>None</method>
<code>
1 import functools
2 import re
3 from collections import defaultdict
4 from itertools import chain
5 
6 from django.conf import settings
7 from django.db import models
8 from django.db.migrations import operations
9 from django.db.migrations.migration import Migration
10 from django.db.migrations.operations.models import AlterModelOptions
11 from django.db.migrations.optimizer import MigrationOptimizer
12 from django.db.migrations.questioner import MigrationQuestioner
13 from django.db.migrations.utils import (
14     COMPILED_REGEX_TYPE,
15     RegexObject,
16     resolve_relation,
17 )
18 from django.utils.topological_sort import stable_topological_sort
19 
20 
21 class MigrationAutodetector:
22     """
23     Take a pair of ProjectStates and compare them to see what the first would
24     need doing to make it match the second (the second usually being the
25     project's current state).
26 
27     Note that this naturally operates on entire projects at a time,
28     as it's likely that changes interact (for example, you can't
29     add a ForeignKey without having a migration to add the table it
30     depends on first). A user interface may offer single-app usage
31     if it wishes, with the caveat that it may not always be possible.
32     """
33 
34     def __init__(self, from_state, to_state, questioner=None):
35         self.from_state = from_state
36         self.to_state = to_state
37         self.questioner = questioner or MigrationQuestioner()
38         self.existing_apps = {app for app, model in from_state.models}
39 
40     def changes(self, graph, trim_to_apps=None, convert_apps=None, migration_name=None):
41         """
42         Main entry point to produce a list of applicable changes.
43         Take a graph to base names on and an optional set of apps
44         to try and restrict to (restriction is not guaranteed)
45         """
46         changes = self._detect_changes(convert_apps, graph)
47         changes = self.arrange_for_graph(changes, graph, migration_name)
48         if trim_to_apps:
49             changes = self._trim_to_apps(changes, trim_to_apps)
50         return changes
51 
52     def deep_deconstruct(self, obj):
53         """
54         Recursive deconstruction for a field and its arguments.
55         Used for full comparison for rename/alter; sometimes a single-level
56         deconstruction will not compare correctly.
57         """
58         if isinstance(obj, list):
59             return [self.deep_deconstruct(value) for value in obj]
60         elif isinstance(obj, tuple):
61             return tuple(self.deep_deconstruct(value) for value in obj)
62         elif isinstance(obj, dict):
63             return {key: self.deep_deconstruct(value) for key, value in obj.items()}
64         elif isinstance(obj, functools.partial):
65             return (
66                 obj.func,
67                 self.deep_deconstruct(obj.args),
68                 self.deep_deconstruct(obj.keywords),
69             )
70         elif isinstance(obj, COMPILED_REGEX_TYPE):
71             return RegexObject(obj)
72         elif isinstance(obj, type):
73             # If this is a type that implements 'deconstruct' as an instance method,
74             # avoid treating this as being deconstructible itself - see #22951
75             return obj
76         elif hasattr(obj, "deconstruct"):
77             deconstructed = obj.deconstruct()
78             if isinstance(obj, models.Field):
79                 # we have a field which also returns a name
80                 deconstructed = deconstructed[1:]
81             path, args, kwargs = deconstructed
82             return (
83                 path,
84                 [self.deep_deconstruct(value) for value in args],
85                 {key: self.deep_deconstruct(value) for key, value in kwargs.items()},
86             )
87         else:
88             return obj
89 
90     def only_relation_agnostic_fields(self, fields):
91         """
92         Return a definition of the fields that ignores field names and
93         what related fields actually relate to. Used for detecting renames (as
94         the related fields change during renames).
95         """
96         fields_def = []
97         for name, field in sorted(fields.items()):
98             deconstruction = self.deep_deconstruct(field)
99             if field.remote_field and field.remote_field.model:
100                 deconstruction[2].pop("to", None)
101             fields_def.append(deconstruction)
102         return fields_def
103 
104     def _detect_changes(self, convert_apps=None, graph=None):
105         """
106         Return a dict of migration plans which will achieve the
107         change from from_state to to_state. The dict has app labels
108         as keys and a list of migrations as values.
109 
110         The resulting migrations aren't specially named, but the names
111         do matter for dependencies inside the set.
112 
113         convert_apps is the list of apps to convert to use migrations
114         (i.e. to make initial migrations for, in the usual case)
115 
116         graph is an optional argument that, if provided, can help improve
117         dependency generation and avoid potential circular dependencies.
118         """
119         # The first phase is generating all the operations for each app
120         # and gathering them into a big per-app list.
121         # Then go through that list, order it, and split into migrations to
122         # resolve dependencies caused by M2Ms and FKs.
123         self.generated_operations = {}
124         self.altered_indexes = {}
125         self.altered_constraints = {}
126         self.renamed_fields = {}
127 
128         # Prepare some old/new state and model lists, separating
129         # proxy models and ignoring unmigrated apps.
130         self.old_model_keys = set()
131         self.old_proxy_keys = set()
132         self.old_unmanaged_keys = set()
133         self.new_model_keys = set()
134         self.new_proxy_keys = set()
135         self.new_unmanaged_keys = set()
136         for (app_label, model_name), model_state in self.from_state.models.items():
137             if not model_state.options.get("managed", True):
138                 self.old_unmanaged_keys.add((app_label, model_name))
139             elif app_label not in self.from_state.real_apps:
140                 if model_state.options.get("proxy"):
141                     self.old_proxy_keys.add((app_label, model_name))
142                 else:
143                     self.old_model_keys.add((app_label, model_name))
144 
145         for (app_label, model_name), model_state in self.to_state.models.items():
146             if not model_state.options.get("managed", True):
147                 self.new_unmanaged_keys.add((app_label, model_name))
148             elif app_label not in self.from_state.real_apps or (
149                 convert_apps and app_label in convert_apps
150             ):
151                 if model_state.options.get("proxy"):
152                     self.new_proxy_keys.add((app_label, model_name))
153                 else:
154                     self.new_model_keys.add((app_label, model_name))
155 
156         self.from_state.resolve_fields_and_relations()
157         self.to_state.resolve_fields_and_relations()
158 
159         # Renames have to come first
160         self.generate_renamed_models()
161 
162         # Prepare lists of fields and generate through model map
163         self._prepare_field_lists()
164         self._generate_through_model_map()
165 
166         # Generate non-rename model operations
167         self.generate_deleted_models()
168         self.generate_created_models()
169         self.generate_deleted_proxies()
170         self.generate_created_proxies()
171         self.generate_altered_options()
172         self.generate_altered_managers()
173 
174         # Create the renamed fields and store them in self.renamed_fields.
175         # They are used by create_altered_indexes(), generate_altered_fields(),
176         # generate_removed_altered_index/unique_together(), and
177         # generate_altered_index/unique_together().
178         self.create_renamed_fields()
179         # Create the altered indexes and store them in self.altered_indexes.
180         # This avoids the same computation in generate_removed_indexes()
181         # and generate_added_indexes().
182         self.create_altered_indexes()
183         self.create_altered_constraints()
184         # Generate index removal operations before field is removed
185         self.generate_removed_constraints()
186         self.generate_removed_indexes()
187         # Generate field renaming operations.
188         self.generate_renamed_fields()
189         self.generate_renamed_indexes()
190         # Generate removal of foo together.
191         self.generate_removed_altered_unique_together()
192         self.generate_removed_altered_index_together()
193         # Generate field operations.
194         self.generate_removed_fields()
195         self.generate_added_fields()
196         self.generate_altered_fields()
197         self.generate_altered_order_with_respect_to()
198         self.generate_altered_unique_together()
199         self.generate_altered_index_together()
200         self.generate_added_indexes()
201         self.generate_added_constraints()
202         self.generate_altered_db_table()
203 
204         self._sort_migrations()
205         self._build_migration_list(graph)
206         self._optimize_migrations()
207 
208         return self.migrations
209 
210     def _prepare_field_lists(self):
211         """
212         Prepare field lists and a list of the fields that used through models
213         in the old state so dependencies can be made from the through model
214         deletion to the field that uses it.
215         """
216         self.kept_model_keys = self.old_model_keys & self.new_model_keys
217         self.kept_proxy_keys = self.old_proxy_keys & self.new_proxy_keys
218         self.kept_unmanaged_keys = self.old_unmanaged_keys & self.new_unmanaged_keys
219         self.through_users = {}
220         self.old_field_keys = {
221             (app_label, model_name, field_name)
222             for app_label, model_name in self.kept_model_keys
223             for field_name in self.from_state.models[
224                 app_label, self.renamed_models.get((app_label, model_name), model_name)
225             ].fields
226         }
227         self.new_field_keys = {
228             (app_label, model_name, field_name)
229             for app_label, model_name in self.kept_model_keys
230             for field_name in self.to_state.models[app_label, model_name].fields
231         }
232 
233     def _generate_through_model_map(self):
234         """Through model map generation."""
235         for app_label, model_name in sorted(self.old_model_keys):
236             old_model_name = self.renamed_models.get(
237                 (app_label, model_name), model_name
238             )
239             old_model_state = self.from_state.models[app_label, old_model_name]
240             for field_name, field in old_model_state.fields.items():
241                 if hasattr(field, "remote_field") and getattr(
242                     field.remote_field, "through", None
243                 ):
244                     through_key = resolve_relation(
245                         field.remote_field.through, app_label, model_name
246                     )
247                     self.through_users[through_key] = (
248                         app_label,
249                         old_model_name,
250                         field_name,
251                     )
252 
253     @staticmethod
254     def _resolve_dependency(dependency):
255         """
256         Return the resolved dependency and a boolean denoting whether or not
257         it was swappable.
258         """
259         if dependency[0] != "__setting__":
260             return dependency, False
261         resolved_app_label, resolved_object_name = getattr(
262             settings, dependency[1]
263         ).split(".")
264         return (resolved_app_label, resolved_object_name.lower()) + dependency[2:], True
265 
266     def _build_migration_list(self, graph=None):
267         """
268         Chop the lists of operations up into migrations with dependencies on
269         each other. Do this by going through an app's list of operations until
270         one is found that has an outgoing dependency that isn't in another
271         app's migration yet (hasn't been chopped off its list). Then chop off
272         the operations before it into a migration and move onto the next app.
273         If the loops completes without doing anything, there's a circular
274         dependency (which _should_ be impossible as the operations are
275         all split at this point so they can't depend and be depended on).
276         """
277         self.migrations = {}
278         num_ops = sum(len(x) for x in self.generated_operations.values())
279         chop_mode = False
280         while num_ops:
281             # On every iteration, we step through all the apps and see if there
282             # is a completed set of operations.
283             # If we find that a subset of the operations are complete we can
284             # try to chop it off from the rest and continue, but we only
285             # do this if we've already been through the list once before
286             # without any chopping and nothing has changed.
287             for app_label in sorted(self.generated_operations):
288                 chopped = []
289                 dependencies = set()
290                 for operation in list(self.generated_operations[app_label]):
291                     deps_satisfied = True
292                     operation_dependencies = set()
293                     for dep in operation._auto_deps:
294                         # Temporarily resolve the swappable dependency to
295                         # prevent circular references. While keeping the
296                         # dependency checks on the resolved model, add the
297                         # swappable dependencies.
298                         original_dep = dep
299                         dep, is_swappable_dep = self._resolve_dependency(dep)
300                         if dep[0] != app_label:
301                             # External app dependency. See if it's not yet
302                             # satisfied.
303                             for other_operation in self.generated_operations.get(
304                                 dep[0], []
305                             ):
306                                 if self.check_dependency(other_operation, dep):
307                                     deps_satisfied = False
308                                     break
309                             if not deps_satisfied:
310                                 break
311                             else:
312                                 if is_swappable_dep:
313                                     operation_dependencies.add(
314                                         (original_dep[0], original_dep[1])
315                                     )
316                                 elif dep[0] in self.migrations:
317                                     operation_dependencies.add(
318                                         (dep[0], self.migrations[dep[0]][-1].name)
319                                     )
320                                 else:
321                                     # If we can't find the other app, we add a
322                                     # first/last dependency, but only if we've
323                                     # already been through once and checked
324                                     # everything.
325                                     if chop_mode:
326                                         # If the app already exists, we add a
327                                         # dependency on the last migration, as
328                                         # we don't know which migration
329                                         # contains the target field. If it's
330                                         # not yet migrated or has no
331                                         # migrations, we use __first__.
332                                         if graph and graph.leaf_nodes(dep[0]):
333                                             operation_dependencies.add(
334                                                 graph.leaf_nodes(dep[0])[0]
335                                             )
336                                         else:
337                                             operation_dependencies.add(
338                                                 (dep[0], "__first__")
339                                             )
340                                     else:
341                                         deps_satisfied = False
342                     if deps_satisfied:
343                         chopped.append(operation)
344                         dependencies.update(operation_dependencies)
345                         del self.generated_operations[app_label][0]
346                     else:
347                         break
348                 # Make a migration! Well, only if there's stuff to put in it
349                 if dependencies or chopped:
350                     if not self.generated_operations[app_label] or chop_mode:
351                         subclass = type(
352                             "Migration",
353                             (Migration,),
354                             {"operations": [], "dependencies": []},
355                         )
356                         instance = subclass(
357                             "auto_%i" % (len(self.migrations.get(app_label, [])) + 1),
358                             app_label,
359                         )
360                         instance.dependencies = list(dependencies)
361                         instance.operations = chopped
362                         instance.initial = app_label not in self.existing_apps
363                         self.migrations.setdefault(app_label, []).append(instance)
364                         chop_mode = False
365                     else:
366                         self.generated_operations[app_label] = (
367                             chopped + self.generated_operations[app_label]
368                         )
369             new_num_ops = sum(len(x) for x in self.generated_operations.values())
370             if new_num_ops == num_ops:
371                 if not chop_mode:
372                     chop_mode = True
373                 else:
374                     raise ValueError(
375                         "Cannot resolve operation dependencies: %r"
376                         % self.generated_operations
377                     )
378             num_ops = new_num_ops
379 
380     def _sort_migrations(self):
381         """
382         Reorder to make things possible. Reordering may be needed so FKs work
383         nicely inside the same app.
384         """
385         for app_label, ops in sorted(self.generated_operations.items()):
386             # construct a dependency graph for intra-app dependencies
387             dependency_graph = {op: set() for op in ops}
388             for op in ops:
389                 for dep in op._auto_deps:
390                     # Resolve intra-app dependencies to handle circular
391                     # references involving a swappable model.
392                     dep = self._resolve_dependency(dep)[0]
393                     if dep[0] == app_label:
394                         for op2 in ops:
395                             if self.check_dependency(op2, dep):
396                                 dependency_graph[op].add(op2)
397 
398             # we use a stable sort for deterministic tests & general behavior
399             self.generated_operations[app_label] = stable_topological_sort(
400                 ops, dependency_graph
401             )
402 
403     def _optimize_migrations(self):
404         # Add in internal dependencies among the migrations
405         for app_label, migrations in self.migrations.items():
406             for m1, m2 in zip(migrations, migrations[1:]):
407                 m2.dependencies.append((app_label, m1.name))
408 
409         # De-dupe dependencies
410         for migrations in self.migrations.values():
411             for migration in migrations:
412                 migration.dependencies = list(set(migration.dependencies))
413 
414         # Optimize migrations
415         for app_label, migrations in self.migrations.items():
416             for migration in migrations:
417                 migration.operations = MigrationOptimizer().optimize(
418                     migration.operations, app_label
419                 )
420 
421     def check_dependency(self, operation, dependency):
422         """
423         Return True if the given operation depends on the given dependency,
424         False otherwise.
425         """
426         # Created model
427         if dependency[2] is None and dependency[3] is True:
428             return (
429                 isinstance(operation, operations.CreateModel)
430                 and operation.name_lower == dependency[1].lower()
431             )
432         # Created field
433         elif dependency[2] is not None and dependency[3] is True:
434             return (
435                 isinstance(operation, operations.CreateModel)
436                 and operation.name_lower == dependency[1].lower()
437                 and any(dependency[2] == x for x, y in operation.fields)
438             ) or (
439                 isinstance(operation, operations.AddField)
440                 and operation.model_name_lower == dependency[1].lower()
441                 and operation.name_lower == dependency[2].lower()
442             )
443         # Removed field
444         elif dependency[2] is not None and dependency[3] is False:
445             return (
446                 isinstance(operation, operations.RemoveField)
447                 and operation.model_name_lower == dependency[1].lower()
448                 and operation.name_lower == dependency[2].lower()
449             )
450         # Removed model
451         elif dependency[2] is None and dependency[3] is False:
452             return (
453                 isinstance(operation, operations.DeleteModel)
454                 and operation.name_lower == dependency[1].lower()
455             )
456         # Field being altered
457         elif dependency[2] is not None and dependency[3] == "alter":
458             return (
459                 isinstance(operation, operations.AlterField)
460                 and operation.model_name_lower == dependency[1].lower()
461                 and operation.name_lower == dependency[2].lower()
462             )
463         # order_with_respect_to being unset for a field
464         elif dependency[2] is not None and dependency[3] == "order_wrt_unset":
465             return (
466                 isinstance(operation, operations.AlterOrderWithRespectTo)
467                 and operation.name_lower == dependency[1].lower()
468                 and (operation.order_with_respect_to or "").lower()
469                 != dependency[2].lower()
470             )
471         # Field is removed and part of an index/unique_together
472         elif dependency[2] is not None and dependency[3] == "foo_together_change":
473             return (
474                 isinstance(
475                     operation,
476                     (operations.AlterUniqueTogether, operations.AlterIndexTogether),
477                 )
478                 and operation.name_lower == dependency[1].lower()
479             )
480         # Unknown dependency. Raise an error.
481         else:
482             raise ValueError("Can't handle dependency %r" % (dependency,))
483 
484     def add_operation(self, app_label, operation, dependencies=None, beginning=False):
485         # Dependencies are
486         # (app_label, model_name, field_name, create/delete as True/False)
487         operation._auto_deps = dependencies or []
488         if beginning:
489             self.generated_operations.setdefault(app_label, []).insert(0, operation)
490         else:
491             self.generated_operations.setdefault(app_label, []).append(operation)
492 
493     def swappable_first_key(self, item):
494         """
495         Place potential swappable models first in lists of created models (only
496         real way to solve #22783).
497         """
498         try:
499             model_state = self.to_state.models[item]
500             base_names = {
501                 base if isinstance(base, str) else base.__name__
502                 for base in model_state.bases
503             }
504             string_version = "%s.%s" % (item[0], item[1])
505             if (
506                 model_state.options.get("swappable")
507                 or "AbstractUser" in base_names
508                 or "AbstractBaseUser" in base_names
509                 or settings.AUTH_USER_MODEL.lower() == string_version.lower()
510             ):
511                 return ("___" + item[0], "___" + item[1])
512         except LookupError:
513             pass
514         return item
515 
516     def generate_renamed_models(self):
517         """
518         Find any renamed models, generate the operations for them, and remove
519         the old entry from the model lists. Must be run before other
520         model-level generation.
521         """
522         self.renamed_models = {}
523         self.renamed_models_rel = {}
524         added_models = self.new_model_keys - self.old_model_keys
525         for app_label, model_name in sorted(added_models):
526             model_state = self.to_state.models[app_label, model_name]
527             model_fields_def = self.only_relation_agnostic_fields(model_state.fields)
528 
529             removed_models = self.old_model_keys - self.new_model_keys
530             for rem_app_label, rem_model_name in removed_models:
531                 if rem_app_label == app_label:
532                     rem_model_state = self.from_state.models[
533                         rem_app_label, rem_model_name
534                     ]
535                     rem_model_fields_def = self.only_relation_agnostic_fields(
536                         rem_model_state.fields
537                     )
538                     if model_fields_def == rem_model_fields_def:
539                         if self.questioner.ask_rename_model(
540                             rem_model_state, model_state
541                         ):
542                             dependencies = []
543                             fields = list(model_state.fields.values()) + [
544                                 field.remote_field
545                                 for relations in self.to_state.relations[
546                                     app_label, model_name
547                                 ].values()
548                                 for field in relations.values()
549                             ]
550                             for field in fields:
551                                 if field.is_relation:
552                                     dependencies.extend(
553                                         self._get_dependencies_for_foreign_key(
554                                             app_label,
555                                             model_name,
556                                             field,
557                                             self.to_state,
558                                         )
559                                     )
560                             self.add_operation(
561                                 app_label,
562                                 operations.RenameModel(
563                                     old_name=rem_model_state.name,
564                                     new_name=model_state.name,
565                                 ),
566                                 dependencies=dependencies,
567                             )
568                             self.renamed_models[app_label, model_name] = rem_model_name
569                             renamed_models_rel_key = "%s.%s" % (
570                                 rem_model_state.app_label,
571                                 rem_model_state.name_lower,
572                             )
573                             self.renamed_models_rel[
574                                 renamed_models_rel_key
575                             ] = "%s.%s" % (
576                                 model_state.app_label,
577                                 model_state.name_lower,
578                             )
579                             self.old_model_keys.remove((rem_app_label, rem_model_name))
580                             self.old_model_keys.add((app_label, model_name))
581                             break
582 
583     def generate_created_models(self):
584         """
585         Find all new models (both managed and unmanaged) and make create
586         operations for them as well as separate operations to create any
587         foreign key or M2M relationships (these are optimized later, if
588         possible).
589 
590         Defer any model options that refer to collections of fields that might
591         be deferred (e.g. unique_together, index_together).
592         """
593         old_keys = self.old_model_keys | self.old_unmanaged_keys
594         added_models = self.new_model_keys - old_keys
595         added_unmanaged_models = self.new_unmanaged_keys - old_keys
596         all_added_models = chain(
597             sorted(added_models, key=self.swappable_first_key, reverse=True),
598             sorted(added_unmanaged_models, key=self.swappable_first_key, reverse=True),
599         )
600         for app_label, model_name in all_added_models:
601             model_state = self.to_state.models[app_label, model_name]
602             # Gather related fields
603             related_fields = {}
604             primary_key_rel = None
605             for field_name, field in model_state.fields.items():
606                 if field.remote_field:
607                     if field.remote_field.model:
608                         if field.primary_key:
609                             primary_key_rel = field.remote_field.model
610                         elif not field.remote_field.parent_link:
611                             related_fields[field_name] = field
612                     if getattr(field.remote_field, "through", None):
613                         related_fields[field_name] = field
614 
615             # Are there indexes/unique|index_together to defer?
616             indexes = model_state.options.pop("indexes")
617             constraints = model_state.options.pop("constraints")
618             unique_together = model_state.options.pop("unique_together", None)
619             index_together = model_state.options.pop("index_together", None)
620             order_with_respect_to = model_state.options.pop(
621                 "order_with_respect_to", None
622             )
623             # Depend on the deletion of any possible proxy version of us
624             dependencies = [
625                 (app_label, model_name, None, False),
626             ]
627             # Depend on all bases
628             for base in model_state.bases:
629                 if isinstance(base, str) and "." in base:
630                     base_app_label, base_name = base.split(".", 1)
631                     dependencies.append((base_app_label, base_name, None, True))
632                     # Depend on the removal of base fields if the new model has
633                     # a field with the same name.
634                     old_base_model_state = self.from_state.models.get(
635                         (base_app_label, base_name)
636                     )
637                     new_base_model_state = self.to_state.models.get(
638                         (base_app_label, base_name)
639                     )
640                     if old_base_model_state and new_base_model_state:
641                         removed_base_fields = (
642                             set(old_base_model_state.fields)
643                             .difference(
644                                 new_base_model_state.fields,
645                             )
646                             .intersection(model_state.fields)
647                         )
648                         for removed_base_field in removed_base_fields:
649                             dependencies.append(
650                                 (base_app_label, base_name, removed_base_field, False)
651                             )
652             # Depend on the other end of the primary key if it's a relation
653             if primary_key_rel:
654                 dependencies.append(
655                     resolve_relation(
656                         primary_key_rel,
657                         app_label,
658                         model_name,
659                     )
660                     + (None, True)
661                 )
662             # Generate creation operation
663             self.add_operation(
664                 app_label,
665                 operations.CreateModel(
666                     name=model_state.name,
667                     fields=[
668                         d
669                         for d in model_state.fields.items()
670                         if d[0] not in related_fields
671                     ],
672                     options=model_state.options,
673                     bases=model_state.bases,
674                     managers=model_state.managers,
675                 ),
676                 dependencies=dependencies,
677                 beginning=True,
678             )
679 
680             # Don't add operations which modify the database for unmanaged models
681             if not model_state.options.get("managed", True):
682                 continue
683 
684             # Generate operations for each related field
685             for name, field in sorted(related_fields.items()):
686                 dependencies = self._get_dependencies_for_foreign_key(
687                     app_label,
688                     model_name,
689                     field,
690                     self.to_state,
691                 )
692                 # Depend on our own model being created
693                 dependencies.append((app_label, model_name, None, True))
694                 # Make operation
695                 self.add_operation(
696                     app_label,
697                     operations.AddField(
698                         model_name=model_name,
699                         name=name,
700                         field=field,
701                     ),
702                     dependencies=list(set(dependencies)),
703                 )
704             # Generate other opns
705             if order_with_respect_to:
706                 self.add_operation(
707                     app_label,
708                     operations.AlterOrderWithRespectTo(
709                         name=model_name,
710                         order_with_respect_to=order_with_respect_to,
711                     ),
712                     dependencies=[
713                         (app_label, model_name, order_with_respect_to, True),
714                         (app_label, model_name, None, True),
715                     ],
716                 )
717             related_dependencies = [
718                 (app_label, model_name, name, True) for name in sorted(related_fields)
719             ]
720             related_dependencies.append((app_label, model_name, None, True))
721             for index in indexes:
722                 self.add_operation(
723                     app_label,
724                     operations.AddIndex(
725                         model_name=model_name,
726                         index=index,
727                     ),
728                     dependencies=related_dependencies,
729                 )
730             for constraint in constraints:
731                 self.add_operation(
732                     app_label,
733                     operations.AddConstraint(
734                         model_name=model_name,
735                         constraint=constraint,
736                     ),
737                     dependencies=related_dependencies,
738                 )
739             if unique_together:
740                 self.add_operation(
741                     app_label,
742                     operations.AlterUniqueTogether(
743                         name=model_name,
744                         unique_together=unique_together,
745                     ),
746                     dependencies=related_dependencies,
747                 )
748             if index_together:
749                 self.add_operation(
750                     app_label,
751                     operations.AlterIndexTogether(
752                         name=model_name,
753                         index_together=index_together,
754                     ),
755                     dependencies=related_dependencies,
756                 )
757             # Fix relationships if the model changed from a proxy model to a
758             # concrete model.
759             relations = self.to_state.relations
760             if (app_label, model_name) in self.old_proxy_keys:
761                 for related_model_key, related_fields in relations[
762                     app_label, model_name
763                 ].items():
764                     related_model_state = self.to_state.models[related_model_key]
765                     for related_field_name, related_field in related_fields.items():
766                         self.add_operation(
767                             related_model_state.app_label,
768                             operations.AlterField(
769                                 model_name=related_model_state.name,
770                                 name=related_field_name,
771                                 field=related_field,
772                             ),
773                             dependencies=[(app_label, model_name, None, True)],
774                         )
775 
776     def generate_created_proxies(self):
777         """
778         Make CreateModel statements for proxy models. Use the same statements
779         as that way there's less code duplication, but for proxy models it's
780         safe to skip all the pointless field stuff and chuck out an operation.
781         """
782         added = self.new_proxy_keys - self.old_proxy_keys
783         for app_label, model_name in sorted(added):
784             model_state = self.to_state.models[app_label, model_name]
785             assert model_state.options.get("proxy")
786             # Depend on the deletion of any possible non-proxy version of us
787             dependencies = [
788                 (app_label, model_name, None, False),
789             ]
790             # Depend on all bases
791             for base in model_state.bases:
792                 if isinstance(base, str) and "." in base:
793                     base_app_label, base_name = base.split(".", 1)
794                     dependencies.append((base_app_label, base_name, None, True))
795             # Generate creation operation
796             self.add_operation(
797                 app_label,
798                 operations.CreateModel(
799                     name=model_state.name,
800                     fields=[],
801                     options=model_state.options,
802                     bases=model_state.bases,
803                     managers=model_state.managers,
804                 ),
805                 # Depend on the deletion of any possible non-proxy version of us
806                 dependencies=dependencies,
807             )
808 
809     def generate_deleted_models(self):
810         """
811         Find all deleted models (managed and unmanaged) and make delete
812         operations for them as well as separate operations to delete any
813         foreign key or M2M relationships (these are optimized later, if
814         possible).
815 
816         Also bring forward removal of any model options that refer to
817         collections of fields - the inverse of generate_created_models().
818         """
819         new_keys = self.new_model_keys | self.new_unmanaged_keys
820         deleted_models = self.old_model_keys - new_keys
821         deleted_unmanaged_models = self.old_unmanaged_keys - new_keys
822         all_deleted_models = chain(
823             sorted(deleted_models), sorted(deleted_unmanaged_models)
824         )
825         for app_label, model_name in all_deleted_models:
826             model_state = self.from_state.models[app_label, model_name]
827             # Gather related fields
828             related_fields = {}
829             for field_name, field in model_state.fields.items():
830                 if field.remote_field:
831                     if field.remote_field.model:
832                         related_fields[field_name] = field
833                     if getattr(field.remote_field, "through", None):
834                         related_fields[field_name] = field
835             # Generate option removal first
836             unique_together = model_state.options.pop("unique_together", None)
837             index_together = model_state.options.pop("index_together", None)
838             if unique_together:
839                 self.add_operation(
840                     app_label,
841                     operations.AlterUniqueTogether(
842                         name=model_name,
843                         unique_together=None,
844                     ),
845                 )
846             if index_together:
847                 self.add_operation(
848                     app_label,
849                     operations.AlterIndexTogether(
850                         name=model_name,
851                         index_together=None,
852                     ),
853                 )
854             # Then remove each related field
855             for name in sorted(related_fields):
856                 self.add_operation(
857                     app_label,
858                     operations.RemoveField(
859                         model_name=model_name,
860                         name=name,
861                     ),
862                 )
863             # Finally, remove the model.
864             # This depends on both the removal/alteration of all incoming fields
865             # and the removal of all its own related fields, and if it's
866             # a through model the field that references it.
867             dependencies = []
868             relations = self.from_state.relations
869             for (
870                 related_object_app_label,
871                 object_name,
872             ), relation_related_fields in relations[app_label, model_name].items():
873                 for field_name, field in relation_related_fields.items():
874                     dependencies.append(
875                         (related_object_app_label, object_name, field_name, False),
876                     )
877                     if not field.many_to_many:
878                         dependencies.append(
879                             (
880                                 related_object_app_label,
881                                 object_name,
882                                 field_name,
883                                 "alter",
884                             ),
885                         )
886 
887             for name in sorted(related_fields):
888                 dependencies.append((app_label, model_name, name, False))
889             # We're referenced in another field's through=
890             through_user = self.through_users.get((app_label, model_state.name_lower))
891             if through_user:
892                 dependencies.append(
893                     (through_user[0], through_user[1], through_user[2], False)
894                 )
895             # Finally, make the operation, deduping any dependencies
896             self.add_operation(
897                 app_label,
898                 operations.DeleteModel(
899                     name=model_state.name,
900                 ),
901                 dependencies=list(set(dependencies)),
902             )
903 
904     def generate_deleted_proxies(self):
905         """Make DeleteModel options for proxy models."""
906         deleted = self.old_proxy_keys - self.new_proxy_keys
907         for app_label, model_name in sorted(deleted):
908             model_state = self.from_state.models[app_label, model_name]
909             assert model_state.options.get("proxy")
910             self.add_operation(
911                 app_label,
912                 operations.DeleteModel(
913                     name=model_state.name,
914                 ),
915             )
916 
917     def create_renamed_fields(self):
918         """Work out renamed fields."""
919         self.renamed_operations = []
920         old_field_keys = self.old_field_keys.copy()
921         for app_label, model_name, field_name in sorted(
922             self.new_field_keys - old_field_keys
923         ):
924             old_model_name = self.renamed_models.get(
925                 (app_label, model_name), model_name
926             )
927             old_model_state = self.from_state.models[app_label, old_model_name]
928             new_model_state = self.to_state.models[app_label, model_name]
929             field = new_model_state.get_field(field_name)
930             # Scan to see if this is actually a rename!
931             field_dec = self.deep_deconstruct(field)
932             for rem_app_label, rem_model_name, rem_field_name in sorted(
933                 old_field_keys - self.new_field_keys
934             ):
935                 if rem_app_label == app_label and rem_model_name == model_name:
936                     old_field = old_model_state.get_field(rem_field_name)
937                     old_field_dec = self.deep_deconstruct(old_field)
938                     if (
939                         field.remote_field
940                         and field.remote_field.model
941                         and "to" in old_field_dec[2]
942                     ):
943                         old_rel_to = old_field_dec[2]["to"]
944                         if old_rel_to in self.renamed_models_rel:
945                             old_field_dec[2]["to"] = self.renamed_models_rel[old_rel_to]
946                     old_field.set_attributes_from_name(rem_field_name)
947                     old_db_column = old_field.get_attname_column()[1]
948                     if old_field_dec == field_dec or (
949                         # Was the field renamed and db_column equal to the
950                         # old field's column added?
951                         old_field_dec[0:2] == field_dec[0:2]
952                         and dict(old_field_dec[2], db_column=old_db_column)
953                         == field_dec[2]
954                     ):
955                         if self.questioner.ask_rename(
956                             model_name, rem_field_name, field_name, field
957                         ):
958                             self.renamed_operations.append(
959                                 (
960                                     rem_app_label,
961                                     rem_model_name,
962                                     old_field.db_column,
963                                     rem_field_name,
964                                     app_label,
965                                     model_name,
966                                     field,
967                                     field_name,
968                                 )
969                             )
970                             old_field_keys.remove(
971                                 (rem_app_label, rem_model_name, rem_field_name)
972                             )
973                             old_field_keys.add((app_label, model_name, field_name))
974                             self.renamed_fields[
975                                 app_label, model_name, field_name
976                             ] = rem_field_name
977                             break
978 
979     def generate_renamed_fields(self):
980         """Generate RenameField operations."""
981         for (
982             rem_app_label,
983             rem_model_name,
984             rem_db_column,
985             rem_field_name,
986             app_label,
987             model_name,
988             field,
989             field_name,
990         ) in self.renamed_operations:
991             # A db_column mismatch requires a prior noop AlterField for the
992             # subsequent RenameField to be a noop on attempts at preserving the
993             # old name.
994             if rem_db_column != field.db_column:
995                 altered_field = field.clone()
996                 altered_field.name = rem_field_name
997                 self.add_operation(
998                     app_label,
999                     operations.AlterField(
1000                         model_name=model_name,
1001                         name=rem_field_name,
1002                         field=altered_field,
1003                     ),
1004                 )
1005             self.add_operation(
1006                 app_label,
1007                 operations.RenameField(
1008                     model_name=model_name,
1009                     old_name=rem_field_name,
1010                     new_name=field_name,
1011                 ),
1012             )
1013             self.old_field_keys.remove((rem_app_label, rem_model_name, rem_field_name))
1014             self.old_field_keys.add((app_label, model_name, field_name))
1015 
1016     def generate_added_fields(self):
1017         """Make AddField operations."""
1018         for app_label, model_name, field_name in sorted(
1019             self.new_field_keys - self.old_field_keys
1020         ):
1021             self._generate_added_field(app_label, model_name, field_name)
1022 
1023     def _generate_added_field(self, app_label, model_name, field_name):
1024         field = self.to_state.models[app_label, model_name].get_field(field_name)
1025         # Adding a field always depends at least on its removal.
1026         dependencies = [(app_label, model_name, field_name, False)]
1027         # Fields that are foreignkeys/m2ms depend on stuff.
1028         if field.remote_field and field.remote_field.model:
1029             dependencies.extend(
1030                 self._get_dependencies_for_foreign_key(
1031                     app_label,
1032                     model_name,
1033                     field,
1034                     self.to_state,
1035                 )
1036             )
1037         # You can't just add NOT NULL fields with no default or fields
1038         # which don't allow empty strings as default.
1039         time_fields = (models.DateField, models.DateTimeField, models.TimeField)
1040         preserve_default = (
1041             field.null
1042             or field.has_default()
1043             or field.many_to_many
1044             or (field.blank and field.empty_strings_allowed)
1045             or (isinstance(field, time_fields) and field.auto_now)
1046         )
1047         if not preserve_default:
1048             field = field.clone()
1049             if isinstance(field, time_fields) and field.auto_now_add:
1050                 field.default = self.questioner.ask_auto_now_add_addition(
1051                     field_name, model_name
1052                 )
1053             else:
1054                 field.default = self.questioner.ask_not_null_addition(
1055                     field_name, model_name
1056                 )
1057         if (
1058             field.unique
1059             and field.default is not models.NOT_PROVIDED
1060             and callable(field.default)
1061         ):
1062             self.questioner.ask_unique_callable_default_addition(field_name, model_name)
1063         self.add_operation(
1064             app_label,
1065             operations.AddField(
1066                 model_name=model_name,
1067                 name=field_name,
1068                 field=field,
1069                 preserve_default=preserve_default,
1070             ),
1071             dependencies=dependencies,
1072         )
1073 
1074     def generate_removed_fields(self):
1075         """Make RemoveField operations."""
1076         for app_label, model_name, field_name in sorted(
1077             self.old_field_keys - self.new_field_keys
1078         ):
1079             self._generate_removed_field(app_label, model_name, field_name)
1080 
1081     def _generate_removed_field(self, app_label, model_name, field_name):
1082         self.add_operation(
1083             app_label,
1084             operations.RemoveField(
1085                 model_name=model_name,
1086                 name=field_name,
1087             ),
1088             # We might need to depend on the removal of an
1089             # order_with_respect_to or index/unique_together operation;
1090             # this is safely ignored if there isn't one
1091             dependencies=[
1092                 (app_label, model_name, field_name, "order_wrt_unset"),
1093                 (app_label, model_name, field_name, "foo_together_change"),
1094             ],
1095         )
1096 
1097     def generate_altered_fields(self):
1098         """
1099         Make AlterField operations, or possibly RemovedField/AddField if alter
1100         isn't possible.
1101         """
1102         for app_label, model_name, field_name in sorted(
1103             self.old_field_keys & self.new_field_keys
1104         ):
1105             # Did the field change?
1106             old_model_name = self.renamed_models.get(
1107                 (app_label, model_name), model_name
1108             )
1109             old_field_name = self.renamed_fields.get(
1110                 (app_label, model_name, field_name), field_name
1111             )
1112             old_field = self.from_state.models[app_label, old_model_name].get_field(
1113                 old_field_name
1114             )
1115             new_field = self.to_state.models[app_label, model_name].get_field(
1116                 field_name
1117             )
1118             dependencies = []
1119             # Implement any model renames on relations; these are handled by RenameModel
1120             # so we need to exclude them from the comparison
1121             if hasattr(new_field, "remote_field") and getattr(
1122                 new_field.remote_field, "model", None
1123             ):
1124                 rename_key = resolve_relation(
1125                     new_field.remote_field.model, app_label, model_name
1126                 )
1127                 if rename_key in self.renamed_models:
1128                     new_field.remote_field.model = old_field.remote_field.model
1129                 # Handle ForeignKey which can only have a single to_field.
1130                 remote_field_name = getattr(new_field.remote_field, "field_name", None)
1131                 if remote_field_name:
1132                     to_field_rename_key = rename_key + (remote_field_name,)
1133                     if to_field_rename_key in self.renamed_fields:
1134                         # Repoint both model and field name because to_field
1135                         # inclusion in ForeignKey.deconstruct() is based on
1136                         # both.
1137                         new_field.remote_field.model = old_field.remote_field.model
1138                         new_field.remote_field.field_name = (
1139                             old_field.remote_field.field_name
1140                         )
1141                 # Handle ForeignObjects which can have multiple from_fields/to_fields.
1142                 from_fields = getattr(new_field, "from_fields", None)
1143                 if from_fields:
1144                     from_rename_key = (app_label, model_name)
1145                     new_field.from_fields = tuple(
1146                         [
1147                             self.renamed_fields.get(
1148                                 from_rename_key + (from_field,), from_field
1149                             )
1150                             for from_field in from_fields
1151                         ]
1152                     )
1153                     new_field.to_fields = tuple(
1154                         [
1155                             self.renamed_fields.get(rename_key + (to_field,), to_field)
1156                             for to_field in new_field.to_fields
1157                         ]
1158                     )
1159                 dependencies.extend(
1160                     self._get_dependencies_for_foreign_key(
1161                         app_label,
1162                         model_name,
1163                         new_field,
1164                         self.to_state,
1165                     )
1166                 )
1167             if hasattr(new_field, "remote_field") and getattr(
1168                 new_field.remote_field, "through", None
1169             ):
1170                 rename_key = resolve_relation(
1171                     new_field.remote_field.through, app_label, model_name
1172                 )
1173                 if rename_key in self.renamed_models:
1174                     new_field.remote_field.through = old_field.remote_field.through
1175             old_field_dec = self.deep_deconstruct(old_field)
1176             new_field_dec = self.deep_deconstruct(new_field)
1177             # If the field was confirmed to be renamed it means that only
1178             # db_column was allowed to change which generate_renamed_fields()
1179             # already accounts for by adding an AlterField operation.
1180             if old_field_dec != new_field_dec and old_field_name == field_name:
1181                 both_m2m = old_field.many_to_many and new_field.many_to_many
1182                 neither_m2m = not old_field.many_to_many and not new_field.many_to_many
1183                 if both_m2m or neither_m2m:
1184                     # Either both fields are m2m or neither is
1185                     preserve_default = True
1186                     if (
1187                         old_field.null
1188                         and not new_field.null
1189                         and not new_field.has_default()
1190                         and not new_field.many_to_many
1191                     ):
1192                         field = new_field.clone()
1193                         new_default = self.questioner.ask_not_null_alteration(
1194                             field_name, model_name
1195                         )
1196                         if new_default is not models.NOT_PROVIDED:
1197                             field.default = new_default
1198                             preserve_default = False
1199                     else:
1200                         field = new_field
1201                     self.add_operation(
1202                         app_label,
1203                         operations.AlterField(
1204                             model_name=model_name,
1205                             name=field_name,
1206                             field=field,
1207                             preserve_default=preserve_default,
1208                         ),
1209                         dependencies=dependencies,
1210                     )
1211                 else:
1212                     # We cannot alter between m2m and concrete fields
1213                     self._generate_removed_field(app_label, model_name, field_name)
1214                     self._generate_added_field(app_label, model_name, field_name)
1215 
1216     def create_altered_indexes(self):
1217         option_name = operations.AddIndex.option_name
1218         self.renamed_index_together_values = defaultdict(list)
1219 
1220         for app_label, model_name in sorted(self.kept_model_keys):
1221             old_model_name = self.renamed_models.get(
1222                 (app_label, model_name), model_name
1223             )
1224             old_model_state = self.from_state.models[app_label, old_model_name]
1225             new_model_state = self.to_state.models[app_label, model_name]
1226 
1227             old_indexes = old_model_state.options[option_name]
1228             new_indexes = new_model_state.options[option_name]
1229             added_indexes = [idx for idx in new_indexes if idx not in old_indexes]
1230             removed_indexes = [idx for idx in old_indexes if idx not in new_indexes]
1231             renamed_indexes = []
1232             # Find renamed indexes.
1233             remove_from_added = []
1234             remove_from_removed = []
1235             for new_index in added_indexes:
1236                 new_index_dec = new_index.deconstruct()
1237                 new_index_name = new_index_dec[2].pop("name")
1238                 for old_index in removed_indexes:
1239                     old_index_dec = old_index.deconstruct()
1240                     old_index_name = old_index_dec[2].pop("name")
1241                     # Indexes are the same except for the names.
1242                     if (
1243                         new_index_dec == old_index_dec
1244                         and new_index_name != old_index_name
1245                     ):
1246                         renamed_indexes.append((old_index_name, new_index_name, None))
1247                         remove_from_added.append(new_index)
1248                         remove_from_removed.append(old_index)
1249             # Find index_together changed to indexes.
1250             for (
1251                 old_value,
1252                 new_value,
1253                 index_together_app_label,
1254                 index_together_model_name,
1255                 dependencies,
1256             ) in self._get_altered_foo_together_operations(
1257                 operations.AlterIndexTogether.option_name
1258             ):
1259                 if (
1260                     app_label != index_together_app_label
1261                     or model_name != index_together_model_name
1262                 ):
1263                     continue
1264                 removed_values = old_value.difference(new_value)
1265                 for removed_index_together in removed_values:
1266                     renamed_index_together_indexes = []
1267                     for new_index in added_indexes:
1268                         _, args, kwargs = new_index.deconstruct()
1269                         # Ensure only 'fields' are defined in the Index.
1270                         if (
1271                             not args
1272                             and new_index.fields == list(removed_index_together)
1273                             and set(kwargs) == {"name", "fields"}
1274                         ):
1275                             renamed_index_together_indexes.append(new_index)
1276 
1277                     if len(renamed_index_together_indexes) == 1:
1278                         renamed_index = renamed_index_together_indexes[0]
1279                         remove_from_added.append(renamed_index)
1280                         renamed_indexes.append(
1281                             (None, renamed_index.name, removed_index_together)
1282                         )
1283                         self.renamed_index_together_values[
1284                             index_together_app_label, index_together_model_name
1285                         ].append(removed_index_together)
1286             # Remove renamed indexes from the lists of added and removed
1287             # indexes.
1288             added_indexes = [
1289                 idx for idx in added_indexes if idx not in remove_from_added
1290             ]
1291             removed_indexes = [
1292                 idx for idx in removed_indexes if idx not in remove_from_removed
1293             ]
1294 
1295             self.altered_indexes.update(
1296                 {
1297                     (app_label, model_name): {
1298                         "added_indexes": added_indexes,
1299                         "removed_indexes": removed_indexes,
1300                         "renamed_indexes": renamed_indexes,
1301                     }
1302                 }
1303             )
1304 
1305     def generate_added_indexes(self):
1306         for (app_label, model_name), alt_indexes in self.altered_indexes.items():
1307             for index in alt_indexes["added_indexes"]:
1308                 self.add_operation(
1309                     app_label,
1310                     operations.AddIndex(
1311                         model_name=model_name,
1312                         index=index,
1313                     ),
1314                 )
1315 
1316     def generate_removed_indexes(self):
1317         for (app_label, model_name), alt_indexes in self.altered_indexes.items():
1318             for index in alt_indexes["removed_indexes"]:
1319                 self.add_operation(
1320                     app_label,
1321                     operations.RemoveIndex(
1322                         model_name=model_name,
1323                         name=index.name,
1324                     ),
1325                 )
1326 
1327     def generate_renamed_indexes(self):
1328         for (app_label, model_name), alt_indexes in self.altered_indexes.items():
1329             for old_index_name, new_index_name, old_fields in alt_indexes[
1330                 "renamed_indexes"
1331             ]:
1332                 self.add_operation(
1333                     app_label,
1334                     operations.RenameIndex(
1335                         model_name=model_name,
1336                         new_name=new_index_name,
1337                         old_name=old_index_name,
1338                         old_fields=old_fields,
1339                     ),
1340                 )
1341 
1342     def create_altered_constraints(self):
1343         option_name = operations.AddConstraint.option_name
1344         for app_label, model_name in sorted(self.kept_model_keys):
1345             old_model_name = self.renamed_models.get(
1346                 (app_label, model_name), model_name
1347             )
1348             old_model_state = self.from_state.models[app_label, old_model_name]
1349             new_model_state = self.to_state.models[app_label, model_name]
1350 
1351             old_constraints = old_model_state.options[option_name]
1352             new_constraints = new_model_state.options[option_name]
1353             add_constraints = [c for c in new_constraints if c not in old_constraints]
1354             rem_constraints = [c for c in old_constraints if c not in new_constraints]
1355 
1356             self.altered_constraints.update(
1357                 {
1358                     (app_label, model_name): {
1359                         "added_constraints": add_constraints,
1360                         "removed_constraints": rem_constraints,
1361                     }
1362                 }
1363             )
1364 
1365     def generate_added_constraints(self):
1366         for (
1367             app_label,
1368             model_name,
1369         ), alt_constraints in self.altered_constraints.items():
1370             for constraint in alt_constraints["added_constraints"]:
1371                 self.add_operation(
1372                     app_label,
1373                     operations.AddConstraint(
1374                         model_name=model_name,
1375                         constraint=constraint,
1376                     ),
1377                 )
1378 
1379     def generate_removed_constraints(self):
1380         for (
1381             app_label,
1382             model_name,
1383         ), alt_constraints in self.altered_constraints.items():
1384             for constraint in alt_constraints["removed_constraints"]:
1385                 self.add_operation(
1386                     app_label,
1387                     operations.RemoveConstraint(
1388                         model_name=model_name,
1389                         name=constraint.name,
1390                     ),
1391                 )
1392 
1393     @staticmethod
1394     def _get_dependencies_for_foreign_key(app_label, model_name, field, project_state):
1395         remote_field_model = None
1396         if hasattr(field.remote_field, "model"):
1397             remote_field_model = field.remote_field.model
1398         else:
1399             relations = project_state.relations[app_label, model_name]
1400             for (remote_app_label, remote_model_name), fields in relations.items():
1401                 if any(
1402                     field == related_field.remote_field
1403                     for related_field in fields.values()
1404                 ):
1405                     remote_field_model = f"{remote_app_label}.{remote_model_name}"
1406                     break
1407         # Account for FKs to swappable models
1408         swappable_setting = getattr(field, "swappable_setting", None)
1409         if swappable_setting is not None:
1410             dep_app_label = "__setting__"
1411             dep_object_name = swappable_setting
1412         else:
1413             dep_app_label, dep_object_name = resolve_relation(
1414                 remote_field_model,
1415                 app_label,
1416                 model_name,
1417             )
1418         dependencies = [(dep_app_label, dep_object_name, None, True)]
1419         if getattr(field.remote_field, "through", None):
1420             through_app_label, through_object_name = resolve_relation(
1421                 remote_field_model,
1422                 app_label,
1423                 model_name,
1424             )
1425             dependencies.append((through_app_label, through_object_name, None, True))
1426         return dependencies
1427 
1428     def _get_altered_foo_together_operations(self, option_name):
1429         for app_label, model_name in sorted(self.kept_model_keys):
1430             old_model_name = self.renamed_models.get(
1431                 (app_label, model_name), model_name
1432             )
1433             old_model_state = self.from_state.models[app_label, old_model_name]
1434             new_model_state = self.to_state.models[app_label, model_name]
1435 
1436             # We run the old version through the field renames to account for those
1437             old_value = old_model_state.options.get(option_name)
1438             old_value = (
1439                 {
1440                     tuple(
1441                         self.renamed_fields.get((app_label, model_name, n), n)
1442                         for n in unique
1443                     )
1444                     for unique in old_value
1445                 }
1446                 if old_value
1447                 else set()
1448             )
1449 
1450             new_value = new_model_state.options.get(option_name)
1451             new_value = set(new_value) if new_value else set()
1452 
1453             if old_value != new_value:
1454                 dependencies = []
1455                 for foo_togethers in new_value:
1456                     for field_name in foo_togethers:
1457                         field = new_model_state.get_field(field_name)
1458                         if field.remote_field and field.remote_field.model:
1459                             dependencies.extend(
1460                                 self._get_dependencies_for_foreign_key(
1461                                     app_label,
1462                                     model_name,
1463                                     field,
1464                                     self.to_state,
1465                                 )
1466                             )
1467                 yield (
1468                     old_value,
1469                     new_value,
1470                     app_label,
1471                     model_name,
1472                     dependencies,
1473                 )
1474 
1475     def _generate_removed_altered_foo_together(self, operation):
1476         for (
1477             old_value,
1478             new_value,
1479             app_label,
1480             model_name,
1481             dependencies,
1482         ) in self._get_altered_foo_together_operations(operation.option_name):
1483             if operation == operations.AlterIndexTogether:
1484                 old_value = {
1485                     value
1486                     for value in old_value
1487                     if value
1488                     not in self.renamed_index_together_values[app_label, model_name]
1489                 }
1490             removal_value = new_value.intersection(old_value)
1491             if removal_value or old_value:
1492                 self.add_operation(
1493                     app_label,
1494                     operation(
1495                         name=model_name, **{operation.option_name: removal_value}
1496                     ),
1497                     dependencies=dependencies,
1498                 )
1499 
1500     def generate_removed_altered_unique_together(self):
1501         self._generate_removed_altered_foo_together(operations.AlterUniqueTogether)
1502 
1503     def generate_removed_altered_index_together(self):
1504         self._generate_removed_altered_foo_together(operations.AlterIndexTogether)
1505 
1506     def _generate_altered_foo_together(self, operation):
1507         for (
1508             old_value,
1509             new_value,
1510             app_label,
1511             model_name,
1512             dependencies,
1513         ) in self._get_altered_foo_together_operations(operation.option_name):
1514             removal_value = new_value.intersection(old_value)
1515             if new_value != removal_value:
1516                 self.add_operation(
1517                     app_label,
1518                     operation(name=model_name, **{operation.option_name: new_value}),
1519                     dependencies=dependencies,
1520                 )
1521 
1522     def generate_altered_unique_together(self):
1523         self._generate_altered_foo_together(operations.AlterUniqueTogether)
1524 
1525     def generate_altered_index_together(self):
1526         self._generate_altered_foo_together(operations.AlterIndexTogether)
1527 
1528     def generate_altered_db_table(self):
1529         models_to_check = self.kept_model_keys.union(
1530             self.kept_proxy_keys, self.kept_unmanaged_keys
1531         )
1532         for app_label, model_name in sorted(models_to_check):
1533             old_model_name = self.renamed_models.get(
1534                 (app_label, model_name), model_name
1535             )
1536             old_model_state = self.from_state.models[app_label, old_model_name]
1537             new_model_state = self.to_state.models[app_label, model_name]
1538             old_db_table_name = old_model_state.options.get("db_table")
1539             new_db_table_name = new_model_state.options.get("db_table")
1540             if old_db_table_name != new_db_table_name:
1541                 self.add_operation(
1542                     app_label,
1543                     operations.AlterModelTable(
1544                         name=model_name,
1545                         table=new_db_table_name,
1546                     ),
1547                 )
1548 
1549     def generate_altered_options(self):
1550         """
1551         Work out if any non-schema-affecting options have changed and make an
1552         operation to represent them in state changes (in case Python code in
1553         migrations needs them).
1554         """
1555         models_to_check = self.kept_model_keys.union(
1556             self.kept_proxy_keys,
1557             self.kept_unmanaged_keys,
1558             # unmanaged converted to managed
1559             self.old_unmanaged_keys & self.new_model_keys,
1560             # managed converted to unmanaged
1561             self.old_model_keys & self.new_unmanaged_keys,
1562         )
1563 
1564         for app_label, model_name in sorted(models_to_check):
1565             old_model_name = self.renamed_models.get(
1566                 (app_label, model_name), model_name
1567             )
1568             old_model_state = self.from_state.models[app_label, old_model_name]
1569             new_model_state = self.to_state.models[app_label, model_name]
1570             old_options = {
1571                 key: value
1572                 for key, value in old_model_state.options.items()
1573                 if key in AlterModelOptions.ALTER_OPTION_KEYS
1574             }
1575             new_options = {
1576                 key: value
1577                 for key, value in new_model_state.options.items()
1578                 if key in AlterModelOptions.ALTER_OPTION_KEYS
1579             }
1580             if old_options != new_options:
1581                 self.add_operation(
1582                     app_label,
1583                     operations.AlterModelOptions(
1584                         name=model_name,
1585                         options=new_options,
1586                     ),
1587                 )
1588 
1589     def generate_altered_order_with_respect_to(self):
1590         for app_label, model_name in sorted(self.kept_model_keys):
1591             old_model_name = self.renamed_models.get(
1592                 (app_label, model_name), model_name
1593             )
1594             old_model_state = self.from_state.models[app_label, old_model_name]
1595             new_model_state = self.to_state.models[app_label, model_name]
1596             if old_model_state.options.get(
1597                 "order_with_respect_to"
1598             ) != new_model_state.options.get("order_with_respect_to"):
1599                 # Make sure it comes second if we're adding
1600                 # (removal dependency is part of RemoveField)
1601                 dependencies = []
1602                 if new_model_state.options.get("order_with_respect_to"):
1603                     dependencies.append(
1604                         (
1605                             app_label,
1606                             model_name,
1607                             new_model_state.options["order_with_respect_to"],
1608                             True,
1609                         )
1610                     )
1611                 # Actually generate the operation
1612                 self.add_operation(
1613                     app_label,
1614                     operations.AlterOrderWithRespectTo(
1615                         name=model_name,
1616                         order_with_respect_to=new_model_state.options.get(
1617                             "order_with_respect_to"
1618                         ),
1619                     ),
1620                     dependencies=dependencies,
1621                 )
1622 
1623     def generate_altered_managers(self):
1624         for app_label, model_name in sorted(self.kept_model_keys):
1625             old_model_name = self.renamed_models.get(
1626                 (app_label, model_name), model_name
1627             )
1628             old_model_state = self.from_state.models[app_label, old_model_name]
1629             new_model_state = self.to_state.models[app_label, model_name]
1630             if old_model_state.managers != new_model_state.managers:
1631                 self.add_operation(
1632                     app_label,
1633                     operations.AlterModelManagers(
1634                         name=model_name,
1635                         managers=new_model_state.managers,
1636                     ),
1637                 )
1638 
1639     def arrange_for_graph(self, changes, graph, migration_name=None):
1640         """
1641         Take a result from changes() and a MigrationGraph, and fix the names
1642         and dependencies of the changes so they extend the graph from the leaf
1643         nodes for each app.
1644         """
1645         leaves = graph.leaf_nodes()
1646         name_map = {}
1647         for app_label, migrations in list(changes.items()):
1648             if not migrations:
1649                 continue
1650             # Find the app label's current leaf node
1651             app_leaf = None
1652             for leaf in leaves:
1653                 if leaf[0] == app_label:
1654                     app_leaf = leaf
1655                     break
1656             # Do they want an initial migration for this app?
1657             if app_leaf is None and not self.questioner.ask_initial(app_label):
1658                 # They don't.
1659                 for migration in migrations:
1660                     name_map[(app_label, migration.name)] = (app_label, "__first__")
1661                 del changes[app_label]
1662                 continue
1663             # Work out the next number in the sequence
1664             if app_leaf is None:
1665                 next_number = 1
1666             else:
1667                 next_number = (self.parse_number(app_leaf[1]) or 0) + 1
1668             # Name each migration
1669             for i, migration in enumerate(migrations):
1670                 if i == 0 and app_leaf:
1671                     migration.dependencies.append(app_leaf)
1672                 new_name_parts = ["%04i" % next_number]
1673                 if migration_name:
1674                     new_name_parts.append(migration_name)
1675                 elif i == 0 and not app_leaf:
1676                     new_name_parts.append("initial")
1677                 else:
1678                     new_name_parts.append(migration.suggest_name()[:100])
1679                 new_name = "_".join(new_name_parts)
1680                 name_map[(app_label, migration.name)] = (app_label, new_name)
1681                 next_number += 1
1682                 migration.name = new_name
1683         # Now fix dependencies
1684         for migrations in changes.values():
1685             for migration in migrations:
1686                 migration.dependencies = [
1687                     name_map.get(d, d) for d in migration.dependencies
1688                 ]
1689         return changes
1690 
1691     def _trim_to_apps(self, changes, app_labels):
1692         """
1693         Take changes from arrange_for_graph() and set of app labels, and return
1694         a modified set of changes which trims out as many migrations that are
1695         not in app_labels as possible. Note that some other migrations may
1696         still be present as they may be required dependencies.
1697         """
1698         # Gather other app dependencies in a first pass
1699         app_dependencies = {}
1700         for app_label, migrations in changes.items():
1701             for migration in migrations:
1702                 for dep_app_label, name in migration.dependencies:
1703                     app_dependencies.setdefault(app_label, set()).add(dep_app_label)
1704         required_apps = set(app_labels)
1705         # Keep resolving till there's no change
1706         old_required_apps = None
1707         while old_required_apps != required_apps:
1708             old_required_apps = set(required_apps)
1709             required_apps.update(
1710                 *[app_dependencies.get(app_label, ()) for app_label in required_apps]
1711             )
1712         # Remove all migrations that aren't needed
1713         for app_label in list(changes):
1714             if app_label not in required_apps:
1715                 del changes[app_label]
1716         return changes
1717 
1718     @classmethod
1719     def parse_number(cls, name):
1720         """
1721         Given a migration name, try to extract a number from the beginning of
1722         it. For a squashed migration such as '0001_squashed_0004', return the
1723         second number. If no number is found, return None.
1724         """
1725         if squashed_match := re.search(r".*_squashed_(\d+)", name):
1726             return int(squashed_match[1])
1727         match = re.match(r"^\d+", name)
1728         if match:
1729             return int(match[0])
1730         return None

</code><intended_behavior>Correctly identify changes from `index_together` to `Model.Meta.indexes` for migration generation, ensuring error-free recognition and operation reflection.</intended_behavior>, <file>django/db/backends/base/schema.py</file>
<class>None</class>
<method>None</method>
<code>
1 import logging
2 import operator
3 from datetime import datetime
4 
5 from django.conf import settings
6 from django.db.backends.ddl_references import (
7     Columns,
8     Expressions,
9     ForeignKeyName,
10     IndexName,
11     Statement,
12     Table,
13 )
14 from django.db.backends.utils import names_digest, split_identifier
15 from django.db.models import Deferrable, Index
16 from django.db.models.sql import Query
17 from django.db.transaction import TransactionManagementError, atomic
18 from django.utils import timezone
19 
20 logger = logging.getLogger("django.db.backends.schema")
21 
22 
23 def _is_relevant_relation(relation, altered_field):
24     """
25     When altering the given field, must constraints on its model from the given
26     relation be temporarily dropped?
27     """
28     field = relation.field
29     if field.many_to_many:
30         # M2M reverse field
31         return False
32     if altered_field.primary_key and field.to_fields == [None]:
33         # Foreign key constraint on the primary key, which is being altered.
34         return True
35     # Is the constraint targeting the field being altered?
36     return altered_field.name in field.to_fields
37 
38 
39 def _all_related_fields(model):
40     # Related fields must be returned in a deterministic order.
41     return sorted(
42         model._meta._get_fields(
43             forward=False,
44             reverse=True,
45             include_hidden=True,
46             include_parents=False,
47         ),
48         key=operator.attrgetter("name"),
49     )
50 
51 
52 def _related_non_m2m_objects(old_field, new_field):
53     # Filter out m2m objects from reverse relations.
54     # Return (old_relation, new_relation) tuples.
55     related_fields = zip(
56         (
57             obj
58             for obj in _all_related_fields(old_field.model)
59             if _is_relevant_relation(obj, old_field)
60         ),
61         (
62             obj
63             for obj in _all_related_fields(new_field.model)
64             if _is_relevant_relation(obj, new_field)
65         ),
66     )
67     for old_rel, new_rel in related_fields:
68         yield old_rel, new_rel
69         yield from _related_non_m2m_objects(
70             old_rel.remote_field,
71             new_rel.remote_field,
72         )
73 
74 
75 class BaseDatabaseSchemaEditor:
76     """
77     This class and its subclasses are responsible for emitting schema-changing
78     statements to the databases - model creation/removal/alteration, field
79     renaming, index fiddling, and so on.
80     """
81 
82     # Overrideable SQL templates
83     sql_create_table = "CREATE TABLE %(table)s (%(definition)s)"
84     sql_rename_table = "ALTER TABLE %(old_table)s RENAME TO %(new_table)s"
85     sql_retablespace_table = "ALTER TABLE %(table)s SET TABLESPACE %(new_tablespace)s"
86     sql_delete_table = "DROP TABLE %(table)s CASCADE"
87 
88     sql_create_column = "ALTER TABLE %(table)s ADD COLUMN %(column)s %(definition)s"
89     sql_alter_column = "ALTER TABLE %(table)s %(changes)s"
90     sql_alter_column_type = "ALTER COLUMN %(column)s TYPE %(type)s"
91     sql_alter_column_null = "ALTER COLUMN %(column)s DROP NOT NULL"
92     sql_alter_column_not_null = "ALTER COLUMN %(column)s SET NOT NULL"
93     sql_alter_column_default = "ALTER COLUMN %(column)s SET DEFAULT %(default)s"
94     sql_alter_column_no_default = "ALTER COLUMN %(column)s DROP DEFAULT"
95     sql_alter_column_no_default_null = sql_alter_column_no_default
96     sql_alter_column_collate = "ALTER COLUMN %(column)s TYPE %(type)s%(collation)s"
97     sql_delete_column = "ALTER TABLE %(table)s DROP COLUMN %(column)s CASCADE"
98     sql_rename_column = (
99         "ALTER TABLE %(table)s RENAME COLUMN %(old_column)s TO %(new_column)s"
100     )
101     sql_update_with_default = (
102         "UPDATE %(table)s SET %(column)s = %(default)s WHERE %(column)s IS NULL"
103     )
104 
105     sql_unique_constraint = "UNIQUE (%(columns)s)%(deferrable)s"
106     sql_check_constraint = "CHECK (%(check)s)"
107     sql_delete_constraint = "ALTER TABLE %(table)s DROP CONSTRAINT %(name)s"
108     sql_constraint = "CONSTRAINT %(name)s %(constraint)s"
109 
110     sql_create_check = "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s CHECK (%(check)s)"
111     sql_delete_check = sql_delete_constraint
112 
113     sql_create_unique = (
114         "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s "
115         "UNIQUE (%(columns)s)%(deferrable)s"
116     )
117     sql_delete_unique = sql_delete_constraint
118 
119     sql_create_fk = (
120         "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s FOREIGN KEY (%(column)s) "
121         "REFERENCES %(to_table)s (%(to_column)s)%(deferrable)s"
122     )
123     sql_create_inline_fk = None
124     sql_create_column_inline_fk = None
125     sql_delete_fk = sql_delete_constraint
126 
127     sql_create_index = (
128         "CREATE INDEX %(name)s ON %(table)s "
129         "(%(columns)s)%(include)s%(extra)s%(condition)s"
130     )
131     sql_create_unique_index = (
132         "CREATE UNIQUE INDEX %(name)s ON %(table)s "
133         "(%(columns)s)%(include)s%(condition)s"
134     )
135     sql_rename_index = "ALTER INDEX %(old_name)s RENAME TO %(new_name)s"
136     sql_delete_index = "DROP INDEX %(name)s"
137 
138     sql_create_pk = (
139         "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s PRIMARY KEY (%(columns)s)"
140     )
141     sql_delete_pk = sql_delete_constraint
142 
143     sql_delete_procedure = "DROP PROCEDURE %(procedure)s"
144 
145     def __init__(self, connection, collect_sql=False, atomic=True):
146         self.connection = connection
147         self.collect_sql = collect_sql
148         if self.collect_sql:
149             self.collected_sql = []
150         self.atomic_migration = self.connection.features.can_rollback_ddl and atomic
151 
152     # State-managing methods
153 
154     def __enter__(self):
155         self.deferred_sql = []
156         if self.atomic_migration:
157             self.atomic = atomic(self.connection.alias)
158             self.atomic.__enter__()
159         return self
160 
161     def __exit__(self, exc_type, exc_value, traceback):
162         if exc_type is None:
163             for sql in self.deferred_sql:
164                 self.execute(sql)
165         if self.atomic_migration:
166             self.atomic.__exit__(exc_type, exc_value, traceback)
167 
168     # Core utility functions
169 
170     def execute(self, sql, params=()):
171         """Execute the given SQL statement, with optional parameters."""
172         # Don't perform the transactional DDL check if SQL is being collected
173         # as it's not going to be executed anyway.
174         if (
175             not self.collect_sql
176             and self.connection.in_atomic_block
177             and not self.connection.features.can_rollback_ddl
178         ):
179             raise TransactionManagementError(
180                 "Executing DDL statements while in a transaction on databases "
181                 "that can't perform a rollback is prohibited."
182             )
183         # Account for non-string statement objects.
184         sql = str(sql)
185         # Log the command we're running, then run it
186         logger.debug(
187             "%s; (params %r)", sql, params, extra={"params": params, "sql": sql}
188         )
189         if self.collect_sql:
190             ending = "" if sql.rstrip().endswith(";") else ";"
191             if params is not None:
192                 self.collected_sql.append(
193                     (sql % tuple(map(self.quote_value, params))) + ending
194                 )
195             else:
196                 self.collected_sql.append(sql + ending)
197         else:
198             with self.connection.cursor() as cursor:
199                 cursor.execute(sql, params)
200 
201     def quote_name(self, name):
202         return self.connection.ops.quote_name(name)
203 
204     def table_sql(self, model):
205         """Take a model and return its table definition."""
206         # Add any unique_togethers (always deferred, as some fields might be
207         # created afterward, like geometry fields with some backends).
208         for field_names in model._meta.unique_together:
209             fields = [model._meta.get_field(field) for field in field_names]
210             self.deferred_sql.append(self._create_unique_sql(model, fields))
211         # Create column SQL, add FK deferreds if needed.
212         column_sqls = []
213         params = []
214         for field in model._meta.local_fields:
215             # SQL.
216             definition, extra_params = self.column_sql(model, field)
217             if definition is None:
218                 continue
219             # Check constraints can go on the column SQL here.
220             db_params = field.db_parameters(connection=self.connection)
221             if db_params["check"]:
222                 definition += " " + self.sql_check_constraint % db_params
223             # Autoincrement SQL (for backends with inline variant).
224             col_type_suffix = field.db_type_suffix(connection=self.connection)
225             if col_type_suffix:
226                 definition += " %s" % col_type_suffix
227             params.extend(extra_params)
228             # FK.
229             if field.remote_field and field.db_constraint:
230                 to_table = field.remote_field.model._meta.db_table
231                 to_column = field.remote_field.model._meta.get_field(
232                     field.remote_field.field_name
233                 ).column
234                 if self.sql_create_inline_fk:
235                     definition += " " + self.sql_create_inline_fk % {
236                         "to_table": self.quote_name(to_table),
237                         "to_column": self.quote_name(to_column),
238                     }
239                 elif self.connection.features.supports_foreign_keys:
240                     self.deferred_sql.append(
241                         self._create_fk_sql(
242                             model, field, "_fk_%(to_table)s_%(to_column)s"
243                         )
244                     )
245             # Add the SQL to our big list.
246             column_sqls.append(
247                 "%s %s"
248                 % (
249                     self.quote_name(field.column),
250                     definition,
251                 )
252             )
253             # Autoincrement SQL (for backends with post table definition
254             # variant).
255             if field.get_internal_type() in (
256                 "AutoField",
257                 "BigAutoField",
258                 "SmallAutoField",
259             ):
260                 autoinc_sql = self.connection.ops.autoinc_sql(
261                     model._meta.db_table, field.column
262                 )
263                 if autoinc_sql:
264                     self.deferred_sql.extend(autoinc_sql)
265         constraints = [
266             constraint.constraint_sql(model, self)
267             for constraint in model._meta.constraints
268         ]
269         sql = self.sql_create_table % {
270             "table": self.quote_name(model._meta.db_table),
271             "definition": ", ".join(
272                 constraint for constraint in (*column_sqls, *constraints) if constraint
273             ),
274         }
275         if model._meta.db_tablespace:
276             tablespace_sql = self.connection.ops.tablespace_sql(
277                 model._meta.db_tablespace
278             )
279             if tablespace_sql:
280                 sql += " " + tablespace_sql
281         return sql, params
282 
283     # Field <-> database mapping functions
284 
285     def _iter_column_sql(
286         self, column_db_type, params, model, field, field_db_params, include_default
287     ):
288         yield column_db_type
289         if collation := field_db_params.get("collation"):
290             yield self._collate_sql(collation)
291         # Work out nullability.
292         null = field.null
293         # Include a default value, if requested.
294         include_default = (
295             include_default
296             and not self.skip_default(field)
297             and
298             # Don't include a default value if it's a nullable field and the
299             # default cannot be dropped in the ALTER COLUMN statement (e.g.
300             # MySQL longtext and longblob).
301             not (null and self.skip_default_on_alter(field))
302         )
303         if include_default:
304             default_value = self.effective_default(field)
305             if default_value is not None:
306                 column_default = "DEFAULT " + self._column_default_sql(field)
307                 if self.connection.features.requires_literal_defaults:
308                     # Some databases can't take defaults as a parameter (Oracle).
309                     # If this is the case, the individual schema backend should
310                     # implement prepare_default().
311                     yield column_default % self.prepare_default(default_value)
312                 else:
313                     yield column_default
314                     params.append(default_value)
315         # Oracle treats the empty string ('') as null, so coerce the null
316         # option whenever '' is a possible value.
317         if (
318             field.empty_strings_allowed
319             and not field.primary_key
320             and self.connection.features.interprets_empty_strings_as_nulls
321         ):
322             null = True
323         if not null:
324             yield "NOT NULL"
325         elif not self.connection.features.implied_column_null:
326             yield "NULL"
327         if field.primary_key:
328             yield "PRIMARY KEY"
329         elif field.unique:
330             yield "UNIQUE"
331         # Optionally add the tablespace if it's an implicitly indexed column.
332         tablespace = field.db_tablespace or model._meta.db_tablespace
333         if (
334             tablespace
335             and self.connection.features.supports_tablespaces
336             and field.unique
337         ):
338             yield self.connection.ops.tablespace_sql(tablespace, inline=True)
339 
340     def column_sql(self, model, field, include_default=False):
341         """
342         Return the column definition for a field. The field must already have
343         had set_attributes_from_name() called.
344         """
345         # Get the column's type and use that as the basis of the SQL.
346         field_db_params = field.db_parameters(connection=self.connection)
347         column_db_type = field_db_params["type"]
348         # Check for fields that aren't actually columns (e.g. M2M).
349         if column_db_type is None:
350             return None, None
351         params = []
352         return (
353             " ".join(
354                 # This appends to the params being returned.
355                 self._iter_column_sql(
356                     column_db_type,
357                     params,
358                     model,
359                     field,
360                     field_db_params,
361                     include_default,
362                 )
363             ),
364             params,
365         )
366 
367     def skip_default(self, field):
368         """
369         Some backends don't accept default values for certain columns types
370         (i.e. MySQL longtext and longblob).
371         """
372         return False
373 
374     def skip_default_on_alter(self, field):
375         """
376         Some backends don't accept default values for certain columns types
377         (i.e. MySQL longtext and longblob) in the ALTER COLUMN statement.
378         """
379         return False
380 
381     def prepare_default(self, value):
382         """
383         Only used for backends which have requires_literal_defaults feature
384         """
385         raise NotImplementedError(
386             "subclasses of BaseDatabaseSchemaEditor for backends which have "
387             "requires_literal_defaults must provide a prepare_default() method"
388         )
389 
390     def _column_default_sql(self, field):
391         """
392         Return the SQL to use in a DEFAULT clause. The resulting string should
393         contain a '%s' placeholder for a default value.
394         """
395         return "%s"
396 
397     @staticmethod
398     def _effective_default(field):
399         # This method allows testing its logic without a connection.
400         if field.has_default():
401             default = field.get_default()
402         elif not field.null and field.blank and field.empty_strings_allowed:
403             if field.get_internal_type() == "BinaryField":
404                 default = b""
405             else:
406                 default = ""
407         elif getattr(field, "auto_now", False) or getattr(field, "auto_now_add", False):
408             internal_type = field.get_internal_type()
409             if internal_type == "DateTimeField":
410                 default = timezone.now()
411             else:
412                 default = datetime.now()
413                 if internal_type == "DateField":
414                     default = default.date()
415                 elif internal_type == "TimeField":
416                     default = default.time()
417         else:
418             default = None
419         return default
420 
421     def effective_default(self, field):
422         """Return a field's effective database default value."""
423         return field.get_db_prep_save(self._effective_default(field), self.connection)
424 
425     def quote_value(self, value):
426         """
427         Return a quoted version of the value so it's safe to use in an SQL
428         string. This is not safe against injection from user code; it is
429         intended only for use in making SQL scripts or preparing default values
430         for particularly tricky backends (defaults are not user-defined, though,
431         so this is safe).
432         """
433         raise NotImplementedError()
434 
435     # Actions
436 
437     def create_model(self, model):
438         """
439         Create a table and any accompanying indexes or unique constraints for
440         the given `model`.
441         """
442         sql, params = self.table_sql(model)
443         # Prevent using [] as params, in the case a literal '%' is used in the
444         # definition.
445         self.execute(sql, params or None)
446 
447         # Add any field index and index_together's (deferred as SQLite
448         # _remake_table needs it).
449         self.deferred_sql.extend(self._model_indexes_sql(model))
450 
451         # Make M2M tables
452         for field in model._meta.local_many_to_many:
453             if field.remote_field.through._meta.auto_created:
454                 self.create_model(field.remote_field.through)
455 
456     def delete_model(self, model):
457         """Delete a model from the database."""
458         # Handle auto-created intermediary models
459         for field in model._meta.local_many_to_many:
460             if field.remote_field.through._meta.auto_created:
461                 self.delete_model(field.remote_field.through)
462 
463         # Delete the table
464         self.execute(
465             self.sql_delete_table
466             % {
467                 "table": self.quote_name(model._meta.db_table),
468             }
469         )
470         # Remove all deferred statements referencing the deleted table.
471         for sql in list(self.deferred_sql):
472             if isinstance(sql, Statement) and sql.references_table(
473                 model._meta.db_table
474             ):
475                 self.deferred_sql.remove(sql)
476 
477     def add_index(self, model, index):
478         """Add an index on a model."""
479         if (
480             index.contains_expressions
481             and not self.connection.features.supports_expression_indexes
482         ):
483             return None
484         # Index.create_sql returns interpolated SQL which makes params=None a
485         # necessity to avoid escaping attempts on execution.
486         self.execute(index.create_sql(model, self), params=None)
487 
488     def remove_index(self, model, index):
489         """Remove an index from a model."""
490         if (
491             index.contains_expressions
492             and not self.connection.features.supports_expression_indexes
493         ):
494             return None
495         self.execute(index.remove_sql(model, self))
496 
497     def rename_index(self, model, old_index, new_index):
498         if self.connection.features.can_rename_index:
499             self.execute(
500                 self._rename_index_sql(model, old_index.name, new_index.name),
501                 params=None,
502             )
503         else:
504             self.remove_index(model, old_index)
505             self.add_index(model, new_index)
506 
507     def add_constraint(self, model, constraint):
508         """Add a constraint to a model."""
509         sql = constraint.create_sql(model, self)
510         if sql:
511             # Constraint.create_sql returns interpolated SQL which makes
512             # params=None a necessity to avoid escaping attempts on execution.
513             self.execute(sql, params=None)
514 
515     def remove_constraint(self, model, constraint):
516         """Remove a constraint from a model."""
517         sql = constraint.remove_sql(model, self)
518         if sql:
519             self.execute(sql)
520 
521     def alter_unique_together(self, model, old_unique_together, new_unique_together):
522         """
523         Deal with a model changing its unique_together. The input
524         unique_togethers must be doubly-nested, not the single-nested
525         ["foo", "bar"] format.
526         """
527         olds = {tuple(fields) for fields in old_unique_together}
528         news = {tuple(fields) for fields in new_unique_together}
529         # Deleted uniques
530         for fields in olds.difference(news):
531             self._delete_composed_index(
532                 model,
533                 fields,
534                 {"unique": True, "primary_key": False},
535                 self.sql_delete_unique,
536             )
537         # Created uniques
538         for field_names in news.difference(olds):
539             fields = [model._meta.get_field(field) for field in field_names]
540             self.execute(self._create_unique_sql(model, fields))
541 
542     def alter_index_together(self, model, old_index_together, new_index_together):
543         """
544         Deal with a model changing its index_together. The input
545         index_togethers must be doubly-nested, not the single-nested
546         ["foo", "bar"] format.
547         """
548         olds = {tuple(fields) for fields in old_index_together}
549         news = {tuple(fields) for fields in new_index_together}
550         # Deleted indexes
551         for fields in olds.difference(news):
552             self._delete_composed_index(
553                 model,
554                 fields,
555                 {"index": True, "unique": False},
556                 self.sql_delete_index,
557             )
558         # Created indexes
559         for field_names in news.difference(olds):
560             fields = [model._meta.get_field(field) for field in field_names]
561             self.execute(self._create_index_sql(model, fields=fields, suffix="_idx"))
562 
563     def _delete_composed_index(self, model, fields, constraint_kwargs, sql):
564         meta_constraint_names = {
565             constraint.name for constraint in model._meta.constraints
566         }
567         meta_index_names = {constraint.name for constraint in model._meta.indexes}
568         columns = [model._meta.get_field(field).column for field in fields]
569         constraint_names = self._constraint_names(
570             model,
571             columns,
572             exclude=meta_constraint_names | meta_index_names,
573             **constraint_kwargs,
574         )
575         if (
576             constraint_kwargs.get("unique") is True
577             and constraint_names
578             and self.connection.features.allows_multiple_constraints_on_same_fields
579         ):
580             # Constraint matching the unique_together name.
581             default_name = str(
582                 self._unique_constraint_name(model._meta.db_table, columns, quote=False)
583             )
584             if default_name in constraint_names:
585                 constraint_names = [default_name]
586         if len(constraint_names) != 1:
587             raise ValueError(
588                 "Found wrong number (%s) of constraints for %s(%s)"
589                 % (
590                     len(constraint_names),
591                     model._meta.db_table,
592                     ", ".join(columns),
593                 )
594             )
595         self.execute(self._delete_constraint_sql(sql, model, constraint_names[0]))
596 
597     def alter_db_table(self, model, old_db_table, new_db_table):
598         """Rename the table a model points to."""
599         if old_db_table == new_db_table or (
600             self.connection.features.ignores_table_name_case
601             and old_db_table.lower() == new_db_table.lower()
602         ):
603             return
604         self.execute(
605             self.sql_rename_table
606             % {
607                 "old_table": self.quote_name(old_db_table),
608                 "new_table": self.quote_name(new_db_table),
609             }
610         )
611         # Rename all references to the old table name.
612         for sql in self.deferred_sql:
613             if isinstance(sql, Statement):
614                 sql.rename_table_references(old_db_table, new_db_table)
615 
616     def alter_db_tablespace(self, model, old_db_tablespace, new_db_tablespace):
617         """Move a model's table between tablespaces."""
618         self.execute(
619             self.sql_retablespace_table
620             % {
621                 "table": self.quote_name(model._meta.db_table),
622                 "old_tablespace": self.quote_name(old_db_tablespace),
623                 "new_tablespace": self.quote_name(new_db_tablespace),
624             }
625         )
626 
627     def add_field(self, model, field):
628         """
629         Create a field on a model. Usually involves adding a column, but may
630         involve adding a table instead (for M2M fields).
631         """
632         # Special-case implicit M2M tables
633         if field.many_to_many and field.remote_field.through._meta.auto_created:
634             return self.create_model(field.remote_field.through)
635         # Get the column's definition
636         definition, params = self.column_sql(model, field, include_default=True)
637         # It might not actually have a column behind it
638         if definition is None:
639             return
640         # Check constraints can go on the column SQL here
641         db_params = field.db_parameters(connection=self.connection)
642         if db_params["check"]:
643             definition += " " + self.sql_check_constraint % db_params
644         if (
645             field.remote_field
646             and self.connection.features.supports_foreign_keys
647             and field.db_constraint
648         ):
649             constraint_suffix = "_fk_%(to_table)s_%(to_column)s"
650             # Add FK constraint inline, if supported.
651             if self.sql_create_column_inline_fk:
652                 to_table = field.remote_field.model._meta.db_table
653                 to_column = field.remote_field.model._meta.get_field(
654                     field.remote_field.field_name
655                 ).column
656                 namespace, _ = split_identifier(model._meta.db_table)
657                 definition += " " + self.sql_create_column_inline_fk % {
658                     "name": self._fk_constraint_name(model, field, constraint_suffix),
659                     "namespace": "%s." % self.quote_name(namespace)
660                     if namespace
661                     else "",
662                     "column": self.quote_name(field.column),
663                     "to_table": self.quote_name(to_table),
664                     "to_column": self.quote_name(to_column),
665                     "deferrable": self.connection.ops.deferrable_sql(),
666                 }
667             # Otherwise, add FK constraints later.
668             else:
669                 self.deferred_sql.append(
670                     self._create_fk_sql(model, field, constraint_suffix)
671                 )
672         # Build the SQL and run it
673         sql = self.sql_create_column % {
674             "table": self.quote_name(model._meta.db_table),
675             "column": self.quote_name(field.column),
676             "definition": definition,
677         }
678         self.execute(sql, params)
679         # Drop the default if we need to
680         # (Django usually does not use in-database defaults)
681         if (
682             not self.skip_default_on_alter(field)
683             and self.effective_default(field) is not None
684         ):
685             changes_sql, params = self._alter_column_default_sql(
686                 model, None, field, drop=True
687             )
688             sql = self.sql_alter_column % {
689                 "table": self.quote_name(model._meta.db_table),
690                 "changes": changes_sql,
691             }
692             self.execute(sql, params)
693         # Add an index, if required
694         self.deferred_sql.extend(self._field_indexes_sql(model, field))
695         # Reset connection if required
696         if self.connection.features.connection_persists_old_columns:
697             self.connection.close()
698 
699     def remove_field(self, model, field):
700         """
701         Remove a field from a model. Usually involves deleting a column,
702         but for M2Ms may involve deleting a table.
703         """
704         # Special-case implicit M2M tables
705         if field.many_to_many and field.remote_field.through._meta.auto_created:
706             return self.delete_model(field.remote_field.through)
707         # It might not actually have a column behind it
708         if field.db_parameters(connection=self.connection)["type"] is None:
709             return
710         # Drop any FK constraints, MySQL requires explicit deletion
711         if field.remote_field:
712             fk_names = self._constraint_names(model, [field.column], foreign_key=True)
713             for fk_name in fk_names:
714                 self.execute(self._delete_fk_sql(model, fk_name))
715         # Delete the column
716         sql = self.sql_delete_column % {
717             "table": self.quote_name(model._meta.db_table),
718             "column": self.quote_name(field.column),
719         }
720         self.execute(sql)
721         # Reset connection if required
722         if self.connection.features.connection_persists_old_columns:
723             self.connection.close()
724         # Remove all deferred statements referencing the deleted column.
725         for sql in list(self.deferred_sql):
726             if isinstance(sql, Statement) and sql.references_column(
727                 model._meta.db_table, field.column
728             ):
729                 self.deferred_sql.remove(sql)
730 
731     def alter_field(self, model, old_field, new_field, strict=False):
732         """
733         Allow a field's type, uniqueness, nullability, default, column,
734         constraints, etc. to be modified.
735         `old_field` is required to compute the necessary changes.
736         If `strict` is True, raise errors if the old column does not match
737         `old_field` precisely.
738         """
739         if not self._field_should_be_altered(old_field, new_field):
740             return
741         # Ensure this field is even column-based
742         old_db_params = old_field.db_parameters(connection=self.connection)
743         old_type = old_db_params["type"]
744         new_db_params = new_field.db_parameters(connection=self.connection)
745         new_type = new_db_params["type"]
746         if (old_type is None and old_field.remote_field is None) or (
747             new_type is None and new_field.remote_field is None
748         ):
749             raise ValueError(
750                 "Cannot alter field %s into %s - they do not properly define "
751                 "db_type (are you using a badly-written custom field?)"
752                 % (old_field, new_field),
753             )
754         elif (
755             old_type is None
756             and new_type is None
757             and (
758                 old_field.remote_field.through
759                 and new_field.remote_field.through
760                 and old_field.remote_field.through._meta.auto_created
761                 and new_field.remote_field.through._meta.auto_created
762             )
763         ):
764             return self._alter_many_to_many(model, old_field, new_field, strict)
765         elif (
766             old_type is None
767             and new_type is None
768             and (
769                 old_field.remote_field.through
770                 and new_field.remote_field.through
771                 and not old_field.remote_field.through._meta.auto_created
772                 and not new_field.remote_field.through._meta.auto_created
773             )
774         ):
775             # Both sides have through models; this is a no-op.
776             return
777         elif old_type is None or new_type is None:
778             raise ValueError(
779                 "Cannot alter field %s into %s - they are not compatible types "
780                 "(you cannot alter to or from M2M fields, or add or remove "
781                 "through= on M2M fields)" % (old_field, new_field)
782             )
783 
784         self._alter_field(
785             model,
786             old_field,
787             new_field,
788             old_type,
789             new_type,
790             old_db_params,
791             new_db_params,
792             strict,
793         )
794 
795     def _alter_field(
796         self,
797         model,
798         old_field,
799         new_field,
800         old_type,
801         new_type,
802         old_db_params,
803         new_db_params,
804         strict=False,
805     ):
806         """Perform a "physical" (non-ManyToMany) field update."""
807         # Drop any FK constraints, we'll remake them later
808         fks_dropped = set()
809         if (
810             self.connection.features.supports_foreign_keys
811             and old_field.remote_field
812             and old_field.db_constraint
813         ):
814             fk_names = self._constraint_names(
815                 model, [old_field.column], foreign_key=True
816             )
817             if strict and len(fk_names) != 1:
818                 raise ValueError(
819                     "Found wrong number (%s) of foreign key constraints for %s.%s"
820                     % (
821                         len(fk_names),
822                         model._meta.db_table,
823                         old_field.column,
824                     )
825                 )
826             for fk_name in fk_names:
827                 fks_dropped.add((old_field.column,))
828                 self.execute(self._delete_fk_sql(model, fk_name))
829         # Has unique been removed?
830         if old_field.unique and (
831             not new_field.unique or self._field_became_primary_key(old_field, new_field)
832         ):
833             # Find the unique constraint for this field
834             meta_constraint_names = {
835                 constraint.name for constraint in model._meta.constraints
836             }
837             constraint_names = self._constraint_names(
838                 model,
839                 [old_field.column],
840                 unique=True,
841                 primary_key=False,
842                 exclude=meta_constraint_names,
843             )
844             if strict and len(constraint_names) != 1:
845                 raise ValueError(
846                     "Found wrong number (%s) of unique constraints for %s.%s"
847                     % (
848                         len(constraint_names),
849                         model._meta.db_table,
850                         old_field.column,
851                     )
852                 )
853             for constraint_name in constraint_names:
854                 self.execute(self._delete_unique_sql(model, constraint_name))
855         # Drop incoming FK constraints if the field is a primary key or unique,
856         # which might be a to_field target, and things are going to change.
857         old_collation = old_db_params.get("collation")
858         new_collation = new_db_params.get("collation")
859         drop_foreign_keys = (
860             self.connection.features.supports_foreign_keys
861             and (
862                 (old_field.primary_key and new_field.primary_key)
863                 or (old_field.unique and new_field.unique)
864             )
865             and ((old_type != new_type) or (old_collation != new_collation))
866         )
867         if drop_foreign_keys:
868             # '_meta.related_field' also contains M2M reverse fields, these
869             # will be filtered out
870             for _old_rel, new_rel in _related_non_m2m_objects(old_field, new_field):
871                 rel_fk_names = self._constraint_names(
872                     new_rel.related_model, [new_rel.field.column], foreign_key=True
873                 )
874                 for fk_name in rel_fk_names:
875                     self.execute(self._delete_fk_sql(new_rel.related_model, fk_name))
876         # Removed an index? (no strict check, as multiple indexes are possible)
877         # Remove indexes if db_index switched to False or a unique constraint
878         # will now be used in lieu of an index. The following lines from the
879         # truth table show all True cases; the rest are False:
880         #
881         # old_field.db_index | old_field.unique | new_field.db_index | new_field.unique
882         # ------------------------------------------------------------------------------
883         # True               | False            | False              | False
884         # True               | False            | False              | True
885         # True               | False            | True               | True
886         if (
887             old_field.db_index
888             and not old_field.unique
889             and (not new_field.db_index or new_field.unique)
890         ):
891             # Find the index for this field
892             meta_index_names = {index.name for index in model._meta.indexes}
893             # Retrieve only BTREE indexes since this is what's created with
894             # db_index=True.
895             index_names = self._constraint_names(
896                 model,
897                 [old_field.column],
898                 index=True,
899                 type_=Index.suffix,
900                 exclude=meta_index_names,
901             )
902             for index_name in index_names:
903                 # The only way to check if an index was created with
904                 # db_index=True or with Index(['field'], name='foo')
905                 # is to look at its name (refs #28053).
906                 self.execute(self._delete_index_sql(model, index_name))
907         # Change check constraints?
908         if old_db_params["check"] != new_db_params["check"] and old_db_params["check"]:
909             meta_constraint_names = {
910                 constraint.name for constraint in model._meta.constraints
911             }
912             constraint_names = self._constraint_names(
913                 model,
914                 [old_field.column],
915                 check=True,
916                 exclude=meta_constraint_names,
917             )
918             if strict and len(constraint_names) != 1:
919                 raise ValueError(
920                     "Found wrong number (%s) of check constraints for %s.%s"
921                     % (
922                         len(constraint_names),
923                         model._meta.db_table,
924                         old_field.column,
925                     )
926                 )
927             for constraint_name in constraint_names:
928                 self.execute(self._delete_check_sql(model, constraint_name))
929         # Have they renamed the column?
930         if old_field.column != new_field.column:
931             self.execute(
932                 self._rename_field_sql(
933                     model._meta.db_table, old_field, new_field, new_type
934                 )
935             )
936             # Rename all references to the renamed column.
937             for sql in self.deferred_sql:
938                 if isinstance(sql, Statement):
939                     sql.rename_column_references(
940                         model._meta.db_table, old_field.column, new_field.column
941                     )
942         # Next, start accumulating actions to do
943         actions = []
944         null_actions = []
945         post_actions = []
946         # Type suffix change? (e.g. auto increment).
947         old_type_suffix = old_field.db_type_suffix(connection=self.connection)
948         new_type_suffix = new_field.db_type_suffix(connection=self.connection)
949         # Collation change?
950         if old_collation != new_collation:
951             # Collation change handles also a type change.
952             fragment = self._alter_column_collation_sql(
953                 model, new_field, new_type, new_collation
954             )
955             actions.append(fragment)
956         # Type change?
957         elif (old_type, old_type_suffix) != (new_type, new_type_suffix):
958             fragment, other_actions = self._alter_column_type_sql(
959                 model, old_field, new_field, new_type
960             )
961             actions.append(fragment)
962             post_actions.extend(other_actions)
963         # When changing a column NULL constraint to NOT NULL with a given
964         # default value, we need to perform 4 steps:
965         #  1. Add a default for new incoming writes
966         #  2. Update existing NULL rows with new default
967         #  3. Replace NULL constraint with NOT NULL
968         #  4. Drop the default again.
969         # Default change?
970         needs_database_default = False
971         if old_field.null and not new_field.null:
972             old_default = self.effective_default(old_field)
973             new_default = self.effective_default(new_field)
974             if (
975                 not self.skip_default_on_alter(new_field)
976                 and old_default != new_default
977                 and new_default is not None
978             ):
979                 needs_database_default = True
980                 actions.append(
981                     self._alter_column_default_sql(model, old_field, new_field)
982                 )
983         # Nullability change?
984         if old_field.null != new_field.null:
985             fragment = self._alter_column_null_sql(model, old_field, new_field)
986             if fragment:
987                 null_actions.append(fragment)
988         # Only if we have a default and there is a change from NULL to NOT NULL
989         four_way_default_alteration = new_field.has_default() and (
990             old_field.null and not new_field.null
991         )
992         if actions or null_actions:
993             if not four_way_default_alteration:
994                 # If we don't have to do a 4-way default alteration we can
995                 # directly run a (NOT) NULL alteration
996                 actions = actions + null_actions
997             # Combine actions together if we can (e.g. postgres)
998             if self.connection.features.supports_combined_alters and actions:
999                 sql, params = tuple(zip(*actions))
1000                 actions = [(", ".join(sql), sum(params, []))]
1001             # Apply those actions
1002             for sql, params in actions:
1003                 self.execute(
1004                     self.sql_alter_column
1005                     % {
1006                         "table": self.quote_name(model._meta.db_table),
1007                         "changes": sql,
1008                     },
1009                     params,
1010                 )
1011             if four_way_default_alteration:
1012                 # Update existing rows with default value
1013                 self.execute(
1014                     self.sql_update_with_default
1015                     % {
1016                         "table": self.quote_name(model._meta.db_table),
1017                         "column": self.quote_name(new_field.column),
1018                         "default": "%s",
1019                     },
1020                     [new_default],
1021                 )
1022                 # Since we didn't run a NOT NULL change before we need to do it
1023                 # now
1024                 for sql, params in null_actions:
1025                     self.execute(
1026                         self.sql_alter_column
1027                         % {
1028                             "table": self.quote_name(model._meta.db_table),
1029                             "changes": sql,
1030                         },
1031                         params,
1032                     )
1033         if post_actions:
1034             for sql, params in post_actions:
1035                 self.execute(sql, params)
1036         # If primary_key changed to False, delete the primary key constraint.
1037         if old_field.primary_key and not new_field.primary_key:
1038             self._delete_primary_key(model, strict)
1039         # Added a unique?
1040         if self._unique_should_be_added(old_field, new_field):
1041             self.execute(self._create_unique_sql(model, [new_field]))
1042         # Added an index? Add an index if db_index switched to True or a unique
1043         # constraint will no longer be used in lieu of an index. The following
1044         # lines from the truth table show all True cases; the rest are False:
1045         #
1046         # old_field.db_index | old_field.unique | new_field.db_index | new_field.unique
1047         # ------------------------------------------------------------------------------
1048         # False              | False            | True               | False
1049         # False              | True             | True               | False
1050         # True               | True             | True               | False
1051         if (
1052             (not old_field.db_index or old_field.unique)
1053             and new_field.db_index
1054             and not new_field.unique
1055         ):
1056             self.execute(self._create_index_sql(model, fields=[new_field]))
1057         # Type alteration on primary key? Then we need to alter the column
1058         # referring to us.
1059         rels_to_update = []
1060         if drop_foreign_keys:
1061             rels_to_update.extend(_related_non_m2m_objects(old_field, new_field))
1062         # Changed to become primary key?
1063         if self._field_became_primary_key(old_field, new_field):
1064             # Make the new one
1065             self.execute(self._create_primary_key_sql(model, new_field))
1066             # Update all referencing columns
1067             rels_to_update.extend(_related_non_m2m_objects(old_field, new_field))
1068         # Handle our type alters on the other end of rels from the PK stuff above
1069         for old_rel, new_rel in rels_to_update:
1070             rel_db_params = new_rel.field.db_parameters(connection=self.connection)
1071             rel_type = rel_db_params["type"]
1072             rel_collation = rel_db_params.get("collation")
1073             old_rel_db_params = old_rel.field.db_parameters(connection=self.connection)
1074             old_rel_collation = old_rel_db_params.get("collation")
1075             if old_rel_collation != rel_collation:
1076                 # Collation change handles also a type change.
1077                 fragment = self._alter_column_collation_sql(
1078                     new_rel.related_model,
1079                     new_rel.field,
1080                     rel_type,
1081                     rel_collation,
1082                 )
1083                 other_actions = []
1084             else:
1085                 fragment, other_actions = self._alter_column_type_sql(
1086                     new_rel.related_model, old_rel.field, new_rel.field, rel_type
1087                 )
1088             self.execute(
1089                 self.sql_alter_column
1090                 % {
1091                     "table": self.quote_name(new_rel.related_model._meta.db_table),
1092                     "changes": fragment[0],
1093                 },
1094                 fragment[1],
1095             )
1096             for sql, params in other_actions:
1097                 self.execute(sql, params)
1098         # Does it have a foreign key?
1099         if (
1100             self.connection.features.supports_foreign_keys
1101             and new_field.remote_field
1102             and (
1103                 fks_dropped or not old_field.remote_field or not old_field.db_constraint
1104             )
1105             and new_field.db_constraint
1106         ):
1107             self.execute(
1108                 self._create_fk_sql(model, new_field, "_fk_%(to_table)s_%(to_column)s")
1109             )
1110         # Rebuild FKs that pointed to us if we previously had to drop them
1111         if drop_foreign_keys:
1112             for _, rel in rels_to_update:
1113                 if rel.field.db_constraint:
1114                     self.execute(
1115                         self._create_fk_sql(rel.related_model, rel.field, "_fk")
1116                     )
1117         # Does it have check constraints we need to add?
1118         if old_db_params["check"] != new_db_params["check"] and new_db_params["check"]:
1119             constraint_name = self._create_index_name(
1120                 model._meta.db_table, [new_field.column], suffix="_check"
1121             )
1122             self.execute(
1123                 self._create_check_sql(model, constraint_name, new_db_params["check"])
1124             )
1125         # Drop the default if we need to
1126         # (Django usually does not use in-database defaults)
1127         if needs_database_default:
1128             changes_sql, params = self._alter_column_default_sql(
1129                 model, old_field, new_field, drop=True
1130             )
1131             sql = self.sql_alter_column % {
1132                 "table": self.quote_name(model._meta.db_table),
1133                 "changes": changes_sql,
1134             }
1135             self.execute(sql, params)
1136         # Reset connection if required
1137         if self.connection.features.connection_persists_old_columns:
1138             self.connection.close()
1139 
1140     def _alter_column_null_sql(self, model, old_field, new_field):
1141         """
1142         Hook to specialize column null alteration.
1143 
1144         Return a (sql, params) fragment to set a column to null or non-null
1145         as required by new_field, or None if no changes are required.
1146         """
1147         if (
1148             self.connection.features.interprets_empty_strings_as_nulls
1149             and new_field.empty_strings_allowed
1150         ):
1151             # The field is nullable in the database anyway, leave it alone.
1152             return
1153         else:
1154             new_db_params = new_field.db_parameters(connection=self.connection)
1155             sql = (
1156                 self.sql_alter_column_null
1157                 if new_field.null
1158                 else self.sql_alter_column_not_null
1159             )
1160             return (
1161                 sql
1162                 % {
1163                     "column": self.quote_name(new_field.column),
1164                     "type": new_db_params["type"],
1165                 },
1166                 [],
1167             )
1168 
1169     def _alter_column_default_sql(self, model, old_field, new_field, drop=False):
1170         """
1171         Hook to specialize column default alteration.
1172 
1173         Return a (sql, params) fragment to add or drop (depending on the drop
1174         argument) a default to new_field's column.
1175         """
1176         new_default = self.effective_default(new_field)
1177         default = self._column_default_sql(new_field)
1178         params = [new_default]
1179 
1180         if drop:
1181             params = []
1182         elif self.connection.features.requires_literal_defaults:
1183             # Some databases (Oracle) can't take defaults as a parameter
1184             # If this is the case, the SchemaEditor for that database should
1185             # implement prepare_default().
1186             default = self.prepare_default(new_default)
1187             params = []
1188 
1189         new_db_params = new_field.db_parameters(connection=self.connection)
1190         if drop:
1191             if new_field.null:
1192                 sql = self.sql_alter_column_no_default_null
1193             else:
1194                 sql = self.sql_alter_column_no_default
1195         else:
1196             sql = self.sql_alter_column_default
1197         return (
1198             sql
1199             % {
1200                 "column": self.quote_name(new_field.column),
1201                 "type": new_db_params["type"],
1202                 "default": default,
1203             },
1204             params,
1205         )
1206 
1207     def _alter_column_type_sql(self, model, old_field, new_field, new_type):
1208         """
1209         Hook to specialize column type alteration for different backends,
1210         for cases when a creation type is different to an alteration type
1211         (e.g. SERIAL in PostgreSQL, PostGIS fields).
1212 
1213         Return a two-tuple of: an SQL fragment of (sql, params) to insert into
1214         an ALTER TABLE statement and a list of extra (sql, params) tuples to
1215         run once the field is altered.
1216         """
1217         return (
1218             (
1219                 self.sql_alter_column_type
1220                 % {
1221                     "column": self.quote_name(new_field.column),
1222                     "type": new_type,
1223                 },
1224                 [],
1225             ),
1226             [],
1227         )
1228 
1229     def _alter_column_collation_sql(self, model, new_field, new_type, new_collation):
1230         return (
1231             self.sql_alter_column_collate
1232             % {
1233                 "column": self.quote_name(new_field.column),
1234                 "type": new_type,
1235                 "collation": " " + self._collate_sql(new_collation)
1236                 if new_collation
1237                 else "",
1238             },
1239             [],
1240         )
1241 
1242     def _alter_many_to_many(self, model, old_field, new_field, strict):
1243         """Alter M2Ms to repoint their to= endpoints."""
1244         # Rename the through table
1245         if (
1246             old_field.remote_field.through._meta.db_table
1247             != new_field.remote_field.through._meta.db_table
1248         ):
1249             self.alter_db_table(
1250                 old_field.remote_field.through,
1251                 old_field.remote_field.through._meta.db_table,
1252                 new_field.remote_field.through._meta.db_table,
1253             )
1254         # Repoint the FK to the other side
1255         self.alter_field(
1256             new_field.remote_field.through,
1257             # The field that points to the target model is needed, so we can
1258             # tell alter_field to change it - this is m2m_reverse_field_name()
1259             # (as opposed to m2m_field_name(), which points to our model).
1260             old_field.remote_field.through._meta.get_field(
1261                 old_field.m2m_reverse_field_name()
1262             ),
1263             new_field.remote_field.through._meta.get_field(
1264                 new_field.m2m_reverse_field_name()
1265             ),
1266         )
1267         self.alter_field(
1268             new_field.remote_field.through,
1269             # for self-referential models we need to alter field from the other end too
1270             old_field.remote_field.through._meta.get_field(old_field.m2m_field_name()),
1271             new_field.remote_field.through._meta.get_field(new_field.m2m_field_name()),
1272         )
1273 
1274     def _create_index_name(self, table_name, column_names, suffix=""):
1275         """
1276         Generate a unique name for an index/unique constraint.
1277 
1278         The name is divided into 3 parts: the table name, the column names,
1279         and a unique digest and suffix.
1280         """
1281         _, table_name = split_identifier(table_name)
1282         hash_suffix_part = "%s%s" % (
1283             names_digest(table_name, *column_names, length=8),
1284             suffix,
1285         )
1286         max_length = self.connection.ops.max_name_length() or 200
1287         # If everything fits into max_length, use that name.
1288         index_name = "%s_%s_%s" % (table_name, "_".join(column_names), hash_suffix_part)
1289         if len(index_name) <= max_length:
1290             return index_name
1291         # Shorten a long suffix.
1292         if len(hash_suffix_part) > max_length / 3:
1293             hash_suffix_part = hash_suffix_part[: max_length // 3]
1294         other_length = (max_length - len(hash_suffix_part)) // 2 - 1
1295         index_name = "%s_%s_%s" % (
1296             table_name[:other_length],
1297             "_".join(column_names)[:other_length],
1298             hash_suffix_part,
1299         )
1300         # Prepend D if needed to prevent the name from starting with an
1301         # underscore or a number (not permitted on Oracle).
1302         if index_name[0] == "_" or index_name[0].isdigit():
1303             index_name = "D%s" % index_name[:-1]
1304         return index_name
1305 
1306     def _get_index_tablespace_sql(self, model, fields, db_tablespace=None):
1307         if db_tablespace is None:
1308             if len(fields) == 1 and fields[0].db_tablespace:
1309                 db_tablespace = fields[0].db_tablespace
1310             elif settings.DEFAULT_INDEX_TABLESPACE:
1311                 db_tablespace = settings.DEFAULT_INDEX_TABLESPACE
1312             elif model._meta.db_tablespace:
1313                 db_tablespace = model._meta.db_tablespace
1314         if db_tablespace is not None:
1315             return " " + self.connection.ops.tablespace_sql(db_tablespace)
1316         return ""
1317 
1318     def _index_condition_sql(self, condition):
1319         if condition:
1320             return " WHERE " + condition
1321         return ""
1322 
1323     def _index_include_sql(self, model, columns):
1324         if not columns or not self.connection.features.supports_covering_indexes:
1325             return ""
1326         return Statement(
1327             " INCLUDE (%(columns)s)",
1328             columns=Columns(model._meta.db_table, columns, self.quote_name),
1329         )
1330 
1331     def _create_index_sql(
1332         self,
1333         model,
1334         *,
1335         fields=None,
1336         name=None,
1337         suffix="",
1338         using="",
1339         db_tablespace=None,
1340         col_suffixes=(),
1341         sql=None,
1342         opclasses=(),
1343         condition=None,
1344         include=None,
1345         expressions=None,
1346     ):
1347         """
1348         Return the SQL statement to create the index for one or several fields
1349         or expressions. `sql` can be specified if the syntax differs from the
1350         standard (GIS indexes, ...).
1351         """
1352         fields = fields or []
1353         expressions = expressions or []
1354         compiler = Query(model, alias_cols=False).get_compiler(
1355             connection=self.connection,
1356         )
1357         tablespace_sql = self._get_index_tablespace_sql(
1358             model, fields, db_tablespace=db_tablespace
1359         )
1360         columns = [field.column for field in fields]
1361         sql_create_index = sql or self.sql_create_index
1362         table = model._meta.db_table
1363 
1364         def create_index_name(*args, **kwargs):
1365             nonlocal name
1366             if name is None:
1367                 name = self._create_index_name(*args, **kwargs)
1368             return self.quote_name(name)
1369 
1370         return Statement(
1371             sql_create_index,
1372             table=Table(table, self.quote_name),
1373             name=IndexName(table, columns, suffix, create_index_name),
1374             using=using,
1375             columns=(
1376                 self._index_columns(table, columns, col_suffixes, opclasses)
1377                 if columns
1378                 else Expressions(table, expressions, compiler, self.quote_value)
1379             ),
1380             extra=tablespace_sql,
1381             condition=self._index_condition_sql(condition),
1382             include=self._index_include_sql(model, include),
1383         )
1384 
1385     def _delete_index_sql(self, model, name, sql=None):
1386         return Statement(
1387             sql or self.sql_delete_index,
1388             table=Table(model._meta.db_table, self.quote_name),
1389             name=self.quote_name(name),
1390         )
1391 
1392     def _rename_index_sql(self, model, old_name, new_name):
1393         return Statement(
1394             self.sql_rename_index,
1395             table=Table(model._meta.db_table, self.quote_name),
1396             old_name=self.quote_name(old_name),
1397             new_name=self.quote_name(new_name),
1398         )
1399 
1400     def _index_columns(self, table, columns, col_suffixes, opclasses):
1401         return Columns(table, columns, self.quote_name, col_suffixes=col_suffixes)
1402 
1403     def _model_indexes_sql(self, model):
1404         """
1405         Return a list of all index SQL statements (field indexes,
1406         index_together, Meta.indexes) for the specified model.
1407         """
1408         if not model._meta.managed or model._meta.proxy or model._meta.swapped:
1409             return []
1410         output = []
1411         for field in model._meta.local_fields:
1412             output.extend(self._field_indexes_sql(model, field))
1413 
1414         for field_names in model._meta.index_together:
1415             fields = [model._meta.get_field(field) for field in field_names]
1416             output.append(self._create_index_sql(model, fields=fields, suffix="_idx"))
1417 
1418         for index in model._meta.indexes:
1419             if (
1420                 not index.contains_expressions
1421                 or self.connection.features.supports_expression_indexes
1422             ):
1423                 output.append(index.create_sql(model, self))
1424         return output
1425 
1426     def _field_indexes_sql(self, model, field):
1427         """
1428         Return a list of all index SQL statements for the specified field.
1429         """
1430         output = []
1431         if self._field_should_be_indexed(model, field):
1432             output.append(self._create_index_sql(model, fields=[field]))
1433         return output
1434 
1435     def _field_should_be_altered(self, old_field, new_field):
1436         _, old_path, old_args, old_kwargs = old_field.deconstruct()
1437         _, new_path, new_args, new_kwargs = new_field.deconstruct()
1438         # Don't alter when:
1439         # - changing only a field name
1440         # - changing an attribute that doesn't affect the schema
1441         # - adding only a db_column and the column name is not changed
1442         for attr in old_field.non_db_attrs:
1443             old_kwargs.pop(attr, None)
1444         for attr in new_field.non_db_attrs:
1445             new_kwargs.pop(attr, None)
1446         return self.quote_name(old_field.column) != self.quote_name(
1447             new_field.column
1448         ) or (old_path, old_args, old_kwargs) != (new_path, new_args, new_kwargs)
1449 
1450     def _field_should_be_indexed(self, model, field):
1451         return field.db_index and not field.unique
1452 
1453     def _field_became_primary_key(self, old_field, new_field):
1454         return not old_field.primary_key and new_field.primary_key
1455 
1456     def _unique_should_be_added(self, old_field, new_field):
1457         return (
1458             not new_field.primary_key
1459             and new_field.unique
1460             and (not old_field.unique or old_field.primary_key)
1461         )
1462 
1463     def _rename_field_sql(self, table, old_field, new_field, new_type):
1464         return self.sql_rename_column % {
1465             "table": self.quote_name(table),
1466             "old_column": self.quote_name(old_field.column),
1467             "new_column": self.quote_name(new_field.column),
1468             "type": new_type,
1469         }
1470 
1471     def _create_fk_sql(self, model, field, suffix):
1472         table = Table(model._meta.db_table, self.quote_name)
1473         name = self._fk_constraint_name(model, field, suffix)
1474         column = Columns(model._meta.db_table, [field.column], self.quote_name)
1475         to_table = Table(field.target_field.model._meta.db_table, self.quote_name)
1476         to_column = Columns(
1477             field.target_field.model._meta.db_table,
1478             [field.target_field.column],
1479             self.quote_name,
1480         )
1481         deferrable = self.connection.ops.deferrable_sql()
1482         return Statement(
1483             self.sql_create_fk,
1484             table=table,
1485             name=name,
1486             column=column,
1487             to_table=to_table,
1488             to_column=to_column,
1489             deferrable=deferrable,
1490         )
1491 
1492     def _fk_constraint_name(self, model, field, suffix):
1493         def create_fk_name(*args, **kwargs):
1494             return self.quote_name(self._create_index_name(*args, **kwargs))
1495 
1496         return ForeignKeyName(
1497             model._meta.db_table,
1498             [field.column],
1499             split_identifier(field.target_field.model._meta.db_table)[1],
1500             [field.target_field.column],
1501             suffix,
1502             create_fk_name,
1503         )
1504 
1505     def _delete_fk_sql(self, model, name):
1506         return self._delete_constraint_sql(self.sql_delete_fk, model, name)
1507 
1508     def _deferrable_constraint_sql(self, deferrable):
1509         if deferrable is None:
1510             return ""
1511         if deferrable == Deferrable.DEFERRED:
1512             return " DEFERRABLE INITIALLY DEFERRED"
1513         if deferrable == Deferrable.IMMEDIATE:
1514             return " DEFERRABLE INITIALLY IMMEDIATE"
1515 
1516     def _unique_sql(
1517         self,
1518         model,
1519         fields,
1520         name,
1521         condition=None,
1522         deferrable=None,
1523         include=None,
1524         opclasses=None,
1525         expressions=None,
1526     ):
1527         if (
1528             deferrable
1529             and not self.connection.features.supports_deferrable_unique_constraints
1530         ):
1531             return None
1532         if condition or include or opclasses or expressions:
1533             # Databases support conditional, covering, and functional unique
1534             # constraints via a unique index.
1535             sql = self._create_unique_sql(
1536                 model,
1537                 fields,
1538                 name=name,
1539                 condition=condition,
1540                 include=include,
1541                 opclasses=opclasses,
1542                 expressions=expressions,
1543             )
1544             if sql:
1545                 self.deferred_sql.append(sql)
1546             return None
1547         constraint = self.sql_unique_constraint % {
1548             "columns": ", ".join([self.quote_name(field.column) for field in fields]),
1549             "deferrable": self._deferrable_constraint_sql(deferrable),
1550         }
1551         return self.sql_constraint % {
1552             "name": self.quote_name(name),
1553             "constraint": constraint,
1554         }
1555 
1556     def _create_unique_sql(
1557         self,
1558         model,
1559         fields,
1560         name=None,
1561         condition=None,
1562         deferrable=None,
1563         include=None,
1564         opclasses=None,
1565         expressions=None,
1566     ):
1567         if (
1568             (
1569                 deferrable
1570                 and not self.connection.features.supports_deferrable_unique_constraints
1571             )
1572             or (condition and not self.connection.features.supports_partial_indexes)
1573             or (include and not self.connection.features.supports_covering_indexes)
1574             or (
1575                 expressions and not self.connection.features.supports_expression_indexes
1576             )
1577         ):
1578             return None
1579 
1580         compiler = Query(model, alias_cols=False).get_compiler(
1581             connection=self.connection
1582         )
1583         table = model._meta.db_table
1584         columns = [field.column for field in fields]
1585         if name is None:
1586             name = self._unique_constraint_name(table, columns, quote=True)
1587         else:
1588             name = self.quote_name(name)
1589         if condition or include or opclasses or expressions:
1590             sql = self.sql_create_unique_index
1591         else:
1592             sql = self.sql_create_unique
1593         if columns:
1594             columns = self._index_columns(
1595                 table, columns, col_suffixes=(), opclasses=opclasses
1596             )
1597         else:
1598             columns = Expressions(table, expressions, compiler, self.quote_value)
1599         return Statement(
1600             sql,
1601             table=Table(table, self.quote_name),
1602             name=name,
1603             columns=columns,
1604             condition=self._index_condition_sql(condition),
1605             deferrable=self._deferrable_constraint_sql(deferrable),
1606             include=self._index_include_sql(model, include),
1607         )
1608 
1609     def _unique_constraint_name(self, table, columns, quote=True):
1610         if quote:
1611 
1612             def create_unique_name(*args, **kwargs):
1613                 return self.quote_name(self._create_index_name(*args, **kwargs))
1614 
1615         else:
1616             create_unique_name = self._create_index_name
1617 
1618         return IndexName(table, columns, "_uniq", create_unique_name)
1619 
1620     def _delete_unique_sql(
1621         self,
1622         model,
1623         name,
1624         condition=None,
1625         deferrable=None,
1626         include=None,
1627         opclasses=None,
1628         expressions=None,
1629     ):
1630         if (
1631             (
1632                 deferrable
1633                 and not self.connection.features.supports_deferrable_unique_constraints
1634             )
1635             or (condition and not self.connection.features.supports_partial_indexes)
1636             or (include and not self.connection.features.supports_covering_indexes)
1637             or (
1638                 expressions and not self.connection.features.supports_expression_indexes
1639             )
1640         ):
1641             return None
1642         if condition or include or opclasses or expressions:
1643             sql = self.sql_delete_index
1644         else:
1645             sql = self.sql_delete_unique
1646         return self._delete_constraint_sql(sql, model, name)
1647 
1648     def _check_sql(self, name, check):
1649         return self.sql_constraint % {
1650             "name": self.quote_name(name),
1651             "constraint": self.sql_check_constraint % {"check": check},
1652         }
1653 
1654     def _create_check_sql(self, model, name, check):
1655         return Statement(
1656             self.sql_create_check,
1657             table=Table(model._meta.db_table, self.quote_name),
1658             name=self.quote_name(name),
1659             check=check,
1660         )
1661 
1662     def _delete_check_sql(self, model, name):
1663         return self._delete_constraint_sql(self.sql_delete_check, model, name)
1664 
1665     def _delete_constraint_sql(self, template, model, name):
1666         return Statement(
1667             template,
1668             table=Table(model._meta.db_table, self.quote_name),
1669             name=self.quote_name(name),
1670         )
1671 
1672     def _constraint_names(
1673         self,
1674         model,
1675         column_names=None,
1676         unique=None,
1677         primary_key=None,
1678         index=None,
1679         foreign_key=None,
1680         check=None,
1681         type_=None,
1682         exclude=None,
1683     ):
1684         """Return all constraint names matching the columns and conditions."""
1685         if column_names is not None:
1686             column_names = [
1687                 self.connection.introspection.identifier_converter(name)
1688                 for name in column_names
1689             ]
1690         with self.connection.cursor() as cursor:
1691             constraints = self.connection.introspection.get_constraints(
1692                 cursor, model._meta.db_table
1693             )
1694         result = []
1695         for name, infodict in constraints.items():
1696             if column_names is None or column_names == infodict["columns"]:
1697                 if unique is not None and infodict["unique"] != unique:
1698                     continue
1699                 if primary_key is not None and infodict["primary_key"] != primary_key:
1700                     continue
1701                 if index is not None and infodict["index"] != index:
1702                     continue
1703                 if check is not None and infodict["check"] != check:
1704                     continue
1705                 if foreign_key is not None and not infodict["foreign_key"]:
1706                     continue
1707                 if type_ is not None and infodict["type"] != type_:
1708                     continue
1709                 if not exclude or name not in exclude:
1710                     result.append(name)
1711         return result
1712 
1713     def _delete_primary_key(self, model, strict=False):
1714         constraint_names = self._constraint_names(model, primary_key=True)
1715         if strict and len(constraint_names) != 1:
1716             raise ValueError(
1717                 "Found wrong number (%s) of PK constraints for %s"
1718                 % (
1719                     len(constraint_names),
1720                     model._meta.db_table,
1721                 )
1722             )
1723         for constraint_name in constraint_names:
1724             self.execute(self._delete_primary_key_sql(model, constraint_name))
1725 
1726     def _create_primary_key_sql(self, model, field):
1727         return Statement(
1728             self.sql_create_pk,
1729             table=Table(model._meta.db_table, self.quote_name),
1730             name=self.quote_name(
1731                 self._create_index_name(
1732                     model._meta.db_table, [field.column], suffix="_pk"
1733                 )
1734             ),
1735             columns=Columns(model._meta.db_table, [field.column], self.quote_name),
1736         )
1737 
1738     def _delete_primary_key_sql(self, model, name):
1739         return self._delete_constraint_sql(self.sql_delete_pk, model, name)
1740 
1741     def _collate_sql(self, collation):
1742         return "COLLATE " + self.quote_name(collation)
1743 
1744     def remove_procedure(self, procedure_name, param_types=()):
1745         sql = self.sql_delete_procedure % {
1746             "procedure": self.quote_name(procedure_name),
1747             "param_types": ",".join(param_types),
1748         }
1749         self.execute(sql)

</code><intended_behavior>Ensure schema generation logic translates `indexes` attributes into correct SQL statements, maintaining functionality equivalence with `index_together`.</intended_behavior>, <file>django/db/backends/sqlite3/schema.py</file>
<class>None</class>
<method>None</method>
<code>
1 import copy
2 from decimal import Decimal
3 
4 from django.apps.registry import Apps
5 from django.db import NotSupportedError
6 from django.db.backends.base.schema import BaseDatabaseSchemaEditor
7 from django.db.backends.ddl_references import Statement
8 from django.db.backends.utils import strip_quotes
9 from django.db.models import UniqueConstraint
10 from django.db.transaction import atomic
11 
12 
13 class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):
14 
15     sql_delete_table = "DROP TABLE %(table)s"
16     sql_create_fk = None
17     sql_create_inline_fk = (
18         "REFERENCES %(to_table)s (%(to_column)s) DEFERRABLE INITIALLY DEFERRED"
19     )
20     sql_create_column_inline_fk = sql_create_inline_fk
21     sql_delete_column = "ALTER TABLE %(table)s DROP COLUMN %(column)s"
22     sql_create_unique = "CREATE UNIQUE INDEX %(name)s ON %(table)s (%(columns)s)"
23     sql_delete_unique = "DROP INDEX %(name)s"
24 
25     def __enter__(self):
26         # Some SQLite schema alterations need foreign key constraints to be
27         # disabled. Enforce it here for the duration of the schema edition.
28         if not self.connection.disable_constraint_checking():
29             raise NotSupportedError(
30                 "SQLite schema editor cannot be used while foreign key "
31                 "constraint checks are enabled. Make sure to disable them "
32                 "before entering a transaction.atomic() context because "
33                 "SQLite does not support disabling them in the middle of "
34                 "a multi-statement transaction."
35             )
36         return super().__enter__()
37 
38     def __exit__(self, exc_type, exc_value, traceback):
39         self.connection.check_constraints()
40         super().__exit__(exc_type, exc_value, traceback)
41         self.connection.enable_constraint_checking()
42 
43     def quote_value(self, value):
44         # The backend "mostly works" without this function and there are use
45         # cases for compiling Python without the sqlite3 libraries (e.g.
46         # security hardening).
47         try:
48             import sqlite3
49 
50             value = sqlite3.adapt(value)
51         except ImportError:
52             pass
53         except sqlite3.ProgrammingError:
54             pass
55         # Manual emulation of SQLite parameter quoting
56         if isinstance(value, bool):
57             return str(int(value))
58         elif isinstance(value, (Decimal, float, int)):
59             return str(value)
60         elif isinstance(value, str):
61             return "'%s'" % value.replace("'", "''")
62         elif value is None:
63             return "NULL"
64         elif isinstance(value, (bytes, bytearray, memoryview)):
65             # Bytes are only allowed for BLOB fields, encoded as string
66             # literals containing hexadecimal data and preceded by a single "X"
67             # character.
68             return "X'%s'" % value.hex()
69         else:
70             raise ValueError(
71                 "Cannot quote parameter value %r of type %s" % (value, type(value))
72             )
73 
74     def prepare_default(self, value):
75         return self.quote_value(value)
76 
77     def _is_referenced_by_fk_constraint(
78         self, table_name, column_name=None, ignore_self=False
79     ):
80         """
81         Return whether or not the provided table name is referenced by another
82         one. If `column_name` is specified, only references pointing to that
83         column are considered. If `ignore_self` is True, self-referential
84         constraints are ignored.
85         """
86         with self.connection.cursor() as cursor:
87             for other_table in self.connection.introspection.get_table_list(cursor):
88                 if ignore_self and other_table.name == table_name:
89                     continue
90                 relations = self.connection.introspection.get_relations(
91                     cursor, other_table.name
92                 )
93                 for constraint_column, constraint_table in relations.values():
94                     if constraint_table == table_name and (
95                         column_name is None or constraint_column == column_name
96                     ):
97                         return True
98         return False
99 
100     def alter_db_table(
101         self, model, old_db_table, new_db_table, disable_constraints=True
102     ):
103         if (
104             not self.connection.features.supports_atomic_references_rename
105             and disable_constraints
106             and self._is_referenced_by_fk_constraint(old_db_table)
107         ):
108             if self.connection.in_atomic_block:
109                 raise NotSupportedError(
110                     (
111                         "Renaming the %r table while in a transaction is not "
112                         "supported on SQLite < 3.26 because it would break referential "
113                         "integrity. Try adding `atomic = False` to the Migration class."
114                     )
115                     % old_db_table
116                 )
117             self.connection.enable_constraint_checking()
118             super().alter_db_table(model, old_db_table, new_db_table)
119             self.connection.disable_constraint_checking()
120         else:
121             super().alter_db_table(model, old_db_table, new_db_table)
122 
123     def alter_field(self, model, old_field, new_field, strict=False):
124         if not self._field_should_be_altered(old_field, new_field):
125             return
126         old_field_name = old_field.name
127         table_name = model._meta.db_table
128         _, old_column_name = old_field.get_attname_column()
129         if (
130             new_field.name != old_field_name
131             and not self.connection.features.supports_atomic_references_rename
132             and self._is_referenced_by_fk_constraint(
133                 table_name, old_column_name, ignore_self=True
134             )
135         ):
136             if self.connection.in_atomic_block:
137                 raise NotSupportedError(
138                     (
139                         "Renaming the %r.%r column while in a transaction is not "
140                         "supported on SQLite < 3.26 because it would break referential "
141                         "integrity. Try adding `atomic = False` to the Migration class."
142                     )
143                     % (model._meta.db_table, old_field_name)
144                 )
145             with atomic(self.connection.alias):
146                 super().alter_field(model, old_field, new_field, strict=strict)
147                 # Follow SQLite's documented procedure for performing changes
148                 # that don't affect the on-disk content.
149                 # https://sqlite.org/lang_altertable.html#otheralter
150                 with self.connection.cursor() as cursor:
151                     schema_version = cursor.execute("PRAGMA schema_version").fetchone()[
152                         0
153                     ]
154                     cursor.execute("PRAGMA writable_schema = 1")
155                     references_template = ' REFERENCES "%s" ("%%s") ' % table_name
156                     new_column_name = new_field.get_attname_column()[1]
157                     search = references_template % old_column_name
158                     replacement = references_template % new_column_name
159                     cursor.execute(
160                         "UPDATE sqlite_master SET sql = replace(sql, %s, %s)",
161                         (search, replacement),
162                     )
163                     cursor.execute("PRAGMA schema_version = %d" % (schema_version + 1))
164                     cursor.execute("PRAGMA writable_schema = 0")
165                     # The integrity check will raise an exception and rollback
166                     # the transaction if the sqlite_master updates corrupt the
167                     # database.
168                     cursor.execute("PRAGMA integrity_check")
169             # Perform a VACUUM to refresh the database representation from
170             # the sqlite_master table.
171             with self.connection.cursor() as cursor:
172                 cursor.execute("VACUUM")
173         else:
174             super().alter_field(model, old_field, new_field, strict=strict)
175 
176     def _remake_table(
177         self, model, create_field=None, delete_field=None, alter_field=None
178     ):
179         """
180         Shortcut to transform a model from old_model into new_model
181 
182         This follows the correct procedure to perform non-rename or column
183         addition operations based on SQLite's documentation
184 
185         https://www.sqlite.org/lang_altertable.html#caution
186 
187         The essential steps are:
188           1. Create a table with the updated definition called "new__app_model"
189           2. Copy the data from the existing "app_model" table to the new table
190           3. Drop the "app_model" table
191           4. Rename the "new__app_model" table to "app_model"
192           5. Restore any index of the previous "app_model" table.
193         """
194         # Self-referential fields must be recreated rather than copied from
195         # the old model to ensure their remote_field.field_name doesn't refer
196         # to an altered field.
197         def is_self_referential(f):
198             return f.is_relation and f.remote_field.model is model
199 
200         # Work out the new fields dict / mapping
201         body = {
202             f.name: f.clone() if is_self_referential(f) else f
203             for f in model._meta.local_concrete_fields
204         }
205         # Since mapping might mix column names and default values,
206         # its values must be already quoted.
207         mapping = {
208             f.column: self.quote_name(f.column)
209             for f in model._meta.local_concrete_fields
210         }
211         # This maps field names (not columns) for things like unique_together
212         rename_mapping = {}
213         # If any of the new or altered fields is introducing a new PK,
214         # remove the old one
215         restore_pk_field = None
216         if getattr(create_field, "primary_key", False) or (
217             alter_field and getattr(alter_field[1], "primary_key", False)
218         ):
219             for name, field in list(body.items()):
220                 if field.primary_key and not (
221                     # Do not remove the old primary key when an altered field
222                     # that introduces a primary key is the same field.
223                     alter_field
224                     and name == alter_field[1].name
225                 ):
226                     field.primary_key = False
227                     restore_pk_field = field
228                     if field.auto_created:
229                         del body[name]
230                         del mapping[field.column]
231         # Add in any created fields
232         if create_field:
233             body[create_field.name] = create_field
234             # Choose a default and insert it into the copy map
235             if not create_field.many_to_many and create_field.concrete:
236                 mapping[create_field.column] = self.prepare_default(
237                     self.effective_default(create_field),
238                 )
239         # Add in any altered fields
240         if alter_field:
241             old_field, new_field = alter_field
242             body.pop(old_field.name, None)
243             mapping.pop(old_field.column, None)
244             body[new_field.name] = new_field
245             if old_field.null and not new_field.null:
246                 case_sql = "coalesce(%(col)s, %(default)s)" % {
247                     "col": self.quote_name(old_field.column),
248                     "default": self.prepare_default(self.effective_default(new_field)),
249                 }
250                 mapping[new_field.column] = case_sql
251             else:
252                 mapping[new_field.column] = self.quote_name(old_field.column)
253             rename_mapping[old_field.name] = new_field.name
254         # Remove any deleted fields
255         if delete_field:
256             del body[delete_field.name]
257             del mapping[delete_field.column]
258             # Remove any implicit M2M tables
259             if (
260                 delete_field.many_to_many
261                 and delete_field.remote_field.through._meta.auto_created
262             ):
263                 return self.delete_model(delete_field.remote_field.through)
264         # Work inside a new app registry
265         apps = Apps()
266 
267         # Work out the new value of unique_together, taking renames into
268         # account
269         unique_together = [
270             [rename_mapping.get(n, n) for n in unique]
271             for unique in model._meta.unique_together
272         ]
273 
274         # Work out the new value for index_together, taking renames into
275         # account
276         index_together = [
277             [rename_mapping.get(n, n) for n in index]
278             for index in model._meta.index_together
279         ]
280 
281         indexes = model._meta.indexes
282         if delete_field:
283             indexes = [
284                 index for index in indexes if delete_field.name not in index.fields
285             ]
286 
287         constraints = list(model._meta.constraints)
288 
289         # Provide isolated instances of the fields to the new model body so
290         # that the existing model's internals aren't interfered with when
291         # the dummy model is constructed.
292         body_copy = copy.deepcopy(body)
293 
294         # Construct a new model with the new fields to allow self referential
295         # primary key to resolve to. This model won't ever be materialized as a
296         # table and solely exists for foreign key reference resolution purposes.
297         # This wouldn't be required if the schema editor was operating on model
298         # states instead of rendered models.
299         meta_contents = {
300             "app_label": model._meta.app_label,
301             "db_table": model._meta.db_table,
302             "unique_together": unique_together,
303             "index_together": index_together,
304             "indexes": indexes,
305             "constraints": constraints,
306             "apps": apps,
307         }
308         meta = type("Meta", (), meta_contents)
309         body_copy["Meta"] = meta
310         body_copy["__module__"] = model.__module__
311         type(model._meta.object_name, model.__bases__, body_copy)
312 
313         # Construct a model with a renamed table name.
314         body_copy = copy.deepcopy(body)
315         meta_contents = {
316             "app_label": model._meta.app_label,
317             "db_table": "new__%s" % strip_quotes(model._meta.db_table),
318             "unique_together": unique_together,
319             "index_together": index_together,
320             "indexes": indexes,
321             "constraints": constraints,
322             "apps": apps,
323         }
324         meta = type("Meta", (), meta_contents)
325         body_copy["Meta"] = meta
326         body_copy["__module__"] = model.__module__
327         new_model = type("New%s" % model._meta.object_name, model.__bases__, body_copy)
328 
329         # Create a new table with the updated schema.
330         self.create_model(new_model)
331 
332         # Copy data from the old table into the new table
333         self.execute(
334             "INSERT INTO %s (%s) SELECT %s FROM %s"
335             % (
336                 self.quote_name(new_model._meta.db_table),
337                 ", ".join(self.quote_name(x) for x in mapping),
338                 ", ".join(mapping.values()),
339                 self.quote_name(model._meta.db_table),
340             )
341         )
342 
343         # Delete the old table to make way for the new
344         self.delete_model(model, handle_autom2m=False)
345 
346         # Rename the new table to take way for the old
347         self.alter_db_table(
348             new_model,
349             new_model._meta.db_table,
350             model._meta.db_table,
351             disable_constraints=False,
352         )
353 
354         # Run deferred SQL on correct table
355         for sql in self.deferred_sql:
356             self.execute(sql)
357         self.deferred_sql = []
358         # Fix any PK-removed field
359         if restore_pk_field:
360             restore_pk_field.primary_key = True
361 
362     def delete_model(self, model, handle_autom2m=True):
363         if handle_autom2m:
364             super().delete_model(model)
365         else:
366             # Delete the table (and only that)
367             self.execute(
368                 self.sql_delete_table
369                 % {
370                     "table": self.quote_name(model._meta.db_table),
371                 }
372             )
373             # Remove all deferred statements referencing the deleted table.
374             for sql in list(self.deferred_sql):
375                 if isinstance(sql, Statement) and sql.references_table(
376                     model._meta.db_table
377                 ):
378                     self.deferred_sql.remove(sql)
379 
380     def add_field(self, model, field):
381         """Create a field on a model."""
382         if (
383             # Primary keys and unique fields are not supported in ALTER TABLE
384             # ADD COLUMN.
385             field.primary_key
386             or field.unique
387             or
388             # Fields with default values cannot by handled by ALTER TABLE ADD
389             # COLUMN statement because DROP DEFAULT is not supported in
390             # ALTER TABLE.
391             not field.null
392             or self.effective_default(field) is not None
393         ):
394             self._remake_table(model, create_field=field)
395         else:
396             super().add_field(model, field)
397 
398     def remove_field(self, model, field):
399         """
400         Remove a field from a model. Usually involves deleting a column,
401         but for M2Ms may involve deleting a table.
402         """
403         # M2M fields are a special case
404         if field.many_to_many:
405             # For implicit M2M tables, delete the auto-created table
406             if field.remote_field.through._meta.auto_created:
407                 self.delete_model(field.remote_field.through)
408             # For explicit "through" M2M fields, do nothing
409         elif (
410             self.connection.features.can_alter_table_drop_column
411             # Primary keys, unique fields, and foreign keys are not
412             # supported in ALTER TABLE DROP COLUMN.
413             and not field.primary_key
414             and not field.unique
415             and not (field.remote_field and field.db_constraint)
416         ):
417             super().remove_field(model, field)
418         # For everything else, remake.
419         else:
420             # It might not actually have a column behind it
421             if field.db_parameters(connection=self.connection)["type"] is None:
422                 return
423             self._remake_table(model, delete_field=field)
424 
425     def _alter_field(
426         self,
427         model,
428         old_field,
429         new_field,
430         old_type,
431         new_type,
432         old_db_params,
433         new_db_params,
434         strict=False,
435     ):
436         """Perform a "physical" (non-ManyToMany) field update."""
437         # Use "ALTER TABLE ... RENAME COLUMN" if only the column name
438         # changed and there aren't any constraints.
439         if (
440             self.connection.features.can_alter_table_rename_column
441             and old_field.column != new_field.column
442             and self.column_sql(model, old_field) == self.column_sql(model, new_field)
443             and not (
444                 old_field.remote_field
445                 and old_field.db_constraint
446                 or new_field.remote_field
447                 and new_field.db_constraint
448             )
449         ):
450             return self.execute(
451                 self._rename_field_sql(
452                     model._meta.db_table, old_field, new_field, new_type
453                 )
454             )
455         # Alter by remaking table
456         self._remake_table(model, alter_field=(old_field, new_field))
457         # Rebuild tables with FKs pointing to this field.
458         old_collation = old_db_params.get("collation")
459         new_collation = new_db_params.get("collation")
460         if new_field.unique and (
461             old_type != new_type or old_collation != new_collation
462         ):
463             related_models = set()
464             opts = new_field.model._meta
465             for remote_field in opts.related_objects:
466                 # Ignore self-relationship since the table was already rebuilt.
467                 if remote_field.related_model == model:
468                     continue
469                 if not remote_field.many_to_many:
470                     if remote_field.field_name == new_field.name:
471                         related_models.add(remote_field.related_model)
472                 elif new_field.primary_key and remote_field.through._meta.auto_created:
473                     related_models.add(remote_field.through)
474             if new_field.primary_key:
475                 for many_to_many in opts.many_to_many:
476                     # Ignore self-relationship since the table was already rebuilt.
477                     if many_to_many.related_model == model:
478                         continue
479                     if many_to_many.remote_field.through._meta.auto_created:
480                         related_models.add(many_to_many.remote_field.through)
481             for related_model in related_models:
482                 self._remake_table(related_model)
483 
484     def _alter_many_to_many(self, model, old_field, new_field, strict):
485         """Alter M2Ms to repoint their to= endpoints."""
486         if (
487             old_field.remote_field.through._meta.db_table
488             == new_field.remote_field.through._meta.db_table
489         ):
490             # The field name didn't change, but some options did, so we have to
491             # propagate this altering.
492             self._remake_table(
493                 old_field.remote_field.through,
494                 alter_field=(
495                     # The field that points to the target model is needed, so
496                     # we can tell alter_field to change it - this is
497                     # m2m_reverse_field_name() (as opposed to m2m_field_name(),
498                     # which points to our model).
499                     old_field.remote_field.through._meta.get_field(
500                         old_field.m2m_reverse_field_name()
501                     ),
502                     new_field.remote_field.through._meta.get_field(
503                         new_field.m2m_reverse_field_name()
504                     ),
505                 ),
506             )
507             return
508 
509         # Make a new through table
510         self.create_model(new_field.remote_field.through)
511         # Copy the data across
512         self.execute(
513             "INSERT INTO %s (%s) SELECT %s FROM %s"
514             % (
515                 self.quote_name(new_field.remote_field.through._meta.db_table),
516                 ", ".join(
517                     [
518                         "id",
519                         new_field.m2m_column_name(),
520                         new_field.m2m_reverse_name(),
521                     ]
522                 ),
523                 ", ".join(
524                     [
525                         "id",
526                         old_field.m2m_column_name(),
527                         old_field.m2m_reverse_name(),
528                     ]
529                 ),
530                 self.quote_name(old_field.remote_field.through._meta.db_table),
531             )
532         )
533         # Delete the old through table
534         self.delete_model(old_field.remote_field.through)
535 
536     def add_constraint(self, model, constraint):
537         if isinstance(constraint, UniqueConstraint) and (
538             constraint.condition
539             or constraint.contains_expressions
540             or constraint.include
541             or constraint.deferrable
542         ):
543             super().add_constraint(model, constraint)
544         else:
545             self._remake_table(model)
546 
547     def remove_constraint(self, model, constraint):
548         if isinstance(constraint, UniqueConstraint) and (
549             constraint.condition
550             or constraint.contains_expressions
551             or constraint.include
552             or constraint.deferrable
553         ):
554             super().remove_constraint(model, constraint)
555         else:
556             self._remake_table(model)
557 
558     def _collate_sql(self, collation):
559         return "COLLATE " + collation

</code><intended_behavior>Ensure compatibility or appropriate translation to use of `indexes`, ensuring backend-specific handling of `index_together` is updated.</intended_behavior>]
2025-10-17 13:13:32.212 | INFO     | Search completed. Bug locations: [<file>django/db/models/options.py</file>
<class>None</class>
<method>None</method>
<code>
1 import bisect
2 import copy
3 import inspect
4 from collections import defaultdict
5 
6 from django.apps import apps
7 from django.conf import settings
8 from django.core.exceptions import FieldDoesNotExist, ImproperlyConfigured
9 from django.db import connections
10 from django.db.models import AutoField, Manager, OrderWrt, UniqueConstraint
11 from django.db.models.query_utils import PathInfo
12 from django.utils.datastructures import ImmutableList, OrderedSet
13 from django.utils.functional import cached_property
14 from django.utils.module_loading import import_string
15 from django.utils.text import camel_case_to_spaces, format_lazy
16 from django.utils.translation import override
17 
18 PROXY_PARENTS = object()
19 
20 EMPTY_RELATION_TREE = ()
21 
22 IMMUTABLE_WARNING = (
23     "The return type of '%s' should never be mutated. If you want to manipulate this "
24     "list for your own use, make a copy first."
25 )
26 
27 DEFAULT_NAMES = (
28     "verbose_name",
29     "verbose_name_plural",
30     "db_table",
31     "ordering",
32     "unique_together",
33     "permissions",
34     "get_latest_by",
35     "order_with_respect_to",
36     "app_label",
37     "db_tablespace",
38     "abstract",
39     "managed",
40     "proxy",
41     "swappable",
42     "auto_created",
43     "index_together",
44     "apps",
45     "default_permissions",
46     "select_on_save",
47     "default_related_name",
48     "required_db_features",
49     "required_db_vendor",
50     "base_manager_name",
51     "default_manager_name",
52     "indexes",
53     "constraints",
54 )
55 
56 
57 def normalize_together(option_together):
58     """
59     option_together can be either a tuple of tuples, or a single
60     tuple of two strings. Normalize it to a tuple of tuples, so that
61     calling code can uniformly expect that.
62     """
63     try:
64         if not option_together:
65             return ()
66         if not isinstance(option_together, (tuple, list)):
67             raise TypeError
68         first_element = option_together[0]
69         if not isinstance(first_element, (tuple, list)):
70             option_together = (option_together,)
71         # Normalize everything to tuples
72         return tuple(tuple(ot) for ot in option_together)
73     except TypeError:
74         # If the value of option_together isn't valid, return it
75         # verbatim; this will be picked up by the check framework later.
76         return option_together
77 
78 
79 def make_immutable_fields_list(name, data):
80     return ImmutableList(data, warning=IMMUTABLE_WARNING % name)
81 
82 
83 class Options:
84     FORWARD_PROPERTIES = {
85         "fields",
86         "many_to_many",
87         "concrete_fields",
88         "local_concrete_fields",
89         "_forward_fields_map",
90         "managers",
91         "managers_map",
92         "base_manager",
93         "default_manager",
94     }
95     REVERSE_PROPERTIES = {"related_objects", "fields_map", "_relation_tree"}
96 
97     default_apps = apps
98 
99     def __init__(self, meta, app_label=None):
100         self._get_fields_cache = {}
101         self.local_fields = []
102         self.local_many_to_many = []
103         self.private_fields = []
104         self.local_managers = []
105         self.base_manager_name = None
106         self.default_manager_name = None
107         self.model_name = None
108         self.verbose_name = None
109         self.verbose_name_plural = None
110         self.db_table = ""
111         self.ordering = []
112         self._ordering_clash = False
113         self.indexes = []
114         self.constraints = []
115         self.unique_together = []
116         self.index_together = []
117         self.select_on_save = False
118         self.default_permissions = ("add", "change", "delete", "view")
119         self.permissions = []
120         self.object_name = None
121         self.app_label = app_label
122         self.get_latest_by = None
123         self.order_with_respect_to = None
124         self.db_tablespace = settings.DEFAULT_TABLESPACE
125         self.required_db_features = []
126         self.required_db_vendor = None
127         self.meta = meta
128         self.pk = None
129         self.auto_field = None
130         self.abstract = False
131         self.managed = True
132         self.proxy = False
133         # For any class that is a proxy (including automatically created
134         # classes for deferred object loading), proxy_for_model tells us
135         # which class this model is proxying. Note that proxy_for_model
136         # can create a chain of proxy models. For non-proxy models, the
137         # variable is always None.
138         self.proxy_for_model = None
139         # For any non-abstract class, the concrete class is the model
140         # in the end of the proxy_for_model chain. In particular, for
141         # concrete models, the concrete_model is always the class itself.
142         self.concrete_model = None
143         self.swappable = None
144         self.parents = {}
145         self.auto_created = False
146 
147         # List of all lookups defined in ForeignKey 'limit_choices_to' options
148         # from *other* models. Needed for some admin checks. Internal use only.
149         self.related_fkey_lookups = []
150 
151         # A custom app registry to use, if you're making a separate model set.
152         self.apps = self.default_apps
153 
154         self.default_related_name = None
155 
156     @property
157     def label(self):
158         return "%s.%s" % (self.app_label, self.object_name)
159 
160     @property
161     def label_lower(self):
162         return "%s.%s" % (self.app_label, self.model_name)
163 
164     @property
165     def app_config(self):
166         # Don't go through get_app_config to avoid triggering imports.
167         return self.apps.app_configs.get(self.app_label)
168 
169     def contribute_to_class(self, cls, name):
170         from django.db import connection
171         from django.db.backends.utils import truncate_name
172 
173         cls._meta = self
174         self.model = cls
175         # First, construct the default values for these options.
176         self.object_name = cls.__name__
177         self.model_name = self.object_name.lower()
178         self.verbose_name = camel_case_to_spaces(self.object_name)
179 
180         # Store the original user-defined values for each option,
181         # for use when serializing the model definition
182         self.original_attrs = {}
183 
184         # Next, apply any overridden values from 'class Meta'.
185         if self.meta:
186             meta_attrs = self.meta.__dict__.copy()
187             for name in self.meta.__dict__:
188                 # Ignore any private attributes that Django doesn't care about.
189                 # NOTE: We can't modify a dictionary's contents while looping
190                 # over it, so we loop over the *original* dictionary instead.
191                 if name.startswith("_"):
192                     del meta_attrs[name]
193             for attr_name in DEFAULT_NAMES:
194                 if attr_name in meta_attrs:
195                     setattr(self, attr_name, meta_attrs.pop(attr_name))
196                     self.original_attrs[attr_name] = getattr(self, attr_name)
197                 elif hasattr(self.meta, attr_name):
198                     setattr(self, attr_name, getattr(self.meta, attr_name))
199                     self.original_attrs[attr_name] = getattr(self, attr_name)
200 
201             self.unique_together = normalize_together(self.unique_together)
202             self.index_together = normalize_together(self.index_together)
203             # App label/class name interpolation for names of constraints and
204             # indexes.
205             if not getattr(cls._meta, "abstract", False):
206                 for attr_name in {"constraints", "indexes"}:
207                     objs = getattr(self, attr_name, [])
208                     setattr(self, attr_name, self._format_names_with_class(cls, objs))
209 
210             # verbose_name_plural is a special case because it uses a 's'
211             # by default.
212             if self.verbose_name_plural is None:
213                 self.verbose_name_plural = format_lazy("{}s", self.verbose_name)
214 
215             # order_with_respect_and ordering are mutually exclusive.
216             self._ordering_clash = bool(self.ordering and self.order_with_respect_to)
217 
218             # Any leftover attributes must be invalid.
219             if meta_attrs != {}:
220                 raise TypeError(
221                     "'class Meta' got invalid attribute(s): %s" % ",".join(meta_attrs)
222                 )
223         else:
224             self.verbose_name_plural = format_lazy("{}s", self.verbose_name)
225         del self.meta
226 
227         # If the db_table wasn't provided, use the app_label + model_name.
228         if not self.db_table:
229             self.db_table = "%s_%s" % (self.app_label, self.model_name)
230             self.db_table = truncate_name(
231                 self.db_table, connection.ops.max_name_length()
232             )
233 
234     def _format_names_with_class(self, cls, objs):
235         """App label/class name interpolation for object names."""
236         new_objs = []
237         for obj in objs:
238             obj = obj.clone()
239             obj.name = obj.name % {
240                 "app_label": cls._meta.app_label.lower(),
241                 "class": cls.__name__.lower(),
242             }
243             new_objs.append(obj)
244         return new_objs
245 
246     def _get_default_pk_class(self):
247         pk_class_path = getattr(
248             self.app_config,
249             "default_auto_field",
250             settings.DEFAULT_AUTO_FIELD,
251         )
252         if self.app_config and self.app_config._is_default_auto_field_overridden:
253             app_config_class = type(self.app_config)
254             source = (
255                 f"{app_config_class.__module__}."
256                 f"{app_config_class.__qualname__}.default_auto_field"
257             )
258         else:
259             source = "DEFAULT_AUTO_FIELD"
260         if not pk_class_path:
261             raise ImproperlyConfigured(f"{source} must not be empty.")
262         try:
263             pk_class = import_string(pk_class_path)
264         except ImportError as e:
265             msg = (
266                 f"{source} refers to the module '{pk_class_path}' that could "
267                 f"not be imported."
268             )
269             raise ImproperlyConfigured(msg) from e
270         if not issubclass(pk_class, AutoField):
271             raise ValueError(
272                 f"Primary key '{pk_class_path}' referred by {source} must "
273                 f"subclass AutoField."
274             )
275         return pk_class
276 
277     def _prepare(self, model):
278         if self.order_with_respect_to:
279             # The app registry will not be ready at this point, so we cannot
280             # use get_field().
281             query = self.order_with_respect_to
282             try:
283                 self.order_with_respect_to = next(
284                     f
285                     for f in self._get_fields(reverse=False)
286                     if f.name == query or f.attname == query
287                 )
288             except StopIteration:
289                 raise FieldDoesNotExist(
290                     "%s has no field named '%s'" % (self.object_name, query)
291                 )
292 
293             self.ordering = ("_order",)
294             if not any(
295                 isinstance(field, OrderWrt) for field in model._meta.local_fields
296             ):
297                 model.add_to_class("_order", OrderWrt())
298         else:
299             self.order_with_respect_to = None
300 
301         if self.pk is None:
302             if self.parents:
303                 # Promote the first parent link in lieu of adding yet another
304                 # field.
305                 field = next(iter(self.parents.values()))
306                 # Look for a local field with the same name as the
307                 # first parent link. If a local field has already been
308                 # created, use it instead of promoting the parent
309                 already_created = [
310                     fld for fld in self.local_fields if fld.name == field.name
311                 ]
312                 if already_created:
313                     field = already_created[0]
314                 field.primary_key = True
315                 self.setup_pk(field)
316             else:
317                 pk_class = self._get_default_pk_class()
318                 auto = pk_class(verbose_name="ID", primary_key=True, auto_created=True)
319                 model.add_to_class("id", auto)
320 
321     def add_manager(self, manager):
322         self.local_managers.append(manager)
323         self._expire_cache()
324 
325     def add_field(self, field, private=False):
326         # Insert the given field in the order in which it was created, using
327         # the "creation_counter" attribute of the field.
328         # Move many-to-many related fields from self.fields into
329         # self.many_to_many.
330         if private:
331             self.private_fields.append(field)
332         elif field.is_relation and field.many_to_many:
333             bisect.insort(self.local_many_to_many, field)
334         else:
335             bisect.insort(self.local_fields, field)
336             self.setup_pk(field)
337 
338         # If the field being added is a relation to another known field,
339         # expire the cache on this field and the forward cache on the field
340         # being referenced, because there will be new relationships in the
341         # cache. Otherwise, expire the cache of references *to* this field.
342         # The mechanism for getting at the related model is slightly odd -
343         # ideally, we'd just ask for field.related_model. However, related_model
344         # is a cached property, and all the models haven't been loaded yet, so
345         # we need to make sure we don't cache a string reference.
346         if (
347             field.is_relation
348             and hasattr(field.remote_field, "model")
349             and field.remote_field.model
350         ):
351             try:
352                 field.remote_field.model._meta._expire_cache(forward=False)
353             except AttributeError:
354                 pass
355             self._expire_cache()
356         else:
357             self._expire_cache(reverse=False)
358 
359     def setup_pk(self, field):
360         if not self.pk and field.primary_key:
361             self.pk = field
362             field.serialize = False
363 
364     def setup_proxy(self, target):
365         """
366         Do the internal setup so that the current model is a proxy for
367         "target".
368         """
369         self.pk = target._meta.pk
370         self.proxy_for_model = target
371         self.db_table = target._meta.db_table
372 
373     def __repr__(self):
374         return "<Options for %s>" % self.object_name
375 
376     def __str__(self):
377         return self.label_lower
378 
379     def can_migrate(self, connection):
380         """
381         Return True if the model can/should be migrated on the `connection`.
382         `connection` can be either a real connection or a connection alias.
383         """
384         if self.proxy or self.swapped or not self.managed:
385             return False
386         if isinstance(connection, str):
387             connection = connections[connection]
388         if self.required_db_vendor:
389             return self.required_db_vendor == connection.vendor
390         if self.required_db_features:
391             return all(
392                 getattr(connection.features, feat, False)
393                 for feat in self.required_db_features
394             )
395         return True
396 
397     @property
398     def verbose_name_raw(self):
399         """Return the untranslated verbose name."""
400         with override(None):
401             return str(self.verbose_name)
402 
403     @property
404     def swapped(self):
405         """
406         Has this model been swapped out for another? If so, return the model
407         name of the replacement; otherwise, return None.
408 
409         For historical reasons, model name lookups using get_model() are
410         case insensitive, so we make sure we are case insensitive here.
411         """
412         if self.swappable:
413             swapped_for = getattr(settings, self.swappable, None)
414             if swapped_for:
415                 try:
416                     swapped_label, swapped_object = swapped_for.split(".")
417                 except ValueError:
418                     # setting not in the format app_label.model_name
419                     # raising ImproperlyConfigured here causes problems with
420                     # test cleanup code - instead it is raised in get_user_model
421                     # or as part of validation.
422                     return swapped_for
423 
424                 if (
425                     "%s.%s" % (swapped_label, swapped_object.lower())
426                     != self.label_lower
427                 ):
428                     return swapped_for
429         return None
430 
431     @cached_property
432     def managers(self):
433         managers = []
434         seen_managers = set()
435         bases = (b for b in self.model.mro() if hasattr(b, "_meta"))
436         for depth, base in enumerate(bases):
437             for manager in base._meta.local_managers:
438                 if manager.name in seen_managers:
439                     continue
440 
441                 manager = copy.copy(manager)
442                 manager.model = self.model
443                 seen_managers.add(manager.name)
444                 managers.append((depth, manager.creation_counter, manager))
445 
446         return make_immutable_fields_list(
447             "managers",
448             (m[2] for m in sorted(managers)),
449         )
450 
451     @cached_property
452     def managers_map(self):
453         return {manager.name: manager for manager in self.managers}
454 
455     @cached_property
456     def base_manager(self):
457         base_manager_name = self.base_manager_name
458         if not base_manager_name:
459             # Get the first parent's base_manager_name if there's one.
460             for parent in self.model.mro()[1:]:
461                 if hasattr(parent, "_meta"):
462                     if parent._base_manager.name != "_base_manager":
463                         base_manager_name = parent._base_manager.name
464                     break
465 
466         if base_manager_name:
467             try:
468                 return self.managers_map[base_manager_name]
469             except KeyError:
470                 raise ValueError(
471                     "%s has no manager named %r"
472                     % (
473                         self.object_name,
474                         base_manager_name,
475                     )
476                 )
477 
478         manager = Manager()
479         manager.name = "_base_manager"
480         manager.model = self.model
481         manager.auto_created = True
482         return manager
483 
484     @cached_property
485     def default_manager(self):
486         default_manager_name = self.default_manager_name
487         if not default_manager_name and not self.local_managers:
488             # Get the first parent's default_manager_name if there's one.
489             for parent in self.model.mro()[1:]:
490                 if hasattr(parent, "_meta"):
491                     default_manager_name = parent._meta.default_manager_name
492                     break
493 
494         if default_manager_name:
495             try:
496                 return self.managers_map[default_manager_name]
497             except KeyError:
498                 raise ValueError(
499                     "%s has no manager named %r"
500                     % (
501                         self.object_name,
502                         default_manager_name,
503                     )
504                 )
505 
506         if self.managers:
507             return self.managers[0]
508 
509     @cached_property
510     def fields(self):
511         """
512         Return a list of all forward fields on the model and its parents,
513         excluding ManyToManyFields.
514 
515         Private API intended only to be used by Django itself; get_fields()
516         combined with filtering of field properties is the public API for
517         obtaining this field list.
518         """
519         # For legacy reasons, the fields property should only contain forward
520         # fields that are not private or with a m2m cardinality. Therefore we
521         # pass these three filters as filters to the generator.
522         # The third lambda is a longwinded way of checking f.related_model - we don't
523         # use that property directly because related_model is a cached property,
524         # and all the models may not have been loaded yet; we don't want to cache
525         # the string reference to the related_model.
526         def is_not_an_m2m_field(f):
527             return not (f.is_relation and f.many_to_many)
528 
529         def is_not_a_generic_relation(f):
530             return not (f.is_relation and f.one_to_many)
531 
532         def is_not_a_generic_foreign_key(f):
533             return not (
534                 f.is_relation
535                 and f.many_to_one
536                 and not (hasattr(f.remote_field, "model") and f.remote_field.model)
537             )
538 
539         return make_immutable_fields_list(
540             "fields",
541             (
542                 f
543                 for f in self._get_fields(reverse=False)
544                 if is_not_an_m2m_field(f)
545                 and is_not_a_generic_relation(f)
546                 and is_not_a_generic_foreign_key(f)
547             ),
548         )
549 
550     @cached_property
551     def concrete_fields(self):
552         """
553         Return a list of all concrete fields on the model and its parents.
554 
555         Private API intended only to be used by Django itself; get_fields()
556         combined with filtering of field properties is the public API for
557         obtaining this field list.
558         """
559         return make_immutable_fields_list(
560             "concrete_fields", (f for f in self.fields if f.concrete)
561         )
562 
563     @cached_property
564     def local_concrete_fields(self):
565         """
566         Return a list of all concrete fields on the model.
567 
568         Private API intended only to be used by Django itself; get_fields()
569         combined with filtering of field properties is the public API for
570         obtaining this field list.
571         """
572         return make_immutable_fields_list(
573             "local_concrete_fields", (f for f in self.local_fields if f.concrete)
574         )
575 
576     @cached_property
577     def many_to_many(self):
578         """
579         Return a list of all many to many fields on the model and its parents.
580 
581         Private API intended only to be used by Django itself; get_fields()
582         combined with filtering of field properties is the public API for
583         obtaining this list.
584         """
585         return make_immutable_fields_list(
586             "many_to_many",
587             (
588                 f
589                 for f in self._get_fields(reverse=False)
590                 if f.is_relation and f.many_to_many
591             ),
592         )
593 
594     @cached_property
595     def related_objects(self):
596         """
597         Return all related objects pointing to the current model. The related
598         objects can come from a one-to-one, one-to-many, or many-to-many field
599         relation type.
600 
601         Private API intended only to be used by Django itself; get_fields()
602         combined with filtering of field properties is the public API for
603         obtaining this field list.
604         """
605         all_related_fields = self._get_fields(
606             forward=False, reverse=True, include_hidden=True
607         )
608         return make_immutable_fields_list(
609             "related_objects",
610             (
611                 obj
612                 for obj in all_related_fields
613                 if not obj.hidden or obj.field.many_to_many
614             ),
615         )
616 
617     @cached_property
618     def _forward_fields_map(self):
619         res = {}
620         fields = self._get_fields(reverse=False)
621         for field in fields:
622             res[field.name] = field
623             # Due to the way Django's internals work, get_field() should also
624             # be able to fetch a field by attname. In the case of a concrete
625             # field with relation, includes the *_id name too
626             try:
627                 res[field.attname] = field
628             except AttributeError:
629                 pass
630         return res
631 
632     @cached_property
633     def fields_map(self):
634         res = {}
635         fields = self._get_fields(forward=False, include_hidden=True)
636         for field in fields:
637             res[field.name] = field
638             # Due to the way Django's internals work, get_field() should also
639             # be able to fetch a field by attname. In the case of a concrete
640             # field with relation, includes the *_id name too
641             try:
642                 res[field.attname] = field
643             except AttributeError:
644                 pass
645         return res
646 
647     def get_field(self, field_name):
648         """
649         Return a field instance given the name of a forward or reverse field.
650         """
651         try:
652             # In order to avoid premature loading of the relation tree
653             # (expensive) we prefer checking if the field is a forward field.
654             return self._forward_fields_map[field_name]
655         except KeyError:
656             # If the app registry is not ready, reverse fields are
657             # unavailable, therefore we throw a FieldDoesNotExist exception.
658             if not self.apps.models_ready:
659                 raise FieldDoesNotExist(
660                     "%s has no field named '%s'. The app cache isn't ready yet, "
661                     "so if this is an auto-created related field, it won't "
662                     "be available yet." % (self.object_name, field_name)
663                 )
664 
665         try:
666             # Retrieve field instance by name from cached or just-computed
667             # field map.
668             return self.fields_map[field_name]
669         except KeyError:
670             raise FieldDoesNotExist(
671                 "%s has no field named '%s'" % (self.object_name, field_name)
672             )
673 
674     def get_base_chain(self, model):
675         """
676         Return a list of parent classes leading to `model` (ordered from
677         closest to most distant ancestor). This has to handle the case where
678         `model` is a grandparent or even more distant relation.
679         """
680         if not self.parents:
681             return []
682         if model in self.parents:
683             return [model]
684         for parent in self.parents:
685             res = parent._meta.get_base_chain(model)
686             if res:
687                 res.insert(0, parent)
688                 return res
689         return []
690 
691     def get_parent_list(self):
692         """
693         Return all the ancestors of this model as a list ordered by MRO.
694         Useful for determining if something is an ancestor, regardless of lineage.
695         """
696         result = OrderedSet(self.parents)
697         for parent in self.parents:
698             for ancestor in parent._meta.get_parent_list():
699                 result.add(ancestor)
700         return list(result)
701 
702     def get_ancestor_link(self, ancestor):
703         """
704         Return the field on the current model which points to the given
705         "ancestor". This is possible an indirect link (a pointer to a parent
706         model, which points, eventually, to the ancestor). Used when
707         constructing table joins for model inheritance.
708 
709         Return None if the model isn't an ancestor of this one.
710         """
711         if ancestor in self.parents:
712             return self.parents[ancestor]
713         for parent in self.parents:
714             # Tries to get a link field from the immediate parent
715             parent_link = parent._meta.get_ancestor_link(ancestor)
716             if parent_link:
717                 # In case of a proxied model, the first link
718                 # of the chain to the ancestor is that parent
719                 # links
720                 return self.parents[parent] or parent_link
721 
722     def get_path_to_parent(self, parent):
723         """
724         Return a list of PathInfos containing the path from the current
725         model to the parent model, or an empty list if parent is not a
726         parent of the current model.
727         """
728         if self.model is parent:
729             return []
730         # Skip the chain of proxy to the concrete proxied model.
731         proxied_model = self.concrete_model
732         path = []
733         opts = self
734         for int_model in self.get_base_chain(parent):
735             if int_model is proxied_model:
736                 opts = int_model._meta
737             else:
738                 final_field = opts.parents[int_model]
739                 targets = (final_field.remote_field.get_related_field(),)
740                 opts = int_model._meta
741                 path.append(
742                     PathInfo(
743                         from_opts=final_field.model._meta,
744                         to_opts=opts,
745                         target_fields=targets,
746                         join_field=final_field,
747                         m2m=False,
748                         direct=True,
749                         filtered_relation=None,
750                     )
751                 )
752         return path
753 
754     def get_path_from_parent(self, parent):
755         """
756         Return a list of PathInfos containing the path from the parent
757         model to the current model, or an empty list if parent is not a
758         parent of the current model.
759         """
760         if self.model is parent:
761             return []
762         model = self.concrete_model
763         # Get a reversed base chain including both the current and parent
764         # models.
765         chain = model._meta.get_base_chain(parent)
766         chain.reverse()
767         chain.append(model)
768         # Construct a list of the PathInfos between models in chain.
769         path = []
770         for i, ancestor in enumerate(chain[:-1]):
771             child = chain[i + 1]
772             link = child._meta.get_ancestor_link(ancestor)
773             path.extend(link.reverse_path_infos)
774         return path
775 
776     def _populate_directed_relation_graph(self):
777         """
778         This method is used by each model to find its reverse objects. As this
779         method is very expensive and is accessed frequently (it looks up every
780         field in a model, in every app), it is computed on first access and then
781         is set as a property on every model.
782         """
783         related_objects_graph = defaultdict(list)
784 
785         all_models = self.apps.get_models(include_auto_created=True)
786         for model in all_models:
787             opts = model._meta
788             # Abstract model's fields are copied to child models, hence we will
789             # see the fields from the child models.
790             if opts.abstract:
791                 continue
792             fields_with_relations = (
793                 f
794                 for f in opts._get_fields(reverse=False, include_parents=False)
795                 if f.is_relation and f.related_model is not None
796             )
797             for f in fields_with_relations:
798                 if not isinstance(f.remote_field.model, str):
799                     remote_label = f.remote_field.model._meta.concrete_model._meta.label
800                     related_objects_graph[remote_label].append(f)
801 
802         for model in all_models:
803             # Set the relation_tree using the internal __dict__. In this way
804             # we avoid calling the cached property. In attribute lookup,
805             # __dict__ takes precedence over a data descriptor (such as
806             # @cached_property). This means that the _meta._relation_tree is
807             # only called if related_objects is not in __dict__.
808             related_objects = related_objects_graph[
809                 model._meta.concrete_model._meta.label
810             ]
811             model._meta.__dict__["_relation_tree"] = related_objects
812         # It seems it is possible that self is not in all_models, so guard
813         # against that with default for get().
814         return self.__dict__.get("_relation_tree", EMPTY_RELATION_TREE)
815 
816     @cached_property
817     def _relation_tree(self):
818         return self._populate_directed_relation_graph()
819 
820     def _expire_cache(self, forward=True, reverse=True):
821         # This method is usually called by apps.cache_clear(), when the
822         # registry is finalized, or when a new field is added.
823         if forward:
824             for cache_key in self.FORWARD_PROPERTIES:
825                 if cache_key in self.__dict__:
826                     delattr(self, cache_key)
827         if reverse and not self.abstract:
828             for cache_key in self.REVERSE_PROPERTIES:
829                 if cache_key in self.__dict__:
830                     delattr(self, cache_key)
831         self._get_fields_cache = {}
832 
833     def get_fields(self, include_parents=True, include_hidden=False):
834         """
835         Return a list of fields associated to the model. By default, include
836         forward and reverse fields, fields derived from inheritance, but not
837         hidden fields. The returned fields can be changed using the parameters:
838 
839         - include_parents: include fields derived from inheritance
840         - include_hidden:  include fields that have a related_name that
841                            starts with a "+"
842         """
843         if include_parents is False:
844             include_parents = PROXY_PARENTS
845         return self._get_fields(
846             include_parents=include_parents, include_hidden=include_hidden
847         )
848 
849     def _get_fields(
850         self,
851         forward=True,
852         reverse=True,
853         include_parents=True,
854         include_hidden=False,
855         seen_models=None,
856     ):
857         """
858         Internal helper function to return fields of the model.
859         * If forward=True, then fields defined on this model are returned.
860         * If reverse=True, then relations pointing to this model are returned.
861         * If include_hidden=True, then fields with is_hidden=True are returned.
862         * The include_parents argument toggles if fields from parent models
863           should be included. It has three values: True, False, and
864           PROXY_PARENTS. When set to PROXY_PARENTS, the call will return all
865           fields defined for the current model or any of its parents in the
866           parent chain to the model's concrete model.
867         """
868         if include_parents not in (True, False, PROXY_PARENTS):
869             raise TypeError(
870                 "Invalid argument for include_parents: %s" % (include_parents,)
871             )
872         # This helper function is used to allow recursion in ``get_fields()``
873         # implementation and to provide a fast way for Django's internals to
874         # access specific subsets of fields.
875 
876         # We must keep track of which models we have already seen. Otherwise we
877         # could include the same field multiple times from different models.
878         topmost_call = seen_models is None
879         if topmost_call:
880             seen_models = set()
881         seen_models.add(self.model)
882 
883         # Creates a cache key composed of all arguments
884         cache_key = (forward, reverse, include_parents, include_hidden, topmost_call)
885 
886         try:
887             # In order to avoid list manipulation. Always return a shallow copy
888             # of the results.
889             return self._get_fields_cache[cache_key]
890         except KeyError:
891             pass
892 
893         fields = []
894         # Recursively call _get_fields() on each parent, with the same
895         # options provided in this call.
896         if include_parents is not False:
897             for parent in self.parents:
898                 # In diamond inheritance it is possible that we see the same
899                 # model from two different routes. In that case, avoid adding
900                 # fields from the same parent again.
901                 if parent in seen_models:
902                     continue
903                 if (
904                     parent._meta.concrete_model != self.concrete_model
905                     and include_parents == PROXY_PARENTS
906                 ):
907                     continue
908                 for obj in parent._meta._get_fields(
909                     forward=forward,
910                     reverse=reverse,
911                     include_parents=include_parents,
912                     include_hidden=include_hidden,
913                     seen_models=seen_models,
914                 ):
915                     if (
916                         not getattr(obj, "parent_link", False)
917                         or obj.model == self.concrete_model
918                     ):
919                         fields.append(obj)
920         if reverse and not self.proxy:
921             # Tree is computed once and cached until the app cache is expired.
922             # It is composed of a list of fields pointing to the current model
923             # from other models.
924             all_fields = self._relation_tree
925             for field in all_fields:
926                 # If hidden fields should be included or the relation is not
927                 # intentionally hidden, add to the fields dict.
928                 if include_hidden or not field.remote_field.hidden:
929                     fields.append(field.remote_field)
930 
931         if forward:
932             fields += self.local_fields
933             fields += self.local_many_to_many
934             # Private fields are recopied to each child model, and they get a
935             # different model as field.model in each child. Hence we have to
936             # add the private fields separately from the topmost call. If we
937             # did this recursively similar to local_fields, we would get field
938             # instances with field.model != self.model.
939             if topmost_call:
940                 fields += self.private_fields
941 
942         # In order to avoid list manipulation. Always
943         # return a shallow copy of the results
944         fields = make_immutable_fields_list("get_fields()", fields)
945 
946         # Store result into cache for later access
947         self._get_fields_cache[cache_key] = fields
948         return fields
949 
950     @cached_property
951     def total_unique_constraints(self):
952         """
953         Return a list of total unique constraints. Useful for determining set
954         of fields guaranteed to be unique for all rows.
955         """
956         return [
957             constraint
958             for constraint in self.constraints
959             if (
960                 isinstance(constraint, UniqueConstraint)
961                 and constraint.condition is None
962                 and not constraint.contains_expressions
963             )
964         ]
965 
966     @cached_property
967     def _property_names(self):
968         """Return a set of the names of the properties defined on the model."""
969         names = []
970         for name in dir(self.model):
971             attr = inspect.getattr_static(self.model, name)
972             if isinstance(attr, property):
973                 names.append(name)
974         return frozenset(names)
975 
976     @cached_property
977     def db_returning_fields(self):
978         """
979         Private API intended only to be used by Django itself.
980         Fields to be returned after a database insert.
981         """
982         return [
983             field
984             for field in self._get_fields(
985                 forward=True, reverse=False, include_parents=PROXY_PARENTS
986             )
987             if getattr(field, "db_returning", False)
988         ]

</code><intended_behavior>Ensure functionality parsing or utilizing `index_together` supports or migrates to `Model.Meta.indexes` with `Index` class, possibly showing deprecation warnings for `index_together`.</intended_behavior>, <file>django/db/migrations/autodetector.py</file>
<class>None</class>
<method>None</method>
<code>
1 import functools
2 import re
3 from collections import defaultdict
4 from itertools import chain
5 
6 from django.conf import settings
7 from django.db import models
8 from django.db.migrations import operations
9 from django.db.migrations.migration import Migration
10 from django.db.migrations.operations.models import AlterModelOptions
11 from django.db.migrations.optimizer import MigrationOptimizer
12 from django.db.migrations.questioner import MigrationQuestioner
13 from django.db.migrations.utils import (
14     COMPILED_REGEX_TYPE,
15     RegexObject,
16     resolve_relation,
17 )
18 from django.utils.topological_sort import stable_topological_sort
19 
20 
21 class MigrationAutodetector:
22     """
23     Take a pair of ProjectStates and compare them to see what the first would
24     need doing to make it match the second (the second usually being the
25     project's current state).
26 
27     Note that this naturally operates on entire projects at a time,
28     as it's likely that changes interact (for example, you can't
29     add a ForeignKey without having a migration to add the table it
30     depends on first). A user interface may offer single-app usage
31     if it wishes, with the caveat that it may not always be possible.
32     """
33 
34     def __init__(self, from_state, to_state, questioner=None):
35         self.from_state = from_state
36         self.to_state = to_state
37         self.questioner = questioner or MigrationQuestioner()
38         self.existing_apps = {app for app, model in from_state.models}
39 
40     def changes(self, graph, trim_to_apps=None, convert_apps=None, migration_name=None):
41         """
42         Main entry point to produce a list of applicable changes.
43         Take a graph to base names on and an optional set of apps
44         to try and restrict to (restriction is not guaranteed)
45         """
46         changes = self._detect_changes(convert_apps, graph)
47         changes = self.arrange_for_graph(changes, graph, migration_name)
48         if trim_to_apps:
49             changes = self._trim_to_apps(changes, trim_to_apps)
50         return changes
51 
52     def deep_deconstruct(self, obj):
53         """
54         Recursive deconstruction for a field and its arguments.
55         Used for full comparison for rename/alter; sometimes a single-level
56         deconstruction will not compare correctly.
57         """
58         if isinstance(obj, list):
59             return [self.deep_deconstruct(value) for value in obj]
60         elif isinstance(obj, tuple):
61             return tuple(self.deep_deconstruct(value) for value in obj)
62         elif isinstance(obj, dict):
63             return {key: self.deep_deconstruct(value) for key, value in obj.items()}
64         elif isinstance(obj, functools.partial):
65             return (
66                 obj.func,
67                 self.deep_deconstruct(obj.args),
68                 self.deep_deconstruct(obj.keywords),
69             )
70         elif isinstance(obj, COMPILED_REGEX_TYPE):
71             return RegexObject(obj)
72         elif isinstance(obj, type):
73             # If this is a type that implements 'deconstruct' as an instance method,
74             # avoid treating this as being deconstructible itself - see #22951
75             return obj
76         elif hasattr(obj, "deconstruct"):
77             deconstructed = obj.deconstruct()
78             if isinstance(obj, models.Field):
79                 # we have a field which also returns a name
80                 deconstructed = deconstructed[1:]
81             path, args, kwargs = deconstructed
82             return (
83                 path,
84                 [self.deep_deconstruct(value) for value in args],
85                 {key: self.deep_deconstruct(value) for key, value in kwargs.items()},
86             )
87         else:
88             return obj
89 
90     def only_relation_agnostic_fields(self, fields):
91         """
92         Return a definition of the fields that ignores field names and
93         what related fields actually relate to. Used for detecting renames (as
94         the related fields change during renames).
95         """
96         fields_def = []
97         for name, field in sorted(fields.items()):
98             deconstruction = self.deep_deconstruct(field)
99             if field.remote_field and field.remote_field.model:
100                 deconstruction[2].pop("to", None)
101             fields_def.append(deconstruction)
102         return fields_def
103 
104     def _detect_changes(self, convert_apps=None, graph=None):
105         """
106         Return a dict of migration plans which will achieve the
107         change from from_state to to_state. The dict has app labels
108         as keys and a list of migrations as values.
109 
110         The resulting migrations aren't specially named, but the names
111         do matter for dependencies inside the set.
112 
113         convert_apps is the list of apps to convert to use migrations
114         (i.e. to make initial migrations for, in the usual case)
115 
116         graph is an optional argument that, if provided, can help improve
117         dependency generation and avoid potential circular dependencies.
118         """
119         # The first phase is generating all the operations for each app
120         # and gathering them into a big per-app list.
121         # Then go through that list, order it, and split into migrations to
122         # resolve dependencies caused by M2Ms and FKs.
123         self.generated_operations = {}
124         self.altered_indexes = {}
125         self.altered_constraints = {}
126         self.renamed_fields = {}
127 
128         # Prepare some old/new state and model lists, separating
129         # proxy models and ignoring unmigrated apps.
130         self.old_model_keys = set()
131         self.old_proxy_keys = set()
132         self.old_unmanaged_keys = set()
133         self.new_model_keys = set()
134         self.new_proxy_keys = set()
135         self.new_unmanaged_keys = set()
136         for (app_label, model_name), model_state in self.from_state.models.items():
137             if not model_state.options.get("managed", True):
138                 self.old_unmanaged_keys.add((app_label, model_name))
139             elif app_label not in self.from_state.real_apps:
140                 if model_state.options.get("proxy"):
141                     self.old_proxy_keys.add((app_label, model_name))
142                 else:
143                     self.old_model_keys.add((app_label, model_name))
144 
145         for (app_label, model_name), model_state in self.to_state.models.items():
146             if not model_state.options.get("managed", True):
147                 self.new_unmanaged_keys.add((app_label, model_name))
148             elif app_label not in self.from_state.real_apps or (
149                 convert_apps and app_label in convert_apps
150             ):
151                 if model_state.options.get("proxy"):
152                     self.new_proxy_keys.add((app_label, model_name))
153                 else:
154                     self.new_model_keys.add((app_label, model_name))
155 
156         self.from_state.resolve_fields_and_relations()
157         self.to_state.resolve_fields_and_relations()
158 
159         # Renames have to come first
160         self.generate_renamed_models()
161 
162         # Prepare lists of fields and generate through model map
163         self._prepare_field_lists()
164         self._generate_through_model_map()
165 
166         # Generate non-rename model operations
167         self.generate_deleted_models()
168         self.generate_created_models()
169         self.generate_deleted_proxies()
170         self.generate_created_proxies()
171         self.generate_altered_options()
172         self.generate_altered_managers()
173 
174         # Create the renamed fields and store them in self.renamed_fields.
175         # They are used by create_altered_indexes(), generate_altered_fields(),
176         # generate_removed_altered_index/unique_together(), and
177         # generate_altered_index/unique_together().
178         self.create_renamed_fields()
179         # Create the altered indexes and store them in self.altered_indexes.
180         # This avoids the same computation in generate_removed_indexes()
181         # and generate_added_indexes().
182         self.create_altered_indexes()
183         self.create_altered_constraints()
184         # Generate index removal operations before field is removed
185         self.generate_removed_constraints()
186         self.generate_removed_indexes()
187         # Generate field renaming operations.
188         self.generate_renamed_fields()
189         self.generate_renamed_indexes()
190         # Generate removal of foo together.
191         self.generate_removed_altered_unique_together()
192         self.generate_removed_altered_index_together()
193         # Generate field operations.
194         self.generate_removed_fields()
195         self.generate_added_fields()
196         self.generate_altered_fields()
197         self.generate_altered_order_with_respect_to()
198         self.generate_altered_unique_together()
199         self.generate_altered_index_together()
200         self.generate_added_indexes()
201         self.generate_added_constraints()
202         self.generate_altered_db_table()
203 
204         self._sort_migrations()
205         self._build_migration_list(graph)
206         self._optimize_migrations()
207 
208         return self.migrations
209 
210     def _prepare_field_lists(self):
211         """
212         Prepare field lists and a list of the fields that used through models
213         in the old state so dependencies can be made from the through model
214         deletion to the field that uses it.
215         """
216         self.kept_model_keys = self.old_model_keys & self.new_model_keys
217         self.kept_proxy_keys = self.old_proxy_keys & self.new_proxy_keys
218         self.kept_unmanaged_keys = self.old_unmanaged_keys & self.new_unmanaged_keys
219         self.through_users = {}
220         self.old_field_keys = {
221             (app_label, model_name, field_name)
222             for app_label, model_name in self.kept_model_keys
223             for field_name in self.from_state.models[
224                 app_label, self.renamed_models.get((app_label, model_name), model_name)
225             ].fields
226         }
227         self.new_field_keys = {
228             (app_label, model_name, field_name)
229             for app_label, model_name in self.kept_model_keys
230             for field_name in self.to_state.models[app_label, model_name].fields
231         }
232 
233     def _generate_through_model_map(self):
234         """Through model map generation."""
235         for app_label, model_name in sorted(self.old_model_keys):
236             old_model_name = self.renamed_models.get(
237                 (app_label, model_name), model_name
238             )
239             old_model_state = self.from_state.models[app_label, old_model_name]
240             for field_name, field in old_model_state.fields.items():
241                 if hasattr(field, "remote_field") and getattr(
242                     field.remote_field, "through", None
243                 ):
244                     through_key = resolve_relation(
245                         field.remote_field.through, app_label, model_name
246                     )
247                     self.through_users[through_key] = (
248                         app_label,
249                         old_model_name,
250                         field_name,
251                     )
252 
253     @staticmethod
254     def _resolve_dependency(dependency):
255         """
256         Return the resolved dependency and a boolean denoting whether or not
257         it was swappable.
258         """
259         if dependency[0] != "__setting__":
260             return dependency, False
261         resolved_app_label, resolved_object_name = getattr(
262             settings, dependency[1]
263         ).split(".")
264         return (resolved_app_label, resolved_object_name.lower()) + dependency[2:], True
265 
266     def _build_migration_list(self, graph=None):
267         """
268         Chop the lists of operations up into migrations with dependencies on
269         each other. Do this by going through an app's list of operations until
270         one is found that has an outgoing dependency that isn't in another
271         app's migration yet (hasn't been chopped off its list). Then chop off
272         the operations before it into a migration and move onto the next app.
273         If the loops completes without doing anything, there's a circular
274         dependency (which _should_ be impossible as the operations are
275         all split at this point so they can't depend and be depended on).
276         """
277         self.migrations = {}
278         num_ops = sum(len(x) for x in self.generated_operations.values())
279         chop_mode = False
280         while num_ops:
281             # On every iteration, we step through all the apps and see if there
282             # is a completed set of operations.
283             # If we find that a subset of the operations are complete we can
284             # try to chop it off from the rest and continue, but we only
285             # do this if we've already been through the list once before
286             # without any chopping and nothing has changed.
287             for app_label in sorted(self.generated_operations):
288                 chopped = []
289                 dependencies = set()
290                 for operation in list(self.generated_operations[app_label]):
291                     deps_satisfied = True
292                     operation_dependencies = set()
293                     for dep in operation._auto_deps:
294                         # Temporarily resolve the swappable dependency to
295                         # prevent circular references. While keeping the
296                         # dependency checks on the resolved model, add the
297                         # swappable dependencies.
298                         original_dep = dep
299                         dep, is_swappable_dep = self._resolve_dependency(dep)
300                         if dep[0] != app_label:
301                             # External app dependency. See if it's not yet
302                             # satisfied.
303                             for other_operation in self.generated_operations.get(
304                                 dep[0], []
305                             ):
306                                 if self.check_dependency(other_operation, dep):
307                                     deps_satisfied = False
308                                     break
309                             if not deps_satisfied:
310                                 break
311                             else:
312                                 if is_swappable_dep:
313                                     operation_dependencies.add(
314                                         (original_dep[0], original_dep[1])
315                                     )
316                                 elif dep[0] in self.migrations:
317                                     operation_dependencies.add(
318                                         (dep[0], self.migrations[dep[0]][-1].name)
319                                     )
320                                 else:
321                                     # If we can't find the other app, we add a
322                                     # first/last dependency, but only if we've
323                                     # already been through once and checked
324                                     # everything.
325                                     if chop_mode:
326                                         # If the app already exists, we add a
327                                         # dependency on the last migration, as
328                                         # we don't know which migration
329                                         # contains the target field. If it's
330                                         # not yet migrated or has no
331                                         # migrations, we use __first__.
332                                         if graph and graph.leaf_nodes(dep[0]):
333                                             operation_dependencies.add(
334                                                 graph.leaf_nodes(dep[0])[0]
335                                             )
336                                         else:
337                                             operation_dependencies.add(
338                                                 (dep[0], "__first__")
339                                             )
340                                     else:
341                                         deps_satisfied = False
342                     if deps_satisfied:
343                         chopped.append(operation)
344                         dependencies.update(operation_dependencies)
345                         del self.generated_operations[app_label][0]
346                     else:
347                         break
348                 # Make a migration! Well, only if there's stuff to put in it
349                 if dependencies or chopped:
350                     if not self.generated_operations[app_label] or chop_mode:
351                         subclass = type(
352                             "Migration",
353                             (Migration,),
354                             {"operations": [], "dependencies": []},
355                         )
356                         instance = subclass(
357                             "auto_%i" % (len(self.migrations.get(app_label, [])) + 1),
358                             app_label,
359                         )
360                         instance.dependencies = list(dependencies)
361                         instance.operations = chopped
362                         instance.initial = app_label not in self.existing_apps
363                         self.migrations.setdefault(app_label, []).append(instance)
364                         chop_mode = False
365                     else:
366                         self.generated_operations[app_label] = (
367                             chopped + self.generated_operations[app_label]
368                         )
369             new_num_ops = sum(len(x) for x in self.generated_operations.values())
370             if new_num_ops == num_ops:
371                 if not chop_mode:
372                     chop_mode = True
373                 else:
374                     raise ValueError(
375                         "Cannot resolve operation dependencies: %r"
376                         % self.generated_operations
377                     )
378             num_ops = new_num_ops
379 
380     def _sort_migrations(self):
381         """
382         Reorder to make things possible. Reordering may be needed so FKs work
383         nicely inside the same app.
384         """
385         for app_label, ops in sorted(self.generated_operations.items()):
386             # construct a dependency graph for intra-app dependencies
387             dependency_graph = {op: set() for op in ops}
388             for op in ops:
389                 for dep in op._auto_deps:
390                     # Resolve intra-app dependencies to handle circular
391                     # references involving a swappable model.
392                     dep = self._resolve_dependency(dep)[0]
393                     if dep[0] == app_label:
394                         for op2 in ops:
395                             if self.check_dependency(op2, dep):
396                                 dependency_graph[op].add(op2)
397 
398             # we use a stable sort for deterministic tests & general behavior
399             self.generated_operations[app_label] = stable_topological_sort(
400                 ops, dependency_graph
401             )
402 
403     def _optimize_migrations(self):
404         # Add in internal dependencies among the migrations
405         for app_label, migrations in self.migrations.items():
406             for m1, m2 in zip(migrations, migrations[1:]):
407                 m2.dependencies.append((app_label, m1.name))
408 
409         # De-dupe dependencies
410         for migrations in self.migrations.values():
411             for migration in migrations:
412                 migration.dependencies = list(set(migration.dependencies))
413 
414         # Optimize migrations
415         for app_label, migrations in self.migrations.items():
416             for migration in migrations:
417                 migration.operations = MigrationOptimizer().optimize(
418                     migration.operations, app_label
419                 )
420 
421     def check_dependency(self, operation, dependency):
422         """
423         Return True if the given operation depends on the given dependency,
424         False otherwise.
425         """
426         # Created model
427         if dependency[2] is None and dependency[3] is True:
428             return (
429                 isinstance(operation, operations.CreateModel)
430                 and operation.name_lower == dependency[1].lower()
431             )
432         # Created field
433         elif dependency[2] is not None and dependency[3] is True:
434             return (
435                 isinstance(operation, operations.CreateModel)
436                 and operation.name_lower == dependency[1].lower()
437                 and any(dependency[2] == x for x, y in operation.fields)
438             ) or (
439                 isinstance(operation, operations.AddField)
440                 and operation.model_name_lower == dependency[1].lower()
441                 and operation.name_lower == dependency[2].lower()
442             )
443         # Removed field
444         elif dependency[2] is not None and dependency[3] is False:
445             return (
446                 isinstance(operation, operations.RemoveField)
447                 and operation.model_name_lower == dependency[1].lower()
448                 and operation.name_lower == dependency[2].lower()
449             )
450         # Removed model
451         elif dependency[2] is None and dependency[3] is False:
452             return (
453                 isinstance(operation, operations.DeleteModel)
454                 and operation.name_lower == dependency[1].lower()
455             )
456         # Field being altered
457         elif dependency[2] is not None and dependency[3] == "alter":
458             return (
459                 isinstance(operation, operations.AlterField)
460                 and operation.model_name_lower == dependency[1].lower()
461                 and operation.name_lower == dependency[2].lower()
462             )
463         # order_with_respect_to being unset for a field
464         elif dependency[2] is not None and dependency[3] == "order_wrt_unset":
465             return (
466                 isinstance(operation, operations.AlterOrderWithRespectTo)
467                 and operation.name_lower == dependency[1].lower()
468                 and (operation.order_with_respect_to or "").lower()
469                 != dependency[2].lower()
470             )
471         # Field is removed and part of an index/unique_together
472         elif dependency[2] is not None and dependency[3] == "foo_together_change":
473             return (
474                 isinstance(
475                     operation,
476                     (operations.AlterUniqueTogether, operations.AlterIndexTogether),
477                 )
478                 and operation.name_lower == dependency[1].lower()
479             )
480         # Unknown dependency. Raise an error.
481         else:
482             raise ValueError("Can't handle dependency %r" % (dependency,))
483 
484     def add_operation(self, app_label, operation, dependencies=None, beginning=False):
485         # Dependencies are
486         # (app_label, model_name, field_name, create/delete as True/False)
487         operation._auto_deps = dependencies or []
488         if beginning:
489             self.generated_operations.setdefault(app_label, []).insert(0, operation)
490         else:
491             self.generated_operations.setdefault(app_label, []).append(operation)
492 
493     def swappable_first_key(self, item):
494         """
495         Place potential swappable models first in lists of created models (only
496         real way to solve #22783).
497         """
498         try:
499             model_state = self.to_state.models[item]
500             base_names = {
501                 base if isinstance(base, str) else base.__name__
502                 for base in model_state.bases
503             }
504             string_version = "%s.%s" % (item[0], item[1])
505             if (
506                 model_state.options.get("swappable")
507                 or "AbstractUser" in base_names
508                 or "AbstractBaseUser" in base_names
509                 or settings.AUTH_USER_MODEL.lower() == string_version.lower()
510             ):
511                 return ("___" + item[0], "___" + item[1])
512         except LookupError:
513             pass
514         return item
515 
516     def generate_renamed_models(self):
517         """
518         Find any renamed models, generate the operations for them, and remove
519         the old entry from the model lists. Must be run before other
520         model-level generation.
521         """
522         self.renamed_models = {}
523         self.renamed_models_rel = {}
524         added_models = self.new_model_keys - self.old_model_keys
525         for app_label, model_name in sorted(added_models):
526             model_state = self.to_state.models[app_label, model_name]
527             model_fields_def = self.only_relation_agnostic_fields(model_state.fields)
528 
529             removed_models = self.old_model_keys - self.new_model_keys
530             for rem_app_label, rem_model_name in removed_models:
531                 if rem_app_label == app_label:
532                     rem_model_state = self.from_state.models[
533                         rem_app_label, rem_model_name
534                     ]
535                     rem_model_fields_def = self.only_relation_agnostic_fields(
536                         rem_model_state.fields
537                     )
538                     if model_fields_def == rem_model_fields_def:
539                         if self.questioner.ask_rename_model(
540                             rem_model_state, model_state
541                         ):
542                             dependencies = []
543                             fields = list(model_state.fields.values()) + [
544                                 field.remote_field
545                                 for relations in self.to_state.relations[
546                                     app_label, model_name
547                                 ].values()
548                                 for field in relations.values()
549                             ]
550                             for field in fields:
551                                 if field.is_relation:
552                                     dependencies.extend(
553                                         self._get_dependencies_for_foreign_key(
554                                             app_label,
555                                             model_name,
556                                             field,
557                                             self.to_state,
558                                         )
559                                     )
560                             self.add_operation(
561                                 app_label,
562                                 operations.RenameModel(
563                                     old_name=rem_model_state.name,
564                                     new_name=model_state.name,
565                                 ),
566                                 dependencies=dependencies,
567                             )
568                             self.renamed_models[app_label, model_name] = rem_model_name
569                             renamed_models_rel_key = "%s.%s" % (
570                                 rem_model_state.app_label,
571                                 rem_model_state.name_lower,
572                             )
573                             self.renamed_models_rel[
574                                 renamed_models_rel_key
575                             ] = "%s.%s" % (
576                                 model_state.app_label,
577                                 model_state.name_lower,
578                             )
579                             self.old_model_keys.remove((rem_app_label, rem_model_name))
580                             self.old_model_keys.add((app_label, model_name))
581                             break
582 
583     def generate_created_models(self):
584         """
585         Find all new models (both managed and unmanaged) and make create
586         operations for them as well as separate operations to create any
587         foreign key or M2M relationships (these are optimized later, if
588         possible).
589 
590         Defer any model options that refer to collections of fields that might
591         be deferred (e.g. unique_together, index_together).
592         """
593         old_keys = self.old_model_keys | self.old_unmanaged_keys
594         added_models = self.new_model_keys - old_keys
595         added_unmanaged_models = self.new_unmanaged_keys - old_keys
596         all_added_models = chain(
597             sorted(added_models, key=self.swappable_first_key, reverse=True),
598             sorted(added_unmanaged_models, key=self.swappable_first_key, reverse=True),
599         )
600         for app_label, model_name in all_added_models:
601             model_state = self.to_state.models[app_label, model_name]
602             # Gather related fields
603             related_fields = {}
604             primary_key_rel = None
605             for field_name, field in model_state.fields.items():
606                 if field.remote_field:
607                     if field.remote_field.model:
608                         if field.primary_key:
609                             primary_key_rel = field.remote_field.model
610                         elif not field.remote_field.parent_link:
611                             related_fields[field_name] = field
612                     if getattr(field.remote_field, "through", None):
613                         related_fields[field_name] = field
614 
615             # Are there indexes/unique|index_together to defer?
616             indexes = model_state.options.pop("indexes")
617             constraints = model_state.options.pop("constraints")
618             unique_together = model_state.options.pop("unique_together", None)
619             index_together = model_state.options.pop("index_together", None)
620             order_with_respect_to = model_state.options.pop(
621                 "order_with_respect_to", None
622             )
623             # Depend on the deletion of any possible proxy version of us
624             dependencies = [
625                 (app_label, model_name, None, False),
626             ]
627             # Depend on all bases
628             for base in model_state.bases:
629                 if isinstance(base, str) and "." in base:
630                     base_app_label, base_name = base.split(".", 1)
631                     dependencies.append((base_app_label, base_name, None, True))
632                     # Depend on the removal of base fields if the new model has
633                     # a field with the same name.
634                     old_base_model_state = self.from_state.models.get(
635                         (base_app_label, base_name)
636                     )
637                     new_base_model_state = self.to_state.models.get(
638                         (base_app_label, base_name)
639                     )
640                     if old_base_model_state and new_base_model_state:
641                         removed_base_fields = (
642                             set(old_base_model_state.fields)
643                             .difference(
644                                 new_base_model_state.fields,
645                             )
646                             .intersection(model_state.fields)
647                         )
648                         for removed_base_field in removed_base_fields:
649                             dependencies.append(
650                                 (base_app_label, base_name, removed_base_field, False)
651                             )
652             # Depend on the other end of the primary key if it's a relation
653             if primary_key_rel:
654                 dependencies.append(
655                     resolve_relation(
656                         primary_key_rel,
657                         app_label,
658                         model_name,
659                     )
660                     + (None, True)
661                 )
662             # Generate creation operation
663             self.add_operation(
664                 app_label,
665                 operations.CreateModel(
666                     name=model_state.name,
667                     fields=[
668                         d
669                         for d in model_state.fields.items()
670                         if d[0] not in related_fields
671                     ],
672                     options=model_state.options,
673                     bases=model_state.bases,
674                     managers=model_state.managers,
675                 ),
676                 dependencies=dependencies,
677                 beginning=True,
678             )
679 
680             # Don't add operations which modify the database for unmanaged models
681             if not model_state.options.get("managed", True):
682                 continue
683 
684             # Generate operations for each related field
685             for name, field in sorted(related_fields.items()):
686                 dependencies = self._get_dependencies_for_foreign_key(
687                     app_label,
688                     model_name,
689                     field,
690                     self.to_state,
691                 )
692                 # Depend on our own model being created
693                 dependencies.append((app_label, model_name, None, True))
694                 # Make operation
695                 self.add_operation(
696                     app_label,
697                     operations.AddField(
698                         model_name=model_name,
699                         name=name,
700                         field=field,
701                     ),
702                     dependencies=list(set(dependencies)),
703                 )
704             # Generate other opns
705             if order_with_respect_to:
706                 self.add_operation(
707                     app_label,
708                     operations.AlterOrderWithRespectTo(
709                         name=model_name,
710                         order_with_respect_to=order_with_respect_to,
711                     ),
712                     dependencies=[
713                         (app_label, model_name, order_with_respect_to, True),
714                         (app_label, model_name, None, True),
715                     ],
716                 )
717             related_dependencies = [
718                 (app_label, model_name, name, True) for name in sorted(related_fields)
719             ]
720             related_dependencies.append((app_label, model_name, None, True))
721             for index in indexes:
722                 self.add_operation(
723                     app_label,
724                     operations.AddIndex(
725                         model_name=model_name,
726                         index=index,
727                     ),
728                     dependencies=related_dependencies,
729                 )
730             for constraint in constraints:
731                 self.add_operation(
732                     app_label,
733                     operations.AddConstraint(
734                         model_name=model_name,
735                         constraint=constraint,
736                     ),
737                     dependencies=related_dependencies,
738                 )
739             if unique_together:
740                 self.add_operation(
741                     app_label,
742                     operations.AlterUniqueTogether(
743                         name=model_name,
744                         unique_together=unique_together,
745                     ),
746                     dependencies=related_dependencies,
747                 )
748             if index_together:
749                 self.add_operation(
750                     app_label,
751                     operations.AlterIndexTogether(
752                         name=model_name,
753                         index_together=index_together,
754                     ),
755                     dependencies=related_dependencies,
756                 )
757             # Fix relationships if the model changed from a proxy model to a
758             # concrete model.
759             relations = self.to_state.relations
760             if (app_label, model_name) in self.old_proxy_keys:
761                 for related_model_key, related_fields in relations[
762                     app_label, model_name
763                 ].items():
764                     related_model_state = self.to_state.models[related_model_key]
765                     for related_field_name, related_field in related_fields.items():
766                         self.add_operation(
767                             related_model_state.app_label,
768                             operations.AlterField(
769                                 model_name=related_model_state.name,
770                                 name=related_field_name,
771                                 field=related_field,
772                             ),
773                             dependencies=[(app_label, model_name, None, True)],
774                         )
775 
776     def generate_created_proxies(self):
777         """
778         Make CreateModel statements for proxy models. Use the same statements
779         as that way there's less code duplication, but for proxy models it's
780         safe to skip all the pointless field stuff and chuck out an operation.
781         """
782         added = self.new_proxy_keys - self.old_proxy_keys
783         for app_label, model_name in sorted(added):
784             model_state = self.to_state.models[app_label, model_name]
785             assert model_state.options.get("proxy")
786             # Depend on the deletion of any possible non-proxy version of us
787             dependencies = [
788                 (app_label, model_name, None, False),
789             ]
790             # Depend on all bases
791             for base in model_state.bases:
792                 if isinstance(base, str) and "." in base:
793                     base_app_label, base_name = base.split(".", 1)
794                     dependencies.append((base_app_label, base_name, None, True))
795             # Generate creation operation
796             self.add_operation(
797                 app_label,
798                 operations.CreateModel(
799                     name=model_state.name,
800                     fields=[],
801                     options=model_state.options,
802                     bases=model_state.bases,
803                     managers=model_state.managers,
804                 ),
805                 # Depend on the deletion of any possible non-proxy version of us
806                 dependencies=dependencies,
807             )
808 
809     def generate_deleted_models(self):
810         """
811         Find all deleted models (managed and unmanaged) and make delete
812         operations for them as well as separate operations to delete any
813         foreign key or M2M relationships (these are optimized later, if
814         possible).
815 
816         Also bring forward removal of any model options that refer to
817         collections of fields - the inverse of generate_created_models().
818         """
819         new_keys = self.new_model_keys | self.new_unmanaged_keys
820         deleted_models = self.old_model_keys - new_keys
821         deleted_unmanaged_models = self.old_unmanaged_keys - new_keys
822         all_deleted_models = chain(
823             sorted(deleted_models), sorted(deleted_unmanaged_models)
824         )
825         for app_label, model_name in all_deleted_models:
826             model_state = self.from_state.models[app_label, model_name]
827             # Gather related fields
828             related_fields = {}
829             for field_name, field in model_state.fields.items():
830                 if field.remote_field:
831                     if field.remote_field.model:
832                         related_fields[field_name] = field
833                     if getattr(field.remote_field, "through", None):
834                         related_fields[field_name] = field
835             # Generate option removal first
836             unique_together = model_state.options.pop("unique_together", None)
837             index_together = model_state.options.pop("index_together", None)
838             if unique_together:
839                 self.add_operation(
840                     app_label,
841                     operations.AlterUniqueTogether(
842                         name=model_name,
843                         unique_together=None,
844                     ),
845                 )
846             if index_together:
847                 self.add_operation(
848                     app_label,
849                     operations.AlterIndexTogether(
850                         name=model_name,
851                         index_together=None,
852                     ),
853                 )
854             # Then remove each related field
855             for name in sorted(related_fields):
856                 self.add_operation(
857                     app_label,
858                     operations.RemoveField(
859                         model_name=model_name,
860                         name=name,
861                     ),
862                 )
863             # Finally, remove the model.
864             # This depends on both the removal/alteration of all incoming fields
865             # and the removal of all its own related fields, and if it's
866             # a through model the field that references it.
867             dependencies = []
868             relations = self.from_state.relations
869             for (
870                 related_object_app_label,
871                 object_name,
872             ), relation_related_fields in relations[app_label, model_name].items():
873                 for field_name, field in relation_related_fields.items():
874                     dependencies.append(
875                         (related_object_app_label, object_name, field_name, False),
876                     )
877                     if not field.many_to_many:
878                         dependencies.append(
879                             (
880                                 related_object_app_label,
881                                 object_name,
882                                 field_name,
883                                 "alter",
884                             ),
885                         )
886 
887             for name in sorted(related_fields):
888                 dependencies.append((app_label, model_name, name, False))
889             # We're referenced in another field's through=
890             through_user = self.through_users.get((app_label, model_state.name_lower))
891             if through_user:
892                 dependencies.append(
893                     (through_user[0], through_user[1], through_user[2], False)
894                 )
895             # Finally, make the operation, deduping any dependencies
896             self.add_operation(
897                 app_label,
898                 operations.DeleteModel(
899                     name=model_state.name,
900                 ),
901                 dependencies=list(set(dependencies)),
902             )
903 
904     def generate_deleted_proxies(self):
905         """Make DeleteModel options for proxy models."""
906         deleted = self.old_proxy_keys - self.new_proxy_keys
907         for app_label, model_name in sorted(deleted):
908             model_state = self.from_state.models[app_label, model_name]
909             assert model_state.options.get("proxy")
910             self.add_operation(
911                 app_label,
912                 operations.DeleteModel(
913                     name=model_state.name,
914                 ),
915             )
916 
917     def create_renamed_fields(self):
918         """Work out renamed fields."""
919         self.renamed_operations = []
920         old_field_keys = self.old_field_keys.copy()
921         for app_label, model_name, field_name in sorted(
922             self.new_field_keys - old_field_keys
923         ):
924             old_model_name = self.renamed_models.get(
925                 (app_label, model_name), model_name
926             )
927             old_model_state = self.from_state.models[app_label, old_model_name]
928             new_model_state = self.to_state.models[app_label, model_name]
929             field = new_model_state.get_field(field_name)
930             # Scan to see if this is actually a rename!
931             field_dec = self.deep_deconstruct(field)
932             for rem_app_label, rem_model_name, rem_field_name in sorted(
933                 old_field_keys - self.new_field_keys
934             ):
935                 if rem_app_label == app_label and rem_model_name == model_name:
936                     old_field = old_model_state.get_field(rem_field_name)
937                     old_field_dec = self.deep_deconstruct(old_field)
938                     if (
939                         field.remote_field
940                         and field.remote_field.model
941                         and "to" in old_field_dec[2]
942                     ):
943                         old_rel_to = old_field_dec[2]["to"]
944                         if old_rel_to in self.renamed_models_rel:
945                             old_field_dec[2]["to"] = self.renamed_models_rel[old_rel_to]
946                     old_field.set_attributes_from_name(rem_field_name)
947                     old_db_column = old_field.get_attname_column()[1]
948                     if old_field_dec == field_dec or (
949                         # Was the field renamed and db_column equal to the
950                         # old field's column added?
951                         old_field_dec[0:2] == field_dec[0:2]
952                         and dict(old_field_dec[2], db_column=old_db_column)
953                         == field_dec[2]
954                     ):
955                         if self.questioner.ask_rename(
956                             model_name, rem_field_name, field_name, field
957                         ):
958                             self.renamed_operations.append(
959                                 (
960                                     rem_app_label,
961                                     rem_model_name,
962                                     old_field.db_column,
963                                     rem_field_name,
964                                     app_label,
965                                     model_name,
966                                     field,
967                                     field_name,
968                                 )
969                             )
970                             old_field_keys.remove(
971                                 (rem_app_label, rem_model_name, rem_field_name)
972                             )
973                             old_field_keys.add((app_label, model_name, field_name))
974                             self.renamed_fields[
975                                 app_label, model_name, field_name
976                             ] = rem_field_name
977                             break
978 
979     def generate_renamed_fields(self):
980         """Generate RenameField operations."""
981         for (
982             rem_app_label,
983             rem_model_name,
984             rem_db_column,
985             rem_field_name,
986             app_label,
987             model_name,
988             field,
989             field_name,
990         ) in self.renamed_operations:
991             # A db_column mismatch requires a prior noop AlterField for the
992             # subsequent RenameField to be a noop on attempts at preserving the
993             # old name.
994             if rem_db_column != field.db_column:
995                 altered_field = field.clone()
996                 altered_field.name = rem_field_name
997                 self.add_operation(
998                     app_label,
999                     operations.AlterField(
1000                         model_name=model_name,
1001                         name=rem_field_name,
1002                         field=altered_field,
1003                     ),
1004                 )
1005             self.add_operation(
1006                 app_label,
1007                 operations.RenameField(
1008                     model_name=model_name,
1009                     old_name=rem_field_name,
1010                     new_name=field_name,
1011                 ),
1012             )
1013             self.old_field_keys.remove((rem_app_label, rem_model_name, rem_field_name))
1014             self.old_field_keys.add((app_label, model_name, field_name))
1015 
1016     def generate_added_fields(self):
1017         """Make AddField operations."""
1018         for app_label, model_name, field_name in sorted(
1019             self.new_field_keys - self.old_field_keys
1020         ):
1021             self._generate_added_field(app_label, model_name, field_name)
1022 
1023     def _generate_added_field(self, app_label, model_name, field_name):
1024         field = self.to_state.models[app_label, model_name].get_field(field_name)
1025         # Adding a field always depends at least on its removal.
1026         dependencies = [(app_label, model_name, field_name, False)]
1027         # Fields that are foreignkeys/m2ms depend on stuff.
1028         if field.remote_field and field.remote_field.model:
1029             dependencies.extend(
1030                 self._get_dependencies_for_foreign_key(
1031                     app_label,
1032                     model_name,
1033                     field,
1034                     self.to_state,
1035                 )
1036             )
1037         # You can't just add NOT NULL fields with no default or fields
1038         # which don't allow empty strings as default.
1039         time_fields = (models.DateField, models.DateTimeField, models.TimeField)
1040         preserve_default = (
1041             field.null
1042             or field.has_default()
1043             or field.many_to_many
1044             or (field.blank and field.empty_strings_allowed)
1045             or (isinstance(field, time_fields) and field.auto_now)
1046         )
1047         if not preserve_default:
1048             field = field.clone()
1049             if isinstance(field, time_fields) and field.auto_now_add:
1050                 field.default = self.questioner.ask_auto_now_add_addition(
1051                     field_name, model_name
1052                 )
1053             else:
1054                 field.default = self.questioner.ask_not_null_addition(
1055                     field_name, model_name
1056                 )
1057         if (
1058             field.unique
1059             and field.default is not models.NOT_PROVIDED
1060             and callable(field.default)
1061         ):
1062             self.questioner.ask_unique_callable_default_addition(field_name, model_name)
1063         self.add_operation(
1064             app_label,
1065             operations.AddField(
1066                 model_name=model_name,
1067                 name=field_name,
1068                 field=field,
1069                 preserve_default=preserve_default,
1070             ),
1071             dependencies=dependencies,
1072         )
1073 
1074     def generate_removed_fields(self):
1075         """Make RemoveField operations."""
1076         for app_label, model_name, field_name in sorted(
1077             self.old_field_keys - self.new_field_keys
1078         ):
1079             self._generate_removed_field(app_label, model_name, field_name)
1080 
1081     def _generate_removed_field(self, app_label, model_name, field_name):
1082         self.add_operation(
1083             app_label,
1084             operations.RemoveField(
1085                 model_name=model_name,
1086                 name=field_name,
1087             ),
1088             # We might need to depend on the removal of an
1089             # order_with_respect_to or index/unique_together operation;
1090             # this is safely ignored if there isn't one
1091             dependencies=[
1092                 (app_label, model_name, field_name, "order_wrt_unset"),
1093                 (app_label, model_name, field_name, "foo_together_change"),
1094             ],
1095         )
1096 
1097     def generate_altered_fields(self):
1098         """
1099         Make AlterField operations, or possibly RemovedField/AddField if alter
1100         isn't possible.
1101         """
1102         for app_label, model_name, field_name in sorted(
1103             self.old_field_keys & self.new_field_keys
1104         ):
1105             # Did the field change?
1106             old_model_name = self.renamed_models.get(
1107                 (app_label, model_name), model_name
1108             )
1109             old_field_name = self.renamed_fields.get(
1110                 (app_label, model_name, field_name), field_name
1111             )
1112             old_field = self.from_state.models[app_label, old_model_name].get_field(
1113                 old_field_name
1114             )
1115             new_field = self.to_state.models[app_label, model_name].get_field(
1116                 field_name
1117             )
1118             dependencies = []
1119             # Implement any model renames on relations; these are handled by RenameModel
1120             # so we need to exclude them from the comparison
1121             if hasattr(new_field, "remote_field") and getattr(
1122                 new_field.remote_field, "model", None
1123             ):
1124                 rename_key = resolve_relation(
1125                     new_field.remote_field.model, app_label, model_name
1126                 )
1127                 if rename_key in self.renamed_models:
1128                     new_field.remote_field.model = old_field.remote_field.model
1129                 # Handle ForeignKey which can only have a single to_field.
1130                 remote_field_name = getattr(new_field.remote_field, "field_name", None)
1131                 if remote_field_name:
1132                     to_field_rename_key = rename_key + (remote_field_name,)
1133                     if to_field_rename_key in self.renamed_fields:
1134                         # Repoint both model and field name because to_field
1135                         # inclusion in ForeignKey.deconstruct() is based on
1136                         # both.
1137                         new_field.remote_field.model = old_field.remote_field.model
1138                         new_field.remote_field.field_name = (
1139                             old_field.remote_field.field_name
1140                         )
1141                 # Handle ForeignObjects which can have multiple from_fields/to_fields.
1142                 from_fields = getattr(new_field, "from_fields", None)
1143                 if from_fields:
1144                     from_rename_key = (app_label, model_name)
1145                     new_field.from_fields = tuple(
1146                         [
1147                             self.renamed_fields.get(
1148                                 from_rename_key + (from_field,), from_field
1149                             )
1150                             for from_field in from_fields
1151                         ]
1152                     )
1153                     new_field.to_fields = tuple(
1154                         [
1155                             self.renamed_fields.get(rename_key + (to_field,), to_field)
1156                             for to_field in new_field.to_fields
1157                         ]
1158                     )
1159                 dependencies.extend(
1160                     self._get_dependencies_for_foreign_key(
1161                         app_label,
1162                         model_name,
1163                         new_field,
1164                         self.to_state,
1165                     )
1166                 )
1167             if hasattr(new_field, "remote_field") and getattr(
1168                 new_field.remote_field, "through", None
1169             ):
1170                 rename_key = resolve_relation(
1171                     new_field.remote_field.through, app_label, model_name
1172                 )
1173                 if rename_key in self.renamed_models:
1174                     new_field.remote_field.through = old_field.remote_field.through
1175             old_field_dec = self.deep_deconstruct(old_field)
1176             new_field_dec = self.deep_deconstruct(new_field)
1177             # If the field was confirmed to be renamed it means that only
1178             # db_column was allowed to change which generate_renamed_fields()
1179             # already accounts for by adding an AlterField operation.
1180             if old_field_dec != new_field_dec and old_field_name == field_name:
1181                 both_m2m = old_field.many_to_many and new_field.many_to_many
1182                 neither_m2m = not old_field.many_to_many and not new_field.many_to_many
1183                 if both_m2m or neither_m2m:
1184                     # Either both fields are m2m or neither is
1185                     preserve_default = True
1186                     if (
1187                         old_field.null
1188                         and not new_field.null
1189                         and not new_field.has_default()
1190                         and not new_field.many_to_many
1191                     ):
1192                         field = new_field.clone()
1193                         new_default = self.questioner.ask_not_null_alteration(
1194                             field_name, model_name
1195                         )
1196                         if new_default is not models.NOT_PROVIDED:
1197                             field.default = new_default
1198                             preserve_default = False
1199                     else:
1200                         field = new_field
1201                     self.add_operation(
1202                         app_label,
1203                         operations.AlterField(
1204                             model_name=model_name,
1205                             name=field_name,
1206                             field=field,
1207                             preserve_default=preserve_default,
1208                         ),
1209                         dependencies=dependencies,
1210                     )
1211                 else:
1212                     # We cannot alter between m2m and concrete fields
1213                     self._generate_removed_field(app_label, model_name, field_name)
1214                     self._generate_added_field(app_label, model_name, field_name)
1215 
1216     def create_altered_indexes(self):
1217         option_name = operations.AddIndex.option_name
1218         self.renamed_index_together_values = defaultdict(list)
1219 
1220         for app_label, model_name in sorted(self.kept_model_keys):
1221             old_model_name = self.renamed_models.get(
1222                 (app_label, model_name), model_name
1223             )
1224             old_model_state = self.from_state.models[app_label, old_model_name]
1225             new_model_state = self.to_state.models[app_label, model_name]
1226 
1227             old_indexes = old_model_state.options[option_name]
1228             new_indexes = new_model_state.options[option_name]
1229             added_indexes = [idx for idx in new_indexes if idx not in old_indexes]
1230             removed_indexes = [idx for idx in old_indexes if idx not in new_indexes]
1231             renamed_indexes = []
1232             # Find renamed indexes.
1233             remove_from_added = []
1234             remove_from_removed = []
1235             for new_index in added_indexes:
1236                 new_index_dec = new_index.deconstruct()
1237                 new_index_name = new_index_dec[2].pop("name")
1238                 for old_index in removed_indexes:
1239                     old_index_dec = old_index.deconstruct()
1240                     old_index_name = old_index_dec[2].pop("name")
1241                     # Indexes are the same except for the names.
1242                     if (
1243                         new_index_dec == old_index_dec
1244                         and new_index_name != old_index_name
1245                     ):
1246                         renamed_indexes.append((old_index_name, new_index_name, None))
1247                         remove_from_added.append(new_index)
1248                         remove_from_removed.append(old_index)
1249             # Find index_together changed to indexes.
1250             for (
1251                 old_value,
1252                 new_value,
1253                 index_together_app_label,
1254                 index_together_model_name,
1255                 dependencies,
1256             ) in self._get_altered_foo_together_operations(
1257                 operations.AlterIndexTogether.option_name
1258             ):
1259                 if (
1260                     app_label != index_together_app_label
1261                     or model_name != index_together_model_name
1262                 ):
1263                     continue
1264                 removed_values = old_value.difference(new_value)
1265                 for removed_index_together in removed_values:
1266                     renamed_index_together_indexes = []
1267                     for new_index in added_indexes:
1268                         _, args, kwargs = new_index.deconstruct()
1269                         # Ensure only 'fields' are defined in the Index.
1270                         if (
1271                             not args
1272                             and new_index.fields == list(removed_index_together)
1273                             and set(kwargs) == {"name", "fields"}
1274                         ):
1275                             renamed_index_together_indexes.append(new_index)
1276 
1277                     if len(renamed_index_together_indexes) == 1:
1278                         renamed_index = renamed_index_together_indexes[0]
1279                         remove_from_added.append(renamed_index)
1280                         renamed_indexes.append(
1281                             (None, renamed_index.name, removed_index_together)
1282                         )
1283                         self.renamed_index_together_values[
1284                             index_together_app_label, index_together_model_name
1285                         ].append(removed_index_together)
1286             # Remove renamed indexes from the lists of added and removed
1287             # indexes.
1288             added_indexes = [
1289                 idx for idx in added_indexes if idx not in remove_from_added
1290             ]
1291             removed_indexes = [
1292                 idx for idx in removed_indexes if idx not in remove_from_removed
1293             ]
1294 
1295             self.altered_indexes.update(
1296                 {
1297                     (app_label, model_name): {
1298                         "added_indexes": added_indexes,
1299                         "removed_indexes": removed_indexes,
1300                         "renamed_indexes": renamed_indexes,
1301                     }
1302                 }
1303             )
1304 
1305     def generate_added_indexes(self):
1306         for (app_label, model_name), alt_indexes in self.altered_indexes.items():
1307             for index in alt_indexes["added_indexes"]:
1308                 self.add_operation(
1309                     app_label,
1310                     operations.AddIndex(
1311                         model_name=model_name,
1312                         index=index,
1313                     ),
1314                 )
1315 
1316     def generate_removed_indexes(self):
1317         for (app_label, model_name), alt_indexes in self.altered_indexes.items():
1318             for index in alt_indexes["removed_indexes"]:
1319                 self.add_operation(
1320                     app_label,
1321                     operations.RemoveIndex(
1322                         model_name=model_name,
1323                         name=index.name,
1324                     ),
1325                 )
1326 
1327     def generate_renamed_indexes(self):
1328         for (app_label, model_name), alt_indexes in self.altered_indexes.items():
1329             for old_index_name, new_index_name, old_fields in alt_indexes[
1330                 "renamed_indexes"
1331             ]:
1332                 self.add_operation(
1333                     app_label,
1334                     operations.RenameIndex(
1335                         model_name=model_name,
1336                         new_name=new_index_name,
1337                         old_name=old_index_name,
1338                         old_fields=old_fields,
1339                     ),
1340                 )
1341 
1342     def create_altered_constraints(self):
1343         option_name = operations.AddConstraint.option_name
1344         for app_label, model_name in sorted(self.kept_model_keys):
1345             old_model_name = self.renamed_models.get(
1346                 (app_label, model_name), model_name
1347             )
1348             old_model_state = self.from_state.models[app_label, old_model_name]
1349             new_model_state = self.to_state.models[app_label, model_name]
1350 
1351             old_constraints = old_model_state.options[option_name]
1352             new_constraints = new_model_state.options[option_name]
1353             add_constraints = [c for c in new_constraints if c not in old_constraints]
1354             rem_constraints = [c for c in old_constraints if c not in new_constraints]
1355 
1356             self.altered_constraints.update(
1357                 {
1358                     (app_label, model_name): {
1359                         "added_constraints": add_constraints,
1360                         "removed_constraints": rem_constraints,
1361                     }
1362                 }
1363             )
1364 
1365     def generate_added_constraints(self):
1366         for (
1367             app_label,
1368             model_name,
1369         ), alt_constraints in self.altered_constraints.items():
1370             for constraint in alt_constraints["added_constraints"]:
1371                 self.add_operation(
1372                     app_label,
1373                     operations.AddConstraint(
1374                         model_name=model_name,
1375                         constraint=constraint,
1376                     ),
1377                 )
1378 
1379     def generate_removed_constraints(self):
1380         for (
1381             app_label,
1382             model_name,
1383         ), alt_constraints in self.altered_constraints.items():
1384             for constraint in alt_constraints["removed_constraints"]:
1385                 self.add_operation(
1386                     app_label,
1387                     operations.RemoveConstraint(
1388                         model_name=model_name,
1389                         name=constraint.name,
1390                     ),
1391                 )
1392 
1393     @staticmethod
1394     def _get_dependencies_for_foreign_key(app_label, model_name, field, project_state):
1395         remote_field_model = None
1396         if hasattr(field.remote_field, "model"):
1397             remote_field_model = field.remote_field.model
1398         else:
1399             relations = project_state.relations[app_label, model_name]
1400             for (remote_app_label, remote_model_name), fields in relations.items():
1401                 if any(
1402                     field == related_field.remote_field
1403                     for related_field in fields.values()
1404                 ):
1405                     remote_field_model = f"{remote_app_label}.{remote_model_name}"
1406                     break
1407         # Account for FKs to swappable models
1408         swappable_setting = getattr(field, "swappable_setting", None)
1409         if swappable_setting is not None:
1410             dep_app_label = "__setting__"
1411             dep_object_name = swappable_setting
1412         else:
1413             dep_app_label, dep_object_name = resolve_relation(
1414                 remote_field_model,
1415                 app_label,
1416                 model_name,
1417             )
1418         dependencies = [(dep_app_label, dep_object_name, None, True)]
1419         if getattr(field.remote_field, "through", None):
1420             through_app_label, through_object_name = resolve_relation(
1421                 remote_field_model,
1422                 app_label,
1423                 model_name,
1424             )
1425             dependencies.append((through_app_label, through_object_name, None, True))
1426         return dependencies
1427 
1428     def _get_altered_foo_together_operations(self, option_name):
1429         for app_label, model_name in sorted(self.kept_model_keys):
1430             old_model_name = self.renamed_models.get(
1431                 (app_label, model_name), model_name
1432             )
1433             old_model_state = self.from_state.models[app_label, old_model_name]
1434             new_model_state = self.to_state.models[app_label, model_name]
1435 
1436             # We run the old version through the field renames to account for those
1437             old_value = old_model_state.options.get(option_name)
1438             old_value = (
1439                 {
1440                     tuple(
1441                         self.renamed_fields.get((app_label, model_name, n), n)
1442                         for n in unique
1443                     )
1444                     for unique in old_value
1445                 }
1446                 if old_value
1447                 else set()
1448             )
1449 
1450             new_value = new_model_state.options.get(option_name)
1451             new_value = set(new_value) if new_value else set()
1452 
1453             if old_value != new_value:
1454                 dependencies = []
1455                 for foo_togethers in new_value:
1456                     for field_name in foo_togethers:
1457                         field = new_model_state.get_field(field_name)
1458                         if field.remote_field and field.remote_field.model:
1459                             dependencies.extend(
1460                                 self._get_dependencies_for_foreign_key(
1461                                     app_label,
1462                                     model_name,
1463                                     field,
1464                                     self.to_state,
1465                                 )
1466                             )
1467                 yield (
1468                     old_value,
1469                     new_value,
1470                     app_label,
1471                     model_name,
1472                     dependencies,
1473                 )
1474 
1475     def _generate_removed_altered_foo_together(self, operation):
1476         for (
1477             old_value,
1478             new_value,
1479             app_label,
1480             model_name,
1481             dependencies,
1482         ) in self._get_altered_foo_together_operations(operation.option_name):
1483             if operation == operations.AlterIndexTogether:
1484                 old_value = {
1485                     value
1486                     for value in old_value
1487                     if value
1488                     not in self.renamed_index_together_values[app_label, model_name]
1489                 }
1490             removal_value = new_value.intersection(old_value)
1491             if removal_value or old_value:
1492                 self.add_operation(
1493                     app_label,
1494                     operation(
1495                         name=model_name, **{operation.option_name: removal_value}
1496                     ),
1497                     dependencies=dependencies,
1498                 )
1499 
1500     def generate_removed_altered_unique_together(self):
1501         self._generate_removed_altered_foo_together(operations.AlterUniqueTogether)
1502 
1503     def generate_removed_altered_index_together(self):
1504         self._generate_removed_altered_foo_together(operations.AlterIndexTogether)
1505 
1506     def _generate_altered_foo_together(self, operation):
1507         for (
1508             old_value,
1509             new_value,
1510             app_label,
1511             model_name,
1512             dependencies,
1513         ) in self._get_altered_foo_together_operations(operation.option_name):
1514             removal_value = new_value.intersection(old_value)
1515             if new_value != removal_value:
1516                 self.add_operation(
1517                     app_label,
1518                     operation(name=model_name, **{operation.option_name: new_value}),
1519                     dependencies=dependencies,
1520                 )
1521 
1522     def generate_altered_unique_together(self):
1523         self._generate_altered_foo_together(operations.AlterUniqueTogether)
1524 
1525     def generate_altered_index_together(self):
1526         self._generate_altered_foo_together(operations.AlterIndexTogether)
1527 
1528     def generate_altered_db_table(self):
1529         models_to_check = self.kept_model_keys.union(
1530             self.kept_proxy_keys, self.kept_unmanaged_keys
1531         )
1532         for app_label, model_name in sorted(models_to_check):
1533             old_model_name = self.renamed_models.get(
1534                 (app_label, model_name), model_name
1535             )
1536             old_model_state = self.from_state.models[app_label, old_model_name]
1537             new_model_state = self.to_state.models[app_label, model_name]
1538             old_db_table_name = old_model_state.options.get("db_table")
1539             new_db_table_name = new_model_state.options.get("db_table")
1540             if old_db_table_name != new_db_table_name:
1541                 self.add_operation(
1542                     app_label,
1543                     operations.AlterModelTable(
1544                         name=model_name,
1545                         table=new_db_table_name,
1546                     ),
1547                 )
1548 
1549     def generate_altered_options(self):
1550         """
1551         Work out if any non-schema-affecting options have changed and make an
1552         operation to represent them in state changes (in case Python code in
1553         migrations needs them).
1554         """
1555         models_to_check = self.kept_model_keys.union(
1556             self.kept_proxy_keys,
1557             self.kept_unmanaged_keys,
1558             # unmanaged converted to managed
1559             self.old_unmanaged_keys & self.new_model_keys,
1560             # managed converted to unmanaged
1561             self.old_model_keys & self.new_unmanaged_keys,
1562         )
1563 
1564         for app_label, model_name in sorted(models_to_check):
1565             old_model_name = self.renamed_models.get(
1566                 (app_label, model_name), model_name
1567             )
1568             old_model_state = self.from_state.models[app_label, old_model_name]
1569             new_model_state = self.to_state.models[app_label, model_name]
1570             old_options = {
1571                 key: value
1572                 for key, value in old_model_state.options.items()
1573                 if key in AlterModelOptions.ALTER_OPTION_KEYS
1574             }
1575             new_options = {
1576                 key: value
1577                 for key, value in new_model_state.options.items()
1578                 if key in AlterModelOptions.ALTER_OPTION_KEYS
1579             }
1580             if old_options != new_options:
1581                 self.add_operation(
1582                     app_label,
1583                     operations.AlterModelOptions(
1584                         name=model_name,
1585                         options=new_options,
1586                     ),
1587                 )
1588 
1589     def generate_altered_order_with_respect_to(self):
1590         for app_label, model_name in sorted(self.kept_model_keys):
1591             old_model_name = self.renamed_models.get(
1592                 (app_label, model_name), model_name
1593             )
1594             old_model_state = self.from_state.models[app_label, old_model_name]
1595             new_model_state = self.to_state.models[app_label, model_name]
1596             if old_model_state.options.get(
1597                 "order_with_respect_to"
1598             ) != new_model_state.options.get("order_with_respect_to"):
1599                 # Make sure it comes second if we're adding
1600                 # (removal dependency is part of RemoveField)
1601                 dependencies = []
1602                 if new_model_state.options.get("order_with_respect_to"):
1603                     dependencies.append(
1604                         (
1605                             app_label,
1606                             model_name,
1607                             new_model_state.options["order_with_respect_to"],
1608                             True,
1609                         )
1610                     )
1611                 # Actually generate the operation
1612                 self.add_operation(
1613                     app_label,
1614                     operations.AlterOrderWithRespectTo(
1615                         name=model_name,
1616                         order_with_respect_to=new_model_state.options.get(
1617                             "order_with_respect_to"
1618                         ),
1619                     ),
1620                     dependencies=dependencies,
1621                 )
1622 
1623     def generate_altered_managers(self):
1624         for app_label, model_name in sorted(self.kept_model_keys):
1625             old_model_name = self.renamed_models.get(
1626                 (app_label, model_name), model_name
1627             )
1628             old_model_state = self.from_state.models[app_label, old_model_name]
1629             new_model_state = self.to_state.models[app_label, model_name]
1630             if old_model_state.managers != new_model_state.managers:
1631                 self.add_operation(
1632                     app_label,
1633                     operations.AlterModelManagers(
1634                         name=model_name,
1635                         managers=new_model_state.managers,
1636                     ),
1637                 )
1638 
1639     def arrange_for_graph(self, changes, graph, migration_name=None):
1640         """
1641         Take a result from changes() and a MigrationGraph, and fix the names
1642         and dependencies of the changes so they extend the graph from the leaf
1643         nodes for each app.
1644         """
1645         leaves = graph.leaf_nodes()
1646         name_map = {}
1647         for app_label, migrations in list(changes.items()):
1648             if not migrations:
1649                 continue
1650             # Find the app label's current leaf node
1651             app_leaf = None
1652             for leaf in leaves:
1653                 if leaf[0] == app_label:
1654                     app_leaf = leaf
1655                     break
1656             # Do they want an initial migration for this app?
1657             if app_leaf is None and not self.questioner.ask_initial(app_label):
1658                 # They don't.
1659                 for migration in migrations:
1660                     name_map[(app_label, migration.name)] = (app_label, "__first__")
1661                 del changes[app_label]
1662                 continue
1663             # Work out the next number in the sequence
1664             if app_leaf is None:
1665                 next_number = 1
1666             else:
1667                 next_number = (self.parse_number(app_leaf[1]) or 0) + 1
1668             # Name each migration
1669             for i, migration in enumerate(migrations):
1670                 if i == 0 and app_leaf:
1671                     migration.dependencies.append(app_leaf)
1672                 new_name_parts = ["%04i" % next_number]
1673                 if migration_name:
1674                     new_name_parts.append(migration_name)
1675                 elif i == 0 and not app_leaf:
1676                     new_name_parts.append("initial")
1677                 else:
1678                     new_name_parts.append(migration.suggest_name()[:100])
1679                 new_name = "_".join(new_name_parts)
1680                 name_map[(app_label, migration.name)] = (app_label, new_name)
1681                 next_number += 1
1682                 migration.name = new_name
1683         # Now fix dependencies
1684         for migrations in changes.values():
1685             for migration in migrations:
1686                 migration.dependencies = [
1687                     name_map.get(d, d) for d in migration.dependencies
1688                 ]
1689         return changes
1690 
1691     def _trim_to_apps(self, changes, app_labels):
1692         """
1693         Take changes from arrange_for_graph() and set of app labels, and return
1694         a modified set of changes which trims out as many migrations that are
1695         not in app_labels as possible. Note that some other migrations may
1696         still be present as they may be required dependencies.
1697         """
1698         # Gather other app dependencies in a first pass
1699         app_dependencies = {}
1700         for app_label, migrations in changes.items():
1701             for migration in migrations:
1702                 for dep_app_label, name in migration.dependencies:
1703                     app_dependencies.setdefault(app_label, set()).add(dep_app_label)
1704         required_apps = set(app_labels)
1705         # Keep resolving till there's no change
1706         old_required_apps = None
1707         while old_required_apps != required_apps:
1708             old_required_apps = set(required_apps)
1709             required_apps.update(
1710                 *[app_dependencies.get(app_label, ()) for app_label in required_apps]
1711             )
1712         # Remove all migrations that aren't needed
1713         for app_label in list(changes):
1714             if app_label not in required_apps:
1715                 del changes[app_label]
1716         return changes
1717 
1718     @classmethod
1719     def parse_number(cls, name):
1720         """
1721         Given a migration name, try to extract a number from the beginning of
1722         it. For a squashed migration such as '0001_squashed_0004', return the
1723         second number. If no number is found, return None.
1724         """
1725         if squashed_match := re.search(r".*_squashed_(\d+)", name):
1726             return int(squashed_match[1])
1727         match = re.match(r"^\d+", name)
1728         if match:
1729             return int(match[0])
1730         return None

</code><intended_behavior>Correctly identify changes from `index_together` to `Model.Meta.indexes` for migration generation, ensuring error-free recognition and operation reflection.</intended_behavior>, <file>django/db/backends/base/schema.py</file>
<class>None</class>
<method>None</method>
<code>
1 import logging
2 import operator
3 from datetime import datetime
4 
5 from django.conf import settings
6 from django.db.backends.ddl_references import (
7     Columns,
8     Expressions,
9     ForeignKeyName,
10     IndexName,
11     Statement,
12     Table,
13 )
14 from django.db.backends.utils import names_digest, split_identifier
15 from django.db.models import Deferrable, Index
16 from django.db.models.sql import Query
17 from django.db.transaction import TransactionManagementError, atomic
18 from django.utils import timezone
19 
20 logger = logging.getLogger("django.db.backends.schema")
21 
22 
23 def _is_relevant_relation(relation, altered_field):
24     """
25     When altering the given field, must constraints on its model from the given
26     relation be temporarily dropped?
27     """
28     field = relation.field
29     if field.many_to_many:
30         # M2M reverse field
31         return False
32     if altered_field.primary_key and field.to_fields == [None]:
33         # Foreign key constraint on the primary key, which is being altered.
34         return True
35     # Is the constraint targeting the field being altered?
36     return altered_field.name in field.to_fields
37 
38 
39 def _all_related_fields(model):
40     # Related fields must be returned in a deterministic order.
41     return sorted(
42         model._meta._get_fields(
43             forward=False,
44             reverse=True,
45             include_hidden=True,
46             include_parents=False,
47         ),
48         key=operator.attrgetter("name"),
49     )
50 
51 
52 def _related_non_m2m_objects(old_field, new_field):
53     # Filter out m2m objects from reverse relations.
54     # Return (old_relation, new_relation) tuples.
55     related_fields = zip(
56         (
57             obj
58             for obj in _all_related_fields(old_field.model)
59             if _is_relevant_relation(obj, old_field)
60         ),
61         (
62             obj
63             for obj in _all_related_fields(new_field.model)
64             if _is_relevant_relation(obj, new_field)
65         ),
66     )
67     for old_rel, new_rel in related_fields:
68         yield old_rel, new_rel
69         yield from _related_non_m2m_objects(
70             old_rel.remote_field,
71             new_rel.remote_field,
72         )
73 
74 
75 class BaseDatabaseSchemaEditor:
76     """
77     This class and its subclasses are responsible for emitting schema-changing
78     statements to the databases - model creation/removal/alteration, field
79     renaming, index fiddling, and so on.
80     """
81 
82     # Overrideable SQL templates
83     sql_create_table = "CREATE TABLE %(table)s (%(definition)s)"
84     sql_rename_table = "ALTER TABLE %(old_table)s RENAME TO %(new_table)s"
85     sql_retablespace_table = "ALTER TABLE %(table)s SET TABLESPACE %(new_tablespace)s"
86     sql_delete_table = "DROP TABLE %(table)s CASCADE"
87 
88     sql_create_column = "ALTER TABLE %(table)s ADD COLUMN %(column)s %(definition)s"
89     sql_alter_column = "ALTER TABLE %(table)s %(changes)s"
90     sql_alter_column_type = "ALTER COLUMN %(column)s TYPE %(type)s"
91     sql_alter_column_null = "ALTER COLUMN %(column)s DROP NOT NULL"
92     sql_alter_column_not_null = "ALTER COLUMN %(column)s SET NOT NULL"
93     sql_alter_column_default = "ALTER COLUMN %(column)s SET DEFAULT %(default)s"
94     sql_alter_column_no_default = "ALTER COLUMN %(column)s DROP DEFAULT"
95     sql_alter_column_no_default_null = sql_alter_column_no_default
96     sql_alter_column_collate = "ALTER COLUMN %(column)s TYPE %(type)s%(collation)s"
97     sql_delete_column = "ALTER TABLE %(table)s DROP COLUMN %(column)s CASCADE"
98     sql_rename_column = (
99         "ALTER TABLE %(table)s RENAME COLUMN %(old_column)s TO %(new_column)s"
100     )
101     sql_update_with_default = (
102         "UPDATE %(table)s SET %(column)s = %(default)s WHERE %(column)s IS NULL"
103     )
104 
105     sql_unique_constraint = "UNIQUE (%(columns)s)%(deferrable)s"
106     sql_check_constraint = "CHECK (%(check)s)"
107     sql_delete_constraint = "ALTER TABLE %(table)s DROP CONSTRAINT %(name)s"
108     sql_constraint = "CONSTRAINT %(name)s %(constraint)s"
109 
110     sql_create_check = "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s CHECK (%(check)s)"
111     sql_delete_check = sql_delete_constraint
112 
113     sql_create_unique = (
114         "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s "
115         "UNIQUE (%(columns)s)%(deferrable)s"
116     )
117     sql_delete_unique = sql_delete_constraint
118 
119     sql_create_fk = (
120         "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s FOREIGN KEY (%(column)s) "
121         "REFERENCES %(to_table)s (%(to_column)s)%(deferrable)s"
122     )
123     sql_create_inline_fk = None
124     sql_create_column_inline_fk = None
125     sql_delete_fk = sql_delete_constraint
126 
127     sql_create_index = (
128         "CREATE INDEX %(name)s ON %(table)s "
129         "(%(columns)s)%(include)s%(extra)s%(condition)s"
130     )
131     sql_create_unique_index = (
132         "CREATE UNIQUE INDEX %(name)s ON %(table)s "
133         "(%(columns)s)%(include)s%(condition)s"
134     )
135     sql_rename_index = "ALTER INDEX %(old_name)s RENAME TO %(new_name)s"
136     sql_delete_index = "DROP INDEX %(name)s"
137 
138     sql_create_pk = (
139         "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s PRIMARY KEY (%(columns)s)"
140     )
141     sql_delete_pk = sql_delete_constraint
142 
143     sql_delete_procedure = "DROP PROCEDURE %(procedure)s"
144 
145     def __init__(self, connection, collect_sql=False, atomic=True):
146         self.connection = connection
147         self.collect_sql = collect_sql
148         if self.collect_sql:
149             self.collected_sql = []
150         self.atomic_migration = self.connection.features.can_rollback_ddl and atomic
151 
152     # State-managing methods
153 
154     def __enter__(self):
155         self.deferred_sql = []
156         if self.atomic_migration:
157             self.atomic = atomic(self.connection.alias)
158             self.atomic.__enter__()
159         return self
160 
161     def __exit__(self, exc_type, exc_value, traceback):
162         if exc_type is None:
163             for sql in self.deferred_sql:
164                 self.execute(sql)
165         if self.atomic_migration:
166             self.atomic.__exit__(exc_type, exc_value, traceback)
167 
168     # Core utility functions
169 
170     def execute(self, sql, params=()):
171         """Execute the given SQL statement, with optional parameters."""
172         # Don't perform the transactional DDL check if SQL is being collected
173         # as it's not going to be executed anyway.
174         if (
175             not self.collect_sql
176             and self.connection.in_atomic_block
177             and not self.connection.features.can_rollback_ddl
178         ):
179             raise TransactionManagementError(
180                 "Executing DDL statements while in a transaction on databases "
181                 "that can't perform a rollback is prohibited."
182             )
183         # Account for non-string statement objects.
184         sql = str(sql)
185         # Log the command we're running, then run it
186         logger.debug(
187             "%s; (params %r)", sql, params, extra={"params": params, "sql": sql}
188         )
189         if self.collect_sql:
190             ending = "" if sql.rstrip().endswith(";") else ";"
191             if params is not None:
192                 self.collected_sql.append(
193                     (sql % tuple(map(self.quote_value, params))) + ending
194                 )
195             else:
196                 self.collected_sql.append(sql + ending)
197         else:
198             with self.connection.cursor() as cursor:
199                 cursor.execute(sql, params)
200 
201     def quote_name(self, name):
202         return self.connection.ops.quote_name(name)
203 
204     def table_sql(self, model):
205         """Take a model and return its table definition."""
206         # Add any unique_togethers (always deferred, as some fields might be
207         # created afterward, like geometry fields with some backends).
208         for field_names in model._meta.unique_together:
209             fields = [model._meta.get_field(field) for field in field_names]
210             self.deferred_sql.append(self._create_unique_sql(model, fields))
211         # Create column SQL, add FK deferreds if needed.
212         column_sqls = []
213         params = []
214         for field in model._meta.local_fields:
215             # SQL.
216             definition, extra_params = self.column_sql(model, field)
217             if definition is None:
218                 continue
219             # Check constraints can go on the column SQL here.
220             db_params = field.db_parameters(connection=self.connection)
221             if db_params["check"]:
222                 definition += " " + self.sql_check_constraint % db_params
223             # Autoincrement SQL (for backends with inline variant).
224             col_type_suffix = field.db_type_suffix(connection=self.connection)
225             if col_type_suffix:
226                 definition += " %s" % col_type_suffix
227             params.extend(extra_params)
228             # FK.
229             if field.remote_field and field.db_constraint:
230                 to_table = field.remote_field.model._meta.db_table
231                 to_column = field.remote_field.model._meta.get_field(
232                     field.remote_field.field_name
233                 ).column
234                 if self.sql_create_inline_fk:
235                     definition += " " + self.sql_create_inline_fk % {
236                         "to_table": self.quote_name(to_table),
237                         "to_column": self.quote_name(to_column),
238                     }
239                 elif self.connection.features.supports_foreign_keys:
240                     self.deferred_sql.append(
241                         self._create_fk_sql(
242                             model, field, "_fk_%(to_table)s_%(to_column)s"
243                         )
244                     )
245             # Add the SQL to our big list.
246             column_sqls.append(
247                 "%s %s"
248                 % (
249                     self.quote_name(field.column),
250                     definition,
251                 )
252             )
253             # Autoincrement SQL (for backends with post table definition
254             # variant).
255             if field.get_internal_type() in (
256                 "AutoField",
257                 "BigAutoField",
258                 "SmallAutoField",
259             ):
260                 autoinc_sql = self.connection.ops.autoinc_sql(
261                     model._meta.db_table, field.column
262                 )
263                 if autoinc_sql:
264                     self.deferred_sql.extend(autoinc_sql)
265         constraints = [
266             constraint.constraint_sql(model, self)
267             for constraint in model._meta.constraints
268         ]
269         sql = self.sql_create_table % {
270             "table": self.quote_name(model._meta.db_table),
271             "definition": ", ".join(
272                 constraint for constraint in (*column_sqls, *constraints) if constraint
273             ),
274         }
275         if model._meta.db_tablespace:
276             tablespace_sql = self.connection.ops.tablespace_sql(
277                 model._meta.db_tablespace
278             )
279             if tablespace_sql:
280                 sql += " " + tablespace_sql
281         return sql, params
282 
283     # Field <-> database mapping functions
284 
285     def _iter_column_sql(
286         self, column_db_type, params, model, field, field_db_params, include_default
287     ):
288         yield column_db_type
289         if collation := field_db_params.get("collation"):
290             yield self._collate_sql(collation)
291         # Work out nullability.
292         null = field.null
293         # Include a default value, if requested.
294         include_default = (
295             include_default
296             and not self.skip_default(field)
297             and
298             # Don't include a default value if it's a nullable field and the
299             # default cannot be dropped in the ALTER COLUMN statement (e.g.
300             # MySQL longtext and longblob).
301             not (null and self.skip_default_on_alter(field))
302         )
303         if include_default:
304             default_value = self.effective_default(field)
305             if default_value is not None:
306                 column_default = "DEFAULT " + self._column_default_sql(field)
307                 if self.connection.features.requires_literal_defaults:
308                     # Some databases can't take defaults as a parameter (Oracle).
309                     # If this is the case, the individual schema backend should
310                     # implement prepare_default().
311                     yield column_default % self.prepare_default(default_value)
312                 else:
313                     yield column_default
314                     params.append(default_value)
315         # Oracle treats the empty string ('') as null, so coerce the null
316         # option whenever '' is a possible value.
317         if (
318             field.empty_strings_allowed
319             and not field.primary_key
320             and self.connection.features.interprets_empty_strings_as_nulls
321         ):
322             null = True
323         if not null:
324             yield "NOT NULL"
325         elif not self.connection.features.implied_column_null:
326             yield "NULL"
327         if field.primary_key:
328             yield "PRIMARY KEY"
329         elif field.unique:
330             yield "UNIQUE"
331         # Optionally add the tablespace if it's an implicitly indexed column.
332         tablespace = field.db_tablespace or model._meta.db_tablespace
333         if (
334             tablespace
335             and self.connection.features.supports_tablespaces
336             and field.unique
337         ):
338             yield self.connection.ops.tablespace_sql(tablespace, inline=True)
339 
340     def column_sql(self, model, field, include_default=False):
341         """
342         Return the column definition for a field. The field must already have
343         had set_attributes_from_name() called.
344         """
345         # Get the column's type and use that as the basis of the SQL.
346         field_db_params = field.db_parameters(connection=self.connection)
347         column_db_type = field_db_params["type"]
348         # Check for fields that aren't actually columns (e.g. M2M).
349         if column_db_type is None:
350             return None, None
351         params = []
352         return (
353             " ".join(
354                 # This appends to the params being returned.
355                 self._iter_column_sql(
356                     column_db_type,
357                     params,
358                     model,
359                     field,
360                     field_db_params,
361                     include_default,
362                 )
363             ),
364             params,
365         )
366 
367     def skip_default(self, field):
368         """
369         Some backends don't accept default values for certain columns types
370         (i.e. MySQL longtext and longblob).
371         """
372         return False
373 
374     def skip_default_on_alter(self, field):
375         """
376         Some backends don't accept default values for certain columns types
377         (i.e. MySQL longtext and longblob) in the ALTER COLUMN statement.
378         """
379         return False
380 
381     def prepare_default(self, value):
382         """
383         Only used for backends which have requires_literal_defaults feature
384         """
385         raise NotImplementedError(
386             "subclasses of BaseDatabaseSchemaEditor for backends which have "
387             "requires_literal_defaults must provide a prepare_default() method"
388         )
389 
390     def _column_default_sql(self, field):
391         """
392         Return the SQL to use in a DEFAULT clause. The resulting string should
393         contain a '%s' placeholder for a default value.
394         """
395         return "%s"
396 
397     @staticmethod
398     def _effective_default(field):
399         # This method allows testing its logic without a connection.
400         if field.has_default():
401             default = field.get_default()
402         elif not field.null and field.blank and field.empty_strings_allowed:
403             if field.get_internal_type() == "BinaryField":
404                 default = b""
405             else:
406                 default = ""
407         elif getattr(field, "auto_now", False) or getattr(field, "auto_now_add", False):
408             internal_type = field.get_internal_type()
409             if internal_type == "DateTimeField":
410                 default = timezone.now()
411             else:
412                 default = datetime.now()
413                 if internal_type == "DateField":
414                     default = default.date()
415                 elif internal_type == "TimeField":
416                     default = default.time()
417         else:
418             default = None
419         return default
420 
421     def effective_default(self, field):
422         """Return a field's effective database default value."""
423         return field.get_db_prep_save(self._effective_default(field), self.connection)
424 
425     def quote_value(self, value):
426         """
427         Return a quoted version of the value so it's safe to use in an SQL
428         string. This is not safe against injection from user code; it is
429         intended only for use in making SQL scripts or preparing default values
430         for particularly tricky backends (defaults are not user-defined, though,
431         so this is safe).
432         """
433         raise NotImplementedError()
434 
435     # Actions
436 
437     def create_model(self, model):
438         """
439         Create a table and any accompanying indexes or unique constraints for
440         the given `model`.
441         """
442         sql, params = self.table_sql(model)
443         # Prevent using [] as params, in the case a literal '%' is used in the
444         # definition.
445         self.execute(sql, params or None)
446 
447         # Add any field index and index_together's (deferred as SQLite
448         # _remake_table needs it).
449         self.deferred_sql.extend(self._model_indexes_sql(model))
450 
451         # Make M2M tables
452         for field in model._meta.local_many_to_many:
453             if field.remote_field.through._meta.auto_created:
454                 self.create_model(field.remote_field.through)
455 
456     def delete_model(self, model):
457         """Delete a model from the database."""
458         # Handle auto-created intermediary models
459         for field in model._meta.local_many_to_many:
460             if field.remote_field.through._meta.auto_created:
461                 self.delete_model(field.remote_field.through)
462 
463         # Delete the table
464         self.execute(
465             self.sql_delete_table
466             % {
467                 "table": self.quote_name(model._meta.db_table),
468             }
469         )
470         # Remove all deferred statements referencing the deleted table.
471         for sql in list(self.deferred_sql):
472             if isinstance(sql, Statement) and sql.references_table(
473                 model._meta.db_table
474             ):
475                 self.deferred_sql.remove(sql)
476 
477     def add_index(self, model, index):
478         """Add an index on a model."""
479         if (
480             index.contains_expressions
481             and not self.connection.features.supports_expression_indexes
482         ):
483             return None
484         # Index.create_sql returns interpolated SQL which makes params=None a
485         # necessity to avoid escaping attempts on execution.
486         self.execute(index.create_sql(model, self), params=None)
487 
488     def remove_index(self, model, index):
489         """Remove an index from a model."""
490         if (
491             index.contains_expressions
492             and not self.connection.features.supports_expression_indexes
493         ):
494             return None
495         self.execute(index.remove_sql(model, self))
496 
497     def rename_index(self, model, old_index, new_index):
498         if self.connection.features.can_rename_index:
499             self.execute(
500                 self._rename_index_sql(model, old_index.name, new_index.name),
501                 params=None,
502             )
503         else:
504             self.remove_index(model, old_index)
505             self.add_index(model, new_index)
506 
507     def add_constraint(self, model, constraint):
508         """Add a constraint to a model."""
509         sql = constraint.create_sql(model, self)
510         if sql:
511             # Constraint.create_sql returns interpolated SQL which makes
512             # params=None a necessity to avoid escaping attempts on execution.
513             self.execute(sql, params=None)
514 
515     def remove_constraint(self, model, constraint):
516         """Remove a constraint from a model."""
517         sql = constraint.remove_sql(model, self)
518         if sql:
519             self.execute(sql)
520 
521     def alter_unique_together(self, model, old_unique_together, new_unique_together):
522         """
523         Deal with a model changing its unique_together. The input
524         unique_togethers must be doubly-nested, not the single-nested
525         ["foo", "bar"] format.
526         """
527         olds = {tuple(fields) for fields in old_unique_together}
528         news = {tuple(fields) for fields in new_unique_together}
529         # Deleted uniques
530         for fields in olds.difference(news):
531             self._delete_composed_index(
532                 model,
533                 fields,
534                 {"unique": True, "primary_key": False},
535                 self.sql_delete_unique,
536             )
537         # Created uniques
538         for field_names in news.difference(olds):
539             fields = [model._meta.get_field(field) for field in field_names]
540             self.execute(self._create_unique_sql(model, fields))
541 
542     def alter_index_together(self, model, old_index_together, new_index_together):
543         """
544         Deal with a model changing its index_together. The input
545         index_togethers must be doubly-nested, not the single-nested
546         ["foo", "bar"] format.
547         """
548         olds = {tuple(fields) for fields in old_index_together}
549         news = {tuple(fields) for fields in new_index_together}
550         # Deleted indexes
551         for fields in olds.difference(news):
552             self._delete_composed_index(
553                 model,
554                 fields,
555                 {"index": True, "unique": False},
556                 self.sql_delete_index,
557             )
558         # Created indexes
559         for field_names in news.difference(olds):
560             fields = [model._meta.get_field(field) for field in field_names]
561             self.execute(self._create_index_sql(model, fields=fields, suffix="_idx"))
562 
563     def _delete_composed_index(self, model, fields, constraint_kwargs, sql):
564         meta_constraint_names = {
565             constraint.name for constraint in model._meta.constraints
566         }
567         meta_index_names = {constraint.name for constraint in model._meta.indexes}
568         columns = [model._meta.get_field(field).column for field in fields]
569         constraint_names = self._constraint_names(
570             model,
571             columns,
572             exclude=meta_constraint_names | meta_index_names,
573             **constraint_kwargs,
574         )
575         if (
576             constraint_kwargs.get("unique") is True
577             and constraint_names
578             and self.connection.features.allows_multiple_constraints_on_same_fields
579         ):
580             # Constraint matching the unique_together name.
581             default_name = str(
582                 self._unique_constraint_name(model._meta.db_table, columns, quote=False)
583             )
584             if default_name in constraint_names:
585                 constraint_names = [default_name]
586         if len(constraint_names) != 1:
587             raise ValueError(
588                 "Found wrong number (%s) of constraints for %s(%s)"
589                 % (
590                     len(constraint_names),
591                     model._meta.db_table,
592                     ", ".join(columns),
593                 )
594             )
595         self.execute(self._delete_constraint_sql(sql, model, constraint_names[0]))
596 
597     def alter_db_table(self, model, old_db_table, new_db_table):
598         """Rename the table a model points to."""
599         if old_db_table == new_db_table or (
600             self.connection.features.ignores_table_name_case
601             and old_db_table.lower() == new_db_table.lower()
602         ):
603             return
604         self.execute(
605             self.sql_rename_table
606             % {
607                 "old_table": self.quote_name(old_db_table),
608                 "new_table": self.quote_name(new_db_table),
609             }
610         )
611         # Rename all references to the old table name.
612         for sql in self.deferred_sql:
613             if isinstance(sql, Statement):
614                 sql.rename_table_references(old_db_table, new_db_table)
615 
616     def alter_db_tablespace(self, model, old_db_tablespace, new_db_tablespace):
617         """Move a model's table between tablespaces."""
618         self.execute(
619             self.sql_retablespace_table
620             % {
621                 "table": self.quote_name(model._meta.db_table),
622                 "old_tablespace": self.quote_name(old_db_tablespace),
623                 "new_tablespace": self.quote_name(new_db_tablespace),
624             }
625         )
626 
627     def add_field(self, model, field):
628         """
629         Create a field on a model. Usually involves adding a column, but may
630         involve adding a table instead (for M2M fields).
631         """
632         # Special-case implicit M2M tables
633         if field.many_to_many and field.remote_field.through._meta.auto_created:
634             return self.create_model(field.remote_field.through)
635         # Get the column's definition
636         definition, params = self.column_sql(model, field, include_default=True)
637         # It might not actually have a column behind it
638         if definition is None:
639             return
640         # Check constraints can go on the column SQL here
641         db_params = field.db_parameters(connection=self.connection)
642         if db_params["check"]:
643             definition += " " + self.sql_check_constraint % db_params
644         if (
645             field.remote_field
646             and self.connection.features.supports_foreign_keys
647             and field.db_constraint
648         ):
649             constraint_suffix = "_fk_%(to_table)s_%(to_column)s"
650             # Add FK constraint inline, if supported.
651             if self.sql_create_column_inline_fk:
652                 to_table = field.remote_field.model._meta.db_table
653                 to_column = field.remote_field.model._meta.get_field(
654                     field.remote_field.field_name
655                 ).column
656                 namespace, _ = split_identifier(model._meta.db_table)
657                 definition += " " + self.sql_create_column_inline_fk % {
658                     "name": self._fk_constraint_name(model, field, constraint_suffix),
659                     "namespace": "%s." % self.quote_name(namespace)
660                     if namespace
661                     else "",
662                     "column": self.quote_name(field.column),
663                     "to_table": self.quote_name(to_table),
664                     "to_column": self.quote_name(to_column),
665                     "deferrable": self.connection.ops.deferrable_sql(),
666                 }
667             # Otherwise, add FK constraints later.
668             else:
669                 self.deferred_sql.append(
670                     self._create_fk_sql(model, field, constraint_suffix)
671                 )
672         # Build the SQL and run it
673         sql = self.sql_create_column % {
674             "table": self.quote_name(model._meta.db_table),
675             "column": self.quote_name(field.column),
676             "definition": definition,
677         }
678         self.execute(sql, params)
679         # Drop the default if we need to
680         # (Django usually does not use in-database defaults)
681         if (
682             not self.skip_default_on_alter(field)
683             and self.effective_default(field) is not None
684         ):
685             changes_sql, params = self._alter_column_default_sql(
686                 model, None, field, drop=True
687             )
688             sql = self.sql_alter_column % {
689                 "table": self.quote_name(model._meta.db_table),
690                 "changes": changes_sql,
691             }
692             self.execute(sql, params)
693         # Add an index, if required
694         self.deferred_sql.extend(self._field_indexes_sql(model, field))
695         # Reset connection if required
696         if self.connection.features.connection_persists_old_columns:
697             self.connection.close()
698 
699     def remove_field(self, model, field):
700         """
701         Remove a field from a model. Usually involves deleting a column,
702         but for M2Ms may involve deleting a table.
703         """
704         # Special-case implicit M2M tables
705         if field.many_to_many and field.remote_field.through._meta.auto_created:
706             return self.delete_model(field.remote_field.through)
707         # It might not actually have a column behind it
708         if field.db_parameters(connection=self.connection)["type"] is None:
709             return
710         # Drop any FK constraints, MySQL requires explicit deletion
711         if field.remote_field:
712             fk_names = self._constraint_names(model, [field.column], foreign_key=True)
713             for fk_name in fk_names:
714                 self.execute(self._delete_fk_sql(model, fk_name))
715         # Delete the column
716         sql = self.sql_delete_column % {
717             "table": self.quote_name(model._meta.db_table),
718             "column": self.quote_name(field.column),
719         }
720         self.execute(sql)
721         # Reset connection if required
722         if self.connection.features.connection_persists_old_columns:
723             self.connection.close()
724         # Remove all deferred statements referencing the deleted column.
725         for sql in list(self.deferred_sql):
726             if isinstance(sql, Statement) and sql.references_column(
727                 model._meta.db_table, field.column
728             ):
729                 self.deferred_sql.remove(sql)
730 
731     def alter_field(self, model, old_field, new_field, strict=False):
732         """
733         Allow a field's type, uniqueness, nullability, default, column,
734         constraints, etc. to be modified.
735         `old_field` is required to compute the necessary changes.
736         If `strict` is True, raise errors if the old column does not match
737         `old_field` precisely.
738         """
739         if not self._field_should_be_altered(old_field, new_field):
740             return
741         # Ensure this field is even column-based
742         old_db_params = old_field.db_parameters(connection=self.connection)
743         old_type = old_db_params["type"]
744         new_db_params = new_field.db_parameters(connection=self.connection)
745         new_type = new_db_params["type"]
746         if (old_type is None and old_field.remote_field is None) or (
747             new_type is None and new_field.remote_field is None
748         ):
749             raise ValueError(
750                 "Cannot alter field %s into %s - they do not properly define "
751                 "db_type (are you using a badly-written custom field?)"
752                 % (old_field, new_field),
753             )
754         elif (
755             old_type is None
756             and new_type is None
757             and (
758                 old_field.remote_field.through
759                 and new_field.remote_field.through
760                 and old_field.remote_field.through._meta.auto_created
761                 and new_field.remote_field.through._meta.auto_created
762             )
763         ):
764             return self._alter_many_to_many(model, old_field, new_field, strict)
765         elif (
766             old_type is None
767             and new_type is None
768             and (
769                 old_field.remote_field.through
770                 and new_field.remote_field.through
771                 and not old_field.remote_field.through._meta.auto_created
772                 and not new_field.remote_field.through._meta.auto_created
773             )
774         ):
775             # Both sides have through models; this is a no-op.
776             return
777         elif old_type is None or new_type is None:
778             raise ValueError(
779                 "Cannot alter field %s into %s - they are not compatible types "
780                 "(you cannot alter to or from M2M fields, or add or remove "
781                 "through= on M2M fields)" % (old_field, new_field)
782             )
783 
784         self._alter_field(
785             model,
786             old_field,
787             new_field,
788             old_type,
789             new_type,
790             old_db_params,
791             new_db_params,
792             strict,
793         )
794 
795     def _alter_field(
796         self,
797         model,
798         old_field,
799         new_field,
800         old_type,
801         new_type,
802         old_db_params,
803         new_db_params,
804         strict=False,
805     ):
806         """Perform a "physical" (non-ManyToMany) field update."""
807         # Drop any FK constraints, we'll remake them later
808         fks_dropped = set()
809         if (
810             self.connection.features.supports_foreign_keys
811             and old_field.remote_field
812             and old_field.db_constraint
813         ):
814             fk_names = self._constraint_names(
815                 model, [old_field.column], foreign_key=True
816             )
817             if strict and len(fk_names) != 1:
818                 raise ValueError(
819                     "Found wrong number (%s) of foreign key constraints for %s.%s"
820                     % (
821                         len(fk_names),
822                         model._meta.db_table,
823                         old_field.column,
824                     )
825                 )
826             for fk_name in fk_names:
827                 fks_dropped.add((old_field.column,))
828                 self.execute(self._delete_fk_sql(model, fk_name))
829         # Has unique been removed?
830         if old_field.unique and (
831             not new_field.unique or self._field_became_primary_key(old_field, new_field)
832         ):
833             # Find the unique constraint for this field
834             meta_constraint_names = {
835                 constraint.name for constraint in model._meta.constraints
836             }
837             constraint_names = self._constraint_names(
838                 model,
839                 [old_field.column],
840                 unique=True,
841                 primary_key=False,
842                 exclude=meta_constraint_names,
843             )
844             if strict and len(constraint_names) != 1:
845                 raise ValueError(
846                     "Found wrong number (%s) of unique constraints for %s.%s"
847                     % (
848                         len(constraint_names),
849                         model._meta.db_table,
850                         old_field.column,
851                     )
852                 )
853             for constraint_name in constraint_names:
854                 self.execute(self._delete_unique_sql(model, constraint_name))
855         # Drop incoming FK constraints if the field is a primary key or unique,
856         # which might be a to_field target, and things are going to change.
857         old_collation = old_db_params.get("collation")
858         new_collation = new_db_params.get("collation")
859         drop_foreign_keys = (
860             self.connection.features.supports_foreign_keys
861             and (
862                 (old_field.primary_key and new_field.primary_key)
863                 or (old_field.unique and new_field.unique)
864             )
865             and ((old_type != new_type) or (old_collation != new_collation))
866         )
867         if drop_foreign_keys:
868             # '_meta.related_field' also contains M2M reverse fields, these
869             # will be filtered out
870             for _old_rel, new_rel in _related_non_m2m_objects(old_field, new_field):
871                 rel_fk_names = self._constraint_names(
872                     new_rel.related_model, [new_rel.field.column], foreign_key=True
873                 )
874                 for fk_name in rel_fk_names:
875                     self.execute(self._delete_fk_sql(new_rel.related_model, fk_name))
876         # Removed an index? (no strict check, as multiple indexes are possible)
877         # Remove indexes if db_index switched to False or a unique constraint
878         # will now be used in lieu of an index. The following lines from the
879         # truth table show all True cases; the rest are False:
880         #
881         # old_field.db_index | old_field.unique | new_field.db_index | new_field.unique
882         # ------------------------------------------------------------------------------
883         # True               | False            | False              | False
884         # True               | False            | False              | True
885         # True               | False            | True               | True
886         if (
887             old_field.db_index
888             and not old_field.unique
889             and (not new_field.db_index or new_field.unique)
890         ):
891             # Find the index for this field
892             meta_index_names = {index.name for index in model._meta.indexes}
893             # Retrieve only BTREE indexes since this is what's created with
894             # db_index=True.
895             index_names = self._constraint_names(
896                 model,
897                 [old_field.column],
898                 index=True,
899                 type_=Index.suffix,
900                 exclude=meta_index_names,
901             )
902             for index_name in index_names:
903                 # The only way to check if an index was created with
904                 # db_index=True or with Index(['field'], name='foo')
905                 # is to look at its name (refs #28053).
906                 self.execute(self._delete_index_sql(model, index_name))
907         # Change check constraints?
908         if old_db_params["check"] != new_db_params["check"] and old_db_params["check"]:
909             meta_constraint_names = {
910                 constraint.name for constraint in model._meta.constraints
911             }
912             constraint_names = self._constraint_names(
913                 model,
914                 [old_field.column],
915                 check=True,
916                 exclude=meta_constraint_names,
917             )
918             if strict and len(constraint_names) != 1:
919                 raise ValueError(
920                     "Found wrong number (%s) of check constraints for %s.%s"
921                     % (
922                         len(constraint_names),
923                         model._meta.db_table,
924                         old_field.column,
925                     )
926                 )
927             for constraint_name in constraint_names:
928                 self.execute(self._delete_check_sql(model, constraint_name))
929         # Have they renamed the column?
930         if old_field.column != new_field.column:
931             self.execute(
932                 self._rename_field_sql(
933                     model._meta.db_table, old_field, new_field, new_type
934                 )
935             )
936             # Rename all references to the renamed column.
937             for sql in self.deferred_sql:
938                 if isinstance(sql, Statement):
939                     sql.rename_column_references(
940                         model._meta.db_table, old_field.column, new_field.column
941                     )
942         # Next, start accumulating actions to do
943         actions = []
944         null_actions = []
945         post_actions = []
946         # Type suffix change? (e.g. auto increment).
947         old_type_suffix = old_field.db_type_suffix(connection=self.connection)
948         new_type_suffix = new_field.db_type_suffix(connection=self.connection)
949         # Collation change?
950         if old_collation != new_collation:
951             # Collation change handles also a type change.
952             fragment = self._alter_column_collation_sql(
953                 model, new_field, new_type, new_collation
954             )
955             actions.append(fragment)
956         # Type change?
957         elif (old_type, old_type_suffix) != (new_type, new_type_suffix):
958             fragment, other_actions = self._alter_column_type_sql(
959                 model, old_field, new_field, new_type
960             )
961             actions.append(fragment)
962             post_actions.extend(other_actions)
963         # When changing a column NULL constraint to NOT NULL with a given
964         # default value, we need to perform 4 steps:
965         #  1. Add a default for new incoming writes
966         #  2. Update existing NULL rows with new default
967         #  3. Replace NULL constraint with NOT NULL
968         #  4. Drop the default again.
969         # Default change?
970         needs_database_default = False
971         if old_field.null and not new_field.null:
972             old_default = self.effective_default(old_field)
973             new_default = self.effective_default(new_field)
974             if (
975                 not self.skip_default_on_alter(new_field)
976                 and old_default != new_default
977                 and new_default is not None
978             ):
979                 needs_database_default = True
980                 actions.append(
981                     self._alter_column_default_sql(model, old_field, new_field)
982                 )
983         # Nullability change?
984         if old_field.null != new_field.null:
985             fragment = self._alter_column_null_sql(model, old_field, new_field)
986             if fragment:
987                 null_actions.append(fragment)
988         # Only if we have a default and there is a change from NULL to NOT NULL
989         four_way_default_alteration = new_field.has_default() and (
990             old_field.null and not new_field.null
991         )
992         if actions or null_actions:
993             if not four_way_default_alteration:
994                 # If we don't have to do a 4-way default alteration we can
995                 # directly run a (NOT) NULL alteration
996                 actions = actions + null_actions
997             # Combine actions together if we can (e.g. postgres)
998             if self.connection.features.supports_combined_alters and actions:
999                 sql, params = tuple(zip(*actions))
1000                 actions = [(", ".join(sql), sum(params, []))]
1001             # Apply those actions
1002             for sql, params in actions:
1003                 self.execute(
1004                     self.sql_alter_column
1005                     % {
1006                         "table": self.quote_name(model._meta.db_table),
1007                         "changes": sql,
1008                     },
1009                     params,
1010                 )
1011             if four_way_default_alteration:
1012                 # Update existing rows with default value
1013                 self.execute(
1014                     self.sql_update_with_default
1015                     % {
1016                         "table": self.quote_name(model._meta.db_table),
1017                         "column": self.quote_name(new_field.column),
1018                         "default": "%s",
1019                     },
1020                     [new_default],
1021                 )
1022                 # Since we didn't run a NOT NULL change before we need to do it
1023                 # now
1024                 for sql, params in null_actions:
1025                     self.execute(
1026                         self.sql_alter_column
1027                         % {
1028                             "table": self.quote_name(model._meta.db_table),
1029                             "changes": sql,
1030                         },
1031                         params,
1032                     )
1033         if post_actions:
1034             for sql, params in post_actions:
1035                 self.execute(sql, params)
1036         # If primary_key changed to False, delete the primary key constraint.
1037         if old_field.primary_key and not new_field.primary_key:
1038             self._delete_primary_key(model, strict)
1039         # Added a unique?
1040         if self._unique_should_be_added(old_field, new_field):
1041             self.execute(self._create_unique_sql(model, [new_field]))
1042         # Added an index? Add an index if db_index switched to True or a unique
1043         # constraint will no longer be used in lieu of an index. The following
1044         # lines from the truth table show all True cases; the rest are False:
1045         #
1046         # old_field.db_index | old_field.unique | new_field.db_index | new_field.unique
1047         # ------------------------------------------------------------------------------
1048         # False              | False            | True               | False
1049         # False              | True             | True               | False
1050         # True               | True             | True               | False
1051         if (
1052             (not old_field.db_index or old_field.unique)
1053             and new_field.db_index
1054             and not new_field.unique
1055         ):
1056             self.execute(self._create_index_sql(model, fields=[new_field]))
1057         # Type alteration on primary key? Then we need to alter the column
1058         # referring to us.
1059         rels_to_update = []
1060         if drop_foreign_keys:
1061             rels_to_update.extend(_related_non_m2m_objects(old_field, new_field))
1062         # Changed to become primary key?
1063         if self._field_became_primary_key(old_field, new_field):
1064             # Make the new one
1065             self.execute(self._create_primary_key_sql(model, new_field))
1066             # Update all referencing columns
1067             rels_to_update.extend(_related_non_m2m_objects(old_field, new_field))
1068         # Handle our type alters on the other end of rels from the PK stuff above
1069         for old_rel, new_rel in rels_to_update:
1070             rel_db_params = new_rel.field.db_parameters(connection=self.connection)
1071             rel_type = rel_db_params["type"]
1072             rel_collation = rel_db_params.get("collation")
1073             old_rel_db_params = old_rel.field.db_parameters(connection=self.connection)
1074             old_rel_collation = old_rel_db_params.get("collation")
1075             if old_rel_collation != rel_collation:
1076                 # Collation change handles also a type change.
1077                 fragment = self._alter_column_collation_sql(
1078                     new_rel.related_model,
1079                     new_rel.field,
1080                     rel_type,
1081                     rel_collation,
1082                 )
1083                 other_actions = []
1084             else:
1085                 fragment, other_actions = self._alter_column_type_sql(
1086                     new_rel.related_model, old_rel.field, new_rel.field, rel_type
1087                 )
1088             self.execute(
1089                 self.sql_alter_column
1090                 % {
1091                     "table": self.quote_name(new_rel.related_model._meta.db_table),
1092                     "changes": fragment[0],
1093                 },
1094                 fragment[1],
1095             )
1096             for sql, params in other_actions:
1097                 self.execute(sql, params)
1098         # Does it have a foreign key?
1099         if (
1100             self.connection.features.supports_foreign_keys
1101             and new_field.remote_field
1102             and (
1103                 fks_dropped or not old_field.remote_field or not old_field.db_constraint
1104             )
1105             and new_field.db_constraint
1106         ):
1107             self.execute(
1108                 self._create_fk_sql(model, new_field, "_fk_%(to_table)s_%(to_column)s")
1109             )
1110         # Rebuild FKs that pointed to us if we previously had to drop them
1111         if drop_foreign_keys:
1112             for _, rel in rels_to_update:
1113                 if rel.field.db_constraint:
1114                     self.execute(
1115                         self._create_fk_sql(rel.related_model, rel.field, "_fk")
1116                     )
1117         # Does it have check constraints we need to add?
1118         if old_db_params["check"] != new_db_params["check"] and new_db_params["check"]:
1119             constraint_name = self._create_index_name(
1120                 model._meta.db_table, [new_field.column], suffix="_check"
1121             )
1122             self.execute(
1123                 self._create_check_sql(model, constraint_name, new_db_params["check"])
1124             )
1125         # Drop the default if we need to
1126         # (Django usually does not use in-database defaults)
1127         if needs_database_default:
1128             changes_sql, params = self._alter_column_default_sql(
1129                 model, old_field, new_field, drop=True
1130             )
1131             sql = self.sql_alter_column % {
1132                 "table": self.quote_name(model._meta.db_table),
1133                 "changes": changes_sql,
1134             }
1135             self.execute(sql, params)
1136         # Reset connection if required
1137         if self.connection.features.connection_persists_old_columns:
1138             self.connection.close()
1139 
1140     def _alter_column_null_sql(self, model, old_field, new_field):
1141         """
1142         Hook to specialize column null alteration.
1143 
1144         Return a (sql, params) fragment to set a column to null or non-null
1145         as required by new_field, or None if no changes are required.
1146         """
1147         if (
1148             self.connection.features.interprets_empty_strings_as_nulls
1149             and new_field.empty_strings_allowed
1150         ):
1151             # The field is nullable in the database anyway, leave it alone.
1152             return
1153         else:
1154             new_db_params = new_field.db_parameters(connection=self.connection)
1155             sql = (
1156                 self.sql_alter_column_null
1157                 if new_field.null
1158                 else self.sql_alter_column_not_null
1159             )
1160             return (
1161                 sql
1162                 % {
1163                     "column": self.quote_name(new_field.column),
1164                     "type": new_db_params["type"],
1165                 },
1166                 [],
1167             )
1168 
1169     def _alter_column_default_sql(self, model, old_field, new_field, drop=False):
1170         """
1171         Hook to specialize column default alteration.
1172 
1173         Return a (sql, params) fragment to add or drop (depending on the drop
1174         argument) a default to new_field's column.
1175         """
1176         new_default = self.effective_default(new_field)
1177         default = self._column_default_sql(new_field)
1178         params = [new_default]
1179 
1180         if drop:
1181             params = []
1182         elif self.connection.features.requires_literal_defaults:
1183             # Some databases (Oracle) can't take defaults as a parameter
1184             # If this is the case, the SchemaEditor for that database should
1185             # implement prepare_default().
1186             default = self.prepare_default(new_default)
1187             params = []
1188 
1189         new_db_params = new_field.db_parameters(connection=self.connection)
1190         if drop:
1191             if new_field.null:
1192                 sql = self.sql_alter_column_no_default_null
1193             else:
1194                 sql = self.sql_alter_column_no_default
1195         else:
1196             sql = self.sql_alter_column_default
1197         return (
1198             sql
1199             % {
1200                 "column": self.quote_name(new_field.column),
1201                 "type": new_db_params["type"],
1202                 "default": default,
1203             },
1204             params,
1205         )
1206 
1207     def _alter_column_type_sql(self, model, old_field, new_field, new_type):
1208         """
1209         Hook to specialize column type alteration for different backends,
1210         for cases when a creation type is different to an alteration type
1211         (e.g. SERIAL in PostgreSQL, PostGIS fields).
1212 
1213         Return a two-tuple of: an SQL fragment of (sql, params) to insert into
1214         an ALTER TABLE statement and a list of extra (sql, params) tuples to
1215         run once the field is altered.
1216         """
1217         return (
1218             (
1219                 self.sql_alter_column_type
1220                 % {
1221                     "column": self.quote_name(new_field.column),
1222                     "type": new_type,
1223                 },
1224                 [],
1225             ),
1226             [],
1227         )
1228 
1229     def _alter_column_collation_sql(self, model, new_field, new_type, new_collation):
1230         return (
1231             self.sql_alter_column_collate
1232             % {
1233                 "column": self.quote_name(new_field.column),
1234                 "type": new_type,
1235                 "collation": " " + self._collate_sql(new_collation)
1236                 if new_collation
1237                 else "",
1238             },
1239             [],
1240         )
1241 
1242     def _alter_many_to_many(self, model, old_field, new_field, strict):
1243         """Alter M2Ms to repoint their to= endpoints."""
1244         # Rename the through table
1245         if (
1246             old_field.remote_field.through._meta.db_table
1247             != new_field.remote_field.through._meta.db_table
1248         ):
1249             self.alter_db_table(
1250                 old_field.remote_field.through,
1251                 old_field.remote_field.through._meta.db_table,
1252                 new_field.remote_field.through._meta.db_table,
1253             )
1254         # Repoint the FK to the other side
1255         self.alter_field(
1256             new_field.remote_field.through,
1257             # The field that points to the target model is needed, so we can
1258             # tell alter_field to change it - this is m2m_reverse_field_name()
1259             # (as opposed to m2m_field_name(), which points to our model).
1260             old_field.remote_field.through._meta.get_field(
1261                 old_field.m2m_reverse_field_name()
1262             ),
1263             new_field.remote_field.through._meta.get_field(
1264                 new_field.m2m_reverse_field_name()
1265             ),
1266         )
1267         self.alter_field(
1268             new_field.remote_field.through,
1269             # for self-referential models we need to alter field from the other end too
1270             old_field.remote_field.through._meta.get_field(old_field.m2m_field_name()),
1271             new_field.remote_field.through._meta.get_field(new_field.m2m_field_name()),
1272         )
1273 
1274     def _create_index_name(self, table_name, column_names, suffix=""):
1275         """
1276         Generate a unique name for an index/unique constraint.
1277 
1278         The name is divided into 3 parts: the table name, the column names,
1279         and a unique digest and suffix.
1280         """
1281         _, table_name = split_identifier(table_name)
1282         hash_suffix_part = "%s%s" % (
1283             names_digest(table_name, *column_names, length=8),
1284             suffix,
1285         )
1286         max_length = self.connection.ops.max_name_length() or 200
1287         # If everything fits into max_length, use that name.
1288         index_name = "%s_%s_%s" % (table_name, "_".join(column_names), hash_suffix_part)
1289         if len(index_name) <= max_length:
1290             return index_name
1291         # Shorten a long suffix.
1292         if len(hash_suffix_part) > max_length / 3:
1293             hash_suffix_part = hash_suffix_part[: max_length // 3]
1294         other_length = (max_length - len(hash_suffix_part)) // 2 - 1
1295         index_name = "%s_%s_%s" % (
1296             table_name[:other_length],
1297             "_".join(column_names)[:other_length],
1298             hash_suffix_part,
1299         )
1300         # Prepend D if needed to prevent the name from starting with an
1301         # underscore or a number (not permitted on Oracle).
1302         if index_name[0] == "_" or index_name[0].isdigit():
1303             index_name = "D%s" % index_name[:-1]
1304         return index_name
1305 
1306     def _get_index_tablespace_sql(self, model, fields, db_tablespace=None):
1307         if db_tablespace is None:
1308             if len(fields) == 1 and fields[0].db_tablespace:
1309                 db_tablespace = fields[0].db_tablespace
1310             elif settings.DEFAULT_INDEX_TABLESPACE:
1311                 db_tablespace = settings.DEFAULT_INDEX_TABLESPACE
1312             elif model._meta.db_tablespace:
1313                 db_tablespace = model._meta.db_tablespace
1314         if db_tablespace is not None:
1315             return " " + self.connection.ops.tablespace_sql(db_tablespace)
1316         return ""
1317 
1318     def _index_condition_sql(self, condition):
1319         if condition:
1320             return " WHERE " + condition
1321         return ""
1322 
1323     def _index_include_sql(self, model, columns):
1324         if not columns or not self.connection.features.supports_covering_indexes:
1325             return ""
1326         return Statement(
1327             " INCLUDE (%(columns)s)",
1328             columns=Columns(model._meta.db_table, columns, self.quote_name),
1329         )
1330 
1331     def _create_index_sql(
1332         self,
1333         model,
1334         *,
1335         fields=None,
1336         name=None,
1337         suffix="",
1338         using="",
1339         db_tablespace=None,
1340         col_suffixes=(),
1341         sql=None,
1342         opclasses=(),
1343         condition=None,
1344         include=None,
1345         expressions=None,
1346     ):
1347         """
1348         Return the SQL statement to create the index for one or several fields
1349         or expressions. `sql` can be specified if the syntax differs from the
1350         standard (GIS indexes, ...).
1351         """
1352         fields = fields or []
1353         expressions = expressions or []
1354         compiler = Query(model, alias_cols=False).get_compiler(
1355             connection=self.connection,
1356         )
1357         tablespace_sql = self._get_index_tablespace_sql(
1358             model, fields, db_tablespace=db_tablespace
1359         )
1360         columns = [field.column for field in fields]
1361         sql_create_index = sql or self.sql_create_index
1362         table = model._meta.db_table
1363 
1364         def create_index_name(*args, **kwargs):
1365             nonlocal name
1366             if name is None:
1367                 name = self._create_index_name(*args, **kwargs)
1368             return self.quote_name(name)
1369 
1370         return Statement(
1371             sql_create_index,
1372             table=Table(table, self.quote_name),
1373             name=IndexName(table, columns, suffix, create_index_name),
1374             using=using,
1375             columns=(
1376                 self._index_columns(table, columns, col_suffixes, opclasses)
1377                 if columns
1378                 else Expressions(table, expressions, compiler, self.quote_value)
1379             ),
1380             extra=tablespace_sql,
1381             condition=self._index_condition_sql(condition),
1382             include=self._index_include_sql(model, include),
1383         )
1384 
1385     def _delete_index_sql(self, model, name, sql=None):
1386         return Statement(
1387             sql or self.sql_delete_index,
1388             table=Table(model._meta.db_table, self.quote_name),
1389             name=self.quote_name(name),
1390         )
1391 
1392     def _rename_index_sql(self, model, old_name, new_name):
1393         return Statement(
1394             self.sql_rename_index,
1395             table=Table(model._meta.db_table, self.quote_name),
1396             old_name=self.quote_name(old_name),
1397             new_name=self.quote_name(new_name),
1398         )
1399 
1400     def _index_columns(self, table, columns, col_suffixes, opclasses):
1401         return Columns(table, columns, self.quote_name, col_suffixes=col_suffixes)
1402 
1403     def _model_indexes_sql(self, model):
1404         """
1405         Return a list of all index SQL statements (field indexes,
1406         index_together, Meta.indexes) for the specified model.
1407         """
1408         if not model._meta.managed or model._meta.proxy or model._meta.swapped:
1409             return []
1410         output = []
1411         for field in model._meta.local_fields:
1412             output.extend(self._field_indexes_sql(model, field))
1413 
1414         for field_names in model._meta.index_together:
1415             fields = [model._meta.get_field(field) for field in field_names]
1416             output.append(self._create_index_sql(model, fields=fields, suffix="_idx"))
1417 
1418         for index in model._meta.indexes:
1419             if (
1420                 not index.contains_expressions
1421                 or self.connection.features.supports_expression_indexes
1422             ):
1423                 output.append(index.create_sql(model, self))
1424         return output
1425 
1426     def _field_indexes_sql(self, model, field):
1427         """
1428         Return a list of all index SQL statements for the specified field.
1429         """
1430         output = []
1431         if self._field_should_be_indexed(model, field):
1432             output.append(self._create_index_sql(model, fields=[field]))
1433         return output
1434 
1435     def _field_should_be_altered(self, old_field, new_field):
1436         _, old_path, old_args, old_kwargs = old_field.deconstruct()
1437         _, new_path, new_args, new_kwargs = new_field.deconstruct()
1438         # Don't alter when:
1439         # - changing only a field name
1440         # - changing an attribute that doesn't affect the schema
1441         # - adding only a db_column and the column name is not changed
1442         for attr in old_field.non_db_attrs:
1443             old_kwargs.pop(attr, None)
1444         for attr in new_field.non_db_attrs:
1445             new_kwargs.pop(attr, None)
1446         return self.quote_name(old_field.column) != self.quote_name(
1447             new_field.column
1448         ) or (old_path, old_args, old_kwargs) != (new_path, new_args, new_kwargs)
1449 
1450     def _field_should_be_indexed(self, model, field):
1451         return field.db_index and not field.unique
1452 
1453     def _field_became_primary_key(self, old_field, new_field):
1454         return not old_field.primary_key and new_field.primary_key
1455 
1456     def _unique_should_be_added(self, old_field, new_field):
1457         return (
1458             not new_field.primary_key
1459             and new_field.unique
1460             and (not old_field.unique or old_field.primary_key)
1461         )
1462 
1463     def _rename_field_sql(self, table, old_field, new_field, new_type):
1464         return self.sql_rename_column % {
1465             "table": self.quote_name(table),
1466             "old_column": self.quote_name(old_field.column),
1467             "new_column": self.quote_name(new_field.column),
1468             "type": new_type,
1469         }
1470 
1471     def _create_fk_sql(self, model, field, suffix):
1472         table = Table(model._meta.db_table, self.quote_name)
1473         name = self._fk_constraint_name(model, field, suffix)
1474         column = Columns(model._meta.db_table, [field.column], self.quote_name)
1475         to_table = Table(field.target_field.model._meta.db_table, self.quote_name)
1476         to_column = Columns(
1477             field.target_field.model._meta.db_table,
1478             [field.target_field.column],
1479             self.quote_name,
1480         )
1481         deferrable = self.connection.ops.deferrable_sql()
1482         return Statement(
1483             self.sql_create_fk,
1484             table=table,
1485             name=name,
1486             column=column,
1487             to_table=to_table,
1488             to_column=to_column,
1489             deferrable=deferrable,
1490         )
1491 
1492     def _fk_constraint_name(self, model, field, suffix):
1493         def create_fk_name(*args, **kwargs):
1494             return self.quote_name(self._create_index_name(*args, **kwargs))
1495 
1496         return ForeignKeyName(
1497             model._meta.db_table,
1498             [field.column],
1499             split_identifier(field.target_field.model._meta.db_table)[1],
1500             [field.target_field.column],
1501             suffix,
1502             create_fk_name,
1503         )
1504 
1505     def _delete_fk_sql(self, model, name):
1506         return self._delete_constraint_sql(self.sql_delete_fk, model, name)
1507 
1508     def _deferrable_constraint_sql(self, deferrable):
1509         if deferrable is None:
1510             return ""
1511         if deferrable == Deferrable.DEFERRED:
1512             return " DEFERRABLE INITIALLY DEFERRED"
1513         if deferrable == Deferrable.IMMEDIATE:
1514             return " DEFERRABLE INITIALLY IMMEDIATE"
1515 
1516     def _unique_sql(
1517         self,
1518         model,
1519         fields,
1520         name,
1521         condition=None,
1522         deferrable=None,
1523         include=None,
1524         opclasses=None,
1525         expressions=None,
1526     ):
1527         if (
1528             deferrable
1529             and not self.connection.features.supports_deferrable_unique_constraints
1530         ):
1531             return None
1532         if condition or include or opclasses or expressions:
1533             # Databases support conditional, covering, and functional unique
1534             # constraints via a unique index.
1535             sql = self._create_unique_sql(
1536                 model,
1537                 fields,
1538                 name=name,
1539                 condition=condition,
1540                 include=include,
1541                 opclasses=opclasses,
1542                 expressions=expressions,
1543             )
1544             if sql:
1545                 self.deferred_sql.append(sql)
1546             return None
1547         constraint = self.sql_unique_constraint % {
1548             "columns": ", ".join([self.quote_name(field.column) for field in fields]),
1549             "deferrable": self._deferrable_constraint_sql(deferrable),
1550         }
1551         return self.sql_constraint % {
1552             "name": self.quote_name(name),
1553             "constraint": constraint,
1554         }
1555 
1556     def _create_unique_sql(
1557         self,
1558         model,
1559         fields,
1560         name=None,
1561         condition=None,
1562         deferrable=None,
1563         include=None,
1564         opclasses=None,
1565         expressions=None,
1566     ):
1567         if (
1568             (
1569                 deferrable
1570                 and not self.connection.features.supports_deferrable_unique_constraints
1571             )
1572             or (condition and not self.connection.features.supports_partial_indexes)
1573             or (include and not self.connection.features.supports_covering_indexes)
1574             or (
1575                 expressions and not self.connection.features.supports_expression_indexes
1576             )
1577         ):
1578             return None
1579 
1580         compiler = Query(model, alias_cols=False).get_compiler(
1581             connection=self.connection
1582         )
1583         table = model._meta.db_table
1584         columns = [field.column for field in fields]
1585         if name is None:
1586             name = self._unique_constraint_name(table, columns, quote=True)
1587         else:
1588             name = self.quote_name(name)
1589         if condition or include or opclasses or expressions:
1590             sql = self.sql_create_unique_index
1591         else:
1592             sql = self.sql_create_unique
1593         if columns:
1594             columns = self._index_columns(
1595                 table, columns, col_suffixes=(), opclasses=opclasses
1596             )
1597         else:
1598             columns = Expressions(table, expressions, compiler, self.quote_value)
1599         return Statement(
1600             sql,
1601             table=Table(table, self.quote_name),
1602             name=name,
1603             columns=columns,
1604             condition=self._index_condition_sql(condition),
1605             deferrable=self._deferrable_constraint_sql(deferrable),
1606             include=self._index_include_sql(model, include),
1607         )
1608 
1609     def _unique_constraint_name(self, table, columns, quote=True):
1610         if quote:
1611 
1612             def create_unique_name(*args, **kwargs):
1613                 return self.quote_name(self._create_index_name(*args, **kwargs))
1614 
1615         else:
1616             create_unique_name = self._create_index_name
1617 
1618         return IndexName(table, columns, "_uniq", create_unique_name)
1619 
1620     def _delete_unique_sql(
1621         self,
1622         model,
1623         name,
1624         condition=None,
1625         deferrable=None,
1626         include=None,
1627         opclasses=None,
1628         expressions=None,
1629     ):
1630         if (
1631             (
1632                 deferrable
1633                 and not self.connection.features.supports_deferrable_unique_constraints
1634             )
1635             or (condition and not self.connection.features.supports_partial_indexes)
1636             or (include and not self.connection.features.supports_covering_indexes)
1637             or (
1638                 expressions and not self.connection.features.supports_expression_indexes
1639             )
1640         ):
1641             return None
1642         if condition or include or opclasses or expressions:
1643             sql = self.sql_delete_index
1644         else:
1645             sql = self.sql_delete_unique
1646         return self._delete_constraint_sql(sql, model, name)
1647 
1648     def _check_sql(self, name, check):
1649         return self.sql_constraint % {
1650             "name": self.quote_name(name),
1651             "constraint": self.sql_check_constraint % {"check": check},
1652         }
1653 
1654     def _create_check_sql(self, model, name, check):
1655         return Statement(
1656             self.sql_create_check,
1657             table=Table(model._meta.db_table, self.quote_name),
1658             name=self.quote_name(name),
1659             check=check,
1660         )
1661 
1662     def _delete_check_sql(self, model, name):
1663         return self._delete_constraint_sql(self.sql_delete_check, model, name)
1664 
1665     def _delete_constraint_sql(self, template, model, name):
1666         return Statement(
1667             template,
1668             table=Table(model._meta.db_table, self.quote_name),
1669             name=self.quote_name(name),
1670         )
1671 
1672     def _constraint_names(
1673         self,
1674         model,
1675         column_names=None,
1676         unique=None,
1677         primary_key=None,
1678         index=None,
1679         foreign_key=None,
1680         check=None,
1681         type_=None,
1682         exclude=None,
1683     ):
1684         """Return all constraint names matching the columns and conditions."""
1685         if column_names is not None:
1686             column_names = [
1687                 self.connection.introspection.identifier_converter(name)
1688                 for name in column_names
1689             ]
1690         with self.connection.cursor() as cursor:
1691             constraints = self.connection.introspection.get_constraints(
1692                 cursor, model._meta.db_table
1693             )
1694         result = []
1695         for name, infodict in constraints.items():
1696             if column_names is None or column_names == infodict["columns"]:
1697                 if unique is not None and infodict["unique"] != unique:
1698                     continue
1699                 if primary_key is not None and infodict["primary_key"] != primary_key:
1700                     continue
1701                 if index is not None and infodict["index"] != index:
1702                     continue
1703                 if check is not None and infodict["check"] != check:
1704                     continue
1705                 if foreign_key is not None and not infodict["foreign_key"]:
1706                     continue
1707                 if type_ is not None and infodict["type"] != type_:
1708                     continue
1709                 if not exclude or name not in exclude:
1710                     result.append(name)
1711         return result
1712 
1713     def _delete_primary_key(self, model, strict=False):
1714         constraint_names = self._constraint_names(model, primary_key=True)
1715         if strict and len(constraint_names) != 1:
1716             raise ValueError(
1717                 "Found wrong number (%s) of PK constraints for %s"
1718                 % (
1719                     len(constraint_names),
1720                     model._meta.db_table,
1721                 )
1722             )
1723         for constraint_name in constraint_names:
1724             self.execute(self._delete_primary_key_sql(model, constraint_name))
1725 
1726     def _create_primary_key_sql(self, model, field):
1727         return Statement(
1728             self.sql_create_pk,
1729             table=Table(model._meta.db_table, self.quote_name),
1730             name=self.quote_name(
1731                 self._create_index_name(
1732                     model._meta.db_table, [field.column], suffix="_pk"
1733                 )
1734             ),
1735             columns=Columns(model._meta.db_table, [field.column], self.quote_name),
1736         )
1737 
1738     def _delete_primary_key_sql(self, model, name):
1739         return self._delete_constraint_sql(self.sql_delete_pk, model, name)
1740 
1741     def _collate_sql(self, collation):
1742         return "COLLATE " + self.quote_name(collation)
1743 
1744     def remove_procedure(self, procedure_name, param_types=()):
1745         sql = self.sql_delete_procedure % {
1746             "procedure": self.quote_name(procedure_name),
1747             "param_types": ",".join(param_types),
1748         }
1749         self.execute(sql)

</code><intended_behavior>Ensure schema generation logic translates `indexes` attributes into correct SQL statements, maintaining functionality equivalence with `index_together`.</intended_behavior>, <file>django/db/backends/sqlite3/schema.py</file>
<class>None</class>
<method>None</method>
<code>
1 import copy
2 from decimal import Decimal
3 
4 from django.apps.registry import Apps
5 from django.db import NotSupportedError
6 from django.db.backends.base.schema import BaseDatabaseSchemaEditor
7 from django.db.backends.ddl_references import Statement
8 from django.db.backends.utils import strip_quotes
9 from django.db.models import UniqueConstraint
10 from django.db.transaction import atomic
11 
12 
13 class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):
14 
15     sql_delete_table = "DROP TABLE %(table)s"
16     sql_create_fk = None
17     sql_create_inline_fk = (
18         "REFERENCES %(to_table)s (%(to_column)s) DEFERRABLE INITIALLY DEFERRED"
19     )
20     sql_create_column_inline_fk = sql_create_inline_fk
21     sql_delete_column = "ALTER TABLE %(table)s DROP COLUMN %(column)s"
22     sql_create_unique = "CREATE UNIQUE INDEX %(name)s ON %(table)s (%(columns)s)"
23     sql_delete_unique = "DROP INDEX %(name)s"
24 
25     def __enter__(self):
26         # Some SQLite schema alterations need foreign key constraints to be
27         # disabled. Enforce it here for the duration of the schema edition.
28         if not self.connection.disable_constraint_checking():
29             raise NotSupportedError(
30                 "SQLite schema editor cannot be used while foreign key "
31                 "constraint checks are enabled. Make sure to disable them "
32                 "before entering a transaction.atomic() context because "
33                 "SQLite does not support disabling them in the middle of "
34                 "a multi-statement transaction."
35             )
36         return super().__enter__()
37 
38     def __exit__(self, exc_type, exc_value, traceback):
39         self.connection.check_constraints()
40         super().__exit__(exc_type, exc_value, traceback)
41         self.connection.enable_constraint_checking()
42 
43     def quote_value(self, value):
44         # The backend "mostly works" without this function and there are use
45         # cases for compiling Python without the sqlite3 libraries (e.g.
46         # security hardening).
47         try:
48             import sqlite3
49 
50             value = sqlite3.adapt(value)
51         except ImportError:
52             pass
53         except sqlite3.ProgrammingError:
54             pass
55         # Manual emulation of SQLite parameter quoting
56         if isinstance(value, bool):
57             return str(int(value))
58         elif isinstance(value, (Decimal, float, int)):
59             return str(value)
60         elif isinstance(value, str):
61             return "'%s'" % value.replace("'", "''")
62         elif value is None:
63             return "NULL"
64         elif isinstance(value, (bytes, bytearray, memoryview)):
65             # Bytes are only allowed for BLOB fields, encoded as string
66             # literals containing hexadecimal data and preceded by a single "X"
67             # character.
68             return "X'%s'" % value.hex()
69         else:
70             raise ValueError(
71                 "Cannot quote parameter value %r of type %s" % (value, type(value))
72             )
73 
74     def prepare_default(self, value):
75         return self.quote_value(value)
76 
77     def _is_referenced_by_fk_constraint(
78         self, table_name, column_name=None, ignore_self=False
79     ):
80         """
81         Return whether or not the provided table name is referenced by another
82         one. If `column_name` is specified, only references pointing to that
83         column are considered. If `ignore_self` is True, self-referential
84         constraints are ignored.
85         """
86         with self.connection.cursor() as cursor:
87             for other_table in self.connection.introspection.get_table_list(cursor):
88                 if ignore_self and other_table.name == table_name:
89                     continue
90                 relations = self.connection.introspection.get_relations(
91                     cursor, other_table.name
92                 )
93                 for constraint_column, constraint_table in relations.values():
94                     if constraint_table == table_name and (
95                         column_name is None or constraint_column == column_name
96                     ):
97                         return True
98         return False
99 
100     def alter_db_table(
101         self, model, old_db_table, new_db_table, disable_constraints=True
102     ):
103         if (
104             not self.connection.features.supports_atomic_references_rename
105             and disable_constraints
106             and self._is_referenced_by_fk_constraint(old_db_table)
107         ):
108             if self.connection.in_atomic_block:
109                 raise NotSupportedError(
110                     (
111                         "Renaming the %r table while in a transaction is not "
112                         "supported on SQLite < 3.26 because it would break referential "
113                         "integrity. Try adding `atomic = False` to the Migration class."
114                     )
115                     % old_db_table
116                 )
117             self.connection.enable_constraint_checking()
118             super().alter_db_table(model, old_db_table, new_db_table)
119             self.connection.disable_constraint_checking()
120         else:
121             super().alter_db_table(model, old_db_table, new_db_table)
122 
123     def alter_field(self, model, old_field, new_field, strict=False):
124         if not self._field_should_be_altered(old_field, new_field):
125             return
126         old_field_name = old_field.name
127         table_name = model._meta.db_table
128         _, old_column_name = old_field.get_attname_column()
129         if (
130             new_field.name != old_field_name
131             and not self.connection.features.supports_atomic_references_rename
132             and self._is_referenced_by_fk_constraint(
133                 table_name, old_column_name, ignore_self=True
134             )
135         ):
136             if self.connection.in_atomic_block:
137                 raise NotSupportedError(
138                     (
139                         "Renaming the %r.%r column while in a transaction is not "
140                         "supported on SQLite < 3.26 because it would break referential "
141                         "integrity. Try adding `atomic = False` to the Migration class."
142                     )
143                     % (model._meta.db_table, old_field_name)
144                 )
145             with atomic(self.connection.alias):
146                 super().alter_field(model, old_field, new_field, strict=strict)
147                 # Follow SQLite's documented procedure for performing changes
148                 # that don't affect the on-disk content.
149                 # https://sqlite.org/lang_altertable.html#otheralter
150                 with self.connection.cursor() as cursor:
151                     schema_version = cursor.execute("PRAGMA schema_version").fetchone()[
152                         0
153                     ]
154                     cursor.execute("PRAGMA writable_schema = 1")
155                     references_template = ' REFERENCES "%s" ("%%s") ' % table_name
156                     new_column_name = new_field.get_attname_column()[1]
157                     search = references_template % old_column_name
158                     replacement = references_template % new_column_name
159                     cursor.execute(
160                         "UPDATE sqlite_master SET sql = replace(sql, %s, %s)",
161                         (search, replacement),
162                     )
163                     cursor.execute("PRAGMA schema_version = %d" % (schema_version + 1))
164                     cursor.execute("PRAGMA writable_schema = 0")
165                     # The integrity check will raise an exception and rollback
166                     # the transaction if the sqlite_master updates corrupt the
167                     # database.
168                     cursor.execute("PRAGMA integrity_check")
169             # Perform a VACUUM to refresh the database representation from
170             # the sqlite_master table.
171             with self.connection.cursor() as cursor:
172                 cursor.execute("VACUUM")
173         else:
174             super().alter_field(model, old_field, new_field, strict=strict)
175 
176     def _remake_table(
177         self, model, create_field=None, delete_field=None, alter_field=None
178     ):
179         """
180         Shortcut to transform a model from old_model into new_model
181 
182         This follows the correct procedure to perform non-rename or column
183         addition operations based on SQLite's documentation
184 
185         https://www.sqlite.org/lang_altertable.html#caution
186 
187         The essential steps are:
188           1. Create a table with the updated definition called "new__app_model"
189           2. Copy the data from the existing "app_model" table to the new table
190           3. Drop the "app_model" table
191           4. Rename the "new__app_model" table to "app_model"
192           5. Restore any index of the previous "app_model" table.
193         """
194         # Self-referential fields must be recreated rather than copied from
195         # the old model to ensure their remote_field.field_name doesn't refer
196         # to an altered field.
197         def is_self_referential(f):
198             return f.is_relation and f.remote_field.model is model
199 
200         # Work out the new fields dict / mapping
201         body = {
202             f.name: f.clone() if is_self_referential(f) else f
203             for f in model._meta.local_concrete_fields
204         }
205         # Since mapping might mix column names and default values,
206         # its values must be already quoted.
207         mapping = {
208             f.column: self.quote_name(f.column)
209             for f in model._meta.local_concrete_fields
210         }
211         # This maps field names (not columns) for things like unique_together
212         rename_mapping = {}
213         # If any of the new or altered fields is introducing a new PK,
214         # remove the old one
215         restore_pk_field = None
216         if getattr(create_field, "primary_key", False) or (
217             alter_field and getattr(alter_field[1], "primary_key", False)
218         ):
219             for name, field in list(body.items()):
220                 if field.primary_key and not (
221                     # Do not remove the old primary key when an altered field
222                     # that introduces a primary key is the same field.
223                     alter_field
224                     and name == alter_field[1].name
225                 ):
226                     field.primary_key = False
227                     restore_pk_field = field
228                     if field.auto_created:
229                         del body[name]
230                         del mapping[field.column]
231         # Add in any created fields
232         if create_field:
233             body[create_field.name] = create_field
234             # Choose a default and insert it into the copy map
235             if not create_field.many_to_many and create_field.concrete:
236                 mapping[create_field.column] = self.prepare_default(
237                     self.effective_default(create_field),
238                 )
239         # Add in any altered fields
240         if alter_field:
241             old_field, new_field = alter_field
242             body.pop(old_field.name, None)
243             mapping.pop(old_field.column, None)
244             body[new_field.name] = new_field
245             if old_field.null and not new_field.null:
246                 case_sql = "coalesce(%(col)s, %(default)s)" % {
247                     "col": self.quote_name(old_field.column),
248                     "default": self.prepare_default(self.effective_default(new_field)),
249                 }
250                 mapping[new_field.column] = case_sql
251             else:
252                 mapping[new_field.column] = self.quote_name(old_field.column)
253             rename_mapping[old_field.name] = new_field.name
254         # Remove any deleted fields
255         if delete_field:
256             del body[delete_field.name]
257             del mapping[delete_field.column]
258             # Remove any implicit M2M tables
259             if (
260                 delete_field.many_to_many
261                 and delete_field.remote_field.through._meta.auto_created
262             ):
263                 return self.delete_model(delete_field.remote_field.through)
264         # Work inside a new app registry
265         apps = Apps()
266 
267         # Work out the new value of unique_together, taking renames into
268         # account
269         unique_together = [
270             [rename_mapping.get(n, n) for n in unique]
271             for unique in model._meta.unique_together
272         ]
273 
274         # Work out the new value for index_together, taking renames into
275         # account
276         index_together = [
277             [rename_mapping.get(n, n) for n in index]
278             for index in model._meta.index_together
279         ]
280 
281         indexes = model._meta.indexes
282         if delete_field:
283             indexes = [
284                 index for index in indexes if delete_field.name not in index.fields
285             ]
286 
287         constraints = list(model._meta.constraints)
288 
289         # Provide isolated instances of the fields to the new model body so
290         # that the existing model's internals aren't interfered with when
291         # the dummy model is constructed.
292         body_copy = copy.deepcopy(body)
293 
294         # Construct a new model with the new fields to allow self referential
295         # primary key to resolve to. This model won't ever be materialized as a
296         # table and solely exists for foreign key reference resolution purposes.
297         # This wouldn't be required if the schema editor was operating on model
298         # states instead of rendered models.
299         meta_contents = {
300             "app_label": model._meta.app_label,
301             "db_table": model._meta.db_table,
302             "unique_together": unique_together,
303             "index_together": index_together,
304             "indexes": indexes,
305             "constraints": constraints,
306             "apps": apps,
307         }
308         meta = type("Meta", (), meta_contents)
309         body_copy["Meta"] = meta
310         body_copy["__module__"] = model.__module__
311         type(model._meta.object_name, model.__bases__, body_copy)
312 
313         # Construct a model with a renamed table name.
314         body_copy = copy.deepcopy(body)
315         meta_contents = {
316             "app_label": model._meta.app_label,
317             "db_table": "new__%s" % strip_quotes(model._meta.db_table),
318             "unique_together": unique_together,
319             "index_together": index_together,
320             "indexes": indexes,
321             "constraints": constraints,
322             "apps": apps,
323         }
324         meta = type("Meta", (), meta_contents)
325         body_copy["Meta"] = meta
326         body_copy["__module__"] = model.__module__
327         new_model = type("New%s" % model._meta.object_name, model.__bases__, body_copy)
328 
329         # Create a new table with the updated schema.
330         self.create_model(new_model)
331 
332         # Copy data from the old table into the new table
333         self.execute(
334             "INSERT INTO %s (%s) SELECT %s FROM %s"
335             % (
336                 self.quote_name(new_model._meta.db_table),
337                 ", ".join(self.quote_name(x) for x in mapping),
338                 ", ".join(mapping.values()),
339                 self.quote_name(model._meta.db_table),
340             )
341         )
342 
343         # Delete the old table to make way for the new
344         self.delete_model(model, handle_autom2m=False)
345 
346         # Rename the new table to take way for the old
347         self.alter_db_table(
348             new_model,
349             new_model._meta.db_table,
350             model._meta.db_table,
351             disable_constraints=False,
352         )
353 
354         # Run deferred SQL on correct table
355         for sql in self.deferred_sql:
356             self.execute(sql)
357         self.deferred_sql = []
358         # Fix any PK-removed field
359         if restore_pk_field:
360             restore_pk_field.primary_key = True
361 
362     def delete_model(self, model, handle_autom2m=True):
363         if handle_autom2m:
364             super().delete_model(model)
365         else:
366             # Delete the table (and only that)
367             self.execute(
368                 self.sql_delete_table
369                 % {
370                     "table": self.quote_name(model._meta.db_table),
371                 }
372             )
373             # Remove all deferred statements referencing the deleted table.
374             for sql in list(self.deferred_sql):
375                 if isinstance(sql, Statement) and sql.references_table(
376                     model._meta.db_table
377                 ):
378                     self.deferred_sql.remove(sql)
379 
380     def add_field(self, model, field):
381         """Create a field on a model."""
382         if (
383             # Primary keys and unique fields are not supported in ALTER TABLE
384             # ADD COLUMN.
385             field.primary_key
386             or field.unique
387             or
388             # Fields with default values cannot by handled by ALTER TABLE ADD
389             # COLUMN statement because DROP DEFAULT is not supported in
390             # ALTER TABLE.
391             not field.null
392             or self.effective_default(field) is not None
393         ):
394             self._remake_table(model, create_field=field)
395         else:
396             super().add_field(model, field)
397 
398     def remove_field(self, model, field):
399         """
400         Remove a field from a model. Usually involves deleting a column,
401         but for M2Ms may involve deleting a table.
402         """
403         # M2M fields are a special case
404         if field.many_to_many:
405             # For implicit M2M tables, delete the auto-created table
406             if field.remote_field.through._meta.auto_created:
407                 self.delete_model(field.remote_field.through)
408             # For explicit "through" M2M fields, do nothing
409         elif (
410             self.connection.features.can_alter_table_drop_column
411             # Primary keys, unique fields, and foreign keys are not
412             # supported in ALTER TABLE DROP COLUMN.
413             and not field.primary_key
414             and not field.unique
415             and not (field.remote_field and field.db_constraint)
416         ):
417             super().remove_field(model, field)
418         # For everything else, remake.
419         else:
420             # It might not actually have a column behind it
421             if field.db_parameters(connection=self.connection)["type"] is None:
422                 return
423             self._remake_table(model, delete_field=field)
424 
425     def _alter_field(
426         self,
427         model,
428         old_field,
429         new_field,
430         old_type,
431         new_type,
432         old_db_params,
433         new_db_params,
434         strict=False,
435     ):
436         """Perform a "physical" (non-ManyToMany) field update."""
437         # Use "ALTER TABLE ... RENAME COLUMN" if only the column name
438         # changed and there aren't any constraints.
439         if (
440             self.connection.features.can_alter_table_rename_column
441             and old_field.column != new_field.column
442             and self.column_sql(model, old_field) == self.column_sql(model, new_field)
443             and not (
444                 old_field.remote_field
445                 and old_field.db_constraint
446                 or new_field.remote_field
447                 and new_field.db_constraint
448             )
449         ):
450             return self.execute(
451                 self._rename_field_sql(
452                     model._meta.db_table, old_field, new_field, new_type
453                 )
454             )
455         # Alter by remaking table
456         self._remake_table(model, alter_field=(old_field, new_field))
457         # Rebuild tables with FKs pointing to this field.
458         old_collation = old_db_params.get("collation")
459         new_collation = new_db_params.get("collation")
460         if new_field.unique and (
461             old_type != new_type or old_collation != new_collation
462         ):
463             related_models = set()
464             opts = new_field.model._meta
465             for remote_field in opts.related_objects:
466                 # Ignore self-relationship since the table was already rebuilt.
467                 if remote_field.related_model == model:
468                     continue
469                 if not remote_field.many_to_many:
470                     if remote_field.field_name == new_field.name:
471                         related_models.add(remote_field.related_model)
472                 elif new_field.primary_key and remote_field.through._meta.auto_created:
473                     related_models.add(remote_field.through)
474             if new_field.primary_key:
475                 for many_to_many in opts.many_to_many:
476                     # Ignore self-relationship since the table was already rebuilt.
477                     if many_to_many.related_model == model:
478                         continue
479                     if many_to_many.remote_field.through._meta.auto_created:
480                         related_models.add(many_to_many.remote_field.through)
481             for related_model in related_models:
482                 self._remake_table(related_model)
483 
484     def _alter_many_to_many(self, model, old_field, new_field, strict):
485         """Alter M2Ms to repoint their to= endpoints."""
486         if (
487             old_field.remote_field.through._meta.db_table
488             == new_field.remote_field.through._meta.db_table
489         ):
490             # The field name didn't change, but some options did, so we have to
491             # propagate this altering.
492             self._remake_table(
493                 old_field.remote_field.through,
494                 alter_field=(
495                     # The field that points to the target model is needed, so
496                     # we can tell alter_field to change it - this is
497                     # m2m_reverse_field_name() (as opposed to m2m_field_name(),
498                     # which points to our model).
499                     old_field.remote_field.through._meta.get_field(
500                         old_field.m2m_reverse_field_name()
501                     ),
502                     new_field.remote_field.through._meta.get_field(
503                         new_field.m2m_reverse_field_name()
504                     ),
505                 ),
506             )
507             return
508 
509         # Make a new through table
510         self.create_model(new_field.remote_field.through)
511         # Copy the data across
512         self.execute(
513             "INSERT INTO %s (%s) SELECT %s FROM %s"
514             % (
515                 self.quote_name(new_field.remote_field.through._meta.db_table),
516                 ", ".join(
517                     [
518                         "id",
519                         new_field.m2m_column_name(),
520                         new_field.m2m_reverse_name(),
521                     ]
522                 ),
523                 ", ".join(
524                     [
525                         "id",
526                         old_field.m2m_column_name(),
527                         old_field.m2m_reverse_name(),
528                     ]
529                 ),
530                 self.quote_name(old_field.remote_field.through._meta.db_table),
531             )
532         )
533         # Delete the old through table
534         self.delete_model(old_field.remote_field.through)
535 
536     def add_constraint(self, model, constraint):
537         if isinstance(constraint, UniqueConstraint) and (
538             constraint.condition
539             or constraint.contains_expressions
540             or constraint.include
541             or constraint.deferrable
542         ):
543             super().add_constraint(model, constraint)
544         else:
545             self._remake_table(model)
546 
547     def remove_constraint(self, model, constraint):
548         if isinstance(constraint, UniqueConstraint) and (
549             constraint.condition
550             or constraint.contains_expressions
551             or constraint.include
552             or constraint.deferrable
553         ):
554             super().remove_constraint(model, constraint)
555         else:
556             self._remake_table(model)
557 
558     def _collate_sql(self, collation):
559         return "COLLATE " + collation

</code><intended_behavior>Ensure compatibility or appropriate translation to use of `indexes`, ensuring backend-specific handling of `index_together` is updated.</intended_behavior>]
2025-10-17 13:13:32.212 | INFO     | Overall retry 0 succeeded; ending workflow
2025-10-17 13:13:32.213 | INFO     | Search-only: skipping patch selection
2025-10-17 13:13:32.376 | INFO     | Task django__django-15703 completed successfully.
2025-10-17 13:13:32.377 | INFO     | No patch generated. You can try running ACR again.
