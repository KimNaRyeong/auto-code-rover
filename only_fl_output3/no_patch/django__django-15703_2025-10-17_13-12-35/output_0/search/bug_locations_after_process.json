[
    {
        "rel_file_path": "django/db/models/options.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__4.2/django/db/models/options.py",
        "start": 1,
        "end": 988,
        "class_name": null,
        "method_name": null,
        "code": "1 import bisect\n2 import copy\n3 import inspect\n4 from collections import defaultdict\n5 \n6 from django.apps import apps\n7 from django.conf import settings\n8 from django.core.exceptions import FieldDoesNotExist, ImproperlyConfigured\n9 from django.db import connections\n10 from django.db.models import AutoField, Manager, OrderWrt, UniqueConstraint\n11 from django.db.models.query_utils import PathInfo\n12 from django.utils.datastructures import ImmutableList, OrderedSet\n13 from django.utils.functional import cached_property\n14 from django.utils.module_loading import import_string\n15 from django.utils.text import camel_case_to_spaces, format_lazy\n16 from django.utils.translation import override\n17 \n18 PROXY_PARENTS = object()\n19 \n20 EMPTY_RELATION_TREE = ()\n21 \n22 IMMUTABLE_WARNING = (\n23     \"The return type of '%s' should never be mutated. If you want to manipulate this \"\n24     \"list for your own use, make a copy first.\"\n25 )\n26 \n27 DEFAULT_NAMES = (\n28     \"verbose_name\",\n29     \"verbose_name_plural\",\n30     \"db_table\",\n31     \"ordering\",\n32     \"unique_together\",\n33     \"permissions\",\n34     \"get_latest_by\",\n35     \"order_with_respect_to\",\n36     \"app_label\",\n37     \"db_tablespace\",\n38     \"abstract\",\n39     \"managed\",\n40     \"proxy\",\n41     \"swappable\",\n42     \"auto_created\",\n43     \"index_together\",\n44     \"apps\",\n45     \"default_permissions\",\n46     \"select_on_save\",\n47     \"default_related_name\",\n48     \"required_db_features\",\n49     \"required_db_vendor\",\n50     \"base_manager_name\",\n51     \"default_manager_name\",\n52     \"indexes\",\n53     \"constraints\",\n54 )\n55 \n56 \n57 def normalize_together(option_together):\n58     \"\"\"\n59     option_together can be either a tuple of tuples, or a single\n60     tuple of two strings. Normalize it to a tuple of tuples, so that\n61     calling code can uniformly expect that.\n62     \"\"\"\n63     try:\n64         if not option_together:\n65             return ()\n66         if not isinstance(option_together, (tuple, list)):\n67             raise TypeError\n68         first_element = option_together[0]\n69         if not isinstance(first_element, (tuple, list)):\n70             option_together = (option_together,)\n71         # Normalize everything to tuples\n72         return tuple(tuple(ot) for ot in option_together)\n73     except TypeError:\n74         # If the value of option_together isn't valid, return it\n75         # verbatim; this will be picked up by the check framework later.\n76         return option_together\n77 \n78 \n79 def make_immutable_fields_list(name, data):\n80     return ImmutableList(data, warning=IMMUTABLE_WARNING % name)\n81 \n82 \n83 class Options:\n84     FORWARD_PROPERTIES = {\n85         \"fields\",\n86         \"many_to_many\",\n87         \"concrete_fields\",\n88         \"local_concrete_fields\",\n89         \"_forward_fields_map\",\n90         \"managers\",\n91         \"managers_map\",\n92         \"base_manager\",\n93         \"default_manager\",\n94     }\n95     REVERSE_PROPERTIES = {\"related_objects\", \"fields_map\", \"_relation_tree\"}\n96 \n97     default_apps = apps\n98 \n99     def __init__(self, meta, app_label=None):\n100         self._get_fields_cache = {}\n101         self.local_fields = []\n102         self.local_many_to_many = []\n103         self.private_fields = []\n104         self.local_managers = []\n105         self.base_manager_name = None\n106         self.default_manager_name = None\n107         self.model_name = None\n108         self.verbose_name = None\n109         self.verbose_name_plural = None\n110         self.db_table = \"\"\n111         self.ordering = []\n112         self._ordering_clash = False\n113         self.indexes = []\n114         self.constraints = []\n115         self.unique_together = []\n116         self.index_together = []\n117         self.select_on_save = False\n118         self.default_permissions = (\"add\", \"change\", \"delete\", \"view\")\n119         self.permissions = []\n120         self.object_name = None\n121         self.app_label = app_label\n122         self.get_latest_by = None\n123         self.order_with_respect_to = None\n124         self.db_tablespace = settings.DEFAULT_TABLESPACE\n125         self.required_db_features = []\n126         self.required_db_vendor = None\n127         self.meta = meta\n128         self.pk = None\n129         self.auto_field = None\n130         self.abstract = False\n131         self.managed = True\n132         self.proxy = False\n133         # For any class that is a proxy (including automatically created\n134         # classes for deferred object loading), proxy_for_model tells us\n135         # which class this model is proxying. Note that proxy_for_model\n136         # can create a chain of proxy models. For non-proxy models, the\n137         # variable is always None.\n138         self.proxy_for_model = None\n139         # For any non-abstract class, the concrete class is the model\n140         # in the end of the proxy_for_model chain. In particular, for\n141         # concrete models, the concrete_model is always the class itself.\n142         self.concrete_model = None\n143         self.swappable = None\n144         self.parents = {}\n145         self.auto_created = False\n146 \n147         # List of all lookups defined in ForeignKey 'limit_choices_to' options\n148         # from *other* models. Needed for some admin checks. Internal use only.\n149         self.related_fkey_lookups = []\n150 \n151         # A custom app registry to use, if you're making a separate model set.\n152         self.apps = self.default_apps\n153 \n154         self.default_related_name = None\n155 \n156     @property\n157     def label(self):\n158         return \"%s.%s\" % (self.app_label, self.object_name)\n159 \n160     @property\n161     def label_lower(self):\n162         return \"%s.%s\" % (self.app_label, self.model_name)\n163 \n164     @property\n165     def app_config(self):\n166         # Don't go through get_app_config to avoid triggering imports.\n167         return self.apps.app_configs.get(self.app_label)\n168 \n169     def contribute_to_class(self, cls, name):\n170         from django.db import connection\n171         from django.db.backends.utils import truncate_name\n172 \n173         cls._meta = self\n174         self.model = cls\n175         # First, construct the default values for these options.\n176         self.object_name = cls.__name__\n177         self.model_name = self.object_name.lower()\n178         self.verbose_name = camel_case_to_spaces(self.object_name)\n179 \n180         # Store the original user-defined values for each option,\n181         # for use when serializing the model definition\n182         self.original_attrs = {}\n183 \n184         # Next, apply any overridden values from 'class Meta'.\n185         if self.meta:\n186             meta_attrs = self.meta.__dict__.copy()\n187             for name in self.meta.__dict__:\n188                 # Ignore any private attributes that Django doesn't care about.\n189                 # NOTE: We can't modify a dictionary's contents while looping\n190                 # over it, so we loop over the *original* dictionary instead.\n191                 if name.startswith(\"_\"):\n192                     del meta_attrs[name]\n193             for attr_name in DEFAULT_NAMES:\n194                 if attr_name in meta_attrs:\n195                     setattr(self, attr_name, meta_attrs.pop(attr_name))\n196                     self.original_attrs[attr_name] = getattr(self, attr_name)\n197                 elif hasattr(self.meta, attr_name):\n198                     setattr(self, attr_name, getattr(self.meta, attr_name))\n199                     self.original_attrs[attr_name] = getattr(self, attr_name)\n200 \n201             self.unique_together = normalize_together(self.unique_together)\n202             self.index_together = normalize_together(self.index_together)\n203             # App label/class name interpolation for names of constraints and\n204             # indexes.\n205             if not getattr(cls._meta, \"abstract\", False):\n206                 for attr_name in {\"constraints\", \"indexes\"}:\n207                     objs = getattr(self, attr_name, [])\n208                     setattr(self, attr_name, self._format_names_with_class(cls, objs))\n209 \n210             # verbose_name_plural is a special case because it uses a 's'\n211             # by default.\n212             if self.verbose_name_plural is None:\n213                 self.verbose_name_plural = format_lazy(\"{}s\", self.verbose_name)\n214 \n215             # order_with_respect_and ordering are mutually exclusive.\n216             self._ordering_clash = bool(self.ordering and self.order_with_respect_to)\n217 \n218             # Any leftover attributes must be invalid.\n219             if meta_attrs != {}:\n220                 raise TypeError(\n221                     \"'class Meta' got invalid attribute(s): %s\" % \",\".join(meta_attrs)\n222                 )\n223         else:\n224             self.verbose_name_plural = format_lazy(\"{}s\", self.verbose_name)\n225         del self.meta\n226 \n227         # If the db_table wasn't provided, use the app_label + model_name.\n228         if not self.db_table:\n229             self.db_table = \"%s_%s\" % (self.app_label, self.model_name)\n230             self.db_table = truncate_name(\n231                 self.db_table, connection.ops.max_name_length()\n232             )\n233 \n234     def _format_names_with_class(self, cls, objs):\n235         \"\"\"App label/class name interpolation for object names.\"\"\"\n236         new_objs = []\n237         for obj in objs:\n238             obj = obj.clone()\n239             obj.name = obj.name % {\n240                 \"app_label\": cls._meta.app_label.lower(),\n241                 \"class\": cls.__name__.lower(),\n242             }\n243             new_objs.append(obj)\n244         return new_objs\n245 \n246     def _get_default_pk_class(self):\n247         pk_class_path = getattr(\n248             self.app_config,\n249             \"default_auto_field\",\n250             settings.DEFAULT_AUTO_FIELD,\n251         )\n252         if self.app_config and self.app_config._is_default_auto_field_overridden:\n253             app_config_class = type(self.app_config)\n254             source = (\n255                 f\"{app_config_class.__module__}.\"\n256                 f\"{app_config_class.__qualname__}.default_auto_field\"\n257             )\n258         else:\n259             source = \"DEFAULT_AUTO_FIELD\"\n260         if not pk_class_path:\n261             raise ImproperlyConfigured(f\"{source} must not be empty.\")\n262         try:\n263             pk_class = import_string(pk_class_path)\n264         except ImportError as e:\n265             msg = (\n266                 f\"{source} refers to the module '{pk_class_path}' that could \"\n267                 f\"not be imported.\"\n268             )\n269             raise ImproperlyConfigured(msg) from e\n270         if not issubclass(pk_class, AutoField):\n271             raise ValueError(\n272                 f\"Primary key '{pk_class_path}' referred by {source} must \"\n273                 f\"subclass AutoField.\"\n274             )\n275         return pk_class\n276 \n277     def _prepare(self, model):\n278         if self.order_with_respect_to:\n279             # The app registry will not be ready at this point, so we cannot\n280             # use get_field().\n281             query = self.order_with_respect_to\n282             try:\n283                 self.order_with_respect_to = next(\n284                     f\n285                     for f in self._get_fields(reverse=False)\n286                     if f.name == query or f.attname == query\n287                 )\n288             except StopIteration:\n289                 raise FieldDoesNotExist(\n290                     \"%s has no field named '%s'\" % (self.object_name, query)\n291                 )\n292 \n293             self.ordering = (\"_order\",)\n294             if not any(\n295                 isinstance(field, OrderWrt) for field in model._meta.local_fields\n296             ):\n297                 model.add_to_class(\"_order\", OrderWrt())\n298         else:\n299             self.order_with_respect_to = None\n300 \n301         if self.pk is None:\n302             if self.parents:\n303                 # Promote the first parent link in lieu of adding yet another\n304                 # field.\n305                 field = next(iter(self.parents.values()))\n306                 # Look for a local field with the same name as the\n307                 # first parent link. If a local field has already been\n308                 # created, use it instead of promoting the parent\n309                 already_created = [\n310                     fld for fld in self.local_fields if fld.name == field.name\n311                 ]\n312                 if already_created:\n313                     field = already_created[0]\n314                 field.primary_key = True\n315                 self.setup_pk(field)\n316             else:\n317                 pk_class = self._get_default_pk_class()\n318                 auto = pk_class(verbose_name=\"ID\", primary_key=True, auto_created=True)\n319                 model.add_to_class(\"id\", auto)\n320 \n321     def add_manager(self, manager):\n322         self.local_managers.append(manager)\n323         self._expire_cache()\n324 \n325     def add_field(self, field, private=False):\n326         # Insert the given field in the order in which it was created, using\n327         # the \"creation_counter\" attribute of the field.\n328         # Move many-to-many related fields from self.fields into\n329         # self.many_to_many.\n330         if private:\n331             self.private_fields.append(field)\n332         elif field.is_relation and field.many_to_many:\n333             bisect.insort(self.local_many_to_many, field)\n334         else:\n335             bisect.insort(self.local_fields, field)\n336             self.setup_pk(field)\n337 \n338         # If the field being added is a relation to another known field,\n339         # expire the cache on this field and the forward cache on the field\n340         # being referenced, because there will be new relationships in the\n341         # cache. Otherwise, expire the cache of references *to* this field.\n342         # The mechanism for getting at the related model is slightly odd -\n343         # ideally, we'd just ask for field.related_model. However, related_model\n344         # is a cached property, and all the models haven't been loaded yet, so\n345         # we need to make sure we don't cache a string reference.\n346         if (\n347             field.is_relation\n348             and hasattr(field.remote_field, \"model\")\n349             and field.remote_field.model\n350         ):\n351             try:\n352                 field.remote_field.model._meta._expire_cache(forward=False)\n353             except AttributeError:\n354                 pass\n355             self._expire_cache()\n356         else:\n357             self._expire_cache(reverse=False)\n358 \n359     def setup_pk(self, field):\n360         if not self.pk and field.primary_key:\n361             self.pk = field\n362             field.serialize = False\n363 \n364     def setup_proxy(self, target):\n365         \"\"\"\n366         Do the internal setup so that the current model is a proxy for\n367         \"target\".\n368         \"\"\"\n369         self.pk = target._meta.pk\n370         self.proxy_for_model = target\n371         self.db_table = target._meta.db_table\n372 \n373     def __repr__(self):\n374         return \"<Options for %s>\" % self.object_name\n375 \n376     def __str__(self):\n377         return self.label_lower\n378 \n379     def can_migrate(self, connection):\n380         \"\"\"\n381         Return True if the model can/should be migrated on the `connection`.\n382         `connection` can be either a real connection or a connection alias.\n383         \"\"\"\n384         if self.proxy or self.swapped or not self.managed:\n385             return False\n386         if isinstance(connection, str):\n387             connection = connections[connection]\n388         if self.required_db_vendor:\n389             return self.required_db_vendor == connection.vendor\n390         if self.required_db_features:\n391             return all(\n392                 getattr(connection.features, feat, False)\n393                 for feat in self.required_db_features\n394             )\n395         return True\n396 \n397     @property\n398     def verbose_name_raw(self):\n399         \"\"\"Return the untranslated verbose name.\"\"\"\n400         with override(None):\n401             return str(self.verbose_name)\n402 \n403     @property\n404     def swapped(self):\n405         \"\"\"\n406         Has this model been swapped out for another? If so, return the model\n407         name of the replacement; otherwise, return None.\n408 \n409         For historical reasons, model name lookups using get_model() are\n410         case insensitive, so we make sure we are case insensitive here.\n411         \"\"\"\n412         if self.swappable:\n413             swapped_for = getattr(settings, self.swappable, None)\n414             if swapped_for:\n415                 try:\n416                     swapped_label, swapped_object = swapped_for.split(\".\")\n417                 except ValueError:\n418                     # setting not in the format app_label.model_name\n419                     # raising ImproperlyConfigured here causes problems with\n420                     # test cleanup code - instead it is raised in get_user_model\n421                     # or as part of validation.\n422                     return swapped_for\n423 \n424                 if (\n425                     \"%s.%s\" % (swapped_label, swapped_object.lower())\n426                     != self.label_lower\n427                 ):\n428                     return swapped_for\n429         return None\n430 \n431     @cached_property\n432     def managers(self):\n433         managers = []\n434         seen_managers = set()\n435         bases = (b for b in self.model.mro() if hasattr(b, \"_meta\"))\n436         for depth, base in enumerate(bases):\n437             for manager in base._meta.local_managers:\n438                 if manager.name in seen_managers:\n439                     continue\n440 \n441                 manager = copy.copy(manager)\n442                 manager.model = self.model\n443                 seen_managers.add(manager.name)\n444                 managers.append((depth, manager.creation_counter, manager))\n445 \n446         return make_immutable_fields_list(\n447             \"managers\",\n448             (m[2] for m in sorted(managers)),\n449         )\n450 \n451     @cached_property\n452     def managers_map(self):\n453         return {manager.name: manager for manager in self.managers}\n454 \n455     @cached_property\n456     def base_manager(self):\n457         base_manager_name = self.base_manager_name\n458         if not base_manager_name:\n459             # Get the first parent's base_manager_name if there's one.\n460             for parent in self.model.mro()[1:]:\n461                 if hasattr(parent, \"_meta\"):\n462                     if parent._base_manager.name != \"_base_manager\":\n463                         base_manager_name = parent._base_manager.name\n464                     break\n465 \n466         if base_manager_name:\n467             try:\n468                 return self.managers_map[base_manager_name]\n469             except KeyError:\n470                 raise ValueError(\n471                     \"%s has no manager named %r\"\n472                     % (\n473                         self.object_name,\n474                         base_manager_name,\n475                     )\n476                 )\n477 \n478         manager = Manager()\n479         manager.name = \"_base_manager\"\n480         manager.model = self.model\n481         manager.auto_created = True\n482         return manager\n483 \n484     @cached_property\n485     def default_manager(self):\n486         default_manager_name = self.default_manager_name\n487         if not default_manager_name and not self.local_managers:\n488             # Get the first parent's default_manager_name if there's one.\n489             for parent in self.model.mro()[1:]:\n490                 if hasattr(parent, \"_meta\"):\n491                     default_manager_name = parent._meta.default_manager_name\n492                     break\n493 \n494         if default_manager_name:\n495             try:\n496                 return self.managers_map[default_manager_name]\n497             except KeyError:\n498                 raise ValueError(\n499                     \"%s has no manager named %r\"\n500                     % (\n501                         self.object_name,\n502                         default_manager_name,\n503                     )\n504                 )\n505 \n506         if self.managers:\n507             return self.managers[0]\n508 \n509     @cached_property\n510     def fields(self):\n511         \"\"\"\n512         Return a list of all forward fields on the model and its parents,\n513         excluding ManyToManyFields.\n514 \n515         Private API intended only to be used by Django itself; get_fields()\n516         combined with filtering of field properties is the public API for\n517         obtaining this field list.\n518         \"\"\"\n519         # For legacy reasons, the fields property should only contain forward\n520         # fields that are not private or with a m2m cardinality. Therefore we\n521         # pass these three filters as filters to the generator.\n522         # The third lambda is a longwinded way of checking f.related_model - we don't\n523         # use that property directly because related_model is a cached property,\n524         # and all the models may not have been loaded yet; we don't want to cache\n525         # the string reference to the related_model.\n526         def is_not_an_m2m_field(f):\n527             return not (f.is_relation and f.many_to_many)\n528 \n529         def is_not_a_generic_relation(f):\n530             return not (f.is_relation and f.one_to_many)\n531 \n532         def is_not_a_generic_foreign_key(f):\n533             return not (\n534                 f.is_relation\n535                 and f.many_to_one\n536                 and not (hasattr(f.remote_field, \"model\") and f.remote_field.model)\n537             )\n538 \n539         return make_immutable_fields_list(\n540             \"fields\",\n541             (\n542                 f\n543                 for f in self._get_fields(reverse=False)\n544                 if is_not_an_m2m_field(f)\n545                 and is_not_a_generic_relation(f)\n546                 and is_not_a_generic_foreign_key(f)\n547             ),\n548         )\n549 \n550     @cached_property\n551     def concrete_fields(self):\n552         \"\"\"\n553         Return a list of all concrete fields on the model and its parents.\n554 \n555         Private API intended only to be used by Django itself; get_fields()\n556         combined with filtering of field properties is the public API for\n557         obtaining this field list.\n558         \"\"\"\n559         return make_immutable_fields_list(\n560             \"concrete_fields\", (f for f in self.fields if f.concrete)\n561         )\n562 \n563     @cached_property\n564     def local_concrete_fields(self):\n565         \"\"\"\n566         Return a list of all concrete fields on the model.\n567 \n568         Private API intended only to be used by Django itself; get_fields()\n569         combined with filtering of field properties is the public API for\n570         obtaining this field list.\n571         \"\"\"\n572         return make_immutable_fields_list(\n573             \"local_concrete_fields\", (f for f in self.local_fields if f.concrete)\n574         )\n575 \n576     @cached_property\n577     def many_to_many(self):\n578         \"\"\"\n579         Return a list of all many to many fields on the model and its parents.\n580 \n581         Private API intended only to be used by Django itself; get_fields()\n582         combined with filtering of field properties is the public API for\n583         obtaining this list.\n584         \"\"\"\n585         return make_immutable_fields_list(\n586             \"many_to_many\",\n587             (\n588                 f\n589                 for f in self._get_fields(reverse=False)\n590                 if f.is_relation and f.many_to_many\n591             ),\n592         )\n593 \n594     @cached_property\n595     def related_objects(self):\n596         \"\"\"\n597         Return all related objects pointing to the current model. The related\n598         objects can come from a one-to-one, one-to-many, or many-to-many field\n599         relation type.\n600 \n601         Private API intended only to be used by Django itself; get_fields()\n602         combined with filtering of field properties is the public API for\n603         obtaining this field list.\n604         \"\"\"\n605         all_related_fields = self._get_fields(\n606             forward=False, reverse=True, include_hidden=True\n607         )\n608         return make_immutable_fields_list(\n609             \"related_objects\",\n610             (\n611                 obj\n612                 for obj in all_related_fields\n613                 if not obj.hidden or obj.field.many_to_many\n614             ),\n615         )\n616 \n617     @cached_property\n618     def _forward_fields_map(self):\n619         res = {}\n620         fields = self._get_fields(reverse=False)\n621         for field in fields:\n622             res[field.name] = field\n623             # Due to the way Django's internals work, get_field() should also\n624             # be able to fetch a field by attname. In the case of a concrete\n625             # field with relation, includes the *_id name too\n626             try:\n627                 res[field.attname] = field\n628             except AttributeError:\n629                 pass\n630         return res\n631 \n632     @cached_property\n633     def fields_map(self):\n634         res = {}\n635         fields = self._get_fields(forward=False, include_hidden=True)\n636         for field in fields:\n637             res[field.name] = field\n638             # Due to the way Django's internals work, get_field() should also\n639             # be able to fetch a field by attname. In the case of a concrete\n640             # field with relation, includes the *_id name too\n641             try:\n642                 res[field.attname] = field\n643             except AttributeError:\n644                 pass\n645         return res\n646 \n647     def get_field(self, field_name):\n648         \"\"\"\n649         Return a field instance given the name of a forward or reverse field.\n650         \"\"\"\n651         try:\n652             # In order to avoid premature loading of the relation tree\n653             # (expensive) we prefer checking if the field is a forward field.\n654             return self._forward_fields_map[field_name]\n655         except KeyError:\n656             # If the app registry is not ready, reverse fields are\n657             # unavailable, therefore we throw a FieldDoesNotExist exception.\n658             if not self.apps.models_ready:\n659                 raise FieldDoesNotExist(\n660                     \"%s has no field named '%s'. The app cache isn't ready yet, \"\n661                     \"so if this is an auto-created related field, it won't \"\n662                     \"be available yet.\" % (self.object_name, field_name)\n663                 )\n664 \n665         try:\n666             # Retrieve field instance by name from cached or just-computed\n667             # field map.\n668             return self.fields_map[field_name]\n669         except KeyError:\n670             raise FieldDoesNotExist(\n671                 \"%s has no field named '%s'\" % (self.object_name, field_name)\n672             )\n673 \n674     def get_base_chain(self, model):\n675         \"\"\"\n676         Return a list of parent classes leading to `model` (ordered from\n677         closest to most distant ancestor). This has to handle the case where\n678         `model` is a grandparent or even more distant relation.\n679         \"\"\"\n680         if not self.parents:\n681             return []\n682         if model in self.parents:\n683             return [model]\n684         for parent in self.parents:\n685             res = parent._meta.get_base_chain(model)\n686             if res:\n687                 res.insert(0, parent)\n688                 return res\n689         return []\n690 \n691     def get_parent_list(self):\n692         \"\"\"\n693         Return all the ancestors of this model as a list ordered by MRO.\n694         Useful for determining if something is an ancestor, regardless of lineage.\n695         \"\"\"\n696         result = OrderedSet(self.parents)\n697         for parent in self.parents:\n698             for ancestor in parent._meta.get_parent_list():\n699                 result.add(ancestor)\n700         return list(result)\n701 \n702     def get_ancestor_link(self, ancestor):\n703         \"\"\"\n704         Return the field on the current model which points to the given\n705         \"ancestor\". This is possible an indirect link (a pointer to a parent\n706         model, which points, eventually, to the ancestor). Used when\n707         constructing table joins for model inheritance.\n708 \n709         Return None if the model isn't an ancestor of this one.\n710         \"\"\"\n711         if ancestor in self.parents:\n712             return self.parents[ancestor]\n713         for parent in self.parents:\n714             # Tries to get a link field from the immediate parent\n715             parent_link = parent._meta.get_ancestor_link(ancestor)\n716             if parent_link:\n717                 # In case of a proxied model, the first link\n718                 # of the chain to the ancestor is that parent\n719                 # links\n720                 return self.parents[parent] or parent_link\n721 \n722     def get_path_to_parent(self, parent):\n723         \"\"\"\n724         Return a list of PathInfos containing the path from the current\n725         model to the parent model, or an empty list if parent is not a\n726         parent of the current model.\n727         \"\"\"\n728         if self.model is parent:\n729             return []\n730         # Skip the chain of proxy to the concrete proxied model.\n731         proxied_model = self.concrete_model\n732         path = []\n733         opts = self\n734         for int_model in self.get_base_chain(parent):\n735             if int_model is proxied_model:\n736                 opts = int_model._meta\n737             else:\n738                 final_field = opts.parents[int_model]\n739                 targets = (final_field.remote_field.get_related_field(),)\n740                 opts = int_model._meta\n741                 path.append(\n742                     PathInfo(\n743                         from_opts=final_field.model._meta,\n744                         to_opts=opts,\n745                         target_fields=targets,\n746                         join_field=final_field,\n747                         m2m=False,\n748                         direct=True,\n749                         filtered_relation=None,\n750                     )\n751                 )\n752         return path\n753 \n754     def get_path_from_parent(self, parent):\n755         \"\"\"\n756         Return a list of PathInfos containing the path from the parent\n757         model to the current model, or an empty list if parent is not a\n758         parent of the current model.\n759         \"\"\"\n760         if self.model is parent:\n761             return []\n762         model = self.concrete_model\n763         # Get a reversed base chain including both the current and parent\n764         # models.\n765         chain = model._meta.get_base_chain(parent)\n766         chain.reverse()\n767         chain.append(model)\n768         # Construct a list of the PathInfos between models in chain.\n769         path = []\n770         for i, ancestor in enumerate(chain[:-1]):\n771             child = chain[i + 1]\n772             link = child._meta.get_ancestor_link(ancestor)\n773             path.extend(link.reverse_path_infos)\n774         return path\n775 \n776     def _populate_directed_relation_graph(self):\n777         \"\"\"\n778         This method is used by each model to find its reverse objects. As this\n779         method is very expensive and is accessed frequently (it looks up every\n780         field in a model, in every app), it is computed on first access and then\n781         is set as a property on every model.\n782         \"\"\"\n783         related_objects_graph = defaultdict(list)\n784 \n785         all_models = self.apps.get_models(include_auto_created=True)\n786         for model in all_models:\n787             opts = model._meta\n788             # Abstract model's fields are copied to child models, hence we will\n789             # see the fields from the child models.\n790             if opts.abstract:\n791                 continue\n792             fields_with_relations = (\n793                 f\n794                 for f in opts._get_fields(reverse=False, include_parents=False)\n795                 if f.is_relation and f.related_model is not None\n796             )\n797             for f in fields_with_relations:\n798                 if not isinstance(f.remote_field.model, str):\n799                     remote_label = f.remote_field.model._meta.concrete_model._meta.label\n800                     related_objects_graph[remote_label].append(f)\n801 \n802         for model in all_models:\n803             # Set the relation_tree using the internal __dict__. In this way\n804             # we avoid calling the cached property. In attribute lookup,\n805             # __dict__ takes precedence over a data descriptor (such as\n806             # @cached_property). This means that the _meta._relation_tree is\n807             # only called if related_objects is not in __dict__.\n808             related_objects = related_objects_graph[\n809                 model._meta.concrete_model._meta.label\n810             ]\n811             model._meta.__dict__[\"_relation_tree\"] = related_objects\n812         # It seems it is possible that self is not in all_models, so guard\n813         # against that with default for get().\n814         return self.__dict__.get(\"_relation_tree\", EMPTY_RELATION_TREE)\n815 \n816     @cached_property\n817     def _relation_tree(self):\n818         return self._populate_directed_relation_graph()\n819 \n820     def _expire_cache(self, forward=True, reverse=True):\n821         # This method is usually called by apps.cache_clear(), when the\n822         # registry is finalized, or when a new field is added.\n823         if forward:\n824             for cache_key in self.FORWARD_PROPERTIES:\n825                 if cache_key in self.__dict__:\n826                     delattr(self, cache_key)\n827         if reverse and not self.abstract:\n828             for cache_key in self.REVERSE_PROPERTIES:\n829                 if cache_key in self.__dict__:\n830                     delattr(self, cache_key)\n831         self._get_fields_cache = {}\n832 \n833     def get_fields(self, include_parents=True, include_hidden=False):\n834         \"\"\"\n835         Return a list of fields associated to the model. By default, include\n836         forward and reverse fields, fields derived from inheritance, but not\n837         hidden fields. The returned fields can be changed using the parameters:\n838 \n839         - include_parents: include fields derived from inheritance\n840         - include_hidden:  include fields that have a related_name that\n841                            starts with a \"+\"\n842         \"\"\"\n843         if include_parents is False:\n844             include_parents = PROXY_PARENTS\n845         return self._get_fields(\n846             include_parents=include_parents, include_hidden=include_hidden\n847         )\n848 \n849     def _get_fields(\n850         self,\n851         forward=True,\n852         reverse=True,\n853         include_parents=True,\n854         include_hidden=False,\n855         seen_models=None,\n856     ):\n857         \"\"\"\n858         Internal helper function to return fields of the model.\n859         * If forward=True, then fields defined on this model are returned.\n860         * If reverse=True, then relations pointing to this model are returned.\n861         * If include_hidden=True, then fields with is_hidden=True are returned.\n862         * The include_parents argument toggles if fields from parent models\n863           should be included. It has three values: True, False, and\n864           PROXY_PARENTS. When set to PROXY_PARENTS, the call will return all\n865           fields defined for the current model or any of its parents in the\n866           parent chain to the model's concrete model.\n867         \"\"\"\n868         if include_parents not in (True, False, PROXY_PARENTS):\n869             raise TypeError(\n870                 \"Invalid argument for include_parents: %s\" % (include_parents,)\n871             )\n872         # This helper function is used to allow recursion in ``get_fields()``\n873         # implementation and to provide a fast way for Django's internals to\n874         # access specific subsets of fields.\n875 \n876         # We must keep track of which models we have already seen. Otherwise we\n877         # could include the same field multiple times from different models.\n878         topmost_call = seen_models is None\n879         if topmost_call:\n880             seen_models = set()\n881         seen_models.add(self.model)\n882 \n883         # Creates a cache key composed of all arguments\n884         cache_key = (forward, reverse, include_parents, include_hidden, topmost_call)\n885 \n886         try:\n887             # In order to avoid list manipulation. Always return a shallow copy\n888             # of the results.\n889             return self._get_fields_cache[cache_key]\n890         except KeyError:\n891             pass\n892 \n893         fields = []\n894         # Recursively call _get_fields() on each parent, with the same\n895         # options provided in this call.\n896         if include_parents is not False:\n897             for parent in self.parents:\n898                 # In diamond inheritance it is possible that we see the same\n899                 # model from two different routes. In that case, avoid adding\n900                 # fields from the same parent again.\n901                 if parent in seen_models:\n902                     continue\n903                 if (\n904                     parent._meta.concrete_model != self.concrete_model\n905                     and include_parents == PROXY_PARENTS\n906                 ):\n907                     continue\n908                 for obj in parent._meta._get_fields(\n909                     forward=forward,\n910                     reverse=reverse,\n911                     include_parents=include_parents,\n912                     include_hidden=include_hidden,\n913                     seen_models=seen_models,\n914                 ):\n915                     if (\n916                         not getattr(obj, \"parent_link\", False)\n917                         or obj.model == self.concrete_model\n918                     ):\n919                         fields.append(obj)\n920         if reverse and not self.proxy:\n921             # Tree is computed once and cached until the app cache is expired.\n922             # It is composed of a list of fields pointing to the current model\n923             # from other models.\n924             all_fields = self._relation_tree\n925             for field in all_fields:\n926                 # If hidden fields should be included or the relation is not\n927                 # intentionally hidden, add to the fields dict.\n928                 if include_hidden or not field.remote_field.hidden:\n929                     fields.append(field.remote_field)\n930 \n931         if forward:\n932             fields += self.local_fields\n933             fields += self.local_many_to_many\n934             # Private fields are recopied to each child model, and they get a\n935             # different model as field.model in each child. Hence we have to\n936             # add the private fields separately from the topmost call. If we\n937             # did this recursively similar to local_fields, we would get field\n938             # instances with field.model != self.model.\n939             if topmost_call:\n940                 fields += self.private_fields\n941 \n942         # In order to avoid list manipulation. Always\n943         # return a shallow copy of the results\n944         fields = make_immutable_fields_list(\"get_fields()\", fields)\n945 \n946         # Store result into cache for later access\n947         self._get_fields_cache[cache_key] = fields\n948         return fields\n949 \n950     @cached_property\n951     def total_unique_constraints(self):\n952         \"\"\"\n953         Return a list of total unique constraints. Useful for determining set\n954         of fields guaranteed to be unique for all rows.\n955         \"\"\"\n956         return [\n957             constraint\n958             for constraint in self.constraints\n959             if (\n960                 isinstance(constraint, UniqueConstraint)\n961                 and constraint.condition is None\n962                 and not constraint.contains_expressions\n963             )\n964         ]\n965 \n966     @cached_property\n967     def _property_names(self):\n968         \"\"\"Return a set of the names of the properties defined on the model.\"\"\"\n969         names = []\n970         for name in dir(self.model):\n971             attr = inspect.getattr_static(self.model, name)\n972             if isinstance(attr, property):\n973                 names.append(name)\n974         return frozenset(names)\n975 \n976     @cached_property\n977     def db_returning_fields(self):\n978         \"\"\"\n979         Private API intended only to be used by Django itself.\n980         Fields to be returned after a database insert.\n981         \"\"\"\n982         return [\n983             field\n984             for field in self._get_fields(\n985                 forward=True, reverse=False, include_parents=PROXY_PARENTS\n986             )\n987             if getattr(field, \"db_returning\", False)\n988         ]\n",
        "intended_behavior": "Ensure functionality parsing or utilizing `index_together` supports or migrates to `Model.Meta.indexes` with `Index` class, possibly showing deprecation warnings for `index_together`."
    },
    {
        "rel_file_path": "django/db/migrations/autodetector.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__4.2/django/db/migrations/autodetector.py",
        "start": 1,
        "end": 1730,
        "class_name": null,
        "method_name": null,
        "code": "1 import functools\n2 import re\n3 from collections import defaultdict\n4 from itertools import chain\n5 \n6 from django.conf import settings\n7 from django.db import models\n8 from django.db.migrations import operations\n9 from django.db.migrations.migration import Migration\n10 from django.db.migrations.operations.models import AlterModelOptions\n11 from django.db.migrations.optimizer import MigrationOptimizer\n12 from django.db.migrations.questioner import MigrationQuestioner\n13 from django.db.migrations.utils import (\n14     COMPILED_REGEX_TYPE,\n15     RegexObject,\n16     resolve_relation,\n17 )\n18 from django.utils.topological_sort import stable_topological_sort\n19 \n20 \n21 class MigrationAutodetector:\n22     \"\"\"\n23     Take a pair of ProjectStates and compare them to see what the first would\n24     need doing to make it match the second (the second usually being the\n25     project's current state).\n26 \n27     Note that this naturally operates on entire projects at a time,\n28     as it's likely that changes interact (for example, you can't\n29     add a ForeignKey without having a migration to add the table it\n30     depends on first). A user interface may offer single-app usage\n31     if it wishes, with the caveat that it may not always be possible.\n32     \"\"\"\n33 \n34     def __init__(self, from_state, to_state, questioner=None):\n35         self.from_state = from_state\n36         self.to_state = to_state\n37         self.questioner = questioner or MigrationQuestioner()\n38         self.existing_apps = {app for app, model in from_state.models}\n39 \n40     def changes(self, graph, trim_to_apps=None, convert_apps=None, migration_name=None):\n41         \"\"\"\n42         Main entry point to produce a list of applicable changes.\n43         Take a graph to base names on and an optional set of apps\n44         to try and restrict to (restriction is not guaranteed)\n45         \"\"\"\n46         changes = self._detect_changes(convert_apps, graph)\n47         changes = self.arrange_for_graph(changes, graph, migration_name)\n48         if trim_to_apps:\n49             changes = self._trim_to_apps(changes, trim_to_apps)\n50         return changes\n51 \n52     def deep_deconstruct(self, obj):\n53         \"\"\"\n54         Recursive deconstruction for a field and its arguments.\n55         Used for full comparison for rename/alter; sometimes a single-level\n56         deconstruction will not compare correctly.\n57         \"\"\"\n58         if isinstance(obj, list):\n59             return [self.deep_deconstruct(value) for value in obj]\n60         elif isinstance(obj, tuple):\n61             return tuple(self.deep_deconstruct(value) for value in obj)\n62         elif isinstance(obj, dict):\n63             return {key: self.deep_deconstruct(value) for key, value in obj.items()}\n64         elif isinstance(obj, functools.partial):\n65             return (\n66                 obj.func,\n67                 self.deep_deconstruct(obj.args),\n68                 self.deep_deconstruct(obj.keywords),\n69             )\n70         elif isinstance(obj, COMPILED_REGEX_TYPE):\n71             return RegexObject(obj)\n72         elif isinstance(obj, type):\n73             # If this is a type that implements 'deconstruct' as an instance method,\n74             # avoid treating this as being deconstructible itself - see #22951\n75             return obj\n76         elif hasattr(obj, \"deconstruct\"):\n77             deconstructed = obj.deconstruct()\n78             if isinstance(obj, models.Field):\n79                 # we have a field which also returns a name\n80                 deconstructed = deconstructed[1:]\n81             path, args, kwargs = deconstructed\n82             return (\n83                 path,\n84                 [self.deep_deconstruct(value) for value in args],\n85                 {key: self.deep_deconstruct(value) for key, value in kwargs.items()},\n86             )\n87         else:\n88             return obj\n89 \n90     def only_relation_agnostic_fields(self, fields):\n91         \"\"\"\n92         Return a definition of the fields that ignores field names and\n93         what related fields actually relate to. Used for detecting renames (as\n94         the related fields change during renames).\n95         \"\"\"\n96         fields_def = []\n97         for name, field in sorted(fields.items()):\n98             deconstruction = self.deep_deconstruct(field)\n99             if field.remote_field and field.remote_field.model:\n100                 deconstruction[2].pop(\"to\", None)\n101             fields_def.append(deconstruction)\n102         return fields_def\n103 \n104     def _detect_changes(self, convert_apps=None, graph=None):\n105         \"\"\"\n106         Return a dict of migration plans which will achieve the\n107         change from from_state to to_state. The dict has app labels\n108         as keys and a list of migrations as values.\n109 \n110         The resulting migrations aren't specially named, but the names\n111         do matter for dependencies inside the set.\n112 \n113         convert_apps is the list of apps to convert to use migrations\n114         (i.e. to make initial migrations for, in the usual case)\n115 \n116         graph is an optional argument that, if provided, can help improve\n117         dependency generation and avoid potential circular dependencies.\n118         \"\"\"\n119         # The first phase is generating all the operations for each app\n120         # and gathering them into a big per-app list.\n121         # Then go through that list, order it, and split into migrations to\n122         # resolve dependencies caused by M2Ms and FKs.\n123         self.generated_operations = {}\n124         self.altered_indexes = {}\n125         self.altered_constraints = {}\n126         self.renamed_fields = {}\n127 \n128         # Prepare some old/new state and model lists, separating\n129         # proxy models and ignoring unmigrated apps.\n130         self.old_model_keys = set()\n131         self.old_proxy_keys = set()\n132         self.old_unmanaged_keys = set()\n133         self.new_model_keys = set()\n134         self.new_proxy_keys = set()\n135         self.new_unmanaged_keys = set()\n136         for (app_label, model_name), model_state in self.from_state.models.items():\n137             if not model_state.options.get(\"managed\", True):\n138                 self.old_unmanaged_keys.add((app_label, model_name))\n139             elif app_label not in self.from_state.real_apps:\n140                 if model_state.options.get(\"proxy\"):\n141                     self.old_proxy_keys.add((app_label, model_name))\n142                 else:\n143                     self.old_model_keys.add((app_label, model_name))\n144 \n145         for (app_label, model_name), model_state in self.to_state.models.items():\n146             if not model_state.options.get(\"managed\", True):\n147                 self.new_unmanaged_keys.add((app_label, model_name))\n148             elif app_label not in self.from_state.real_apps or (\n149                 convert_apps and app_label in convert_apps\n150             ):\n151                 if model_state.options.get(\"proxy\"):\n152                     self.new_proxy_keys.add((app_label, model_name))\n153                 else:\n154                     self.new_model_keys.add((app_label, model_name))\n155 \n156         self.from_state.resolve_fields_and_relations()\n157         self.to_state.resolve_fields_and_relations()\n158 \n159         # Renames have to come first\n160         self.generate_renamed_models()\n161 \n162         # Prepare lists of fields and generate through model map\n163         self._prepare_field_lists()\n164         self._generate_through_model_map()\n165 \n166         # Generate non-rename model operations\n167         self.generate_deleted_models()\n168         self.generate_created_models()\n169         self.generate_deleted_proxies()\n170         self.generate_created_proxies()\n171         self.generate_altered_options()\n172         self.generate_altered_managers()\n173 \n174         # Create the renamed fields and store them in self.renamed_fields.\n175         # They are used by create_altered_indexes(), generate_altered_fields(),\n176         # generate_removed_altered_index/unique_together(), and\n177         # generate_altered_index/unique_together().\n178         self.create_renamed_fields()\n179         # Create the altered indexes and store them in self.altered_indexes.\n180         # This avoids the same computation in generate_removed_indexes()\n181         # and generate_added_indexes().\n182         self.create_altered_indexes()\n183         self.create_altered_constraints()\n184         # Generate index removal operations before field is removed\n185         self.generate_removed_constraints()\n186         self.generate_removed_indexes()\n187         # Generate field renaming operations.\n188         self.generate_renamed_fields()\n189         self.generate_renamed_indexes()\n190         # Generate removal of foo together.\n191         self.generate_removed_altered_unique_together()\n192         self.generate_removed_altered_index_together()\n193         # Generate field operations.\n194         self.generate_removed_fields()\n195         self.generate_added_fields()\n196         self.generate_altered_fields()\n197         self.generate_altered_order_with_respect_to()\n198         self.generate_altered_unique_together()\n199         self.generate_altered_index_together()\n200         self.generate_added_indexes()\n201         self.generate_added_constraints()\n202         self.generate_altered_db_table()\n203 \n204         self._sort_migrations()\n205         self._build_migration_list(graph)\n206         self._optimize_migrations()\n207 \n208         return self.migrations\n209 \n210     def _prepare_field_lists(self):\n211         \"\"\"\n212         Prepare field lists and a list of the fields that used through models\n213         in the old state so dependencies can be made from the through model\n214         deletion to the field that uses it.\n215         \"\"\"\n216         self.kept_model_keys = self.old_model_keys & self.new_model_keys\n217         self.kept_proxy_keys = self.old_proxy_keys & self.new_proxy_keys\n218         self.kept_unmanaged_keys = self.old_unmanaged_keys & self.new_unmanaged_keys\n219         self.through_users = {}\n220         self.old_field_keys = {\n221             (app_label, model_name, field_name)\n222             for app_label, model_name in self.kept_model_keys\n223             for field_name in self.from_state.models[\n224                 app_label, self.renamed_models.get((app_label, model_name), model_name)\n225             ].fields\n226         }\n227         self.new_field_keys = {\n228             (app_label, model_name, field_name)\n229             for app_label, model_name in self.kept_model_keys\n230             for field_name in self.to_state.models[app_label, model_name].fields\n231         }\n232 \n233     def _generate_through_model_map(self):\n234         \"\"\"Through model map generation.\"\"\"\n235         for app_label, model_name in sorted(self.old_model_keys):\n236             old_model_name = self.renamed_models.get(\n237                 (app_label, model_name), model_name\n238             )\n239             old_model_state = self.from_state.models[app_label, old_model_name]\n240             for field_name, field in old_model_state.fields.items():\n241                 if hasattr(field, \"remote_field\") and getattr(\n242                     field.remote_field, \"through\", None\n243                 ):\n244                     through_key = resolve_relation(\n245                         field.remote_field.through, app_label, model_name\n246                     )\n247                     self.through_users[through_key] = (\n248                         app_label,\n249                         old_model_name,\n250                         field_name,\n251                     )\n252 \n253     @staticmethod\n254     def _resolve_dependency(dependency):\n255         \"\"\"\n256         Return the resolved dependency and a boolean denoting whether or not\n257         it was swappable.\n258         \"\"\"\n259         if dependency[0] != \"__setting__\":\n260             return dependency, False\n261         resolved_app_label, resolved_object_name = getattr(\n262             settings, dependency[1]\n263         ).split(\".\")\n264         return (resolved_app_label, resolved_object_name.lower()) + dependency[2:], True\n265 \n266     def _build_migration_list(self, graph=None):\n267         \"\"\"\n268         Chop the lists of operations up into migrations with dependencies on\n269         each other. Do this by going through an app's list of operations until\n270         one is found that has an outgoing dependency that isn't in another\n271         app's migration yet (hasn't been chopped off its list). Then chop off\n272         the operations before it into a migration and move onto the next app.\n273         If the loops completes without doing anything, there's a circular\n274         dependency (which _should_ be impossible as the operations are\n275         all split at this point so they can't depend and be depended on).\n276         \"\"\"\n277         self.migrations = {}\n278         num_ops = sum(len(x) for x in self.generated_operations.values())\n279         chop_mode = False\n280         while num_ops:\n281             # On every iteration, we step through all the apps and see if there\n282             # is a completed set of operations.\n283             # If we find that a subset of the operations are complete we can\n284             # try to chop it off from the rest and continue, but we only\n285             # do this if we've already been through the list once before\n286             # without any chopping and nothing has changed.\n287             for app_label in sorted(self.generated_operations):\n288                 chopped = []\n289                 dependencies = set()\n290                 for operation in list(self.generated_operations[app_label]):\n291                     deps_satisfied = True\n292                     operation_dependencies = set()\n293                     for dep in operation._auto_deps:\n294                         # Temporarily resolve the swappable dependency to\n295                         # prevent circular references. While keeping the\n296                         # dependency checks on the resolved model, add the\n297                         # swappable dependencies.\n298                         original_dep = dep\n299                         dep, is_swappable_dep = self._resolve_dependency(dep)\n300                         if dep[0] != app_label:\n301                             # External app dependency. See if it's not yet\n302                             # satisfied.\n303                             for other_operation in self.generated_operations.get(\n304                                 dep[0], []\n305                             ):\n306                                 if self.check_dependency(other_operation, dep):\n307                                     deps_satisfied = False\n308                                     break\n309                             if not deps_satisfied:\n310                                 break\n311                             else:\n312                                 if is_swappable_dep:\n313                                     operation_dependencies.add(\n314                                         (original_dep[0], original_dep[1])\n315                                     )\n316                                 elif dep[0] in self.migrations:\n317                                     operation_dependencies.add(\n318                                         (dep[0], self.migrations[dep[0]][-1].name)\n319                                     )\n320                                 else:\n321                                     # If we can't find the other app, we add a\n322                                     # first/last dependency, but only if we've\n323                                     # already been through once and checked\n324                                     # everything.\n325                                     if chop_mode:\n326                                         # If the app already exists, we add a\n327                                         # dependency on the last migration, as\n328                                         # we don't know which migration\n329                                         # contains the target field. If it's\n330                                         # not yet migrated or has no\n331                                         # migrations, we use __first__.\n332                                         if graph and graph.leaf_nodes(dep[0]):\n333                                             operation_dependencies.add(\n334                                                 graph.leaf_nodes(dep[0])[0]\n335                                             )\n336                                         else:\n337                                             operation_dependencies.add(\n338                                                 (dep[0], \"__first__\")\n339                                             )\n340                                     else:\n341                                         deps_satisfied = False\n342                     if deps_satisfied:\n343                         chopped.append(operation)\n344                         dependencies.update(operation_dependencies)\n345                         del self.generated_operations[app_label][0]\n346                     else:\n347                         break\n348                 # Make a migration! Well, only if there's stuff to put in it\n349                 if dependencies or chopped:\n350                     if not self.generated_operations[app_label] or chop_mode:\n351                         subclass = type(\n352                             \"Migration\",\n353                             (Migration,),\n354                             {\"operations\": [], \"dependencies\": []},\n355                         )\n356                         instance = subclass(\n357                             \"auto_%i\" % (len(self.migrations.get(app_label, [])) + 1),\n358                             app_label,\n359                         )\n360                         instance.dependencies = list(dependencies)\n361                         instance.operations = chopped\n362                         instance.initial = app_label not in self.existing_apps\n363                         self.migrations.setdefault(app_label, []).append(instance)\n364                         chop_mode = False\n365                     else:\n366                         self.generated_operations[app_label] = (\n367                             chopped + self.generated_operations[app_label]\n368                         )\n369             new_num_ops = sum(len(x) for x in self.generated_operations.values())\n370             if new_num_ops == num_ops:\n371                 if not chop_mode:\n372                     chop_mode = True\n373                 else:\n374                     raise ValueError(\n375                         \"Cannot resolve operation dependencies: %r\"\n376                         % self.generated_operations\n377                     )\n378             num_ops = new_num_ops\n379 \n380     def _sort_migrations(self):\n381         \"\"\"\n382         Reorder to make things possible. Reordering may be needed so FKs work\n383         nicely inside the same app.\n384         \"\"\"\n385         for app_label, ops in sorted(self.generated_operations.items()):\n386             # construct a dependency graph for intra-app dependencies\n387             dependency_graph = {op: set() for op in ops}\n388             for op in ops:\n389                 for dep in op._auto_deps:\n390                     # Resolve intra-app dependencies to handle circular\n391                     # references involving a swappable model.\n392                     dep = self._resolve_dependency(dep)[0]\n393                     if dep[0] == app_label:\n394                         for op2 in ops:\n395                             if self.check_dependency(op2, dep):\n396                                 dependency_graph[op].add(op2)\n397 \n398             # we use a stable sort for deterministic tests & general behavior\n399             self.generated_operations[app_label] = stable_topological_sort(\n400                 ops, dependency_graph\n401             )\n402 \n403     def _optimize_migrations(self):\n404         # Add in internal dependencies among the migrations\n405         for app_label, migrations in self.migrations.items():\n406             for m1, m2 in zip(migrations, migrations[1:]):\n407                 m2.dependencies.append((app_label, m1.name))\n408 \n409         # De-dupe dependencies\n410         for migrations in self.migrations.values():\n411             for migration in migrations:\n412                 migration.dependencies = list(set(migration.dependencies))\n413 \n414         # Optimize migrations\n415         for app_label, migrations in self.migrations.items():\n416             for migration in migrations:\n417                 migration.operations = MigrationOptimizer().optimize(\n418                     migration.operations, app_label\n419                 )\n420 \n421     def check_dependency(self, operation, dependency):\n422         \"\"\"\n423         Return True if the given operation depends on the given dependency,\n424         False otherwise.\n425         \"\"\"\n426         # Created model\n427         if dependency[2] is None and dependency[3] is True:\n428             return (\n429                 isinstance(operation, operations.CreateModel)\n430                 and operation.name_lower == dependency[1].lower()\n431             )\n432         # Created field\n433         elif dependency[2] is not None and dependency[3] is True:\n434             return (\n435                 isinstance(operation, operations.CreateModel)\n436                 and operation.name_lower == dependency[1].lower()\n437                 and any(dependency[2] == x for x, y in operation.fields)\n438             ) or (\n439                 isinstance(operation, operations.AddField)\n440                 and operation.model_name_lower == dependency[1].lower()\n441                 and operation.name_lower == dependency[2].lower()\n442             )\n443         # Removed field\n444         elif dependency[2] is not None and dependency[3] is False:\n445             return (\n446                 isinstance(operation, operations.RemoveField)\n447                 and operation.model_name_lower == dependency[1].lower()\n448                 and operation.name_lower == dependency[2].lower()\n449             )\n450         # Removed model\n451         elif dependency[2] is None and dependency[3] is False:\n452             return (\n453                 isinstance(operation, operations.DeleteModel)\n454                 and operation.name_lower == dependency[1].lower()\n455             )\n456         # Field being altered\n457         elif dependency[2] is not None and dependency[3] == \"alter\":\n458             return (\n459                 isinstance(operation, operations.AlterField)\n460                 and operation.model_name_lower == dependency[1].lower()\n461                 and operation.name_lower == dependency[2].lower()\n462             )\n463         # order_with_respect_to being unset for a field\n464         elif dependency[2] is not None and dependency[3] == \"order_wrt_unset\":\n465             return (\n466                 isinstance(operation, operations.AlterOrderWithRespectTo)\n467                 and operation.name_lower == dependency[1].lower()\n468                 and (operation.order_with_respect_to or \"\").lower()\n469                 != dependency[2].lower()\n470             )\n471         # Field is removed and part of an index/unique_together\n472         elif dependency[2] is not None and dependency[3] == \"foo_together_change\":\n473             return (\n474                 isinstance(\n475                     operation,\n476                     (operations.AlterUniqueTogether, operations.AlterIndexTogether),\n477                 )\n478                 and operation.name_lower == dependency[1].lower()\n479             )\n480         # Unknown dependency. Raise an error.\n481         else:\n482             raise ValueError(\"Can't handle dependency %r\" % (dependency,))\n483 \n484     def add_operation(self, app_label, operation, dependencies=None, beginning=False):\n485         # Dependencies are\n486         # (app_label, model_name, field_name, create/delete as True/False)\n487         operation._auto_deps = dependencies or []\n488         if beginning:\n489             self.generated_operations.setdefault(app_label, []).insert(0, operation)\n490         else:\n491             self.generated_operations.setdefault(app_label, []).append(operation)\n492 \n493     def swappable_first_key(self, item):\n494         \"\"\"\n495         Place potential swappable models first in lists of created models (only\n496         real way to solve #22783).\n497         \"\"\"\n498         try:\n499             model_state = self.to_state.models[item]\n500             base_names = {\n501                 base if isinstance(base, str) else base.__name__\n502                 for base in model_state.bases\n503             }\n504             string_version = \"%s.%s\" % (item[0], item[1])\n505             if (\n506                 model_state.options.get(\"swappable\")\n507                 or \"AbstractUser\" in base_names\n508                 or \"AbstractBaseUser\" in base_names\n509                 or settings.AUTH_USER_MODEL.lower() == string_version.lower()\n510             ):\n511                 return (\"___\" + item[0], \"___\" + item[1])\n512         except LookupError:\n513             pass\n514         return item\n515 \n516     def generate_renamed_models(self):\n517         \"\"\"\n518         Find any renamed models, generate the operations for them, and remove\n519         the old entry from the model lists. Must be run before other\n520         model-level generation.\n521         \"\"\"\n522         self.renamed_models = {}\n523         self.renamed_models_rel = {}\n524         added_models = self.new_model_keys - self.old_model_keys\n525         for app_label, model_name in sorted(added_models):\n526             model_state = self.to_state.models[app_label, model_name]\n527             model_fields_def = self.only_relation_agnostic_fields(model_state.fields)\n528 \n529             removed_models = self.old_model_keys - self.new_model_keys\n530             for rem_app_label, rem_model_name in removed_models:\n531                 if rem_app_label == app_label:\n532                     rem_model_state = self.from_state.models[\n533                         rem_app_label, rem_model_name\n534                     ]\n535                     rem_model_fields_def = self.only_relation_agnostic_fields(\n536                         rem_model_state.fields\n537                     )\n538                     if model_fields_def == rem_model_fields_def:\n539                         if self.questioner.ask_rename_model(\n540                             rem_model_state, model_state\n541                         ):\n542                             dependencies = []\n543                             fields = list(model_state.fields.values()) + [\n544                                 field.remote_field\n545                                 for relations in self.to_state.relations[\n546                                     app_label, model_name\n547                                 ].values()\n548                                 for field in relations.values()\n549                             ]\n550                             for field in fields:\n551                                 if field.is_relation:\n552                                     dependencies.extend(\n553                                         self._get_dependencies_for_foreign_key(\n554                                             app_label,\n555                                             model_name,\n556                                             field,\n557                                             self.to_state,\n558                                         )\n559                                     )\n560                             self.add_operation(\n561                                 app_label,\n562                                 operations.RenameModel(\n563                                     old_name=rem_model_state.name,\n564                                     new_name=model_state.name,\n565                                 ),\n566                                 dependencies=dependencies,\n567                             )\n568                             self.renamed_models[app_label, model_name] = rem_model_name\n569                             renamed_models_rel_key = \"%s.%s\" % (\n570                                 rem_model_state.app_label,\n571                                 rem_model_state.name_lower,\n572                             )\n573                             self.renamed_models_rel[\n574                                 renamed_models_rel_key\n575                             ] = \"%s.%s\" % (\n576                                 model_state.app_label,\n577                                 model_state.name_lower,\n578                             )\n579                             self.old_model_keys.remove((rem_app_label, rem_model_name))\n580                             self.old_model_keys.add((app_label, model_name))\n581                             break\n582 \n583     def generate_created_models(self):\n584         \"\"\"\n585         Find all new models (both managed and unmanaged) and make create\n586         operations for them as well as separate operations to create any\n587         foreign key or M2M relationships (these are optimized later, if\n588         possible).\n589 \n590         Defer any model options that refer to collections of fields that might\n591         be deferred (e.g. unique_together, index_together).\n592         \"\"\"\n593         old_keys = self.old_model_keys | self.old_unmanaged_keys\n594         added_models = self.new_model_keys - old_keys\n595         added_unmanaged_models = self.new_unmanaged_keys - old_keys\n596         all_added_models = chain(\n597             sorted(added_models, key=self.swappable_first_key, reverse=True),\n598             sorted(added_unmanaged_models, key=self.swappable_first_key, reverse=True),\n599         )\n600         for app_label, model_name in all_added_models:\n601             model_state = self.to_state.models[app_label, model_name]\n602             # Gather related fields\n603             related_fields = {}\n604             primary_key_rel = None\n605             for field_name, field in model_state.fields.items():\n606                 if field.remote_field:\n607                     if field.remote_field.model:\n608                         if field.primary_key:\n609                             primary_key_rel = field.remote_field.model\n610                         elif not field.remote_field.parent_link:\n611                             related_fields[field_name] = field\n612                     if getattr(field.remote_field, \"through\", None):\n613                         related_fields[field_name] = field\n614 \n615             # Are there indexes/unique|index_together to defer?\n616             indexes = model_state.options.pop(\"indexes\")\n617             constraints = model_state.options.pop(\"constraints\")\n618             unique_together = model_state.options.pop(\"unique_together\", None)\n619             index_together = model_state.options.pop(\"index_together\", None)\n620             order_with_respect_to = model_state.options.pop(\n621                 \"order_with_respect_to\", None\n622             )\n623             # Depend on the deletion of any possible proxy version of us\n624             dependencies = [\n625                 (app_label, model_name, None, False),\n626             ]\n627             # Depend on all bases\n628             for base in model_state.bases:\n629                 if isinstance(base, str) and \".\" in base:\n630                     base_app_label, base_name = base.split(\".\", 1)\n631                     dependencies.append((base_app_label, base_name, None, True))\n632                     # Depend on the removal of base fields if the new model has\n633                     # a field with the same name.\n634                     old_base_model_state = self.from_state.models.get(\n635                         (base_app_label, base_name)\n636                     )\n637                     new_base_model_state = self.to_state.models.get(\n638                         (base_app_label, base_name)\n639                     )\n640                     if old_base_model_state and new_base_model_state:\n641                         removed_base_fields = (\n642                             set(old_base_model_state.fields)\n643                             .difference(\n644                                 new_base_model_state.fields,\n645                             )\n646                             .intersection(model_state.fields)\n647                         )\n648                         for removed_base_field in removed_base_fields:\n649                             dependencies.append(\n650                                 (base_app_label, base_name, removed_base_field, False)\n651                             )\n652             # Depend on the other end of the primary key if it's a relation\n653             if primary_key_rel:\n654                 dependencies.append(\n655                     resolve_relation(\n656                         primary_key_rel,\n657                         app_label,\n658                         model_name,\n659                     )\n660                     + (None, True)\n661                 )\n662             # Generate creation operation\n663             self.add_operation(\n664                 app_label,\n665                 operations.CreateModel(\n666                     name=model_state.name,\n667                     fields=[\n668                         d\n669                         for d in model_state.fields.items()\n670                         if d[0] not in related_fields\n671                     ],\n672                     options=model_state.options,\n673                     bases=model_state.bases,\n674                     managers=model_state.managers,\n675                 ),\n676                 dependencies=dependencies,\n677                 beginning=True,\n678             )\n679 \n680             # Don't add operations which modify the database for unmanaged models\n681             if not model_state.options.get(\"managed\", True):\n682                 continue\n683 \n684             # Generate operations for each related field\n685             for name, field in sorted(related_fields.items()):\n686                 dependencies = self._get_dependencies_for_foreign_key(\n687                     app_label,\n688                     model_name,\n689                     field,\n690                     self.to_state,\n691                 )\n692                 # Depend on our own model being created\n693                 dependencies.append((app_label, model_name, None, True))\n694                 # Make operation\n695                 self.add_operation(\n696                     app_label,\n697                     operations.AddField(\n698                         model_name=model_name,\n699                         name=name,\n700                         field=field,\n701                     ),\n702                     dependencies=list(set(dependencies)),\n703                 )\n704             # Generate other opns\n705             if order_with_respect_to:\n706                 self.add_operation(\n707                     app_label,\n708                     operations.AlterOrderWithRespectTo(\n709                         name=model_name,\n710                         order_with_respect_to=order_with_respect_to,\n711                     ),\n712                     dependencies=[\n713                         (app_label, model_name, order_with_respect_to, True),\n714                         (app_label, model_name, None, True),\n715                     ],\n716                 )\n717             related_dependencies = [\n718                 (app_label, model_name, name, True) for name in sorted(related_fields)\n719             ]\n720             related_dependencies.append((app_label, model_name, None, True))\n721             for index in indexes:\n722                 self.add_operation(\n723                     app_label,\n724                     operations.AddIndex(\n725                         model_name=model_name,\n726                         index=index,\n727                     ),\n728                     dependencies=related_dependencies,\n729                 )\n730             for constraint in constraints:\n731                 self.add_operation(\n732                     app_label,\n733                     operations.AddConstraint(\n734                         model_name=model_name,\n735                         constraint=constraint,\n736                     ),\n737                     dependencies=related_dependencies,\n738                 )\n739             if unique_together:\n740                 self.add_operation(\n741                     app_label,\n742                     operations.AlterUniqueTogether(\n743                         name=model_name,\n744                         unique_together=unique_together,\n745                     ),\n746                     dependencies=related_dependencies,\n747                 )\n748             if index_together:\n749                 self.add_operation(\n750                     app_label,\n751                     operations.AlterIndexTogether(\n752                         name=model_name,\n753                         index_together=index_together,\n754                     ),\n755                     dependencies=related_dependencies,\n756                 )\n757             # Fix relationships if the model changed from a proxy model to a\n758             # concrete model.\n759             relations = self.to_state.relations\n760             if (app_label, model_name) in self.old_proxy_keys:\n761                 for related_model_key, related_fields in relations[\n762                     app_label, model_name\n763                 ].items():\n764                     related_model_state = self.to_state.models[related_model_key]\n765                     for related_field_name, related_field in related_fields.items():\n766                         self.add_operation(\n767                             related_model_state.app_label,\n768                             operations.AlterField(\n769                                 model_name=related_model_state.name,\n770                                 name=related_field_name,\n771                                 field=related_field,\n772                             ),\n773                             dependencies=[(app_label, model_name, None, True)],\n774                         )\n775 \n776     def generate_created_proxies(self):\n777         \"\"\"\n778         Make CreateModel statements for proxy models. Use the same statements\n779         as that way there's less code duplication, but for proxy models it's\n780         safe to skip all the pointless field stuff and chuck out an operation.\n781         \"\"\"\n782         added = self.new_proxy_keys - self.old_proxy_keys\n783         for app_label, model_name in sorted(added):\n784             model_state = self.to_state.models[app_label, model_name]\n785             assert model_state.options.get(\"proxy\")\n786             # Depend on the deletion of any possible non-proxy version of us\n787             dependencies = [\n788                 (app_label, model_name, None, False),\n789             ]\n790             # Depend on all bases\n791             for base in model_state.bases:\n792                 if isinstance(base, str) and \".\" in base:\n793                     base_app_label, base_name = base.split(\".\", 1)\n794                     dependencies.append((base_app_label, base_name, None, True))\n795             # Generate creation operation\n796             self.add_operation(\n797                 app_label,\n798                 operations.CreateModel(\n799                     name=model_state.name,\n800                     fields=[],\n801                     options=model_state.options,\n802                     bases=model_state.bases,\n803                     managers=model_state.managers,\n804                 ),\n805                 # Depend on the deletion of any possible non-proxy version of us\n806                 dependencies=dependencies,\n807             )\n808 \n809     def generate_deleted_models(self):\n810         \"\"\"\n811         Find all deleted models (managed and unmanaged) and make delete\n812         operations for them as well as separate operations to delete any\n813         foreign key or M2M relationships (these are optimized later, if\n814         possible).\n815 \n816         Also bring forward removal of any model options that refer to\n817         collections of fields - the inverse of generate_created_models().\n818         \"\"\"\n819         new_keys = self.new_model_keys | self.new_unmanaged_keys\n820         deleted_models = self.old_model_keys - new_keys\n821         deleted_unmanaged_models = self.old_unmanaged_keys - new_keys\n822         all_deleted_models = chain(\n823             sorted(deleted_models), sorted(deleted_unmanaged_models)\n824         )\n825         for app_label, model_name in all_deleted_models:\n826             model_state = self.from_state.models[app_label, model_name]\n827             # Gather related fields\n828             related_fields = {}\n829             for field_name, field in model_state.fields.items():\n830                 if field.remote_field:\n831                     if field.remote_field.model:\n832                         related_fields[field_name] = field\n833                     if getattr(field.remote_field, \"through\", None):\n834                         related_fields[field_name] = field\n835             # Generate option removal first\n836             unique_together = model_state.options.pop(\"unique_together\", None)\n837             index_together = model_state.options.pop(\"index_together\", None)\n838             if unique_together:\n839                 self.add_operation(\n840                     app_label,\n841                     operations.AlterUniqueTogether(\n842                         name=model_name,\n843                         unique_together=None,\n844                     ),\n845                 )\n846             if index_together:\n847                 self.add_operation(\n848                     app_label,\n849                     operations.AlterIndexTogether(\n850                         name=model_name,\n851                         index_together=None,\n852                     ),\n853                 )\n854             # Then remove each related field\n855             for name in sorted(related_fields):\n856                 self.add_operation(\n857                     app_label,\n858                     operations.RemoveField(\n859                         model_name=model_name,\n860                         name=name,\n861                     ),\n862                 )\n863             # Finally, remove the model.\n864             # This depends on both the removal/alteration of all incoming fields\n865             # and the removal of all its own related fields, and if it's\n866             # a through model the field that references it.\n867             dependencies = []\n868             relations = self.from_state.relations\n869             for (\n870                 related_object_app_label,\n871                 object_name,\n872             ), relation_related_fields in relations[app_label, model_name].items():\n873                 for field_name, field in relation_related_fields.items():\n874                     dependencies.append(\n875                         (related_object_app_label, object_name, field_name, False),\n876                     )\n877                     if not field.many_to_many:\n878                         dependencies.append(\n879                             (\n880                                 related_object_app_label,\n881                                 object_name,\n882                                 field_name,\n883                                 \"alter\",\n884                             ),\n885                         )\n886 \n887             for name in sorted(related_fields):\n888                 dependencies.append((app_label, model_name, name, False))\n889             # We're referenced in another field's through=\n890             through_user = self.through_users.get((app_label, model_state.name_lower))\n891             if through_user:\n892                 dependencies.append(\n893                     (through_user[0], through_user[1], through_user[2], False)\n894                 )\n895             # Finally, make the operation, deduping any dependencies\n896             self.add_operation(\n897                 app_label,\n898                 operations.DeleteModel(\n899                     name=model_state.name,\n900                 ),\n901                 dependencies=list(set(dependencies)),\n902             )\n903 \n904     def generate_deleted_proxies(self):\n905         \"\"\"Make DeleteModel options for proxy models.\"\"\"\n906         deleted = self.old_proxy_keys - self.new_proxy_keys\n907         for app_label, model_name in sorted(deleted):\n908             model_state = self.from_state.models[app_label, model_name]\n909             assert model_state.options.get(\"proxy\")\n910             self.add_operation(\n911                 app_label,\n912                 operations.DeleteModel(\n913                     name=model_state.name,\n914                 ),\n915             )\n916 \n917     def create_renamed_fields(self):\n918         \"\"\"Work out renamed fields.\"\"\"\n919         self.renamed_operations = []\n920         old_field_keys = self.old_field_keys.copy()\n921         for app_label, model_name, field_name in sorted(\n922             self.new_field_keys - old_field_keys\n923         ):\n924             old_model_name = self.renamed_models.get(\n925                 (app_label, model_name), model_name\n926             )\n927             old_model_state = self.from_state.models[app_label, old_model_name]\n928             new_model_state = self.to_state.models[app_label, model_name]\n929             field = new_model_state.get_field(field_name)\n930             # Scan to see if this is actually a rename!\n931             field_dec = self.deep_deconstruct(field)\n932             for rem_app_label, rem_model_name, rem_field_name in sorted(\n933                 old_field_keys - self.new_field_keys\n934             ):\n935                 if rem_app_label == app_label and rem_model_name == model_name:\n936                     old_field = old_model_state.get_field(rem_field_name)\n937                     old_field_dec = self.deep_deconstruct(old_field)\n938                     if (\n939                         field.remote_field\n940                         and field.remote_field.model\n941                         and \"to\" in old_field_dec[2]\n942                     ):\n943                         old_rel_to = old_field_dec[2][\"to\"]\n944                         if old_rel_to in self.renamed_models_rel:\n945                             old_field_dec[2][\"to\"] = self.renamed_models_rel[old_rel_to]\n946                     old_field.set_attributes_from_name(rem_field_name)\n947                     old_db_column = old_field.get_attname_column()[1]\n948                     if old_field_dec == field_dec or (\n949                         # Was the field renamed and db_column equal to the\n950                         # old field's column added?\n951                         old_field_dec[0:2] == field_dec[0:2]\n952                         and dict(old_field_dec[2], db_column=old_db_column)\n953                         == field_dec[2]\n954                     ):\n955                         if self.questioner.ask_rename(\n956                             model_name, rem_field_name, field_name, field\n957                         ):\n958                             self.renamed_operations.append(\n959                                 (\n960                                     rem_app_label,\n961                                     rem_model_name,\n962                                     old_field.db_column,\n963                                     rem_field_name,\n964                                     app_label,\n965                                     model_name,\n966                                     field,\n967                                     field_name,\n968                                 )\n969                             )\n970                             old_field_keys.remove(\n971                                 (rem_app_label, rem_model_name, rem_field_name)\n972                             )\n973                             old_field_keys.add((app_label, model_name, field_name))\n974                             self.renamed_fields[\n975                                 app_label, model_name, field_name\n976                             ] = rem_field_name\n977                             break\n978 \n979     def generate_renamed_fields(self):\n980         \"\"\"Generate RenameField operations.\"\"\"\n981         for (\n982             rem_app_label,\n983             rem_model_name,\n984             rem_db_column,\n985             rem_field_name,\n986             app_label,\n987             model_name,\n988             field,\n989             field_name,\n990         ) in self.renamed_operations:\n991             # A db_column mismatch requires a prior noop AlterField for the\n992             # subsequent RenameField to be a noop on attempts at preserving the\n993             # old name.\n994             if rem_db_column != field.db_column:\n995                 altered_field = field.clone()\n996                 altered_field.name = rem_field_name\n997                 self.add_operation(\n998                     app_label,\n999                     operations.AlterField(\n1000                         model_name=model_name,\n1001                         name=rem_field_name,\n1002                         field=altered_field,\n1003                     ),\n1004                 )\n1005             self.add_operation(\n1006                 app_label,\n1007                 operations.RenameField(\n1008                     model_name=model_name,\n1009                     old_name=rem_field_name,\n1010                     new_name=field_name,\n1011                 ),\n1012             )\n1013             self.old_field_keys.remove((rem_app_label, rem_model_name, rem_field_name))\n1014             self.old_field_keys.add((app_label, model_name, field_name))\n1015 \n1016     def generate_added_fields(self):\n1017         \"\"\"Make AddField operations.\"\"\"\n1018         for app_label, model_name, field_name in sorted(\n1019             self.new_field_keys - self.old_field_keys\n1020         ):\n1021             self._generate_added_field(app_label, model_name, field_name)\n1022 \n1023     def _generate_added_field(self, app_label, model_name, field_name):\n1024         field = self.to_state.models[app_label, model_name].get_field(field_name)\n1025         # Adding a field always depends at least on its removal.\n1026         dependencies = [(app_label, model_name, field_name, False)]\n1027         # Fields that are foreignkeys/m2ms depend on stuff.\n1028         if field.remote_field and field.remote_field.model:\n1029             dependencies.extend(\n1030                 self._get_dependencies_for_foreign_key(\n1031                     app_label,\n1032                     model_name,\n1033                     field,\n1034                     self.to_state,\n1035                 )\n1036             )\n1037         # You can't just add NOT NULL fields with no default or fields\n1038         # which don't allow empty strings as default.\n1039         time_fields = (models.DateField, models.DateTimeField, models.TimeField)\n1040         preserve_default = (\n1041             field.null\n1042             or field.has_default()\n1043             or field.many_to_many\n1044             or (field.blank and field.empty_strings_allowed)\n1045             or (isinstance(field, time_fields) and field.auto_now)\n1046         )\n1047         if not preserve_default:\n1048             field = field.clone()\n1049             if isinstance(field, time_fields) and field.auto_now_add:\n1050                 field.default = self.questioner.ask_auto_now_add_addition(\n1051                     field_name, model_name\n1052                 )\n1053             else:\n1054                 field.default = self.questioner.ask_not_null_addition(\n1055                     field_name, model_name\n1056                 )\n1057         if (\n1058             field.unique\n1059             and field.default is not models.NOT_PROVIDED\n1060             and callable(field.default)\n1061         ):\n1062             self.questioner.ask_unique_callable_default_addition(field_name, model_name)\n1063         self.add_operation(\n1064             app_label,\n1065             operations.AddField(\n1066                 model_name=model_name,\n1067                 name=field_name,\n1068                 field=field,\n1069                 preserve_default=preserve_default,\n1070             ),\n1071             dependencies=dependencies,\n1072         )\n1073 \n1074     def generate_removed_fields(self):\n1075         \"\"\"Make RemoveField operations.\"\"\"\n1076         for app_label, model_name, field_name in sorted(\n1077             self.old_field_keys - self.new_field_keys\n1078         ):\n1079             self._generate_removed_field(app_label, model_name, field_name)\n1080 \n1081     def _generate_removed_field(self, app_label, model_name, field_name):\n1082         self.add_operation(\n1083             app_label,\n1084             operations.RemoveField(\n1085                 model_name=model_name,\n1086                 name=field_name,\n1087             ),\n1088             # We might need to depend on the removal of an\n1089             # order_with_respect_to or index/unique_together operation;\n1090             # this is safely ignored if there isn't one\n1091             dependencies=[\n1092                 (app_label, model_name, field_name, \"order_wrt_unset\"),\n1093                 (app_label, model_name, field_name, \"foo_together_change\"),\n1094             ],\n1095         )\n1096 \n1097     def generate_altered_fields(self):\n1098         \"\"\"\n1099         Make AlterField operations, or possibly RemovedField/AddField if alter\n1100         isn't possible.\n1101         \"\"\"\n1102         for app_label, model_name, field_name in sorted(\n1103             self.old_field_keys & self.new_field_keys\n1104         ):\n1105             # Did the field change?\n1106             old_model_name = self.renamed_models.get(\n1107                 (app_label, model_name), model_name\n1108             )\n1109             old_field_name = self.renamed_fields.get(\n1110                 (app_label, model_name, field_name), field_name\n1111             )\n1112             old_field = self.from_state.models[app_label, old_model_name].get_field(\n1113                 old_field_name\n1114             )\n1115             new_field = self.to_state.models[app_label, model_name].get_field(\n1116                 field_name\n1117             )\n1118             dependencies = []\n1119             # Implement any model renames on relations; these are handled by RenameModel\n1120             # so we need to exclude them from the comparison\n1121             if hasattr(new_field, \"remote_field\") and getattr(\n1122                 new_field.remote_field, \"model\", None\n1123             ):\n1124                 rename_key = resolve_relation(\n1125                     new_field.remote_field.model, app_label, model_name\n1126                 )\n1127                 if rename_key in self.renamed_models:\n1128                     new_field.remote_field.model = old_field.remote_field.model\n1129                 # Handle ForeignKey which can only have a single to_field.\n1130                 remote_field_name = getattr(new_field.remote_field, \"field_name\", None)\n1131                 if remote_field_name:\n1132                     to_field_rename_key = rename_key + (remote_field_name,)\n1133                     if to_field_rename_key in self.renamed_fields:\n1134                         # Repoint both model and field name because to_field\n1135                         # inclusion in ForeignKey.deconstruct() is based on\n1136                         # both.\n1137                         new_field.remote_field.model = old_field.remote_field.model\n1138                         new_field.remote_field.field_name = (\n1139                             old_field.remote_field.field_name\n1140                         )\n1141                 # Handle ForeignObjects which can have multiple from_fields/to_fields.\n1142                 from_fields = getattr(new_field, \"from_fields\", None)\n1143                 if from_fields:\n1144                     from_rename_key = (app_label, model_name)\n1145                     new_field.from_fields = tuple(\n1146                         [\n1147                             self.renamed_fields.get(\n1148                                 from_rename_key + (from_field,), from_field\n1149                             )\n1150                             for from_field in from_fields\n1151                         ]\n1152                     )\n1153                     new_field.to_fields = tuple(\n1154                         [\n1155                             self.renamed_fields.get(rename_key + (to_field,), to_field)\n1156                             for to_field in new_field.to_fields\n1157                         ]\n1158                     )\n1159                 dependencies.extend(\n1160                     self._get_dependencies_for_foreign_key(\n1161                         app_label,\n1162                         model_name,\n1163                         new_field,\n1164                         self.to_state,\n1165                     )\n1166                 )\n1167             if hasattr(new_field, \"remote_field\") and getattr(\n1168                 new_field.remote_field, \"through\", None\n1169             ):\n1170                 rename_key = resolve_relation(\n1171                     new_field.remote_field.through, app_label, model_name\n1172                 )\n1173                 if rename_key in self.renamed_models:\n1174                     new_field.remote_field.through = old_field.remote_field.through\n1175             old_field_dec = self.deep_deconstruct(old_field)\n1176             new_field_dec = self.deep_deconstruct(new_field)\n1177             # If the field was confirmed to be renamed it means that only\n1178             # db_column was allowed to change which generate_renamed_fields()\n1179             # already accounts for by adding an AlterField operation.\n1180             if old_field_dec != new_field_dec and old_field_name == field_name:\n1181                 both_m2m = old_field.many_to_many and new_field.many_to_many\n1182                 neither_m2m = not old_field.many_to_many and not new_field.many_to_many\n1183                 if both_m2m or neither_m2m:\n1184                     # Either both fields are m2m or neither is\n1185                     preserve_default = True\n1186                     if (\n1187                         old_field.null\n1188                         and not new_field.null\n1189                         and not new_field.has_default()\n1190                         and not new_field.many_to_many\n1191                     ):\n1192                         field = new_field.clone()\n1193                         new_default = self.questioner.ask_not_null_alteration(\n1194                             field_name, model_name\n1195                         )\n1196                         if new_default is not models.NOT_PROVIDED:\n1197                             field.default = new_default\n1198                             preserve_default = False\n1199                     else:\n1200                         field = new_field\n1201                     self.add_operation(\n1202                         app_label,\n1203                         operations.AlterField(\n1204                             model_name=model_name,\n1205                             name=field_name,\n1206                             field=field,\n1207                             preserve_default=preserve_default,\n1208                         ),\n1209                         dependencies=dependencies,\n1210                     )\n1211                 else:\n1212                     # We cannot alter between m2m and concrete fields\n1213                     self._generate_removed_field(app_label, model_name, field_name)\n1214                     self._generate_added_field(app_label, model_name, field_name)\n1215 \n1216     def create_altered_indexes(self):\n1217         option_name = operations.AddIndex.option_name\n1218         self.renamed_index_together_values = defaultdict(list)\n1219 \n1220         for app_label, model_name in sorted(self.kept_model_keys):\n1221             old_model_name = self.renamed_models.get(\n1222                 (app_label, model_name), model_name\n1223             )\n1224             old_model_state = self.from_state.models[app_label, old_model_name]\n1225             new_model_state = self.to_state.models[app_label, model_name]\n1226 \n1227             old_indexes = old_model_state.options[option_name]\n1228             new_indexes = new_model_state.options[option_name]\n1229             added_indexes = [idx for idx in new_indexes if idx not in old_indexes]\n1230             removed_indexes = [idx for idx in old_indexes if idx not in new_indexes]\n1231             renamed_indexes = []\n1232             # Find renamed indexes.\n1233             remove_from_added = []\n1234             remove_from_removed = []\n1235             for new_index in added_indexes:\n1236                 new_index_dec = new_index.deconstruct()\n1237                 new_index_name = new_index_dec[2].pop(\"name\")\n1238                 for old_index in removed_indexes:\n1239                     old_index_dec = old_index.deconstruct()\n1240                     old_index_name = old_index_dec[2].pop(\"name\")\n1241                     # Indexes are the same except for the names.\n1242                     if (\n1243                         new_index_dec == old_index_dec\n1244                         and new_index_name != old_index_name\n1245                     ):\n1246                         renamed_indexes.append((old_index_name, new_index_name, None))\n1247                         remove_from_added.append(new_index)\n1248                         remove_from_removed.append(old_index)\n1249             # Find index_together changed to indexes.\n1250             for (\n1251                 old_value,\n1252                 new_value,\n1253                 index_together_app_label,\n1254                 index_together_model_name,\n1255                 dependencies,\n1256             ) in self._get_altered_foo_together_operations(\n1257                 operations.AlterIndexTogether.option_name\n1258             ):\n1259                 if (\n1260                     app_label != index_together_app_label\n1261                     or model_name != index_together_model_name\n1262                 ):\n1263                     continue\n1264                 removed_values = old_value.difference(new_value)\n1265                 for removed_index_together in removed_values:\n1266                     renamed_index_together_indexes = []\n1267                     for new_index in added_indexes:\n1268                         _, args, kwargs = new_index.deconstruct()\n1269                         # Ensure only 'fields' are defined in the Index.\n1270                         if (\n1271                             not args\n1272                             and new_index.fields == list(removed_index_together)\n1273                             and set(kwargs) == {\"name\", \"fields\"}\n1274                         ):\n1275                             renamed_index_together_indexes.append(new_index)\n1276 \n1277                     if len(renamed_index_together_indexes) == 1:\n1278                         renamed_index = renamed_index_together_indexes[0]\n1279                         remove_from_added.append(renamed_index)\n1280                         renamed_indexes.append(\n1281                             (None, renamed_index.name, removed_index_together)\n1282                         )\n1283                         self.renamed_index_together_values[\n1284                             index_together_app_label, index_together_model_name\n1285                         ].append(removed_index_together)\n1286             # Remove renamed indexes from the lists of added and removed\n1287             # indexes.\n1288             added_indexes = [\n1289                 idx for idx in added_indexes if idx not in remove_from_added\n1290             ]\n1291             removed_indexes = [\n1292                 idx for idx in removed_indexes if idx not in remove_from_removed\n1293             ]\n1294 \n1295             self.altered_indexes.update(\n1296                 {\n1297                     (app_label, model_name): {\n1298                         \"added_indexes\": added_indexes,\n1299                         \"removed_indexes\": removed_indexes,\n1300                         \"renamed_indexes\": renamed_indexes,\n1301                     }\n1302                 }\n1303             )\n1304 \n1305     def generate_added_indexes(self):\n1306         for (app_label, model_name), alt_indexes in self.altered_indexes.items():\n1307             for index in alt_indexes[\"added_indexes\"]:\n1308                 self.add_operation(\n1309                     app_label,\n1310                     operations.AddIndex(\n1311                         model_name=model_name,\n1312                         index=index,\n1313                     ),\n1314                 )\n1315 \n1316     def generate_removed_indexes(self):\n1317         for (app_label, model_name), alt_indexes in self.altered_indexes.items():\n1318             for index in alt_indexes[\"removed_indexes\"]:\n1319                 self.add_operation(\n1320                     app_label,\n1321                     operations.RemoveIndex(\n1322                         model_name=model_name,\n1323                         name=index.name,\n1324                     ),\n1325                 )\n1326 \n1327     def generate_renamed_indexes(self):\n1328         for (app_label, model_name), alt_indexes in self.altered_indexes.items():\n1329             for old_index_name, new_index_name, old_fields in alt_indexes[\n1330                 \"renamed_indexes\"\n1331             ]:\n1332                 self.add_operation(\n1333                     app_label,\n1334                     operations.RenameIndex(\n1335                         model_name=model_name,\n1336                         new_name=new_index_name,\n1337                         old_name=old_index_name,\n1338                         old_fields=old_fields,\n1339                     ),\n1340                 )\n1341 \n1342     def create_altered_constraints(self):\n1343         option_name = operations.AddConstraint.option_name\n1344         for app_label, model_name in sorted(self.kept_model_keys):\n1345             old_model_name = self.renamed_models.get(\n1346                 (app_label, model_name), model_name\n1347             )\n1348             old_model_state = self.from_state.models[app_label, old_model_name]\n1349             new_model_state = self.to_state.models[app_label, model_name]\n1350 \n1351             old_constraints = old_model_state.options[option_name]\n1352             new_constraints = new_model_state.options[option_name]\n1353             add_constraints = [c for c in new_constraints if c not in old_constraints]\n1354             rem_constraints = [c for c in old_constraints if c not in new_constraints]\n1355 \n1356             self.altered_constraints.update(\n1357                 {\n1358                     (app_label, model_name): {\n1359                         \"added_constraints\": add_constraints,\n1360                         \"removed_constraints\": rem_constraints,\n1361                     }\n1362                 }\n1363             )\n1364 \n1365     def generate_added_constraints(self):\n1366         for (\n1367             app_label,\n1368             model_name,\n1369         ), alt_constraints in self.altered_constraints.items():\n1370             for constraint in alt_constraints[\"added_constraints\"]:\n1371                 self.add_operation(\n1372                     app_label,\n1373                     operations.AddConstraint(\n1374                         model_name=model_name,\n1375                         constraint=constraint,\n1376                     ),\n1377                 )\n1378 \n1379     def generate_removed_constraints(self):\n1380         for (\n1381             app_label,\n1382             model_name,\n1383         ), alt_constraints in self.altered_constraints.items():\n1384             for constraint in alt_constraints[\"removed_constraints\"]:\n1385                 self.add_operation(\n1386                     app_label,\n1387                     operations.RemoveConstraint(\n1388                         model_name=model_name,\n1389                         name=constraint.name,\n1390                     ),\n1391                 )\n1392 \n1393     @staticmethod\n1394     def _get_dependencies_for_foreign_key(app_label, model_name, field, project_state):\n1395         remote_field_model = None\n1396         if hasattr(field.remote_field, \"model\"):\n1397             remote_field_model = field.remote_field.model\n1398         else:\n1399             relations = project_state.relations[app_label, model_name]\n1400             for (remote_app_label, remote_model_name), fields in relations.items():\n1401                 if any(\n1402                     field == related_field.remote_field\n1403                     for related_field in fields.values()\n1404                 ):\n1405                     remote_field_model = f\"{remote_app_label}.{remote_model_name}\"\n1406                     break\n1407         # Account for FKs to swappable models\n1408         swappable_setting = getattr(field, \"swappable_setting\", None)\n1409         if swappable_setting is not None:\n1410             dep_app_label = \"__setting__\"\n1411             dep_object_name = swappable_setting\n1412         else:\n1413             dep_app_label, dep_object_name = resolve_relation(\n1414                 remote_field_model,\n1415                 app_label,\n1416                 model_name,\n1417             )\n1418         dependencies = [(dep_app_label, dep_object_name, None, True)]\n1419         if getattr(field.remote_field, \"through\", None):\n1420             through_app_label, through_object_name = resolve_relation(\n1421                 remote_field_model,\n1422                 app_label,\n1423                 model_name,\n1424             )\n1425             dependencies.append((through_app_label, through_object_name, None, True))\n1426         return dependencies\n1427 \n1428     def _get_altered_foo_together_operations(self, option_name):\n1429         for app_label, model_name in sorted(self.kept_model_keys):\n1430             old_model_name = self.renamed_models.get(\n1431                 (app_label, model_name), model_name\n1432             )\n1433             old_model_state = self.from_state.models[app_label, old_model_name]\n1434             new_model_state = self.to_state.models[app_label, model_name]\n1435 \n1436             # We run the old version through the field renames to account for those\n1437             old_value = old_model_state.options.get(option_name)\n1438             old_value = (\n1439                 {\n1440                     tuple(\n1441                         self.renamed_fields.get((app_label, model_name, n), n)\n1442                         for n in unique\n1443                     )\n1444                     for unique in old_value\n1445                 }\n1446                 if old_value\n1447                 else set()\n1448             )\n1449 \n1450             new_value = new_model_state.options.get(option_name)\n1451             new_value = set(new_value) if new_value else set()\n1452 \n1453             if old_value != new_value:\n1454                 dependencies = []\n1455                 for foo_togethers in new_value:\n1456                     for field_name in foo_togethers:\n1457                         field = new_model_state.get_field(field_name)\n1458                         if field.remote_field and field.remote_field.model:\n1459                             dependencies.extend(\n1460                                 self._get_dependencies_for_foreign_key(\n1461                                     app_label,\n1462                                     model_name,\n1463                                     field,\n1464                                     self.to_state,\n1465                                 )\n1466                             )\n1467                 yield (\n1468                     old_value,\n1469                     new_value,\n1470                     app_label,\n1471                     model_name,\n1472                     dependencies,\n1473                 )\n1474 \n1475     def _generate_removed_altered_foo_together(self, operation):\n1476         for (\n1477             old_value,\n1478             new_value,\n1479             app_label,\n1480             model_name,\n1481             dependencies,\n1482         ) in self._get_altered_foo_together_operations(operation.option_name):\n1483             if operation == operations.AlterIndexTogether:\n1484                 old_value = {\n1485                     value\n1486                     for value in old_value\n1487                     if value\n1488                     not in self.renamed_index_together_values[app_label, model_name]\n1489                 }\n1490             removal_value = new_value.intersection(old_value)\n1491             if removal_value or old_value:\n1492                 self.add_operation(\n1493                     app_label,\n1494                     operation(\n1495                         name=model_name, **{operation.option_name: removal_value}\n1496                     ),\n1497                     dependencies=dependencies,\n1498                 )\n1499 \n1500     def generate_removed_altered_unique_together(self):\n1501         self._generate_removed_altered_foo_together(operations.AlterUniqueTogether)\n1502 \n1503     def generate_removed_altered_index_together(self):\n1504         self._generate_removed_altered_foo_together(operations.AlterIndexTogether)\n1505 \n1506     def _generate_altered_foo_together(self, operation):\n1507         for (\n1508             old_value,\n1509             new_value,\n1510             app_label,\n1511             model_name,\n1512             dependencies,\n1513         ) in self._get_altered_foo_together_operations(operation.option_name):\n1514             removal_value = new_value.intersection(old_value)\n1515             if new_value != removal_value:\n1516                 self.add_operation(\n1517                     app_label,\n1518                     operation(name=model_name, **{operation.option_name: new_value}),\n1519                     dependencies=dependencies,\n1520                 )\n1521 \n1522     def generate_altered_unique_together(self):\n1523         self._generate_altered_foo_together(operations.AlterUniqueTogether)\n1524 \n1525     def generate_altered_index_together(self):\n1526         self._generate_altered_foo_together(operations.AlterIndexTogether)\n1527 \n1528     def generate_altered_db_table(self):\n1529         models_to_check = self.kept_model_keys.union(\n1530             self.kept_proxy_keys, self.kept_unmanaged_keys\n1531         )\n1532         for app_label, model_name in sorted(models_to_check):\n1533             old_model_name = self.renamed_models.get(\n1534                 (app_label, model_name), model_name\n1535             )\n1536             old_model_state = self.from_state.models[app_label, old_model_name]\n1537             new_model_state = self.to_state.models[app_label, model_name]\n1538             old_db_table_name = old_model_state.options.get(\"db_table\")\n1539             new_db_table_name = new_model_state.options.get(\"db_table\")\n1540             if old_db_table_name != new_db_table_name:\n1541                 self.add_operation(\n1542                     app_label,\n1543                     operations.AlterModelTable(\n1544                         name=model_name,\n1545                         table=new_db_table_name,\n1546                     ),\n1547                 )\n1548 \n1549     def generate_altered_options(self):\n1550         \"\"\"\n1551         Work out if any non-schema-affecting options have changed and make an\n1552         operation to represent them in state changes (in case Python code in\n1553         migrations needs them).\n1554         \"\"\"\n1555         models_to_check = self.kept_model_keys.union(\n1556             self.kept_proxy_keys,\n1557             self.kept_unmanaged_keys,\n1558             # unmanaged converted to managed\n1559             self.old_unmanaged_keys & self.new_model_keys,\n1560             # managed converted to unmanaged\n1561             self.old_model_keys & self.new_unmanaged_keys,\n1562         )\n1563 \n1564         for app_label, model_name in sorted(models_to_check):\n1565             old_model_name = self.renamed_models.get(\n1566                 (app_label, model_name), model_name\n1567             )\n1568             old_model_state = self.from_state.models[app_label, old_model_name]\n1569             new_model_state = self.to_state.models[app_label, model_name]\n1570             old_options = {\n1571                 key: value\n1572                 for key, value in old_model_state.options.items()\n1573                 if key in AlterModelOptions.ALTER_OPTION_KEYS\n1574             }\n1575             new_options = {\n1576                 key: value\n1577                 for key, value in new_model_state.options.items()\n1578                 if key in AlterModelOptions.ALTER_OPTION_KEYS\n1579             }\n1580             if old_options != new_options:\n1581                 self.add_operation(\n1582                     app_label,\n1583                     operations.AlterModelOptions(\n1584                         name=model_name,\n1585                         options=new_options,\n1586                     ),\n1587                 )\n1588 \n1589     def generate_altered_order_with_respect_to(self):\n1590         for app_label, model_name in sorted(self.kept_model_keys):\n1591             old_model_name = self.renamed_models.get(\n1592                 (app_label, model_name), model_name\n1593             )\n1594             old_model_state = self.from_state.models[app_label, old_model_name]\n1595             new_model_state = self.to_state.models[app_label, model_name]\n1596             if old_model_state.options.get(\n1597                 \"order_with_respect_to\"\n1598             ) != new_model_state.options.get(\"order_with_respect_to\"):\n1599                 # Make sure it comes second if we're adding\n1600                 # (removal dependency is part of RemoveField)\n1601                 dependencies = []\n1602                 if new_model_state.options.get(\"order_with_respect_to\"):\n1603                     dependencies.append(\n1604                         (\n1605                             app_label,\n1606                             model_name,\n1607                             new_model_state.options[\"order_with_respect_to\"],\n1608                             True,\n1609                         )\n1610                     )\n1611                 # Actually generate the operation\n1612                 self.add_operation(\n1613                     app_label,\n1614                     operations.AlterOrderWithRespectTo(\n1615                         name=model_name,\n1616                         order_with_respect_to=new_model_state.options.get(\n1617                             \"order_with_respect_to\"\n1618                         ),\n1619                     ),\n1620                     dependencies=dependencies,\n1621                 )\n1622 \n1623     def generate_altered_managers(self):\n1624         for app_label, model_name in sorted(self.kept_model_keys):\n1625             old_model_name = self.renamed_models.get(\n1626                 (app_label, model_name), model_name\n1627             )\n1628             old_model_state = self.from_state.models[app_label, old_model_name]\n1629             new_model_state = self.to_state.models[app_label, model_name]\n1630             if old_model_state.managers != new_model_state.managers:\n1631                 self.add_operation(\n1632                     app_label,\n1633                     operations.AlterModelManagers(\n1634                         name=model_name,\n1635                         managers=new_model_state.managers,\n1636                     ),\n1637                 )\n1638 \n1639     def arrange_for_graph(self, changes, graph, migration_name=None):\n1640         \"\"\"\n1641         Take a result from changes() and a MigrationGraph, and fix the names\n1642         and dependencies of the changes so they extend the graph from the leaf\n1643         nodes for each app.\n1644         \"\"\"\n1645         leaves = graph.leaf_nodes()\n1646         name_map = {}\n1647         for app_label, migrations in list(changes.items()):\n1648             if not migrations:\n1649                 continue\n1650             # Find the app label's current leaf node\n1651             app_leaf = None\n1652             for leaf in leaves:\n1653                 if leaf[0] == app_label:\n1654                     app_leaf = leaf\n1655                     break\n1656             # Do they want an initial migration for this app?\n1657             if app_leaf is None and not self.questioner.ask_initial(app_label):\n1658                 # They don't.\n1659                 for migration in migrations:\n1660                     name_map[(app_label, migration.name)] = (app_label, \"__first__\")\n1661                 del changes[app_label]\n1662                 continue\n1663             # Work out the next number in the sequence\n1664             if app_leaf is None:\n1665                 next_number = 1\n1666             else:\n1667                 next_number = (self.parse_number(app_leaf[1]) or 0) + 1\n1668             # Name each migration\n1669             for i, migration in enumerate(migrations):\n1670                 if i == 0 and app_leaf:\n1671                     migration.dependencies.append(app_leaf)\n1672                 new_name_parts = [\"%04i\" % next_number]\n1673                 if migration_name:\n1674                     new_name_parts.append(migration_name)\n1675                 elif i == 0 and not app_leaf:\n1676                     new_name_parts.append(\"initial\")\n1677                 else:\n1678                     new_name_parts.append(migration.suggest_name()[:100])\n1679                 new_name = \"_\".join(new_name_parts)\n1680                 name_map[(app_label, migration.name)] = (app_label, new_name)\n1681                 next_number += 1\n1682                 migration.name = new_name\n1683         # Now fix dependencies\n1684         for migrations in changes.values():\n1685             for migration in migrations:\n1686                 migration.dependencies = [\n1687                     name_map.get(d, d) for d in migration.dependencies\n1688                 ]\n1689         return changes\n1690 \n1691     def _trim_to_apps(self, changes, app_labels):\n1692         \"\"\"\n1693         Take changes from arrange_for_graph() and set of app labels, and return\n1694         a modified set of changes which trims out as many migrations that are\n1695         not in app_labels as possible. Note that some other migrations may\n1696         still be present as they may be required dependencies.\n1697         \"\"\"\n1698         # Gather other app dependencies in a first pass\n1699         app_dependencies = {}\n1700         for app_label, migrations in changes.items():\n1701             for migration in migrations:\n1702                 for dep_app_label, name in migration.dependencies:\n1703                     app_dependencies.setdefault(app_label, set()).add(dep_app_label)\n1704         required_apps = set(app_labels)\n1705         # Keep resolving till there's no change\n1706         old_required_apps = None\n1707         while old_required_apps != required_apps:\n1708             old_required_apps = set(required_apps)\n1709             required_apps.update(\n1710                 *[app_dependencies.get(app_label, ()) for app_label in required_apps]\n1711             )\n1712         # Remove all migrations that aren't needed\n1713         for app_label in list(changes):\n1714             if app_label not in required_apps:\n1715                 del changes[app_label]\n1716         return changes\n1717 \n1718     @classmethod\n1719     def parse_number(cls, name):\n1720         \"\"\"\n1721         Given a migration name, try to extract a number from the beginning of\n1722         it. For a squashed migration such as '0001_squashed_0004\u2026', return the\n1723         second number. If no number is found, return None.\n1724         \"\"\"\n1725         if squashed_match := re.search(r\".*_squashed_(\\d+)\", name):\n1726             return int(squashed_match[1])\n1727         match = re.match(r\"^\\d+\", name)\n1728         if match:\n1729             return int(match[0])\n1730         return None\n",
        "intended_behavior": "Correctly identify changes from `index_together` to `Model.Meta.indexes` for migration generation, ensuring error-free recognition and operation reflection."
    },
    {
        "rel_file_path": "django/db/backends/base/schema.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__4.2/django/db/backends/base/schema.py",
        "start": 1,
        "end": 1749,
        "class_name": null,
        "method_name": null,
        "code": "1 import logging\n2 import operator\n3 from datetime import datetime\n4 \n5 from django.conf import settings\n6 from django.db.backends.ddl_references import (\n7     Columns,\n8     Expressions,\n9     ForeignKeyName,\n10     IndexName,\n11     Statement,\n12     Table,\n13 )\n14 from django.db.backends.utils import names_digest, split_identifier\n15 from django.db.models import Deferrable, Index\n16 from django.db.models.sql import Query\n17 from django.db.transaction import TransactionManagementError, atomic\n18 from django.utils import timezone\n19 \n20 logger = logging.getLogger(\"django.db.backends.schema\")\n21 \n22 \n23 def _is_relevant_relation(relation, altered_field):\n24     \"\"\"\n25     When altering the given field, must constraints on its model from the given\n26     relation be temporarily dropped?\n27     \"\"\"\n28     field = relation.field\n29     if field.many_to_many:\n30         # M2M reverse field\n31         return False\n32     if altered_field.primary_key and field.to_fields == [None]:\n33         # Foreign key constraint on the primary key, which is being altered.\n34         return True\n35     # Is the constraint targeting the field being altered?\n36     return altered_field.name in field.to_fields\n37 \n38 \n39 def _all_related_fields(model):\n40     # Related fields must be returned in a deterministic order.\n41     return sorted(\n42         model._meta._get_fields(\n43             forward=False,\n44             reverse=True,\n45             include_hidden=True,\n46             include_parents=False,\n47         ),\n48         key=operator.attrgetter(\"name\"),\n49     )\n50 \n51 \n52 def _related_non_m2m_objects(old_field, new_field):\n53     # Filter out m2m objects from reverse relations.\n54     # Return (old_relation, new_relation) tuples.\n55     related_fields = zip(\n56         (\n57             obj\n58             for obj in _all_related_fields(old_field.model)\n59             if _is_relevant_relation(obj, old_field)\n60         ),\n61         (\n62             obj\n63             for obj in _all_related_fields(new_field.model)\n64             if _is_relevant_relation(obj, new_field)\n65         ),\n66     )\n67     for old_rel, new_rel in related_fields:\n68         yield old_rel, new_rel\n69         yield from _related_non_m2m_objects(\n70             old_rel.remote_field,\n71             new_rel.remote_field,\n72         )\n73 \n74 \n75 class BaseDatabaseSchemaEditor:\n76     \"\"\"\n77     This class and its subclasses are responsible for emitting schema-changing\n78     statements to the databases - model creation/removal/alteration, field\n79     renaming, index fiddling, and so on.\n80     \"\"\"\n81 \n82     # Overrideable SQL templates\n83     sql_create_table = \"CREATE TABLE %(table)s (%(definition)s)\"\n84     sql_rename_table = \"ALTER TABLE %(old_table)s RENAME TO %(new_table)s\"\n85     sql_retablespace_table = \"ALTER TABLE %(table)s SET TABLESPACE %(new_tablespace)s\"\n86     sql_delete_table = \"DROP TABLE %(table)s CASCADE\"\n87 \n88     sql_create_column = \"ALTER TABLE %(table)s ADD COLUMN %(column)s %(definition)s\"\n89     sql_alter_column = \"ALTER TABLE %(table)s %(changes)s\"\n90     sql_alter_column_type = \"ALTER COLUMN %(column)s TYPE %(type)s\"\n91     sql_alter_column_null = \"ALTER COLUMN %(column)s DROP NOT NULL\"\n92     sql_alter_column_not_null = \"ALTER COLUMN %(column)s SET NOT NULL\"\n93     sql_alter_column_default = \"ALTER COLUMN %(column)s SET DEFAULT %(default)s\"\n94     sql_alter_column_no_default = \"ALTER COLUMN %(column)s DROP DEFAULT\"\n95     sql_alter_column_no_default_null = sql_alter_column_no_default\n96     sql_alter_column_collate = \"ALTER COLUMN %(column)s TYPE %(type)s%(collation)s\"\n97     sql_delete_column = \"ALTER TABLE %(table)s DROP COLUMN %(column)s CASCADE\"\n98     sql_rename_column = (\n99         \"ALTER TABLE %(table)s RENAME COLUMN %(old_column)s TO %(new_column)s\"\n100     )\n101     sql_update_with_default = (\n102         \"UPDATE %(table)s SET %(column)s = %(default)s WHERE %(column)s IS NULL\"\n103     )\n104 \n105     sql_unique_constraint = \"UNIQUE (%(columns)s)%(deferrable)s\"\n106     sql_check_constraint = \"CHECK (%(check)s)\"\n107     sql_delete_constraint = \"ALTER TABLE %(table)s DROP CONSTRAINT %(name)s\"\n108     sql_constraint = \"CONSTRAINT %(name)s %(constraint)s\"\n109 \n110     sql_create_check = \"ALTER TABLE %(table)s ADD CONSTRAINT %(name)s CHECK (%(check)s)\"\n111     sql_delete_check = sql_delete_constraint\n112 \n113     sql_create_unique = (\n114         \"ALTER TABLE %(table)s ADD CONSTRAINT %(name)s \"\n115         \"UNIQUE (%(columns)s)%(deferrable)s\"\n116     )\n117     sql_delete_unique = sql_delete_constraint\n118 \n119     sql_create_fk = (\n120         \"ALTER TABLE %(table)s ADD CONSTRAINT %(name)s FOREIGN KEY (%(column)s) \"\n121         \"REFERENCES %(to_table)s (%(to_column)s)%(deferrable)s\"\n122     )\n123     sql_create_inline_fk = None\n124     sql_create_column_inline_fk = None\n125     sql_delete_fk = sql_delete_constraint\n126 \n127     sql_create_index = (\n128         \"CREATE INDEX %(name)s ON %(table)s \"\n129         \"(%(columns)s)%(include)s%(extra)s%(condition)s\"\n130     )\n131     sql_create_unique_index = (\n132         \"CREATE UNIQUE INDEX %(name)s ON %(table)s \"\n133         \"(%(columns)s)%(include)s%(condition)s\"\n134     )\n135     sql_rename_index = \"ALTER INDEX %(old_name)s RENAME TO %(new_name)s\"\n136     sql_delete_index = \"DROP INDEX %(name)s\"\n137 \n138     sql_create_pk = (\n139         \"ALTER TABLE %(table)s ADD CONSTRAINT %(name)s PRIMARY KEY (%(columns)s)\"\n140     )\n141     sql_delete_pk = sql_delete_constraint\n142 \n143     sql_delete_procedure = \"DROP PROCEDURE %(procedure)s\"\n144 \n145     def __init__(self, connection, collect_sql=False, atomic=True):\n146         self.connection = connection\n147         self.collect_sql = collect_sql\n148         if self.collect_sql:\n149             self.collected_sql = []\n150         self.atomic_migration = self.connection.features.can_rollback_ddl and atomic\n151 \n152     # State-managing methods\n153 \n154     def __enter__(self):\n155         self.deferred_sql = []\n156         if self.atomic_migration:\n157             self.atomic = atomic(self.connection.alias)\n158             self.atomic.__enter__()\n159         return self\n160 \n161     def __exit__(self, exc_type, exc_value, traceback):\n162         if exc_type is None:\n163             for sql in self.deferred_sql:\n164                 self.execute(sql)\n165         if self.atomic_migration:\n166             self.atomic.__exit__(exc_type, exc_value, traceback)\n167 \n168     # Core utility functions\n169 \n170     def execute(self, sql, params=()):\n171         \"\"\"Execute the given SQL statement, with optional parameters.\"\"\"\n172         # Don't perform the transactional DDL check if SQL is being collected\n173         # as it's not going to be executed anyway.\n174         if (\n175             not self.collect_sql\n176             and self.connection.in_atomic_block\n177             and not self.connection.features.can_rollback_ddl\n178         ):\n179             raise TransactionManagementError(\n180                 \"Executing DDL statements while in a transaction on databases \"\n181                 \"that can't perform a rollback is prohibited.\"\n182             )\n183         # Account for non-string statement objects.\n184         sql = str(sql)\n185         # Log the command we're running, then run it\n186         logger.debug(\n187             \"%s; (params %r)\", sql, params, extra={\"params\": params, \"sql\": sql}\n188         )\n189         if self.collect_sql:\n190             ending = \"\" if sql.rstrip().endswith(\";\") else \";\"\n191             if params is not None:\n192                 self.collected_sql.append(\n193                     (sql % tuple(map(self.quote_value, params))) + ending\n194                 )\n195             else:\n196                 self.collected_sql.append(sql + ending)\n197         else:\n198             with self.connection.cursor() as cursor:\n199                 cursor.execute(sql, params)\n200 \n201     def quote_name(self, name):\n202         return self.connection.ops.quote_name(name)\n203 \n204     def table_sql(self, model):\n205         \"\"\"Take a model and return its table definition.\"\"\"\n206         # Add any unique_togethers (always deferred, as some fields might be\n207         # created afterward, like geometry fields with some backends).\n208         for field_names in model._meta.unique_together:\n209             fields = [model._meta.get_field(field) for field in field_names]\n210             self.deferred_sql.append(self._create_unique_sql(model, fields))\n211         # Create column SQL, add FK deferreds if needed.\n212         column_sqls = []\n213         params = []\n214         for field in model._meta.local_fields:\n215             # SQL.\n216             definition, extra_params = self.column_sql(model, field)\n217             if definition is None:\n218                 continue\n219             # Check constraints can go on the column SQL here.\n220             db_params = field.db_parameters(connection=self.connection)\n221             if db_params[\"check\"]:\n222                 definition += \" \" + self.sql_check_constraint % db_params\n223             # Autoincrement SQL (for backends with inline variant).\n224             col_type_suffix = field.db_type_suffix(connection=self.connection)\n225             if col_type_suffix:\n226                 definition += \" %s\" % col_type_suffix\n227             params.extend(extra_params)\n228             # FK.\n229             if field.remote_field and field.db_constraint:\n230                 to_table = field.remote_field.model._meta.db_table\n231                 to_column = field.remote_field.model._meta.get_field(\n232                     field.remote_field.field_name\n233                 ).column\n234                 if self.sql_create_inline_fk:\n235                     definition += \" \" + self.sql_create_inline_fk % {\n236                         \"to_table\": self.quote_name(to_table),\n237                         \"to_column\": self.quote_name(to_column),\n238                     }\n239                 elif self.connection.features.supports_foreign_keys:\n240                     self.deferred_sql.append(\n241                         self._create_fk_sql(\n242                             model, field, \"_fk_%(to_table)s_%(to_column)s\"\n243                         )\n244                     )\n245             # Add the SQL to our big list.\n246             column_sqls.append(\n247                 \"%s %s\"\n248                 % (\n249                     self.quote_name(field.column),\n250                     definition,\n251                 )\n252             )\n253             # Autoincrement SQL (for backends with post table definition\n254             # variant).\n255             if field.get_internal_type() in (\n256                 \"AutoField\",\n257                 \"BigAutoField\",\n258                 \"SmallAutoField\",\n259             ):\n260                 autoinc_sql = self.connection.ops.autoinc_sql(\n261                     model._meta.db_table, field.column\n262                 )\n263                 if autoinc_sql:\n264                     self.deferred_sql.extend(autoinc_sql)\n265         constraints = [\n266             constraint.constraint_sql(model, self)\n267             for constraint in model._meta.constraints\n268         ]\n269         sql = self.sql_create_table % {\n270             \"table\": self.quote_name(model._meta.db_table),\n271             \"definition\": \", \".join(\n272                 constraint for constraint in (*column_sqls, *constraints) if constraint\n273             ),\n274         }\n275         if model._meta.db_tablespace:\n276             tablespace_sql = self.connection.ops.tablespace_sql(\n277                 model._meta.db_tablespace\n278             )\n279             if tablespace_sql:\n280                 sql += \" \" + tablespace_sql\n281         return sql, params\n282 \n283     # Field <-> database mapping functions\n284 \n285     def _iter_column_sql(\n286         self, column_db_type, params, model, field, field_db_params, include_default\n287     ):\n288         yield column_db_type\n289         if collation := field_db_params.get(\"collation\"):\n290             yield self._collate_sql(collation)\n291         # Work out nullability.\n292         null = field.null\n293         # Include a default value, if requested.\n294         include_default = (\n295             include_default\n296             and not self.skip_default(field)\n297             and\n298             # Don't include a default value if it's a nullable field and the\n299             # default cannot be dropped in the ALTER COLUMN statement (e.g.\n300             # MySQL longtext and longblob).\n301             not (null and self.skip_default_on_alter(field))\n302         )\n303         if include_default:\n304             default_value = self.effective_default(field)\n305             if default_value is not None:\n306                 column_default = \"DEFAULT \" + self._column_default_sql(field)\n307                 if self.connection.features.requires_literal_defaults:\n308                     # Some databases can't take defaults as a parameter (Oracle).\n309                     # If this is the case, the individual schema backend should\n310                     # implement prepare_default().\n311                     yield column_default % self.prepare_default(default_value)\n312                 else:\n313                     yield column_default\n314                     params.append(default_value)\n315         # Oracle treats the empty string ('') as null, so coerce the null\n316         # option whenever '' is a possible value.\n317         if (\n318             field.empty_strings_allowed\n319             and not field.primary_key\n320             and self.connection.features.interprets_empty_strings_as_nulls\n321         ):\n322             null = True\n323         if not null:\n324             yield \"NOT NULL\"\n325         elif not self.connection.features.implied_column_null:\n326             yield \"NULL\"\n327         if field.primary_key:\n328             yield \"PRIMARY KEY\"\n329         elif field.unique:\n330             yield \"UNIQUE\"\n331         # Optionally add the tablespace if it's an implicitly indexed column.\n332         tablespace = field.db_tablespace or model._meta.db_tablespace\n333         if (\n334             tablespace\n335             and self.connection.features.supports_tablespaces\n336             and field.unique\n337         ):\n338             yield self.connection.ops.tablespace_sql(tablespace, inline=True)\n339 \n340     def column_sql(self, model, field, include_default=False):\n341         \"\"\"\n342         Return the column definition for a field. The field must already have\n343         had set_attributes_from_name() called.\n344         \"\"\"\n345         # Get the column's type and use that as the basis of the SQL.\n346         field_db_params = field.db_parameters(connection=self.connection)\n347         column_db_type = field_db_params[\"type\"]\n348         # Check for fields that aren't actually columns (e.g. M2M).\n349         if column_db_type is None:\n350             return None, None\n351         params = []\n352         return (\n353             \" \".join(\n354                 # This appends to the params being returned.\n355                 self._iter_column_sql(\n356                     column_db_type,\n357                     params,\n358                     model,\n359                     field,\n360                     field_db_params,\n361                     include_default,\n362                 )\n363             ),\n364             params,\n365         )\n366 \n367     def skip_default(self, field):\n368         \"\"\"\n369         Some backends don't accept default values for certain columns types\n370         (i.e. MySQL longtext and longblob).\n371         \"\"\"\n372         return False\n373 \n374     def skip_default_on_alter(self, field):\n375         \"\"\"\n376         Some backends don't accept default values for certain columns types\n377         (i.e. MySQL longtext and longblob) in the ALTER COLUMN statement.\n378         \"\"\"\n379         return False\n380 \n381     def prepare_default(self, value):\n382         \"\"\"\n383         Only used for backends which have requires_literal_defaults feature\n384         \"\"\"\n385         raise NotImplementedError(\n386             \"subclasses of BaseDatabaseSchemaEditor for backends which have \"\n387             \"requires_literal_defaults must provide a prepare_default() method\"\n388         )\n389 \n390     def _column_default_sql(self, field):\n391         \"\"\"\n392         Return the SQL to use in a DEFAULT clause. The resulting string should\n393         contain a '%s' placeholder for a default value.\n394         \"\"\"\n395         return \"%s\"\n396 \n397     @staticmethod\n398     def _effective_default(field):\n399         # This method allows testing its logic without a connection.\n400         if field.has_default():\n401             default = field.get_default()\n402         elif not field.null and field.blank and field.empty_strings_allowed:\n403             if field.get_internal_type() == \"BinaryField\":\n404                 default = b\"\"\n405             else:\n406                 default = \"\"\n407         elif getattr(field, \"auto_now\", False) or getattr(field, \"auto_now_add\", False):\n408             internal_type = field.get_internal_type()\n409             if internal_type == \"DateTimeField\":\n410                 default = timezone.now()\n411             else:\n412                 default = datetime.now()\n413                 if internal_type == \"DateField\":\n414                     default = default.date()\n415                 elif internal_type == \"TimeField\":\n416                     default = default.time()\n417         else:\n418             default = None\n419         return default\n420 \n421     def effective_default(self, field):\n422         \"\"\"Return a field's effective database default value.\"\"\"\n423         return field.get_db_prep_save(self._effective_default(field), self.connection)\n424 \n425     def quote_value(self, value):\n426         \"\"\"\n427         Return a quoted version of the value so it's safe to use in an SQL\n428         string. This is not safe against injection from user code; it is\n429         intended only for use in making SQL scripts or preparing default values\n430         for particularly tricky backends (defaults are not user-defined, though,\n431         so this is safe).\n432         \"\"\"\n433         raise NotImplementedError()\n434 \n435     # Actions\n436 \n437     def create_model(self, model):\n438         \"\"\"\n439         Create a table and any accompanying indexes or unique constraints for\n440         the given `model`.\n441         \"\"\"\n442         sql, params = self.table_sql(model)\n443         # Prevent using [] as params, in the case a literal '%' is used in the\n444         # definition.\n445         self.execute(sql, params or None)\n446 \n447         # Add any field index and index_together's (deferred as SQLite\n448         # _remake_table needs it).\n449         self.deferred_sql.extend(self._model_indexes_sql(model))\n450 \n451         # Make M2M tables\n452         for field in model._meta.local_many_to_many:\n453             if field.remote_field.through._meta.auto_created:\n454                 self.create_model(field.remote_field.through)\n455 \n456     def delete_model(self, model):\n457         \"\"\"Delete a model from the database.\"\"\"\n458         # Handle auto-created intermediary models\n459         for field in model._meta.local_many_to_many:\n460             if field.remote_field.through._meta.auto_created:\n461                 self.delete_model(field.remote_field.through)\n462 \n463         # Delete the table\n464         self.execute(\n465             self.sql_delete_table\n466             % {\n467                 \"table\": self.quote_name(model._meta.db_table),\n468             }\n469         )\n470         # Remove all deferred statements referencing the deleted table.\n471         for sql in list(self.deferred_sql):\n472             if isinstance(sql, Statement) and sql.references_table(\n473                 model._meta.db_table\n474             ):\n475                 self.deferred_sql.remove(sql)\n476 \n477     def add_index(self, model, index):\n478         \"\"\"Add an index on a model.\"\"\"\n479         if (\n480             index.contains_expressions\n481             and not self.connection.features.supports_expression_indexes\n482         ):\n483             return None\n484         # Index.create_sql returns interpolated SQL which makes params=None a\n485         # necessity to avoid escaping attempts on execution.\n486         self.execute(index.create_sql(model, self), params=None)\n487 \n488     def remove_index(self, model, index):\n489         \"\"\"Remove an index from a model.\"\"\"\n490         if (\n491             index.contains_expressions\n492             and not self.connection.features.supports_expression_indexes\n493         ):\n494             return None\n495         self.execute(index.remove_sql(model, self))\n496 \n497     def rename_index(self, model, old_index, new_index):\n498         if self.connection.features.can_rename_index:\n499             self.execute(\n500                 self._rename_index_sql(model, old_index.name, new_index.name),\n501                 params=None,\n502             )\n503         else:\n504             self.remove_index(model, old_index)\n505             self.add_index(model, new_index)\n506 \n507     def add_constraint(self, model, constraint):\n508         \"\"\"Add a constraint to a model.\"\"\"\n509         sql = constraint.create_sql(model, self)\n510         if sql:\n511             # Constraint.create_sql returns interpolated SQL which makes\n512             # params=None a necessity to avoid escaping attempts on execution.\n513             self.execute(sql, params=None)\n514 \n515     def remove_constraint(self, model, constraint):\n516         \"\"\"Remove a constraint from a model.\"\"\"\n517         sql = constraint.remove_sql(model, self)\n518         if sql:\n519             self.execute(sql)\n520 \n521     def alter_unique_together(self, model, old_unique_together, new_unique_together):\n522         \"\"\"\n523         Deal with a model changing its unique_together. The input\n524         unique_togethers must be doubly-nested, not the single-nested\n525         [\"foo\", \"bar\"] format.\n526         \"\"\"\n527         olds = {tuple(fields) for fields in old_unique_together}\n528         news = {tuple(fields) for fields in new_unique_together}\n529         # Deleted uniques\n530         for fields in olds.difference(news):\n531             self._delete_composed_index(\n532                 model,\n533                 fields,\n534                 {\"unique\": True, \"primary_key\": False},\n535                 self.sql_delete_unique,\n536             )\n537         # Created uniques\n538         for field_names in news.difference(olds):\n539             fields = [model._meta.get_field(field) for field in field_names]\n540             self.execute(self._create_unique_sql(model, fields))\n541 \n542     def alter_index_together(self, model, old_index_together, new_index_together):\n543         \"\"\"\n544         Deal with a model changing its index_together. The input\n545         index_togethers must be doubly-nested, not the single-nested\n546         [\"foo\", \"bar\"] format.\n547         \"\"\"\n548         olds = {tuple(fields) for fields in old_index_together}\n549         news = {tuple(fields) for fields in new_index_together}\n550         # Deleted indexes\n551         for fields in olds.difference(news):\n552             self._delete_composed_index(\n553                 model,\n554                 fields,\n555                 {\"index\": True, \"unique\": False},\n556                 self.sql_delete_index,\n557             )\n558         # Created indexes\n559         for field_names in news.difference(olds):\n560             fields = [model._meta.get_field(field) for field in field_names]\n561             self.execute(self._create_index_sql(model, fields=fields, suffix=\"_idx\"))\n562 \n563     def _delete_composed_index(self, model, fields, constraint_kwargs, sql):\n564         meta_constraint_names = {\n565             constraint.name for constraint in model._meta.constraints\n566         }\n567         meta_index_names = {constraint.name for constraint in model._meta.indexes}\n568         columns = [model._meta.get_field(field).column for field in fields]\n569         constraint_names = self._constraint_names(\n570             model,\n571             columns,\n572             exclude=meta_constraint_names | meta_index_names,\n573             **constraint_kwargs,\n574         )\n575         if (\n576             constraint_kwargs.get(\"unique\") is True\n577             and constraint_names\n578             and self.connection.features.allows_multiple_constraints_on_same_fields\n579         ):\n580             # Constraint matching the unique_together name.\n581             default_name = str(\n582                 self._unique_constraint_name(model._meta.db_table, columns, quote=False)\n583             )\n584             if default_name in constraint_names:\n585                 constraint_names = [default_name]\n586         if len(constraint_names) != 1:\n587             raise ValueError(\n588                 \"Found wrong number (%s) of constraints for %s(%s)\"\n589                 % (\n590                     len(constraint_names),\n591                     model._meta.db_table,\n592                     \", \".join(columns),\n593                 )\n594             )\n595         self.execute(self._delete_constraint_sql(sql, model, constraint_names[0]))\n596 \n597     def alter_db_table(self, model, old_db_table, new_db_table):\n598         \"\"\"Rename the table a model points to.\"\"\"\n599         if old_db_table == new_db_table or (\n600             self.connection.features.ignores_table_name_case\n601             and old_db_table.lower() == new_db_table.lower()\n602         ):\n603             return\n604         self.execute(\n605             self.sql_rename_table\n606             % {\n607                 \"old_table\": self.quote_name(old_db_table),\n608                 \"new_table\": self.quote_name(new_db_table),\n609             }\n610         )\n611         # Rename all references to the old table name.\n612         for sql in self.deferred_sql:\n613             if isinstance(sql, Statement):\n614                 sql.rename_table_references(old_db_table, new_db_table)\n615 \n616     def alter_db_tablespace(self, model, old_db_tablespace, new_db_tablespace):\n617         \"\"\"Move a model's table between tablespaces.\"\"\"\n618         self.execute(\n619             self.sql_retablespace_table\n620             % {\n621                 \"table\": self.quote_name(model._meta.db_table),\n622                 \"old_tablespace\": self.quote_name(old_db_tablespace),\n623                 \"new_tablespace\": self.quote_name(new_db_tablespace),\n624             }\n625         )\n626 \n627     def add_field(self, model, field):\n628         \"\"\"\n629         Create a field on a model. Usually involves adding a column, but may\n630         involve adding a table instead (for M2M fields).\n631         \"\"\"\n632         # Special-case implicit M2M tables\n633         if field.many_to_many and field.remote_field.through._meta.auto_created:\n634             return self.create_model(field.remote_field.through)\n635         # Get the column's definition\n636         definition, params = self.column_sql(model, field, include_default=True)\n637         # It might not actually have a column behind it\n638         if definition is None:\n639             return\n640         # Check constraints can go on the column SQL here\n641         db_params = field.db_parameters(connection=self.connection)\n642         if db_params[\"check\"]:\n643             definition += \" \" + self.sql_check_constraint % db_params\n644         if (\n645             field.remote_field\n646             and self.connection.features.supports_foreign_keys\n647             and field.db_constraint\n648         ):\n649             constraint_suffix = \"_fk_%(to_table)s_%(to_column)s\"\n650             # Add FK constraint inline, if supported.\n651             if self.sql_create_column_inline_fk:\n652                 to_table = field.remote_field.model._meta.db_table\n653                 to_column = field.remote_field.model._meta.get_field(\n654                     field.remote_field.field_name\n655                 ).column\n656                 namespace, _ = split_identifier(model._meta.db_table)\n657                 definition += \" \" + self.sql_create_column_inline_fk % {\n658                     \"name\": self._fk_constraint_name(model, field, constraint_suffix),\n659                     \"namespace\": \"%s.\" % self.quote_name(namespace)\n660                     if namespace\n661                     else \"\",\n662                     \"column\": self.quote_name(field.column),\n663                     \"to_table\": self.quote_name(to_table),\n664                     \"to_column\": self.quote_name(to_column),\n665                     \"deferrable\": self.connection.ops.deferrable_sql(),\n666                 }\n667             # Otherwise, add FK constraints later.\n668             else:\n669                 self.deferred_sql.append(\n670                     self._create_fk_sql(model, field, constraint_suffix)\n671                 )\n672         # Build the SQL and run it\n673         sql = self.sql_create_column % {\n674             \"table\": self.quote_name(model._meta.db_table),\n675             \"column\": self.quote_name(field.column),\n676             \"definition\": definition,\n677         }\n678         self.execute(sql, params)\n679         # Drop the default if we need to\n680         # (Django usually does not use in-database defaults)\n681         if (\n682             not self.skip_default_on_alter(field)\n683             and self.effective_default(field) is not None\n684         ):\n685             changes_sql, params = self._alter_column_default_sql(\n686                 model, None, field, drop=True\n687             )\n688             sql = self.sql_alter_column % {\n689                 \"table\": self.quote_name(model._meta.db_table),\n690                 \"changes\": changes_sql,\n691             }\n692             self.execute(sql, params)\n693         # Add an index, if required\n694         self.deferred_sql.extend(self._field_indexes_sql(model, field))\n695         # Reset connection if required\n696         if self.connection.features.connection_persists_old_columns:\n697             self.connection.close()\n698 \n699     def remove_field(self, model, field):\n700         \"\"\"\n701         Remove a field from a model. Usually involves deleting a column,\n702         but for M2Ms may involve deleting a table.\n703         \"\"\"\n704         # Special-case implicit M2M tables\n705         if field.many_to_many and field.remote_field.through._meta.auto_created:\n706             return self.delete_model(field.remote_field.through)\n707         # It might not actually have a column behind it\n708         if field.db_parameters(connection=self.connection)[\"type\"] is None:\n709             return\n710         # Drop any FK constraints, MySQL requires explicit deletion\n711         if field.remote_field:\n712             fk_names = self._constraint_names(model, [field.column], foreign_key=True)\n713             for fk_name in fk_names:\n714                 self.execute(self._delete_fk_sql(model, fk_name))\n715         # Delete the column\n716         sql = self.sql_delete_column % {\n717             \"table\": self.quote_name(model._meta.db_table),\n718             \"column\": self.quote_name(field.column),\n719         }\n720         self.execute(sql)\n721         # Reset connection if required\n722         if self.connection.features.connection_persists_old_columns:\n723             self.connection.close()\n724         # Remove all deferred statements referencing the deleted column.\n725         for sql in list(self.deferred_sql):\n726             if isinstance(sql, Statement) and sql.references_column(\n727                 model._meta.db_table, field.column\n728             ):\n729                 self.deferred_sql.remove(sql)\n730 \n731     def alter_field(self, model, old_field, new_field, strict=False):\n732         \"\"\"\n733         Allow a field's type, uniqueness, nullability, default, column,\n734         constraints, etc. to be modified.\n735         `old_field` is required to compute the necessary changes.\n736         If `strict` is True, raise errors if the old column does not match\n737         `old_field` precisely.\n738         \"\"\"\n739         if not self._field_should_be_altered(old_field, new_field):\n740             return\n741         # Ensure this field is even column-based\n742         old_db_params = old_field.db_parameters(connection=self.connection)\n743         old_type = old_db_params[\"type\"]\n744         new_db_params = new_field.db_parameters(connection=self.connection)\n745         new_type = new_db_params[\"type\"]\n746         if (old_type is None and old_field.remote_field is None) or (\n747             new_type is None and new_field.remote_field is None\n748         ):\n749             raise ValueError(\n750                 \"Cannot alter field %s into %s - they do not properly define \"\n751                 \"db_type (are you using a badly-written custom field?)\"\n752                 % (old_field, new_field),\n753             )\n754         elif (\n755             old_type is None\n756             and new_type is None\n757             and (\n758                 old_field.remote_field.through\n759                 and new_field.remote_field.through\n760                 and old_field.remote_field.through._meta.auto_created\n761                 and new_field.remote_field.through._meta.auto_created\n762             )\n763         ):\n764             return self._alter_many_to_many(model, old_field, new_field, strict)\n765         elif (\n766             old_type is None\n767             and new_type is None\n768             and (\n769                 old_field.remote_field.through\n770                 and new_field.remote_field.through\n771                 and not old_field.remote_field.through._meta.auto_created\n772                 and not new_field.remote_field.through._meta.auto_created\n773             )\n774         ):\n775             # Both sides have through models; this is a no-op.\n776             return\n777         elif old_type is None or new_type is None:\n778             raise ValueError(\n779                 \"Cannot alter field %s into %s - they are not compatible types \"\n780                 \"(you cannot alter to or from M2M fields, or add or remove \"\n781                 \"through= on M2M fields)\" % (old_field, new_field)\n782             )\n783 \n784         self._alter_field(\n785             model,\n786             old_field,\n787             new_field,\n788             old_type,\n789             new_type,\n790             old_db_params,\n791             new_db_params,\n792             strict,\n793         )\n794 \n795     def _alter_field(\n796         self,\n797         model,\n798         old_field,\n799         new_field,\n800         old_type,\n801         new_type,\n802         old_db_params,\n803         new_db_params,\n804         strict=False,\n805     ):\n806         \"\"\"Perform a \"physical\" (non-ManyToMany) field update.\"\"\"\n807         # Drop any FK constraints, we'll remake them later\n808         fks_dropped = set()\n809         if (\n810             self.connection.features.supports_foreign_keys\n811             and old_field.remote_field\n812             and old_field.db_constraint\n813         ):\n814             fk_names = self._constraint_names(\n815                 model, [old_field.column], foreign_key=True\n816             )\n817             if strict and len(fk_names) != 1:\n818                 raise ValueError(\n819                     \"Found wrong number (%s) of foreign key constraints for %s.%s\"\n820                     % (\n821                         len(fk_names),\n822                         model._meta.db_table,\n823                         old_field.column,\n824                     )\n825                 )\n826             for fk_name in fk_names:\n827                 fks_dropped.add((old_field.column,))\n828                 self.execute(self._delete_fk_sql(model, fk_name))\n829         # Has unique been removed?\n830         if old_field.unique and (\n831             not new_field.unique or self._field_became_primary_key(old_field, new_field)\n832         ):\n833             # Find the unique constraint for this field\n834             meta_constraint_names = {\n835                 constraint.name for constraint in model._meta.constraints\n836             }\n837             constraint_names = self._constraint_names(\n838                 model,\n839                 [old_field.column],\n840                 unique=True,\n841                 primary_key=False,\n842                 exclude=meta_constraint_names,\n843             )\n844             if strict and len(constraint_names) != 1:\n845                 raise ValueError(\n846                     \"Found wrong number (%s) of unique constraints for %s.%s\"\n847                     % (\n848                         len(constraint_names),\n849                         model._meta.db_table,\n850                         old_field.column,\n851                     )\n852                 )\n853             for constraint_name in constraint_names:\n854                 self.execute(self._delete_unique_sql(model, constraint_name))\n855         # Drop incoming FK constraints if the field is a primary key or unique,\n856         # which might be a to_field target, and things are going to change.\n857         old_collation = old_db_params.get(\"collation\")\n858         new_collation = new_db_params.get(\"collation\")\n859         drop_foreign_keys = (\n860             self.connection.features.supports_foreign_keys\n861             and (\n862                 (old_field.primary_key and new_field.primary_key)\n863                 or (old_field.unique and new_field.unique)\n864             )\n865             and ((old_type != new_type) or (old_collation != new_collation))\n866         )\n867         if drop_foreign_keys:\n868             # '_meta.related_field' also contains M2M reverse fields, these\n869             # will be filtered out\n870             for _old_rel, new_rel in _related_non_m2m_objects(old_field, new_field):\n871                 rel_fk_names = self._constraint_names(\n872                     new_rel.related_model, [new_rel.field.column], foreign_key=True\n873                 )\n874                 for fk_name in rel_fk_names:\n875                     self.execute(self._delete_fk_sql(new_rel.related_model, fk_name))\n876         # Removed an index? (no strict check, as multiple indexes are possible)\n877         # Remove indexes if db_index switched to False or a unique constraint\n878         # will now be used in lieu of an index. The following lines from the\n879         # truth table show all True cases; the rest are False:\n880         #\n881         # old_field.db_index | old_field.unique | new_field.db_index | new_field.unique\n882         # ------------------------------------------------------------------------------\n883         # True               | False            | False              | False\n884         # True               | False            | False              | True\n885         # True               | False            | True               | True\n886         if (\n887             old_field.db_index\n888             and not old_field.unique\n889             and (not new_field.db_index or new_field.unique)\n890         ):\n891             # Find the index for this field\n892             meta_index_names = {index.name for index in model._meta.indexes}\n893             # Retrieve only BTREE indexes since this is what's created with\n894             # db_index=True.\n895             index_names = self._constraint_names(\n896                 model,\n897                 [old_field.column],\n898                 index=True,\n899                 type_=Index.suffix,\n900                 exclude=meta_index_names,\n901             )\n902             for index_name in index_names:\n903                 # The only way to check if an index was created with\n904                 # db_index=True or with Index(['field'], name='foo')\n905                 # is to look at its name (refs #28053).\n906                 self.execute(self._delete_index_sql(model, index_name))\n907         # Change check constraints?\n908         if old_db_params[\"check\"] != new_db_params[\"check\"] and old_db_params[\"check\"]:\n909             meta_constraint_names = {\n910                 constraint.name for constraint in model._meta.constraints\n911             }\n912             constraint_names = self._constraint_names(\n913                 model,\n914                 [old_field.column],\n915                 check=True,\n916                 exclude=meta_constraint_names,\n917             )\n918             if strict and len(constraint_names) != 1:\n919                 raise ValueError(\n920                     \"Found wrong number (%s) of check constraints for %s.%s\"\n921                     % (\n922                         len(constraint_names),\n923                         model._meta.db_table,\n924                         old_field.column,\n925                     )\n926                 )\n927             for constraint_name in constraint_names:\n928                 self.execute(self._delete_check_sql(model, constraint_name))\n929         # Have they renamed the column?\n930         if old_field.column != new_field.column:\n931             self.execute(\n932                 self._rename_field_sql(\n933                     model._meta.db_table, old_field, new_field, new_type\n934                 )\n935             )\n936             # Rename all references to the renamed column.\n937             for sql in self.deferred_sql:\n938                 if isinstance(sql, Statement):\n939                     sql.rename_column_references(\n940                         model._meta.db_table, old_field.column, new_field.column\n941                     )\n942         # Next, start accumulating actions to do\n943         actions = []\n944         null_actions = []\n945         post_actions = []\n946         # Type suffix change? (e.g. auto increment).\n947         old_type_suffix = old_field.db_type_suffix(connection=self.connection)\n948         new_type_suffix = new_field.db_type_suffix(connection=self.connection)\n949         # Collation change?\n950         if old_collation != new_collation:\n951             # Collation change handles also a type change.\n952             fragment = self._alter_column_collation_sql(\n953                 model, new_field, new_type, new_collation\n954             )\n955             actions.append(fragment)\n956         # Type change?\n957         elif (old_type, old_type_suffix) != (new_type, new_type_suffix):\n958             fragment, other_actions = self._alter_column_type_sql(\n959                 model, old_field, new_field, new_type\n960             )\n961             actions.append(fragment)\n962             post_actions.extend(other_actions)\n963         # When changing a column NULL constraint to NOT NULL with a given\n964         # default value, we need to perform 4 steps:\n965         #  1. Add a default for new incoming writes\n966         #  2. Update existing NULL rows with new default\n967         #  3. Replace NULL constraint with NOT NULL\n968         #  4. Drop the default again.\n969         # Default change?\n970         needs_database_default = False\n971         if old_field.null and not new_field.null:\n972             old_default = self.effective_default(old_field)\n973             new_default = self.effective_default(new_field)\n974             if (\n975                 not self.skip_default_on_alter(new_field)\n976                 and old_default != new_default\n977                 and new_default is not None\n978             ):\n979                 needs_database_default = True\n980                 actions.append(\n981                     self._alter_column_default_sql(model, old_field, new_field)\n982                 )\n983         # Nullability change?\n984         if old_field.null != new_field.null:\n985             fragment = self._alter_column_null_sql(model, old_field, new_field)\n986             if fragment:\n987                 null_actions.append(fragment)\n988         # Only if we have a default and there is a change from NULL to NOT NULL\n989         four_way_default_alteration = new_field.has_default() and (\n990             old_field.null and not new_field.null\n991         )\n992         if actions or null_actions:\n993             if not four_way_default_alteration:\n994                 # If we don't have to do a 4-way default alteration we can\n995                 # directly run a (NOT) NULL alteration\n996                 actions = actions + null_actions\n997             # Combine actions together if we can (e.g. postgres)\n998             if self.connection.features.supports_combined_alters and actions:\n999                 sql, params = tuple(zip(*actions))\n1000                 actions = [(\", \".join(sql), sum(params, []))]\n1001             # Apply those actions\n1002             for sql, params in actions:\n1003                 self.execute(\n1004                     self.sql_alter_column\n1005                     % {\n1006                         \"table\": self.quote_name(model._meta.db_table),\n1007                         \"changes\": sql,\n1008                     },\n1009                     params,\n1010                 )\n1011             if four_way_default_alteration:\n1012                 # Update existing rows with default value\n1013                 self.execute(\n1014                     self.sql_update_with_default\n1015                     % {\n1016                         \"table\": self.quote_name(model._meta.db_table),\n1017                         \"column\": self.quote_name(new_field.column),\n1018                         \"default\": \"%s\",\n1019                     },\n1020                     [new_default],\n1021                 )\n1022                 # Since we didn't run a NOT NULL change before we need to do it\n1023                 # now\n1024                 for sql, params in null_actions:\n1025                     self.execute(\n1026                         self.sql_alter_column\n1027                         % {\n1028                             \"table\": self.quote_name(model._meta.db_table),\n1029                             \"changes\": sql,\n1030                         },\n1031                         params,\n1032                     )\n1033         if post_actions:\n1034             for sql, params in post_actions:\n1035                 self.execute(sql, params)\n1036         # If primary_key changed to False, delete the primary key constraint.\n1037         if old_field.primary_key and not new_field.primary_key:\n1038             self._delete_primary_key(model, strict)\n1039         # Added a unique?\n1040         if self._unique_should_be_added(old_field, new_field):\n1041             self.execute(self._create_unique_sql(model, [new_field]))\n1042         # Added an index? Add an index if db_index switched to True or a unique\n1043         # constraint will no longer be used in lieu of an index. The following\n1044         # lines from the truth table show all True cases; the rest are False:\n1045         #\n1046         # old_field.db_index | old_field.unique | new_field.db_index | new_field.unique\n1047         # ------------------------------------------------------------------------------\n1048         # False              | False            | True               | False\n1049         # False              | True             | True               | False\n1050         # True               | True             | True               | False\n1051         if (\n1052             (not old_field.db_index or old_field.unique)\n1053             and new_field.db_index\n1054             and not new_field.unique\n1055         ):\n1056             self.execute(self._create_index_sql(model, fields=[new_field]))\n1057         # Type alteration on primary key? Then we need to alter the column\n1058         # referring to us.\n1059         rels_to_update = []\n1060         if drop_foreign_keys:\n1061             rels_to_update.extend(_related_non_m2m_objects(old_field, new_field))\n1062         # Changed to become primary key?\n1063         if self._field_became_primary_key(old_field, new_field):\n1064             # Make the new one\n1065             self.execute(self._create_primary_key_sql(model, new_field))\n1066             # Update all referencing columns\n1067             rels_to_update.extend(_related_non_m2m_objects(old_field, new_field))\n1068         # Handle our type alters on the other end of rels from the PK stuff above\n1069         for old_rel, new_rel in rels_to_update:\n1070             rel_db_params = new_rel.field.db_parameters(connection=self.connection)\n1071             rel_type = rel_db_params[\"type\"]\n1072             rel_collation = rel_db_params.get(\"collation\")\n1073             old_rel_db_params = old_rel.field.db_parameters(connection=self.connection)\n1074             old_rel_collation = old_rel_db_params.get(\"collation\")\n1075             if old_rel_collation != rel_collation:\n1076                 # Collation change handles also a type change.\n1077                 fragment = self._alter_column_collation_sql(\n1078                     new_rel.related_model,\n1079                     new_rel.field,\n1080                     rel_type,\n1081                     rel_collation,\n1082                 )\n1083                 other_actions = []\n1084             else:\n1085                 fragment, other_actions = self._alter_column_type_sql(\n1086                     new_rel.related_model, old_rel.field, new_rel.field, rel_type\n1087                 )\n1088             self.execute(\n1089                 self.sql_alter_column\n1090                 % {\n1091                     \"table\": self.quote_name(new_rel.related_model._meta.db_table),\n1092                     \"changes\": fragment[0],\n1093                 },\n1094                 fragment[1],\n1095             )\n1096             for sql, params in other_actions:\n1097                 self.execute(sql, params)\n1098         # Does it have a foreign key?\n1099         if (\n1100             self.connection.features.supports_foreign_keys\n1101             and new_field.remote_field\n1102             and (\n1103                 fks_dropped or not old_field.remote_field or not old_field.db_constraint\n1104             )\n1105             and new_field.db_constraint\n1106         ):\n1107             self.execute(\n1108                 self._create_fk_sql(model, new_field, \"_fk_%(to_table)s_%(to_column)s\")\n1109             )\n1110         # Rebuild FKs that pointed to us if we previously had to drop them\n1111         if drop_foreign_keys:\n1112             for _, rel in rels_to_update:\n1113                 if rel.field.db_constraint:\n1114                     self.execute(\n1115                         self._create_fk_sql(rel.related_model, rel.field, \"_fk\")\n1116                     )\n1117         # Does it have check constraints we need to add?\n1118         if old_db_params[\"check\"] != new_db_params[\"check\"] and new_db_params[\"check\"]:\n1119             constraint_name = self._create_index_name(\n1120                 model._meta.db_table, [new_field.column], suffix=\"_check\"\n1121             )\n1122             self.execute(\n1123                 self._create_check_sql(model, constraint_name, new_db_params[\"check\"])\n1124             )\n1125         # Drop the default if we need to\n1126         # (Django usually does not use in-database defaults)\n1127         if needs_database_default:\n1128             changes_sql, params = self._alter_column_default_sql(\n1129                 model, old_field, new_field, drop=True\n1130             )\n1131             sql = self.sql_alter_column % {\n1132                 \"table\": self.quote_name(model._meta.db_table),\n1133                 \"changes\": changes_sql,\n1134             }\n1135             self.execute(sql, params)\n1136         # Reset connection if required\n1137         if self.connection.features.connection_persists_old_columns:\n1138             self.connection.close()\n1139 \n1140     def _alter_column_null_sql(self, model, old_field, new_field):\n1141         \"\"\"\n1142         Hook to specialize column null alteration.\n1143 \n1144         Return a (sql, params) fragment to set a column to null or non-null\n1145         as required by new_field, or None if no changes are required.\n1146         \"\"\"\n1147         if (\n1148             self.connection.features.interprets_empty_strings_as_nulls\n1149             and new_field.empty_strings_allowed\n1150         ):\n1151             # The field is nullable in the database anyway, leave it alone.\n1152             return\n1153         else:\n1154             new_db_params = new_field.db_parameters(connection=self.connection)\n1155             sql = (\n1156                 self.sql_alter_column_null\n1157                 if new_field.null\n1158                 else self.sql_alter_column_not_null\n1159             )\n1160             return (\n1161                 sql\n1162                 % {\n1163                     \"column\": self.quote_name(new_field.column),\n1164                     \"type\": new_db_params[\"type\"],\n1165                 },\n1166                 [],\n1167             )\n1168 \n1169     def _alter_column_default_sql(self, model, old_field, new_field, drop=False):\n1170         \"\"\"\n1171         Hook to specialize column default alteration.\n1172 \n1173         Return a (sql, params) fragment to add or drop (depending on the drop\n1174         argument) a default to new_field's column.\n1175         \"\"\"\n1176         new_default = self.effective_default(new_field)\n1177         default = self._column_default_sql(new_field)\n1178         params = [new_default]\n1179 \n1180         if drop:\n1181             params = []\n1182         elif self.connection.features.requires_literal_defaults:\n1183             # Some databases (Oracle) can't take defaults as a parameter\n1184             # If this is the case, the SchemaEditor for that database should\n1185             # implement prepare_default().\n1186             default = self.prepare_default(new_default)\n1187             params = []\n1188 \n1189         new_db_params = new_field.db_parameters(connection=self.connection)\n1190         if drop:\n1191             if new_field.null:\n1192                 sql = self.sql_alter_column_no_default_null\n1193             else:\n1194                 sql = self.sql_alter_column_no_default\n1195         else:\n1196             sql = self.sql_alter_column_default\n1197         return (\n1198             sql\n1199             % {\n1200                 \"column\": self.quote_name(new_field.column),\n1201                 \"type\": new_db_params[\"type\"],\n1202                 \"default\": default,\n1203             },\n1204             params,\n1205         )\n1206 \n1207     def _alter_column_type_sql(self, model, old_field, new_field, new_type):\n1208         \"\"\"\n1209         Hook to specialize column type alteration for different backends,\n1210         for cases when a creation type is different to an alteration type\n1211         (e.g. SERIAL in PostgreSQL, PostGIS fields).\n1212 \n1213         Return a two-tuple of: an SQL fragment of (sql, params) to insert into\n1214         an ALTER TABLE statement and a list of extra (sql, params) tuples to\n1215         run once the field is altered.\n1216         \"\"\"\n1217         return (\n1218             (\n1219                 self.sql_alter_column_type\n1220                 % {\n1221                     \"column\": self.quote_name(new_field.column),\n1222                     \"type\": new_type,\n1223                 },\n1224                 [],\n1225             ),\n1226             [],\n1227         )\n1228 \n1229     def _alter_column_collation_sql(self, model, new_field, new_type, new_collation):\n1230         return (\n1231             self.sql_alter_column_collate\n1232             % {\n1233                 \"column\": self.quote_name(new_field.column),\n1234                 \"type\": new_type,\n1235                 \"collation\": \" \" + self._collate_sql(new_collation)\n1236                 if new_collation\n1237                 else \"\",\n1238             },\n1239             [],\n1240         )\n1241 \n1242     def _alter_many_to_many(self, model, old_field, new_field, strict):\n1243         \"\"\"Alter M2Ms to repoint their to= endpoints.\"\"\"\n1244         # Rename the through table\n1245         if (\n1246             old_field.remote_field.through._meta.db_table\n1247             != new_field.remote_field.through._meta.db_table\n1248         ):\n1249             self.alter_db_table(\n1250                 old_field.remote_field.through,\n1251                 old_field.remote_field.through._meta.db_table,\n1252                 new_field.remote_field.through._meta.db_table,\n1253             )\n1254         # Repoint the FK to the other side\n1255         self.alter_field(\n1256             new_field.remote_field.through,\n1257             # The field that points to the target model is needed, so we can\n1258             # tell alter_field to change it - this is m2m_reverse_field_name()\n1259             # (as opposed to m2m_field_name(), which points to our model).\n1260             old_field.remote_field.through._meta.get_field(\n1261                 old_field.m2m_reverse_field_name()\n1262             ),\n1263             new_field.remote_field.through._meta.get_field(\n1264                 new_field.m2m_reverse_field_name()\n1265             ),\n1266         )\n1267         self.alter_field(\n1268             new_field.remote_field.through,\n1269             # for self-referential models we need to alter field from the other end too\n1270             old_field.remote_field.through._meta.get_field(old_field.m2m_field_name()),\n1271             new_field.remote_field.through._meta.get_field(new_field.m2m_field_name()),\n1272         )\n1273 \n1274     def _create_index_name(self, table_name, column_names, suffix=\"\"):\n1275         \"\"\"\n1276         Generate a unique name for an index/unique constraint.\n1277 \n1278         The name is divided into 3 parts: the table name, the column names,\n1279         and a unique digest and suffix.\n1280         \"\"\"\n1281         _, table_name = split_identifier(table_name)\n1282         hash_suffix_part = \"%s%s\" % (\n1283             names_digest(table_name, *column_names, length=8),\n1284             suffix,\n1285         )\n1286         max_length = self.connection.ops.max_name_length() or 200\n1287         # If everything fits into max_length, use that name.\n1288         index_name = \"%s_%s_%s\" % (table_name, \"_\".join(column_names), hash_suffix_part)\n1289         if len(index_name) <= max_length:\n1290             return index_name\n1291         # Shorten a long suffix.\n1292         if len(hash_suffix_part) > max_length / 3:\n1293             hash_suffix_part = hash_suffix_part[: max_length // 3]\n1294         other_length = (max_length - len(hash_suffix_part)) // 2 - 1\n1295         index_name = \"%s_%s_%s\" % (\n1296             table_name[:other_length],\n1297             \"_\".join(column_names)[:other_length],\n1298             hash_suffix_part,\n1299         )\n1300         # Prepend D if needed to prevent the name from starting with an\n1301         # underscore or a number (not permitted on Oracle).\n1302         if index_name[0] == \"_\" or index_name[0].isdigit():\n1303             index_name = \"D%s\" % index_name[:-1]\n1304         return index_name\n1305 \n1306     def _get_index_tablespace_sql(self, model, fields, db_tablespace=None):\n1307         if db_tablespace is None:\n1308             if len(fields) == 1 and fields[0].db_tablespace:\n1309                 db_tablespace = fields[0].db_tablespace\n1310             elif settings.DEFAULT_INDEX_TABLESPACE:\n1311                 db_tablespace = settings.DEFAULT_INDEX_TABLESPACE\n1312             elif model._meta.db_tablespace:\n1313                 db_tablespace = model._meta.db_tablespace\n1314         if db_tablespace is not None:\n1315             return \" \" + self.connection.ops.tablespace_sql(db_tablespace)\n1316         return \"\"\n1317 \n1318     def _index_condition_sql(self, condition):\n1319         if condition:\n1320             return \" WHERE \" + condition\n1321         return \"\"\n1322 \n1323     def _index_include_sql(self, model, columns):\n1324         if not columns or not self.connection.features.supports_covering_indexes:\n1325             return \"\"\n1326         return Statement(\n1327             \" INCLUDE (%(columns)s)\",\n1328             columns=Columns(model._meta.db_table, columns, self.quote_name),\n1329         )\n1330 \n1331     def _create_index_sql(\n1332         self,\n1333         model,\n1334         *,\n1335         fields=None,\n1336         name=None,\n1337         suffix=\"\",\n1338         using=\"\",\n1339         db_tablespace=None,\n1340         col_suffixes=(),\n1341         sql=None,\n1342         opclasses=(),\n1343         condition=None,\n1344         include=None,\n1345         expressions=None,\n1346     ):\n1347         \"\"\"\n1348         Return the SQL statement to create the index for one or several fields\n1349         or expressions. `sql` can be specified if the syntax differs from the\n1350         standard (GIS indexes, ...).\n1351         \"\"\"\n1352         fields = fields or []\n1353         expressions = expressions or []\n1354         compiler = Query(model, alias_cols=False).get_compiler(\n1355             connection=self.connection,\n1356         )\n1357         tablespace_sql = self._get_index_tablespace_sql(\n1358             model, fields, db_tablespace=db_tablespace\n1359         )\n1360         columns = [field.column for field in fields]\n1361         sql_create_index = sql or self.sql_create_index\n1362         table = model._meta.db_table\n1363 \n1364         def create_index_name(*args, **kwargs):\n1365             nonlocal name\n1366             if name is None:\n1367                 name = self._create_index_name(*args, **kwargs)\n1368             return self.quote_name(name)\n1369 \n1370         return Statement(\n1371             sql_create_index,\n1372             table=Table(table, self.quote_name),\n1373             name=IndexName(table, columns, suffix, create_index_name),\n1374             using=using,\n1375             columns=(\n1376                 self._index_columns(table, columns, col_suffixes, opclasses)\n1377                 if columns\n1378                 else Expressions(table, expressions, compiler, self.quote_value)\n1379             ),\n1380             extra=tablespace_sql,\n1381             condition=self._index_condition_sql(condition),\n1382             include=self._index_include_sql(model, include),\n1383         )\n1384 \n1385     def _delete_index_sql(self, model, name, sql=None):\n1386         return Statement(\n1387             sql or self.sql_delete_index,\n1388             table=Table(model._meta.db_table, self.quote_name),\n1389             name=self.quote_name(name),\n1390         )\n1391 \n1392     def _rename_index_sql(self, model, old_name, new_name):\n1393         return Statement(\n1394             self.sql_rename_index,\n1395             table=Table(model._meta.db_table, self.quote_name),\n1396             old_name=self.quote_name(old_name),\n1397             new_name=self.quote_name(new_name),\n1398         )\n1399 \n1400     def _index_columns(self, table, columns, col_suffixes, opclasses):\n1401         return Columns(table, columns, self.quote_name, col_suffixes=col_suffixes)\n1402 \n1403     def _model_indexes_sql(self, model):\n1404         \"\"\"\n1405         Return a list of all index SQL statements (field indexes,\n1406         index_together, Meta.indexes) for the specified model.\n1407         \"\"\"\n1408         if not model._meta.managed or model._meta.proxy or model._meta.swapped:\n1409             return []\n1410         output = []\n1411         for field in model._meta.local_fields:\n1412             output.extend(self._field_indexes_sql(model, field))\n1413 \n1414         for field_names in model._meta.index_together:\n1415             fields = [model._meta.get_field(field) for field in field_names]\n1416             output.append(self._create_index_sql(model, fields=fields, suffix=\"_idx\"))\n1417 \n1418         for index in model._meta.indexes:\n1419             if (\n1420                 not index.contains_expressions\n1421                 or self.connection.features.supports_expression_indexes\n1422             ):\n1423                 output.append(index.create_sql(model, self))\n1424         return output\n1425 \n1426     def _field_indexes_sql(self, model, field):\n1427         \"\"\"\n1428         Return a list of all index SQL statements for the specified field.\n1429         \"\"\"\n1430         output = []\n1431         if self._field_should_be_indexed(model, field):\n1432             output.append(self._create_index_sql(model, fields=[field]))\n1433         return output\n1434 \n1435     def _field_should_be_altered(self, old_field, new_field):\n1436         _, old_path, old_args, old_kwargs = old_field.deconstruct()\n1437         _, new_path, new_args, new_kwargs = new_field.deconstruct()\n1438         # Don't alter when:\n1439         # - changing only a field name\n1440         # - changing an attribute that doesn't affect the schema\n1441         # - adding only a db_column and the column name is not changed\n1442         for attr in old_field.non_db_attrs:\n1443             old_kwargs.pop(attr, None)\n1444         for attr in new_field.non_db_attrs:\n1445             new_kwargs.pop(attr, None)\n1446         return self.quote_name(old_field.column) != self.quote_name(\n1447             new_field.column\n1448         ) or (old_path, old_args, old_kwargs) != (new_path, new_args, new_kwargs)\n1449 \n1450     def _field_should_be_indexed(self, model, field):\n1451         return field.db_index and not field.unique\n1452 \n1453     def _field_became_primary_key(self, old_field, new_field):\n1454         return not old_field.primary_key and new_field.primary_key\n1455 \n1456     def _unique_should_be_added(self, old_field, new_field):\n1457         return (\n1458             not new_field.primary_key\n1459             and new_field.unique\n1460             and (not old_field.unique or old_field.primary_key)\n1461         )\n1462 \n1463     def _rename_field_sql(self, table, old_field, new_field, new_type):\n1464         return self.sql_rename_column % {\n1465             \"table\": self.quote_name(table),\n1466             \"old_column\": self.quote_name(old_field.column),\n1467             \"new_column\": self.quote_name(new_field.column),\n1468             \"type\": new_type,\n1469         }\n1470 \n1471     def _create_fk_sql(self, model, field, suffix):\n1472         table = Table(model._meta.db_table, self.quote_name)\n1473         name = self._fk_constraint_name(model, field, suffix)\n1474         column = Columns(model._meta.db_table, [field.column], self.quote_name)\n1475         to_table = Table(field.target_field.model._meta.db_table, self.quote_name)\n1476         to_column = Columns(\n1477             field.target_field.model._meta.db_table,\n1478             [field.target_field.column],\n1479             self.quote_name,\n1480         )\n1481         deferrable = self.connection.ops.deferrable_sql()\n1482         return Statement(\n1483             self.sql_create_fk,\n1484             table=table,\n1485             name=name,\n1486             column=column,\n1487             to_table=to_table,\n1488             to_column=to_column,\n1489             deferrable=deferrable,\n1490         )\n1491 \n1492     def _fk_constraint_name(self, model, field, suffix):\n1493         def create_fk_name(*args, **kwargs):\n1494             return self.quote_name(self._create_index_name(*args, **kwargs))\n1495 \n1496         return ForeignKeyName(\n1497             model._meta.db_table,\n1498             [field.column],\n1499             split_identifier(field.target_field.model._meta.db_table)[1],\n1500             [field.target_field.column],\n1501             suffix,\n1502             create_fk_name,\n1503         )\n1504 \n1505     def _delete_fk_sql(self, model, name):\n1506         return self._delete_constraint_sql(self.sql_delete_fk, model, name)\n1507 \n1508     def _deferrable_constraint_sql(self, deferrable):\n1509         if deferrable is None:\n1510             return \"\"\n1511         if deferrable == Deferrable.DEFERRED:\n1512             return \" DEFERRABLE INITIALLY DEFERRED\"\n1513         if deferrable == Deferrable.IMMEDIATE:\n1514             return \" DEFERRABLE INITIALLY IMMEDIATE\"\n1515 \n1516     def _unique_sql(\n1517         self,\n1518         model,\n1519         fields,\n1520         name,\n1521         condition=None,\n1522         deferrable=None,\n1523         include=None,\n1524         opclasses=None,\n1525         expressions=None,\n1526     ):\n1527         if (\n1528             deferrable\n1529             and not self.connection.features.supports_deferrable_unique_constraints\n1530         ):\n1531             return None\n1532         if condition or include or opclasses or expressions:\n1533             # Databases support conditional, covering, and functional unique\n1534             # constraints via a unique index.\n1535             sql = self._create_unique_sql(\n1536                 model,\n1537                 fields,\n1538                 name=name,\n1539                 condition=condition,\n1540                 include=include,\n1541                 opclasses=opclasses,\n1542                 expressions=expressions,\n1543             )\n1544             if sql:\n1545                 self.deferred_sql.append(sql)\n1546             return None\n1547         constraint = self.sql_unique_constraint % {\n1548             \"columns\": \", \".join([self.quote_name(field.column) for field in fields]),\n1549             \"deferrable\": self._deferrable_constraint_sql(deferrable),\n1550         }\n1551         return self.sql_constraint % {\n1552             \"name\": self.quote_name(name),\n1553             \"constraint\": constraint,\n1554         }\n1555 \n1556     def _create_unique_sql(\n1557         self,\n1558         model,\n1559         fields,\n1560         name=None,\n1561         condition=None,\n1562         deferrable=None,\n1563         include=None,\n1564         opclasses=None,\n1565         expressions=None,\n1566     ):\n1567         if (\n1568             (\n1569                 deferrable\n1570                 and not self.connection.features.supports_deferrable_unique_constraints\n1571             )\n1572             or (condition and not self.connection.features.supports_partial_indexes)\n1573             or (include and not self.connection.features.supports_covering_indexes)\n1574             or (\n1575                 expressions and not self.connection.features.supports_expression_indexes\n1576             )\n1577         ):\n1578             return None\n1579 \n1580         compiler = Query(model, alias_cols=False).get_compiler(\n1581             connection=self.connection\n1582         )\n1583         table = model._meta.db_table\n1584         columns = [field.column for field in fields]\n1585         if name is None:\n1586             name = self._unique_constraint_name(table, columns, quote=True)\n1587         else:\n1588             name = self.quote_name(name)\n1589         if condition or include or opclasses or expressions:\n1590             sql = self.sql_create_unique_index\n1591         else:\n1592             sql = self.sql_create_unique\n1593         if columns:\n1594             columns = self._index_columns(\n1595                 table, columns, col_suffixes=(), opclasses=opclasses\n1596             )\n1597         else:\n1598             columns = Expressions(table, expressions, compiler, self.quote_value)\n1599         return Statement(\n1600             sql,\n1601             table=Table(table, self.quote_name),\n1602             name=name,\n1603             columns=columns,\n1604             condition=self._index_condition_sql(condition),\n1605             deferrable=self._deferrable_constraint_sql(deferrable),\n1606             include=self._index_include_sql(model, include),\n1607         )\n1608 \n1609     def _unique_constraint_name(self, table, columns, quote=True):\n1610         if quote:\n1611 \n1612             def create_unique_name(*args, **kwargs):\n1613                 return self.quote_name(self._create_index_name(*args, **kwargs))\n1614 \n1615         else:\n1616             create_unique_name = self._create_index_name\n1617 \n1618         return IndexName(table, columns, \"_uniq\", create_unique_name)\n1619 \n1620     def _delete_unique_sql(\n1621         self,\n1622         model,\n1623         name,\n1624         condition=None,\n1625         deferrable=None,\n1626         include=None,\n1627         opclasses=None,\n1628         expressions=None,\n1629     ):\n1630         if (\n1631             (\n1632                 deferrable\n1633                 and not self.connection.features.supports_deferrable_unique_constraints\n1634             )\n1635             or (condition and not self.connection.features.supports_partial_indexes)\n1636             or (include and not self.connection.features.supports_covering_indexes)\n1637             or (\n1638                 expressions and not self.connection.features.supports_expression_indexes\n1639             )\n1640         ):\n1641             return None\n1642         if condition or include or opclasses or expressions:\n1643             sql = self.sql_delete_index\n1644         else:\n1645             sql = self.sql_delete_unique\n1646         return self._delete_constraint_sql(sql, model, name)\n1647 \n1648     def _check_sql(self, name, check):\n1649         return self.sql_constraint % {\n1650             \"name\": self.quote_name(name),\n1651             \"constraint\": self.sql_check_constraint % {\"check\": check},\n1652         }\n1653 \n1654     def _create_check_sql(self, model, name, check):\n1655         return Statement(\n1656             self.sql_create_check,\n1657             table=Table(model._meta.db_table, self.quote_name),\n1658             name=self.quote_name(name),\n1659             check=check,\n1660         )\n1661 \n1662     def _delete_check_sql(self, model, name):\n1663         return self._delete_constraint_sql(self.sql_delete_check, model, name)\n1664 \n1665     def _delete_constraint_sql(self, template, model, name):\n1666         return Statement(\n1667             template,\n1668             table=Table(model._meta.db_table, self.quote_name),\n1669             name=self.quote_name(name),\n1670         )\n1671 \n1672     def _constraint_names(\n1673         self,\n1674         model,\n1675         column_names=None,\n1676         unique=None,\n1677         primary_key=None,\n1678         index=None,\n1679         foreign_key=None,\n1680         check=None,\n1681         type_=None,\n1682         exclude=None,\n1683     ):\n1684         \"\"\"Return all constraint names matching the columns and conditions.\"\"\"\n1685         if column_names is not None:\n1686             column_names = [\n1687                 self.connection.introspection.identifier_converter(name)\n1688                 for name in column_names\n1689             ]\n1690         with self.connection.cursor() as cursor:\n1691             constraints = self.connection.introspection.get_constraints(\n1692                 cursor, model._meta.db_table\n1693             )\n1694         result = []\n1695         for name, infodict in constraints.items():\n1696             if column_names is None or column_names == infodict[\"columns\"]:\n1697                 if unique is not None and infodict[\"unique\"] != unique:\n1698                     continue\n1699                 if primary_key is not None and infodict[\"primary_key\"] != primary_key:\n1700                     continue\n1701                 if index is not None and infodict[\"index\"] != index:\n1702                     continue\n1703                 if check is not None and infodict[\"check\"] != check:\n1704                     continue\n1705                 if foreign_key is not None and not infodict[\"foreign_key\"]:\n1706                     continue\n1707                 if type_ is not None and infodict[\"type\"] != type_:\n1708                     continue\n1709                 if not exclude or name not in exclude:\n1710                     result.append(name)\n1711         return result\n1712 \n1713     def _delete_primary_key(self, model, strict=False):\n1714         constraint_names = self._constraint_names(model, primary_key=True)\n1715         if strict and len(constraint_names) != 1:\n1716             raise ValueError(\n1717                 \"Found wrong number (%s) of PK constraints for %s\"\n1718                 % (\n1719                     len(constraint_names),\n1720                     model._meta.db_table,\n1721                 )\n1722             )\n1723         for constraint_name in constraint_names:\n1724             self.execute(self._delete_primary_key_sql(model, constraint_name))\n1725 \n1726     def _create_primary_key_sql(self, model, field):\n1727         return Statement(\n1728             self.sql_create_pk,\n1729             table=Table(model._meta.db_table, self.quote_name),\n1730             name=self.quote_name(\n1731                 self._create_index_name(\n1732                     model._meta.db_table, [field.column], suffix=\"_pk\"\n1733                 )\n1734             ),\n1735             columns=Columns(model._meta.db_table, [field.column], self.quote_name),\n1736         )\n1737 \n1738     def _delete_primary_key_sql(self, model, name):\n1739         return self._delete_constraint_sql(self.sql_delete_pk, model, name)\n1740 \n1741     def _collate_sql(self, collation):\n1742         return \"COLLATE \" + self.quote_name(collation)\n1743 \n1744     def remove_procedure(self, procedure_name, param_types=()):\n1745         sql = self.sql_delete_procedure % {\n1746             \"procedure\": self.quote_name(procedure_name),\n1747             \"param_types\": \",\".join(param_types),\n1748         }\n1749         self.execute(sql)\n",
        "intended_behavior": "Ensure schema generation logic translates `indexes` attributes into correct SQL statements, maintaining functionality equivalence with `index_together`."
    },
    {
        "rel_file_path": "django/db/backends/sqlite3/schema.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__4.2/django/db/backends/sqlite3/schema.py",
        "start": 1,
        "end": 559,
        "class_name": null,
        "method_name": null,
        "code": "1 import copy\n2 from decimal import Decimal\n3 \n4 from django.apps.registry import Apps\n5 from django.db import NotSupportedError\n6 from django.db.backends.base.schema import BaseDatabaseSchemaEditor\n7 from django.db.backends.ddl_references import Statement\n8 from django.db.backends.utils import strip_quotes\n9 from django.db.models import UniqueConstraint\n10 from django.db.transaction import atomic\n11 \n12 \n13 class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n14 \n15     sql_delete_table = \"DROP TABLE %(table)s\"\n16     sql_create_fk = None\n17     sql_create_inline_fk = (\n18         \"REFERENCES %(to_table)s (%(to_column)s) DEFERRABLE INITIALLY DEFERRED\"\n19     )\n20     sql_create_column_inline_fk = sql_create_inline_fk\n21     sql_delete_column = \"ALTER TABLE %(table)s DROP COLUMN %(column)s\"\n22     sql_create_unique = \"CREATE UNIQUE INDEX %(name)s ON %(table)s (%(columns)s)\"\n23     sql_delete_unique = \"DROP INDEX %(name)s\"\n24 \n25     def __enter__(self):\n26         # Some SQLite schema alterations need foreign key constraints to be\n27         # disabled. Enforce it here for the duration of the schema edition.\n28         if not self.connection.disable_constraint_checking():\n29             raise NotSupportedError(\n30                 \"SQLite schema editor cannot be used while foreign key \"\n31                 \"constraint checks are enabled. Make sure to disable them \"\n32                 \"before entering a transaction.atomic() context because \"\n33                 \"SQLite does not support disabling them in the middle of \"\n34                 \"a multi-statement transaction.\"\n35             )\n36         return super().__enter__()\n37 \n38     def __exit__(self, exc_type, exc_value, traceback):\n39         self.connection.check_constraints()\n40         super().__exit__(exc_type, exc_value, traceback)\n41         self.connection.enable_constraint_checking()\n42 \n43     def quote_value(self, value):\n44         # The backend \"mostly works\" without this function and there are use\n45         # cases for compiling Python without the sqlite3 libraries (e.g.\n46         # security hardening).\n47         try:\n48             import sqlite3\n49 \n50             value = sqlite3.adapt(value)\n51         except ImportError:\n52             pass\n53         except sqlite3.ProgrammingError:\n54             pass\n55         # Manual emulation of SQLite parameter quoting\n56         if isinstance(value, bool):\n57             return str(int(value))\n58         elif isinstance(value, (Decimal, float, int)):\n59             return str(value)\n60         elif isinstance(value, str):\n61             return \"'%s'\" % value.replace(\"'\", \"''\")\n62         elif value is None:\n63             return \"NULL\"\n64         elif isinstance(value, (bytes, bytearray, memoryview)):\n65             # Bytes are only allowed for BLOB fields, encoded as string\n66             # literals containing hexadecimal data and preceded by a single \"X\"\n67             # character.\n68             return \"X'%s'\" % value.hex()\n69         else:\n70             raise ValueError(\n71                 \"Cannot quote parameter value %r of type %s\" % (value, type(value))\n72             )\n73 \n74     def prepare_default(self, value):\n75         return self.quote_value(value)\n76 \n77     def _is_referenced_by_fk_constraint(\n78         self, table_name, column_name=None, ignore_self=False\n79     ):\n80         \"\"\"\n81         Return whether or not the provided table name is referenced by another\n82         one. If `column_name` is specified, only references pointing to that\n83         column are considered. If `ignore_self` is True, self-referential\n84         constraints are ignored.\n85         \"\"\"\n86         with self.connection.cursor() as cursor:\n87             for other_table in self.connection.introspection.get_table_list(cursor):\n88                 if ignore_self and other_table.name == table_name:\n89                     continue\n90                 relations = self.connection.introspection.get_relations(\n91                     cursor, other_table.name\n92                 )\n93                 for constraint_column, constraint_table in relations.values():\n94                     if constraint_table == table_name and (\n95                         column_name is None or constraint_column == column_name\n96                     ):\n97                         return True\n98         return False\n99 \n100     def alter_db_table(\n101         self, model, old_db_table, new_db_table, disable_constraints=True\n102     ):\n103         if (\n104             not self.connection.features.supports_atomic_references_rename\n105             and disable_constraints\n106             and self._is_referenced_by_fk_constraint(old_db_table)\n107         ):\n108             if self.connection.in_atomic_block:\n109                 raise NotSupportedError(\n110                     (\n111                         \"Renaming the %r table while in a transaction is not \"\n112                         \"supported on SQLite < 3.26 because it would break referential \"\n113                         \"integrity. Try adding `atomic = False` to the Migration class.\"\n114                     )\n115                     % old_db_table\n116                 )\n117             self.connection.enable_constraint_checking()\n118             super().alter_db_table(model, old_db_table, new_db_table)\n119             self.connection.disable_constraint_checking()\n120         else:\n121             super().alter_db_table(model, old_db_table, new_db_table)\n122 \n123     def alter_field(self, model, old_field, new_field, strict=False):\n124         if not self._field_should_be_altered(old_field, new_field):\n125             return\n126         old_field_name = old_field.name\n127         table_name = model._meta.db_table\n128         _, old_column_name = old_field.get_attname_column()\n129         if (\n130             new_field.name != old_field_name\n131             and not self.connection.features.supports_atomic_references_rename\n132             and self._is_referenced_by_fk_constraint(\n133                 table_name, old_column_name, ignore_self=True\n134             )\n135         ):\n136             if self.connection.in_atomic_block:\n137                 raise NotSupportedError(\n138                     (\n139                         \"Renaming the %r.%r column while in a transaction is not \"\n140                         \"supported on SQLite < 3.26 because it would break referential \"\n141                         \"integrity. Try adding `atomic = False` to the Migration class.\"\n142                     )\n143                     % (model._meta.db_table, old_field_name)\n144                 )\n145             with atomic(self.connection.alias):\n146                 super().alter_field(model, old_field, new_field, strict=strict)\n147                 # Follow SQLite's documented procedure for performing changes\n148                 # that don't affect the on-disk content.\n149                 # https://sqlite.org/lang_altertable.html#otheralter\n150                 with self.connection.cursor() as cursor:\n151                     schema_version = cursor.execute(\"PRAGMA schema_version\").fetchone()[\n152                         0\n153                     ]\n154                     cursor.execute(\"PRAGMA writable_schema = 1\")\n155                     references_template = ' REFERENCES \"%s\" (\"%%s\") ' % table_name\n156                     new_column_name = new_field.get_attname_column()[1]\n157                     search = references_template % old_column_name\n158                     replacement = references_template % new_column_name\n159                     cursor.execute(\n160                         \"UPDATE sqlite_master SET sql = replace(sql, %s, %s)\",\n161                         (search, replacement),\n162                     )\n163                     cursor.execute(\"PRAGMA schema_version = %d\" % (schema_version + 1))\n164                     cursor.execute(\"PRAGMA writable_schema = 0\")\n165                     # The integrity check will raise an exception and rollback\n166                     # the transaction if the sqlite_master updates corrupt the\n167                     # database.\n168                     cursor.execute(\"PRAGMA integrity_check\")\n169             # Perform a VACUUM to refresh the database representation from\n170             # the sqlite_master table.\n171             with self.connection.cursor() as cursor:\n172                 cursor.execute(\"VACUUM\")\n173         else:\n174             super().alter_field(model, old_field, new_field, strict=strict)\n175 \n176     def _remake_table(\n177         self, model, create_field=None, delete_field=None, alter_field=None\n178     ):\n179         \"\"\"\n180         Shortcut to transform a model from old_model into new_model\n181 \n182         This follows the correct procedure to perform non-rename or column\n183         addition operations based on SQLite's documentation\n184 \n185         https://www.sqlite.org/lang_altertable.html#caution\n186 \n187         The essential steps are:\n188           1. Create a table with the updated definition called \"new__app_model\"\n189           2. Copy the data from the existing \"app_model\" table to the new table\n190           3. Drop the \"app_model\" table\n191           4. Rename the \"new__app_model\" table to \"app_model\"\n192           5. Restore any index of the previous \"app_model\" table.\n193         \"\"\"\n194         # Self-referential fields must be recreated rather than copied from\n195         # the old model to ensure their remote_field.field_name doesn't refer\n196         # to an altered field.\n197         def is_self_referential(f):\n198             return f.is_relation and f.remote_field.model is model\n199 \n200         # Work out the new fields dict / mapping\n201         body = {\n202             f.name: f.clone() if is_self_referential(f) else f\n203             for f in model._meta.local_concrete_fields\n204         }\n205         # Since mapping might mix column names and default values,\n206         # its values must be already quoted.\n207         mapping = {\n208             f.column: self.quote_name(f.column)\n209             for f in model._meta.local_concrete_fields\n210         }\n211         # This maps field names (not columns) for things like unique_together\n212         rename_mapping = {}\n213         # If any of the new or altered fields is introducing a new PK,\n214         # remove the old one\n215         restore_pk_field = None\n216         if getattr(create_field, \"primary_key\", False) or (\n217             alter_field and getattr(alter_field[1], \"primary_key\", False)\n218         ):\n219             for name, field in list(body.items()):\n220                 if field.primary_key and not (\n221                     # Do not remove the old primary key when an altered field\n222                     # that introduces a primary key is the same field.\n223                     alter_field\n224                     and name == alter_field[1].name\n225                 ):\n226                     field.primary_key = False\n227                     restore_pk_field = field\n228                     if field.auto_created:\n229                         del body[name]\n230                         del mapping[field.column]\n231         # Add in any created fields\n232         if create_field:\n233             body[create_field.name] = create_field\n234             # Choose a default and insert it into the copy map\n235             if not create_field.many_to_many and create_field.concrete:\n236                 mapping[create_field.column] = self.prepare_default(\n237                     self.effective_default(create_field),\n238                 )\n239         # Add in any altered fields\n240         if alter_field:\n241             old_field, new_field = alter_field\n242             body.pop(old_field.name, None)\n243             mapping.pop(old_field.column, None)\n244             body[new_field.name] = new_field\n245             if old_field.null and not new_field.null:\n246                 case_sql = \"coalesce(%(col)s, %(default)s)\" % {\n247                     \"col\": self.quote_name(old_field.column),\n248                     \"default\": self.prepare_default(self.effective_default(new_field)),\n249                 }\n250                 mapping[new_field.column] = case_sql\n251             else:\n252                 mapping[new_field.column] = self.quote_name(old_field.column)\n253             rename_mapping[old_field.name] = new_field.name\n254         # Remove any deleted fields\n255         if delete_field:\n256             del body[delete_field.name]\n257             del mapping[delete_field.column]\n258             # Remove any implicit M2M tables\n259             if (\n260                 delete_field.many_to_many\n261                 and delete_field.remote_field.through._meta.auto_created\n262             ):\n263                 return self.delete_model(delete_field.remote_field.through)\n264         # Work inside a new app registry\n265         apps = Apps()\n266 \n267         # Work out the new value of unique_together, taking renames into\n268         # account\n269         unique_together = [\n270             [rename_mapping.get(n, n) for n in unique]\n271             for unique in model._meta.unique_together\n272         ]\n273 \n274         # Work out the new value for index_together, taking renames into\n275         # account\n276         index_together = [\n277             [rename_mapping.get(n, n) for n in index]\n278             for index in model._meta.index_together\n279         ]\n280 \n281         indexes = model._meta.indexes\n282         if delete_field:\n283             indexes = [\n284                 index for index in indexes if delete_field.name not in index.fields\n285             ]\n286 \n287         constraints = list(model._meta.constraints)\n288 \n289         # Provide isolated instances of the fields to the new model body so\n290         # that the existing model's internals aren't interfered with when\n291         # the dummy model is constructed.\n292         body_copy = copy.deepcopy(body)\n293 \n294         # Construct a new model with the new fields to allow self referential\n295         # primary key to resolve to. This model won't ever be materialized as a\n296         # table and solely exists for foreign key reference resolution purposes.\n297         # This wouldn't be required if the schema editor was operating on model\n298         # states instead of rendered models.\n299         meta_contents = {\n300             \"app_label\": model._meta.app_label,\n301             \"db_table\": model._meta.db_table,\n302             \"unique_together\": unique_together,\n303             \"index_together\": index_together,\n304             \"indexes\": indexes,\n305             \"constraints\": constraints,\n306             \"apps\": apps,\n307         }\n308         meta = type(\"Meta\", (), meta_contents)\n309         body_copy[\"Meta\"] = meta\n310         body_copy[\"__module__\"] = model.__module__\n311         type(model._meta.object_name, model.__bases__, body_copy)\n312 \n313         # Construct a model with a renamed table name.\n314         body_copy = copy.deepcopy(body)\n315         meta_contents = {\n316             \"app_label\": model._meta.app_label,\n317             \"db_table\": \"new__%s\" % strip_quotes(model._meta.db_table),\n318             \"unique_together\": unique_together,\n319             \"index_together\": index_together,\n320             \"indexes\": indexes,\n321             \"constraints\": constraints,\n322             \"apps\": apps,\n323         }\n324         meta = type(\"Meta\", (), meta_contents)\n325         body_copy[\"Meta\"] = meta\n326         body_copy[\"__module__\"] = model.__module__\n327         new_model = type(\"New%s\" % model._meta.object_name, model.__bases__, body_copy)\n328 \n329         # Create a new table with the updated schema.\n330         self.create_model(new_model)\n331 \n332         # Copy data from the old table into the new table\n333         self.execute(\n334             \"INSERT INTO %s (%s) SELECT %s FROM %s\"\n335             % (\n336                 self.quote_name(new_model._meta.db_table),\n337                 \", \".join(self.quote_name(x) for x in mapping),\n338                 \", \".join(mapping.values()),\n339                 self.quote_name(model._meta.db_table),\n340             )\n341         )\n342 \n343         # Delete the old table to make way for the new\n344         self.delete_model(model, handle_autom2m=False)\n345 \n346         # Rename the new table to take way for the old\n347         self.alter_db_table(\n348             new_model,\n349             new_model._meta.db_table,\n350             model._meta.db_table,\n351             disable_constraints=False,\n352         )\n353 \n354         # Run deferred SQL on correct table\n355         for sql in self.deferred_sql:\n356             self.execute(sql)\n357         self.deferred_sql = []\n358         # Fix any PK-removed field\n359         if restore_pk_field:\n360             restore_pk_field.primary_key = True\n361 \n362     def delete_model(self, model, handle_autom2m=True):\n363         if handle_autom2m:\n364             super().delete_model(model)\n365         else:\n366             # Delete the table (and only that)\n367             self.execute(\n368                 self.sql_delete_table\n369                 % {\n370                     \"table\": self.quote_name(model._meta.db_table),\n371                 }\n372             )\n373             # Remove all deferred statements referencing the deleted table.\n374             for sql in list(self.deferred_sql):\n375                 if isinstance(sql, Statement) and sql.references_table(\n376                     model._meta.db_table\n377                 ):\n378                     self.deferred_sql.remove(sql)\n379 \n380     def add_field(self, model, field):\n381         \"\"\"Create a field on a model.\"\"\"\n382         if (\n383             # Primary keys and unique fields are not supported in ALTER TABLE\n384             # ADD COLUMN.\n385             field.primary_key\n386             or field.unique\n387             or\n388             # Fields with default values cannot by handled by ALTER TABLE ADD\n389             # COLUMN statement because DROP DEFAULT is not supported in\n390             # ALTER TABLE.\n391             not field.null\n392             or self.effective_default(field) is not None\n393         ):\n394             self._remake_table(model, create_field=field)\n395         else:\n396             super().add_field(model, field)\n397 \n398     def remove_field(self, model, field):\n399         \"\"\"\n400         Remove a field from a model. Usually involves deleting a column,\n401         but for M2Ms may involve deleting a table.\n402         \"\"\"\n403         # M2M fields are a special case\n404         if field.many_to_many:\n405             # For implicit M2M tables, delete the auto-created table\n406             if field.remote_field.through._meta.auto_created:\n407                 self.delete_model(field.remote_field.through)\n408             # For explicit \"through\" M2M fields, do nothing\n409         elif (\n410             self.connection.features.can_alter_table_drop_column\n411             # Primary keys, unique fields, and foreign keys are not\n412             # supported in ALTER TABLE DROP COLUMN.\n413             and not field.primary_key\n414             and not field.unique\n415             and not (field.remote_field and field.db_constraint)\n416         ):\n417             super().remove_field(model, field)\n418         # For everything else, remake.\n419         else:\n420             # It might not actually have a column behind it\n421             if field.db_parameters(connection=self.connection)[\"type\"] is None:\n422                 return\n423             self._remake_table(model, delete_field=field)\n424 \n425     def _alter_field(\n426         self,\n427         model,\n428         old_field,\n429         new_field,\n430         old_type,\n431         new_type,\n432         old_db_params,\n433         new_db_params,\n434         strict=False,\n435     ):\n436         \"\"\"Perform a \"physical\" (non-ManyToMany) field update.\"\"\"\n437         # Use \"ALTER TABLE ... RENAME COLUMN\" if only the column name\n438         # changed and there aren't any constraints.\n439         if (\n440             self.connection.features.can_alter_table_rename_column\n441             and old_field.column != new_field.column\n442             and self.column_sql(model, old_field) == self.column_sql(model, new_field)\n443             and not (\n444                 old_field.remote_field\n445                 and old_field.db_constraint\n446                 or new_field.remote_field\n447                 and new_field.db_constraint\n448             )\n449         ):\n450             return self.execute(\n451                 self._rename_field_sql(\n452                     model._meta.db_table, old_field, new_field, new_type\n453                 )\n454             )\n455         # Alter by remaking table\n456         self._remake_table(model, alter_field=(old_field, new_field))\n457         # Rebuild tables with FKs pointing to this field.\n458         old_collation = old_db_params.get(\"collation\")\n459         new_collation = new_db_params.get(\"collation\")\n460         if new_field.unique and (\n461             old_type != new_type or old_collation != new_collation\n462         ):\n463             related_models = set()\n464             opts = new_field.model._meta\n465             for remote_field in opts.related_objects:\n466                 # Ignore self-relationship since the table was already rebuilt.\n467                 if remote_field.related_model == model:\n468                     continue\n469                 if not remote_field.many_to_many:\n470                     if remote_field.field_name == new_field.name:\n471                         related_models.add(remote_field.related_model)\n472                 elif new_field.primary_key and remote_field.through._meta.auto_created:\n473                     related_models.add(remote_field.through)\n474             if new_field.primary_key:\n475                 for many_to_many in opts.many_to_many:\n476                     # Ignore self-relationship since the table was already rebuilt.\n477                     if many_to_many.related_model == model:\n478                         continue\n479                     if many_to_many.remote_field.through._meta.auto_created:\n480                         related_models.add(many_to_many.remote_field.through)\n481             for related_model in related_models:\n482                 self._remake_table(related_model)\n483 \n484     def _alter_many_to_many(self, model, old_field, new_field, strict):\n485         \"\"\"Alter M2Ms to repoint their to= endpoints.\"\"\"\n486         if (\n487             old_field.remote_field.through._meta.db_table\n488             == new_field.remote_field.through._meta.db_table\n489         ):\n490             # The field name didn't change, but some options did, so we have to\n491             # propagate this altering.\n492             self._remake_table(\n493                 old_field.remote_field.through,\n494                 alter_field=(\n495                     # The field that points to the target model is needed, so\n496                     # we can tell alter_field to change it - this is\n497                     # m2m_reverse_field_name() (as opposed to m2m_field_name(),\n498                     # which points to our model).\n499                     old_field.remote_field.through._meta.get_field(\n500                         old_field.m2m_reverse_field_name()\n501                     ),\n502                     new_field.remote_field.through._meta.get_field(\n503                         new_field.m2m_reverse_field_name()\n504                     ),\n505                 ),\n506             )\n507             return\n508 \n509         # Make a new through table\n510         self.create_model(new_field.remote_field.through)\n511         # Copy the data across\n512         self.execute(\n513             \"INSERT INTO %s (%s) SELECT %s FROM %s\"\n514             % (\n515                 self.quote_name(new_field.remote_field.through._meta.db_table),\n516                 \", \".join(\n517                     [\n518                         \"id\",\n519                         new_field.m2m_column_name(),\n520                         new_field.m2m_reverse_name(),\n521                     ]\n522                 ),\n523                 \", \".join(\n524                     [\n525                         \"id\",\n526                         old_field.m2m_column_name(),\n527                         old_field.m2m_reverse_name(),\n528                     ]\n529                 ),\n530                 self.quote_name(old_field.remote_field.through._meta.db_table),\n531             )\n532         )\n533         # Delete the old through table\n534         self.delete_model(old_field.remote_field.through)\n535 \n536     def add_constraint(self, model, constraint):\n537         if isinstance(constraint, UniqueConstraint) and (\n538             constraint.condition\n539             or constraint.contains_expressions\n540             or constraint.include\n541             or constraint.deferrable\n542         ):\n543             super().add_constraint(model, constraint)\n544         else:\n545             self._remake_table(model)\n546 \n547     def remove_constraint(self, model, constraint):\n548         if isinstance(constraint, UniqueConstraint) and (\n549             constraint.condition\n550             or constraint.contains_expressions\n551             or constraint.include\n552             or constraint.deferrable\n553         ):\n554             super().remove_constraint(model, constraint)\n555         else:\n556             self._remake_table(model)\n557 \n558     def _collate_sql(self, collation):\n559         return \"COLLATE \" + collation\n",
        "intended_behavior": "Ensure compatibility or appropriate translation to use of `indexes`, ensuring backend-specific handling of `index_together` is updated."
    }
]