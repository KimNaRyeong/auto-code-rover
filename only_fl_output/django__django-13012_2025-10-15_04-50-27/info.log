2025-10-15 04:50:27.245 | INFO     | Starting overall retry 0 with model gpt-4-0125-preview
2025-10-15 04:50:30.662 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=412, output_tokens=12, cost=0.004480
2025-10-15 04:50:47.958 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=592, output_tokens=742, cost=0.028180
2025-10-15 04:50:49.143 | INFO     | registered non reproducing test 0
2025-10-15 04:51:07.677 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=2380, output_tokens=806, cost=0.047980
2025-10-15 04:51:08.802 | INFO     | registered non reproducing test 1
2025-10-15 04:51:28.200 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=1680, output_tokens=778, cost=0.040140
2025-10-15 04:51:29.436 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-15 04:51:35.220 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=718, output_tokens=218, cost=0.013720
2025-10-15 04:51:35.226 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-15 04:51:36.805 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=572, output_tokens=42, cost=0.006980
2025-10-15 04:51:36.806 | DEBUG    | Extracted a valid json.
2025-10-15 04:51:36.806 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_class(\"ExpressionWrapper\")",
        "search_method(\"annotate\")",
        "search_code(\"GROUP BY\")"
    ],
    "bug_locations": []
}
2025-10-15 04:51:36.888 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-15 04:51:36.889 | DEBUG    | <Agent search> Analyzing search results.
2025-10-15 04:51:54.136 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=2316, output_tokens=804, cost=0.047280
2025-10-15 04:51:54.149 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-15 04:52:03.030 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=3336, output_tokens=335, cost=0.043410
2025-10-15 04:52:03.035 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-15 04:52:10.528 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=689, output_tokens=283, cost=0.015380
2025-10-15 04:52:10.530 | DEBUG    | Extracted a valid json.
2025-10-15 04:52:10.530 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [],
    "bug_locations": [
        {
            "file": "django/db/models/expressions.py",
            "class": "ExpressionWrapper",
            "method": "as_sql",
            "intended_behavior": "In the as_sql method of ExpressionWrapper, the generation of SQL should account for constant expressions wrapped within it, ensuring they are not included in the GROUP BY clause when the SQL query is constructed. The modification should detect when the expression is a constant (e.g., using Value) and handle it such that it does not break SQL syntax rules for databases like PostgreSQL. This behavior should preserve existing functionality for non-constant expressions, maintaining the versatility of ExpressionWrapper in annotating querysets with both dynamic and constant data."
        },
        {
            "file": "django/db/models/sql/compiler.py",
            "class": "",
            "method": "",
            "intended_behavior": "The GROUP BY assembling logic within this file should be revised to correctly handle constant expressions, particularly those wrapped in ExpressionWrapper. This involves ensuring that such expressions do not result in a GROUP BY clause that includes constants, as this is invalid in SQL queries for certain databases (like PostgreSQL). The intended behavior should allow for constants to be included in the SELECT part of the query without being added to GROUP BY, maintaining correct query results while adhering to SQL standards."
        }
    ]
}
2025-10-15 04:52:10.534 | DEBUG    | Found override of as_sql in BaseExpression
2025-10-15 04:52:10.534 | ERROR    | SearchBackend.search_method_in_class() missing 1 required positional argument: 'class_name'
Traceback (most recent call last):

  File "/home/kimnal0/auto-code-rover/app/main.py", line 656, in <module>
    main()
    └ <function main at 0x74155fd22c00>

  File "/home/kimnal0/auto-code-rover/app/main.py", line 120, in main
    run_task_groups(groups, num_processes, organize_output=True)
    │               │       └ 1
    │               └ {'setup_astropy__astropy__4.3': [<app.raw_tasks.RawSweTask object at 0x74146d85f0e0>, <app.raw_tasks.RawSweTask object at 0x7...
    └ <function run_task_groups at 0x74146fb623e0>

  File "/home/kimnal0/auto-code-rover/app/main.py", line 396, in run_task_groups
    run_tasks_serial(all_tasks)
    │                └ [<app.raw_tasks.RawSweTask object at 0x74146d85f0e0>, <app.raw_tasks.RawSweTask object at 0x74146d85f110>, <app.raw_tasks.Raw...
    └ <function run_tasks_serial at 0x74146fb62480>

  File "/home/kimnal0/auto-code-rover/app/main.py", line 414, in run_tasks_serial
    run_task_in_subprocess(task)
    │                      └ <app.raw_tasks.RawSweTask object at 0x74146d794b60>
    └ <function run_task_in_subprocess at 0x74146fb62660>

  File "/home/kimnal0/auto-code-rover/app/main.py", line 462, in run_task_in_subprocess
    executor.submit(run_raw_task, task)
    │        │      │             └ <app.raw_tasks.RawSweTask object at 0x74146d794b60>
    │        │      └ <function run_raw_task at 0x74146fb62700>
    │        └ <function ProcessPoolExecutor.submit at 0x74155f94a020>
    └ <concurrent.futures.process.ProcessPoolExecutor object at 0x74146fd79100>

  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/concurrent/futures/process.py", line 831, in submit
    self._start_executor_manager_thread()
    │    └ <function ProcessPoolExecutor._start_executor_manager_thread at 0x74155f949da0>
    └ <concurrent.futures.process.ProcessPoolExecutor object at 0x74146fd79100>
  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/concurrent/futures/process.py", line 770, in _start_executor_manager_thread
    self._launch_processes()
    │    └ <function ProcessPoolExecutor._launch_processes at 0x74155f949ee0>
    └ <concurrent.futures.process.ProcessPoolExecutor object at 0x74146fd79100>
  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/concurrent/futures/process.py", line 797, in _launch_processes
    self._spawn_process()
    │    └ <function ProcessPoolExecutor._spawn_process at 0x74155f949f80>
    └ <concurrent.futures.process.ProcessPoolExecutor object at 0x74146fd79100>
  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/concurrent/futures/process.py", line 807, in _spawn_process
    p.start()
    │ └ <function BaseProcess.start at 0x74155fb14ea0>
    └ <ForkProcess name='ForkProcess-111' parent=45407 started>
  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/multiprocessing/process.py", line 121, in start
    self._popen = self._Popen(self)
    │    │        │    │      └ <ForkProcess name='ForkProcess-111' parent=45407 started>
    │    │        │    └ <staticmethod(<function ForkProcess._Popen at 0x74155fb860c0>)>
    │    │        └ <ForkProcess name='ForkProcess-111' parent=45407 started>
    │    └ None
    └ <ForkProcess name='ForkProcess-111' parent=45407 started>
  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/multiprocessing/context.py", line 282, in _Popen
    return Popen(process_obj)
           │     └ <ForkProcess name='ForkProcess-111' parent=45407 started>
           └ <class 'multiprocessing.popen_fork.Popen'>
  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/multiprocessing/popen_fork.py", line 19, in __init__
    self._launch(process_obj)
    │    │       └ <ForkProcess name='ForkProcess-111' parent=45407 started>
    │    └ <function Popen._launch at 0x74146db7f7e0>
    └ <multiprocessing.popen_fork.Popen object at 0x74146ee6e2d0>
  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/multiprocessing/popen_fork.py", line 71, in _launch
    code = process_obj._bootstrap(parent_sentinel=child_r)
           │           │                          └ 13
           │           └ <function BaseProcess._bootstrap at 0x74155fb158a0>
           └ <ForkProcess name='ForkProcess-111' parent=45407 started>
  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
    │    └ <function BaseProcess.run at 0x74155fb14e00>
    └ <ForkProcess name='ForkProcess-111' parent=45407 started>
  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
    │    │        │    │        │    └ {}
    │    │        │    │        └ <ForkProcess name='ForkProcess-111' parent=45407 started>
    │    │        │    └ (<concurrent.futures.process._SafeQueue object at 0x74146e5ae4e0>, <multiprocessing.queues.SimpleQueue object at 0x74146fd5e8...
    │    │        └ <ForkProcess name='ForkProcess-111' parent=45407 started>
    │    └ <function _process_worker at 0x74155f9491c0>
    └ <ForkProcess name='ForkProcess-111' parent=45407 started>
  File "/home/kimnal0/miniconda3/envs/auto-code-rover/lib/python3.12/concurrent/futures/process.py", line 263, in _process_worker
    r = call_item.fn(*call_item.args, **call_item.kwargs)
        │         │   │         │       │         └ {}
        │         │   │         │       └ <concurrent.futures.process._CallItem object at 0x74155fdad640>
        │         │   │         └ (<app.raw_tasks.RawSweTask object at 0x74147096ec30>,)
        │         │   └ <concurrent.futures.process._CallItem object at 0x74155fdad640>
        │         └ <function run_raw_task at 0x74146fb62700>
        └ <concurrent.futures.process._CallItem object at 0x74155fdad640>

  File "/home/kimnal0/auto-code-rover/app/main.py", line 494, in run_raw_task
    run_ok = do_inference(task.to_task(), task_output_dir)
             │            │    │          └ '/home/kimnal0/auto-code-rover/only_fl_output/django__django-13012_2025-10-15_04-50-27'
             │            │    └ <function RawSweTask.to_task at 0x74146fb616c0>
             │            └ <app.raw_tasks.RawSweTask object at 0x74147096ec30>
             └ <function do_inference at 0x74146fb628e0>

  File "/home/kimnal0/auto-code-rover/app/main.py", line 590, in do_inference
    run_ok = inference.run_one_task(
             │         └ <function run_one_task at 0x74146fdf0400>
             └ <module 'app.inference' from '/home/kimnal0/auto-code-rover/app/inference.py'>

  File "/home/kimnal0/auto-code-rover/app/inference.py", line 128, in run_one_task
    if _run_one_task(str(out_dir), api_manager, task.get_issue_statement()):
       │                 │         │            │    └ <function SweTask.get_issue_statement at 0x7414702104a0>
       │                 │         │            └ SweTask(task_id='django__django-13012', problem_statement='Constant expressions of an ExpressionWrapper object are incorrectl...
       │                 │         └ <app.manage.ProjectApiManager object at 0x74146fd7b140>
       │                 └ Path('/home/kimnal0/auto-code-rover/only_fl_output/django__django-13012_2025-10-15_04-50-27/output_0')
       └ <function _run_one_task at 0x74146fdf18a0>

  File "/home/kimnal0/auto-code-rover/app/inference.py", line 303, in _run_one_task
    bug_locs, search_msg_thread = api_manager.search_manager.search_iterative(
                                  │           │              └ <function SearchManager.search_iterative at 0x74146fe9dbc0>
                                  │           └ <app.search.search_manage.SearchManager object at 0x74146d8b6960>
                                  └ <app.manage.ProjectApiManager object at 0x74146fd7b140>

  File "/home/kimnal0/auto-code-rover/app/search/search_manage.py", line 125, in search_iterative
    new_bug_locations.extend(self.backend.get_bug_loc_snippets_new(loc))
    │                 │      │    │       │                        └ {'file': 'django/db/models/expressions.py', 'class': 'ExpressionWrapper', 'method': 'as_sql', 'intended_behavior': 'In the as...
    │                 │      │    │       └ <function SearchBackend.get_bug_loc_snippets_new at 0x74146fe9d8a0>
    │                 │      │    └ <app.search.search_backend.SearchBackend object at 0x741470afb9e0>
    │                 │      └ <app.search.search_manage.SearchManager object at 0x74146d8b6960>
    │                 └ <method 'extend' of 'list' objects>
    └ []

  File "/home/kimnal0/auto-code-rover/app/search/search_backend.py", line 825, in get_bug_loc_snippets_new
    self._get_inherited_methods(res.class_name, res.func_name)
    │    │                      │   │           │   └ 'as_sql'
    │    │                      │   │           └ SearchResult(file_path='/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.2/django/db/mo...
    │    │                      │   └ 'ExpressionWrapper'
    │    │                      └ SearchResult(file_path='/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.2/django/db/mo...
    │    └ <function SearchBackend._get_inherited_methods at 0x74146fe9d800>
    └ <app.search.search_backend.SearchBackend object at 0x741470afb9e0>

  File "/home/kimnal0/auto-code-rover/app/search/search_backend.py", line 748, in _get_inherited_methods
    output, search_res, call_ok = self.search_method_in_class(super_call)
                                  │    │                      └ {'class_name': 'BaseExpression', 'method_name': 'as_sql'}
                                  │    └ <function SearchBackend.search_method_in_class at 0x74146fe9cf40>
                                  └ <app.search.search_backend.SearchBackend object at 0x741470afb9e0>

> File "/home/kimnal0/auto-code-rover/app/utils.py", line 343, in wrapper
    return func(*args, **kwargs)
           │     │       └ {}
           │     └ (<app.search.search_backend.SearchBackend object at 0x741470afb9e0>, {'class_name': 'BaseExpression', 'method_name': 'as_sql'})
           └ <function SearchBackend.search_method_in_class at 0x74146fe9cea0>

TypeError: SearchBackend.search_method_in_class() missing 1 required positional argument: 'class_name'
2025-10-15 04:52:10.548 | DEBUG    | Bug location extracted successfully: [<file>django/db/models/expressions.py</file>
<class>ExpressionWrapper</class>
<method>as_sql</method>
<code>
866     def as_sql(self, compiler, connection):
867         return self.expression.as_sql(compiler, connection)

</code><intended_behavior>In the as_sql method of ExpressionWrapper, the generation of SQL should account for constant expressions wrapped within it, ensuring they are not included in the GROUP BY clause when the SQL query is constructed. The modification should detect when the expression is a constant (e.g., using Value) and handle it such that it does not break SQL syntax rules for databases like PostgreSQL. This behavior should preserve existing functionality for non-constant expressions, maintaining the versatility of ExpressionWrapper in annotating querysets with both dynamic and constant data.</intended_behavior>, <file>django/db/models/expressions.py</file>
<class>ExpressionWrapper</class>
<method>None</method>
<code>
850 class ExpressionWrapper(Expression):
851     """
852     An expression that can wrap another expression so that it can provide
853     extra context to the inner expression, such as the output_field.
854     """
855 
856     def __init__(self, expression, output_field):
857         super().__init__(output_field=output_field)
858         self.expression = expression
859 
860     def set_source_expressions(self, exprs):
861         self.expression = exprs[0]
862 
863     def get_source_expressions(self):
864         return [self.expression]
865 
866     def as_sql(self, compiler, connection):
867         return self.expression.as_sql(compiler, connection)
868 
869     def __repr__(self):
870         return "{}({})".format(self.__class__.__name__, self.expression)

</code><intended_behavior>This class provides additional context to the issue.</intended_behavior>, <file>django/db/models/sql/compiler.py</file>
<class>None</class>
<method>None</method>
<code>
1 import collections
2 import re
3 from functools import partial
4 from itertools import chain
5 
6 from django.core.exceptions import EmptyResultSet, FieldError
7 from django.db import DatabaseError, NotSupportedError
8 from django.db.models.constants import LOOKUP_SEP
9 from django.db.models.expressions import F, OrderBy, Random, RawSQL, Ref, Value
10 from django.db.models.functions import Cast
11 from django.db.models.query_utils import Q, select_related_descend
12 from django.db.models.sql.constants import (
13     CURSOR, GET_ITERATOR_CHUNK_SIZE, MULTI, NO_RESULTS, ORDER_DIR, SINGLE,
14 )
15 from django.db.models.sql.query import Query, get_order_dir
16 from django.db.transaction import TransactionManagementError
17 from django.utils.functional import cached_property
18 from django.utils.hashable import make_hashable
19 from django.utils.regex_helper import _lazy_re_compile
20 
21 
22 class SQLCompiler:
23     # Multiline ordering SQL clause may appear from RawSQL.
24     ordering_parts = _lazy_re_compile(
25         r'^(.*)\s(?:ASC|DESC).*',
26         re.MULTILINE | re.DOTALL,
27     )
28 
29     def __init__(self, query, connection, using):
30         self.query = query
31         self.connection = connection
32         self.using = using
33         self.quote_cache = {'*': '*'}
34         # The select, klass_info, and annotations are needed by QuerySet.iterator()
35         # these are set as a side-effect of executing the query. Note that we calculate
36         # separately a list of extra select columns needed for grammatical correctness
37         # of the query, but these columns are not included in self.select.
38         self.select = None
39         self.annotation_col_map = None
40         self.klass_info = None
41         self._meta_ordering = None
42 
43     def setup_query(self):
44         if all(self.query.alias_refcount[a] == 0 for a in self.query.alias_map):
45             self.query.get_initial_alias()
46         self.select, self.klass_info, self.annotation_col_map = self.get_select()
47         self.col_count = len(self.select)
48 
49     def pre_sql_setup(self):
50         """
51         Do any necessary class setup immediately prior to producing SQL. This
52         is for things that can't necessarily be done in __init__ because we
53         might not have all the pieces in place at that time.
54         """
55         self.setup_query()
56         order_by = self.get_order_by()
57         self.where, self.having = self.query.where.split_having()
58         extra_select = self.get_extra_select(order_by, self.select)
59         self.has_extra_select = bool(extra_select)
60         group_by = self.get_group_by(self.select + extra_select, order_by)
61         return extra_select, order_by, group_by
62 
63     def get_group_by(self, select, order_by):
64         """
65         Return a list of 2-tuples of form (sql, params).
66 
67         The logic of what exactly the GROUP BY clause contains is hard
68         to describe in other words than "if it passes the test suite,
69         then it is correct".
70         """
71         # Some examples:
72         #     SomeModel.objects.annotate(Count('somecol'))
73         #     GROUP BY: all fields of the model
74         #
75         #    SomeModel.objects.values('name').annotate(Count('somecol'))
76         #    GROUP BY: name
77         #
78         #    SomeModel.objects.annotate(Count('somecol')).values('name')
79         #    GROUP BY: all cols of the model
80         #
81         #    SomeModel.objects.values('name', 'pk').annotate(Count('somecol')).values('pk')
82         #    GROUP BY: name, pk
83         #
84         #    SomeModel.objects.values('name').annotate(Count('somecol')).values('pk')
85         #    GROUP BY: name, pk
86         #
87         # In fact, the self.query.group_by is the minimal set to GROUP BY. It
88         # can't be ever restricted to a smaller set, but additional columns in
89         # HAVING, ORDER BY, and SELECT clauses are added to it. Unfortunately
90         # the end result is that it is impossible to force the query to have
91         # a chosen GROUP BY clause - you can almost do this by using the form:
92         #     .values(*wanted_cols).annotate(AnAggregate())
93         # but any later annotations, extra selects, values calls that
94         # refer some column outside of the wanted_cols, order_by, or even
95         # filter calls can alter the GROUP BY clause.
96 
97         # The query.group_by is either None (no GROUP BY at all), True
98         # (group by select fields), or a list of expressions to be added
99         # to the group by.
100         if self.query.group_by is None:
101             return []
102         expressions = []
103         if self.query.group_by is not True:
104             # If the group by is set to a list (by .values() call most likely),
105             # then we need to add everything in it to the GROUP BY clause.
106             # Backwards compatibility hack for setting query.group_by. Remove
107             # when  we have public API way of forcing the GROUP BY clause.
108             # Converts string references to expressions.
109             for expr in self.query.group_by:
110                 if not hasattr(expr, 'as_sql'):
111                     expressions.append(self.query.resolve_ref(expr))
112                 else:
113                     expressions.append(expr)
114         # Note that even if the group_by is set, it is only the minimal
115         # set to group by. So, we need to add cols in select, order_by, and
116         # having into the select in any case.
117         ref_sources = {
118             expr.source for expr in expressions if isinstance(expr, Ref)
119         }
120         for expr, _, _ in select:
121             # Skip members of the select clause that are already included
122             # by reference.
123             if expr in ref_sources:
124                 continue
125             cols = expr.get_group_by_cols()
126             for col in cols:
127                 expressions.append(col)
128         for expr, (sql, params, is_ref) in order_by:
129             # Skip References to the select clause, as all expressions in the
130             # select clause are already part of the group by.
131             if not is_ref:
132                 expressions.extend(expr.get_group_by_cols())
133         having_group_by = self.having.get_group_by_cols() if self.having else ()
134         for expr in having_group_by:
135             expressions.append(expr)
136         result = []
137         seen = set()
138         expressions = self.collapse_group_by(expressions, having_group_by)
139 
140         for expr in expressions:
141             sql, params = self.compile(expr)
142             sql, params = expr.select_format(self, sql, params)
143             params_hash = make_hashable(params)
144             if (sql, params_hash) not in seen:
145                 result.append((sql, params))
146                 seen.add((sql, params_hash))
147         return result
148 
149     def collapse_group_by(self, expressions, having):
150         # If the DB can group by primary key, then group by the primary key of
151         # query's main model. Note that for PostgreSQL the GROUP BY clause must
152         # include the primary key of every table, but for MySQL it is enough to
153         # have the main table's primary key.
154         if self.connection.features.allows_group_by_pk:
155             # Determine if the main model's primary key is in the query.
156             pk = None
157             for expr in expressions:
158                 # Is this a reference to query's base table primary key? If the
159                 # expression isn't a Col-like, then skip the expression.
160                 if (getattr(expr, 'target', None) == self.query.model._meta.pk and
161                         getattr(expr, 'alias', None) == self.query.base_table):
162                     pk = expr
163                     break
164             # If the main model's primary key is in the query, group by that
165             # field, HAVING expressions, and expressions associated with tables
166             # that don't have a primary key included in the grouped columns.
167             if pk:
168                 pk_aliases = {
169                     expr.alias for expr in expressions
170                     if hasattr(expr, 'target') and expr.target.primary_key
171                 }
172                 expressions = [pk] + [
173                     expr for expr in expressions
174                     if expr in having or (
175                         getattr(expr, 'alias', None) is not None and expr.alias not in pk_aliases
176                     )
177                 ]
178         elif self.connection.features.allows_group_by_selected_pks:
179             # Filter out all expressions associated with a table's primary key
180             # present in the grouped columns. This is done by identifying all
181             # tables that have their primary key included in the grouped
182             # columns and removing non-primary key columns referring to them.
183             # Unmanaged models are excluded because they could be representing
184             # database views on which the optimization might not be allowed.
185             pks = {
186                 expr for expr in expressions
187                 if (
188                     hasattr(expr, 'target') and
189                     expr.target.primary_key and
190                     self.connection.features.allows_group_by_selected_pks_on_model(expr.target.model)
191                 )
192             }
193             aliases = {expr.alias for expr in pks}
194             expressions = [
195                 expr for expr in expressions if expr in pks or getattr(expr, 'alias', None) not in aliases
196             ]
197         return expressions
198 
199     def get_select(self):
200         """
201         Return three values:
202         - a list of 3-tuples of (expression, (sql, params), alias)
203         - a klass_info structure,
204         - a dictionary of annotations
205 
206         The (sql, params) is what the expression will produce, and alias is the
207         "AS alias" for the column (possibly None).
208 
209         The klass_info structure contains the following information:
210         - The base model of the query.
211         - Which columns for that model are present in the query (by
212           position of the select clause).
213         - related_klass_infos: [f, klass_info] to descent into
214 
215         The annotations is a dictionary of {'attname': column position} values.
216         """
217         select = []
218         klass_info = None
219         annotations = {}
220         select_idx = 0
221         for alias, (sql, params) in self.query.extra_select.items():
222             annotations[alias] = select_idx
223             select.append((RawSQL(sql, params), alias))
224             select_idx += 1
225         assert not (self.query.select and self.query.default_cols)
226         if self.query.default_cols:
227             cols = self.get_default_columns()
228         else:
229             # self.query.select is a special case. These columns never go to
230             # any model.
231             cols = self.query.select
232         if cols:
233             select_list = []
234             for col in cols:
235                 select_list.append(select_idx)
236                 select.append((col, None))
237                 select_idx += 1
238             klass_info = {
239                 'model': self.query.model,
240                 'select_fields': select_list,
241             }
242         for alias, annotation in self.query.annotation_select.items():
243             annotations[alias] = select_idx
244             select.append((annotation, alias))
245             select_idx += 1
246 
247         if self.query.select_related:
248             related_klass_infos = self.get_related_selections(select)
249             klass_info['related_klass_infos'] = related_klass_infos
250 
251             def get_select_from_parent(klass_info):
252                 for ki in klass_info['related_klass_infos']:
253                     if ki['from_parent']:
254                         ki['select_fields'] = (klass_info['select_fields'] +
255                                                ki['select_fields'])
256                     get_select_from_parent(ki)
257             get_select_from_parent(klass_info)
258 
259         ret = []
260         for col, alias in select:
261             try:
262                 sql, params = self.compile(col)
263             except EmptyResultSet:
264                 # Select a predicate that's always False.
265                 sql, params = '0', ()
266             else:
267                 sql, params = col.select_format(self, sql, params)
268             ret.append((col, (sql, params), alias))
269         return ret, klass_info, annotations
270 
271     def get_order_by(self):
272         """
273         Return a list of 2-tuples of form (expr, (sql, params, is_ref)) for the
274         ORDER BY clause.
275 
276         The order_by clause can alter the select clause (for example it
277         can add aliases to clauses that do not yet have one, or it can
278         add totally new select clauses).
279         """
280         if self.query.extra_order_by:
281             ordering = self.query.extra_order_by
282         elif not self.query.default_ordering:
283             ordering = self.query.order_by
284         elif self.query.order_by:
285             ordering = self.query.order_by
286         elif self.query.get_meta().ordering:
287             ordering = self.query.get_meta().ordering
288             self._meta_ordering = ordering
289         else:
290             ordering = []
291         if self.query.standard_ordering:
292             asc, desc = ORDER_DIR['ASC']
293         else:
294             asc, desc = ORDER_DIR['DESC']
295 
296         order_by = []
297         for field in ordering:
298             if hasattr(field, 'resolve_expression'):
299                 if isinstance(field, Value):
300                     # output_field must be resolved for constants.
301                     field = Cast(field, field.output_field)
302                 if not isinstance(field, OrderBy):
303                     field = field.asc()
304                 if not self.query.standard_ordering:
305                     field = field.copy()
306                     field.reverse_ordering()
307                 order_by.append((field, False))
308                 continue
309             if field == '?':  # random
310                 order_by.append((OrderBy(Random()), False))
311                 continue
312 
313             col, order = get_order_dir(field, asc)
314             descending = order == 'DESC'
315 
316             if col in self.query.annotation_select:
317                 # Reference to expression in SELECT clause
318                 order_by.append((
319                     OrderBy(Ref(col, self.query.annotation_select[col]), descending=descending),
320                     True))
321                 continue
322             if col in self.query.annotations:
323                 # References to an expression which is masked out of the SELECT
324                 # clause.
325                 expr = self.query.annotations[col]
326                 if isinstance(expr, Value):
327                     # output_field must be resolved for constants.
328                     expr = Cast(expr, expr.output_field)
329                 order_by.append((OrderBy(expr, descending=descending), False))
330                 continue
331 
332             if '.' in field:
333                 # This came in through an extra(order_by=...) addition. Pass it
334                 # on verbatim.
335                 table, col = col.split('.', 1)
336                 order_by.append((
337                     OrderBy(
338                         RawSQL('%s.%s' % (self.quote_name_unless_alias(table), col), []),
339                         descending=descending
340                     ), False))
341                 continue
342 
343             if not self.query.extra or col not in self.query.extra:
344                 # 'col' is of the form 'field' or 'field1__field2' or
345                 # '-field1__field2__field', etc.
346                 order_by.extend(self.find_ordering_name(
347                     field, self.query.get_meta(), default_order=asc))
348             else:
349                 if col not in self.query.extra_select:
350                     order_by.append((
351                         OrderBy(RawSQL(*self.query.extra[col]), descending=descending),
352                         False))
353                 else:
354                     order_by.append((
355                         OrderBy(Ref(col, RawSQL(*self.query.extra[col])), descending=descending),
356                         True))
357         result = []
358         seen = set()
359 
360         for expr, is_ref in order_by:
361             resolved = expr.resolve_expression(self.query, allow_joins=True, reuse=None)
362             if self.query.combinator:
363                 src = resolved.get_source_expressions()[0]
364                 expr_src = expr.get_source_expressions()[0]
365                 # Relabel order by columns to raw numbers if this is a combined
366                 # query; necessary since the columns can't be referenced by the
367                 # fully qualified name and the simple column names may collide.
368                 for idx, (sel_expr, _, col_alias) in enumerate(self.select):
369                     if is_ref and col_alias == src.refs:
370                         src = src.source
371                     elif col_alias and not (
372                         isinstance(expr_src, F) and col_alias == expr_src.name
373                     ):
374                         continue
375                     if src == sel_expr:
376                         resolved.set_source_expressions([RawSQL('%d' % (idx + 1), ())])
377                         break
378                 else:
379                     if col_alias:
380                         raise DatabaseError('ORDER BY term does not match any column in the result set.')
381                     # Add column used in ORDER BY clause without an alias to
382                     # the selected columns.
383                     self.query.add_select_col(src)
384                     resolved.set_source_expressions([RawSQL('%d' % len(self.query.select), ())])
385             sql, params = self.compile(resolved)
386             # Don't add the same column twice, but the order direction is
387             # not taken into account so we strip it. When this entire method
388             # is refactored into expressions, then we can check each part as we
389             # generate it.
390             without_ordering = self.ordering_parts.search(sql)[1]
391             params_hash = make_hashable(params)
392             if (without_ordering, params_hash) in seen:
393                 continue
394             seen.add((without_ordering, params_hash))
395             result.append((resolved, (sql, params, is_ref)))
396         return result
397 
398     def get_extra_select(self, order_by, select):
399         extra_select = []
400         if self.query.distinct and not self.query.distinct_fields:
401             select_sql = [t[1] for t in select]
402             for expr, (sql, params, is_ref) in order_by:
403                 without_ordering = self.ordering_parts.search(sql)[1]
404                 if not is_ref and (without_ordering, params) not in select_sql:
405                     extra_select.append((expr, (without_ordering, params), None))
406         return extra_select
407 
408     def quote_name_unless_alias(self, name):
409         """
410         A wrapper around connection.ops.quote_name that doesn't quote aliases
411         for table names. This avoids problems with some SQL dialects that treat
412         quoted strings specially (e.g. PostgreSQL).
413         """
414         if name in self.quote_cache:
415             return self.quote_cache[name]
416         if ((name in self.query.alias_map and name not in self.query.table_map) or
417                 name in self.query.extra_select or (
418                     self.query.external_aliases.get(name) and name not in self.query.table_map)):
419             self.quote_cache[name] = name
420             return name
421         r = self.connection.ops.quote_name(name)
422         self.quote_cache[name] = r
423         return r
424 
425     def compile(self, node):
426         vendor_impl = getattr(node, 'as_' + self.connection.vendor, None)
427         if vendor_impl:
428             sql, params = vendor_impl(self, self.connection)
429         else:
430             sql, params = node.as_sql(self, self.connection)
431         return sql, params
432 
433     def get_combinator_sql(self, combinator, all):
434         features = self.connection.features
435         compilers = [
436             query.get_compiler(self.using, self.connection)
437             for query in self.query.combined_queries if not query.is_empty()
438         ]
439         if not features.supports_slicing_ordering_in_compound:
440             for query, compiler in zip(self.query.combined_queries, compilers):
441                 if query.low_mark or query.high_mark:
442                     raise DatabaseError('LIMIT/OFFSET not allowed in subqueries of compound statements.')
443                 if compiler.get_order_by():
444                     raise DatabaseError('ORDER BY not allowed in subqueries of compound statements.')
445         parts = ()
446         for compiler in compilers:
447             try:
448                 # If the columns list is limited, then all combined queries
449                 # must have the same columns list. Set the selects defined on
450                 # the query on all combined queries, if not already set.
451                 if not compiler.query.values_select and self.query.values_select:
452                     compiler.query = compiler.query.clone()
453                     compiler.query.set_values((
454                         *self.query.extra_select,
455                         *self.query.values_select,
456                         *self.query.annotation_select,
457                     ))
458                 part_sql, part_args = compiler.as_sql()
459                 if compiler.query.combinator:
460                     # Wrap in a subquery if wrapping in parentheses isn't
461                     # supported.
462                     if not features.supports_parentheses_in_compound:
463                         part_sql = 'SELECT * FROM ({})'.format(part_sql)
464                     # Add parentheses when combining with compound query if not
465                     # already added for all compound queries.
466                     elif not features.supports_slicing_ordering_in_compound:
467                         part_sql = '({})'.format(part_sql)
468                 parts += ((part_sql, part_args),)
469             except EmptyResultSet:
470                 # Omit the empty queryset with UNION and with DIFFERENCE if the
471                 # first queryset is nonempty.
472                 if combinator == 'union' or (combinator == 'difference' and parts):
473                     continue
474                 raise
475         if not parts:
476             raise EmptyResultSet
477         combinator_sql = self.connection.ops.set_operators[combinator]
478         if all and combinator == 'union':
479             combinator_sql += ' ALL'
480         braces = '({})' if features.supports_slicing_ordering_in_compound else '{}'
481         sql_parts, args_parts = zip(*((braces.format(sql), args) for sql, args in parts))
482         result = [' {} '.format(combinator_sql).join(sql_parts)]
483         params = []
484         for part in args_parts:
485             params.extend(part)
486         return result, params
487 
488     def as_sql(self, with_limits=True, with_col_aliases=False):
489         """
490         Create the SQL for this query. Return the SQL string and list of
491         parameters.
492 
493         If 'with_limits' is False, any limit/offset information is not included
494         in the query.
495         """
496         refcounts_before = self.query.alias_refcount.copy()
497         try:
498             extra_select, order_by, group_by = self.pre_sql_setup()
499             for_update_part = None
500             # Is a LIMIT/OFFSET clause needed?
501             with_limit_offset = with_limits and (self.query.high_mark is not None or self.query.low_mark)
502             combinator = self.query.combinator
503             features = self.connection.features
504             if combinator:
505                 if not getattr(features, 'supports_select_{}'.format(combinator)):
506                     raise NotSupportedError('{} is not supported on this database backend.'.format(combinator))
507                 result, params = self.get_combinator_sql(combinator, self.query.combinator_all)
508             else:
509                 distinct_fields, distinct_params = self.get_distinct()
510                 # This must come after 'select', 'ordering', and 'distinct'
511                 # (see docstring of get_from_clause() for details).
512                 from_, f_params = self.get_from_clause()
513                 where, w_params = self.compile(self.where) if self.where is not None else ("", [])
514                 having, h_params = self.compile(self.having) if self.having is not None else ("", [])
515                 result = ['SELECT']
516                 params = []
517 
518                 if self.query.distinct:
519                     distinct_result, distinct_params = self.connection.ops.distinct_sql(
520                         distinct_fields,
521                         distinct_params,
522                     )
523                     result += distinct_result
524                     params += distinct_params
525 
526                 out_cols = []
527                 col_idx = 1
528                 for _, (s_sql, s_params), alias in self.select + extra_select:
529                     if alias:
530                         s_sql = '%s AS %s' % (s_sql, self.connection.ops.quote_name(alias))
531                     elif with_col_aliases:
532                         s_sql = '%s AS %s' % (s_sql, 'Col%d' % col_idx)
533                         col_idx += 1
534                     params.extend(s_params)
535                     out_cols.append(s_sql)
536 
537                 result += [', '.join(out_cols), 'FROM', *from_]
538                 params.extend(f_params)
539 
540                 if self.query.select_for_update and self.connection.features.has_select_for_update:
541                     if self.connection.get_autocommit():
542                         raise TransactionManagementError('select_for_update cannot be used outside of a transaction.')
543 
544                     if with_limit_offset and not self.connection.features.supports_select_for_update_with_limit:
545                         raise NotSupportedError(
546                             'LIMIT/OFFSET is not supported with '
547                             'select_for_update on this database backend.'
548                         )
549                     nowait = self.query.select_for_update_nowait
550                     skip_locked = self.query.select_for_update_skip_locked
551                     of = self.query.select_for_update_of
552                     no_key = self.query.select_for_no_key_update
553                     # If it's a NOWAIT/SKIP LOCKED/OF/NO KEY query but the
554                     # backend doesn't support it, raise NotSupportedError to
555                     # prevent a possible deadlock.
556                     if nowait and not self.connection.features.has_select_for_update_nowait:
557                         raise NotSupportedError('NOWAIT is not supported on this database backend.')
558                     elif skip_locked and not self.connection.features.has_select_for_update_skip_locked:
559                         raise NotSupportedError('SKIP LOCKED is not supported on this database backend.')
560                     elif of and not self.connection.features.has_select_for_update_of:
561                         raise NotSupportedError('FOR UPDATE OF is not supported on this database backend.')
562                     elif no_key and not self.connection.features.has_select_for_no_key_update:
563                         raise NotSupportedError(
564                             'FOR NO KEY UPDATE is not supported on this '
565                             'database backend.'
566                         )
567                     for_update_part = self.connection.ops.for_update_sql(
568                         nowait=nowait,
569                         skip_locked=skip_locked,
570                         of=self.get_select_for_update_of_arguments(),
571                         no_key=no_key,
572                     )
573 
574                 if for_update_part and self.connection.features.for_update_after_from:
575                     result.append(for_update_part)
576 
577                 if where:
578                     result.append('WHERE %s' % where)
579                     params.extend(w_params)
580 
581                 grouping = []
582                 for g_sql, g_params in group_by:
583                     grouping.append(g_sql)
584                     params.extend(g_params)
585                 if grouping:
586                     if distinct_fields:
587                         raise NotImplementedError('annotate() + distinct(fields) is not implemented.')
588                     order_by = order_by or self.connection.ops.force_no_ordering()
589                     result.append('GROUP BY %s' % ', '.join(grouping))
590                     if self._meta_ordering:
591                         order_by = None
592                 if having:
593                     result.append('HAVING %s' % having)
594                     params.extend(h_params)
595 
596             if self.query.explain_query:
597                 result.insert(0, self.connection.ops.explain_query_prefix(
598                     self.query.explain_format,
599                     **self.query.explain_options
600                 ))
601 
602             if order_by:
603                 ordering = []
604                 for _, (o_sql, o_params, _) in order_by:
605                     ordering.append(o_sql)
606                     params.extend(o_params)
607                 result.append('ORDER BY %s' % ', '.join(ordering))
608 
609             if with_limit_offset:
610                 result.append(self.connection.ops.limit_offset_sql(self.query.low_mark, self.query.high_mark))
611 
612             if for_update_part and not self.connection.features.for_update_after_from:
613                 result.append(for_update_part)
614 
615             if self.query.subquery and extra_select:
616                 # If the query is used as a subquery, the extra selects would
617                 # result in more columns than the left-hand side expression is
618                 # expecting. This can happen when a subquery uses a combination
619                 # of order_by() and distinct(), forcing the ordering expressions
620                 # to be selected as well. Wrap the query in another subquery
621                 # to exclude extraneous selects.
622                 sub_selects = []
623                 sub_params = []
624                 for index, (select, _, alias) in enumerate(self.select, start=1):
625                     if not alias and with_col_aliases:
626                         alias = 'col%d' % index
627                     if alias:
628                         sub_selects.append("%s.%s" % (
629                             self.connection.ops.quote_name('subquery'),
630                             self.connection.ops.quote_name(alias),
631                         ))
632                     else:
633                         select_clone = select.relabeled_clone({select.alias: 'subquery'})
634                         subselect, subparams = select_clone.as_sql(self, self.connection)
635                         sub_selects.append(subselect)
636                         sub_params.extend(subparams)
637                 return 'SELECT %s FROM (%s) subquery' % (
638                     ', '.join(sub_selects),
639                     ' '.join(result),
640                 ), tuple(sub_params + params)
641 
642             return ' '.join(result), tuple(params)
643         finally:
644             # Finally do cleanup - get rid of the joins we created above.
645             self.query.reset_refcounts(refcounts_before)
646 
647     def get_default_columns(self, start_alias=None, opts=None, from_parent=None):
648         """
649         Compute the default columns for selecting every field in the base
650         model. Will sometimes be called to pull in related models (e.g. via
651         select_related), in which case "opts" and "start_alias" will be given
652         to provide a starting point for the traversal.
653 
654         Return a list of strings, quoted appropriately for use in SQL
655         directly, as well as a set of aliases used in the select statement (if
656         'as_pairs' is True, return a list of (alias, col_name) pairs instead
657         of strings as the first component and None as the second component).
658         """
659         result = []
660         if opts is None:
661             opts = self.query.get_meta()
662         only_load = self.deferred_to_columns()
663         start_alias = start_alias or self.query.get_initial_alias()
664         # The 'seen_models' is used to optimize checking the needed parent
665         # alias for a given field. This also includes None -> start_alias to
666         # be used by local fields.
667         seen_models = {None: start_alias}
668 
669         for field in opts.concrete_fields:
670             model = field.model._meta.concrete_model
671             # A proxy model will have a different model and concrete_model. We
672             # will assign None if the field belongs to this model.
673             if model == opts.model:
674                 model = None
675             if from_parent and model is not None and issubclass(
676                     from_parent._meta.concrete_model, model._meta.concrete_model):
677                 # Avoid loading data for already loaded parents.
678                 # We end up here in the case select_related() resolution
679                 # proceeds from parent model to child model. In that case the
680                 # parent model data is already present in the SELECT clause,
681                 # and we want to avoid reloading the same data again.
682                 continue
683             if field.model in only_load and field.attname not in only_load[field.model]:
684                 continue
685             alias = self.query.join_parent_model(opts, model, start_alias,
686                                                  seen_models)
687             column = field.get_col(alias)
688             result.append(column)
689         return result
690 
691     def get_distinct(self):
692         """
693         Return a quoted list of fields to use in DISTINCT ON part of the query.
694 
695         This method can alter the tables in the query, and thus it must be
696         called before get_from_clause().
697         """
698         result = []
699         params = []
700         opts = self.query.get_meta()
701 
702         for name in self.query.distinct_fields:
703             parts = name.split(LOOKUP_SEP)
704             _, targets, alias, joins, path, _, transform_function = self._setup_joins(parts, opts, None)
705             targets, alias, _ = self.query.trim_joins(targets, joins, path)
706             for target in targets:
707                 if name in self.query.annotation_select:
708                     result.append(name)
709                 else:
710                     r, p = self.compile(transform_function(target, alias))
711                     result.append(r)
712                     params.append(p)
713         return result, params
714 
715     def find_ordering_name(self, name, opts, alias=None, default_order='ASC',
716                            already_seen=None):
717         """
718         Return the table alias (the name might be ambiguous, the alias will
719         not be) and column name for ordering by the given 'name' parameter.
720         The 'name' is of the form 'field1__field2__...__fieldN'.
721         """
722         name, order = get_order_dir(name, default_order)
723         descending = order == 'DESC'
724         pieces = name.split(LOOKUP_SEP)
725         field, targets, alias, joins, path, opts, transform_function = self._setup_joins(pieces, opts, alias)
726 
727         # If we get to this point and the field is a relation to another model,
728         # append the default ordering for that model unless it is the pk
729         # shortcut or the attribute name of the field that is specified.
730         if field.is_relation and opts.ordering and getattr(field, 'attname', None) != name and name != 'pk':
731             # Firstly, avoid infinite loops.
732             already_seen = already_seen or set()
733             join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)
734             if join_tuple in already_seen:
735                 raise FieldError('Infinite loop caused by ordering.')
736             already_seen.add(join_tuple)
737 
738             results = []
739             for item in opts.ordering:
740                 if hasattr(item, 'resolve_expression') and not isinstance(item, OrderBy):
741                     item = item.desc() if descending else item.asc()
742                 if isinstance(item, OrderBy):
743                     results.append((item, False))
744                     continue
745                 results.extend(self.find_ordering_name(item, opts, alias,
746                                                        order, already_seen))
747             return results
748         targets, alias, _ = self.query.trim_joins(targets, joins, path)
749         return [(OrderBy(transform_function(t, alias), descending=descending), False) for t in targets]
750 
751     def _setup_joins(self, pieces, opts, alias):
752         """
753         Helper method for get_order_by() and get_distinct().
754 
755         get_ordering() and get_distinct() must produce same target columns on
756         same input, as the prefixes of get_ordering() and get_distinct() must
757         match. Executing SQL where this is not true is an error.
758         """
759         alias = alias or self.query.get_initial_alias()
760         field, targets, opts, joins, path, transform_function = self.query.setup_joins(pieces, opts, alias)
761         alias = joins[-1]
762         return field, targets, alias, joins, path, opts, transform_function
763 
764     def get_from_clause(self):
765         """
766         Return a list of strings that are joined together to go after the
767         "FROM" part of the query, as well as a list any extra parameters that
768         need to be included. Subclasses, can override this to create a
769         from-clause via a "select".
770 
771         This should only be called after any SQL construction methods that
772         might change the tables that are needed. This means the select columns,
773         ordering, and distinct must be done first.
774         """
775         result = []
776         params = []
777         for alias in tuple(self.query.alias_map):
778             if not self.query.alias_refcount[alias]:
779                 continue
780             try:
781                 from_clause = self.query.alias_map[alias]
782             except KeyError:
783                 # Extra tables can end up in self.tables, but not in the
784                 # alias_map if they aren't in a join. That's OK. We skip them.
785                 continue
786             clause_sql, clause_params = self.compile(from_clause)
787             result.append(clause_sql)
788             params.extend(clause_params)
789         for t in self.query.extra_tables:
790             alias, _ = self.query.table_alias(t)
791             # Only add the alias if it's not already present (the table_alias()
792             # call increments the refcount, so an alias refcount of one means
793             # this is the only reference).
794             if alias not in self.query.alias_map or self.query.alias_refcount[alias] == 1:
795                 result.append(', %s' % self.quote_name_unless_alias(alias))
796         return result, params
797 
798     def get_related_selections(self, select, opts=None, root_alias=None, cur_depth=1,
799                                requested=None, restricted=None):
800         """
801         Fill in the information needed for a select_related query. The current
802         depth is measured as the number of connections away from the root model
803         (for example, cur_depth=1 means we are looking at models with direct
804         connections to the root model).
805         """
806         def _get_field_choices():
807             direct_choices = (f.name for f in opts.fields if f.is_relation)
808             reverse_choices = (
809                 f.field.related_query_name()
810                 for f in opts.related_objects if f.field.unique
811             )
812             return chain(direct_choices, reverse_choices, self.query._filtered_relations)
813 
814         related_klass_infos = []
815         if not restricted and cur_depth > self.query.max_depth:
816             # We've recursed far enough; bail out.
817             return related_klass_infos
818 
819         if not opts:
820             opts = self.query.get_meta()
821             root_alias = self.query.get_initial_alias()
822         only_load = self.query.get_loaded_field_names()
823 
824         # Setup for the case when only particular related fields should be
825         # included in the related selection.
826         fields_found = set()
827         if requested is None:
828             restricted = isinstance(self.query.select_related, dict)
829             if restricted:
830                 requested = self.query.select_related
831 
832         def get_related_klass_infos(klass_info, related_klass_infos):
833             klass_info['related_klass_infos'] = related_klass_infos
834 
835         for f in opts.fields:
836             field_model = f.model._meta.concrete_model
837             fields_found.add(f.name)
838 
839             if restricted:
840                 next = requested.get(f.name, {})
841                 if not f.is_relation:
842                     # If a non-related field is used like a relation,
843                     # or if a single non-relational field is given.
844                     if next or f.name in requested:
845                         raise FieldError(
846                             "Non-relational field given in select_related: '%s'. "
847                             "Choices are: %s" % (
848                                 f.name,
849                                 ", ".join(_get_field_choices()) or '(none)',
850                             )
851                         )
852             else:
853                 next = False
854 
855             if not select_related_descend(f, restricted, requested,
856                                           only_load.get(field_model)):
857                 continue
858             klass_info = {
859                 'model': f.remote_field.model,
860                 'field': f,
861                 'reverse': False,
862                 'local_setter': f.set_cached_value,
863                 'remote_setter': f.remote_field.set_cached_value if f.unique else lambda x, y: None,
864                 'from_parent': False,
865             }
866             related_klass_infos.append(klass_info)
867             select_fields = []
868             _, _, _, joins, _, _ = self.query.setup_joins(
869                 [f.name], opts, root_alias)
870             alias = joins[-1]
871             columns = self.get_default_columns(start_alias=alias, opts=f.remote_field.model._meta)
872             for col in columns:
873                 select_fields.append(len(select))
874                 select.append((col, None))
875             klass_info['select_fields'] = select_fields
876             next_klass_infos = self.get_related_selections(
877                 select, f.remote_field.model._meta, alias, cur_depth + 1, next, restricted)
878             get_related_klass_infos(klass_info, next_klass_infos)
879 
880         if restricted:
881             related_fields = [
882                 (o.field, o.related_model)
883                 for o in opts.related_objects
884                 if o.field.unique and not o.many_to_many
885             ]
886             for f, model in related_fields:
887                 if not select_related_descend(f, restricted, requested,
888                                               only_load.get(model), reverse=True):
889                     continue
890 
891                 related_field_name = f.related_query_name()
892                 fields_found.add(related_field_name)
893 
894                 join_info = self.query.setup_joins([related_field_name], opts, root_alias)
895                 alias = join_info.joins[-1]
896                 from_parent = issubclass(model, opts.model) and model is not opts.model
897                 klass_info = {
898                     'model': model,
899                     'field': f,
900                     'reverse': True,
901                     'local_setter': f.remote_field.set_cached_value,
902                     'remote_setter': f.set_cached_value,
903                     'from_parent': from_parent,
904                 }
905                 related_klass_infos.append(klass_info)
906                 select_fields = []
907                 columns = self.get_default_columns(
908                     start_alias=alias, opts=model._meta, from_parent=opts.model)
909                 for col in columns:
910                     select_fields.append(len(select))
911                     select.append((col, None))
912                 klass_info['select_fields'] = select_fields
913                 next = requested.get(f.related_query_name(), {})
914                 next_klass_infos = self.get_related_selections(
915                     select, model._meta, alias, cur_depth + 1,
916                     next, restricted)
917                 get_related_klass_infos(klass_info, next_klass_infos)
918 
919             def local_setter(obj, from_obj):
920                 # Set a reverse fk object when relation is non-empty.
921                 if from_obj:
922                     f.remote_field.set_cached_value(from_obj, obj)
923 
924             def remote_setter(name, obj, from_obj):
925                 setattr(from_obj, name, obj)
926 
927             for name in list(requested):
928                 # Filtered relations work only on the topmost level.
929                 if cur_depth > 1:
930                     break
931                 if name in self.query._filtered_relations:
932                     fields_found.add(name)
933                     f, _, join_opts, joins, _, _ = self.query.setup_joins([name], opts, root_alias)
934                     model = join_opts.model
935                     alias = joins[-1]
936                     from_parent = issubclass(model, opts.model) and model is not opts.model
937                     klass_info = {
938                         'model': model,
939                         'field': f,
940                         'reverse': True,
941                         'local_setter': local_setter,
942                         'remote_setter': partial(remote_setter, name),
943                         'from_parent': from_parent,
944                     }
945                     related_klass_infos.append(klass_info)
946                     select_fields = []
947                     columns = self.get_default_columns(
948                         start_alias=alias, opts=model._meta,
949                         from_parent=opts.model,
950                     )
951                     for col in columns:
952                         select_fields.append(len(select))
953                         select.append((col, None))
954                     klass_info['select_fields'] = select_fields
955                     next_requested = requested.get(name, {})
956                     next_klass_infos = self.get_related_selections(
957                         select, opts=model._meta, root_alias=alias,
958                         cur_depth=cur_depth + 1, requested=next_requested,
959                         restricted=restricted,
960                     )
961                     get_related_klass_infos(klass_info, next_klass_infos)
962             fields_not_found = set(requested).difference(fields_found)
963             if fields_not_found:
964                 invalid_fields = ("'%s'" % s for s in fields_not_found)
965                 raise FieldError(
966                     'Invalid field name(s) given in select_related: %s. '
967                     'Choices are: %s' % (
968                         ', '.join(invalid_fields),
969                         ', '.join(_get_field_choices()) or '(none)',
970                     )
971                 )
972         return related_klass_infos
973 
974     def get_select_for_update_of_arguments(self):
975         """
976         Return a quoted list of arguments for the SELECT FOR UPDATE OF part of
977         the query.
978         """
979         def _get_parent_klass_info(klass_info):
980             for parent_model, parent_link in klass_info['model']._meta.parents.items():
981                 parent_list = parent_model._meta.get_parent_list()
982                 yield {
983                     'model': parent_model,
984                     'field': parent_link,
985                     'reverse': False,
986                     'select_fields': [
987                         select_index
988                         for select_index in klass_info['select_fields']
989                         # Selected columns from a model or its parents.
990                         if (
991                             self.select[select_index][0].target.model == parent_model or
992                             self.select[select_index][0].target.model in parent_list
993                         )
994                     ],
995                 }
996 
997         def _get_first_selected_col_from_model(klass_info):
998             """
999             Find the first selected column from a model. If it doesn't exist,
1000             don't lock a model.
1001 
1002             select_fields is filled recursively, so it also contains fields
1003             from the parent models.
1004             """
1005             for select_index in klass_info['select_fields']:
1006                 if self.select[select_index][0].target.model == klass_info['model']:
1007                     return self.select[select_index][0]
1008 
1009         def _get_field_choices():
1010             """Yield all allowed field paths in breadth-first search order."""
1011             queue = collections.deque([(None, self.klass_info)])
1012             while queue:
1013                 parent_path, klass_info = queue.popleft()
1014                 if parent_path is None:
1015                     path = []
1016                     yield 'self'
1017                 else:
1018                     field = klass_info['field']
1019                     if klass_info['reverse']:
1020                         field = field.remote_field
1021                     path = parent_path + [field.name]
1022                     yield LOOKUP_SEP.join(path)
1023                 queue.extend(
1024                     (path, klass_info)
1025                     for klass_info in _get_parent_klass_info(klass_info)
1026                 )
1027                 queue.extend(
1028                     (path, klass_info)
1029                     for klass_info in klass_info.get('related_klass_infos', [])
1030                 )
1031         result = []
1032         invalid_names = []
1033         for name in self.query.select_for_update_of:
1034             klass_info = self.klass_info
1035             if name == 'self':
1036                 col = _get_first_selected_col_from_model(klass_info)
1037             else:
1038                 for part in name.split(LOOKUP_SEP):
1039                     klass_infos = (
1040                         *klass_info.get('related_klass_infos', []),
1041                         *_get_parent_klass_info(klass_info),
1042                     )
1043                     for related_klass_info in klass_infos:
1044                         field = related_klass_info['field']
1045                         if related_klass_info['reverse']:
1046                             field = field.remote_field
1047                         if field.name == part:
1048                             klass_info = related_klass_info
1049                             break
1050                     else:
1051                         klass_info = None
1052                         break
1053                 if klass_info is None:
1054                     invalid_names.append(name)
1055                     continue
1056                 col = _get_first_selected_col_from_model(klass_info)
1057             if col is not None:
1058                 if self.connection.features.select_for_update_of_column:
1059                     result.append(self.compile(col)[0])
1060                 else:
1061                     result.append(self.quote_name_unless_alias(col.alias))
1062         if invalid_names:
1063             raise FieldError(
1064                 'Invalid field name(s) given in select_for_update(of=(...)): %s. '
1065                 'Only relational fields followed in the query are allowed. '
1066                 'Choices are: %s.' % (
1067                     ', '.join(invalid_names),
1068                     ', '.join(_get_field_choices()),
1069                 )
1070             )
1071         return result
1072 
1073     def deferred_to_columns(self):
1074         """
1075         Convert the self.deferred_loading data structure to mapping of table
1076         names to sets of column names which are to be loaded. Return the
1077         dictionary.
1078         """
1079         columns = {}
1080         self.query.deferred_to_data(columns, self.query.get_loaded_field_names_cb)
1081         return columns
1082 
1083     def get_converters(self, expressions):
1084         converters = {}
1085         for i, expression in enumerate(expressions):
1086             if expression:
1087                 backend_converters = self.connection.ops.get_db_converters(expression)
1088                 field_converters = expression.get_db_converters(self.connection)
1089                 if backend_converters or field_converters:
1090                     converters[i] = (backend_converters + field_converters, expression)
1091         return converters
1092 
1093     def apply_converters(self, rows, converters):
1094         connection = self.connection
1095         converters = list(converters.items())
1096         for row in map(list, rows):
1097             for pos, (convs, expression) in converters:
1098                 value = row[pos]
1099                 for converter in convs:
1100                     value = converter(value, expression, connection)
1101                 row[pos] = value
1102             yield row
1103 
1104     def results_iter(self, results=None, tuple_expected=False, chunked_fetch=False,
1105                      chunk_size=GET_ITERATOR_CHUNK_SIZE):
1106         """Return an iterator over the results from executing this query."""
1107         if results is None:
1108             results = self.execute_sql(MULTI, chunked_fetch=chunked_fetch, chunk_size=chunk_size)
1109         fields = [s[0] for s in self.select[0:self.col_count]]
1110         converters = self.get_converters(fields)
1111         rows = chain.from_iterable(results)
1112         if converters:
1113             rows = self.apply_converters(rows, converters)
1114             if tuple_expected:
1115                 rows = map(tuple, rows)
1116         return rows
1117 
1118     def has_results(self):
1119         """
1120         Backends (e.g. NoSQL) can override this in order to use optimized
1121         versions of "query has any results."
1122         """
1123         # This is always executed on a query clone, so we can modify self.query
1124         self.query.add_extra({'a': 1}, None, None, None, None, None)
1125         self.query.set_extra_mask(['a'])
1126         return bool(self.execute_sql(SINGLE))
1127 
1128     def execute_sql(self, result_type=MULTI, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE):
1129         """
1130         Run the query against the database and return the result(s). The
1131         return value is a single data item if result_type is SINGLE, or an
1132         iterator over the results if the result_type is MULTI.
1133 
1134         result_type is either MULTI (use fetchmany() to retrieve all rows),
1135         SINGLE (only retrieve a single row), or None. In this last case, the
1136         cursor is returned if any query is executed, since it's used by
1137         subclasses such as InsertQuery). It's possible, however, that no query
1138         is needed, as the filters describe an empty set. In that case, None is
1139         returned, to avoid any unnecessary database interaction.
1140         """
1141         result_type = result_type or NO_RESULTS
1142         try:
1143             sql, params = self.as_sql()
1144             if not sql:
1145                 raise EmptyResultSet
1146         except EmptyResultSet:
1147             if result_type == MULTI:
1148                 return iter([])
1149             else:
1150                 return
1151         if chunked_fetch:
1152             cursor = self.connection.chunked_cursor()
1153         else:
1154             cursor = self.connection.cursor()
1155         try:
1156             cursor.execute(sql, params)
1157         except Exception:
1158             # Might fail for server-side cursors (e.g. connection closed)
1159             cursor.close()
1160             raise
1161 
1162         if result_type == CURSOR:
1163             # Give the caller the cursor to process and close.
1164             return cursor
1165         if result_type == SINGLE:
1166             try:
1167                 val = cursor.fetchone()
1168                 if val:
1169                     return val[0:self.col_count]
1170                 return val
1171             finally:
1172                 # done with the cursor
1173                 cursor.close()
1174         if result_type == NO_RESULTS:
1175             cursor.close()
1176             return
1177 
1178         result = cursor_iter(
1179             cursor, self.connection.features.empty_fetchmany_value,
1180             self.col_count if self.has_extra_select else None,
1181             chunk_size,
1182         )
1183         if not chunked_fetch or not self.connection.features.can_use_chunked_reads:
1184             try:
1185                 # If we are using non-chunked reads, we return the same data
1186                 # structure as normally, but ensure it is all read into memory
1187                 # before going any further. Use chunked_fetch if requested,
1188                 # unless the database doesn't support it.
1189                 return list(result)
1190             finally:
1191                 # done with the cursor
1192                 cursor.close()
1193         return result
1194 
1195     def as_subquery_condition(self, alias, columns, compiler):
1196         qn = compiler.quote_name_unless_alias
1197         qn2 = self.connection.ops.quote_name
1198 
1199         for index, select_col in enumerate(self.query.select):
1200             lhs_sql, lhs_params = self.compile(select_col)
1201             rhs = '%s.%s' % (qn(alias), qn2(columns[index]))
1202             self.query.where.add(
1203                 RawSQL('%s = %s' % (lhs_sql, rhs), lhs_params), 'AND')
1204 
1205         sql, params = self.as_sql()
1206         return 'EXISTS (%s)' % sql, params
1207 
1208     def explain_query(self):
1209         result = list(self.execute_sql())
1210         # Some backends return 1 item tuples with strings, and others return
1211         # tuples with integers and strings. Flatten them out into strings.
1212         for row in result[0]:
1213             if not isinstance(row, str):
1214                 yield ' '.join(str(c) for c in row)
1215             else:
1216                 yield row
1217 
1218 
1219 class SQLInsertCompiler(SQLCompiler):
1220     returning_fields = None
1221     returning_params = tuple()
1222 
1223     def field_as_sql(self, field, val):
1224         """
1225         Take a field and a value intended to be saved on that field, and
1226         return placeholder SQL and accompanying params. Check for raw values,
1227         expressions, and fields with get_placeholder() defined in that order.
1228 
1229         When field is None, consider the value raw and use it as the
1230         placeholder, with no corresponding parameters returned.
1231         """
1232         if field is None:
1233             # A field value of None means the value is raw.
1234             sql, params = val, []
1235         elif hasattr(val, 'as_sql'):
1236             # This is an expression, let's compile it.
1237             sql, params = self.compile(val)
1238         elif hasattr(field, 'get_placeholder'):
1239             # Some fields (e.g. geo fields) need special munging before
1240             # they can be inserted.
1241             sql, params = field.get_placeholder(val, self, self.connection), [val]
1242         else:
1243             # Return the common case for the placeholder
1244             sql, params = '%s', [val]
1245 
1246         # The following hook is only used by Oracle Spatial, which sometimes
1247         # needs to yield 'NULL' and [] as its placeholder and params instead
1248         # of '%s' and [None]. The 'NULL' placeholder is produced earlier by
1249         # OracleOperations.get_geom_placeholder(). The following line removes
1250         # the corresponding None parameter. See ticket #10888.
1251         params = self.connection.ops.modify_insert_params(sql, params)
1252 
1253         return sql, params
1254 
1255     def prepare_value(self, field, value):
1256         """
1257         Prepare a value to be used in a query by resolving it if it is an
1258         expression and otherwise calling the field's get_db_prep_save().
1259         """
1260         if hasattr(value, 'resolve_expression'):
1261             value = value.resolve_expression(self.query, allow_joins=False, for_save=True)
1262             # Don't allow values containing Col expressions. They refer to
1263             # existing columns on a row, but in the case of insert the row
1264             # doesn't exist yet.
1265             if value.contains_column_references:
1266                 raise ValueError(
1267                     'Failed to insert expression "%s" on %s. F() expressions '
1268                     'can only be used to update, not to insert.' % (value, field)
1269                 )
1270             if value.contains_aggregate:
1271                 raise FieldError(
1272                     'Aggregate functions are not allowed in this query '
1273                     '(%s=%r).' % (field.name, value)
1274                 )
1275             if value.contains_over_clause:
1276                 raise FieldError(
1277                     'Window expressions are not allowed in this query (%s=%r).'
1278                     % (field.name, value)
1279                 )
1280         else:
1281             value = field.get_db_prep_save(value, connection=self.connection)
1282         return value
1283 
1284     def pre_save_val(self, field, obj):
1285         """
1286         Get the given field's value off the given obj. pre_save() is used for
1287         things like auto_now on DateTimeField. Skip it if this is a raw query.
1288         """
1289         if self.query.raw:
1290             return getattr(obj, field.attname)
1291         return field.pre_save(obj, add=True)
1292 
1293     def assemble_as_sql(self, fields, value_rows):
1294         """
1295         Take a sequence of N fields and a sequence of M rows of values, and
1296         generate placeholder SQL and parameters for each field and value.
1297         Return a pair containing:
1298          * a sequence of M rows of N SQL placeholder strings, and
1299          * a sequence of M rows of corresponding parameter values.
1300 
1301         Each placeholder string may contain any number of '%s' interpolation
1302         strings, and each parameter row will contain exactly as many params
1303         as the total number of '%s's in the corresponding placeholder row.
1304         """
1305         if not value_rows:
1306             return [], []
1307 
1308         # list of (sql, [params]) tuples for each object to be saved
1309         # Shape: [n_objs][n_fields][2]
1310         rows_of_fields_as_sql = (
1311             (self.field_as_sql(field, v) for field, v in zip(fields, row))
1312             for row in value_rows
1313         )
1314 
1315         # tuple like ([sqls], [[params]s]) for each object to be saved
1316         # Shape: [n_objs][2][n_fields]
1317         sql_and_param_pair_rows = (zip(*row) for row in rows_of_fields_as_sql)
1318 
1319         # Extract separate lists for placeholders and params.
1320         # Each of these has shape [n_objs][n_fields]
1321         placeholder_rows, param_rows = zip(*sql_and_param_pair_rows)
1322 
1323         # Params for each field are still lists, and need to be flattened.
1324         param_rows = [[p for ps in row for p in ps] for row in param_rows]
1325 
1326         return placeholder_rows, param_rows
1327 
1328     def as_sql(self):
1329         # We don't need quote_name_unless_alias() here, since these are all
1330         # going to be column names (so we can avoid the extra overhead).
1331         qn = self.connection.ops.quote_name
1332         opts = self.query.get_meta()
1333         insert_statement = self.connection.ops.insert_statement(ignore_conflicts=self.query.ignore_conflicts)
1334         result = ['%s %s' % (insert_statement, qn(opts.db_table))]
1335         fields = self.query.fields or [opts.pk]
1336         result.append('(%s)' % ', '.join(qn(f.column) for f in fields))
1337 
1338         if self.query.fields:
1339             value_rows = [
1340                 [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
1341                 for obj in self.query.objs
1342             ]
1343         else:
1344             # An empty object.
1345             value_rows = [[self.connection.ops.pk_default_value()] for _ in self.query.objs]
1346             fields = [None]
1347 
1348         # Currently the backends just accept values when generating bulk
1349         # queries and generate their own placeholders. Doing that isn't
1350         # necessary and it should be possible to use placeholders and
1351         # expressions in bulk inserts too.
1352         can_bulk = (not self.returning_fields and self.connection.features.has_bulk_insert)
1353 
1354         placeholder_rows, param_rows = self.assemble_as_sql(fields, value_rows)
1355 
1356         ignore_conflicts_suffix_sql = self.connection.ops.ignore_conflicts_suffix_sql(
1357             ignore_conflicts=self.query.ignore_conflicts
1358         )
1359         if self.returning_fields and self.connection.features.can_return_columns_from_insert:
1360             if self.connection.features.can_return_rows_from_bulk_insert:
1361                 result.append(self.connection.ops.bulk_insert_sql(fields, placeholder_rows))
1362                 params = param_rows
1363             else:
1364                 result.append("VALUES (%s)" % ", ".join(placeholder_rows[0]))
1365                 params = [param_rows[0]]
1366             if ignore_conflicts_suffix_sql:
1367                 result.append(ignore_conflicts_suffix_sql)
1368             # Skip empty r_sql to allow subclasses to customize behavior for
1369             # 3rd party backends. Refs #19096.
1370             r_sql, self.returning_params = self.connection.ops.return_insert_columns(self.returning_fields)
1371             if r_sql:
1372                 result.append(r_sql)
1373                 params += [self.returning_params]
1374             return [(" ".join(result), tuple(chain.from_iterable(params)))]
1375 
1376         if can_bulk:
1377             result.append(self.connection.ops.bulk_insert_sql(fields, placeholder_rows))
1378             if ignore_conflicts_suffix_sql:
1379                 result.append(ignore_conflicts_suffix_sql)
1380             return [(" ".join(result), tuple(p for ps in param_rows for p in ps))]
1381         else:
1382             if ignore_conflicts_suffix_sql:
1383                 result.append(ignore_conflicts_suffix_sql)
1384             return [
1385                 (" ".join(result + ["VALUES (%s)" % ", ".join(p)]), vals)
1386                 for p, vals in zip(placeholder_rows, param_rows)
1387             ]
1388 
1389     def execute_sql(self, returning_fields=None):
1390         assert not (
1391             returning_fields and len(self.query.objs) != 1 and
1392             not self.connection.features.can_return_rows_from_bulk_insert
1393         )
1394         self.returning_fields = returning_fields
1395         with self.connection.cursor() as cursor:
1396             for sql, params in self.as_sql():
1397                 cursor.execute(sql, params)
1398             if not self.returning_fields:
1399                 return []
1400             if self.connection.features.can_return_rows_from_bulk_insert and len(self.query.objs) > 1:
1401                 return self.connection.ops.fetch_returned_insert_rows(cursor)
1402             if self.connection.features.can_return_columns_from_insert:
1403                 assert len(self.query.objs) == 1
1404                 return [self.connection.ops.fetch_returned_insert_columns(cursor, self.returning_params)]
1405             return [(self.connection.ops.last_insert_id(
1406                 cursor, self.query.get_meta().db_table, self.query.get_meta().pk.column
1407             ),)]
1408 
1409 
1410 class SQLDeleteCompiler(SQLCompiler):
1411     @cached_property
1412     def single_alias(self):
1413         # Ensure base table is in aliases.
1414         self.query.get_initial_alias()
1415         return sum(self.query.alias_refcount[t] > 0 for t in self.query.alias_map) == 1
1416 
1417     def _as_sql(self, query):
1418         result = [
1419             'DELETE FROM %s' % self.quote_name_unless_alias(query.base_table)
1420         ]
1421         where, params = self.compile(query.where)
1422         if where:
1423             result.append('WHERE %s' % where)
1424         return ' '.join(result), tuple(params)
1425 
1426     def as_sql(self):
1427         """
1428         Create the SQL for this query. Return the SQL string and list of
1429         parameters.
1430         """
1431         if self.single_alias:
1432             return self._as_sql(self.query)
1433         innerq = self.query.clone()
1434         innerq.__class__ = Query
1435         innerq.clear_select_clause()
1436         pk = self.query.model._meta.pk
1437         innerq.select = [
1438             pk.get_col(self.query.get_initial_alias())
1439         ]
1440         outerq = Query(self.query.model)
1441         outerq.where = self.query.where_class()
1442         outerq.add_q(Q(pk__in=innerq))
1443         return self._as_sql(outerq)
1444 
1445 
1446 class SQLUpdateCompiler(SQLCompiler):
1447     def as_sql(self):
1448         """
1449         Create the SQL for this query. Return the SQL string and list of
1450         parameters.
1451         """
1452         self.pre_sql_setup()
1453         if not self.query.values:
1454             return '', ()
1455         qn = self.quote_name_unless_alias
1456         values, update_params = [], []
1457         for field, model, val in self.query.values:
1458             if hasattr(val, 'resolve_expression'):
1459                 val = val.resolve_expression(self.query, allow_joins=False, for_save=True)
1460                 if val.contains_aggregate:
1461                     raise FieldError(
1462                         'Aggregate functions are not allowed in this query '
1463                         '(%s=%r).' % (field.name, val)
1464                     )
1465                 if val.contains_over_clause:
1466                     raise FieldError(
1467                         'Window expressions are not allowed in this query '
1468                         '(%s=%r).' % (field.name, val)
1469                     )
1470             elif hasattr(val, 'prepare_database_save'):
1471                 if field.remote_field:
1472                     val = field.get_db_prep_save(
1473                         val.prepare_database_save(field),
1474                         connection=self.connection,
1475                     )
1476                 else:
1477                     raise TypeError(
1478                         "Tried to update field %s with a model instance, %r. "
1479                         "Use a value compatible with %s."
1480                         % (field, val, field.__class__.__name__)
1481                     )
1482             else:
1483                 val = field.get_db_prep_save(val, connection=self.connection)
1484 
1485             # Getting the placeholder for the field.
1486             if hasattr(field, 'get_placeholder'):
1487                 placeholder = field.get_placeholder(val, self, self.connection)
1488             else:
1489                 placeholder = '%s'
1490             name = field.column
1491             if hasattr(val, 'as_sql'):
1492                 sql, params = self.compile(val)
1493                 values.append('%s = %s' % (qn(name), placeholder % sql))
1494                 update_params.extend(params)
1495             elif val is not None:
1496                 values.append('%s = %s' % (qn(name), placeholder))
1497                 update_params.append(val)
1498             else:
1499                 values.append('%s = NULL' % qn(name))
1500         table = self.query.base_table
1501         result = [
1502             'UPDATE %s SET' % qn(table),
1503             ', '.join(values),
1504         ]
1505         where, params = self.compile(self.query.where)
1506         if where:
1507             result.append('WHERE %s' % where)
1508         return ' '.join(result), tuple(update_params + params)
1509 
1510     def execute_sql(self, result_type):
1511         """
1512         Execute the specified update. Return the number of rows affected by
1513         the primary update query. The "primary update query" is the first
1514         non-empty query that is executed. Row counts for any subsequent,
1515         related queries are not available.
1516         """
1517         cursor = super().execute_sql(result_type)
1518         try:
1519             rows = cursor.rowcount if cursor else 0
1520             is_empty = cursor is None
1521         finally:
1522             if cursor:
1523                 cursor.close()
1524         for query in self.query.get_related_updates():
1525             aux_rows = query.get_compiler(self.using).execute_sql(result_type)
1526             if is_empty and aux_rows:
1527                 rows = aux_rows
1528                 is_empty = False
1529         return rows
1530 
1531     def pre_sql_setup(self):
1532         """
1533         If the update depends on results from other tables, munge the "where"
1534         conditions to match the format required for (portable) SQL updates.
1535 
1536         If multiple updates are required, pull out the id values to update at
1537         this point so that they don't change as a result of the progressive
1538         updates.
1539         """
1540         refcounts_before = self.query.alias_refcount.copy()
1541         # Ensure base table is in the query
1542         self.query.get_initial_alias()
1543         count = self.query.count_active_tables()
1544         if not self.query.related_updates and count == 1:
1545             return
1546         query = self.query.chain(klass=Query)
1547         query.select_related = False
1548         query.clear_ordering(True)
1549         query.extra = {}
1550         query.select = []
1551         query.add_fields([query.get_meta().pk.name])
1552         super().pre_sql_setup()
1553 
1554         must_pre_select = count > 1 and not self.connection.features.update_can_self_select
1555 
1556         # Now we adjust the current query: reset the where clause and get rid
1557         # of all the tables we don't need (since they're in the sub-select).
1558         self.query.where = self.query.where_class()
1559         if self.query.related_updates or must_pre_select:
1560             # Either we're using the idents in multiple update queries (so
1561             # don't want them to change), or the db backend doesn't support
1562             # selecting from the updating table (e.g. MySQL).
1563             idents = []
1564             for rows in query.get_compiler(self.using).execute_sql(MULTI):
1565                 idents.extend(r[0] for r in rows)
1566             self.query.add_filter(('pk__in', idents))
1567             self.query.related_ids = idents
1568         else:
1569             # The fast path. Filters and updates in one query.
1570             self.query.add_filter(('pk__in', query))
1571         self.query.reset_refcounts(refcounts_before)
1572 
1573 
1574 class SQLAggregateCompiler(SQLCompiler):
1575     def as_sql(self):
1576         """
1577         Create the SQL for this query. Return the SQL string and list of
1578         parameters.
1579         """
1580         sql, params = [], []
1581         for annotation in self.query.annotation_select.values():
1582             ann_sql, ann_params = self.compile(annotation)
1583             ann_sql, ann_params = annotation.select_format(self, ann_sql, ann_params)
1584             sql.append(ann_sql)
1585             params.extend(ann_params)
1586         self.col_count = len(self.query.annotation_select)
1587         sql = ', '.join(sql)
1588         params = tuple(params)
1589 
1590         sql = 'SELECT %s FROM (%s) subquery' % (sql, self.query.subquery)
1591         params = params + self.query.sub_params
1592         return sql, params
1593 
1594 
1595 def cursor_iter(cursor, sentinel, col_count, itersize):
1596     """
1597     Yield blocks of rows from a cursor and ensure the cursor is closed when
1598     done.
1599     """
1600     try:
1601         for rows in iter((lambda: cursor.fetchmany(itersize)), sentinel):
1602             yield rows if col_count is None else [r[:col_count] for r in rows]
1603     finally:
1604         cursor.close()

</code><intended_behavior>The GROUP BY assembling logic within this file should be revised to correctly handle constant expressions, particularly those wrapped in ExpressionWrapper. This involves ensuring that such expressions do not result in a GROUP BY clause that includes constants, as this is invalid in SQL queries for certain databases (like PostgreSQL). The intended behavior should allow for constants to be included in the SELECT part of the query without being added to GROUP BY, maintaining correct query results while adhering to SQL standards.</intended_behavior>]
2025-10-15 04:52:10.549 | INFO     | Search completed. Bug locations: [<file>django/db/models/expressions.py</file>
<class>ExpressionWrapper</class>
<method>as_sql</method>
<code>
866     def as_sql(self, compiler, connection):
867         return self.expression.as_sql(compiler, connection)

</code><intended_behavior>In the as_sql method of ExpressionWrapper, the generation of SQL should account for constant expressions wrapped within it, ensuring they are not included in the GROUP BY clause when the SQL query is constructed. The modification should detect when the expression is a constant (e.g., using Value) and handle it such that it does not break SQL syntax rules for databases like PostgreSQL. This behavior should preserve existing functionality for non-constant expressions, maintaining the versatility of ExpressionWrapper in annotating querysets with both dynamic and constant data.</intended_behavior>, <file>django/db/models/expressions.py</file>
<class>ExpressionWrapper</class>
<method>None</method>
<code>
850 class ExpressionWrapper(Expression):
851     """
852     An expression that can wrap another expression so that it can provide
853     extra context to the inner expression, such as the output_field.
854     """
855 
856     def __init__(self, expression, output_field):
857         super().__init__(output_field=output_field)
858         self.expression = expression
859 
860     def set_source_expressions(self, exprs):
861         self.expression = exprs[0]
862 
863     def get_source_expressions(self):
864         return [self.expression]
865 
866     def as_sql(self, compiler, connection):
867         return self.expression.as_sql(compiler, connection)
868 
869     def __repr__(self):
870         return "{}({})".format(self.__class__.__name__, self.expression)

</code><intended_behavior>This class provides additional context to the issue.</intended_behavior>, <file>django/db/models/sql/compiler.py</file>
<class>None</class>
<method>None</method>
<code>
1 import collections
2 import re
3 from functools import partial
4 from itertools import chain
5 
6 from django.core.exceptions import EmptyResultSet, FieldError
7 from django.db import DatabaseError, NotSupportedError
8 from django.db.models.constants import LOOKUP_SEP
9 from django.db.models.expressions import F, OrderBy, Random, RawSQL, Ref, Value
10 from django.db.models.functions import Cast
11 from django.db.models.query_utils import Q, select_related_descend
12 from django.db.models.sql.constants import (
13     CURSOR, GET_ITERATOR_CHUNK_SIZE, MULTI, NO_RESULTS, ORDER_DIR, SINGLE,
14 )
15 from django.db.models.sql.query import Query, get_order_dir
16 from django.db.transaction import TransactionManagementError
17 from django.utils.functional import cached_property
18 from django.utils.hashable import make_hashable
19 from django.utils.regex_helper import _lazy_re_compile
20 
21 
22 class SQLCompiler:
23     # Multiline ordering SQL clause may appear from RawSQL.
24     ordering_parts = _lazy_re_compile(
25         r'^(.*)\s(?:ASC|DESC).*',
26         re.MULTILINE | re.DOTALL,
27     )
28 
29     def __init__(self, query, connection, using):
30         self.query = query
31         self.connection = connection
32         self.using = using
33         self.quote_cache = {'*': '*'}
34         # The select, klass_info, and annotations are needed by QuerySet.iterator()
35         # these are set as a side-effect of executing the query. Note that we calculate
36         # separately a list of extra select columns needed for grammatical correctness
37         # of the query, but these columns are not included in self.select.
38         self.select = None
39         self.annotation_col_map = None
40         self.klass_info = None
41         self._meta_ordering = None
42 
43     def setup_query(self):
44         if all(self.query.alias_refcount[a] == 0 for a in self.query.alias_map):
45             self.query.get_initial_alias()
46         self.select, self.klass_info, self.annotation_col_map = self.get_select()
47         self.col_count = len(self.select)
48 
49     def pre_sql_setup(self):
50         """
51         Do any necessary class setup immediately prior to producing SQL. This
52         is for things that can't necessarily be done in __init__ because we
53         might not have all the pieces in place at that time.
54         """
55         self.setup_query()
56         order_by = self.get_order_by()
57         self.where, self.having = self.query.where.split_having()
58         extra_select = self.get_extra_select(order_by, self.select)
59         self.has_extra_select = bool(extra_select)
60         group_by = self.get_group_by(self.select + extra_select, order_by)
61         return extra_select, order_by, group_by
62 
63     def get_group_by(self, select, order_by):
64         """
65         Return a list of 2-tuples of form (sql, params).
66 
67         The logic of what exactly the GROUP BY clause contains is hard
68         to describe in other words than "if it passes the test suite,
69         then it is correct".
70         """
71         # Some examples:
72         #     SomeModel.objects.annotate(Count('somecol'))
73         #     GROUP BY: all fields of the model
74         #
75         #    SomeModel.objects.values('name').annotate(Count('somecol'))
76         #    GROUP BY: name
77         #
78         #    SomeModel.objects.annotate(Count('somecol')).values('name')
79         #    GROUP BY: all cols of the model
80         #
81         #    SomeModel.objects.values('name', 'pk').annotate(Count('somecol')).values('pk')
82         #    GROUP BY: name, pk
83         #
84         #    SomeModel.objects.values('name').annotate(Count('somecol')).values('pk')
85         #    GROUP BY: name, pk
86         #
87         # In fact, the self.query.group_by is the minimal set to GROUP BY. It
88         # can't be ever restricted to a smaller set, but additional columns in
89         # HAVING, ORDER BY, and SELECT clauses are added to it. Unfortunately
90         # the end result is that it is impossible to force the query to have
91         # a chosen GROUP BY clause - you can almost do this by using the form:
92         #     .values(*wanted_cols).annotate(AnAggregate())
93         # but any later annotations, extra selects, values calls that
94         # refer some column outside of the wanted_cols, order_by, or even
95         # filter calls can alter the GROUP BY clause.
96 
97         # The query.group_by is either None (no GROUP BY at all), True
98         # (group by select fields), or a list of expressions to be added
99         # to the group by.
100         if self.query.group_by is None:
101             return []
102         expressions = []
103         if self.query.group_by is not True:
104             # If the group by is set to a list (by .values() call most likely),
105             # then we need to add everything in it to the GROUP BY clause.
106             # Backwards compatibility hack for setting query.group_by. Remove
107             # when  we have public API way of forcing the GROUP BY clause.
108             # Converts string references to expressions.
109             for expr in self.query.group_by:
110                 if not hasattr(expr, 'as_sql'):
111                     expressions.append(self.query.resolve_ref(expr))
112                 else:
113                     expressions.append(expr)
114         # Note that even if the group_by is set, it is only the minimal
115         # set to group by. So, we need to add cols in select, order_by, and
116         # having into the select in any case.
117         ref_sources = {
118             expr.source for expr in expressions if isinstance(expr, Ref)
119         }
120         for expr, _, _ in select:
121             # Skip members of the select clause that are already included
122             # by reference.
123             if expr in ref_sources:
124                 continue
125             cols = expr.get_group_by_cols()
126             for col in cols:
127                 expressions.append(col)
128         for expr, (sql, params, is_ref) in order_by:
129             # Skip References to the select clause, as all expressions in the
130             # select clause are already part of the group by.
131             if not is_ref:
132                 expressions.extend(expr.get_group_by_cols())
133         having_group_by = self.having.get_group_by_cols() if self.having else ()
134         for expr in having_group_by:
135             expressions.append(expr)
136         result = []
137         seen = set()
138         expressions = self.collapse_group_by(expressions, having_group_by)
139 
140         for expr in expressions:
141             sql, params = self.compile(expr)
142             sql, params = expr.select_format(self, sql, params)
143             params_hash = make_hashable(params)
144             if (sql, params_hash) not in seen:
145                 result.append((sql, params))
146                 seen.add((sql, params_hash))
147         return result
148 
149     def collapse_group_by(self, expressions, having):
150         # If the DB can group by primary key, then group by the primary key of
151         # query's main model. Note that for PostgreSQL the GROUP BY clause must
152         # include the primary key of every table, but for MySQL it is enough to
153         # have the main table's primary key.
154         if self.connection.features.allows_group_by_pk:
155             # Determine if the main model's primary key is in the query.
156             pk = None
157             for expr in expressions:
158                 # Is this a reference to query's base table primary key? If the
159                 # expression isn't a Col-like, then skip the expression.
160                 if (getattr(expr, 'target', None) == self.query.model._meta.pk and
161                         getattr(expr, 'alias', None) == self.query.base_table):
162                     pk = expr
163                     break
164             # If the main model's primary key is in the query, group by that
165             # field, HAVING expressions, and expressions associated with tables
166             # that don't have a primary key included in the grouped columns.
167             if pk:
168                 pk_aliases = {
169                     expr.alias for expr in expressions
170                     if hasattr(expr, 'target') and expr.target.primary_key
171                 }
172                 expressions = [pk] + [
173                     expr for expr in expressions
174                     if expr in having or (
175                         getattr(expr, 'alias', None) is not None and expr.alias not in pk_aliases
176                     )
177                 ]
178         elif self.connection.features.allows_group_by_selected_pks:
179             # Filter out all expressions associated with a table's primary key
180             # present in the grouped columns. This is done by identifying all
181             # tables that have their primary key included in the grouped
182             # columns and removing non-primary key columns referring to them.
183             # Unmanaged models are excluded because they could be representing
184             # database views on which the optimization might not be allowed.
185             pks = {
186                 expr for expr in expressions
187                 if (
188                     hasattr(expr, 'target') and
189                     expr.target.primary_key and
190                     self.connection.features.allows_group_by_selected_pks_on_model(expr.target.model)
191                 )
192             }
193             aliases = {expr.alias for expr in pks}
194             expressions = [
195                 expr for expr in expressions if expr in pks or getattr(expr, 'alias', None) not in aliases
196             ]
197         return expressions
198 
199     def get_select(self):
200         """
201         Return three values:
202         - a list of 3-tuples of (expression, (sql, params), alias)
203         - a klass_info structure,
204         - a dictionary of annotations
205 
206         The (sql, params) is what the expression will produce, and alias is the
207         "AS alias" for the column (possibly None).
208 
209         The klass_info structure contains the following information:
210         - The base model of the query.
211         - Which columns for that model are present in the query (by
212           position of the select clause).
213         - related_klass_infos: [f, klass_info] to descent into
214 
215         The annotations is a dictionary of {'attname': column position} values.
216         """
217         select = []
218         klass_info = None
219         annotations = {}
220         select_idx = 0
221         for alias, (sql, params) in self.query.extra_select.items():
222             annotations[alias] = select_idx
223             select.append((RawSQL(sql, params), alias))
224             select_idx += 1
225         assert not (self.query.select and self.query.default_cols)
226         if self.query.default_cols:
227             cols = self.get_default_columns()
228         else:
229             # self.query.select is a special case. These columns never go to
230             # any model.
231             cols = self.query.select
232         if cols:
233             select_list = []
234             for col in cols:
235                 select_list.append(select_idx)
236                 select.append((col, None))
237                 select_idx += 1
238             klass_info = {
239                 'model': self.query.model,
240                 'select_fields': select_list,
241             }
242         for alias, annotation in self.query.annotation_select.items():
243             annotations[alias] = select_idx
244             select.append((annotation, alias))
245             select_idx += 1
246 
247         if self.query.select_related:
248             related_klass_infos = self.get_related_selections(select)
249             klass_info['related_klass_infos'] = related_klass_infos
250 
251             def get_select_from_parent(klass_info):
252                 for ki in klass_info['related_klass_infos']:
253                     if ki['from_parent']:
254                         ki['select_fields'] = (klass_info['select_fields'] +
255                                                ki['select_fields'])
256                     get_select_from_parent(ki)
257             get_select_from_parent(klass_info)
258 
259         ret = []
260         for col, alias in select:
261             try:
262                 sql, params = self.compile(col)
263             except EmptyResultSet:
264                 # Select a predicate that's always False.
265                 sql, params = '0', ()
266             else:
267                 sql, params = col.select_format(self, sql, params)
268             ret.append((col, (sql, params), alias))
269         return ret, klass_info, annotations
270 
271     def get_order_by(self):
272         """
273         Return a list of 2-tuples of form (expr, (sql, params, is_ref)) for the
274         ORDER BY clause.
275 
276         The order_by clause can alter the select clause (for example it
277         can add aliases to clauses that do not yet have one, or it can
278         add totally new select clauses).
279         """
280         if self.query.extra_order_by:
281             ordering = self.query.extra_order_by
282         elif not self.query.default_ordering:
283             ordering = self.query.order_by
284         elif self.query.order_by:
285             ordering = self.query.order_by
286         elif self.query.get_meta().ordering:
287             ordering = self.query.get_meta().ordering
288             self._meta_ordering = ordering
289         else:
290             ordering = []
291         if self.query.standard_ordering:
292             asc, desc = ORDER_DIR['ASC']
293         else:
294             asc, desc = ORDER_DIR['DESC']
295 
296         order_by = []
297         for field in ordering:
298             if hasattr(field, 'resolve_expression'):
299                 if isinstance(field, Value):
300                     # output_field must be resolved for constants.
301                     field = Cast(field, field.output_field)
302                 if not isinstance(field, OrderBy):
303                     field = field.asc()
304                 if not self.query.standard_ordering:
305                     field = field.copy()
306                     field.reverse_ordering()
307                 order_by.append((field, False))
308                 continue
309             if field == '?':  # random
310                 order_by.append((OrderBy(Random()), False))
311                 continue
312 
313             col, order = get_order_dir(field, asc)
314             descending = order == 'DESC'
315 
316             if col in self.query.annotation_select:
317                 # Reference to expression in SELECT clause
318                 order_by.append((
319                     OrderBy(Ref(col, self.query.annotation_select[col]), descending=descending),
320                     True))
321                 continue
322             if col in self.query.annotations:
323                 # References to an expression which is masked out of the SELECT
324                 # clause.
325                 expr = self.query.annotations[col]
326                 if isinstance(expr, Value):
327                     # output_field must be resolved for constants.
328                     expr = Cast(expr, expr.output_field)
329                 order_by.append((OrderBy(expr, descending=descending), False))
330                 continue
331 
332             if '.' in field:
333                 # This came in through an extra(order_by=...) addition. Pass it
334                 # on verbatim.
335                 table, col = col.split('.', 1)
336                 order_by.append((
337                     OrderBy(
338                         RawSQL('%s.%s' % (self.quote_name_unless_alias(table), col), []),
339                         descending=descending
340                     ), False))
341                 continue
342 
343             if not self.query.extra or col not in self.query.extra:
344                 # 'col' is of the form 'field' or 'field1__field2' or
345                 # '-field1__field2__field', etc.
346                 order_by.extend(self.find_ordering_name(
347                     field, self.query.get_meta(), default_order=asc))
348             else:
349                 if col not in self.query.extra_select:
350                     order_by.append((
351                         OrderBy(RawSQL(*self.query.extra[col]), descending=descending),
352                         False))
353                 else:
354                     order_by.append((
355                         OrderBy(Ref(col, RawSQL(*self.query.extra[col])), descending=descending),
356                         True))
357         result = []
358         seen = set()
359 
360         for expr, is_ref in order_by:
361             resolved = expr.resolve_expression(self.query, allow_joins=True, reuse=None)
362             if self.query.combinator:
363                 src = resolved.get_source_expressions()[0]
364                 expr_src = expr.get_source_expressions()[0]
365                 # Relabel order by columns to raw numbers if this is a combined
366                 # query; necessary since the columns can't be referenced by the
367                 # fully qualified name and the simple column names may collide.
368                 for idx, (sel_expr, _, col_alias) in enumerate(self.select):
369                     if is_ref and col_alias == src.refs:
370                         src = src.source
371                     elif col_alias and not (
372                         isinstance(expr_src, F) and col_alias == expr_src.name
373                     ):
374                         continue
375                     if src == sel_expr:
376                         resolved.set_source_expressions([RawSQL('%d' % (idx + 1), ())])
377                         break
378                 else:
379                     if col_alias:
380                         raise DatabaseError('ORDER BY term does not match any column in the result set.')
381                     # Add column used in ORDER BY clause without an alias to
382                     # the selected columns.
383                     self.query.add_select_col(src)
384                     resolved.set_source_expressions([RawSQL('%d' % len(self.query.select), ())])
385             sql, params = self.compile(resolved)
386             # Don't add the same column twice, but the order direction is
387             # not taken into account so we strip it. When this entire method
388             # is refactored into expressions, then we can check each part as we
389             # generate it.
390             without_ordering = self.ordering_parts.search(sql)[1]
391             params_hash = make_hashable(params)
392             if (without_ordering, params_hash) in seen:
393                 continue
394             seen.add((without_ordering, params_hash))
395             result.append((resolved, (sql, params, is_ref)))
396         return result
397 
398     def get_extra_select(self, order_by, select):
399         extra_select = []
400         if self.query.distinct and not self.query.distinct_fields:
401             select_sql = [t[1] for t in select]
402             for expr, (sql, params, is_ref) in order_by:
403                 without_ordering = self.ordering_parts.search(sql)[1]
404                 if not is_ref and (without_ordering, params) not in select_sql:
405                     extra_select.append((expr, (without_ordering, params), None))
406         return extra_select
407 
408     def quote_name_unless_alias(self, name):
409         """
410         A wrapper around connection.ops.quote_name that doesn't quote aliases
411         for table names. This avoids problems with some SQL dialects that treat
412         quoted strings specially (e.g. PostgreSQL).
413         """
414         if name in self.quote_cache:
415             return self.quote_cache[name]
416         if ((name in self.query.alias_map and name not in self.query.table_map) or
417                 name in self.query.extra_select or (
418                     self.query.external_aliases.get(name) and name not in self.query.table_map)):
419             self.quote_cache[name] = name
420             return name
421         r = self.connection.ops.quote_name(name)
422         self.quote_cache[name] = r
423         return r
424 
425     def compile(self, node):
426         vendor_impl = getattr(node, 'as_' + self.connection.vendor, None)
427         if vendor_impl:
428             sql, params = vendor_impl(self, self.connection)
429         else:
430             sql, params = node.as_sql(self, self.connection)
431         return sql, params
432 
433     def get_combinator_sql(self, combinator, all):
434         features = self.connection.features
435         compilers = [
436             query.get_compiler(self.using, self.connection)
437             for query in self.query.combined_queries if not query.is_empty()
438         ]
439         if not features.supports_slicing_ordering_in_compound:
440             for query, compiler in zip(self.query.combined_queries, compilers):
441                 if query.low_mark or query.high_mark:
442                     raise DatabaseError('LIMIT/OFFSET not allowed in subqueries of compound statements.')
443                 if compiler.get_order_by():
444                     raise DatabaseError('ORDER BY not allowed in subqueries of compound statements.')
445         parts = ()
446         for compiler in compilers:
447             try:
448                 # If the columns list is limited, then all combined queries
449                 # must have the same columns list. Set the selects defined on
450                 # the query on all combined queries, if not already set.
451                 if not compiler.query.values_select and self.query.values_select:
452                     compiler.query = compiler.query.clone()
453                     compiler.query.set_values((
454                         *self.query.extra_select,
455                         *self.query.values_select,
456                         *self.query.annotation_select,
457                     ))
458                 part_sql, part_args = compiler.as_sql()
459                 if compiler.query.combinator:
460                     # Wrap in a subquery if wrapping in parentheses isn't
461                     # supported.
462                     if not features.supports_parentheses_in_compound:
463                         part_sql = 'SELECT * FROM ({})'.format(part_sql)
464                     # Add parentheses when combining with compound query if not
465                     # already added for all compound queries.
466                     elif not features.supports_slicing_ordering_in_compound:
467                         part_sql = '({})'.format(part_sql)
468                 parts += ((part_sql, part_args),)
469             except EmptyResultSet:
470                 # Omit the empty queryset with UNION and with DIFFERENCE if the
471                 # first queryset is nonempty.
472                 if combinator == 'union' or (combinator == 'difference' and parts):
473                     continue
474                 raise
475         if not parts:
476             raise EmptyResultSet
477         combinator_sql = self.connection.ops.set_operators[combinator]
478         if all and combinator == 'union':
479             combinator_sql += ' ALL'
480         braces = '({})' if features.supports_slicing_ordering_in_compound else '{}'
481         sql_parts, args_parts = zip(*((braces.format(sql), args) for sql, args in parts))
482         result = [' {} '.format(combinator_sql).join(sql_parts)]
483         params = []
484         for part in args_parts:
485             params.extend(part)
486         return result, params
487 
488     def as_sql(self, with_limits=True, with_col_aliases=False):
489         """
490         Create the SQL for this query. Return the SQL string and list of
491         parameters.
492 
493         If 'with_limits' is False, any limit/offset information is not included
494         in the query.
495         """
496         refcounts_before = self.query.alias_refcount.copy()
497         try:
498             extra_select, order_by, group_by = self.pre_sql_setup()
499             for_update_part = None
500             # Is a LIMIT/OFFSET clause needed?
501             with_limit_offset = with_limits and (self.query.high_mark is not None or self.query.low_mark)
502             combinator = self.query.combinator
503             features = self.connection.features
504             if combinator:
505                 if not getattr(features, 'supports_select_{}'.format(combinator)):
506                     raise NotSupportedError('{} is not supported on this database backend.'.format(combinator))
507                 result, params = self.get_combinator_sql(combinator, self.query.combinator_all)
508             else:
509                 distinct_fields, distinct_params = self.get_distinct()
510                 # This must come after 'select', 'ordering', and 'distinct'
511                 # (see docstring of get_from_clause() for details).
512                 from_, f_params = self.get_from_clause()
513                 where, w_params = self.compile(self.where) if self.where is not None else ("", [])
514                 having, h_params = self.compile(self.having) if self.having is not None else ("", [])
515                 result = ['SELECT']
516                 params = []
517 
518                 if self.query.distinct:
519                     distinct_result, distinct_params = self.connection.ops.distinct_sql(
520                         distinct_fields,
521                         distinct_params,
522                     )
523                     result += distinct_result
524                     params += distinct_params
525 
526                 out_cols = []
527                 col_idx = 1
528                 for _, (s_sql, s_params), alias in self.select + extra_select:
529                     if alias:
530                         s_sql = '%s AS %s' % (s_sql, self.connection.ops.quote_name(alias))
531                     elif with_col_aliases:
532                         s_sql = '%s AS %s' % (s_sql, 'Col%d' % col_idx)
533                         col_idx += 1
534                     params.extend(s_params)
535                     out_cols.append(s_sql)
536 
537                 result += [', '.join(out_cols), 'FROM', *from_]
538                 params.extend(f_params)
539 
540                 if self.query.select_for_update and self.connection.features.has_select_for_update:
541                     if self.connection.get_autocommit():
542                         raise TransactionManagementError('select_for_update cannot be used outside of a transaction.')
543 
544                     if with_limit_offset and not self.connection.features.supports_select_for_update_with_limit:
545                         raise NotSupportedError(
546                             'LIMIT/OFFSET is not supported with '
547                             'select_for_update on this database backend.'
548                         )
549                     nowait = self.query.select_for_update_nowait
550                     skip_locked = self.query.select_for_update_skip_locked
551                     of = self.query.select_for_update_of
552                     no_key = self.query.select_for_no_key_update
553                     # If it's a NOWAIT/SKIP LOCKED/OF/NO KEY query but the
554                     # backend doesn't support it, raise NotSupportedError to
555                     # prevent a possible deadlock.
556                     if nowait and not self.connection.features.has_select_for_update_nowait:
557                         raise NotSupportedError('NOWAIT is not supported on this database backend.')
558                     elif skip_locked and not self.connection.features.has_select_for_update_skip_locked:
559                         raise NotSupportedError('SKIP LOCKED is not supported on this database backend.')
560                     elif of and not self.connection.features.has_select_for_update_of:
561                         raise NotSupportedError('FOR UPDATE OF is not supported on this database backend.')
562                     elif no_key and not self.connection.features.has_select_for_no_key_update:
563                         raise NotSupportedError(
564                             'FOR NO KEY UPDATE is not supported on this '
565                             'database backend.'
566                         )
567                     for_update_part = self.connection.ops.for_update_sql(
568                         nowait=nowait,
569                         skip_locked=skip_locked,
570                         of=self.get_select_for_update_of_arguments(),
571                         no_key=no_key,
572                     )
573 
574                 if for_update_part and self.connection.features.for_update_after_from:
575                     result.append(for_update_part)
576 
577                 if where:
578                     result.append('WHERE %s' % where)
579                     params.extend(w_params)
580 
581                 grouping = []
582                 for g_sql, g_params in group_by:
583                     grouping.append(g_sql)
584                     params.extend(g_params)
585                 if grouping:
586                     if distinct_fields:
587                         raise NotImplementedError('annotate() + distinct(fields) is not implemented.')
588                     order_by = order_by or self.connection.ops.force_no_ordering()
589                     result.append('GROUP BY %s' % ', '.join(grouping))
590                     if self._meta_ordering:
591                         order_by = None
592                 if having:
593                     result.append('HAVING %s' % having)
594                     params.extend(h_params)
595 
596             if self.query.explain_query:
597                 result.insert(0, self.connection.ops.explain_query_prefix(
598                     self.query.explain_format,
599                     **self.query.explain_options
600                 ))
601 
602             if order_by:
603                 ordering = []
604                 for _, (o_sql, o_params, _) in order_by:
605                     ordering.append(o_sql)
606                     params.extend(o_params)
607                 result.append('ORDER BY %s' % ', '.join(ordering))
608 
609             if with_limit_offset:
610                 result.append(self.connection.ops.limit_offset_sql(self.query.low_mark, self.query.high_mark))
611 
612             if for_update_part and not self.connection.features.for_update_after_from:
613                 result.append(for_update_part)
614 
615             if self.query.subquery and extra_select:
616                 # If the query is used as a subquery, the extra selects would
617                 # result in more columns than the left-hand side expression is
618                 # expecting. This can happen when a subquery uses a combination
619                 # of order_by() and distinct(), forcing the ordering expressions
620                 # to be selected as well. Wrap the query in another subquery
621                 # to exclude extraneous selects.
622                 sub_selects = []
623                 sub_params = []
624                 for index, (select, _, alias) in enumerate(self.select, start=1):
625                     if not alias and with_col_aliases:
626                         alias = 'col%d' % index
627                     if alias:
628                         sub_selects.append("%s.%s" % (
629                             self.connection.ops.quote_name('subquery'),
630                             self.connection.ops.quote_name(alias),
631                         ))
632                     else:
633                         select_clone = select.relabeled_clone({select.alias: 'subquery'})
634                         subselect, subparams = select_clone.as_sql(self, self.connection)
635                         sub_selects.append(subselect)
636                         sub_params.extend(subparams)
637                 return 'SELECT %s FROM (%s) subquery' % (
638                     ', '.join(sub_selects),
639                     ' '.join(result),
640                 ), tuple(sub_params + params)
641 
642             return ' '.join(result), tuple(params)
643         finally:
644             # Finally do cleanup - get rid of the joins we created above.
645             self.query.reset_refcounts(refcounts_before)
646 
647     def get_default_columns(self, start_alias=None, opts=None, from_parent=None):
648         """
649         Compute the default columns for selecting every field in the base
650         model. Will sometimes be called to pull in related models (e.g. via
651         select_related), in which case "opts" and "start_alias" will be given
652         to provide a starting point for the traversal.
653 
654         Return a list of strings, quoted appropriately for use in SQL
655         directly, as well as a set of aliases used in the select statement (if
656         'as_pairs' is True, return a list of (alias, col_name) pairs instead
657         of strings as the first component and None as the second component).
658         """
659         result = []
660         if opts is None:
661             opts = self.query.get_meta()
662         only_load = self.deferred_to_columns()
663         start_alias = start_alias or self.query.get_initial_alias()
664         # The 'seen_models' is used to optimize checking the needed parent
665         # alias for a given field. This also includes None -> start_alias to
666         # be used by local fields.
667         seen_models = {None: start_alias}
668 
669         for field in opts.concrete_fields:
670             model = field.model._meta.concrete_model
671             # A proxy model will have a different model and concrete_model. We
672             # will assign None if the field belongs to this model.
673             if model == opts.model:
674                 model = None
675             if from_parent and model is not None and issubclass(
676                     from_parent._meta.concrete_model, model._meta.concrete_model):
677                 # Avoid loading data for already loaded parents.
678                 # We end up here in the case select_related() resolution
679                 # proceeds from parent model to child model. In that case the
680                 # parent model data is already present in the SELECT clause,
681                 # and we want to avoid reloading the same data again.
682                 continue
683             if field.model in only_load and field.attname not in only_load[field.model]:
684                 continue
685             alias = self.query.join_parent_model(opts, model, start_alias,
686                                                  seen_models)
687             column = field.get_col(alias)
688             result.append(column)
689         return result
690 
691     def get_distinct(self):
692         """
693         Return a quoted list of fields to use in DISTINCT ON part of the query.
694 
695         This method can alter the tables in the query, and thus it must be
696         called before get_from_clause().
697         """
698         result = []
699         params = []
700         opts = self.query.get_meta()
701 
702         for name in self.query.distinct_fields:
703             parts = name.split(LOOKUP_SEP)
704             _, targets, alias, joins, path, _, transform_function = self._setup_joins(parts, opts, None)
705             targets, alias, _ = self.query.trim_joins(targets, joins, path)
706             for target in targets:
707                 if name in self.query.annotation_select:
708                     result.append(name)
709                 else:
710                     r, p = self.compile(transform_function(target, alias))
711                     result.append(r)
712                     params.append(p)
713         return result, params
714 
715     def find_ordering_name(self, name, opts, alias=None, default_order='ASC',
716                            already_seen=None):
717         """
718         Return the table alias (the name might be ambiguous, the alias will
719         not be) and column name for ordering by the given 'name' parameter.
720         The 'name' is of the form 'field1__field2__...__fieldN'.
721         """
722         name, order = get_order_dir(name, default_order)
723         descending = order == 'DESC'
724         pieces = name.split(LOOKUP_SEP)
725         field, targets, alias, joins, path, opts, transform_function = self._setup_joins(pieces, opts, alias)
726 
727         # If we get to this point and the field is a relation to another model,
728         # append the default ordering for that model unless it is the pk
729         # shortcut or the attribute name of the field that is specified.
730         if field.is_relation and opts.ordering and getattr(field, 'attname', None) != name and name != 'pk':
731             # Firstly, avoid infinite loops.
732             already_seen = already_seen or set()
733             join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)
734             if join_tuple in already_seen:
735                 raise FieldError('Infinite loop caused by ordering.')
736             already_seen.add(join_tuple)
737 
738             results = []
739             for item in opts.ordering:
740                 if hasattr(item, 'resolve_expression') and not isinstance(item, OrderBy):
741                     item = item.desc() if descending else item.asc()
742                 if isinstance(item, OrderBy):
743                     results.append((item, False))
744                     continue
745                 results.extend(self.find_ordering_name(item, opts, alias,
746                                                        order, already_seen))
747             return results
748         targets, alias, _ = self.query.trim_joins(targets, joins, path)
749         return [(OrderBy(transform_function(t, alias), descending=descending), False) for t in targets]
750 
751     def _setup_joins(self, pieces, opts, alias):
752         """
753         Helper method for get_order_by() and get_distinct().
754 
755         get_ordering() and get_distinct() must produce same target columns on
756         same input, as the prefixes of get_ordering() and get_distinct() must
757         match. Executing SQL where this is not true is an error.
758         """
759         alias = alias or self.query.get_initial_alias()
760         field, targets, opts, joins, path, transform_function = self.query.setup_joins(pieces, opts, alias)
761         alias = joins[-1]
762         return field, targets, alias, joins, path, opts, transform_function
763 
764     def get_from_clause(self):
765         """
766         Return a list of strings that are joined together to go after the
767         "FROM" part of the query, as well as a list any extra parameters that
768         need to be included. Subclasses, can override this to create a
769         from-clause via a "select".
770 
771         This should only be called after any SQL construction methods that
772         might change the tables that are needed. This means the select columns,
773         ordering, and distinct must be done first.
774         """
775         result = []
776         params = []
777         for alias in tuple(self.query.alias_map):
778             if not self.query.alias_refcount[alias]:
779                 continue
780             try:
781                 from_clause = self.query.alias_map[alias]
782             except KeyError:
783                 # Extra tables can end up in self.tables, but not in the
784                 # alias_map if they aren't in a join. That's OK. We skip them.
785                 continue
786             clause_sql, clause_params = self.compile(from_clause)
787             result.append(clause_sql)
788             params.extend(clause_params)
789         for t in self.query.extra_tables:
790             alias, _ = self.query.table_alias(t)
791             # Only add the alias if it's not already present (the table_alias()
792             # call increments the refcount, so an alias refcount of one means
793             # this is the only reference).
794             if alias not in self.query.alias_map or self.query.alias_refcount[alias] == 1:
795                 result.append(', %s' % self.quote_name_unless_alias(alias))
796         return result, params
797 
798     def get_related_selections(self, select, opts=None, root_alias=None, cur_depth=1,
799                                requested=None, restricted=None):
800         """
801         Fill in the information needed for a select_related query. The current
802         depth is measured as the number of connections away from the root model
803         (for example, cur_depth=1 means we are looking at models with direct
804         connections to the root model).
805         """
806         def _get_field_choices():
807             direct_choices = (f.name for f in opts.fields if f.is_relation)
808             reverse_choices = (
809                 f.field.related_query_name()
810                 for f in opts.related_objects if f.field.unique
811             )
812             return chain(direct_choices, reverse_choices, self.query._filtered_relations)
813 
814         related_klass_infos = []
815         if not restricted and cur_depth > self.query.max_depth:
816             # We've recursed far enough; bail out.
817             return related_klass_infos
818 
819         if not opts:
820             opts = self.query.get_meta()
821             root_alias = self.query.get_initial_alias()
822         only_load = self.query.get_loaded_field_names()
823 
824         # Setup for the case when only particular related fields should be
825         # included in the related selection.
826         fields_found = set()
827         if requested is None:
828             restricted = isinstance(self.query.select_related, dict)
829             if restricted:
830                 requested = self.query.select_related
831 
832         def get_related_klass_infos(klass_info, related_klass_infos):
833             klass_info['related_klass_infos'] = related_klass_infos
834 
835         for f in opts.fields:
836             field_model = f.model._meta.concrete_model
837             fields_found.add(f.name)
838 
839             if restricted:
840                 next = requested.get(f.name, {})
841                 if not f.is_relation:
842                     # If a non-related field is used like a relation,
843                     # or if a single non-relational field is given.
844                     if next or f.name in requested:
845                         raise FieldError(
846                             "Non-relational field given in select_related: '%s'. "
847                             "Choices are: %s" % (
848                                 f.name,
849                                 ", ".join(_get_field_choices()) or '(none)',
850                             )
851                         )
852             else:
853                 next = False
854 
855             if not select_related_descend(f, restricted, requested,
856                                           only_load.get(field_model)):
857                 continue
858             klass_info = {
859                 'model': f.remote_field.model,
860                 'field': f,
861                 'reverse': False,
862                 'local_setter': f.set_cached_value,
863                 'remote_setter': f.remote_field.set_cached_value if f.unique else lambda x, y: None,
864                 'from_parent': False,
865             }
866             related_klass_infos.append(klass_info)
867             select_fields = []
868             _, _, _, joins, _, _ = self.query.setup_joins(
869                 [f.name], opts, root_alias)
870             alias = joins[-1]
871             columns = self.get_default_columns(start_alias=alias, opts=f.remote_field.model._meta)
872             for col in columns:
873                 select_fields.append(len(select))
874                 select.append((col, None))
875             klass_info['select_fields'] = select_fields
876             next_klass_infos = self.get_related_selections(
877                 select, f.remote_field.model._meta, alias, cur_depth + 1, next, restricted)
878             get_related_klass_infos(klass_info, next_klass_infos)
879 
880         if restricted:
881             related_fields = [
882                 (o.field, o.related_model)
883                 for o in opts.related_objects
884                 if o.field.unique and not o.many_to_many
885             ]
886             for f, model in related_fields:
887                 if not select_related_descend(f, restricted, requested,
888                                               only_load.get(model), reverse=True):
889                     continue
890 
891                 related_field_name = f.related_query_name()
892                 fields_found.add(related_field_name)
893 
894                 join_info = self.query.setup_joins([related_field_name], opts, root_alias)
895                 alias = join_info.joins[-1]
896                 from_parent = issubclass(model, opts.model) and model is not opts.model
897                 klass_info = {
898                     'model': model,
899                     'field': f,
900                     'reverse': True,
901                     'local_setter': f.remote_field.set_cached_value,
902                     'remote_setter': f.set_cached_value,
903                     'from_parent': from_parent,
904                 }
905                 related_klass_infos.append(klass_info)
906                 select_fields = []
907                 columns = self.get_default_columns(
908                     start_alias=alias, opts=model._meta, from_parent=opts.model)
909                 for col in columns:
910                     select_fields.append(len(select))
911                     select.append((col, None))
912                 klass_info['select_fields'] = select_fields
913                 next = requested.get(f.related_query_name(), {})
914                 next_klass_infos = self.get_related_selections(
915                     select, model._meta, alias, cur_depth + 1,
916                     next, restricted)
917                 get_related_klass_infos(klass_info, next_klass_infos)
918 
919             def local_setter(obj, from_obj):
920                 # Set a reverse fk object when relation is non-empty.
921                 if from_obj:
922                     f.remote_field.set_cached_value(from_obj, obj)
923 
924             def remote_setter(name, obj, from_obj):
925                 setattr(from_obj, name, obj)
926 
927             for name in list(requested):
928                 # Filtered relations work only on the topmost level.
929                 if cur_depth > 1:
930                     break
931                 if name in self.query._filtered_relations:
932                     fields_found.add(name)
933                     f, _, join_opts, joins, _, _ = self.query.setup_joins([name], opts, root_alias)
934                     model = join_opts.model
935                     alias = joins[-1]
936                     from_parent = issubclass(model, opts.model) and model is not opts.model
937                     klass_info = {
938                         'model': model,
939                         'field': f,
940                         'reverse': True,
941                         'local_setter': local_setter,
942                         'remote_setter': partial(remote_setter, name),
943                         'from_parent': from_parent,
944                     }
945                     related_klass_infos.append(klass_info)
946                     select_fields = []
947                     columns = self.get_default_columns(
948                         start_alias=alias, opts=model._meta,
949                         from_parent=opts.model,
950                     )
951                     for col in columns:
952                         select_fields.append(len(select))
953                         select.append((col, None))
954                     klass_info['select_fields'] = select_fields
955                     next_requested = requested.get(name, {})
956                     next_klass_infos = self.get_related_selections(
957                         select, opts=model._meta, root_alias=alias,
958                         cur_depth=cur_depth + 1, requested=next_requested,
959                         restricted=restricted,
960                     )
961                     get_related_klass_infos(klass_info, next_klass_infos)
962             fields_not_found = set(requested).difference(fields_found)
963             if fields_not_found:
964                 invalid_fields = ("'%s'" % s for s in fields_not_found)
965                 raise FieldError(
966                     'Invalid field name(s) given in select_related: %s. '
967                     'Choices are: %s' % (
968                         ', '.join(invalid_fields),
969                         ', '.join(_get_field_choices()) or '(none)',
970                     )
971                 )
972         return related_klass_infos
973 
974     def get_select_for_update_of_arguments(self):
975         """
976         Return a quoted list of arguments for the SELECT FOR UPDATE OF part of
977         the query.
978         """
979         def _get_parent_klass_info(klass_info):
980             for parent_model, parent_link in klass_info['model']._meta.parents.items():
981                 parent_list = parent_model._meta.get_parent_list()
982                 yield {
983                     'model': parent_model,
984                     'field': parent_link,
985                     'reverse': False,
986                     'select_fields': [
987                         select_index
988                         for select_index in klass_info['select_fields']
989                         # Selected columns from a model or its parents.
990                         if (
991                             self.select[select_index][0].target.model == parent_model or
992                             self.select[select_index][0].target.model in parent_list
993                         )
994                     ],
995                 }
996 
997         def _get_first_selected_col_from_model(klass_info):
998             """
999             Find the first selected column from a model. If it doesn't exist,
1000             don't lock a model.
1001 
1002             select_fields is filled recursively, so it also contains fields
1003             from the parent models.
1004             """
1005             for select_index in klass_info['select_fields']:
1006                 if self.select[select_index][0].target.model == klass_info['model']:
1007                     return self.select[select_index][0]
1008 
1009         def _get_field_choices():
1010             """Yield all allowed field paths in breadth-first search order."""
1011             queue = collections.deque([(None, self.klass_info)])
1012             while queue:
1013                 parent_path, klass_info = queue.popleft()
1014                 if parent_path is None:
1015                     path = []
1016                     yield 'self'
1017                 else:
1018                     field = klass_info['field']
1019                     if klass_info['reverse']:
1020                         field = field.remote_field
1021                     path = parent_path + [field.name]
1022                     yield LOOKUP_SEP.join(path)
1023                 queue.extend(
1024                     (path, klass_info)
1025                     for klass_info in _get_parent_klass_info(klass_info)
1026                 )
1027                 queue.extend(
1028                     (path, klass_info)
1029                     for klass_info in klass_info.get('related_klass_infos', [])
1030                 )
1031         result = []
1032         invalid_names = []
1033         for name in self.query.select_for_update_of:
1034             klass_info = self.klass_info
1035             if name == 'self':
1036                 col = _get_first_selected_col_from_model(klass_info)
1037             else:
1038                 for part in name.split(LOOKUP_SEP):
1039                     klass_infos = (
1040                         *klass_info.get('related_klass_infos', []),
1041                         *_get_parent_klass_info(klass_info),
1042                     )
1043                     for related_klass_info in klass_infos:
1044                         field = related_klass_info['field']
1045                         if related_klass_info['reverse']:
1046                             field = field.remote_field
1047                         if field.name == part:
1048                             klass_info = related_klass_info
1049                             break
1050                     else:
1051                         klass_info = None
1052                         break
1053                 if klass_info is None:
1054                     invalid_names.append(name)
1055                     continue
1056                 col = _get_first_selected_col_from_model(klass_info)
1057             if col is not None:
1058                 if self.connection.features.select_for_update_of_column:
1059                     result.append(self.compile(col)[0])
1060                 else:
1061                     result.append(self.quote_name_unless_alias(col.alias))
1062         if invalid_names:
1063             raise FieldError(
1064                 'Invalid field name(s) given in select_for_update(of=(...)): %s. '
1065                 'Only relational fields followed in the query are allowed. '
1066                 'Choices are: %s.' % (
1067                     ', '.join(invalid_names),
1068                     ', '.join(_get_field_choices()),
1069                 )
1070             )
1071         return result
1072 
1073     def deferred_to_columns(self):
1074         """
1075         Convert the self.deferred_loading data structure to mapping of table
1076         names to sets of column names which are to be loaded. Return the
1077         dictionary.
1078         """
1079         columns = {}
1080         self.query.deferred_to_data(columns, self.query.get_loaded_field_names_cb)
1081         return columns
1082 
1083     def get_converters(self, expressions):
1084         converters = {}
1085         for i, expression in enumerate(expressions):
1086             if expression:
1087                 backend_converters = self.connection.ops.get_db_converters(expression)
1088                 field_converters = expression.get_db_converters(self.connection)
1089                 if backend_converters or field_converters:
1090                     converters[i] = (backend_converters + field_converters, expression)
1091         return converters
1092 
1093     def apply_converters(self, rows, converters):
1094         connection = self.connection
1095         converters = list(converters.items())
1096         for row in map(list, rows):
1097             for pos, (convs, expression) in converters:
1098                 value = row[pos]
1099                 for converter in convs:
1100                     value = converter(value, expression, connection)
1101                 row[pos] = value
1102             yield row
1103 
1104     def results_iter(self, results=None, tuple_expected=False, chunked_fetch=False,
1105                      chunk_size=GET_ITERATOR_CHUNK_SIZE):
1106         """Return an iterator over the results from executing this query."""
1107         if results is None:
1108             results = self.execute_sql(MULTI, chunked_fetch=chunked_fetch, chunk_size=chunk_size)
1109         fields = [s[0] for s in self.select[0:self.col_count]]
1110         converters = self.get_converters(fields)
1111         rows = chain.from_iterable(results)
1112         if converters:
1113             rows = self.apply_converters(rows, converters)
1114             if tuple_expected:
1115                 rows = map(tuple, rows)
1116         return rows
1117 
1118     def has_results(self):
1119         """
1120         Backends (e.g. NoSQL) can override this in order to use optimized
1121         versions of "query has any results."
1122         """
1123         # This is always executed on a query clone, so we can modify self.query
1124         self.query.add_extra({'a': 1}, None, None, None, None, None)
1125         self.query.set_extra_mask(['a'])
1126         return bool(self.execute_sql(SINGLE))
1127 
1128     def execute_sql(self, result_type=MULTI, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE):
1129         """
1130         Run the query against the database and return the result(s). The
1131         return value is a single data item if result_type is SINGLE, or an
1132         iterator over the results if the result_type is MULTI.
1133 
1134         result_type is either MULTI (use fetchmany() to retrieve all rows),
1135         SINGLE (only retrieve a single row), or None. In this last case, the
1136         cursor is returned if any query is executed, since it's used by
1137         subclasses such as InsertQuery). It's possible, however, that no query
1138         is needed, as the filters describe an empty set. In that case, None is
1139         returned, to avoid any unnecessary database interaction.
1140         """
1141         result_type = result_type or NO_RESULTS
1142         try:
1143             sql, params = self.as_sql()
1144             if not sql:
1145                 raise EmptyResultSet
1146         except EmptyResultSet:
1147             if result_type == MULTI:
1148                 return iter([])
1149             else:
1150                 return
1151         if chunked_fetch:
1152             cursor = self.connection.chunked_cursor()
1153         else:
1154             cursor = self.connection.cursor()
1155         try:
1156             cursor.execute(sql, params)
1157         except Exception:
1158             # Might fail for server-side cursors (e.g. connection closed)
1159             cursor.close()
1160             raise
1161 
1162         if result_type == CURSOR:
1163             # Give the caller the cursor to process and close.
1164             return cursor
1165         if result_type == SINGLE:
1166             try:
1167                 val = cursor.fetchone()
1168                 if val:
1169                     return val[0:self.col_count]
1170                 return val
1171             finally:
1172                 # done with the cursor
1173                 cursor.close()
1174         if result_type == NO_RESULTS:
1175             cursor.close()
1176             return
1177 
1178         result = cursor_iter(
1179             cursor, self.connection.features.empty_fetchmany_value,
1180             self.col_count if self.has_extra_select else None,
1181             chunk_size,
1182         )
1183         if not chunked_fetch or not self.connection.features.can_use_chunked_reads:
1184             try:
1185                 # If we are using non-chunked reads, we return the same data
1186                 # structure as normally, but ensure it is all read into memory
1187                 # before going any further. Use chunked_fetch if requested,
1188                 # unless the database doesn't support it.
1189                 return list(result)
1190             finally:
1191                 # done with the cursor
1192                 cursor.close()
1193         return result
1194 
1195     def as_subquery_condition(self, alias, columns, compiler):
1196         qn = compiler.quote_name_unless_alias
1197         qn2 = self.connection.ops.quote_name
1198 
1199         for index, select_col in enumerate(self.query.select):
1200             lhs_sql, lhs_params = self.compile(select_col)
1201             rhs = '%s.%s' % (qn(alias), qn2(columns[index]))
1202             self.query.where.add(
1203                 RawSQL('%s = %s' % (lhs_sql, rhs), lhs_params), 'AND')
1204 
1205         sql, params = self.as_sql()
1206         return 'EXISTS (%s)' % sql, params
1207 
1208     def explain_query(self):
1209         result = list(self.execute_sql())
1210         # Some backends return 1 item tuples with strings, and others return
1211         # tuples with integers and strings. Flatten them out into strings.
1212         for row in result[0]:
1213             if not isinstance(row, str):
1214                 yield ' '.join(str(c) for c in row)
1215             else:
1216                 yield row
1217 
1218 
1219 class SQLInsertCompiler(SQLCompiler):
1220     returning_fields = None
1221     returning_params = tuple()
1222 
1223     def field_as_sql(self, field, val):
1224         """
1225         Take a field and a value intended to be saved on that field, and
1226         return placeholder SQL and accompanying params. Check for raw values,
1227         expressions, and fields with get_placeholder() defined in that order.
1228 
1229         When field is None, consider the value raw and use it as the
1230         placeholder, with no corresponding parameters returned.
1231         """
1232         if field is None:
1233             # A field value of None means the value is raw.
1234             sql, params = val, []
1235         elif hasattr(val, 'as_sql'):
1236             # This is an expression, let's compile it.
1237             sql, params = self.compile(val)
1238         elif hasattr(field, 'get_placeholder'):
1239             # Some fields (e.g. geo fields) need special munging before
1240             # they can be inserted.
1241             sql, params = field.get_placeholder(val, self, self.connection), [val]
1242         else:
1243             # Return the common case for the placeholder
1244             sql, params = '%s', [val]
1245 
1246         # The following hook is only used by Oracle Spatial, which sometimes
1247         # needs to yield 'NULL' and [] as its placeholder and params instead
1248         # of '%s' and [None]. The 'NULL' placeholder is produced earlier by
1249         # OracleOperations.get_geom_placeholder(). The following line removes
1250         # the corresponding None parameter. See ticket #10888.
1251         params = self.connection.ops.modify_insert_params(sql, params)
1252 
1253         return sql, params
1254 
1255     def prepare_value(self, field, value):
1256         """
1257         Prepare a value to be used in a query by resolving it if it is an
1258         expression and otherwise calling the field's get_db_prep_save().
1259         """
1260         if hasattr(value, 'resolve_expression'):
1261             value = value.resolve_expression(self.query, allow_joins=False, for_save=True)
1262             # Don't allow values containing Col expressions. They refer to
1263             # existing columns on a row, but in the case of insert the row
1264             # doesn't exist yet.
1265             if value.contains_column_references:
1266                 raise ValueError(
1267                     'Failed to insert expression "%s" on %s. F() expressions '
1268                     'can only be used to update, not to insert.' % (value, field)
1269                 )
1270             if value.contains_aggregate:
1271                 raise FieldError(
1272                     'Aggregate functions are not allowed in this query '
1273                     '(%s=%r).' % (field.name, value)
1274                 )
1275             if value.contains_over_clause:
1276                 raise FieldError(
1277                     'Window expressions are not allowed in this query (%s=%r).'
1278                     % (field.name, value)
1279                 )
1280         else:
1281             value = field.get_db_prep_save(value, connection=self.connection)
1282         return value
1283 
1284     def pre_save_val(self, field, obj):
1285         """
1286         Get the given field's value off the given obj. pre_save() is used for
1287         things like auto_now on DateTimeField. Skip it if this is a raw query.
1288         """
1289         if self.query.raw:
1290             return getattr(obj, field.attname)
1291         return field.pre_save(obj, add=True)
1292 
1293     def assemble_as_sql(self, fields, value_rows):
1294         """
1295         Take a sequence of N fields and a sequence of M rows of values, and
1296         generate placeholder SQL and parameters for each field and value.
1297         Return a pair containing:
1298          * a sequence of M rows of N SQL placeholder strings, and
1299          * a sequence of M rows of corresponding parameter values.
1300 
1301         Each placeholder string may contain any number of '%s' interpolation
1302         strings, and each parameter row will contain exactly as many params
1303         as the total number of '%s's in the corresponding placeholder row.
1304         """
1305         if not value_rows:
1306             return [], []
1307 
1308         # list of (sql, [params]) tuples for each object to be saved
1309         # Shape: [n_objs][n_fields][2]
1310         rows_of_fields_as_sql = (
1311             (self.field_as_sql(field, v) for field, v in zip(fields, row))
1312             for row in value_rows
1313         )
1314 
1315         # tuple like ([sqls], [[params]s]) for each object to be saved
1316         # Shape: [n_objs][2][n_fields]
1317         sql_and_param_pair_rows = (zip(*row) for row in rows_of_fields_as_sql)
1318 
1319         # Extract separate lists for placeholders and params.
1320         # Each of these has shape [n_objs][n_fields]
1321         placeholder_rows, param_rows = zip(*sql_and_param_pair_rows)
1322 
1323         # Params for each field are still lists, and need to be flattened.
1324         param_rows = [[p for ps in row for p in ps] for row in param_rows]
1325 
1326         return placeholder_rows, param_rows
1327 
1328     def as_sql(self):
1329         # We don't need quote_name_unless_alias() here, since these are all
1330         # going to be column names (so we can avoid the extra overhead).
1331         qn = self.connection.ops.quote_name
1332         opts = self.query.get_meta()
1333         insert_statement = self.connection.ops.insert_statement(ignore_conflicts=self.query.ignore_conflicts)
1334         result = ['%s %s' % (insert_statement, qn(opts.db_table))]
1335         fields = self.query.fields or [opts.pk]
1336         result.append('(%s)' % ', '.join(qn(f.column) for f in fields))
1337 
1338         if self.query.fields:
1339             value_rows = [
1340                 [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
1341                 for obj in self.query.objs
1342             ]
1343         else:
1344             # An empty object.
1345             value_rows = [[self.connection.ops.pk_default_value()] for _ in self.query.objs]
1346             fields = [None]
1347 
1348         # Currently the backends just accept values when generating bulk
1349         # queries and generate their own placeholders. Doing that isn't
1350         # necessary and it should be possible to use placeholders and
1351         # expressions in bulk inserts too.
1352         can_bulk = (not self.returning_fields and self.connection.features.has_bulk_insert)
1353 
1354         placeholder_rows, param_rows = self.assemble_as_sql(fields, value_rows)
1355 
1356         ignore_conflicts_suffix_sql = self.connection.ops.ignore_conflicts_suffix_sql(
1357             ignore_conflicts=self.query.ignore_conflicts
1358         )
1359         if self.returning_fields and self.connection.features.can_return_columns_from_insert:
1360             if self.connection.features.can_return_rows_from_bulk_insert:
1361                 result.append(self.connection.ops.bulk_insert_sql(fields, placeholder_rows))
1362                 params = param_rows
1363             else:
1364                 result.append("VALUES (%s)" % ", ".join(placeholder_rows[0]))
1365                 params = [param_rows[0]]
1366             if ignore_conflicts_suffix_sql:
1367                 result.append(ignore_conflicts_suffix_sql)
1368             # Skip empty r_sql to allow subclasses to customize behavior for
1369             # 3rd party backends. Refs #19096.
1370             r_sql, self.returning_params = self.connection.ops.return_insert_columns(self.returning_fields)
1371             if r_sql:
1372                 result.append(r_sql)
1373                 params += [self.returning_params]
1374             return [(" ".join(result), tuple(chain.from_iterable(params)))]
1375 
1376         if can_bulk:
1377             result.append(self.connection.ops.bulk_insert_sql(fields, placeholder_rows))
1378             if ignore_conflicts_suffix_sql:
1379                 result.append(ignore_conflicts_suffix_sql)
1380             return [(" ".join(result), tuple(p for ps in param_rows for p in ps))]
1381         else:
1382             if ignore_conflicts_suffix_sql:
1383                 result.append(ignore_conflicts_suffix_sql)
1384             return [
1385                 (" ".join(result + ["VALUES (%s)" % ", ".join(p)]), vals)
1386                 for p, vals in zip(placeholder_rows, param_rows)
1387             ]
1388 
1389     def execute_sql(self, returning_fields=None):
1390         assert not (
1391             returning_fields and len(self.query.objs) != 1 and
1392             not self.connection.features.can_return_rows_from_bulk_insert
1393         )
1394         self.returning_fields = returning_fields
1395         with self.connection.cursor() as cursor:
1396             for sql, params in self.as_sql():
1397                 cursor.execute(sql, params)
1398             if not self.returning_fields:
1399                 return []
1400             if self.connection.features.can_return_rows_from_bulk_insert and len(self.query.objs) > 1:
1401                 return self.connection.ops.fetch_returned_insert_rows(cursor)
1402             if self.connection.features.can_return_columns_from_insert:
1403                 assert len(self.query.objs) == 1
1404                 return [self.connection.ops.fetch_returned_insert_columns(cursor, self.returning_params)]
1405             return [(self.connection.ops.last_insert_id(
1406                 cursor, self.query.get_meta().db_table, self.query.get_meta().pk.column
1407             ),)]
1408 
1409 
1410 class SQLDeleteCompiler(SQLCompiler):
1411     @cached_property
1412     def single_alias(self):
1413         # Ensure base table is in aliases.
1414         self.query.get_initial_alias()
1415         return sum(self.query.alias_refcount[t] > 0 for t in self.query.alias_map) == 1
1416 
1417     def _as_sql(self, query):
1418         result = [
1419             'DELETE FROM %s' % self.quote_name_unless_alias(query.base_table)
1420         ]
1421         where, params = self.compile(query.where)
1422         if where:
1423             result.append('WHERE %s' % where)
1424         return ' '.join(result), tuple(params)
1425 
1426     def as_sql(self):
1427         """
1428         Create the SQL for this query. Return the SQL string and list of
1429         parameters.
1430         """
1431         if self.single_alias:
1432             return self._as_sql(self.query)
1433         innerq = self.query.clone()
1434         innerq.__class__ = Query
1435         innerq.clear_select_clause()
1436         pk = self.query.model._meta.pk
1437         innerq.select = [
1438             pk.get_col(self.query.get_initial_alias())
1439         ]
1440         outerq = Query(self.query.model)
1441         outerq.where = self.query.where_class()
1442         outerq.add_q(Q(pk__in=innerq))
1443         return self._as_sql(outerq)
1444 
1445 
1446 class SQLUpdateCompiler(SQLCompiler):
1447     def as_sql(self):
1448         """
1449         Create the SQL for this query. Return the SQL string and list of
1450         parameters.
1451         """
1452         self.pre_sql_setup()
1453         if not self.query.values:
1454             return '', ()
1455         qn = self.quote_name_unless_alias
1456         values, update_params = [], []
1457         for field, model, val in self.query.values:
1458             if hasattr(val, 'resolve_expression'):
1459                 val = val.resolve_expression(self.query, allow_joins=False, for_save=True)
1460                 if val.contains_aggregate:
1461                     raise FieldError(
1462                         'Aggregate functions are not allowed in this query '
1463                         '(%s=%r).' % (field.name, val)
1464                     )
1465                 if val.contains_over_clause:
1466                     raise FieldError(
1467                         'Window expressions are not allowed in this query '
1468                         '(%s=%r).' % (field.name, val)
1469                     )
1470             elif hasattr(val, 'prepare_database_save'):
1471                 if field.remote_field:
1472                     val = field.get_db_prep_save(
1473                         val.prepare_database_save(field),
1474                         connection=self.connection,
1475                     )
1476                 else:
1477                     raise TypeError(
1478                         "Tried to update field %s with a model instance, %r. "
1479                         "Use a value compatible with %s."
1480                         % (field, val, field.__class__.__name__)
1481                     )
1482             else:
1483                 val = field.get_db_prep_save(val, connection=self.connection)
1484 
1485             # Getting the placeholder for the field.
1486             if hasattr(field, 'get_placeholder'):
1487                 placeholder = field.get_placeholder(val, self, self.connection)
1488             else:
1489                 placeholder = '%s'
1490             name = field.column
1491             if hasattr(val, 'as_sql'):
1492                 sql, params = self.compile(val)
1493                 values.append('%s = %s' % (qn(name), placeholder % sql))
1494                 update_params.extend(params)
1495             elif val is not None:
1496                 values.append('%s = %s' % (qn(name), placeholder))
1497                 update_params.append(val)
1498             else:
1499                 values.append('%s = NULL' % qn(name))
1500         table = self.query.base_table
1501         result = [
1502             'UPDATE %s SET' % qn(table),
1503             ', '.join(values),
1504         ]
1505         where, params = self.compile(self.query.where)
1506         if where:
1507             result.append('WHERE %s' % where)
1508         return ' '.join(result), tuple(update_params + params)
1509 
1510     def execute_sql(self, result_type):
1511         """
1512         Execute the specified update. Return the number of rows affected by
1513         the primary update query. The "primary update query" is the first
1514         non-empty query that is executed. Row counts for any subsequent,
1515         related queries are not available.
1516         """
1517         cursor = super().execute_sql(result_type)
1518         try:
1519             rows = cursor.rowcount if cursor else 0
1520             is_empty = cursor is None
1521         finally:
1522             if cursor:
1523                 cursor.close()
1524         for query in self.query.get_related_updates():
1525             aux_rows = query.get_compiler(self.using).execute_sql(result_type)
1526             if is_empty and aux_rows:
1527                 rows = aux_rows
1528                 is_empty = False
1529         return rows
1530 
1531     def pre_sql_setup(self):
1532         """
1533         If the update depends on results from other tables, munge the "where"
1534         conditions to match the format required for (portable) SQL updates.
1535 
1536         If multiple updates are required, pull out the id values to update at
1537         this point so that they don't change as a result of the progressive
1538         updates.
1539         """
1540         refcounts_before = self.query.alias_refcount.copy()
1541         # Ensure base table is in the query
1542         self.query.get_initial_alias()
1543         count = self.query.count_active_tables()
1544         if not self.query.related_updates and count == 1:
1545             return
1546         query = self.query.chain(klass=Query)
1547         query.select_related = False
1548         query.clear_ordering(True)
1549         query.extra = {}
1550         query.select = []
1551         query.add_fields([query.get_meta().pk.name])
1552         super().pre_sql_setup()
1553 
1554         must_pre_select = count > 1 and not self.connection.features.update_can_self_select
1555 
1556         # Now we adjust the current query: reset the where clause and get rid
1557         # of all the tables we don't need (since they're in the sub-select).
1558         self.query.where = self.query.where_class()
1559         if self.query.related_updates or must_pre_select:
1560             # Either we're using the idents in multiple update queries (so
1561             # don't want them to change), or the db backend doesn't support
1562             # selecting from the updating table (e.g. MySQL).
1563             idents = []
1564             for rows in query.get_compiler(self.using).execute_sql(MULTI):
1565                 idents.extend(r[0] for r in rows)
1566             self.query.add_filter(('pk__in', idents))
1567             self.query.related_ids = idents
1568         else:
1569             # The fast path. Filters and updates in one query.
1570             self.query.add_filter(('pk__in', query))
1571         self.query.reset_refcounts(refcounts_before)
1572 
1573 
1574 class SQLAggregateCompiler(SQLCompiler):
1575     def as_sql(self):
1576         """
1577         Create the SQL for this query. Return the SQL string and list of
1578         parameters.
1579         """
1580         sql, params = [], []
1581         for annotation in self.query.annotation_select.values():
1582             ann_sql, ann_params = self.compile(annotation)
1583             ann_sql, ann_params = annotation.select_format(self, ann_sql, ann_params)
1584             sql.append(ann_sql)
1585             params.extend(ann_params)
1586         self.col_count = len(self.query.annotation_select)
1587         sql = ', '.join(sql)
1588         params = tuple(params)
1589 
1590         sql = 'SELECT %s FROM (%s) subquery' % (sql, self.query.subquery)
1591         params = params + self.query.sub_params
1592         return sql, params
1593 
1594 
1595 def cursor_iter(cursor, sentinel, col_count, itersize):
1596     """
1597     Yield blocks of rows from a cursor and ensure the cursor is closed when
1598     done.
1599     """
1600     try:
1601         for rows in iter((lambda: cursor.fetchmany(itersize)), sentinel):
1602             yield rows if col_count is None else [r[:col_count] for r in rows]
1603     finally:
1604         cursor.close()

</code><intended_behavior>The GROUP BY assembling logic within this file should be revised to correctly handle constant expressions, particularly those wrapped in ExpressionWrapper. This involves ensuring that such expressions do not result in a GROUP BY clause that includes constants, as this is invalid in SQL queries for certain databases (like PostgreSQL). The intended behavior should allow for constants to be included in the SELECT part of the query without being added to GROUP BY, maintaining correct query results while adhering to SQL standards.</intended_behavior>]
2025-10-15 04:52:10.549 | INFO     | Overall retry 0 succeeded; ending workflow
2025-10-15 04:52:10.549 | INFO     | Search-only: skipping patch selection
2025-10-15 04:52:10.695 | INFO     | Task django__django-13012 completed successfully.
2025-10-15 04:52:10.696 | INFO     | No patch generated. You can try running ACR again.
