[
    {
        "rel_file_path": "pylint/lint/parallel.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/pylint-dev__pylint/setup_pylint-dev__pylint__3.0/pylint/lint/parallel.py",
        "start": 1,
        "end": 173,
        "class_name": null,
        "method_name": null,
        "code": "1 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html\n2 # For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE\n3 # Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt\n4 \n5 from __future__ import annotations\n6 \n7 import functools\n8 from collections import defaultdict\n9 from collections.abc import Iterable, Sequence\n10 from typing import TYPE_CHECKING, Any\n11 \n12 import dill\n13 \n14 from pylint import reporters\n15 from pylint.lint.utils import _augment_sys_path\n16 from pylint.message import Message\n17 from pylint.typing import FileItem\n18 from pylint.utils import LinterStats, merge_stats\n19 \n20 try:\n21     import multiprocessing\n22 except ImportError:\n23     multiprocessing = None  # type: ignore[assignment]\n24 \n25 try:\n26     from concurrent.futures import ProcessPoolExecutor\n27 except ImportError:\n28     ProcessPoolExecutor = None  # type: ignore[assignment,misc]\n29 \n30 if TYPE_CHECKING:\n31     from pylint.lint import PyLinter\n32 \n33 # PyLinter object used by worker processes when checking files using parallel mode\n34 # should only be used by the worker processes\n35 _worker_linter: PyLinter | None = None\n36 \n37 \n38 def _worker_initialize(\n39     linter: bytes, extra_packages_paths: Sequence[str] | None = None\n40 ) -> None:\n41     \"\"\"Function called to initialize a worker for a Process within a concurrent Pool.\n42 \n43     :param linter: A linter-class (PyLinter) instance pickled with dill\n44     :param extra_packages_paths: Extra entries to be added to `sys.path`\n45     \"\"\"\n46     global _worker_linter  # pylint: disable=global-statement\n47     _worker_linter = dill.loads(linter)\n48     assert _worker_linter\n49 \n50     # On the worker process side the messages are just collected and passed back to\n51     # parent process as _worker_check_file function's return value\n52     _worker_linter.set_reporter(reporters.CollectingReporter())\n53     _worker_linter.open()\n54 \n55     # Re-register dynamic plugins, since the pool does not have access to the\n56     # astroid module that existed when the linter was pickled.\n57     _worker_linter.load_plugin_modules(_worker_linter._dynamic_plugins, force=True)\n58     _worker_linter.load_plugin_configuration()\n59 \n60     if extra_packages_paths:\n61         _augment_sys_path(extra_packages_paths)\n62 \n63 \n64 def _worker_check_single_file(\n65     file_item: FileItem,\n66 ) -> tuple[\n67     int,\n68     str,\n69     str,\n70     str,\n71     list[Message],\n72     LinterStats,\n73     int,\n74     defaultdict[str, list[Any]],\n75 ]:\n76     if not _worker_linter:\n77         raise RuntimeError(\"Worker linter not yet initialised\")\n78     _worker_linter.open()\n79     _worker_linter.check_single_file_item(file_item)\n80     mapreduce_data = defaultdict(list)\n81     for checker in _worker_linter.get_checkers():\n82         data = checker.get_map_data()\n83         if data is not None:\n84             mapreduce_data[checker.name].append(data)\n85     msgs = _worker_linter.reporter.messages\n86     assert isinstance(_worker_linter.reporter, reporters.CollectingReporter)\n87     _worker_linter.reporter.reset()\n88     return (\n89         id(multiprocessing.current_process()),\n90         _worker_linter.current_name,\n91         file_item.filepath,\n92         _worker_linter.file_state.base_name,\n93         msgs,\n94         _worker_linter.stats,\n95         _worker_linter.msg_status,\n96         mapreduce_data,\n97     )\n98 \n99 \n100 def _merge_mapreduce_data(\n101     linter: PyLinter,\n102     all_mapreduce_data: defaultdict[int, list[defaultdict[str, list[Any]]]],\n103 ) -> None:\n104     \"\"\"Merges map/reduce data across workers, invoking relevant APIs on checkers.\"\"\"\n105     # First collate the data and prepare it, so we can send it to the checkers for\n106     # validation. The intent here is to collect all the mapreduce data for all checker-\n107     # runs across processes - that will then be passed to a static method on the\n108     # checkers to be reduced and further processed.\n109     collated_map_reduce_data: defaultdict[str, list[Any]] = defaultdict(list)\n110     for linter_data in all_mapreduce_data.values():\n111         for run_data in linter_data:\n112             for checker_name, data in run_data.items():\n113                 collated_map_reduce_data[checker_name].extend(data)\n114 \n115     # Send the data to checkers that support/require consolidated data\n116     original_checkers = linter.get_checkers()\n117     for checker in original_checkers:\n118         if checker.name in collated_map_reduce_data:\n119             # Assume that if the check has returned map/reduce data that it has the\n120             # reducer function\n121             checker.reduce_map_data(linter, collated_map_reduce_data[checker.name])\n122 \n123 \n124 def check_parallel(\n125     linter: PyLinter,\n126     jobs: int,\n127     files: Iterable[FileItem],\n128     extra_packages_paths: Sequence[str] | None = None,\n129 ) -> None:\n130     \"\"\"Use the given linter to lint the files with given amount of workers (jobs).\n131 \n132     This splits the work filestream-by-filestream. If you need to do work across\n133     multiple files, as in the similarity-checker, then implement the map/reduce mixin functionality.\n134     \"\"\"\n135     # The linter is inherited by all the pool's workers, i.e. the linter\n136     # is identical to the linter object here. This is required so that\n137     # a custom PyLinter object can be used.\n138     initializer = functools.partial(\n139         _worker_initialize, extra_packages_paths=extra_packages_paths\n140     )\n141     with ProcessPoolExecutor(\n142         max_workers=jobs, initializer=initializer, initargs=(dill.dumps(linter),)\n143     ) as executor:\n144         linter.open()\n145         all_stats = []\n146         all_mapreduce_data: defaultdict[\n147             int, list[defaultdict[str, list[Any]]]\n148         ] = defaultdict(list)\n149 \n150         # Maps each file to be worked on by a single _worker_check_single_file() call,\n151         # collecting any map/reduce data by checker module so that we can 'reduce' it\n152         # later.\n153         for (\n154             worker_idx,  # used to merge map/reduce data across workers\n155             module,\n156             file_path,\n157             base_name,\n158             messages,\n159             stats,\n160             msg_status,\n161             mapreduce_data,\n162         ) in executor.map(_worker_check_single_file, files):\n163             linter.file_state.base_name = base_name\n164             linter.file_state._is_base_filestate = False\n165             linter.set_current_module(module, file_path)\n166             for msg in messages:\n167                 linter.reporter.handle_message(msg)\n168             all_stats.append(stats)\n169             all_mapreduce_data[worker_idx].append(mapreduce_data)\n170             linter.msg_status |= msg_status\n171 \n172     _merge_mapreduce_data(linter, all_mapreduce_data)\n173     linter.stats = merge_stats([linter.stats, *all_stats])\n",
        "intended_behavior": "When distributing tasks for linting in parallel, the division should ensure that all parts of the codebase are covered without overlaps or omissions. The aggregation of results from these tasks must accurately collect and combine all findings. It might need a review of the task distribution logic and result aggregation to prevent any loss of lint messages or inconsistencies in the output."
    },
    {
        "rel_file_path": "pylint/lint/pylinter.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/pylint-dev__pylint/setup_pylint-dev__pylint__3.0/pylint/lint/pylinter.py",
        "start": 1,
        "end": 1304,
        "class_name": null,
        "method_name": null,
        "code": "1 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html\n2 # For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE\n3 # Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt\n4 \n5 from __future__ import annotations\n6 \n7 import argparse\n8 import collections\n9 import contextlib\n10 import functools\n11 import os\n12 import sys\n13 import tokenize\n14 import traceback\n15 from collections import defaultdict\n16 from collections.abc import Callable, Iterable, Iterator, Sequence\n17 from io import TextIOWrapper\n18 from pathlib import Path\n19 from re import Pattern\n20 from types import ModuleType\n21 from typing import Any, Protocol\n22 \n23 import astroid\n24 from astroid import nodes\n25 \n26 from pylint import checkers, exceptions, interfaces, reporters\n27 from pylint.checkers.base_checker import BaseChecker\n28 from pylint.config.arguments_manager import _ArgumentsManager\n29 from pylint.constants import (\n30     MAIN_CHECKER_NAME,\n31     MSG_TYPES,\n32     MSG_TYPES_STATUS,\n33     WarningScope,\n34 )\n35 from pylint.interfaces import HIGH\n36 from pylint.lint.base_options import _make_linter_options\n37 from pylint.lint.caching import load_results, save_results\n38 from pylint.lint.expand_modules import (\n39     _is_ignored_file,\n40     discover_package_path,\n41     expand_modules,\n42 )\n43 from pylint.lint.message_state_handler import _MessageStateHandler\n44 from pylint.lint.parallel import check_parallel\n45 from pylint.lint.report_functions import (\n46     report_messages_by_module_stats,\n47     report_messages_stats,\n48     report_total_messages_stats,\n49 )\n50 from pylint.lint.utils import (\n51     _is_relative_to,\n52     augmented_sys_path,\n53     get_fatal_error_message,\n54     prepare_crash_report,\n55 )\n56 from pylint.message import Message, MessageDefinition, MessageDefinitionStore\n57 from pylint.reporters.base_reporter import BaseReporter\n58 from pylint.reporters.text import TextReporter\n59 from pylint.reporters.ureports import nodes as report_nodes\n60 from pylint.typing import (\n61     DirectoryNamespaceDict,\n62     FileItem,\n63     ManagedMessage,\n64     MessageDefinitionTuple,\n65     MessageLocationTuple,\n66     ModuleDescriptionDict,\n67     Options,\n68 )\n69 from pylint.utils import ASTWalker, FileState, LinterStats, utils\n70 \n71 MANAGER = astroid.MANAGER\n72 \n73 \n74 class GetAstProtocol(Protocol):\n75     def __call__(\n76         self, filepath: str, modname: str, data: str | None = None\n77     ) -> nodes.Module:\n78         ...\n79 \n80 \n81 def _read_stdin() -> str:\n82     # See https://github.com/python/typeshed/pull/5623 for rationale behind assertion\n83     assert isinstance(sys.stdin, TextIOWrapper)\n84     sys.stdin = TextIOWrapper(sys.stdin.detach(), encoding=\"utf-8\")\n85     return sys.stdin.read()\n86 \n87 \n88 def _load_reporter_by_class(reporter_class: str) -> type[BaseReporter]:\n89     qname = reporter_class\n90     module_part = astroid.modutils.get_module_part(qname)\n91     module = astroid.modutils.load_module_from_name(module_part)\n92     class_name = qname.split(\".\")[-1]\n93     klass = getattr(module, class_name)\n94     assert issubclass(klass, BaseReporter), f\"{klass} is not a BaseReporter\"\n95     return klass  # type: ignore[no-any-return]\n96 \n97 \n98 # Python Linter class #########################################################\n99 \n100 # pylint: disable-next=consider-using-namedtuple-or-dataclass\n101 MSGS: dict[str, MessageDefinitionTuple] = {\n102     \"F0001\": (\n103         \"%s\",\n104         \"fatal\",\n105         \"Used when an error occurred preventing the analysis of a \\\n106               module (unable to find it for instance).\",\n107         {\"scope\": WarningScope.LINE},\n108     ),\n109     \"F0002\": (\n110         \"%s: %s\",\n111         \"astroid-error\",\n112         \"Used when an unexpected error occurred while building the \"\n113         \"Astroid  representation. This is usually accompanied by a \"\n114         \"traceback. Please report such errors !\",\n115         {\"scope\": WarningScope.LINE},\n116     ),\n117     \"F0010\": (\n118         \"error while code parsing: %s\",\n119         \"parse-error\",\n120         \"Used when an exception occurred while building the Astroid \"\n121         \"representation which could be handled by astroid.\",\n122         {\"scope\": WarningScope.LINE},\n123     ),\n124     \"F0011\": (\n125         \"error while parsing the configuration: %s\",\n126         \"config-parse-error\",\n127         \"Used when an exception occurred while parsing a pylint configuration file.\",\n128         {\"scope\": WarningScope.LINE},\n129     ),\n130     \"I0001\": (\n131         \"Unable to run raw checkers on built-in module %s\",\n132         \"raw-checker-failed\",\n133         \"Used to inform that a built-in module has not been checked \"\n134         \"using the raw checkers.\",\n135         {\n136             \"scope\": WarningScope.LINE,\n137             \"default_enabled\": False,\n138         },\n139     ),\n140     \"I0010\": (\n141         \"Unable to consider inline option %r\",\n142         \"bad-inline-option\",\n143         \"Used when an inline option is either badly formatted or can't \"\n144         \"be used inside modules.\",\n145         {\n146             \"scope\": WarningScope.LINE,\n147             \"default_enabled\": False,\n148         },\n149     ),\n150     \"I0011\": (\n151         \"Locally disabling %s (%s)\",\n152         \"locally-disabled\",\n153         \"Used when an inline option disables a message or a messages category.\",\n154         {\n155             \"scope\": WarningScope.LINE,\n156             \"default_enabled\": False,\n157         },\n158     ),\n159     \"I0013\": (\n160         \"Ignoring entire file\",\n161         \"file-ignored\",\n162         \"Used to inform that the file will not be checked\",\n163         {\n164             \"scope\": WarningScope.LINE,\n165             \"default_enabled\": False,\n166         },\n167     ),\n168     \"I0020\": (\n169         \"Suppressed %s (from line %d)\",\n170         \"suppressed-message\",\n171         \"A message was triggered on a line, but suppressed explicitly \"\n172         \"by a disable= comment in the file. This message is not \"\n173         \"generated for messages that are ignored due to configuration \"\n174         \"settings.\",\n175         {\n176             \"scope\": WarningScope.LINE,\n177             \"default_enabled\": False,\n178         },\n179     ),\n180     \"I0021\": (\n181         \"Useless suppression of %s\",\n182         \"useless-suppression\",\n183         \"Reported when a message is explicitly disabled for a line or \"\n184         \"a block of code, but never triggered.\",\n185         {\n186             \"scope\": WarningScope.LINE,\n187             \"default_enabled\": False,\n188         },\n189     ),\n190     \"I0022\": (\n191         'Pragma \"%s\" is deprecated, use \"%s\" instead',\n192         \"deprecated-pragma\",\n193         \"Some inline pylint options have been renamed or reworked, \"\n194         \"only the most recent form should be used. \"\n195         \"NOTE:skip-all is only available with pylint >= 0.26\",\n196         {\n197             \"old_names\": [(\"I0014\", \"deprecated-disable-all\")],\n198             \"scope\": WarningScope.LINE,\n199             \"default_enabled\": False,\n200         },\n201     ),\n202     \"E0001\": (\n203         \"%s\",\n204         \"syntax-error\",\n205         \"Used when a syntax error is raised for a module.\",\n206         {\"scope\": WarningScope.LINE},\n207     ),\n208     \"E0011\": (\n209         \"Unrecognized file option %r\",\n210         \"unrecognized-inline-option\",\n211         \"Used when an unknown inline option is encountered.\",\n212         {\"scope\": WarningScope.LINE},\n213     ),\n214     \"W0012\": (\n215         \"Unknown option value for '%s', expected a valid pylint message and got '%s'\",\n216         \"unknown-option-value\",\n217         \"Used when an unknown value is encountered for an option.\",\n218         {\n219             \"scope\": WarningScope.LINE,\n220             \"old_names\": [(\"E0012\", \"bad-option-value\")],\n221         },\n222     ),\n223     \"R0022\": (\n224         \"Useless option value for '%s', %s\",\n225         \"useless-option-value\",\n226         \"Used when a value for an option that is now deleted from pylint\"\n227         \" is encountered.\",\n228         {\n229             \"scope\": WarningScope.LINE,\n230             \"old_names\": [(\"E0012\", \"bad-option-value\")],\n231         },\n232     ),\n233     \"E0013\": (\n234         \"Plugin '%s' is impossible to load, is it installed ? ('%s')\",\n235         \"bad-plugin-value\",\n236         \"Used when a bad value is used in 'load-plugins'.\",\n237         {\"scope\": WarningScope.LINE},\n238     ),\n239     \"E0014\": (\n240         \"Out-of-place setting encountered in top level configuration-section '%s' : '%s'\",\n241         \"bad-configuration-section\",\n242         \"Used when we detect a setting in the top level of a toml configuration that\"\n243         \" shouldn't be there.\",\n244         {\"scope\": WarningScope.LINE},\n245     ),\n246     \"E0015\": (\n247         \"Unrecognized option found: %s\",\n248         \"unrecognized-option\",\n249         \"Used when we detect an option that we do not recognize.\",\n250         {\"scope\": WarningScope.LINE},\n251     ),\n252 }\n253 \n254 \n255 # pylint: disable=too-many-instance-attributes,too-many-public-methods\n256 class PyLinter(\n257     _ArgumentsManager,\n258     _MessageStateHandler,\n259     reporters.ReportsHandlerMixIn,\n260     checkers.BaseChecker,\n261 ):\n262     \"\"\"Lint Python modules using external checkers.\n263 \n264     This is the main checker controlling the other ones and the reports\n265     generation. It is itself both a raw checker and an astroid checker in order\n266     to:\n267     * handle message activation / deactivation at the module level\n268     * handle some basic but necessary stats' data (number of classes, methods...)\n269 \n270     IDE plugin developers: you may have to call\n271     `astroid.MANAGER.clear_cache()` across runs if you want\n272     to ensure the latest code version is actually checked.\n273 \n274     This class needs to support pickling for parallel linting to work. The exception\n275     is reporter member; see check_parallel function for more details.\n276     \"\"\"\n277 \n278     name = MAIN_CHECKER_NAME\n279     msgs = MSGS\n280     # Will be used like this : datetime.now().strftime(crash_file_path)\n281     crash_file_path: str = \"pylint-crash-%Y-%m-%d-%H-%M-%S.txt\"\n282 \n283     option_groups_descs = {\n284         \"Messages control\": \"Options controlling analysis messages\",\n285         \"Reports\": \"Options related to output formatting and reporting\",\n286     }\n287 \n288     def __init__(\n289         self,\n290         options: Options = (),\n291         reporter: reporters.BaseReporter | reporters.MultiReporter | None = None,\n292         option_groups: tuple[tuple[str, str], ...] = (),\n293         # TODO: Deprecate passing the pylintrc parameter\n294         pylintrc: str | None = None,  # pylint: disable=unused-argument\n295     ) -> None:\n296         _ArgumentsManager.__init__(self, prog=\"pylint\")\n297         _MessageStateHandler.__init__(self, self)\n298 \n299         # Some stuff has to be done before initialization of other ancestors...\n300         # messages store / checkers / reporter / astroid manager\n301 \n302         # Attributes for reporters\n303         self.reporter: reporters.BaseReporter | reporters.MultiReporter\n304         if reporter:\n305             self.set_reporter(reporter)\n306         else:\n307             self.set_reporter(TextReporter())\n308         self._reporters: dict[str, type[reporters.BaseReporter]] = {}\n309         \"\"\"Dictionary of possible but non-initialized reporters.\"\"\"\n310 \n311         # Attributes for checkers and plugins\n312         self._checkers: defaultdict[\n313             str, list[checkers.BaseChecker]\n314         ] = collections.defaultdict(list)\n315         \"\"\"Dictionary of registered and initialized checkers.\"\"\"\n316         self._dynamic_plugins: dict[str, ModuleType | ModuleNotFoundError | bool] = {}\n317         \"\"\"Set of loaded plugin names.\"\"\"\n318 \n319         # Attributes related to stats\n320         self.stats = LinterStats()\n321 \n322         # Attributes related to (command-line) options and their parsing\n323         self.options: Options = options + _make_linter_options(self)\n324         for opt_group in option_groups:\n325             self.option_groups_descs[opt_group[0]] = opt_group[1]\n326         self._option_groups: tuple[tuple[str, str], ...] = (\n327             *option_groups,\n328             (\"Messages control\", \"Options controlling analysis messages\"),\n329             (\"Reports\", \"Options related to output formatting and reporting\"),\n330         )\n331         self.fail_on_symbols: list[str] = []\n332         \"\"\"List of message symbols on which pylint should fail, set by --fail-on.\"\"\"\n333         self._error_mode = False\n334 \n335         reporters.ReportsHandlerMixIn.__init__(self)\n336         checkers.BaseChecker.__init__(self, self)\n337         # provided reports\n338         self.reports = (\n339             (\"RP0001\", \"Messages by category\", report_total_messages_stats),\n340             (\n341                 \"RP0002\",\n342                 \"% errors / warnings by module\",\n343                 report_messages_by_module_stats,\n344             ),\n345             (\"RP0003\", \"Messages\", report_messages_stats),\n346         )\n347 \n348         # Attributes related to registering messages and their handling\n349         self.msgs_store = MessageDefinitionStore(self.config.py_version)\n350         self.msg_status = 0\n351         self._by_id_managed_msgs: list[ManagedMessage] = []\n352 \n353         # Attributes related to visiting files\n354         self.file_state = FileState(\"\", self.msgs_store, is_base_filestate=True)\n355         self.current_name: str = \"\"\n356         self.current_file: str | None = None\n357         self._ignore_file = False\n358         self._ignore_paths: list[Pattern[str]] = []\n359 \n360         self.register_checker(self)\n361 \n362     def load_default_plugins(self) -> None:\n363         checkers.initialize(self)\n364         reporters.initialize(self)\n365 \n366     def load_plugin_modules(self, modnames: Iterable[str], force: bool = False) -> None:\n367         \"\"\"Check a list of pylint plugins modules, load and register them.\n368 \n369         If a module cannot be loaded, never try to load it again and instead\n370         store the error message for later use in ``load_plugin_configuration``\n371         below.\n372 \n373         If `force` is True (useful when multiprocessing), then the plugin is\n374         reloaded regardless if an entry exists in self._dynamic_plugins.\n375         \"\"\"\n376         for modname in modnames:\n377             if modname in self._dynamic_plugins and not force:\n378                 continue\n379             try:\n380                 module = astroid.modutils.load_module_from_name(modname)\n381                 module.register(self)\n382                 self._dynamic_plugins[modname] = module\n383             except ModuleNotFoundError as mnf_e:\n384                 self._dynamic_plugins[modname] = mnf_e\n385 \n386     def load_plugin_configuration(self) -> None:\n387         \"\"\"Call the configuration hook for plugins.\n388 \n389         This walks through the list of plugins, grabs the \"load_configuration\"\n390         hook, if exposed, and calls it to allow plugins to configure specific\n391         settings.\n392 \n393         The result of attempting to load the plugin of the given name\n394         is stored in the dynamic plugins dictionary in ``load_plugin_modules`` above.\n395 \n396         ..note::\n397             This function previously always tried to load modules again, which\n398             led to some confusion and silent failure conditions as described\n399             in GitHub issue #7264. Making it use the stored result is more efficient, and\n400             means that we avoid the ``init-hook`` problems from before.\n401         \"\"\"\n402         for modname, module_or_error in self._dynamic_plugins.items():\n403             if isinstance(module_or_error, ModuleNotFoundError):\n404                 self.add_message(\n405                     \"bad-plugin-value\", args=(modname, module_or_error), line=0\n406                 )\n407             elif hasattr(module_or_error, \"load_configuration\"):\n408                 module_or_error.load_configuration(self)\n409 \n410         # We re-set all the dictionary values to True here to make sure the dict\n411         # is pickle-able. This is only a problem in multiprocessing/parallel mode.\n412         # (e.g. invoking pylint -j 2)\n413         self._dynamic_plugins = {\n414             modname: not isinstance(val, ModuleNotFoundError)\n415             for modname, val in self._dynamic_plugins.items()\n416         }\n417 \n418     def _load_reporters(self, reporter_names: str) -> None:\n419         \"\"\"Load the reporters if they are available on _reporters.\"\"\"\n420         if not self._reporters:\n421             return\n422         sub_reporters = []\n423         output_files = []\n424         with contextlib.ExitStack() as stack:\n425             for reporter_name in reporter_names.split(\",\"):\n426                 reporter_name, *reporter_output = reporter_name.split(\":\", 1)\n427 \n428                 reporter = self._load_reporter_by_name(reporter_name)\n429                 sub_reporters.append(reporter)\n430                 if reporter_output:\n431                     output_file = stack.enter_context(\n432                         open(reporter_output[0], \"w\", encoding=\"utf-8\")\n433                     )\n434                     reporter.out = output_file\n435                     output_files.append(output_file)\n436 \n437             # Extend the lifetime of all opened output files\n438             close_output_files = stack.pop_all().close\n439 \n440         if len(sub_reporters) > 1 or output_files:\n441             self.set_reporter(\n442                 reporters.MultiReporter(\n443                     sub_reporters,\n444                     close_output_files,\n445                 )\n446             )\n447         else:\n448             self.set_reporter(sub_reporters[0])\n449 \n450     def _load_reporter_by_name(self, reporter_name: str) -> reporters.BaseReporter:\n451         name = reporter_name.lower()\n452         if name in self._reporters:\n453             return self._reporters[name]()\n454 \n455         try:\n456             reporter_class = _load_reporter_by_class(reporter_name)\n457         except (ImportError, AttributeError, AssertionError) as e:\n458             raise exceptions.InvalidReporterError(name) from e\n459 \n460         return reporter_class()\n461 \n462     def set_reporter(\n463         self, reporter: reporters.BaseReporter | reporters.MultiReporter\n464     ) -> None:\n465         \"\"\"Set the reporter used to display messages and reports.\"\"\"\n466         self.reporter = reporter\n467         reporter.linter = self\n468 \n469     def register_reporter(self, reporter_class: type[reporters.BaseReporter]) -> None:\n470         \"\"\"Registers a reporter class on the _reporters attribute.\"\"\"\n471         self._reporters[reporter_class.name] = reporter_class\n472 \n473     def report_order(self) -> list[BaseChecker]:\n474         reports = sorted(self._reports, key=lambda x: getattr(x, \"name\", \"\"))\n475         try:\n476             # Remove the current reporter and add it\n477             # at the end of the list.\n478             reports.pop(reports.index(self))\n479         except ValueError:\n480             pass\n481         else:\n482             reports.append(self)\n483         return reports\n484 \n485     # checkers manipulation methods ############################################\n486 \n487     def register_checker(self, checker: checkers.BaseChecker) -> None:\n488         \"\"\"This method auto registers the checker.\"\"\"\n489         self._checkers[checker.name].append(checker)\n490         for r_id, r_title, r_cb in checker.reports:\n491             self.register_report(r_id, r_title, r_cb, checker)\n492         if hasattr(checker, \"msgs\"):\n493             self.msgs_store.register_messages_from_checker(checker)\n494             for message in checker.messages:\n495                 if not message.default_enabled:\n496                     self.disable(message.msgid)\n497         # Register the checker, but disable all of its messages.\n498         if not getattr(checker, \"enabled\", True):\n499             self.disable(checker.name)\n500 \n501     def enable_fail_on_messages(self) -> None:\n502         \"\"\"Enable 'fail on' msgs.\n503 \n504         Convert values in config.fail_on (which might be msg category, msg id,\n505         or symbol) to specific msgs, then enable and flag them for later.\n506         \"\"\"\n507         fail_on_vals = self.config.fail_on\n508         if not fail_on_vals:\n509             return\n510 \n511         fail_on_cats = set()\n512         fail_on_msgs = set()\n513         for val in fail_on_vals:\n514             # If value is a category, add category, else add message\n515             if val in MSG_TYPES:\n516                 fail_on_cats.add(val)\n517             else:\n518                 fail_on_msgs.add(val)\n519 \n520         # For every message in every checker, if cat or msg flagged, enable check\n521         for all_checkers in self._checkers.values():\n522             for checker in all_checkers:\n523                 for msg in checker.messages:\n524                     if msg.msgid in fail_on_msgs or msg.symbol in fail_on_msgs:\n525                         # message id/symbol matched, enable and flag it\n526                         self.enable(msg.msgid)\n527                         self.fail_on_symbols.append(msg.symbol)\n528                     elif msg.msgid[0] in fail_on_cats:\n529                         # message starts with a category value, flag (but do not enable) it\n530                         self.fail_on_symbols.append(msg.symbol)\n531 \n532     def any_fail_on_issues(self) -> bool:\n533         return any(x in self.fail_on_symbols for x in self.stats.by_msg.keys())\n534 \n535     def disable_reporters(self) -> None:\n536         \"\"\"Disable all reporters.\"\"\"\n537         for _reporters in self._reports.values():\n538             for report_id, _, _ in _reporters:\n539                 self.disable_report(report_id)\n540 \n541     def _parse_error_mode(self) -> None:\n542         \"\"\"Parse the current state of the error mode.\n543 \n544         Error mode: enable only errors; no reports, no persistent.\n545         \"\"\"\n546         if not self._error_mode:\n547             return\n548 \n549         self.disable_noerror_messages()\n550         self.disable(\"miscellaneous\")\n551         self.set_option(\"reports\", False)\n552         self.set_option(\"persistent\", False)\n553         self.set_option(\"score\", False)\n554 \n555     # code checking methods ###################################################\n556 \n557     def get_checkers(self) -> list[BaseChecker]:\n558         \"\"\"Return all available checkers as an ordered list.\"\"\"\n559         return sorted(c for _checkers in self._checkers.values() for c in _checkers)\n560 \n561     def get_checker_names(self) -> list[str]:\n562         \"\"\"Get all the checker names that this linter knows about.\"\"\"\n563         return sorted(\n564             {\n565                 checker.name\n566                 for checker in self.get_checkers()\n567                 if checker.name != MAIN_CHECKER_NAME\n568             }\n569         )\n570 \n571     def prepare_checkers(self) -> list[BaseChecker]:\n572         \"\"\"Return checkers needed for activated messages and reports.\"\"\"\n573         if not self.config.reports:\n574             self.disable_reporters()\n575         # get needed checkers\n576         needed_checkers: list[BaseChecker] = [self]\n577         for checker in self.get_checkers()[1:]:\n578             messages = {msg for msg in checker.msgs if self.is_message_enabled(msg)}\n579             if messages or any(self.report_is_enabled(r[0]) for r in checker.reports):\n580                 needed_checkers.append(checker)\n581         return needed_checkers\n582 \n583     # pylint: disable=unused-argument\n584     @staticmethod\n585     def should_analyze_file(modname: str, path: str, is_argument: bool = False) -> bool:\n586         \"\"\"Returns whether a module should be checked.\n587 \n588         This implementation returns True for all python source file, indicating\n589         that all files should be linted.\n590 \n591         Subclasses may override this method to indicate that modules satisfying\n592         certain conditions should not be linted.\n593 \n594         :param str modname: The name of the module to be checked.\n595         :param str path: The full path to the source code of the module.\n596         :param bool is_argument: Whether the file is an argument to pylint or not.\n597                                  Files which respect this property are always\n598                                  checked, since the user requested it explicitly.\n599         :returns: True if the module should be checked.\n600         \"\"\"\n601         if is_argument:\n602             return True\n603         return path.endswith(\".py\")\n604 \n605     # pylint: enable=unused-argument\n606 \n607     def initialize(self) -> None:\n608         \"\"\"Initialize linter for linting.\n609 \n610         This method is called before any linting is done.\n611         \"\"\"\n612         self._ignore_paths = self.config.ignore_paths\n613         # initialize msgs_state now that all messages have been registered into\n614         # the store\n615         for msg in self.msgs_store.messages:\n616             if not msg.may_be_emitted(self.config.py_version):\n617                 self._msgs_state[msg.msgid] = False\n618 \n619     def _discover_files(self, files_or_modules: Sequence[str]) -> Iterator[str]:\n620         \"\"\"Discover python modules and packages in sub-directory.\n621 \n622         Returns iterator of paths to discovered modules and packages.\n623         \"\"\"\n624         for something in files_or_modules:\n625             if os.path.isdir(something) and not os.path.isfile(\n626                 os.path.join(something, \"__init__.py\")\n627             ):\n628                 skip_subtrees: list[str] = []\n629                 for root, _, files in os.walk(something):\n630                     if any(root.startswith(s) for s in skip_subtrees):\n631                         # Skip subtree of already discovered package.\n632                         continue\n633 \n634                     if _is_ignored_file(\n635                         root,\n636                         self.config.ignore,\n637                         self.config.ignore_patterns,\n638                         self.config.ignore_paths,\n639                     ):\n640                         skip_subtrees.append(root)\n641                         continue\n642 \n643                     if \"__init__.py\" in files:\n644                         skip_subtrees.append(root)\n645                         yield root\n646                     else:\n647                         yield from (\n648                             os.path.join(root, file)\n649                             for file in files\n650                             if file.endswith(\".py\")\n651                         )\n652             else:\n653                 yield something\n654 \n655     def check(self, files_or_modules: Sequence[str]) -> None:\n656         \"\"\"Main checking entry: check a list of files or modules from their name.\n657 \n658         files_or_modules is either a string or list of strings presenting modules to check.\n659         \"\"\"\n660         self.initialize()\n661         if self.config.recursive:\n662             files_or_modules = tuple(self._discover_files(files_or_modules))\n663         if self.config.from_stdin:\n664             if len(files_or_modules) != 1:\n665                 raise exceptions.InvalidArgsError(\n666                     \"Missing filename required for --from-stdin\"\n667                 )\n668 \n669         extra_packages_paths = list(\n670             {\n671                 discover_package_path(file_or_module, self.config.source_roots)\n672                 for file_or_module in files_or_modules\n673             }\n674         )\n675 \n676         # TODO: Move the parallel invocation into step 3 of the checking process\n677         if not self.config.from_stdin and self.config.jobs > 1:\n678             original_sys_path = sys.path[:]\n679             check_parallel(\n680                 self,\n681                 self.config.jobs,\n682                 self._iterate_file_descrs(files_or_modules),\n683                 extra_packages_paths,\n684             )\n685             sys.path = original_sys_path\n686             return\n687 \n688         # 1) Get all FileItems\n689         with augmented_sys_path(extra_packages_paths):\n690             if self.config.from_stdin:\n691                 fileitems = self._get_file_descr_from_stdin(files_or_modules[0])\n692                 data: str | None = _read_stdin()\n693             else:\n694                 fileitems = self._iterate_file_descrs(files_or_modules)\n695                 data = None\n696 \n697         # The contextmanager also opens all checkers and sets up the PyLinter class\n698         with augmented_sys_path(extra_packages_paths):\n699             with self._astroid_module_checker() as check_astroid_module:\n700                 # 2) Get the AST for each FileItem\n701                 ast_per_fileitem = self._get_asts(fileitems, data)\n702 \n703                 # 3) Lint each ast\n704                 self._lint_files(ast_per_fileitem, check_astroid_module)\n705 \n706     def _get_asts(\n707         self, fileitems: Iterator[FileItem], data: str | None\n708     ) -> dict[FileItem, nodes.Module | None]:\n709         \"\"\"Get the AST for all given FileItems.\"\"\"\n710         ast_per_fileitem: dict[FileItem, nodes.Module | None] = {}\n711 \n712         for fileitem in fileitems:\n713             self.set_current_module(fileitem.name, fileitem.filepath)\n714 \n715             try:\n716                 ast_per_fileitem[fileitem] = self.get_ast(\n717                     fileitem.filepath, fileitem.name, data\n718                 )\n719             except astroid.AstroidBuildingError as ex:\n720                 template_path = prepare_crash_report(\n721                     ex, fileitem.filepath, self.crash_file_path\n722                 )\n723                 msg = get_fatal_error_message(fileitem.filepath, template_path)\n724                 self.add_message(\n725                     \"astroid-error\",\n726                     args=(fileitem.filepath, msg),\n727                     confidence=HIGH,\n728                 )\n729 \n730         return ast_per_fileitem\n731 \n732     def check_single_file_item(self, file: FileItem) -> None:\n733         \"\"\"Check single file item.\n734 \n735         The arguments are the same that are documented in _check_files\n736 \n737         initialize() should be called before calling this method\n738         \"\"\"\n739         with self._astroid_module_checker() as check_astroid_module:\n740             self._check_file(self.get_ast, check_astroid_module, file)\n741 \n742     def _lint_files(\n743         self,\n744         ast_mapping: dict[FileItem, nodes.Module | None],\n745         check_astroid_module: Callable[[nodes.Module], bool | None],\n746     ) -> None:\n747         \"\"\"Lint all AST modules from a mapping..\"\"\"\n748         for fileitem, module in ast_mapping.items():\n749             if module is None:\n750                 continue\n751             try:\n752                 self._lint_file(fileitem, module, check_astroid_module)\n753             except Exception as ex:  # pylint: disable=broad-except\n754                 template_path = prepare_crash_report(\n755                     ex, fileitem.filepath, self.crash_file_path\n756                 )\n757                 msg = get_fatal_error_message(fileitem.filepath, template_path)\n758                 if isinstance(ex, astroid.AstroidError):\n759                     self.add_message(\n760                         \"astroid-error\", args=(fileitem.filepath, msg), confidence=HIGH\n761                     )\n762                 else:\n763                     self.add_message(\"fatal\", args=msg, confidence=HIGH)\n764 \n765     def _lint_file(\n766         self,\n767         file: FileItem,\n768         module: nodes.Module,\n769         check_astroid_module: Callable[[nodes.Module], bool | None],\n770     ) -> None:\n771         \"\"\"Lint a file using the passed utility function check_astroid_module).\n772 \n773         :param FileItem file: data about the file\n774         :param nodes.Module module: the ast module to lint\n775         :param Callable check_astroid_module: callable checking an AST taking the following\n776                arguments\n777         - ast: AST of the module\n778         :raises AstroidError: for any failures stemming from astroid\n779         \"\"\"\n780         self.set_current_module(file.name, file.filepath)\n781         self._ignore_file = False\n782         self.file_state = FileState(file.modpath, self.msgs_store, module)\n783         # fix the current file (if the source file was not available or\n784         # if it's actually a c extension)\n785         self.current_file = module.file\n786 \n787         try:\n788             check_astroid_module(module)\n789         except Exception as e:\n790             raise astroid.AstroidError from e\n791 \n792         # warn about spurious inline messages handling\n793         spurious_messages = self.file_state.iter_spurious_suppression_messages(\n794             self.msgs_store\n795         )\n796         for msgid, line, args in spurious_messages:\n797             self.add_message(msgid, line, None, args)\n798 \n799     def _check_file(\n800         self,\n801         get_ast: GetAstProtocol,\n802         check_astroid_module: Callable[[nodes.Module], bool | None],\n803         file: FileItem,\n804     ) -> None:\n805         \"\"\"Check a file using the passed utility functions (get_ast and\n806         check_astroid_module).\n807 \n808         :param callable get_ast: callable returning AST from defined file taking the\n809                                  following arguments\n810         - filepath: path to the file to check\n811         - name: Python module name\n812         :param callable check_astroid_module: callable checking an AST taking the following\n813                arguments\n814         - ast: AST of the module\n815         :param FileItem file: data about the file\n816         :raises AstroidError: for any failures stemming from astroid\n817         \"\"\"\n818         self.set_current_module(file.name, file.filepath)\n819         # get the module representation\n820         ast_node = get_ast(file.filepath, file.name)\n821         if ast_node is None:\n822             return\n823 \n824         self._ignore_file = False\n825 \n826         self.file_state = FileState(file.modpath, self.msgs_store, ast_node)\n827         # fix the current file (if the source file was not available or\n828         # if it's actually a c extension)\n829         self.current_file = ast_node.file\n830         try:\n831             check_astroid_module(ast_node)\n832         except Exception as e:  # pragma: no cover\n833             raise astroid.AstroidError from e\n834         # warn about spurious inline messages handling\n835         spurious_messages = self.file_state.iter_spurious_suppression_messages(\n836             self.msgs_store\n837         )\n838         for msgid, line, args in spurious_messages:\n839             self.add_message(msgid, line, None, args)\n840 \n841     def _get_file_descr_from_stdin(self, filepath: str) -> Iterator[FileItem]:\n842         \"\"\"Return file description (tuple of module name, file path, base name) from\n843         given file path.\n844 \n845         This method is used for creating suitable file description for _check_files when the\n846         source is standard input.\n847         \"\"\"\n848         if _is_ignored_file(\n849             filepath,\n850             self.config.ignore,\n851             self.config.ignore_patterns,\n852             self.config.ignore_paths,\n853         ):\n854             return\n855 \n856         try:\n857             # Note that this function does not really perform an\n858             # __import__ but may raise an ImportError exception, which\n859             # we want to catch here.\n860             modname = \".\".join(astroid.modutils.modpath_from_file(filepath))\n861         except ImportError:\n862             modname = os.path.splitext(os.path.basename(filepath))[0]\n863 \n864         yield FileItem(modname, filepath, filepath)\n865 \n866     def _iterate_file_descrs(\n867         self, files_or_modules: Sequence[str]\n868     ) -> Iterator[FileItem]:\n869         \"\"\"Return generator yielding file descriptions (tuples of module name, file\n870         path, base name).\n871 \n872         The returned generator yield one item for each Python module that should be linted.\n873         \"\"\"\n874         for descr in self._expand_files(files_or_modules).values():\n875             name, filepath, is_arg = descr[\"name\"], descr[\"path\"], descr[\"isarg\"]\n876             if self.should_analyze_file(name, filepath, is_argument=is_arg):\n877                 yield FileItem(name, filepath, descr[\"basename\"])\n878 \n879     def _expand_files(\n880         self, files_or_modules: Sequence[str]\n881     ) -> dict[str, ModuleDescriptionDict]:\n882         \"\"\"Get modules and errors from a list of modules and handle errors.\"\"\"\n883         result, errors = expand_modules(\n884             files_or_modules,\n885             self.config.source_roots,\n886             self.config.ignore,\n887             self.config.ignore_patterns,\n888             self._ignore_paths,\n889         )\n890         for error in errors:\n891             message = modname = error[\"mod\"]\n892             key = error[\"key\"]\n893             self.set_current_module(modname)\n894             if key == \"fatal\":\n895                 message = str(error[\"ex\"]).replace(os.getcwd() + os.sep, \"\")\n896             self.add_message(key, args=message)\n897         return result\n898 \n899     def set_current_module(self, modname: str, filepath: str | None = None) -> None:\n900         \"\"\"Set the name of the currently analyzed module and\n901         init statistics for it.\n902         \"\"\"\n903         if not modname and filepath is None:\n904             return\n905         self.reporter.on_set_current_module(modname or \"\", filepath)\n906         self.current_name = modname\n907         self.current_file = filepath or modname\n908         self.stats.init_single_module(modname or \"\")\n909 \n910         # If there is an actual filepath we might need to update the config attribute\n911         if filepath:\n912             namespace = self._get_namespace_for_file(\n913                 Path(filepath), self._directory_namespaces\n914             )\n915             if namespace:\n916                 self.config = namespace or self._base_config\n917 \n918     def _get_namespace_for_file(\n919         self, filepath: Path, namespaces: DirectoryNamespaceDict\n920     ) -> argparse.Namespace | None:\n921         for directory in namespaces:\n922             if _is_relative_to(filepath, directory):\n923                 namespace = self._get_namespace_for_file(\n924                     filepath, namespaces[directory][1]\n925                 )\n926                 if namespace is None:\n927                     return namespaces[directory][0]\n928         return None\n929 \n930     @contextlib.contextmanager\n931     def _astroid_module_checker(\n932         self,\n933     ) -> Iterator[Callable[[nodes.Module], bool | None]]:\n934         \"\"\"Context manager for checking ASTs.\n935 \n936         The value in the context is callable accepting AST as its only argument.\n937         \"\"\"\n938         walker = ASTWalker(self)\n939         _checkers = self.prepare_checkers()\n940         tokencheckers = [\n941             c for c in _checkers if isinstance(c, checkers.BaseTokenChecker)\n942         ]\n943         rawcheckers = [\n944             c for c in _checkers if isinstance(c, checkers.BaseRawFileChecker)\n945         ]\n946         for checker in _checkers:\n947             checker.open()\n948             walker.add_checker(checker)\n949 \n950         yield functools.partial(\n951             self.check_astroid_module,\n952             walker=walker,\n953             tokencheckers=tokencheckers,\n954             rawcheckers=rawcheckers,\n955         )\n956 \n957         # notify global end\n958         self.stats.statement = walker.nbstatements\n959         for checker in reversed(_checkers):\n960             checker.close()\n961 \n962     def get_ast(\n963         self, filepath: str, modname: str, data: str | None = None\n964     ) -> nodes.Module | None:\n965         \"\"\"Return an ast(roid) representation of a module or a string.\n966 \n967         :param filepath: path to checked file.\n968         :param str modname: The name of the module to be checked.\n969         :param str data: optional contents of the checked file.\n970         :returns: the AST\n971         :rtype: astroid.nodes.Module\n972         :raises AstroidBuildingError: Whenever we encounter an unexpected exception\n973         \"\"\"\n974         try:\n975             if data is None:\n976                 return MANAGER.ast_from_file(filepath, modname, source=True)\n977             return astroid.builder.AstroidBuilder(MANAGER).string_build(\n978                 data, modname, filepath\n979             )\n980         except astroid.AstroidSyntaxError as ex:\n981             line = getattr(ex.error, \"lineno\", None)\n982             if line is None:\n983                 line = 0\n984             self.add_message(\n985                 \"syntax-error\",\n986                 line=line,\n987                 col_offset=getattr(ex.error, \"offset\", None),\n988                 args=f\"Parsing failed: '{ex.error}'\",\n989                 confidence=HIGH,\n990             )\n991         except astroid.AstroidBuildingError as ex:\n992             self.add_message(\"parse-error\", args=ex)\n993         except Exception as ex:\n994             traceback.print_exc()\n995             # We raise BuildingError here as this is essentially an astroid issue\n996             # Creating an issue template and adding the 'astroid-error' message is handled\n997             # by caller: _check_files\n998             raise astroid.AstroidBuildingError(\n999                 \"Building error when trying to create ast representation of module '{modname}'\",\n1000                 modname=modname,\n1001             ) from ex\n1002         return None\n1003 \n1004     def check_astroid_module(\n1005         self,\n1006         ast_node: nodes.Module,\n1007         walker: ASTWalker,\n1008         rawcheckers: list[checkers.BaseRawFileChecker],\n1009         tokencheckers: list[checkers.BaseTokenChecker],\n1010     ) -> bool | None:\n1011         \"\"\"Check a module from its astroid representation.\n1012 \n1013         For return value see _check_astroid_module\n1014         \"\"\"\n1015         before_check_statements = walker.nbstatements\n1016 \n1017         retval = self._check_astroid_module(\n1018             ast_node, walker, rawcheckers, tokencheckers\n1019         )\n1020         self.stats.by_module[self.current_name][\"statement\"] = (\n1021             walker.nbstatements - before_check_statements\n1022         )\n1023 \n1024         return retval\n1025 \n1026     def _check_astroid_module(\n1027         self,\n1028         node: nodes.Module,\n1029         walker: ASTWalker,\n1030         rawcheckers: list[checkers.BaseRawFileChecker],\n1031         tokencheckers: list[checkers.BaseTokenChecker],\n1032     ) -> bool | None:\n1033         \"\"\"Check given AST node with given walker and checkers.\n1034 \n1035         :param astroid.nodes.Module node: AST node of the module to check\n1036         :param pylint.utils.ast_walker.ASTWalker walker: AST walker\n1037         :param list rawcheckers: List of token checkers to use\n1038         :param list tokencheckers: List of raw checkers to use\n1039 \n1040         :returns: True if the module was checked, False if ignored,\n1041             None if the module contents could not be parsed\n1042         \"\"\"\n1043         try:\n1044             tokens = utils.tokenize_module(node)\n1045         except tokenize.TokenError as ex:\n1046             self.add_message(\"syntax-error\", line=ex.args[1][0], args=ex.args[0])\n1047             return None\n1048 \n1049         if not node.pure_python:\n1050             self.add_message(\"raw-checker-failed\", args=node.name)\n1051         else:\n1052             # assert astroid.file.endswith('.py')\n1053             # Parse module/block level option pragma's\n1054             self.process_tokens(tokens)\n1055             if self._ignore_file:\n1056                 return False\n1057             # run raw and tokens checkers\n1058             for raw_checker in rawcheckers:\n1059                 raw_checker.process_module(node)\n1060             for token_checker in tokencheckers:\n1061                 token_checker.process_tokens(tokens)\n1062         # generate events to astroid checkers\n1063         walker.walk(node)\n1064         return True\n1065 \n1066     def open(self) -> None:\n1067         \"\"\"Initialize counters.\"\"\"\n1068         self.stats = LinterStats()\n1069         MANAGER.always_load_extensions = self.config.unsafe_load_any_extension\n1070         MANAGER.max_inferable_values = self.config.limit_inference_results\n1071         MANAGER.extension_package_whitelist.update(self.config.extension_pkg_allow_list)\n1072         if self.config.extension_pkg_whitelist:\n1073             MANAGER.extension_package_whitelist.update(\n1074                 self.config.extension_pkg_whitelist\n1075             )\n1076         self.stats.reset_message_count()\n1077 \n1078     def generate_reports(self) -> int | None:\n1079         \"\"\"Close the whole package /module, it's time to make reports !\n1080 \n1081         if persistent run, pickle results for later comparison\n1082         \"\"\"\n1083         # Display whatever messages are left on the reporter.\n1084         self.reporter.display_messages(report_nodes.Section())\n1085         if not self.file_state._is_base_filestate:\n1086             # load previous results if any\n1087             previous_stats = load_results(self.file_state.base_name)\n1088             self.reporter.on_close(self.stats, previous_stats)\n1089             if self.config.reports:\n1090                 sect = self.make_reports(self.stats, previous_stats)\n1091             else:\n1092                 sect = report_nodes.Section()\n1093 \n1094             if self.config.reports:\n1095                 self.reporter.display_reports(sect)\n1096             score_value = self._report_evaluation()\n1097             # save results if persistent run\n1098             if self.config.persistent:\n1099                 save_results(self.stats, self.file_state.base_name)\n1100         else:\n1101             self.reporter.on_close(self.stats, LinterStats())\n1102             score_value = None\n1103         return score_value\n1104 \n1105     def _report_evaluation(self) -> int | None:\n1106         \"\"\"Make the global evaluation report.\"\"\"\n1107         # check with at least a statement (usually 0 when there is a\n1108         # syntax error preventing pylint from further processing)\n1109         note = None\n1110         previous_stats = load_results(self.file_state.base_name)\n1111         if self.stats.statement == 0:\n1112             return note\n1113 \n1114         # get a global note for the code\n1115         evaluation = self.config.evaluation\n1116         try:\n1117             stats_dict = {\n1118                 \"fatal\": self.stats.fatal,\n1119                 \"error\": self.stats.error,\n1120                 \"warning\": self.stats.warning,\n1121                 \"refactor\": self.stats.refactor,\n1122                 \"convention\": self.stats.convention,\n1123                 \"statement\": self.stats.statement,\n1124                 \"info\": self.stats.info,\n1125             }\n1126             note = eval(evaluation, {}, stats_dict)  # pylint: disable=eval-used\n1127         except Exception as ex:  # pylint: disable=broad-except\n1128             msg = f\"An exception occurred while rating: {ex}\"\n1129         else:\n1130             self.stats.global_note = note\n1131             msg = f\"Your code has been rated at {note:.2f}/10\"\n1132             if previous_stats:\n1133                 pnote = previous_stats.global_note\n1134                 if pnote is not None:\n1135                     msg += f\" (previous run: {pnote:.2f}/10, {note - pnote:+.2f})\"\n1136 \n1137         if self.config.score:\n1138             sect = report_nodes.EvaluationSection(msg)\n1139             self.reporter.display_reports(sect)\n1140         return note\n1141 \n1142     def _add_one_message(\n1143         self,\n1144         message_definition: MessageDefinition,\n1145         line: int | None,\n1146         node: nodes.NodeNG | None,\n1147         args: Any | None,\n1148         confidence: interfaces.Confidence | None,\n1149         col_offset: int | None,\n1150         end_lineno: int | None,\n1151         end_col_offset: int | None,\n1152     ) -> None:\n1153         \"\"\"After various checks have passed a single Message is\n1154         passed to the reporter and added to stats.\n1155         \"\"\"\n1156         message_definition.check_message_definition(line, node)\n1157 \n1158         # Look up \"location\" data of node if not yet supplied\n1159         if node:\n1160             if node.position:\n1161                 if not line:\n1162                     line = node.position.lineno\n1163                 if not col_offset:\n1164                     col_offset = node.position.col_offset\n1165                 if not end_lineno:\n1166                     end_lineno = node.position.end_lineno\n1167                 if not end_col_offset:\n1168                     end_col_offset = node.position.end_col_offset\n1169             else:\n1170                 if not line:\n1171                     line = node.fromlineno\n1172                 if not col_offset:\n1173                     col_offset = node.col_offset\n1174                 if not end_lineno:\n1175                     end_lineno = node.end_lineno\n1176                 if not end_col_offset:\n1177                     end_col_offset = node.end_col_offset\n1178 \n1179         # should this message be displayed\n1180         if not self.is_message_enabled(message_definition.msgid, line, confidence):\n1181             self.file_state.handle_ignored_message(\n1182                 self._get_message_state_scope(\n1183                     message_definition.msgid, line, confidence\n1184                 ),\n1185                 message_definition.msgid,\n1186                 line,\n1187             )\n1188             return\n1189 \n1190         # update stats\n1191         msg_cat = MSG_TYPES[message_definition.msgid[0]]\n1192         self.msg_status |= MSG_TYPES_STATUS[message_definition.msgid[0]]\n1193         self.stats.increase_single_message_count(msg_cat, 1)\n1194         self.stats.increase_single_module_message_count(self.current_name, msg_cat, 1)\n1195         try:\n1196             self.stats.by_msg[message_definition.symbol] += 1\n1197         except KeyError:\n1198             self.stats.by_msg[message_definition.symbol] = 1\n1199         # Interpolate arguments into message string\n1200         msg = message_definition.msg\n1201         if args is not None:\n1202             msg %= args\n1203         # get module and object\n1204         if node is None:\n1205             module, obj = self.current_name, \"\"\n1206             abspath = self.current_file\n1207         else:\n1208             module, obj = utils.get_module_and_frameid(node)\n1209             abspath = node.root().file\n1210         if abspath is not None:\n1211             path = abspath.replace(self.reporter.path_strip_prefix, \"\", 1)\n1212         else:\n1213             path = \"configuration\"\n1214         # add the message\n1215         self.reporter.handle_message(\n1216             Message(\n1217                 message_definition.msgid,\n1218                 message_definition.symbol,\n1219                 MessageLocationTuple(\n1220                     abspath or \"\",\n1221                     path,\n1222                     module or \"\",\n1223                     obj,\n1224                     line or 1,\n1225                     col_offset or 0,\n1226                     end_lineno,\n1227                     end_col_offset,\n1228                 ),\n1229                 msg,\n1230                 confidence,\n1231             )\n1232         )\n1233 \n1234     def add_message(\n1235         self,\n1236         msgid: str,\n1237         line: int | None = None,\n1238         node: nodes.NodeNG | None = None,\n1239         args: Any | None = None,\n1240         confidence: interfaces.Confidence | None = None,\n1241         col_offset: int | None = None,\n1242         end_lineno: int | None = None,\n1243         end_col_offset: int | None = None,\n1244     ) -> None:\n1245         \"\"\"Adds a message given by ID or name.\n1246 \n1247         If provided, the message string is expanded using args.\n1248 \n1249         AST checkers must provide the node argument (but may optionally\n1250         provide line if the line number is different), raw and token checkers\n1251         must provide the line argument.\n1252         \"\"\"\n1253         if confidence is None:\n1254             confidence = interfaces.UNDEFINED\n1255         message_definitions = self.msgs_store.get_message_definitions(msgid)\n1256         for message_definition in message_definitions:\n1257             self._add_one_message(\n1258                 message_definition,\n1259                 line,\n1260                 node,\n1261                 args,\n1262                 confidence,\n1263                 col_offset,\n1264                 end_lineno,\n1265                 end_col_offset,\n1266             )\n1267 \n1268     def add_ignored_message(\n1269         self,\n1270         msgid: str,\n1271         line: int,\n1272         node: nodes.NodeNG | None = None,\n1273         confidence: interfaces.Confidence | None = interfaces.UNDEFINED,\n1274     ) -> None:\n1275         \"\"\"Prepares a message to be added to the ignored message storage.\n1276 \n1277         Some checks return early in special cases and never reach add_message(),\n1278         even though they would normally issue a message.\n1279         This creates false positives for useless-suppression.\n1280         This function avoids this by adding those message to the ignored msgs attribute\n1281         \"\"\"\n1282         message_definitions = self.msgs_store.get_message_definitions(msgid)\n1283         for message_definition in message_definitions:\n1284             message_definition.check_message_definition(line, node)\n1285             self.file_state.handle_ignored_message(\n1286                 self._get_message_state_scope(\n1287                     message_definition.msgid, line, confidence\n1288                 ),\n1289                 message_definition.msgid,\n1290                 line,\n1291             )\n1292 \n1293     def _emit_stashed_messages(self) -> None:\n1294         for keys, values in self._stashed_messages.items():\n1295             modname, symbol = keys\n1296             self.linter.set_current_module(modname)\n1297             for args in values:\n1298                 self.add_message(\n1299                     symbol,\n1300                     args=args,\n1301                     line=0,\n1302                     confidence=HIGH,\n1303                 )\n1304         self._stashed_messages = collections.defaultdict(list)\n",
        "intended_behavior": "Ensure that the initiation of the linting process correctly prepares the environment for a consistent linting experience, whether running in single or multiple job modes. This could involve making sure that configurations (from `pylintrc`) are consistently applied across all jobs and that any initial setup that could affect output is equally established in each parallel process."
    },
    {
        "rel_file_path": "pylint/reporters/base_reporter.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/pylint-dev__pylint/setup_pylint-dev__pylint__3.0/pylint/reporters/base_reporter.py",
        "start": 1,
        "end": 82,
        "class_name": null,
        "method_name": null,
        "code": "1 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html\n2 # For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE\n3 # Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt\n4 \n5 from __future__ import annotations\n6 \n7 import os\n8 import sys\n9 from typing import TYPE_CHECKING, TextIO\n10 \n11 from pylint.message import Message\n12 from pylint.reporters.ureports.nodes import Text\n13 from pylint.utils import LinterStats\n14 \n15 if TYPE_CHECKING:\n16     from pylint.lint.pylinter import PyLinter\n17     from pylint.reporters.ureports.nodes import Section\n18 \n19 \n20 class BaseReporter:\n21     \"\"\"Base class for reporters.\n22 \n23     symbols: show short symbolic names for messages.\n24     \"\"\"\n25 \n26     extension = \"\"\n27 \n28     name = \"base\"\n29     \"\"\"Name of the reporter.\"\"\"\n30 \n31     def __init__(self, output: TextIO | None = None) -> None:\n32         self.linter: PyLinter\n33         self.section = 0\n34         self.out: TextIO = output or sys.stdout\n35         self.messages: list[Message] = []\n36         # Build the path prefix to strip to get relative paths\n37         self.path_strip_prefix = os.getcwd() + os.sep\n38 \n39     def handle_message(self, msg: Message) -> None:\n40         \"\"\"Handle a new message triggered on the current file.\"\"\"\n41         self.messages.append(msg)\n42 \n43     def writeln(self, string: str = \"\") -> None:\n44         \"\"\"Write a line in the output buffer.\"\"\"\n45         print(string, file=self.out)\n46 \n47     def display_reports(self, layout: Section) -> None:\n48         \"\"\"Display results encapsulated in the layout tree.\"\"\"\n49         self.section = 0\n50         if layout.report_id:\n51             if isinstance(layout.children[0].children[0], Text):\n52                 layout.children[0].children[0].data += f\" ({layout.report_id})\"\n53             else:\n54                 raise ValueError(f\"Incorrect child for {layout.children[0].children}\")\n55         self._display(layout)\n56 \n57     def _display(self, layout: Section) -> None:\n58         \"\"\"Display the layout.\"\"\"\n59         raise NotImplementedError()\n60 \n61     def display_messages(self, layout: Section | None) -> None:\n62         \"\"\"Hook for displaying the messages of the reporter.\n63 \n64         This will be called whenever the underlying messages\n65         needs to be displayed. For some reporters, it probably\n66         doesn't make sense to display messages as soon as they\n67         are available, so some mechanism of storing them could be used.\n68         This method can be implemented to display them after they've\n69         been aggregated.\n70         \"\"\"\n71 \n72     # Event callbacks\n73 \n74     def on_set_current_module(self, module: str, filepath: str | None) -> None:\n75         \"\"\"Hook called when a module starts to be analysed.\"\"\"\n76 \n77     def on_close(\n78         self,\n79         stats: LinterStats,\n80         previous_stats: LinterStats | None,\n81     ) -> None:\n82         \"\"\"Hook called when a module finished analyzing.\"\"\"\n",
        "intended_behavior": "The reporting system should be capable of handling messages from multiple sources (parallel jobs) without misordering or losing messages. This might require implementing a more robust method of collecting messages in a thread-safe manner and ensuring the order of messages is preserved (or appropriately handled) to produce consistent output regardless of the number of jobs."
    },
    {
        "rel_file_path": "pylint/lint/parallel.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/pylint-dev__pylint/setup_pylint-dev__pylint__3.0/pylint/lint/parallel.py",
        "start": 1,
        "end": 173,
        "class_name": null,
        "method_name": null,
        "code": "1 # Licensed under the GPL: https://www.gnu.org/licenses/old-licenses/gpl-2.0.html\n2 # For details: https://github.com/pylint-dev/pylint/blob/main/LICENSE\n3 # Copyright (c) https://github.com/pylint-dev/pylint/blob/main/CONTRIBUTORS.txt\n4 \n5 from __future__ import annotations\n6 \n7 import functools\n8 from collections import defaultdict\n9 from collections.abc import Iterable, Sequence\n10 from typing import TYPE_CHECKING, Any\n11 \n12 import dill\n13 \n14 from pylint import reporters\n15 from pylint.lint.utils import _augment_sys_path\n16 from pylint.message import Message\n17 from pylint.typing import FileItem\n18 from pylint.utils import LinterStats, merge_stats\n19 \n20 try:\n21     import multiprocessing\n22 except ImportError:\n23     multiprocessing = None  # type: ignore[assignment]\n24 \n25 try:\n26     from concurrent.futures import ProcessPoolExecutor\n27 except ImportError:\n28     ProcessPoolExecutor = None  # type: ignore[assignment,misc]\n29 \n30 if TYPE_CHECKING:\n31     from pylint.lint import PyLinter\n32 \n33 # PyLinter object used by worker processes when checking files using parallel mode\n34 # should only be used by the worker processes\n35 _worker_linter: PyLinter | None = None\n36 \n37 \n38 def _worker_initialize(\n39     linter: bytes, extra_packages_paths: Sequence[str] | None = None\n40 ) -> None:\n41     \"\"\"Function called to initialize a worker for a Process within a concurrent Pool.\n42 \n43     :param linter: A linter-class (PyLinter) instance pickled with dill\n44     :param extra_packages_paths: Extra entries to be added to `sys.path`\n45     \"\"\"\n46     global _worker_linter  # pylint: disable=global-statement\n47     _worker_linter = dill.loads(linter)\n48     assert _worker_linter\n49 \n50     # On the worker process side the messages are just collected and passed back to\n51     # parent process as _worker_check_file function's return value\n52     _worker_linter.set_reporter(reporters.CollectingReporter())\n53     _worker_linter.open()\n54 \n55     # Re-register dynamic plugins, since the pool does not have access to the\n56     # astroid module that existed when the linter was pickled.\n57     _worker_linter.load_plugin_modules(_worker_linter._dynamic_plugins, force=True)\n58     _worker_linter.load_plugin_configuration()\n59 \n60     if extra_packages_paths:\n61         _augment_sys_path(extra_packages_paths)\n62 \n63 \n64 def _worker_check_single_file(\n65     file_item: FileItem,\n66 ) -> tuple[\n67     int,\n68     str,\n69     str,\n70     str,\n71     list[Message],\n72     LinterStats,\n73     int,\n74     defaultdict[str, list[Any]],\n75 ]:\n76     if not _worker_linter:\n77         raise RuntimeError(\"Worker linter not yet initialised\")\n78     _worker_linter.open()\n79     _worker_linter.check_single_file_item(file_item)\n80     mapreduce_data = defaultdict(list)\n81     for checker in _worker_linter.get_checkers():\n82         data = checker.get_map_data()\n83         if data is not None:\n84             mapreduce_data[checker.name].append(data)\n85     msgs = _worker_linter.reporter.messages\n86     assert isinstance(_worker_linter.reporter, reporters.CollectingReporter)\n87     _worker_linter.reporter.reset()\n88     return (\n89         id(multiprocessing.current_process()),\n90         _worker_linter.current_name,\n91         file_item.filepath,\n92         _worker_linter.file_state.base_name,\n93         msgs,\n94         _worker_linter.stats,\n95         _worker_linter.msg_status,\n96         mapreduce_data,\n97     )\n98 \n99 \n100 def _merge_mapreduce_data(\n101     linter: PyLinter,\n102     all_mapreduce_data: defaultdict[int, list[defaultdict[str, list[Any]]]],\n103 ) -> None:\n104     \"\"\"Merges map/reduce data across workers, invoking relevant APIs on checkers.\"\"\"\n105     # First collate the data and prepare it, so we can send it to the checkers for\n106     # validation. The intent here is to collect all the mapreduce data for all checker-\n107     # runs across processes - that will then be passed to a static method on the\n108     # checkers to be reduced and further processed.\n109     collated_map_reduce_data: defaultdict[str, list[Any]] = defaultdict(list)\n110     for linter_data in all_mapreduce_data.values():\n111         for run_data in linter_data:\n112             for checker_name, data in run_data.items():\n113                 collated_map_reduce_data[checker_name].extend(data)\n114 \n115     # Send the data to checkers that support/require consolidated data\n116     original_checkers = linter.get_checkers()\n117     for checker in original_checkers:\n118         if checker.name in collated_map_reduce_data:\n119             # Assume that if the check has returned map/reduce data that it has the\n120             # reducer function\n121             checker.reduce_map_data(linter, collated_map_reduce_data[checker.name])\n122 \n123 \n124 def check_parallel(\n125     linter: PyLinter,\n126     jobs: int,\n127     files: Iterable[FileItem],\n128     extra_packages_paths: Sequence[str] | None = None,\n129 ) -> None:\n130     \"\"\"Use the given linter to lint the files with given amount of workers (jobs).\n131 \n132     This splits the work filestream-by-filestream. If you need to do work across\n133     multiple files, as in the similarity-checker, then implement the map/reduce mixin functionality.\n134     \"\"\"\n135     # The linter is inherited by all the pool's workers, i.e. the linter\n136     # is identical to the linter object here. This is required so that\n137     # a custom PyLinter object can be used.\n138     initializer = functools.partial(\n139         _worker_initialize, extra_packages_paths=extra_packages_paths\n140     )\n141     with ProcessPoolExecutor(\n142         max_workers=jobs, initializer=initializer, initargs=(dill.dumps(linter),)\n143     ) as executor:\n144         linter.open()\n145         all_stats = []\n146         all_mapreduce_data: defaultdict[\n147             int, list[defaultdict[str, list[Any]]]\n148         ] = defaultdict(list)\n149 \n150         # Maps each file to be worked on by a single _worker_check_single_file() call,\n151         # collecting any map/reduce data by checker module so that we can 'reduce' it\n152         # later.\n153         for (\n154             worker_idx,  # used to merge map/reduce data across workers\n155             module,\n156             file_path,\n157             base_name,\n158             messages,\n159             stats,\n160             msg_status,\n161             mapreduce_data,\n162         ) in executor.map(_worker_check_single_file, files):\n163             linter.file_state.base_name = base_name\n164             linter.file_state._is_base_filestate = False\n165             linter.set_current_module(module, file_path)\n166             for msg in messages:\n167                 linter.reporter.handle_message(msg)\n168             all_stats.append(stats)\n169             all_mapreduce_data[worker_idx].append(mapreduce_data)\n170             linter.msg_status |= msg_status\n171 \n172     _merge_mapreduce_data(linter, all_mapreduce_data)\n173     linter.stats = merge_stats([linter.stats, *all_stats])\n",
        "intended_behavior": "Methods should ensure no results are lost during aggregation and that they handle the merging of results from parallel jobs in a manner that ensures the consistency and completeness of the linting report. This could include mechanisms to verify that all spawned jobs have successfully completed and reported back their findings before concluding the linting process."
    }
]