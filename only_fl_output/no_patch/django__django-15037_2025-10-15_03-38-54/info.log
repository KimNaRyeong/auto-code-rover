2025-10-15 03:38:55.060 | INFO     | Starting overall retry 0 with model gpt-4-0125-preview
2025-10-15 03:38:58.858 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=206, output_tokens=12, cost=0.002420
2025-10-15 03:39:16.140 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=386, output_tokens=799, cost=0.027830
2025-10-15 03:39:17.464 | INFO     | registered non reproducing test 0
2025-10-15 03:39:35.283 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=2286, output_tokens=802, cost=0.046920
2025-10-15 03:39:36.444 | INFO     | registered non reproducing test 1
2025-10-15 03:39:57.883 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=1791, output_tokens=790, cost=0.041610
2025-10-15 03:39:59.060 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-15 03:40:05.680 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=509, output_tokens=247, cost=0.012500
2025-10-15 03:40:05.687 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-15 03:40:07.472 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=601, output_tokens=44, cost=0.007330
2025-10-15 03:40:07.474 | DEBUG    | Extracted a valid json.
2025-10-15 03:40:07.474 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_method(\"inspectdb\")",
        "search_method(\"handle_table\")",
        "search_code(\"FOREIGN KEY\")"
    ],
    "bug_locations": []
}
2025-10-15 03:40:07.522 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-15 03:40:07.522 | DEBUG    | <Agent search> Analyzing search results.
2025-10-15 03:40:22.325 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=997, output_tokens=621, cost=0.028600
2025-10-15 03:40:22.339 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-15 03:40:33.863 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=1834, output_tokens=506, cost=0.033520
2025-10-15 03:40:33.873 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-15 03:40:39.339 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=860, output_tokens=215, cost=0.015050
2025-10-15 03:40:39.340 | DEBUG    | Extracted a valid json.
2025-10-15 03:40:39.340 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [],
    "bug_locations": [
        {
            "file": "django/db/backends/sqlite3/introspection.py",
            "class": "",
            "method": "",
            "intended_behavior": "Correctly identify when a foreign key references a unique field instead of a primary key in another table, and generate a model field that accurately represents this relationship."
        },
        {
            "file": "django/db/backends/mysql/schema.py",
            "class": "",
            "method": "",
            "intended_behavior": "Correctly identify when a foreign key references a unique field instead of a primary key in another table, and generate a model field that accurately represents this relationship."
        },
        {
            "file": "django/db/backends/base/schema.py",
            "class": "",
            "method": "",
            "intended_behavior": "Correctly identify when a foreign key references a unique field instead of a primary key in another table, and generate a model field that accurately represents this relationship."
        }
    ]
}
2025-10-15 03:40:39.352 | DEBUG    | Bug location extracted successfully: [<file>django/db/backends/sqlite3/introspection.py</file>
<class>None</class>
<method>None</method>
<code>
1 import re
2 from collections import namedtuple
3 
4 import sqlparse
5 
6 from django.db.backends.base.introspection import (
7     BaseDatabaseIntrospection, FieldInfo as BaseFieldInfo, TableInfo,
8 )
9 from django.db.models import Index
10 from django.utils.regex_helper import _lazy_re_compile
11 
12 FieldInfo = namedtuple('FieldInfo', BaseFieldInfo._fields + ('pk', 'has_json_constraint'))
13 
14 field_size_re = _lazy_re_compile(r'^\s*(?:var)?char\s*\(\s*(\d+)\s*\)\s*$')
15 
16 
17 def get_field_size(name):
18     """ Extract the size number from a "varchar(11)" type name """
19     m = field_size_re.search(name)
20     return int(m[1]) if m else None
21 
22 
23 # This light wrapper "fakes" a dictionary interface, because some SQLite data
24 # types include variables in them -- e.g. "varchar(30)" -- and can't be matched
25 # as a simple dictionary lookup.
26 class FlexibleFieldLookupDict:
27     # Maps SQL types to Django Field types. Some of the SQL types have multiple
28     # entries here because SQLite allows for anything and doesn't normalize the
29     # field type; it uses whatever was given.
30     base_data_types_reverse = {
31         'bool': 'BooleanField',
32         'boolean': 'BooleanField',
33         'smallint': 'SmallIntegerField',
34         'smallint unsigned': 'PositiveSmallIntegerField',
35         'smallinteger': 'SmallIntegerField',
36         'int': 'IntegerField',
37         'integer': 'IntegerField',
38         'bigint': 'BigIntegerField',
39         'integer unsigned': 'PositiveIntegerField',
40         'bigint unsigned': 'PositiveBigIntegerField',
41         'decimal': 'DecimalField',
42         'real': 'FloatField',
43         'text': 'TextField',
44         'char': 'CharField',
45         'varchar': 'CharField',
46         'blob': 'BinaryField',
47         'date': 'DateField',
48         'datetime': 'DateTimeField',
49         'time': 'TimeField',
50     }
51 
52     def __getitem__(self, key):
53         key = key.lower().split('(', 1)[0].strip()
54         return self.base_data_types_reverse[key]
55 
56 
57 class DatabaseIntrospection(BaseDatabaseIntrospection):
58     data_types_reverse = FlexibleFieldLookupDict()
59 
60     def get_field_type(self, data_type, description):
61         field_type = super().get_field_type(data_type, description)
62         if description.pk and field_type in {'BigIntegerField', 'IntegerField', 'SmallIntegerField'}:
63             # No support for BigAutoField or SmallAutoField as SQLite treats
64             # all integer primary keys as signed 64-bit integers.
65             return 'AutoField'
66         if description.has_json_constraint:
67             return 'JSONField'
68         return field_type
69 
70     def get_table_list(self, cursor):
71         """Return a list of table and view names in the current database."""
72         # Skip the sqlite_sequence system table used for autoincrement key
73         # generation.
74         cursor.execute("""
75             SELECT name, type FROM sqlite_master
76             WHERE type in ('table', 'view') AND NOT name='sqlite_sequence'
77             ORDER BY name""")
78         return [TableInfo(row[0], row[1][0]) for row in cursor.fetchall()]
79 
80     def get_table_description(self, cursor, table_name):
81         """
82         Return a description of the table with the DB-API cursor.description
83         interface.
84         """
85         cursor.execute('PRAGMA table_info(%s)' % self.connection.ops.quote_name(table_name))
86         table_info = cursor.fetchall()
87         collations = self._get_column_collations(cursor, table_name)
88         json_columns = set()
89         if self.connection.features.can_introspect_json_field:
90             for line in table_info:
91                 column = line[1]
92                 json_constraint_sql = '%%json_valid("%s")%%' % column
93                 has_json_constraint = cursor.execute("""
94                     SELECT sql
95                     FROM sqlite_master
96                     WHERE
97                         type = 'table' AND
98                         name = %s AND
99                         sql LIKE %s
100                 """, [table_name, json_constraint_sql]).fetchone()
101                 if has_json_constraint:
102                     json_columns.add(column)
103         return [
104             FieldInfo(
105                 name, data_type, None, get_field_size(data_type), None, None,
106                 not notnull, default, collations.get(name), pk == 1, name in json_columns
107             )
108             for cid, name, data_type, notnull, default, pk in table_info
109         ]
110 
111     def get_sequences(self, cursor, table_name, table_fields=()):
112         pk_col = self.get_primary_key_column(cursor, table_name)
113         return [{'table': table_name, 'column': pk_col}]
114 
115     def get_relations(self, cursor, table_name):
116         """
117         Return a dictionary of {field_name: (field_name_other_table, other_table)}
118         representing all relationships to the given table.
119         """
120         # Dictionary of relations to return
121         relations = {}
122 
123         # Schema for this table
124         cursor.execute(
125             "SELECT sql, type FROM sqlite_master "
126             "WHERE tbl_name = %s AND type IN ('table', 'view')",
127             [table_name]
128         )
129         create_sql, table_type = cursor.fetchone()
130         if table_type == 'view':
131             # It might be a view, then no results will be returned
132             return relations
133         results = create_sql[create_sql.index('(') + 1:create_sql.rindex(')')]
134 
135         # Walk through and look for references to other tables. SQLite doesn't
136         # really have enforced references, but since it echoes out the SQL used
137         # to create the table we can look for REFERENCES statements used there.
138         for field_desc in results.split(','):
139             field_desc = field_desc.strip()
140             if field_desc.startswith("UNIQUE"):
141                 continue
142 
143             m = re.search(r'references (\S*) ?\(["|]?(.*)["|]?\)', field_desc, re.I)
144             if not m:
145                 continue
146             table, column = [s.strip('"') for s in m.groups()]
147 
148             if field_desc.startswith("FOREIGN KEY"):
149                 # Find name of the target FK field
150                 m = re.match(r'FOREIGN KEY\s*\(([^\)]*)\).*', field_desc, re.I)
151                 field_name = m[1].strip('"')
152             else:
153                 field_name = field_desc.split()[0].strip('"')
154 
155             cursor.execute("SELECT sql FROM sqlite_master WHERE tbl_name = %s", [table])
156             result = cursor.fetchall()[0]
157             other_table_results = result[0].strip()
158             li, ri = other_table_results.index('('), other_table_results.rindex(')')
159             other_table_results = other_table_results[li + 1:ri]
160 
161             for other_desc in other_table_results.split(','):
162                 other_desc = other_desc.strip()
163                 if other_desc.startswith('UNIQUE'):
164                     continue
165 
166                 other_name = other_desc.split(' ', 1)[0].strip('"')
167                 if other_name == column:
168                     relations[field_name] = (other_name, table)
169                     break
170 
171         return relations
172 
173     def get_key_columns(self, cursor, table_name):
174         """
175         Return a list of (column_name, referenced_table_name, referenced_column_name)
176         for all key columns in given table.
177         """
178         key_columns = []
179 
180         # Schema for this table
181         cursor.execute("SELECT sql FROM sqlite_master WHERE tbl_name = %s AND type = %s", [table_name, "table"])
182         results = cursor.fetchone()[0].strip()
183         results = results[results.index('(') + 1:results.rindex(')')]
184 
185         # Walk through and look for references to other tables. SQLite doesn't
186         # really have enforced references, but since it echoes out the SQL used
187         # to create the table we can look for REFERENCES statements used there.
188         for field_index, field_desc in enumerate(results.split(',')):
189             field_desc = field_desc.strip()
190             if field_desc.startswith("UNIQUE"):
191                 continue
192 
193             m = re.search(r'"(.*)".*references (.*) \(["|](.*)["|]\)', field_desc, re.I)
194             if not m:
195                 continue
196 
197             # This will append (column_name, referenced_table_name, referenced_column_name) to key_columns
198             key_columns.append(tuple(s.strip('"') for s in m.groups()))
199 
200         return key_columns
201 
202     def get_primary_key_column(self, cursor, table_name):
203         """Return the column name of the primary key for the given table."""
204         cursor.execute(
205             'PRAGMA table_info(%s)' % self.connection.ops.quote_name(table_name)
206         )
207         for _, name, *_, pk in cursor.fetchall():
208             if pk:
209                 return name
210         return None
211 
212     def _get_foreign_key_constraints(self, cursor, table_name):
213         constraints = {}
214         cursor.execute('PRAGMA foreign_key_list(%s)' % self.connection.ops.quote_name(table_name))
215         for row in cursor.fetchall():
216             # Remaining on_update/on_delete/match values are of no interest.
217             id_, _, table, from_, to = row[:5]
218             constraints['fk_%d' % id_] = {
219                 'columns': [from_],
220                 'primary_key': False,
221                 'unique': False,
222                 'foreign_key': (table, to),
223                 'check': False,
224                 'index': False,
225             }
226         return constraints
227 
228     def _parse_column_or_constraint_definition(self, tokens, columns):
229         token = None
230         is_constraint_definition = None
231         field_name = None
232         constraint_name = None
233         unique = False
234         unique_columns = []
235         check = False
236         check_columns = []
237         braces_deep = 0
238         for token in tokens:
239             if token.match(sqlparse.tokens.Punctuation, '('):
240                 braces_deep += 1
241             elif token.match(sqlparse.tokens.Punctuation, ')'):
242                 braces_deep -= 1
243                 if braces_deep < 0:
244                     # End of columns and constraints for table definition.
245                     break
246             elif braces_deep == 0 and token.match(sqlparse.tokens.Punctuation, ','):
247                 # End of current column or constraint definition.
248                 break
249             # Detect column or constraint definition by first token.
250             if is_constraint_definition is None:
251                 is_constraint_definition = token.match(sqlparse.tokens.Keyword, 'CONSTRAINT')
252                 if is_constraint_definition:
253                     continue
254             if is_constraint_definition:
255                 # Detect constraint name by second token.
256                 if constraint_name is None:
257                     if token.ttype in (sqlparse.tokens.Name, sqlparse.tokens.Keyword):
258                         constraint_name = token.value
259                     elif token.ttype == sqlparse.tokens.Literal.String.Symbol:
260                         constraint_name = token.value[1:-1]
261                 # Start constraint columns parsing after UNIQUE keyword.
262                 if token.match(sqlparse.tokens.Keyword, 'UNIQUE'):
263                     unique = True
264                     unique_braces_deep = braces_deep
265                 elif unique:
266                     if unique_braces_deep == braces_deep:
267                         if unique_columns:
268                             # Stop constraint parsing.
269                             unique = False
270                         continue
271                     if token.ttype in (sqlparse.tokens.Name, sqlparse.tokens.Keyword):
272                         unique_columns.append(token.value)
273                     elif token.ttype == sqlparse.tokens.Literal.String.Symbol:
274                         unique_columns.append(token.value[1:-1])
275             else:
276                 # Detect field name by first token.
277                 if field_name is None:
278                     if token.ttype in (sqlparse.tokens.Name, sqlparse.tokens.Keyword):
279                         field_name = token.value
280                     elif token.ttype == sqlparse.tokens.Literal.String.Symbol:
281                         field_name = token.value[1:-1]
282                 if token.match(sqlparse.tokens.Keyword, 'UNIQUE'):
283                     unique_columns = [field_name]
284             # Start constraint columns parsing after CHECK keyword.
285             if token.match(sqlparse.tokens.Keyword, 'CHECK'):
286                 check = True
287                 check_braces_deep = braces_deep
288             elif check:
289                 if check_braces_deep == braces_deep:
290                     if check_columns:
291                         # Stop constraint parsing.
292                         check = False
293                     continue
294                 if token.ttype in (sqlparse.tokens.Name, sqlparse.tokens.Keyword):
295                     if token.value in columns:
296                         check_columns.append(token.value)
297                 elif token.ttype == sqlparse.tokens.Literal.String.Symbol:
298                     if token.value[1:-1] in columns:
299                         check_columns.append(token.value[1:-1])
300         unique_constraint = {
301             'unique': True,
302             'columns': unique_columns,
303             'primary_key': False,
304             'foreign_key': None,
305             'check': False,
306             'index': False,
307         } if unique_columns else None
308         check_constraint = {
309             'check': True,
310             'columns': check_columns,
311             'primary_key': False,
312             'unique': False,
313             'foreign_key': None,
314             'index': False,
315         } if check_columns else None
316         return constraint_name, unique_constraint, check_constraint, token
317 
318     def _parse_table_constraints(self, sql, columns):
319         # Check constraint parsing is based of SQLite syntax diagram.
320         # https://www.sqlite.org/syntaxdiagrams.html#table-constraint
321         statement = sqlparse.parse(sql)[0]
322         constraints = {}
323         unnamed_constrains_index = 0
324         tokens = (token for token in statement.flatten() if not token.is_whitespace)
325         # Go to columns and constraint definition
326         for token in tokens:
327             if token.match(sqlparse.tokens.Punctuation, '('):
328                 break
329         # Parse columns and constraint definition
330         while True:
331             constraint_name, unique, check, end_token = self._parse_column_or_constraint_definition(tokens, columns)
332             if unique:
333                 if constraint_name:
334                     constraints[constraint_name] = unique
335                 else:
336                     unnamed_constrains_index += 1
337                     constraints['__unnamed_constraint_%s__' % unnamed_constrains_index] = unique
338             if check:
339                 if constraint_name:
340                     constraints[constraint_name] = check
341                 else:
342                     unnamed_constrains_index += 1
343                     constraints['__unnamed_constraint_%s__' % unnamed_constrains_index] = check
344             if end_token.match(sqlparse.tokens.Punctuation, ')'):
345                 break
346         return constraints
347 
348     def get_constraints(self, cursor, table_name):
349         """
350         Retrieve any constraints or keys (unique, pk, fk, check, index) across
351         one or more columns.
352         """
353         constraints = {}
354         # Find inline check constraints.
355         try:
356             table_schema = cursor.execute(
357                 "SELECT sql FROM sqlite_master WHERE type='table' and name=%s" % (
358                     self.connection.ops.quote_name(table_name),
359                 )
360             ).fetchone()[0]
361         except TypeError:
362             # table_name is a view.
363             pass
364         else:
365             columns = {info.name for info in self.get_table_description(cursor, table_name)}
366             constraints.update(self._parse_table_constraints(table_schema, columns))
367 
368         # Get the index info
369         cursor.execute("PRAGMA index_list(%s)" % self.connection.ops.quote_name(table_name))
370         for row in cursor.fetchall():
371             # SQLite 3.8.9+ has 5 columns, however older versions only give 3
372             # columns. Discard last 2 columns if there.
373             number, index, unique = row[:3]
374             cursor.execute(
375                 "SELECT sql FROM sqlite_master "
376                 "WHERE type='index' AND name=%s" % self.connection.ops.quote_name(index)
377             )
378             # There's at most one row.
379             sql, = cursor.fetchone() or (None,)
380             # Inline constraints are already detected in
381             # _parse_table_constraints(). The reasons to avoid fetching inline
382             # constraints from `PRAGMA index_list` are:
383             # - Inline constraints can have a different name and information
384             #   than what `PRAGMA index_list` gives.
385             # - Not all inline constraints may appear in `PRAGMA index_list`.
386             if not sql:
387                 # An inline constraint
388                 continue
389             # Get the index info for that index
390             cursor.execute('PRAGMA index_info(%s)' % self.connection.ops.quote_name(index))
391             for index_rank, column_rank, column in cursor.fetchall():
392                 if index not in constraints:
393                     constraints[index] = {
394                         "columns": [],
395                         "primary_key": False,
396                         "unique": bool(unique),
397                         "foreign_key": None,
398                         "check": False,
399                         "index": True,
400                     }
401                 constraints[index]['columns'].append(column)
402             # Add type and column orders for indexes
403             if constraints[index]['index']:
404                 # SQLite doesn't support any index type other than b-tree
405                 constraints[index]['type'] = Index.suffix
406                 orders = self._get_index_columns_orders(sql)
407                 if orders is not None:
408                     constraints[index]['orders'] = orders
409         # Get the PK
410         pk_column = self.get_primary_key_column(cursor, table_name)
411         if pk_column:
412             # SQLite doesn't actually give a name to the PK constraint,
413             # so we invent one. This is fine, as the SQLite backend never
414             # deletes PK constraints by name, as you can't delete constraints
415             # in SQLite; we remake the table with a new PK instead.
416             constraints["__primary__"] = {
417                 "columns": [pk_column],
418                 "primary_key": True,
419                 "unique": False,  # It's not actually a unique constraint.
420                 "foreign_key": None,
421                 "check": False,
422                 "index": False,
423             }
424         constraints.update(self._get_foreign_key_constraints(cursor, table_name))
425         return constraints
426 
427     def _get_index_columns_orders(self, sql):
428         tokens = sqlparse.parse(sql)[0]
429         for token in tokens:
430             if isinstance(token, sqlparse.sql.Parenthesis):
431                 columns = str(token).strip('()').split(', ')
432                 return ['DESC' if info.endswith('DESC') else 'ASC' for info in columns]
433         return None
434 
435     def _get_column_collations(self, cursor, table_name):
436         row = cursor.execute("""
437             SELECT sql
438             FROM sqlite_master
439             WHERE type = 'table' AND name = %s
440         """, [table_name]).fetchone()
441         if not row:
442             return {}
443 
444         sql = row[0]
445         columns = str(sqlparse.parse(sql)[0][-1]).strip('()').split(', ')
446         collations = {}
447         for column in columns:
448             tokens = column[1:].split()
449             column_name = tokens[0].strip('"')
450             for index, token in enumerate(tokens):
451                 if token == 'COLLATE':
452                     collation = tokens[index + 1]
453                     break
454             else:
455                 collation = None
456             collations[column_name] = collation
457         return collations

</code><intended_behavior>Correctly identify when a foreign key references a unique field instead of a primary key in another table, and generate a model field that accurately represents this relationship.</intended_behavior>, <file>django/db/backends/mysql/schema.py</file>
<class>None</class>
<method>None</method>
<code>
1 from django.db.backends.base.schema import BaseDatabaseSchemaEditor
2 from django.db.models import NOT_PROVIDED
3 
4 
5 class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):
6 
7     sql_rename_table = "RENAME TABLE %(old_table)s TO %(new_table)s"
8 
9     sql_alter_column_null = "MODIFY %(column)s %(type)s NULL"
10     sql_alter_column_not_null = "MODIFY %(column)s %(type)s NOT NULL"
11     sql_alter_column_type = "MODIFY %(column)s %(type)s"
12     sql_alter_column_collate = "MODIFY %(column)s %(type)s%(collation)s"
13     sql_alter_column_no_default_null = 'ALTER COLUMN %(column)s SET DEFAULT NULL'
14 
15     # No 'CASCADE' which works as a no-op in MySQL but is undocumented
16     sql_delete_column = "ALTER TABLE %(table)s DROP COLUMN %(column)s"
17 
18     sql_delete_unique = "ALTER TABLE %(table)s DROP INDEX %(name)s"
19     sql_create_column_inline_fk = (
20         ', ADD CONSTRAINT %(name)s FOREIGN KEY (%(column)s) '
21         'REFERENCES %(to_table)s(%(to_column)s)'
22     )
23     sql_delete_fk = "ALTER TABLE %(table)s DROP FOREIGN KEY %(name)s"
24 
25     sql_delete_index = "DROP INDEX %(name)s ON %(table)s"
26 
27     sql_create_pk = "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s PRIMARY KEY (%(columns)s)"
28     sql_delete_pk = "ALTER TABLE %(table)s DROP PRIMARY KEY"
29 
30     sql_create_index = 'CREATE INDEX %(name)s ON %(table)s (%(columns)s)%(extra)s'
31 
32     @property
33     def sql_delete_check(self):
34         if self.connection.mysql_is_mariadb:
35             # The name of the column check constraint is the same as the field
36             # name on MariaDB. Adding IF EXISTS clause prevents migrations
37             # crash. Constraint is removed during a "MODIFY" column statement.
38             return 'ALTER TABLE %(table)s DROP CONSTRAINT IF EXISTS %(name)s'
39         return 'ALTER TABLE %(table)s DROP CHECK %(name)s'
40 
41     @property
42     def sql_rename_column(self):
43         # MariaDB >= 10.5.2 and MySQL >= 8.0.4 support an
44         # "ALTER TABLE ... RENAME COLUMN" statement.
45         if self.connection.mysql_is_mariadb:
46             if self.connection.mysql_version >= (10, 5, 2):
47                 return super().sql_rename_column
48         elif self.connection.mysql_version >= (8, 0, 4):
49             return super().sql_rename_column
50         return 'ALTER TABLE %(table)s CHANGE %(old_column)s %(new_column)s %(type)s'
51 
52     def quote_value(self, value):
53         self.connection.ensure_connection()
54         if isinstance(value, str):
55             value = value.replace('%', '%%')
56         # MySQLdb escapes to string, PyMySQL to bytes.
57         quoted = self.connection.connection.escape(value, self.connection.connection.encoders)
58         if isinstance(value, str) and isinstance(quoted, bytes):
59             quoted = quoted.decode()
60         return quoted
61 
62     def _is_limited_data_type(self, field):
63         db_type = field.db_type(self.connection)
64         return db_type is not None and db_type.lower() in self.connection._limited_data_types
65 
66     def skip_default(self, field):
67         if not self._supports_limited_data_type_defaults:
68             return self._is_limited_data_type(field)
69         return False
70 
71     def skip_default_on_alter(self, field):
72         if self._is_limited_data_type(field) and not self.connection.mysql_is_mariadb:
73             # MySQL doesn't support defaults for BLOB and TEXT in the
74             # ALTER COLUMN statement.
75             return True
76         return False
77 
78     @property
79     def _supports_limited_data_type_defaults(self):
80         # MariaDB and MySQL >= 8.0.13 support defaults for BLOB and TEXT.
81         if self.connection.mysql_is_mariadb:
82             return True
83         return self.connection.mysql_version >= (8, 0, 13)
84 
85     def _column_default_sql(self, field):
86         if (
87             not self.connection.mysql_is_mariadb and
88             self._supports_limited_data_type_defaults and
89             self._is_limited_data_type(field)
90         ):
91             # MySQL supports defaults for BLOB and TEXT columns only if the
92             # default value is written as an expression i.e. in parentheses.
93             return '(%s)'
94         return super()._column_default_sql(field)
95 
96     def add_field(self, model, field):
97         super().add_field(model, field)
98 
99         # Simulate the effect of a one-off default.
100         # field.default may be unhashable, so a set isn't used for "in" check.
101         if self.skip_default(field) and field.default not in (None, NOT_PROVIDED):
102             effective_default = self.effective_default(field)
103             self.execute('UPDATE %(table)s SET %(column)s = %%s' % {
104                 'table': self.quote_name(model._meta.db_table),
105                 'column': self.quote_name(field.column),
106             }, [effective_default])
107 
108     def _field_should_be_indexed(self, model, field):
109         if not super()._field_should_be_indexed(model, field):
110             return False
111 
112         storage = self.connection.introspection.get_storage_engine(
113             self.connection.cursor(), model._meta.db_table
114         )
115         # No need to create an index for ForeignKey fields except if
116         # db_constraint=False because the index from that constraint won't be
117         # created.
118         if (storage == "InnoDB" and
119                 field.get_internal_type() == 'ForeignKey' and
120                 field.db_constraint):
121             return False
122         return not self._is_limited_data_type(field)
123 
124     def _delete_composed_index(self, model, fields, *args):
125         """
126         MySQL can remove an implicit FK index on a field when that field is
127         covered by another index like a unique_together. "covered" here means
128         that the more complex index starts like the simpler one.
129         http://bugs.mysql.com/bug.php?id=37910 / Django ticket #24757
130         We check here before removing the [unique|index]_together if we have to
131         recreate a FK index.
132         """
133         first_field = model._meta.get_field(fields[0])
134         if first_field.get_internal_type() == 'ForeignKey':
135             constraint_names = self._constraint_names(model, [first_field.column], index=True)
136             if not constraint_names:
137                 self.execute(
138                     self._create_index_sql(model, fields=[first_field], suffix='')
139                 )
140         return super()._delete_composed_index(model, fields, *args)
141 
142     def _set_field_new_type_null_status(self, field, new_type):
143         """
144         Keep the null property of the old field. If it has changed, it will be
145         handled separately.
146         """
147         if field.null:
148             new_type += " NULL"
149         else:
150             new_type += " NOT NULL"
151         return new_type
152 
153     def _alter_column_type_sql(self, model, old_field, new_field, new_type):
154         new_type = self._set_field_new_type_null_status(old_field, new_type)
155         return super()._alter_column_type_sql(model, old_field, new_field, new_type)
156 
157     def _rename_field_sql(self, table, old_field, new_field, new_type):
158         new_type = self._set_field_new_type_null_status(old_field, new_type)
159         return super()._rename_field_sql(table, old_field, new_field, new_type)

</code><intended_behavior>Correctly identify when a foreign key references a unique field instead of a primary key in another table, and generate a model field that accurately represents this relationship.</intended_behavior>, <file>django/db/backends/base/schema.py</file>
<class>None</class>
<method>None</method>
<code>
1 import logging
2 from datetime import datetime
3 
4 from django.db.backends.ddl_references import (
5     Columns, Expressions, ForeignKeyName, IndexName, Statement, Table,
6 )
7 from django.db.backends.utils import names_digest, split_identifier
8 from django.db.models import Deferrable, Index
9 from django.db.models.sql import Query
10 from django.db.transaction import TransactionManagementError, atomic
11 from django.utils import timezone
12 
13 logger = logging.getLogger('django.db.backends.schema')
14 
15 
16 def _is_relevant_relation(relation, altered_field):
17     """
18     When altering the given field, must constraints on its model from the given
19     relation be temporarily dropped?
20     """
21     field = relation.field
22     if field.many_to_many:
23         # M2M reverse field
24         return False
25     if altered_field.primary_key and field.to_fields == [None]:
26         # Foreign key constraint on the primary key, which is being altered.
27         return True
28     # Is the constraint targeting the field being altered?
29     return altered_field.name in field.to_fields
30 
31 
32 def _all_related_fields(model):
33     return model._meta._get_fields(forward=False, reverse=True, include_hidden=True)
34 
35 
36 def _related_non_m2m_objects(old_field, new_field):
37     # Filter out m2m objects from reverse relations.
38     # Return (old_relation, new_relation) tuples.
39     related_fields = zip(
40         (obj for obj in _all_related_fields(old_field.model) if _is_relevant_relation(obj, old_field)),
41         (obj for obj in _all_related_fields(new_field.model) if _is_relevant_relation(obj, new_field)),
42     )
43     for old_rel, new_rel in related_fields:
44         yield old_rel, new_rel
45         yield from _related_non_m2m_objects(
46             old_rel.remote_field,
47             new_rel.remote_field,
48         )
49 
50 
51 class BaseDatabaseSchemaEditor:
52     """
53     This class and its subclasses are responsible for emitting schema-changing
54     statements to the databases - model creation/removal/alteration, field
55     renaming, index fiddling, and so on.
56     """
57 
58     # Overrideable SQL templates
59     sql_create_table = "CREATE TABLE %(table)s (%(definition)s)"
60     sql_rename_table = "ALTER TABLE %(old_table)s RENAME TO %(new_table)s"
61     sql_retablespace_table = "ALTER TABLE %(table)s SET TABLESPACE %(new_tablespace)s"
62     sql_delete_table = "DROP TABLE %(table)s CASCADE"
63 
64     sql_create_column = "ALTER TABLE %(table)s ADD COLUMN %(column)s %(definition)s"
65     sql_alter_column = "ALTER TABLE %(table)s %(changes)s"
66     sql_alter_column_type = "ALTER COLUMN %(column)s TYPE %(type)s"
67     sql_alter_column_null = "ALTER COLUMN %(column)s DROP NOT NULL"
68     sql_alter_column_not_null = "ALTER COLUMN %(column)s SET NOT NULL"
69     sql_alter_column_default = "ALTER COLUMN %(column)s SET DEFAULT %(default)s"
70     sql_alter_column_no_default = "ALTER COLUMN %(column)s DROP DEFAULT"
71     sql_alter_column_no_default_null = sql_alter_column_no_default
72     sql_alter_column_collate = "ALTER COLUMN %(column)s TYPE %(type)s%(collation)s"
73     sql_delete_column = "ALTER TABLE %(table)s DROP COLUMN %(column)s CASCADE"
74     sql_rename_column = "ALTER TABLE %(table)s RENAME COLUMN %(old_column)s TO %(new_column)s"
75     sql_update_with_default = "UPDATE %(table)s SET %(column)s = %(default)s WHERE %(column)s IS NULL"
76 
77     sql_unique_constraint = "UNIQUE (%(columns)s)%(deferrable)s"
78     sql_check_constraint = "CHECK (%(check)s)"
79     sql_delete_constraint = "ALTER TABLE %(table)s DROP CONSTRAINT %(name)s"
80     sql_constraint = "CONSTRAINT %(name)s %(constraint)s"
81 
82     sql_create_check = "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s CHECK (%(check)s)"
83     sql_delete_check = sql_delete_constraint
84 
85     sql_create_unique = "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s UNIQUE (%(columns)s)%(deferrable)s"
86     sql_delete_unique = sql_delete_constraint
87 
88     sql_create_fk = (
89         "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s FOREIGN KEY (%(column)s) "
90         "REFERENCES %(to_table)s (%(to_column)s)%(deferrable)s"
91     )
92     sql_create_inline_fk = None
93     sql_create_column_inline_fk = None
94     sql_delete_fk = sql_delete_constraint
95 
96     sql_create_index = "CREATE INDEX %(name)s ON %(table)s (%(columns)s)%(include)s%(extra)s%(condition)s"
97     sql_create_unique_index = "CREATE UNIQUE INDEX %(name)s ON %(table)s (%(columns)s)%(include)s%(condition)s"
98     sql_delete_index = "DROP INDEX %(name)s"
99 
100     sql_create_pk = "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s PRIMARY KEY (%(columns)s)"
101     sql_delete_pk = sql_delete_constraint
102 
103     sql_delete_procedure = 'DROP PROCEDURE %(procedure)s'
104 
105     def __init__(self, connection, collect_sql=False, atomic=True):
106         self.connection = connection
107         self.collect_sql = collect_sql
108         if self.collect_sql:
109             self.collected_sql = []
110         self.atomic_migration = self.connection.features.can_rollback_ddl and atomic
111 
112     # State-managing methods
113 
114     def __enter__(self):
115         self.deferred_sql = []
116         if self.atomic_migration:
117             self.atomic = atomic(self.connection.alias)
118             self.atomic.__enter__()
119         return self
120 
121     def __exit__(self, exc_type, exc_value, traceback):
122         if exc_type is None:
123             for sql in self.deferred_sql:
124                 self.execute(sql)
125         if self.atomic_migration:
126             self.atomic.__exit__(exc_type, exc_value, traceback)
127 
128     # Core utility functions
129 
130     def execute(self, sql, params=()):
131         """Execute the given SQL statement, with optional parameters."""
132         # Don't perform the transactional DDL check if SQL is being collected
133         # as it's not going to be executed anyway.
134         if not self.collect_sql and self.connection.in_atomic_block and not self.connection.features.can_rollback_ddl:
135             raise TransactionManagementError(
136                 "Executing DDL statements while in a transaction on databases "
137                 "that can't perform a rollback is prohibited."
138             )
139         # Account for non-string statement objects.
140         sql = str(sql)
141         # Log the command we're running, then run it
142         logger.debug("%s; (params %r)", sql, params, extra={'params': params, 'sql': sql})
143         if self.collect_sql:
144             ending = "" if sql.rstrip().endswith(";") else ";"
145             if params is not None:
146                 self.collected_sql.append((sql % tuple(map(self.quote_value, params))) + ending)
147             else:
148                 self.collected_sql.append(sql + ending)
149         else:
150             with self.connection.cursor() as cursor:
151                 cursor.execute(sql, params)
152 
153     def quote_name(self, name):
154         return self.connection.ops.quote_name(name)
155 
156     def table_sql(self, model):
157         """Take a model and return its table definition."""
158         # Add any unique_togethers (always deferred, as some fields might be
159         # created afterward, like geometry fields with some backends).
160         for field_names in model._meta.unique_together:
161             fields = [model._meta.get_field(field) for field in field_names]
162             self.deferred_sql.append(self._create_unique_sql(model, fields))
163         # Create column SQL, add FK deferreds if needed.
164         column_sqls = []
165         params = []
166         for field in model._meta.local_fields:
167             # SQL.
168             definition, extra_params = self.column_sql(model, field)
169             if definition is None:
170                 continue
171             # Check constraints can go on the column SQL here.
172             db_params = field.db_parameters(connection=self.connection)
173             if db_params['check']:
174                 definition += ' ' + self.sql_check_constraint % db_params
175             # Autoincrement SQL (for backends with inline variant).
176             col_type_suffix = field.db_type_suffix(connection=self.connection)
177             if col_type_suffix:
178                 definition += ' %s' % col_type_suffix
179             params.extend(extra_params)
180             # FK.
181             if field.remote_field and field.db_constraint:
182                 to_table = field.remote_field.model._meta.db_table
183                 to_column = field.remote_field.model._meta.get_field(field.remote_field.field_name).column
184                 if self.sql_create_inline_fk:
185                     definition += ' ' + self.sql_create_inline_fk % {
186                         'to_table': self.quote_name(to_table),
187                         'to_column': self.quote_name(to_column),
188                     }
189                 elif self.connection.features.supports_foreign_keys:
190                     self.deferred_sql.append(self._create_fk_sql(model, field, '_fk_%(to_table)s_%(to_column)s'))
191             # Add the SQL to our big list.
192             column_sqls.append('%s %s' % (
193                 self.quote_name(field.column),
194                 definition,
195             ))
196             # Autoincrement SQL (for backends with post table definition
197             # variant).
198             if field.get_internal_type() in ('AutoField', 'BigAutoField', 'SmallAutoField'):
199                 autoinc_sql = self.connection.ops.autoinc_sql(model._meta.db_table, field.column)
200                 if autoinc_sql:
201                     self.deferred_sql.extend(autoinc_sql)
202         constraints = [constraint.constraint_sql(model, self) for constraint in model._meta.constraints]
203         sql = self.sql_create_table % {
204             'table': self.quote_name(model._meta.db_table),
205             'definition': ', '.join(constraint for constraint in (*column_sqls, *constraints) if constraint),
206         }
207         if model._meta.db_tablespace:
208             tablespace_sql = self.connection.ops.tablespace_sql(model._meta.db_tablespace)
209             if tablespace_sql:
210                 sql += ' ' + tablespace_sql
211         return sql, params
212 
213     # Field <-> database mapping functions
214 
215     def _iter_column_sql(self, column_db_type, params, model, field, include_default):
216         yield column_db_type
217         collation = getattr(field, 'db_collation', None)
218         if collation:
219             yield self._collate_sql(collation)
220         # Work out nullability.
221         null = field.null
222         # Include a default value, if requested.
223         include_default = (
224             include_default and
225             not self.skip_default(field) and
226             # Don't include a default value if it's a nullable field and the
227             # default cannot be dropped in the ALTER COLUMN statement (e.g.
228             # MySQL longtext and longblob).
229             not (null and self.skip_default_on_alter(field))
230         )
231         if include_default:
232             default_value = self.effective_default(field)
233             if default_value is not None:
234                 column_default = 'DEFAULT ' + self._column_default_sql(field)
235                 if self.connection.features.requires_literal_defaults:
236                     # Some databases can't take defaults as a parameter (Oracle).
237                     # If this is the case, the individual schema backend should
238                     # implement prepare_default().
239                     yield column_default % self.prepare_default(default_value)
240                 else:
241                     yield column_default
242                     params.append(default_value)
243         # Oracle treats the empty string ('') as null, so coerce the null
244         # option whenever '' is a possible value.
245         if (field.empty_strings_allowed and not field.primary_key and
246                 self.connection.features.interprets_empty_strings_as_nulls):
247             null = True
248         if not null:
249             yield 'NOT NULL'
250         elif not self.connection.features.implied_column_null:
251             yield 'NULL'
252         if field.primary_key:
253             yield 'PRIMARY KEY'
254         elif field.unique:
255             yield 'UNIQUE'
256         # Optionally add the tablespace if it's an implicitly indexed column.
257         tablespace = field.db_tablespace or model._meta.db_tablespace
258         if tablespace and self.connection.features.supports_tablespaces and field.unique:
259             yield self.connection.ops.tablespace_sql(tablespace, inline=True)
260 
261     def column_sql(self, model, field, include_default=False):
262         """
263         Return the column definition for a field. The field must already have
264         had set_attributes_from_name() called.
265         """
266         # Get the column's type and use that as the basis of the SQL.
267         db_params = field.db_parameters(connection=self.connection)
268         column_db_type = db_params['type']
269         # Check for fields that aren't actually columns (e.g. M2M).
270         if column_db_type is None:
271             return None, None
272         params = []
273         return ' '.join(
274             # This appends to the params being returned.
275             self._iter_column_sql(column_db_type, params, model, field, include_default)
276         ), params
277 
278     def skip_default(self, field):
279         """
280         Some backends don't accept default values for certain columns types
281         (i.e. MySQL longtext and longblob).
282         """
283         return False
284 
285     def skip_default_on_alter(self, field):
286         """
287         Some backends don't accept default values for certain columns types
288         (i.e. MySQL longtext and longblob) in the ALTER COLUMN statement.
289         """
290         return False
291 
292     def prepare_default(self, value):
293         """
294         Only used for backends which have requires_literal_defaults feature
295         """
296         raise NotImplementedError(
297             'subclasses of BaseDatabaseSchemaEditor for backends which have '
298             'requires_literal_defaults must provide a prepare_default() method'
299         )
300 
301     def _column_default_sql(self, field):
302         """
303         Return the SQL to use in a DEFAULT clause. The resulting string should
304         contain a '%s' placeholder for a default value.
305         """
306         return '%s'
307 
308     @staticmethod
309     def _effective_default(field):
310         # This method allows testing its logic without a connection.
311         if field.has_default():
312             default = field.get_default()
313         elif not field.null and field.blank and field.empty_strings_allowed:
314             if field.get_internal_type() == "BinaryField":
315                 default = b''
316             else:
317                 default = ''
318         elif getattr(field, 'auto_now', False) or getattr(field, 'auto_now_add', False):
319             internal_type = field.get_internal_type()
320             if internal_type == 'DateTimeField':
321                 default = timezone.now()
322             else:
323                 default = datetime.now()
324                 if internal_type == 'DateField':
325                     default = default.date()
326                 elif internal_type == 'TimeField':
327                     default = default.time()
328         else:
329             default = None
330         return default
331 
332     def effective_default(self, field):
333         """Return a field's effective database default value."""
334         return field.get_db_prep_save(self._effective_default(field), self.connection)
335 
336     def quote_value(self, value):
337         """
338         Return a quoted version of the value so it's safe to use in an SQL
339         string. This is not safe against injection from user code; it is
340         intended only for use in making SQL scripts or preparing default values
341         for particularly tricky backends (defaults are not user-defined, though,
342         so this is safe).
343         """
344         raise NotImplementedError()
345 
346     # Actions
347 
348     def create_model(self, model):
349         """
350         Create a table and any accompanying indexes or unique constraints for
351         the given `model`.
352         """
353         sql, params = self.table_sql(model)
354         # Prevent using [] as params, in the case a literal '%' is used in the definition
355         self.execute(sql, params or None)
356 
357         # Add any field index and index_together's (deferred as SQLite _remake_table needs it)
358         self.deferred_sql.extend(self._model_indexes_sql(model))
359 
360         # Make M2M tables
361         for field in model._meta.local_many_to_many:
362             if field.remote_field.through._meta.auto_created:
363                 self.create_model(field.remote_field.through)
364 
365     def delete_model(self, model):
366         """Delete a model from the database."""
367         # Handle auto-created intermediary models
368         for field in model._meta.local_many_to_many:
369             if field.remote_field.through._meta.auto_created:
370                 self.delete_model(field.remote_field.through)
371 
372         # Delete the table
373         self.execute(self.sql_delete_table % {
374             "table": self.quote_name(model._meta.db_table),
375         })
376         # Remove all deferred statements referencing the deleted table.
377         for sql in list(self.deferred_sql):
378             if isinstance(sql, Statement) and sql.references_table(model._meta.db_table):
379                 self.deferred_sql.remove(sql)
380 
381     def add_index(self, model, index):
382         """Add an index on a model."""
383         if (
384             index.contains_expressions and
385             not self.connection.features.supports_expression_indexes
386         ):
387             return None
388         # Index.create_sql returns interpolated SQL which makes params=None a
389         # necessity to avoid escaping attempts on execution.
390         self.execute(index.create_sql(model, self), params=None)
391 
392     def remove_index(self, model, index):
393         """Remove an index from a model."""
394         if (
395             index.contains_expressions and
396             not self.connection.features.supports_expression_indexes
397         ):
398             return None
399         self.execute(index.remove_sql(model, self))
400 
401     def add_constraint(self, model, constraint):
402         """Add a constraint to a model."""
403         sql = constraint.create_sql(model, self)
404         if sql:
405             # Constraint.create_sql returns interpolated SQL which makes
406             # params=None a necessity to avoid escaping attempts on execution.
407             self.execute(sql, params=None)
408 
409     def remove_constraint(self, model, constraint):
410         """Remove a constraint from a model."""
411         sql = constraint.remove_sql(model, self)
412         if sql:
413             self.execute(sql)
414 
415     def alter_unique_together(self, model, old_unique_together, new_unique_together):
416         """
417         Deal with a model changing its unique_together. The input
418         unique_togethers must be doubly-nested, not the single-nested
419         ["foo", "bar"] format.
420         """
421         olds = {tuple(fields) for fields in old_unique_together}
422         news = {tuple(fields) for fields in new_unique_together}
423         # Deleted uniques
424         for fields in olds.difference(news):
425             self._delete_composed_index(model, fields, {'unique': True}, self.sql_delete_unique)
426         # Created uniques
427         for field_names in news.difference(olds):
428             fields = [model._meta.get_field(field) for field in field_names]
429             self.execute(self._create_unique_sql(model, fields))
430 
431     def alter_index_together(self, model, old_index_together, new_index_together):
432         """
433         Deal with a model changing its index_together. The input
434         index_togethers must be doubly-nested, not the single-nested
435         ["foo", "bar"] format.
436         """
437         olds = {tuple(fields) for fields in old_index_together}
438         news = {tuple(fields) for fields in new_index_together}
439         # Deleted indexes
440         for fields in olds.difference(news):
441             self._delete_composed_index(
442                 model,
443                 fields,
444                 {'index': True, 'unique': False},
445                 self.sql_delete_index,
446             )
447         # Created indexes
448         for field_names in news.difference(olds):
449             fields = [model._meta.get_field(field) for field in field_names]
450             self.execute(self._create_index_sql(model, fields=fields, suffix='_idx'))
451 
452     def _delete_composed_index(self, model, fields, constraint_kwargs, sql):
453         meta_constraint_names = {constraint.name for constraint in model._meta.constraints}
454         meta_index_names = {constraint.name for constraint in model._meta.indexes}
455         columns = [model._meta.get_field(field).column for field in fields]
456         constraint_names = self._constraint_names(
457             model, columns, exclude=meta_constraint_names | meta_index_names,
458             **constraint_kwargs
459         )
460         if len(constraint_names) != 1:
461             raise ValueError("Found wrong number (%s) of constraints for %s(%s)" % (
462                 len(constraint_names),
463                 model._meta.db_table,
464                 ", ".join(columns),
465             ))
466         self.execute(self._delete_constraint_sql(sql, model, constraint_names[0]))
467 
468     def alter_db_table(self, model, old_db_table, new_db_table):
469         """Rename the table a model points to."""
470         if (old_db_table == new_db_table or
471             (self.connection.features.ignores_table_name_case and
472                 old_db_table.lower() == new_db_table.lower())):
473             return
474         self.execute(self.sql_rename_table % {
475             "old_table": self.quote_name(old_db_table),
476             "new_table": self.quote_name(new_db_table),
477         })
478         # Rename all references to the old table name.
479         for sql in self.deferred_sql:
480             if isinstance(sql, Statement):
481                 sql.rename_table_references(old_db_table, new_db_table)
482 
483     def alter_db_tablespace(self, model, old_db_tablespace, new_db_tablespace):
484         """Move a model's table between tablespaces."""
485         self.execute(self.sql_retablespace_table % {
486             "table": self.quote_name(model._meta.db_table),
487             "old_tablespace": self.quote_name(old_db_tablespace),
488             "new_tablespace": self.quote_name(new_db_tablespace),
489         })
490 
491     def add_field(self, model, field):
492         """
493         Create a field on a model. Usually involves adding a column, but may
494         involve adding a table instead (for M2M fields).
495         """
496         # Special-case implicit M2M tables
497         if field.many_to_many and field.remote_field.through._meta.auto_created:
498             return self.create_model(field.remote_field.through)
499         # Get the column's definition
500         definition, params = self.column_sql(model, field, include_default=True)
501         # It might not actually have a column behind it
502         if definition is None:
503             return
504         # Check constraints can go on the column SQL here
505         db_params = field.db_parameters(connection=self.connection)
506         if db_params['check']:
507             definition += " " + self.sql_check_constraint % db_params
508         if field.remote_field and self.connection.features.supports_foreign_keys and field.db_constraint:
509             constraint_suffix = '_fk_%(to_table)s_%(to_column)s'
510             # Add FK constraint inline, if supported.
511             if self.sql_create_column_inline_fk:
512                 to_table = field.remote_field.model._meta.db_table
513                 to_column = field.remote_field.model._meta.get_field(field.remote_field.field_name).column
514                 namespace, _ = split_identifier(model._meta.db_table)
515                 definition += " " + self.sql_create_column_inline_fk % {
516                     'name': self._fk_constraint_name(model, field, constraint_suffix),
517                     'namespace': '%s.' % self.quote_name(namespace) if namespace else '',
518                     'column': self.quote_name(field.column),
519                     'to_table': self.quote_name(to_table),
520                     'to_column': self.quote_name(to_column),
521                     'deferrable': self.connection.ops.deferrable_sql()
522                 }
523             # Otherwise, add FK constraints later.
524             else:
525                 self.deferred_sql.append(self._create_fk_sql(model, field, constraint_suffix))
526         # Build the SQL and run it
527         sql = self.sql_create_column % {
528             "table": self.quote_name(model._meta.db_table),
529             "column": self.quote_name(field.column),
530             "definition": definition,
531         }
532         self.execute(sql, params)
533         # Drop the default if we need to
534         # (Django usually does not use in-database defaults)
535         if not self.skip_default_on_alter(field) and self.effective_default(field) is not None:
536             changes_sql, params = self._alter_column_default_sql(model, None, field, drop=True)
537             sql = self.sql_alter_column % {
538                 "table": self.quote_name(model._meta.db_table),
539                 "changes": changes_sql,
540             }
541             self.execute(sql, params)
542         # Add an index, if required
543         self.deferred_sql.extend(self._field_indexes_sql(model, field))
544         # Reset connection if required
545         if self.connection.features.connection_persists_old_columns:
546             self.connection.close()
547 
548     def remove_field(self, model, field):
549         """
550         Remove a field from a model. Usually involves deleting a column,
551         but for M2Ms may involve deleting a table.
552         """
553         # Special-case implicit M2M tables
554         if field.many_to_many and field.remote_field.through._meta.auto_created:
555             return self.delete_model(field.remote_field.through)
556         # It might not actually have a column behind it
557         if field.db_parameters(connection=self.connection)['type'] is None:
558             return
559         # Drop any FK constraints, MySQL requires explicit deletion
560         if field.remote_field:
561             fk_names = self._constraint_names(model, [field.column], foreign_key=True)
562             for fk_name in fk_names:
563                 self.execute(self._delete_fk_sql(model, fk_name))
564         # Delete the column
565         sql = self.sql_delete_column % {
566             "table": self.quote_name(model._meta.db_table),
567             "column": self.quote_name(field.column),
568         }
569         self.execute(sql)
570         # Reset connection if required
571         if self.connection.features.connection_persists_old_columns:
572             self.connection.close()
573         # Remove all deferred statements referencing the deleted column.
574         for sql in list(self.deferred_sql):
575             if isinstance(sql, Statement) and sql.references_column(model._meta.db_table, field.column):
576                 self.deferred_sql.remove(sql)
577 
578     def alter_field(self, model, old_field, new_field, strict=False):
579         """
580         Allow a field's type, uniqueness, nullability, default, column,
581         constraints, etc. to be modified.
582         `old_field` is required to compute the necessary changes.
583         If `strict` is True, raise errors if the old column does not match
584         `old_field` precisely.
585         """
586         if not self._field_should_be_altered(old_field, new_field):
587             return
588         # Ensure this field is even column-based
589         old_db_params = old_field.db_parameters(connection=self.connection)
590         old_type = old_db_params['type']
591         new_db_params = new_field.db_parameters(connection=self.connection)
592         new_type = new_db_params['type']
593         if ((old_type is None and old_field.remote_field is None) or
594                 (new_type is None and new_field.remote_field is None)):
595             raise ValueError(
596                 "Cannot alter field %s into %s - they do not properly define "
597                 "db_type (are you using a badly-written custom field?)" %
598                 (old_field, new_field),
599             )
600         elif old_type is None and new_type is None and (
601                 old_field.remote_field.through and new_field.remote_field.through and
602                 old_field.remote_field.through._meta.auto_created and
603                 new_field.remote_field.through._meta.auto_created):
604             return self._alter_many_to_many(model, old_field, new_field, strict)
605         elif old_type is None and new_type is None and (
606                 old_field.remote_field.through and new_field.remote_field.through and
607                 not old_field.remote_field.through._meta.auto_created and
608                 not new_field.remote_field.through._meta.auto_created):
609             # Both sides have through models; this is a no-op.
610             return
611         elif old_type is None or new_type is None:
612             raise ValueError(
613                 "Cannot alter field %s into %s - they are not compatible types "
614                 "(you cannot alter to or from M2M fields, or add or remove "
615                 "through= on M2M fields)" % (old_field, new_field)
616             )
617 
618         self._alter_field(model, old_field, new_field, old_type, new_type,
619                           old_db_params, new_db_params, strict)
620 
621     def _alter_field(self, model, old_field, new_field, old_type, new_type,
622                      old_db_params, new_db_params, strict=False):
623         """Perform a "physical" (non-ManyToMany) field update."""
624         # Drop any FK constraints, we'll remake them later
625         fks_dropped = set()
626         if (
627             self.connection.features.supports_foreign_keys and
628             old_field.remote_field and
629             old_field.db_constraint
630         ):
631             fk_names = self._constraint_names(model, [old_field.column], foreign_key=True)
632             if strict and len(fk_names) != 1:
633                 raise ValueError("Found wrong number (%s) of foreign key constraints for %s.%s" % (
634                     len(fk_names),
635                     model._meta.db_table,
636                     old_field.column,
637                 ))
638             for fk_name in fk_names:
639                 fks_dropped.add((old_field.column,))
640                 self.execute(self._delete_fk_sql(model, fk_name))
641         # Has unique been removed?
642         if old_field.unique and (not new_field.unique or self._field_became_primary_key(old_field, new_field)):
643             # Find the unique constraint for this field
644             meta_constraint_names = {constraint.name for constraint in model._meta.constraints}
645             constraint_names = self._constraint_names(
646                 model, [old_field.column], unique=True, primary_key=False,
647                 exclude=meta_constraint_names,
648             )
649             if strict and len(constraint_names) != 1:
650                 raise ValueError("Found wrong number (%s) of unique constraints for %s.%s" % (
651                     len(constraint_names),
652                     model._meta.db_table,
653                     old_field.column,
654                 ))
655             for constraint_name in constraint_names:
656                 self.execute(self._delete_unique_sql(model, constraint_name))
657         # Drop incoming FK constraints if the field is a primary key or unique,
658         # which might be a to_field target, and things are going to change.
659         drop_foreign_keys = (
660             self.connection.features.supports_foreign_keys and (
661                 (old_field.primary_key and new_field.primary_key) or
662                 (old_field.unique and new_field.unique)
663             ) and old_type != new_type
664         )
665         if drop_foreign_keys:
666             # '_meta.related_field' also contains M2M reverse fields, these
667             # will be filtered out
668             for _old_rel, new_rel in _related_non_m2m_objects(old_field, new_field):
669                 rel_fk_names = self._constraint_names(
670                     new_rel.related_model, [new_rel.field.column], foreign_key=True
671                 )
672                 for fk_name in rel_fk_names:
673                     self.execute(self._delete_fk_sql(new_rel.related_model, fk_name))
674         # Removed an index? (no strict check, as multiple indexes are possible)
675         # Remove indexes if db_index switched to False or a unique constraint
676         # will now be used in lieu of an index. The following lines from the
677         # truth table show all True cases; the rest are False:
678         #
679         # old_field.db_index | old_field.unique | new_field.db_index | new_field.unique
680         # ------------------------------------------------------------------------------
681         # True               | False            | False              | False
682         # True               | False            | False              | True
683         # True               | False            | True               | True
684         if old_field.db_index and not old_field.unique and (not new_field.db_index or new_field.unique):
685             # Find the index for this field
686             meta_index_names = {index.name for index in model._meta.indexes}
687             # Retrieve only BTREE indexes since this is what's created with
688             # db_index=True.
689             index_names = self._constraint_names(
690                 model, [old_field.column], index=True, type_=Index.suffix,
691                 exclude=meta_index_names,
692             )
693             for index_name in index_names:
694                 # The only way to check if an index was created with
695                 # db_index=True or with Index(['field'], name='foo')
696                 # is to look at its name (refs #28053).
697                 self.execute(self._delete_index_sql(model, index_name))
698         # Change check constraints?
699         if old_db_params['check'] != new_db_params['check'] and old_db_params['check']:
700             meta_constraint_names = {constraint.name for constraint in model._meta.constraints}
701             constraint_names = self._constraint_names(
702                 model, [old_field.column], check=True,
703                 exclude=meta_constraint_names,
704             )
705             if strict and len(constraint_names) != 1:
706                 raise ValueError("Found wrong number (%s) of check constraints for %s.%s" % (
707                     len(constraint_names),
708                     model._meta.db_table,
709                     old_field.column,
710                 ))
711             for constraint_name in constraint_names:
712                 self.execute(self._delete_check_sql(model, constraint_name))
713         # Have they renamed the column?
714         if old_field.column != new_field.column:
715             self.execute(self._rename_field_sql(model._meta.db_table, old_field, new_field, new_type))
716             # Rename all references to the renamed column.
717             for sql in self.deferred_sql:
718                 if isinstance(sql, Statement):
719                     sql.rename_column_references(model._meta.db_table, old_field.column, new_field.column)
720         # Next, start accumulating actions to do
721         actions = []
722         null_actions = []
723         post_actions = []
724         # Collation change?
725         old_collation = getattr(old_field, 'db_collation', None)
726         new_collation = getattr(new_field, 'db_collation', None)
727         if old_collation != new_collation:
728             # Collation change handles also a type change.
729             fragment = self._alter_column_collation_sql(model, new_field, new_type, new_collation)
730             actions.append(fragment)
731         # Type change?
732         elif old_type != new_type:
733             fragment, other_actions = self._alter_column_type_sql(model, old_field, new_field, new_type)
734             actions.append(fragment)
735             post_actions.extend(other_actions)
736         # When changing a column NULL constraint to NOT NULL with a given
737         # default value, we need to perform 4 steps:
738         #  1. Add a default for new incoming writes
739         #  2. Update existing NULL rows with new default
740         #  3. Replace NULL constraint with NOT NULL
741         #  4. Drop the default again.
742         # Default change?
743         needs_database_default = False
744         if old_field.null and not new_field.null:
745             old_default = self.effective_default(old_field)
746             new_default = self.effective_default(new_field)
747             if (
748                 not self.skip_default_on_alter(new_field) and
749                 old_default != new_default and
750                 new_default is not None
751             ):
752                 needs_database_default = True
753                 actions.append(self._alter_column_default_sql(model, old_field, new_field))
754         # Nullability change?
755         if old_field.null != new_field.null:
756             fragment = self._alter_column_null_sql(model, old_field, new_field)
757             if fragment:
758                 null_actions.append(fragment)
759         # Only if we have a default and there is a change from NULL to NOT NULL
760         four_way_default_alteration = (
761             new_field.has_default() and
762             (old_field.null and not new_field.null)
763         )
764         if actions or null_actions:
765             if not four_way_default_alteration:
766                 # If we don't have to do a 4-way default alteration we can
767                 # directly run a (NOT) NULL alteration
768                 actions = actions + null_actions
769             # Combine actions together if we can (e.g. postgres)
770             if self.connection.features.supports_combined_alters and actions:
771                 sql, params = tuple(zip(*actions))
772                 actions = [(", ".join(sql), sum(params, []))]
773             # Apply those actions
774             for sql, params in actions:
775                 self.execute(
776                     self.sql_alter_column % {
777                         "table": self.quote_name(model._meta.db_table),
778                         "changes": sql,
779                     },
780                     params,
781                 )
782             if four_way_default_alteration:
783                 # Update existing rows with default value
784                 self.execute(
785                     self.sql_update_with_default % {
786                         "table": self.quote_name(model._meta.db_table),
787                         "column": self.quote_name(new_field.column),
788                         "default": "%s",
789                     },
790                     [new_default],
791                 )
792                 # Since we didn't run a NOT NULL change before we need to do it
793                 # now
794                 for sql, params in null_actions:
795                     self.execute(
796                         self.sql_alter_column % {
797                             "table": self.quote_name(model._meta.db_table),
798                             "changes": sql,
799                         },
800                         params,
801                     )
802         if post_actions:
803             for sql, params in post_actions:
804                 self.execute(sql, params)
805         # If primary_key changed to False, delete the primary key constraint.
806         if old_field.primary_key and not new_field.primary_key:
807             self._delete_primary_key(model, strict)
808         # Added a unique?
809         if self._unique_should_be_added(old_field, new_field):
810             self.execute(self._create_unique_sql(model, [new_field]))
811         # Added an index? Add an index if db_index switched to True or a unique
812         # constraint will no longer be used in lieu of an index. The following
813         # lines from the truth table show all True cases; the rest are False:
814         #
815         # old_field.db_index | old_field.unique | new_field.db_index | new_field.unique
816         # ------------------------------------------------------------------------------
817         # False              | False            | True               | False
818         # False              | True             | True               | False
819         # True               | True             | True               | False
820         if (not old_field.db_index or old_field.unique) and new_field.db_index and not new_field.unique:
821             self.execute(self._create_index_sql(model, fields=[new_field]))
822         # Type alteration on primary key? Then we need to alter the column
823         # referring to us.
824         rels_to_update = []
825         if drop_foreign_keys:
826             rels_to_update.extend(_related_non_m2m_objects(old_field, new_field))
827         # Changed to become primary key?
828         if self._field_became_primary_key(old_field, new_field):
829             # Make the new one
830             self.execute(self._create_primary_key_sql(model, new_field))
831             # Update all referencing columns
832             rels_to_update.extend(_related_non_m2m_objects(old_field, new_field))
833         # Handle our type alters on the other end of rels from the PK stuff above
834         for old_rel, new_rel in rels_to_update:
835             rel_db_params = new_rel.field.db_parameters(connection=self.connection)
836             rel_type = rel_db_params['type']
837             fragment, other_actions = self._alter_column_type_sql(
838                 new_rel.related_model, old_rel.field, new_rel.field, rel_type
839             )
840             self.execute(
841                 self.sql_alter_column % {
842                     "table": self.quote_name(new_rel.related_model._meta.db_table),
843                     "changes": fragment[0],
844                 },
845                 fragment[1],
846             )
847             for sql, params in other_actions:
848                 self.execute(sql, params)
849         # Does it have a foreign key?
850         if (self.connection.features.supports_foreign_keys and new_field.remote_field and
851                 (fks_dropped or not old_field.remote_field or not old_field.db_constraint) and
852                 new_field.db_constraint):
853             self.execute(self._create_fk_sql(model, new_field, "_fk_%(to_table)s_%(to_column)s"))
854         # Rebuild FKs that pointed to us if we previously had to drop them
855         if drop_foreign_keys:
856             for _, rel in rels_to_update:
857                 if rel.field.db_constraint:
858                     self.execute(self._create_fk_sql(rel.related_model, rel.field, "_fk"))
859         # Does it have check constraints we need to add?
860         if old_db_params['check'] != new_db_params['check'] and new_db_params['check']:
861             constraint_name = self._create_index_name(model._meta.db_table, [new_field.column], suffix='_check')
862             self.execute(self._create_check_sql(model, constraint_name, new_db_params['check']))
863         # Drop the default if we need to
864         # (Django usually does not use in-database defaults)
865         if needs_database_default:
866             changes_sql, params = self._alter_column_default_sql(model, old_field, new_field, drop=True)
867             sql = self.sql_alter_column % {
868                 "table": self.quote_name(model._meta.db_table),
869                 "changes": changes_sql,
870             }
871             self.execute(sql, params)
872         # Reset connection if required
873         if self.connection.features.connection_persists_old_columns:
874             self.connection.close()
875 
876     def _alter_column_null_sql(self, model, old_field, new_field):
877         """
878         Hook to specialize column null alteration.
879 
880         Return a (sql, params) fragment to set a column to null or non-null
881         as required by new_field, or None if no changes are required.
882         """
883         if (
884             self.connection.features.interprets_empty_strings_as_nulls and
885             new_field.empty_strings_allowed
886         ):
887             # The field is nullable in the database anyway, leave it alone.
888             return
889         else:
890             new_db_params = new_field.db_parameters(connection=self.connection)
891             sql = self.sql_alter_column_null if new_field.null else self.sql_alter_column_not_null
892             return (
893                 sql % {
894                     'column': self.quote_name(new_field.column),
895                     'type': new_db_params['type'],
896                 },
897                 [],
898             )
899 
900     def _alter_column_default_sql(self, model, old_field, new_field, drop=False):
901         """
902         Hook to specialize column default alteration.
903 
904         Return a (sql, params) fragment to add or drop (depending on the drop
905         argument) a default to new_field's column.
906         """
907         new_default = self.effective_default(new_field)
908         default = self._column_default_sql(new_field)
909         params = [new_default]
910 
911         if drop:
912             params = []
913         elif self.connection.features.requires_literal_defaults:
914             # Some databases (Oracle) can't take defaults as a parameter
915             # If this is the case, the SchemaEditor for that database should
916             # implement prepare_default().
917             default = self.prepare_default(new_default)
918             params = []
919 
920         new_db_params = new_field.db_parameters(connection=self.connection)
921         if drop:
922             if new_field.null:
923                 sql = self.sql_alter_column_no_default_null
924             else:
925                 sql = self.sql_alter_column_no_default
926         else:
927             sql = self.sql_alter_column_default
928         return (
929             sql % {
930                 'column': self.quote_name(new_field.column),
931                 'type': new_db_params['type'],
932                 'default': default,
933             },
934             params,
935         )
936 
937     def _alter_column_type_sql(self, model, old_field, new_field, new_type):
938         """
939         Hook to specialize column type alteration for different backends,
940         for cases when a creation type is different to an alteration type
941         (e.g. SERIAL in PostgreSQL, PostGIS fields).
942 
943         Return a two-tuple of: an SQL fragment of (sql, params) to insert into
944         an ALTER TABLE statement and a list of extra (sql, params) tuples to
945         run once the field is altered.
946         """
947         return (
948             (
949                 self.sql_alter_column_type % {
950                     "column": self.quote_name(new_field.column),
951                     "type": new_type,
952                 },
953                 [],
954             ),
955             [],
956         )
957 
958     def _alter_column_collation_sql(self, model, new_field, new_type, new_collation):
959         return (
960             self.sql_alter_column_collate % {
961                 'column': self.quote_name(new_field.column),
962                 'type': new_type,
963                 'collation': ' ' + self._collate_sql(new_collation) if new_collation else '',
964             },
965             [],
966         )
967 
968     def _alter_many_to_many(self, model, old_field, new_field, strict):
969         """Alter M2Ms to repoint their to= endpoints."""
970         # Rename the through table
971         if old_field.remote_field.through._meta.db_table != new_field.remote_field.through._meta.db_table:
972             self.alter_db_table(old_field.remote_field.through, old_field.remote_field.through._meta.db_table,
973                                 new_field.remote_field.through._meta.db_table)
974         # Repoint the FK to the other side
975         self.alter_field(
976             new_field.remote_field.through,
977             # We need the field that points to the target model, so we can tell alter_field to change it -
978             # this is m2m_reverse_field_name() (as opposed to m2m_field_name, which points to our model)
979             old_field.remote_field.through._meta.get_field(old_field.m2m_reverse_field_name()),
980             new_field.remote_field.through._meta.get_field(new_field.m2m_reverse_field_name()),
981         )
982         self.alter_field(
983             new_field.remote_field.through,
984             # for self-referential models we need to alter field from the other end too
985             old_field.remote_field.through._meta.get_field(old_field.m2m_field_name()),
986             new_field.remote_field.through._meta.get_field(new_field.m2m_field_name()),
987         )
988 
989     def _create_index_name(self, table_name, column_names, suffix=""):
990         """
991         Generate a unique name for an index/unique constraint.
992 
993         The name is divided into 3 parts: the table name, the column names,
994         and a unique digest and suffix.
995         """
996         _, table_name = split_identifier(table_name)
997         hash_suffix_part = '%s%s' % (names_digest(table_name, *column_names, length=8), suffix)
998         max_length = self.connection.ops.max_name_length() or 200
999         # If everything fits into max_length, use that name.
1000         index_name = '%s_%s_%s' % (table_name, '_'.join(column_names), hash_suffix_part)
1001         if len(index_name) <= max_length:
1002             return index_name
1003         # Shorten a long suffix.
1004         if len(hash_suffix_part) > max_length / 3:
1005             hash_suffix_part = hash_suffix_part[:max_length // 3]
1006         other_length = (max_length - len(hash_suffix_part)) // 2 - 1
1007         index_name = '%s_%s_%s' % (
1008             table_name[:other_length],
1009             '_'.join(column_names)[:other_length],
1010             hash_suffix_part,
1011         )
1012         # Prepend D if needed to prevent the name from starting with an
1013         # underscore or a number (not permitted on Oracle).
1014         if index_name[0] == "_" or index_name[0].isdigit():
1015             index_name = "D%s" % index_name[:-1]
1016         return index_name
1017 
1018     def _get_index_tablespace_sql(self, model, fields, db_tablespace=None):
1019         if db_tablespace is None:
1020             if len(fields) == 1 and fields[0].db_tablespace:
1021                 db_tablespace = fields[0].db_tablespace
1022             elif model._meta.db_tablespace:
1023                 db_tablespace = model._meta.db_tablespace
1024         if db_tablespace is not None:
1025             return ' ' + self.connection.ops.tablespace_sql(db_tablespace)
1026         return ''
1027 
1028     def _index_condition_sql(self, condition):
1029         if condition:
1030             return ' WHERE ' + condition
1031         return ''
1032 
1033     def _index_include_sql(self, model, columns):
1034         if not columns or not self.connection.features.supports_covering_indexes:
1035             return ''
1036         return Statement(
1037             ' INCLUDE (%(columns)s)',
1038             columns=Columns(model._meta.db_table, columns, self.quote_name),
1039         )
1040 
1041     def _create_index_sql(self, model, *, fields=None, name=None, suffix='', using='',
1042                           db_tablespace=None, col_suffixes=(), sql=None, opclasses=(),
1043                           condition=None, include=None, expressions=None):
1044         """
1045         Return the SQL statement to create the index for one or several fields
1046         or expressions. `sql` can be specified if the syntax differs from the
1047         standard (GIS indexes, ...).
1048         """
1049         fields = fields or []
1050         expressions = expressions or []
1051         compiler = Query(model, alias_cols=False).get_compiler(
1052             connection=self.connection,
1053         )
1054         tablespace_sql = self._get_index_tablespace_sql(model, fields, db_tablespace=db_tablespace)
1055         columns = [field.column for field in fields]
1056         sql_create_index = sql or self.sql_create_index
1057         table = model._meta.db_table
1058 
1059         def create_index_name(*args, **kwargs):
1060             nonlocal name
1061             if name is None:
1062                 name = self._create_index_name(*args, **kwargs)
1063             return self.quote_name(name)
1064 
1065         return Statement(
1066             sql_create_index,
1067             table=Table(table, self.quote_name),
1068             name=IndexName(table, columns, suffix, create_index_name),
1069             using=using,
1070             columns=(
1071                 self._index_columns(table, columns, col_suffixes, opclasses)
1072                 if columns
1073                 else Expressions(table, expressions, compiler, self.quote_value)
1074             ),
1075             extra=tablespace_sql,
1076             condition=self._index_condition_sql(condition),
1077             include=self._index_include_sql(model, include),
1078         )
1079 
1080     def _delete_index_sql(self, model, name, sql=None):
1081         return Statement(
1082             sql or self.sql_delete_index,
1083             table=Table(model._meta.db_table, self.quote_name),
1084             name=self.quote_name(name),
1085         )
1086 
1087     def _index_columns(self, table, columns, col_suffixes, opclasses):
1088         return Columns(table, columns, self.quote_name, col_suffixes=col_suffixes)
1089 
1090     def _model_indexes_sql(self, model):
1091         """
1092         Return a list of all index SQL statements (field indexes,
1093         index_together, Meta.indexes) for the specified model.
1094         """
1095         if not model._meta.managed or model._meta.proxy or model._meta.swapped:
1096             return []
1097         output = []
1098         for field in model._meta.local_fields:
1099             output.extend(self._field_indexes_sql(model, field))
1100 
1101         for field_names in model._meta.index_together:
1102             fields = [model._meta.get_field(field) for field in field_names]
1103             output.append(self._create_index_sql(model, fields=fields, suffix='_idx'))
1104 
1105         for index in model._meta.indexes:
1106             if (
1107                 not index.contains_expressions or
1108                 self.connection.features.supports_expression_indexes
1109             ):
1110                 output.append(index.create_sql(model, self))
1111         return output
1112 
1113     def _field_indexes_sql(self, model, field):
1114         """
1115         Return a list of all index SQL statements for the specified field.
1116         """
1117         output = []
1118         if self._field_should_be_indexed(model, field):
1119             output.append(self._create_index_sql(model, fields=[field]))
1120         return output
1121 
1122     def _field_should_be_altered(self, old_field, new_field):
1123         _, old_path, old_args, old_kwargs = old_field.deconstruct()
1124         _, new_path, new_args, new_kwargs = new_field.deconstruct()
1125         # Don't alter when:
1126         # - changing only a field name
1127         # - changing an attribute that doesn't affect the schema
1128         # - adding only a db_column and the column name is not changed
1129         non_database_attrs = [
1130             'blank',
1131             'db_column',
1132             'editable',
1133             'error_messages',
1134             'help_text',
1135             'limit_choices_to',
1136             # Database-level options are not supported, see #21961.
1137             'on_delete',
1138             'related_name',
1139             'related_query_name',
1140             'validators',
1141             'verbose_name',
1142         ]
1143         for attr in non_database_attrs:
1144             old_kwargs.pop(attr, None)
1145             new_kwargs.pop(attr, None)
1146         return (
1147             self.quote_name(old_field.column) != self.quote_name(new_field.column) or
1148             (old_path, old_args, old_kwargs) != (new_path, new_args, new_kwargs)
1149         )
1150 
1151     def _field_should_be_indexed(self, model, field):
1152         return field.db_index and not field.unique
1153 
1154     def _field_became_primary_key(self, old_field, new_field):
1155         return not old_field.primary_key and new_field.primary_key
1156 
1157     def _unique_should_be_added(self, old_field, new_field):
1158         return (
1159             not new_field.primary_key and
1160             new_field.unique and
1161             (not old_field.unique or old_field.primary_key)
1162         )
1163 
1164     def _rename_field_sql(self, table, old_field, new_field, new_type):
1165         return self.sql_rename_column % {
1166             "table": self.quote_name(table),
1167             "old_column": self.quote_name(old_field.column),
1168             "new_column": self.quote_name(new_field.column),
1169             "type": new_type,
1170         }
1171 
1172     def _create_fk_sql(self, model, field, suffix):
1173         table = Table(model._meta.db_table, self.quote_name)
1174         name = self._fk_constraint_name(model, field, suffix)
1175         column = Columns(model._meta.db_table, [field.column], self.quote_name)
1176         to_table = Table(field.target_field.model._meta.db_table, self.quote_name)
1177         to_column = Columns(field.target_field.model._meta.db_table, [field.target_field.column], self.quote_name)
1178         deferrable = self.connection.ops.deferrable_sql()
1179         return Statement(
1180             self.sql_create_fk,
1181             table=table,
1182             name=name,
1183             column=column,
1184             to_table=to_table,
1185             to_column=to_column,
1186             deferrable=deferrable,
1187         )
1188 
1189     def _fk_constraint_name(self, model, field, suffix):
1190         def create_fk_name(*args, **kwargs):
1191             return self.quote_name(self._create_index_name(*args, **kwargs))
1192 
1193         return ForeignKeyName(
1194             model._meta.db_table,
1195             [field.column],
1196             split_identifier(field.target_field.model._meta.db_table)[1],
1197             [field.target_field.column],
1198             suffix,
1199             create_fk_name,
1200         )
1201 
1202     def _delete_fk_sql(self, model, name):
1203         return self._delete_constraint_sql(self.sql_delete_fk, model, name)
1204 
1205     def _deferrable_constraint_sql(self, deferrable):
1206         if deferrable is None:
1207             return ''
1208         if deferrable == Deferrable.DEFERRED:
1209             return ' DEFERRABLE INITIALLY DEFERRED'
1210         if deferrable == Deferrable.IMMEDIATE:
1211             return ' DEFERRABLE INITIALLY IMMEDIATE'
1212 
1213     def _unique_sql(
1214         self, model, fields, name, condition=None, deferrable=None,
1215         include=None, opclasses=None, expressions=None,
1216     ):
1217         if (
1218             deferrable and
1219             not self.connection.features.supports_deferrable_unique_constraints
1220         ):
1221             return None
1222         if condition or include or opclasses or expressions:
1223             # Databases support conditional, covering, and functional unique
1224             # constraints via a unique index.
1225             sql = self._create_unique_sql(
1226                 model,
1227                 fields,
1228                 name=name,
1229                 condition=condition,
1230                 include=include,
1231                 opclasses=opclasses,
1232                 expressions=expressions,
1233             )
1234             if sql:
1235                 self.deferred_sql.append(sql)
1236             return None
1237         constraint = self.sql_unique_constraint % {
1238             'columns': ', '.join([self.quote_name(field.column) for field in fields]),
1239             'deferrable': self._deferrable_constraint_sql(deferrable),
1240         }
1241         return self.sql_constraint % {
1242             'name': self.quote_name(name),
1243             'constraint': constraint,
1244         }
1245 
1246     def _create_unique_sql(
1247         self, model, fields, name=None, condition=None, deferrable=None,
1248         include=None, opclasses=None, expressions=None,
1249     ):
1250         if (
1251             (
1252                 deferrable and
1253                 not self.connection.features.supports_deferrable_unique_constraints
1254             ) or
1255             (condition and not self.connection.features.supports_partial_indexes) or
1256             (include and not self.connection.features.supports_covering_indexes) or
1257             (expressions and not self.connection.features.supports_expression_indexes)
1258         ):
1259             return None
1260 
1261         def create_unique_name(*args, **kwargs):
1262             return self.quote_name(self._create_index_name(*args, **kwargs))
1263 
1264         compiler = Query(model, alias_cols=False).get_compiler(connection=self.connection)
1265         table = model._meta.db_table
1266         columns = [field.column for field in fields]
1267         if name is None:
1268             name = IndexName(table, columns, '_uniq', create_unique_name)
1269         else:
1270             name = self.quote_name(name)
1271         if condition or include or opclasses or expressions:
1272             sql = self.sql_create_unique_index
1273         else:
1274             sql = self.sql_create_unique
1275         if columns:
1276             columns = self._index_columns(table, columns, col_suffixes=(), opclasses=opclasses)
1277         else:
1278             columns = Expressions(table, expressions, compiler, self.quote_value)
1279         return Statement(
1280             sql,
1281             table=Table(table, self.quote_name),
1282             name=name,
1283             columns=columns,
1284             condition=self._index_condition_sql(condition),
1285             deferrable=self._deferrable_constraint_sql(deferrable),
1286             include=self._index_include_sql(model, include),
1287         )
1288 
1289     def _delete_unique_sql(
1290         self, model, name, condition=None, deferrable=None, include=None,
1291         opclasses=None, expressions=None,
1292     ):
1293         if (
1294             (
1295                 deferrable and
1296                 not self.connection.features.supports_deferrable_unique_constraints
1297             ) or
1298             (condition and not self.connection.features.supports_partial_indexes) or
1299             (include and not self.connection.features.supports_covering_indexes) or
1300             (expressions and not self.connection.features.supports_expression_indexes)
1301 
1302         ):
1303             return None
1304         if condition or include or opclasses or expressions:
1305             sql = self.sql_delete_index
1306         else:
1307             sql = self.sql_delete_unique
1308         return self._delete_constraint_sql(sql, model, name)
1309 
1310     def _check_sql(self, name, check):
1311         return self.sql_constraint % {
1312             'name': self.quote_name(name),
1313             'constraint': self.sql_check_constraint % {'check': check},
1314         }
1315 
1316     def _create_check_sql(self, model, name, check):
1317         return Statement(
1318             self.sql_create_check,
1319             table=Table(model._meta.db_table, self.quote_name),
1320             name=self.quote_name(name),
1321             check=check,
1322         )
1323 
1324     def _delete_check_sql(self, model, name):
1325         return self._delete_constraint_sql(self.sql_delete_check, model, name)
1326 
1327     def _delete_constraint_sql(self, template, model, name):
1328         return Statement(
1329             template,
1330             table=Table(model._meta.db_table, self.quote_name),
1331             name=self.quote_name(name),
1332         )
1333 
1334     def _constraint_names(self, model, column_names=None, unique=None,
1335                           primary_key=None, index=None, foreign_key=None,
1336                           check=None, type_=None, exclude=None):
1337         """Return all constraint names matching the columns and conditions."""
1338         if column_names is not None:
1339             column_names = [
1340                 self.connection.introspection.identifier_converter(name)
1341                 for name in column_names
1342             ]
1343         with self.connection.cursor() as cursor:
1344             constraints = self.connection.introspection.get_constraints(cursor, model._meta.db_table)
1345         result = []
1346         for name, infodict in constraints.items():
1347             if column_names is None or column_names == infodict['columns']:
1348                 if unique is not None and infodict['unique'] != unique:
1349                     continue
1350                 if primary_key is not None and infodict['primary_key'] != primary_key:
1351                     continue
1352                 if index is not None and infodict['index'] != index:
1353                     continue
1354                 if check is not None and infodict['check'] != check:
1355                     continue
1356                 if foreign_key is not None and not infodict['foreign_key']:
1357                     continue
1358                 if type_ is not None and infodict['type'] != type_:
1359                     continue
1360                 if not exclude or name not in exclude:
1361                     result.append(name)
1362         return result
1363 
1364     def _delete_primary_key(self, model, strict=False):
1365         constraint_names = self._constraint_names(model, primary_key=True)
1366         if strict and len(constraint_names) != 1:
1367             raise ValueError('Found wrong number (%s) of PK constraints for %s' % (
1368                 len(constraint_names),
1369                 model._meta.db_table,
1370             ))
1371         for constraint_name in constraint_names:
1372             self.execute(self._delete_primary_key_sql(model, constraint_name))
1373 
1374     def _create_primary_key_sql(self, model, field):
1375         return Statement(
1376             self.sql_create_pk,
1377             table=Table(model._meta.db_table, self.quote_name),
1378             name=self.quote_name(
1379                 self._create_index_name(model._meta.db_table, [field.column], suffix="_pk")
1380             ),
1381             columns=Columns(model._meta.db_table, [field.column], self.quote_name),
1382         )
1383 
1384     def _delete_primary_key_sql(self, model, name):
1385         return self._delete_constraint_sql(self.sql_delete_pk, model, name)
1386 
1387     def _collate_sql(self, collation):
1388         return 'COLLATE ' + self.quote_name(collation)
1389 
1390     def remove_procedure(self, procedure_name, param_types=()):
1391         sql = self.sql_delete_procedure % {
1392             'procedure': self.quote_name(procedure_name),
1393             'param_types': ','.join(param_types),
1394         }
1395         self.execute(sql)

</code><intended_behavior>Correctly identify when a foreign key references a unique field instead of a primary key in another table, and generate a model field that accurately represents this relationship.</intended_behavior>]
2025-10-15 03:40:39.352 | INFO     | Search completed. Bug locations: [<file>django/db/backends/sqlite3/introspection.py</file>
<class>None</class>
<method>None</method>
<code>
1 import re
2 from collections import namedtuple
3 
4 import sqlparse
5 
6 from django.db.backends.base.introspection import (
7     BaseDatabaseIntrospection, FieldInfo as BaseFieldInfo, TableInfo,
8 )
9 from django.db.models import Index
10 from django.utils.regex_helper import _lazy_re_compile
11 
12 FieldInfo = namedtuple('FieldInfo', BaseFieldInfo._fields + ('pk', 'has_json_constraint'))
13 
14 field_size_re = _lazy_re_compile(r'^\s*(?:var)?char\s*\(\s*(\d+)\s*\)\s*$')
15 
16 
17 def get_field_size(name):
18     """ Extract the size number from a "varchar(11)" type name """
19     m = field_size_re.search(name)
20     return int(m[1]) if m else None
21 
22 
23 # This light wrapper "fakes" a dictionary interface, because some SQLite data
24 # types include variables in them -- e.g. "varchar(30)" -- and can't be matched
25 # as a simple dictionary lookup.
26 class FlexibleFieldLookupDict:
27     # Maps SQL types to Django Field types. Some of the SQL types have multiple
28     # entries here because SQLite allows for anything and doesn't normalize the
29     # field type; it uses whatever was given.
30     base_data_types_reverse = {
31         'bool': 'BooleanField',
32         'boolean': 'BooleanField',
33         'smallint': 'SmallIntegerField',
34         'smallint unsigned': 'PositiveSmallIntegerField',
35         'smallinteger': 'SmallIntegerField',
36         'int': 'IntegerField',
37         'integer': 'IntegerField',
38         'bigint': 'BigIntegerField',
39         'integer unsigned': 'PositiveIntegerField',
40         'bigint unsigned': 'PositiveBigIntegerField',
41         'decimal': 'DecimalField',
42         'real': 'FloatField',
43         'text': 'TextField',
44         'char': 'CharField',
45         'varchar': 'CharField',
46         'blob': 'BinaryField',
47         'date': 'DateField',
48         'datetime': 'DateTimeField',
49         'time': 'TimeField',
50     }
51 
52     def __getitem__(self, key):
53         key = key.lower().split('(', 1)[0].strip()
54         return self.base_data_types_reverse[key]
55 
56 
57 class DatabaseIntrospection(BaseDatabaseIntrospection):
58     data_types_reverse = FlexibleFieldLookupDict()
59 
60     def get_field_type(self, data_type, description):
61         field_type = super().get_field_type(data_type, description)
62         if description.pk and field_type in {'BigIntegerField', 'IntegerField', 'SmallIntegerField'}:
63             # No support for BigAutoField or SmallAutoField as SQLite treats
64             # all integer primary keys as signed 64-bit integers.
65             return 'AutoField'
66         if description.has_json_constraint:
67             return 'JSONField'
68         return field_type
69 
70     def get_table_list(self, cursor):
71         """Return a list of table and view names in the current database."""
72         # Skip the sqlite_sequence system table used for autoincrement key
73         # generation.
74         cursor.execute("""
75             SELECT name, type FROM sqlite_master
76             WHERE type in ('table', 'view') AND NOT name='sqlite_sequence'
77             ORDER BY name""")
78         return [TableInfo(row[0], row[1][0]) for row in cursor.fetchall()]
79 
80     def get_table_description(self, cursor, table_name):
81         """
82         Return a description of the table with the DB-API cursor.description
83         interface.
84         """
85         cursor.execute('PRAGMA table_info(%s)' % self.connection.ops.quote_name(table_name))
86         table_info = cursor.fetchall()
87         collations = self._get_column_collations(cursor, table_name)
88         json_columns = set()
89         if self.connection.features.can_introspect_json_field:
90             for line in table_info:
91                 column = line[1]
92                 json_constraint_sql = '%%json_valid("%s")%%' % column
93                 has_json_constraint = cursor.execute("""
94                     SELECT sql
95                     FROM sqlite_master
96                     WHERE
97                         type = 'table' AND
98                         name = %s AND
99                         sql LIKE %s
100                 """, [table_name, json_constraint_sql]).fetchone()
101                 if has_json_constraint:
102                     json_columns.add(column)
103         return [
104             FieldInfo(
105                 name, data_type, None, get_field_size(data_type), None, None,
106                 not notnull, default, collations.get(name), pk == 1, name in json_columns
107             )
108             for cid, name, data_type, notnull, default, pk in table_info
109         ]
110 
111     def get_sequences(self, cursor, table_name, table_fields=()):
112         pk_col = self.get_primary_key_column(cursor, table_name)
113         return [{'table': table_name, 'column': pk_col}]
114 
115     def get_relations(self, cursor, table_name):
116         """
117         Return a dictionary of {field_name: (field_name_other_table, other_table)}
118         representing all relationships to the given table.
119         """
120         # Dictionary of relations to return
121         relations = {}
122 
123         # Schema for this table
124         cursor.execute(
125             "SELECT sql, type FROM sqlite_master "
126             "WHERE tbl_name = %s AND type IN ('table', 'view')",
127             [table_name]
128         )
129         create_sql, table_type = cursor.fetchone()
130         if table_type == 'view':
131             # It might be a view, then no results will be returned
132             return relations
133         results = create_sql[create_sql.index('(') + 1:create_sql.rindex(')')]
134 
135         # Walk through and look for references to other tables. SQLite doesn't
136         # really have enforced references, but since it echoes out the SQL used
137         # to create the table we can look for REFERENCES statements used there.
138         for field_desc in results.split(','):
139             field_desc = field_desc.strip()
140             if field_desc.startswith("UNIQUE"):
141                 continue
142 
143             m = re.search(r'references (\S*) ?\(["|]?(.*)["|]?\)', field_desc, re.I)
144             if not m:
145                 continue
146             table, column = [s.strip('"') for s in m.groups()]
147 
148             if field_desc.startswith("FOREIGN KEY"):
149                 # Find name of the target FK field
150                 m = re.match(r'FOREIGN KEY\s*\(([^\)]*)\).*', field_desc, re.I)
151                 field_name = m[1].strip('"')
152             else:
153                 field_name = field_desc.split()[0].strip('"')
154 
155             cursor.execute("SELECT sql FROM sqlite_master WHERE tbl_name = %s", [table])
156             result = cursor.fetchall()[0]
157             other_table_results = result[0].strip()
158             li, ri = other_table_results.index('('), other_table_results.rindex(')')
159             other_table_results = other_table_results[li + 1:ri]
160 
161             for other_desc in other_table_results.split(','):
162                 other_desc = other_desc.strip()
163                 if other_desc.startswith('UNIQUE'):
164                     continue
165 
166                 other_name = other_desc.split(' ', 1)[0].strip('"')
167                 if other_name == column:
168                     relations[field_name] = (other_name, table)
169                     break
170 
171         return relations
172 
173     def get_key_columns(self, cursor, table_name):
174         """
175         Return a list of (column_name, referenced_table_name, referenced_column_name)
176         for all key columns in given table.
177         """
178         key_columns = []
179 
180         # Schema for this table
181         cursor.execute("SELECT sql FROM sqlite_master WHERE tbl_name = %s AND type = %s", [table_name, "table"])
182         results = cursor.fetchone()[0].strip()
183         results = results[results.index('(') + 1:results.rindex(')')]
184 
185         # Walk through and look for references to other tables. SQLite doesn't
186         # really have enforced references, but since it echoes out the SQL used
187         # to create the table we can look for REFERENCES statements used there.
188         for field_index, field_desc in enumerate(results.split(',')):
189             field_desc = field_desc.strip()
190             if field_desc.startswith("UNIQUE"):
191                 continue
192 
193             m = re.search(r'"(.*)".*references (.*) \(["|](.*)["|]\)', field_desc, re.I)
194             if not m:
195                 continue
196 
197             # This will append (column_name, referenced_table_name, referenced_column_name) to key_columns
198             key_columns.append(tuple(s.strip('"') for s in m.groups()))
199 
200         return key_columns
201 
202     def get_primary_key_column(self, cursor, table_name):
203         """Return the column name of the primary key for the given table."""
204         cursor.execute(
205             'PRAGMA table_info(%s)' % self.connection.ops.quote_name(table_name)
206         )
207         for _, name, *_, pk in cursor.fetchall():
208             if pk:
209                 return name
210         return None
211 
212     def _get_foreign_key_constraints(self, cursor, table_name):
213         constraints = {}
214         cursor.execute('PRAGMA foreign_key_list(%s)' % self.connection.ops.quote_name(table_name))
215         for row in cursor.fetchall():
216             # Remaining on_update/on_delete/match values are of no interest.
217             id_, _, table, from_, to = row[:5]
218             constraints['fk_%d' % id_] = {
219                 'columns': [from_],
220                 'primary_key': False,
221                 'unique': False,
222                 'foreign_key': (table, to),
223                 'check': False,
224                 'index': False,
225             }
226         return constraints
227 
228     def _parse_column_or_constraint_definition(self, tokens, columns):
229         token = None
230         is_constraint_definition = None
231         field_name = None
232         constraint_name = None
233         unique = False
234         unique_columns = []
235         check = False
236         check_columns = []
237         braces_deep = 0
238         for token in tokens:
239             if token.match(sqlparse.tokens.Punctuation, '('):
240                 braces_deep += 1
241             elif token.match(sqlparse.tokens.Punctuation, ')'):
242                 braces_deep -= 1
243                 if braces_deep < 0:
244                     # End of columns and constraints for table definition.
245                     break
246             elif braces_deep == 0 and token.match(sqlparse.tokens.Punctuation, ','):
247                 # End of current column or constraint definition.
248                 break
249             # Detect column or constraint definition by first token.
250             if is_constraint_definition is None:
251                 is_constraint_definition = token.match(sqlparse.tokens.Keyword, 'CONSTRAINT')
252                 if is_constraint_definition:
253                     continue
254             if is_constraint_definition:
255                 # Detect constraint name by second token.
256                 if constraint_name is None:
257                     if token.ttype in (sqlparse.tokens.Name, sqlparse.tokens.Keyword):
258                         constraint_name = token.value
259                     elif token.ttype == sqlparse.tokens.Literal.String.Symbol:
260                         constraint_name = token.value[1:-1]
261                 # Start constraint columns parsing after UNIQUE keyword.
262                 if token.match(sqlparse.tokens.Keyword, 'UNIQUE'):
263                     unique = True
264                     unique_braces_deep = braces_deep
265                 elif unique:
266                     if unique_braces_deep == braces_deep:
267                         if unique_columns:
268                             # Stop constraint parsing.
269                             unique = False
270                         continue
271                     if token.ttype in (sqlparse.tokens.Name, sqlparse.tokens.Keyword):
272                         unique_columns.append(token.value)
273                     elif token.ttype == sqlparse.tokens.Literal.String.Symbol:
274                         unique_columns.append(token.value[1:-1])
275             else:
276                 # Detect field name by first token.
277                 if field_name is None:
278                     if token.ttype in (sqlparse.tokens.Name, sqlparse.tokens.Keyword):
279                         field_name = token.value
280                     elif token.ttype == sqlparse.tokens.Literal.String.Symbol:
281                         field_name = token.value[1:-1]
282                 if token.match(sqlparse.tokens.Keyword, 'UNIQUE'):
283                     unique_columns = [field_name]
284             # Start constraint columns parsing after CHECK keyword.
285             if token.match(sqlparse.tokens.Keyword, 'CHECK'):
286                 check = True
287                 check_braces_deep = braces_deep
288             elif check:
289                 if check_braces_deep == braces_deep:
290                     if check_columns:
291                         # Stop constraint parsing.
292                         check = False
293                     continue
294                 if token.ttype in (sqlparse.tokens.Name, sqlparse.tokens.Keyword):
295                     if token.value in columns:
296                         check_columns.append(token.value)
297                 elif token.ttype == sqlparse.tokens.Literal.String.Symbol:
298                     if token.value[1:-1] in columns:
299                         check_columns.append(token.value[1:-1])
300         unique_constraint = {
301             'unique': True,
302             'columns': unique_columns,
303             'primary_key': False,
304             'foreign_key': None,
305             'check': False,
306             'index': False,
307         } if unique_columns else None
308         check_constraint = {
309             'check': True,
310             'columns': check_columns,
311             'primary_key': False,
312             'unique': False,
313             'foreign_key': None,
314             'index': False,
315         } if check_columns else None
316         return constraint_name, unique_constraint, check_constraint, token
317 
318     def _parse_table_constraints(self, sql, columns):
319         # Check constraint parsing is based of SQLite syntax diagram.
320         # https://www.sqlite.org/syntaxdiagrams.html#table-constraint
321         statement = sqlparse.parse(sql)[0]
322         constraints = {}
323         unnamed_constrains_index = 0
324         tokens = (token for token in statement.flatten() if not token.is_whitespace)
325         # Go to columns and constraint definition
326         for token in tokens:
327             if token.match(sqlparse.tokens.Punctuation, '('):
328                 break
329         # Parse columns and constraint definition
330         while True:
331             constraint_name, unique, check, end_token = self._parse_column_or_constraint_definition(tokens, columns)
332             if unique:
333                 if constraint_name:
334                     constraints[constraint_name] = unique
335                 else:
336                     unnamed_constrains_index += 1
337                     constraints['__unnamed_constraint_%s__' % unnamed_constrains_index] = unique
338             if check:
339                 if constraint_name:
340                     constraints[constraint_name] = check
341                 else:
342                     unnamed_constrains_index += 1
343                     constraints['__unnamed_constraint_%s__' % unnamed_constrains_index] = check
344             if end_token.match(sqlparse.tokens.Punctuation, ')'):
345                 break
346         return constraints
347 
348     def get_constraints(self, cursor, table_name):
349         """
350         Retrieve any constraints or keys (unique, pk, fk, check, index) across
351         one or more columns.
352         """
353         constraints = {}
354         # Find inline check constraints.
355         try:
356             table_schema = cursor.execute(
357                 "SELECT sql FROM sqlite_master WHERE type='table' and name=%s" % (
358                     self.connection.ops.quote_name(table_name),
359                 )
360             ).fetchone()[0]
361         except TypeError:
362             # table_name is a view.
363             pass
364         else:
365             columns = {info.name for info in self.get_table_description(cursor, table_name)}
366             constraints.update(self._parse_table_constraints(table_schema, columns))
367 
368         # Get the index info
369         cursor.execute("PRAGMA index_list(%s)" % self.connection.ops.quote_name(table_name))
370         for row in cursor.fetchall():
371             # SQLite 3.8.9+ has 5 columns, however older versions only give 3
372             # columns. Discard last 2 columns if there.
373             number, index, unique = row[:3]
374             cursor.execute(
375                 "SELECT sql FROM sqlite_master "
376                 "WHERE type='index' AND name=%s" % self.connection.ops.quote_name(index)
377             )
378             # There's at most one row.
379             sql, = cursor.fetchone() or (None,)
380             # Inline constraints are already detected in
381             # _parse_table_constraints(). The reasons to avoid fetching inline
382             # constraints from `PRAGMA index_list` are:
383             # - Inline constraints can have a different name and information
384             #   than what `PRAGMA index_list` gives.
385             # - Not all inline constraints may appear in `PRAGMA index_list`.
386             if not sql:
387                 # An inline constraint
388                 continue
389             # Get the index info for that index
390             cursor.execute('PRAGMA index_info(%s)' % self.connection.ops.quote_name(index))
391             for index_rank, column_rank, column in cursor.fetchall():
392                 if index not in constraints:
393                     constraints[index] = {
394                         "columns": [],
395                         "primary_key": False,
396                         "unique": bool(unique),
397                         "foreign_key": None,
398                         "check": False,
399                         "index": True,
400                     }
401                 constraints[index]['columns'].append(column)
402             # Add type and column orders for indexes
403             if constraints[index]['index']:
404                 # SQLite doesn't support any index type other than b-tree
405                 constraints[index]['type'] = Index.suffix
406                 orders = self._get_index_columns_orders(sql)
407                 if orders is not None:
408                     constraints[index]['orders'] = orders
409         # Get the PK
410         pk_column = self.get_primary_key_column(cursor, table_name)
411         if pk_column:
412             # SQLite doesn't actually give a name to the PK constraint,
413             # so we invent one. This is fine, as the SQLite backend never
414             # deletes PK constraints by name, as you can't delete constraints
415             # in SQLite; we remake the table with a new PK instead.
416             constraints["__primary__"] = {
417                 "columns": [pk_column],
418                 "primary_key": True,
419                 "unique": False,  # It's not actually a unique constraint.
420                 "foreign_key": None,
421                 "check": False,
422                 "index": False,
423             }
424         constraints.update(self._get_foreign_key_constraints(cursor, table_name))
425         return constraints
426 
427     def _get_index_columns_orders(self, sql):
428         tokens = sqlparse.parse(sql)[0]
429         for token in tokens:
430             if isinstance(token, sqlparse.sql.Parenthesis):
431                 columns = str(token).strip('()').split(', ')
432                 return ['DESC' if info.endswith('DESC') else 'ASC' for info in columns]
433         return None
434 
435     def _get_column_collations(self, cursor, table_name):
436         row = cursor.execute("""
437             SELECT sql
438             FROM sqlite_master
439             WHERE type = 'table' AND name = %s
440         """, [table_name]).fetchone()
441         if not row:
442             return {}
443 
444         sql = row[0]
445         columns = str(sqlparse.parse(sql)[0][-1]).strip('()').split(', ')
446         collations = {}
447         for column in columns:
448             tokens = column[1:].split()
449             column_name = tokens[0].strip('"')
450             for index, token in enumerate(tokens):
451                 if token == 'COLLATE':
452                     collation = tokens[index + 1]
453                     break
454             else:
455                 collation = None
456             collations[column_name] = collation
457         return collations

</code><intended_behavior>Correctly identify when a foreign key references a unique field instead of a primary key in another table, and generate a model field that accurately represents this relationship.</intended_behavior>, <file>django/db/backends/mysql/schema.py</file>
<class>None</class>
<method>None</method>
<code>
1 from django.db.backends.base.schema import BaseDatabaseSchemaEditor
2 from django.db.models import NOT_PROVIDED
3 
4 
5 class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):
6 
7     sql_rename_table = "RENAME TABLE %(old_table)s TO %(new_table)s"
8 
9     sql_alter_column_null = "MODIFY %(column)s %(type)s NULL"
10     sql_alter_column_not_null = "MODIFY %(column)s %(type)s NOT NULL"
11     sql_alter_column_type = "MODIFY %(column)s %(type)s"
12     sql_alter_column_collate = "MODIFY %(column)s %(type)s%(collation)s"
13     sql_alter_column_no_default_null = 'ALTER COLUMN %(column)s SET DEFAULT NULL'
14 
15     # No 'CASCADE' which works as a no-op in MySQL but is undocumented
16     sql_delete_column = "ALTER TABLE %(table)s DROP COLUMN %(column)s"
17 
18     sql_delete_unique = "ALTER TABLE %(table)s DROP INDEX %(name)s"
19     sql_create_column_inline_fk = (
20         ', ADD CONSTRAINT %(name)s FOREIGN KEY (%(column)s) '
21         'REFERENCES %(to_table)s(%(to_column)s)'
22     )
23     sql_delete_fk = "ALTER TABLE %(table)s DROP FOREIGN KEY %(name)s"
24 
25     sql_delete_index = "DROP INDEX %(name)s ON %(table)s"
26 
27     sql_create_pk = "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s PRIMARY KEY (%(columns)s)"
28     sql_delete_pk = "ALTER TABLE %(table)s DROP PRIMARY KEY"
29 
30     sql_create_index = 'CREATE INDEX %(name)s ON %(table)s (%(columns)s)%(extra)s'
31 
32     @property
33     def sql_delete_check(self):
34         if self.connection.mysql_is_mariadb:
35             # The name of the column check constraint is the same as the field
36             # name on MariaDB. Adding IF EXISTS clause prevents migrations
37             # crash. Constraint is removed during a "MODIFY" column statement.
38             return 'ALTER TABLE %(table)s DROP CONSTRAINT IF EXISTS %(name)s'
39         return 'ALTER TABLE %(table)s DROP CHECK %(name)s'
40 
41     @property
42     def sql_rename_column(self):
43         # MariaDB >= 10.5.2 and MySQL >= 8.0.4 support an
44         # "ALTER TABLE ... RENAME COLUMN" statement.
45         if self.connection.mysql_is_mariadb:
46             if self.connection.mysql_version >= (10, 5, 2):
47                 return super().sql_rename_column
48         elif self.connection.mysql_version >= (8, 0, 4):
49             return super().sql_rename_column
50         return 'ALTER TABLE %(table)s CHANGE %(old_column)s %(new_column)s %(type)s'
51 
52     def quote_value(self, value):
53         self.connection.ensure_connection()
54         if isinstance(value, str):
55             value = value.replace('%', '%%')
56         # MySQLdb escapes to string, PyMySQL to bytes.
57         quoted = self.connection.connection.escape(value, self.connection.connection.encoders)
58         if isinstance(value, str) and isinstance(quoted, bytes):
59             quoted = quoted.decode()
60         return quoted
61 
62     def _is_limited_data_type(self, field):
63         db_type = field.db_type(self.connection)
64         return db_type is not None and db_type.lower() in self.connection._limited_data_types
65 
66     def skip_default(self, field):
67         if not self._supports_limited_data_type_defaults:
68             return self._is_limited_data_type(field)
69         return False
70 
71     def skip_default_on_alter(self, field):
72         if self._is_limited_data_type(field) and not self.connection.mysql_is_mariadb:
73             # MySQL doesn't support defaults for BLOB and TEXT in the
74             # ALTER COLUMN statement.
75             return True
76         return False
77 
78     @property
79     def _supports_limited_data_type_defaults(self):
80         # MariaDB and MySQL >= 8.0.13 support defaults for BLOB and TEXT.
81         if self.connection.mysql_is_mariadb:
82             return True
83         return self.connection.mysql_version >= (8, 0, 13)
84 
85     def _column_default_sql(self, field):
86         if (
87             not self.connection.mysql_is_mariadb and
88             self._supports_limited_data_type_defaults and
89             self._is_limited_data_type(field)
90         ):
91             # MySQL supports defaults for BLOB and TEXT columns only if the
92             # default value is written as an expression i.e. in parentheses.
93             return '(%s)'
94         return super()._column_default_sql(field)
95 
96     def add_field(self, model, field):
97         super().add_field(model, field)
98 
99         # Simulate the effect of a one-off default.
100         # field.default may be unhashable, so a set isn't used for "in" check.
101         if self.skip_default(field) and field.default not in (None, NOT_PROVIDED):
102             effective_default = self.effective_default(field)
103             self.execute('UPDATE %(table)s SET %(column)s = %%s' % {
104                 'table': self.quote_name(model._meta.db_table),
105                 'column': self.quote_name(field.column),
106             }, [effective_default])
107 
108     def _field_should_be_indexed(self, model, field):
109         if not super()._field_should_be_indexed(model, field):
110             return False
111 
112         storage = self.connection.introspection.get_storage_engine(
113             self.connection.cursor(), model._meta.db_table
114         )
115         # No need to create an index for ForeignKey fields except if
116         # db_constraint=False because the index from that constraint won't be
117         # created.
118         if (storage == "InnoDB" and
119                 field.get_internal_type() == 'ForeignKey' and
120                 field.db_constraint):
121             return False
122         return not self._is_limited_data_type(field)
123 
124     def _delete_composed_index(self, model, fields, *args):
125         """
126         MySQL can remove an implicit FK index on a field when that field is
127         covered by another index like a unique_together. "covered" here means
128         that the more complex index starts like the simpler one.
129         http://bugs.mysql.com/bug.php?id=37910 / Django ticket #24757
130         We check here before removing the [unique|index]_together if we have to
131         recreate a FK index.
132         """
133         first_field = model._meta.get_field(fields[0])
134         if first_field.get_internal_type() == 'ForeignKey':
135             constraint_names = self._constraint_names(model, [first_field.column], index=True)
136             if not constraint_names:
137                 self.execute(
138                     self._create_index_sql(model, fields=[first_field], suffix='')
139                 )
140         return super()._delete_composed_index(model, fields, *args)
141 
142     def _set_field_new_type_null_status(self, field, new_type):
143         """
144         Keep the null property of the old field. If it has changed, it will be
145         handled separately.
146         """
147         if field.null:
148             new_type += " NULL"
149         else:
150             new_type += " NOT NULL"
151         return new_type
152 
153     def _alter_column_type_sql(self, model, old_field, new_field, new_type):
154         new_type = self._set_field_new_type_null_status(old_field, new_type)
155         return super()._alter_column_type_sql(model, old_field, new_field, new_type)
156 
157     def _rename_field_sql(self, table, old_field, new_field, new_type):
158         new_type = self._set_field_new_type_null_status(old_field, new_type)
159         return super()._rename_field_sql(table, old_field, new_field, new_type)

</code><intended_behavior>Correctly identify when a foreign key references a unique field instead of a primary key in another table, and generate a model field that accurately represents this relationship.</intended_behavior>, <file>django/db/backends/base/schema.py</file>
<class>None</class>
<method>None</method>
<code>
1 import logging
2 from datetime import datetime
3 
4 from django.db.backends.ddl_references import (
5     Columns, Expressions, ForeignKeyName, IndexName, Statement, Table,
6 )
7 from django.db.backends.utils import names_digest, split_identifier
8 from django.db.models import Deferrable, Index
9 from django.db.models.sql import Query
10 from django.db.transaction import TransactionManagementError, atomic
11 from django.utils import timezone
12 
13 logger = logging.getLogger('django.db.backends.schema')
14 
15 
16 def _is_relevant_relation(relation, altered_field):
17     """
18     When altering the given field, must constraints on its model from the given
19     relation be temporarily dropped?
20     """
21     field = relation.field
22     if field.many_to_many:
23         # M2M reverse field
24         return False
25     if altered_field.primary_key and field.to_fields == [None]:
26         # Foreign key constraint on the primary key, which is being altered.
27         return True
28     # Is the constraint targeting the field being altered?
29     return altered_field.name in field.to_fields
30 
31 
32 def _all_related_fields(model):
33     return model._meta._get_fields(forward=False, reverse=True, include_hidden=True)
34 
35 
36 def _related_non_m2m_objects(old_field, new_field):
37     # Filter out m2m objects from reverse relations.
38     # Return (old_relation, new_relation) tuples.
39     related_fields = zip(
40         (obj for obj in _all_related_fields(old_field.model) if _is_relevant_relation(obj, old_field)),
41         (obj for obj in _all_related_fields(new_field.model) if _is_relevant_relation(obj, new_field)),
42     )
43     for old_rel, new_rel in related_fields:
44         yield old_rel, new_rel
45         yield from _related_non_m2m_objects(
46             old_rel.remote_field,
47             new_rel.remote_field,
48         )
49 
50 
51 class BaseDatabaseSchemaEditor:
52     """
53     This class and its subclasses are responsible for emitting schema-changing
54     statements to the databases - model creation/removal/alteration, field
55     renaming, index fiddling, and so on.
56     """
57 
58     # Overrideable SQL templates
59     sql_create_table = "CREATE TABLE %(table)s (%(definition)s)"
60     sql_rename_table = "ALTER TABLE %(old_table)s RENAME TO %(new_table)s"
61     sql_retablespace_table = "ALTER TABLE %(table)s SET TABLESPACE %(new_tablespace)s"
62     sql_delete_table = "DROP TABLE %(table)s CASCADE"
63 
64     sql_create_column = "ALTER TABLE %(table)s ADD COLUMN %(column)s %(definition)s"
65     sql_alter_column = "ALTER TABLE %(table)s %(changes)s"
66     sql_alter_column_type = "ALTER COLUMN %(column)s TYPE %(type)s"
67     sql_alter_column_null = "ALTER COLUMN %(column)s DROP NOT NULL"
68     sql_alter_column_not_null = "ALTER COLUMN %(column)s SET NOT NULL"
69     sql_alter_column_default = "ALTER COLUMN %(column)s SET DEFAULT %(default)s"
70     sql_alter_column_no_default = "ALTER COLUMN %(column)s DROP DEFAULT"
71     sql_alter_column_no_default_null = sql_alter_column_no_default
72     sql_alter_column_collate = "ALTER COLUMN %(column)s TYPE %(type)s%(collation)s"
73     sql_delete_column = "ALTER TABLE %(table)s DROP COLUMN %(column)s CASCADE"
74     sql_rename_column = "ALTER TABLE %(table)s RENAME COLUMN %(old_column)s TO %(new_column)s"
75     sql_update_with_default = "UPDATE %(table)s SET %(column)s = %(default)s WHERE %(column)s IS NULL"
76 
77     sql_unique_constraint = "UNIQUE (%(columns)s)%(deferrable)s"
78     sql_check_constraint = "CHECK (%(check)s)"
79     sql_delete_constraint = "ALTER TABLE %(table)s DROP CONSTRAINT %(name)s"
80     sql_constraint = "CONSTRAINT %(name)s %(constraint)s"
81 
82     sql_create_check = "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s CHECK (%(check)s)"
83     sql_delete_check = sql_delete_constraint
84 
85     sql_create_unique = "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s UNIQUE (%(columns)s)%(deferrable)s"
86     sql_delete_unique = sql_delete_constraint
87 
88     sql_create_fk = (
89         "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s FOREIGN KEY (%(column)s) "
90         "REFERENCES %(to_table)s (%(to_column)s)%(deferrable)s"
91     )
92     sql_create_inline_fk = None
93     sql_create_column_inline_fk = None
94     sql_delete_fk = sql_delete_constraint
95 
96     sql_create_index = "CREATE INDEX %(name)s ON %(table)s (%(columns)s)%(include)s%(extra)s%(condition)s"
97     sql_create_unique_index = "CREATE UNIQUE INDEX %(name)s ON %(table)s (%(columns)s)%(include)s%(condition)s"
98     sql_delete_index = "DROP INDEX %(name)s"
99 
100     sql_create_pk = "ALTER TABLE %(table)s ADD CONSTRAINT %(name)s PRIMARY KEY (%(columns)s)"
101     sql_delete_pk = sql_delete_constraint
102 
103     sql_delete_procedure = 'DROP PROCEDURE %(procedure)s'
104 
105     def __init__(self, connection, collect_sql=False, atomic=True):
106         self.connection = connection
107         self.collect_sql = collect_sql
108         if self.collect_sql:
109             self.collected_sql = []
110         self.atomic_migration = self.connection.features.can_rollback_ddl and atomic
111 
112     # State-managing methods
113 
114     def __enter__(self):
115         self.deferred_sql = []
116         if self.atomic_migration:
117             self.atomic = atomic(self.connection.alias)
118             self.atomic.__enter__()
119         return self
120 
121     def __exit__(self, exc_type, exc_value, traceback):
122         if exc_type is None:
123             for sql in self.deferred_sql:
124                 self.execute(sql)
125         if self.atomic_migration:
126             self.atomic.__exit__(exc_type, exc_value, traceback)
127 
128     # Core utility functions
129 
130     def execute(self, sql, params=()):
131         """Execute the given SQL statement, with optional parameters."""
132         # Don't perform the transactional DDL check if SQL is being collected
133         # as it's not going to be executed anyway.
134         if not self.collect_sql and self.connection.in_atomic_block and not self.connection.features.can_rollback_ddl:
135             raise TransactionManagementError(
136                 "Executing DDL statements while in a transaction on databases "
137                 "that can't perform a rollback is prohibited."
138             )
139         # Account for non-string statement objects.
140         sql = str(sql)
141         # Log the command we're running, then run it
142         logger.debug("%s; (params %r)", sql, params, extra={'params': params, 'sql': sql})
143         if self.collect_sql:
144             ending = "" if sql.rstrip().endswith(";") else ";"
145             if params is not None:
146                 self.collected_sql.append((sql % tuple(map(self.quote_value, params))) + ending)
147             else:
148                 self.collected_sql.append(sql + ending)
149         else:
150             with self.connection.cursor() as cursor:
151                 cursor.execute(sql, params)
152 
153     def quote_name(self, name):
154         return self.connection.ops.quote_name(name)
155 
156     def table_sql(self, model):
157         """Take a model and return its table definition."""
158         # Add any unique_togethers (always deferred, as some fields might be
159         # created afterward, like geometry fields with some backends).
160         for field_names in model._meta.unique_together:
161             fields = [model._meta.get_field(field) for field in field_names]
162             self.deferred_sql.append(self._create_unique_sql(model, fields))
163         # Create column SQL, add FK deferreds if needed.
164         column_sqls = []
165         params = []
166         for field in model._meta.local_fields:
167             # SQL.
168             definition, extra_params = self.column_sql(model, field)
169             if definition is None:
170                 continue
171             # Check constraints can go on the column SQL here.
172             db_params = field.db_parameters(connection=self.connection)
173             if db_params['check']:
174                 definition += ' ' + self.sql_check_constraint % db_params
175             # Autoincrement SQL (for backends with inline variant).
176             col_type_suffix = field.db_type_suffix(connection=self.connection)
177             if col_type_suffix:
178                 definition += ' %s' % col_type_suffix
179             params.extend(extra_params)
180             # FK.
181             if field.remote_field and field.db_constraint:
182                 to_table = field.remote_field.model._meta.db_table
183                 to_column = field.remote_field.model._meta.get_field(field.remote_field.field_name).column
184                 if self.sql_create_inline_fk:
185                     definition += ' ' + self.sql_create_inline_fk % {
186                         'to_table': self.quote_name(to_table),
187                         'to_column': self.quote_name(to_column),
188                     }
189                 elif self.connection.features.supports_foreign_keys:
190                     self.deferred_sql.append(self._create_fk_sql(model, field, '_fk_%(to_table)s_%(to_column)s'))
191             # Add the SQL to our big list.
192             column_sqls.append('%s %s' % (
193                 self.quote_name(field.column),
194                 definition,
195             ))
196             # Autoincrement SQL (for backends with post table definition
197             # variant).
198             if field.get_internal_type() in ('AutoField', 'BigAutoField', 'SmallAutoField'):
199                 autoinc_sql = self.connection.ops.autoinc_sql(model._meta.db_table, field.column)
200                 if autoinc_sql:
201                     self.deferred_sql.extend(autoinc_sql)
202         constraints = [constraint.constraint_sql(model, self) for constraint in model._meta.constraints]
203         sql = self.sql_create_table % {
204             'table': self.quote_name(model._meta.db_table),
205             'definition': ', '.join(constraint for constraint in (*column_sqls, *constraints) if constraint),
206         }
207         if model._meta.db_tablespace:
208             tablespace_sql = self.connection.ops.tablespace_sql(model._meta.db_tablespace)
209             if tablespace_sql:
210                 sql += ' ' + tablespace_sql
211         return sql, params
212 
213     # Field <-> database mapping functions
214 
215     def _iter_column_sql(self, column_db_type, params, model, field, include_default):
216         yield column_db_type
217         collation = getattr(field, 'db_collation', None)
218         if collation:
219             yield self._collate_sql(collation)
220         # Work out nullability.
221         null = field.null
222         # Include a default value, if requested.
223         include_default = (
224             include_default and
225             not self.skip_default(field) and
226             # Don't include a default value if it's a nullable field and the
227             # default cannot be dropped in the ALTER COLUMN statement (e.g.
228             # MySQL longtext and longblob).
229             not (null and self.skip_default_on_alter(field))
230         )
231         if include_default:
232             default_value = self.effective_default(field)
233             if default_value is not None:
234                 column_default = 'DEFAULT ' + self._column_default_sql(field)
235                 if self.connection.features.requires_literal_defaults:
236                     # Some databases can't take defaults as a parameter (Oracle).
237                     # If this is the case, the individual schema backend should
238                     # implement prepare_default().
239                     yield column_default % self.prepare_default(default_value)
240                 else:
241                     yield column_default
242                     params.append(default_value)
243         # Oracle treats the empty string ('') as null, so coerce the null
244         # option whenever '' is a possible value.
245         if (field.empty_strings_allowed and not field.primary_key and
246                 self.connection.features.interprets_empty_strings_as_nulls):
247             null = True
248         if not null:
249             yield 'NOT NULL'
250         elif not self.connection.features.implied_column_null:
251             yield 'NULL'
252         if field.primary_key:
253             yield 'PRIMARY KEY'
254         elif field.unique:
255             yield 'UNIQUE'
256         # Optionally add the tablespace if it's an implicitly indexed column.
257         tablespace = field.db_tablespace or model._meta.db_tablespace
258         if tablespace and self.connection.features.supports_tablespaces and field.unique:
259             yield self.connection.ops.tablespace_sql(tablespace, inline=True)
260 
261     def column_sql(self, model, field, include_default=False):
262         """
263         Return the column definition for a field. The field must already have
264         had set_attributes_from_name() called.
265         """
266         # Get the column's type and use that as the basis of the SQL.
267         db_params = field.db_parameters(connection=self.connection)
268         column_db_type = db_params['type']
269         # Check for fields that aren't actually columns (e.g. M2M).
270         if column_db_type is None:
271             return None, None
272         params = []
273         return ' '.join(
274             # This appends to the params being returned.
275             self._iter_column_sql(column_db_type, params, model, field, include_default)
276         ), params
277 
278     def skip_default(self, field):
279         """
280         Some backends don't accept default values for certain columns types
281         (i.e. MySQL longtext and longblob).
282         """
283         return False
284 
285     def skip_default_on_alter(self, field):
286         """
287         Some backends don't accept default values for certain columns types
288         (i.e. MySQL longtext and longblob) in the ALTER COLUMN statement.
289         """
290         return False
291 
292     def prepare_default(self, value):
293         """
294         Only used for backends which have requires_literal_defaults feature
295         """
296         raise NotImplementedError(
297             'subclasses of BaseDatabaseSchemaEditor for backends which have '
298             'requires_literal_defaults must provide a prepare_default() method'
299         )
300 
301     def _column_default_sql(self, field):
302         """
303         Return the SQL to use in a DEFAULT clause. The resulting string should
304         contain a '%s' placeholder for a default value.
305         """
306         return '%s'
307 
308     @staticmethod
309     def _effective_default(field):
310         # This method allows testing its logic without a connection.
311         if field.has_default():
312             default = field.get_default()
313         elif not field.null and field.blank and field.empty_strings_allowed:
314             if field.get_internal_type() == "BinaryField":
315                 default = b''
316             else:
317                 default = ''
318         elif getattr(field, 'auto_now', False) or getattr(field, 'auto_now_add', False):
319             internal_type = field.get_internal_type()
320             if internal_type == 'DateTimeField':
321                 default = timezone.now()
322             else:
323                 default = datetime.now()
324                 if internal_type == 'DateField':
325                     default = default.date()
326                 elif internal_type == 'TimeField':
327                     default = default.time()
328         else:
329             default = None
330         return default
331 
332     def effective_default(self, field):
333         """Return a field's effective database default value."""
334         return field.get_db_prep_save(self._effective_default(field), self.connection)
335 
336     def quote_value(self, value):
337         """
338         Return a quoted version of the value so it's safe to use in an SQL
339         string. This is not safe against injection from user code; it is
340         intended only for use in making SQL scripts or preparing default values
341         for particularly tricky backends (defaults are not user-defined, though,
342         so this is safe).
343         """
344         raise NotImplementedError()
345 
346     # Actions
347 
348     def create_model(self, model):
349         """
350         Create a table and any accompanying indexes or unique constraints for
351         the given `model`.
352         """
353         sql, params = self.table_sql(model)
354         # Prevent using [] as params, in the case a literal '%' is used in the definition
355         self.execute(sql, params or None)
356 
357         # Add any field index and index_together's (deferred as SQLite _remake_table needs it)
358         self.deferred_sql.extend(self._model_indexes_sql(model))
359 
360         # Make M2M tables
361         for field in model._meta.local_many_to_many:
362             if field.remote_field.through._meta.auto_created:
363                 self.create_model(field.remote_field.through)
364 
365     def delete_model(self, model):
366         """Delete a model from the database."""
367         # Handle auto-created intermediary models
368         for field in model._meta.local_many_to_many:
369             if field.remote_field.through._meta.auto_created:
370                 self.delete_model(field.remote_field.through)
371 
372         # Delete the table
373         self.execute(self.sql_delete_table % {
374             "table": self.quote_name(model._meta.db_table),
375         })
376         # Remove all deferred statements referencing the deleted table.
377         for sql in list(self.deferred_sql):
378             if isinstance(sql, Statement) and sql.references_table(model._meta.db_table):
379                 self.deferred_sql.remove(sql)
380 
381     def add_index(self, model, index):
382         """Add an index on a model."""
383         if (
384             index.contains_expressions and
385             not self.connection.features.supports_expression_indexes
386         ):
387             return None
388         # Index.create_sql returns interpolated SQL which makes params=None a
389         # necessity to avoid escaping attempts on execution.
390         self.execute(index.create_sql(model, self), params=None)
391 
392     def remove_index(self, model, index):
393         """Remove an index from a model."""
394         if (
395             index.contains_expressions and
396             not self.connection.features.supports_expression_indexes
397         ):
398             return None
399         self.execute(index.remove_sql(model, self))
400 
401     def add_constraint(self, model, constraint):
402         """Add a constraint to a model."""
403         sql = constraint.create_sql(model, self)
404         if sql:
405             # Constraint.create_sql returns interpolated SQL which makes
406             # params=None a necessity to avoid escaping attempts on execution.
407             self.execute(sql, params=None)
408 
409     def remove_constraint(self, model, constraint):
410         """Remove a constraint from a model."""
411         sql = constraint.remove_sql(model, self)
412         if sql:
413             self.execute(sql)
414 
415     def alter_unique_together(self, model, old_unique_together, new_unique_together):
416         """
417         Deal with a model changing its unique_together. The input
418         unique_togethers must be doubly-nested, not the single-nested
419         ["foo", "bar"] format.
420         """
421         olds = {tuple(fields) for fields in old_unique_together}
422         news = {tuple(fields) for fields in new_unique_together}
423         # Deleted uniques
424         for fields in olds.difference(news):
425             self._delete_composed_index(model, fields, {'unique': True}, self.sql_delete_unique)
426         # Created uniques
427         for field_names in news.difference(olds):
428             fields = [model._meta.get_field(field) for field in field_names]
429             self.execute(self._create_unique_sql(model, fields))
430 
431     def alter_index_together(self, model, old_index_together, new_index_together):
432         """
433         Deal with a model changing its index_together. The input
434         index_togethers must be doubly-nested, not the single-nested
435         ["foo", "bar"] format.
436         """
437         olds = {tuple(fields) for fields in old_index_together}
438         news = {tuple(fields) for fields in new_index_together}
439         # Deleted indexes
440         for fields in olds.difference(news):
441             self._delete_composed_index(
442                 model,
443                 fields,
444                 {'index': True, 'unique': False},
445                 self.sql_delete_index,
446             )
447         # Created indexes
448         for field_names in news.difference(olds):
449             fields = [model._meta.get_field(field) for field in field_names]
450             self.execute(self._create_index_sql(model, fields=fields, suffix='_idx'))
451 
452     def _delete_composed_index(self, model, fields, constraint_kwargs, sql):
453         meta_constraint_names = {constraint.name for constraint in model._meta.constraints}
454         meta_index_names = {constraint.name for constraint in model._meta.indexes}
455         columns = [model._meta.get_field(field).column for field in fields]
456         constraint_names = self._constraint_names(
457             model, columns, exclude=meta_constraint_names | meta_index_names,
458             **constraint_kwargs
459         )
460         if len(constraint_names) != 1:
461             raise ValueError("Found wrong number (%s) of constraints for %s(%s)" % (
462                 len(constraint_names),
463                 model._meta.db_table,
464                 ", ".join(columns),
465             ))
466         self.execute(self._delete_constraint_sql(sql, model, constraint_names[0]))
467 
468     def alter_db_table(self, model, old_db_table, new_db_table):
469         """Rename the table a model points to."""
470         if (old_db_table == new_db_table or
471             (self.connection.features.ignores_table_name_case and
472                 old_db_table.lower() == new_db_table.lower())):
473             return
474         self.execute(self.sql_rename_table % {
475             "old_table": self.quote_name(old_db_table),
476             "new_table": self.quote_name(new_db_table),
477         })
478         # Rename all references to the old table name.
479         for sql in self.deferred_sql:
480             if isinstance(sql, Statement):
481                 sql.rename_table_references(old_db_table, new_db_table)
482 
483     def alter_db_tablespace(self, model, old_db_tablespace, new_db_tablespace):
484         """Move a model's table between tablespaces."""
485         self.execute(self.sql_retablespace_table % {
486             "table": self.quote_name(model._meta.db_table),
487             "old_tablespace": self.quote_name(old_db_tablespace),
488             "new_tablespace": self.quote_name(new_db_tablespace),
489         })
490 
491     def add_field(self, model, field):
492         """
493         Create a field on a model. Usually involves adding a column, but may
494         involve adding a table instead (for M2M fields).
495         """
496         # Special-case implicit M2M tables
497         if field.many_to_many and field.remote_field.through._meta.auto_created:
498             return self.create_model(field.remote_field.through)
499         # Get the column's definition
500         definition, params = self.column_sql(model, field, include_default=True)
501         # It might not actually have a column behind it
502         if definition is None:
503             return
504         # Check constraints can go on the column SQL here
505         db_params = field.db_parameters(connection=self.connection)
506         if db_params['check']:
507             definition += " " + self.sql_check_constraint % db_params
508         if field.remote_field and self.connection.features.supports_foreign_keys and field.db_constraint:
509             constraint_suffix = '_fk_%(to_table)s_%(to_column)s'
510             # Add FK constraint inline, if supported.
511             if self.sql_create_column_inline_fk:
512                 to_table = field.remote_field.model._meta.db_table
513                 to_column = field.remote_field.model._meta.get_field(field.remote_field.field_name).column
514                 namespace, _ = split_identifier(model._meta.db_table)
515                 definition += " " + self.sql_create_column_inline_fk % {
516                     'name': self._fk_constraint_name(model, field, constraint_suffix),
517                     'namespace': '%s.' % self.quote_name(namespace) if namespace else '',
518                     'column': self.quote_name(field.column),
519                     'to_table': self.quote_name(to_table),
520                     'to_column': self.quote_name(to_column),
521                     'deferrable': self.connection.ops.deferrable_sql()
522                 }
523             # Otherwise, add FK constraints later.
524             else:
525                 self.deferred_sql.append(self._create_fk_sql(model, field, constraint_suffix))
526         # Build the SQL and run it
527         sql = self.sql_create_column % {
528             "table": self.quote_name(model._meta.db_table),
529             "column": self.quote_name(field.column),
530             "definition": definition,
531         }
532         self.execute(sql, params)
533         # Drop the default if we need to
534         # (Django usually does not use in-database defaults)
535         if not self.skip_default_on_alter(field) and self.effective_default(field) is not None:
536             changes_sql, params = self._alter_column_default_sql(model, None, field, drop=True)
537             sql = self.sql_alter_column % {
538                 "table": self.quote_name(model._meta.db_table),
539                 "changes": changes_sql,
540             }
541             self.execute(sql, params)
542         # Add an index, if required
543         self.deferred_sql.extend(self._field_indexes_sql(model, field))
544         # Reset connection if required
545         if self.connection.features.connection_persists_old_columns:
546             self.connection.close()
547 
548     def remove_field(self, model, field):
549         """
550         Remove a field from a model. Usually involves deleting a column,
551         but for M2Ms may involve deleting a table.
552         """
553         # Special-case implicit M2M tables
554         if field.many_to_many and field.remote_field.through._meta.auto_created:
555             return self.delete_model(field.remote_field.through)
556         # It might not actually have a column behind it
557         if field.db_parameters(connection=self.connection)['type'] is None:
558             return
559         # Drop any FK constraints, MySQL requires explicit deletion
560         if field.remote_field:
561             fk_names = self._constraint_names(model, [field.column], foreign_key=True)
562             for fk_name in fk_names:
563                 self.execute(self._delete_fk_sql(model, fk_name))
564         # Delete the column
565         sql = self.sql_delete_column % {
566             "table": self.quote_name(model._meta.db_table),
567             "column": self.quote_name(field.column),
568         }
569         self.execute(sql)
570         # Reset connection if required
571         if self.connection.features.connection_persists_old_columns:
572             self.connection.close()
573         # Remove all deferred statements referencing the deleted column.
574         for sql in list(self.deferred_sql):
575             if isinstance(sql, Statement) and sql.references_column(model._meta.db_table, field.column):
576                 self.deferred_sql.remove(sql)
577 
578     def alter_field(self, model, old_field, new_field, strict=False):
579         """
580         Allow a field's type, uniqueness, nullability, default, column,
581         constraints, etc. to be modified.
582         `old_field` is required to compute the necessary changes.
583         If `strict` is True, raise errors if the old column does not match
584         `old_field` precisely.
585         """
586         if not self._field_should_be_altered(old_field, new_field):
587             return
588         # Ensure this field is even column-based
589         old_db_params = old_field.db_parameters(connection=self.connection)
590         old_type = old_db_params['type']
591         new_db_params = new_field.db_parameters(connection=self.connection)
592         new_type = new_db_params['type']
593         if ((old_type is None and old_field.remote_field is None) or
594                 (new_type is None and new_field.remote_field is None)):
595             raise ValueError(
596                 "Cannot alter field %s into %s - they do not properly define "
597                 "db_type (are you using a badly-written custom field?)" %
598                 (old_field, new_field),
599             )
600         elif old_type is None and new_type is None and (
601                 old_field.remote_field.through and new_field.remote_field.through and
602                 old_field.remote_field.through._meta.auto_created and
603                 new_field.remote_field.through._meta.auto_created):
604             return self._alter_many_to_many(model, old_field, new_field, strict)
605         elif old_type is None and new_type is None and (
606                 old_field.remote_field.through and new_field.remote_field.through and
607                 not old_field.remote_field.through._meta.auto_created and
608                 not new_field.remote_field.through._meta.auto_created):
609             # Both sides have through models; this is a no-op.
610             return
611         elif old_type is None or new_type is None:
612             raise ValueError(
613                 "Cannot alter field %s into %s - they are not compatible types "
614                 "(you cannot alter to or from M2M fields, or add or remove "
615                 "through= on M2M fields)" % (old_field, new_field)
616             )
617 
618         self._alter_field(model, old_field, new_field, old_type, new_type,
619                           old_db_params, new_db_params, strict)
620 
621     def _alter_field(self, model, old_field, new_field, old_type, new_type,
622                      old_db_params, new_db_params, strict=False):
623         """Perform a "physical" (non-ManyToMany) field update."""
624         # Drop any FK constraints, we'll remake them later
625         fks_dropped = set()
626         if (
627             self.connection.features.supports_foreign_keys and
628             old_field.remote_field and
629             old_field.db_constraint
630         ):
631             fk_names = self._constraint_names(model, [old_field.column], foreign_key=True)
632             if strict and len(fk_names) != 1:
633                 raise ValueError("Found wrong number (%s) of foreign key constraints for %s.%s" % (
634                     len(fk_names),
635                     model._meta.db_table,
636                     old_field.column,
637                 ))
638             for fk_name in fk_names:
639                 fks_dropped.add((old_field.column,))
640                 self.execute(self._delete_fk_sql(model, fk_name))
641         # Has unique been removed?
642         if old_field.unique and (not new_field.unique or self._field_became_primary_key(old_field, new_field)):
643             # Find the unique constraint for this field
644             meta_constraint_names = {constraint.name for constraint in model._meta.constraints}
645             constraint_names = self._constraint_names(
646                 model, [old_field.column], unique=True, primary_key=False,
647                 exclude=meta_constraint_names,
648             )
649             if strict and len(constraint_names) != 1:
650                 raise ValueError("Found wrong number (%s) of unique constraints for %s.%s" % (
651                     len(constraint_names),
652                     model._meta.db_table,
653                     old_field.column,
654                 ))
655             for constraint_name in constraint_names:
656                 self.execute(self._delete_unique_sql(model, constraint_name))
657         # Drop incoming FK constraints if the field is a primary key or unique,
658         # which might be a to_field target, and things are going to change.
659         drop_foreign_keys = (
660             self.connection.features.supports_foreign_keys and (
661                 (old_field.primary_key and new_field.primary_key) or
662                 (old_field.unique and new_field.unique)
663             ) and old_type != new_type
664         )
665         if drop_foreign_keys:
666             # '_meta.related_field' also contains M2M reverse fields, these
667             # will be filtered out
668             for _old_rel, new_rel in _related_non_m2m_objects(old_field, new_field):
669                 rel_fk_names = self._constraint_names(
670                     new_rel.related_model, [new_rel.field.column], foreign_key=True
671                 )
672                 for fk_name in rel_fk_names:
673                     self.execute(self._delete_fk_sql(new_rel.related_model, fk_name))
674         # Removed an index? (no strict check, as multiple indexes are possible)
675         # Remove indexes if db_index switched to False or a unique constraint
676         # will now be used in lieu of an index. The following lines from the
677         # truth table show all True cases; the rest are False:
678         #
679         # old_field.db_index | old_field.unique | new_field.db_index | new_field.unique
680         # ------------------------------------------------------------------------------
681         # True               | False            | False              | False
682         # True               | False            | False              | True
683         # True               | False            | True               | True
684         if old_field.db_index and not old_field.unique and (not new_field.db_index or new_field.unique):
685             # Find the index for this field
686             meta_index_names = {index.name for index in model._meta.indexes}
687             # Retrieve only BTREE indexes since this is what's created with
688             # db_index=True.
689             index_names = self._constraint_names(
690                 model, [old_field.column], index=True, type_=Index.suffix,
691                 exclude=meta_index_names,
692             )
693             for index_name in index_names:
694                 # The only way to check if an index was created with
695                 # db_index=True or with Index(['field'], name='foo')
696                 # is to look at its name (refs #28053).
697                 self.execute(self._delete_index_sql(model, index_name))
698         # Change check constraints?
699         if old_db_params['check'] != new_db_params['check'] and old_db_params['check']:
700             meta_constraint_names = {constraint.name for constraint in model._meta.constraints}
701             constraint_names = self._constraint_names(
702                 model, [old_field.column], check=True,
703                 exclude=meta_constraint_names,
704             )
705             if strict and len(constraint_names) != 1:
706                 raise ValueError("Found wrong number (%s) of check constraints for %s.%s" % (
707                     len(constraint_names),
708                     model._meta.db_table,
709                     old_field.column,
710                 ))
711             for constraint_name in constraint_names:
712                 self.execute(self._delete_check_sql(model, constraint_name))
713         # Have they renamed the column?
714         if old_field.column != new_field.column:
715             self.execute(self._rename_field_sql(model._meta.db_table, old_field, new_field, new_type))
716             # Rename all references to the renamed column.
717             for sql in self.deferred_sql:
718                 if isinstance(sql, Statement):
719                     sql.rename_column_references(model._meta.db_table, old_field.column, new_field.column)
720         # Next, start accumulating actions to do
721         actions = []
722         null_actions = []
723         post_actions = []
724         # Collation change?
725         old_collation = getattr(old_field, 'db_collation', None)
726         new_collation = getattr(new_field, 'db_collation', None)
727         if old_collation != new_collation:
728             # Collation change handles also a type change.
729             fragment = self._alter_column_collation_sql(model, new_field, new_type, new_collation)
730             actions.append(fragment)
731         # Type change?
732         elif old_type != new_type:
733             fragment, other_actions = self._alter_column_type_sql(model, old_field, new_field, new_type)
734             actions.append(fragment)
735             post_actions.extend(other_actions)
736         # When changing a column NULL constraint to NOT NULL with a given
737         # default value, we need to perform 4 steps:
738         #  1. Add a default for new incoming writes
739         #  2. Update existing NULL rows with new default
740         #  3. Replace NULL constraint with NOT NULL
741         #  4. Drop the default again.
742         # Default change?
743         needs_database_default = False
744         if old_field.null and not new_field.null:
745             old_default = self.effective_default(old_field)
746             new_default = self.effective_default(new_field)
747             if (
748                 not self.skip_default_on_alter(new_field) and
749                 old_default != new_default and
750                 new_default is not None
751             ):
752                 needs_database_default = True
753                 actions.append(self._alter_column_default_sql(model, old_field, new_field))
754         # Nullability change?
755         if old_field.null != new_field.null:
756             fragment = self._alter_column_null_sql(model, old_field, new_field)
757             if fragment:
758                 null_actions.append(fragment)
759         # Only if we have a default and there is a change from NULL to NOT NULL
760         four_way_default_alteration = (
761             new_field.has_default() and
762             (old_field.null and not new_field.null)
763         )
764         if actions or null_actions:
765             if not four_way_default_alteration:
766                 # If we don't have to do a 4-way default alteration we can
767                 # directly run a (NOT) NULL alteration
768                 actions = actions + null_actions
769             # Combine actions together if we can (e.g. postgres)
770             if self.connection.features.supports_combined_alters and actions:
771                 sql, params = tuple(zip(*actions))
772                 actions = [(", ".join(sql), sum(params, []))]
773             # Apply those actions
774             for sql, params in actions:
775                 self.execute(
776                     self.sql_alter_column % {
777                         "table": self.quote_name(model._meta.db_table),
778                         "changes": sql,
779                     },
780                     params,
781                 )
782             if four_way_default_alteration:
783                 # Update existing rows with default value
784                 self.execute(
785                     self.sql_update_with_default % {
786                         "table": self.quote_name(model._meta.db_table),
787                         "column": self.quote_name(new_field.column),
788                         "default": "%s",
789                     },
790                     [new_default],
791                 )
792                 # Since we didn't run a NOT NULL change before we need to do it
793                 # now
794                 for sql, params in null_actions:
795                     self.execute(
796                         self.sql_alter_column % {
797                             "table": self.quote_name(model._meta.db_table),
798                             "changes": sql,
799                         },
800                         params,
801                     )
802         if post_actions:
803             for sql, params in post_actions:
804                 self.execute(sql, params)
805         # If primary_key changed to False, delete the primary key constraint.
806         if old_field.primary_key and not new_field.primary_key:
807             self._delete_primary_key(model, strict)
808         # Added a unique?
809         if self._unique_should_be_added(old_field, new_field):
810             self.execute(self._create_unique_sql(model, [new_field]))
811         # Added an index? Add an index if db_index switched to True or a unique
812         # constraint will no longer be used in lieu of an index. The following
813         # lines from the truth table show all True cases; the rest are False:
814         #
815         # old_field.db_index | old_field.unique | new_field.db_index | new_field.unique
816         # ------------------------------------------------------------------------------
817         # False              | False            | True               | False
818         # False              | True             | True               | False
819         # True               | True             | True               | False
820         if (not old_field.db_index or old_field.unique) and new_field.db_index and not new_field.unique:
821             self.execute(self._create_index_sql(model, fields=[new_field]))
822         # Type alteration on primary key? Then we need to alter the column
823         # referring to us.
824         rels_to_update = []
825         if drop_foreign_keys:
826             rels_to_update.extend(_related_non_m2m_objects(old_field, new_field))
827         # Changed to become primary key?
828         if self._field_became_primary_key(old_field, new_field):
829             # Make the new one
830             self.execute(self._create_primary_key_sql(model, new_field))
831             # Update all referencing columns
832             rels_to_update.extend(_related_non_m2m_objects(old_field, new_field))
833         # Handle our type alters on the other end of rels from the PK stuff above
834         for old_rel, new_rel in rels_to_update:
835             rel_db_params = new_rel.field.db_parameters(connection=self.connection)
836             rel_type = rel_db_params['type']
837             fragment, other_actions = self._alter_column_type_sql(
838                 new_rel.related_model, old_rel.field, new_rel.field, rel_type
839             )
840             self.execute(
841                 self.sql_alter_column % {
842                     "table": self.quote_name(new_rel.related_model._meta.db_table),
843                     "changes": fragment[0],
844                 },
845                 fragment[1],
846             )
847             for sql, params in other_actions:
848                 self.execute(sql, params)
849         # Does it have a foreign key?
850         if (self.connection.features.supports_foreign_keys and new_field.remote_field and
851                 (fks_dropped or not old_field.remote_field or not old_field.db_constraint) and
852                 new_field.db_constraint):
853             self.execute(self._create_fk_sql(model, new_field, "_fk_%(to_table)s_%(to_column)s"))
854         # Rebuild FKs that pointed to us if we previously had to drop them
855         if drop_foreign_keys:
856             for _, rel in rels_to_update:
857                 if rel.field.db_constraint:
858                     self.execute(self._create_fk_sql(rel.related_model, rel.field, "_fk"))
859         # Does it have check constraints we need to add?
860         if old_db_params['check'] != new_db_params['check'] and new_db_params['check']:
861             constraint_name = self._create_index_name(model._meta.db_table, [new_field.column], suffix='_check')
862             self.execute(self._create_check_sql(model, constraint_name, new_db_params['check']))
863         # Drop the default if we need to
864         # (Django usually does not use in-database defaults)
865         if needs_database_default:
866             changes_sql, params = self._alter_column_default_sql(model, old_field, new_field, drop=True)
867             sql = self.sql_alter_column % {
868                 "table": self.quote_name(model._meta.db_table),
869                 "changes": changes_sql,
870             }
871             self.execute(sql, params)
872         # Reset connection if required
873         if self.connection.features.connection_persists_old_columns:
874             self.connection.close()
875 
876     def _alter_column_null_sql(self, model, old_field, new_field):
877         """
878         Hook to specialize column null alteration.
879 
880         Return a (sql, params) fragment to set a column to null or non-null
881         as required by new_field, or None if no changes are required.
882         """
883         if (
884             self.connection.features.interprets_empty_strings_as_nulls and
885             new_field.empty_strings_allowed
886         ):
887             # The field is nullable in the database anyway, leave it alone.
888             return
889         else:
890             new_db_params = new_field.db_parameters(connection=self.connection)
891             sql = self.sql_alter_column_null if new_field.null else self.sql_alter_column_not_null
892             return (
893                 sql % {
894                     'column': self.quote_name(new_field.column),
895                     'type': new_db_params['type'],
896                 },
897                 [],
898             )
899 
900     def _alter_column_default_sql(self, model, old_field, new_field, drop=False):
901         """
902         Hook to specialize column default alteration.
903 
904         Return a (sql, params) fragment to add or drop (depending on the drop
905         argument) a default to new_field's column.
906         """
907         new_default = self.effective_default(new_field)
908         default = self._column_default_sql(new_field)
909         params = [new_default]
910 
911         if drop:
912             params = []
913         elif self.connection.features.requires_literal_defaults:
914             # Some databases (Oracle) can't take defaults as a parameter
915             # If this is the case, the SchemaEditor for that database should
916             # implement prepare_default().
917             default = self.prepare_default(new_default)
918             params = []
919 
920         new_db_params = new_field.db_parameters(connection=self.connection)
921         if drop:
922             if new_field.null:
923                 sql = self.sql_alter_column_no_default_null
924             else:
925                 sql = self.sql_alter_column_no_default
926         else:
927             sql = self.sql_alter_column_default
928         return (
929             sql % {
930                 'column': self.quote_name(new_field.column),
931                 'type': new_db_params['type'],
932                 'default': default,
933             },
934             params,
935         )
936 
937     def _alter_column_type_sql(self, model, old_field, new_field, new_type):
938         """
939         Hook to specialize column type alteration for different backends,
940         for cases when a creation type is different to an alteration type
941         (e.g. SERIAL in PostgreSQL, PostGIS fields).
942 
943         Return a two-tuple of: an SQL fragment of (sql, params) to insert into
944         an ALTER TABLE statement and a list of extra (sql, params) tuples to
945         run once the field is altered.
946         """
947         return (
948             (
949                 self.sql_alter_column_type % {
950                     "column": self.quote_name(new_field.column),
951                     "type": new_type,
952                 },
953                 [],
954             ),
955             [],
956         )
957 
958     def _alter_column_collation_sql(self, model, new_field, new_type, new_collation):
959         return (
960             self.sql_alter_column_collate % {
961                 'column': self.quote_name(new_field.column),
962                 'type': new_type,
963                 'collation': ' ' + self._collate_sql(new_collation) if new_collation else '',
964             },
965             [],
966         )
967 
968     def _alter_many_to_many(self, model, old_field, new_field, strict):
969         """Alter M2Ms to repoint their to= endpoints."""
970         # Rename the through table
971         if old_field.remote_field.through._meta.db_table != new_field.remote_field.through._meta.db_table:
972             self.alter_db_table(old_field.remote_field.through, old_field.remote_field.through._meta.db_table,
973                                 new_field.remote_field.through._meta.db_table)
974         # Repoint the FK to the other side
975         self.alter_field(
976             new_field.remote_field.through,
977             # We need the field that points to the target model, so we can tell alter_field to change it -
978             # this is m2m_reverse_field_name() (as opposed to m2m_field_name, which points to our model)
979             old_field.remote_field.through._meta.get_field(old_field.m2m_reverse_field_name()),
980             new_field.remote_field.through._meta.get_field(new_field.m2m_reverse_field_name()),
981         )
982         self.alter_field(
983             new_field.remote_field.through,
984             # for self-referential models we need to alter field from the other end too
985             old_field.remote_field.through._meta.get_field(old_field.m2m_field_name()),
986             new_field.remote_field.through._meta.get_field(new_field.m2m_field_name()),
987         )
988 
989     def _create_index_name(self, table_name, column_names, suffix=""):
990         """
991         Generate a unique name for an index/unique constraint.
992 
993         The name is divided into 3 parts: the table name, the column names,
994         and a unique digest and suffix.
995         """
996         _, table_name = split_identifier(table_name)
997         hash_suffix_part = '%s%s' % (names_digest(table_name, *column_names, length=8), suffix)
998         max_length = self.connection.ops.max_name_length() or 200
999         # If everything fits into max_length, use that name.
1000         index_name = '%s_%s_%s' % (table_name, '_'.join(column_names), hash_suffix_part)
1001         if len(index_name) <= max_length:
1002             return index_name
1003         # Shorten a long suffix.
1004         if len(hash_suffix_part) > max_length / 3:
1005             hash_suffix_part = hash_suffix_part[:max_length // 3]
1006         other_length = (max_length - len(hash_suffix_part)) // 2 - 1
1007         index_name = '%s_%s_%s' % (
1008             table_name[:other_length],
1009             '_'.join(column_names)[:other_length],
1010             hash_suffix_part,
1011         )
1012         # Prepend D if needed to prevent the name from starting with an
1013         # underscore or a number (not permitted on Oracle).
1014         if index_name[0] == "_" or index_name[0].isdigit():
1015             index_name = "D%s" % index_name[:-1]
1016         return index_name
1017 
1018     def _get_index_tablespace_sql(self, model, fields, db_tablespace=None):
1019         if db_tablespace is None:
1020             if len(fields) == 1 and fields[0].db_tablespace:
1021                 db_tablespace = fields[0].db_tablespace
1022             elif model._meta.db_tablespace:
1023                 db_tablespace = model._meta.db_tablespace
1024         if db_tablespace is not None:
1025             return ' ' + self.connection.ops.tablespace_sql(db_tablespace)
1026         return ''
1027 
1028     def _index_condition_sql(self, condition):
1029         if condition:
1030             return ' WHERE ' + condition
1031         return ''
1032 
1033     def _index_include_sql(self, model, columns):
1034         if not columns or not self.connection.features.supports_covering_indexes:
1035             return ''
1036         return Statement(
1037             ' INCLUDE (%(columns)s)',
1038             columns=Columns(model._meta.db_table, columns, self.quote_name),
1039         )
1040 
1041     def _create_index_sql(self, model, *, fields=None, name=None, suffix='', using='',
1042                           db_tablespace=None, col_suffixes=(), sql=None, opclasses=(),
1043                           condition=None, include=None, expressions=None):
1044         """
1045         Return the SQL statement to create the index for one or several fields
1046         or expressions. `sql` can be specified if the syntax differs from the
1047         standard (GIS indexes, ...).
1048         """
1049         fields = fields or []
1050         expressions = expressions or []
1051         compiler = Query(model, alias_cols=False).get_compiler(
1052             connection=self.connection,
1053         )
1054         tablespace_sql = self._get_index_tablespace_sql(model, fields, db_tablespace=db_tablespace)
1055         columns = [field.column for field in fields]
1056         sql_create_index = sql or self.sql_create_index
1057         table = model._meta.db_table
1058 
1059         def create_index_name(*args, **kwargs):
1060             nonlocal name
1061             if name is None:
1062                 name = self._create_index_name(*args, **kwargs)
1063             return self.quote_name(name)
1064 
1065         return Statement(
1066             sql_create_index,
1067             table=Table(table, self.quote_name),
1068             name=IndexName(table, columns, suffix, create_index_name),
1069             using=using,
1070             columns=(
1071                 self._index_columns(table, columns, col_suffixes, opclasses)
1072                 if columns
1073                 else Expressions(table, expressions, compiler, self.quote_value)
1074             ),
1075             extra=tablespace_sql,
1076             condition=self._index_condition_sql(condition),
1077             include=self._index_include_sql(model, include),
1078         )
1079 
1080     def _delete_index_sql(self, model, name, sql=None):
1081         return Statement(
1082             sql or self.sql_delete_index,
1083             table=Table(model._meta.db_table, self.quote_name),
1084             name=self.quote_name(name),
1085         )
1086 
1087     def _index_columns(self, table, columns, col_suffixes, opclasses):
1088         return Columns(table, columns, self.quote_name, col_suffixes=col_suffixes)
1089 
1090     def _model_indexes_sql(self, model):
1091         """
1092         Return a list of all index SQL statements (field indexes,
1093         index_together, Meta.indexes) for the specified model.
1094         """
1095         if not model._meta.managed or model._meta.proxy or model._meta.swapped:
1096             return []
1097         output = []
1098         for field in model._meta.local_fields:
1099             output.extend(self._field_indexes_sql(model, field))
1100 
1101         for field_names in model._meta.index_together:
1102             fields = [model._meta.get_field(field) for field in field_names]
1103             output.append(self._create_index_sql(model, fields=fields, suffix='_idx'))
1104 
1105         for index in model._meta.indexes:
1106             if (
1107                 not index.contains_expressions or
1108                 self.connection.features.supports_expression_indexes
1109             ):
1110                 output.append(index.create_sql(model, self))
1111         return output
1112 
1113     def _field_indexes_sql(self, model, field):
1114         """
1115         Return a list of all index SQL statements for the specified field.
1116         """
1117         output = []
1118         if self._field_should_be_indexed(model, field):
1119             output.append(self._create_index_sql(model, fields=[field]))
1120         return output
1121 
1122     def _field_should_be_altered(self, old_field, new_field):
1123         _, old_path, old_args, old_kwargs = old_field.deconstruct()
1124         _, new_path, new_args, new_kwargs = new_field.deconstruct()
1125         # Don't alter when:
1126         # - changing only a field name
1127         # - changing an attribute that doesn't affect the schema
1128         # - adding only a db_column and the column name is not changed
1129         non_database_attrs = [
1130             'blank',
1131             'db_column',
1132             'editable',
1133             'error_messages',
1134             'help_text',
1135             'limit_choices_to',
1136             # Database-level options are not supported, see #21961.
1137             'on_delete',
1138             'related_name',
1139             'related_query_name',
1140             'validators',
1141             'verbose_name',
1142         ]
1143         for attr in non_database_attrs:
1144             old_kwargs.pop(attr, None)
1145             new_kwargs.pop(attr, None)
1146         return (
1147             self.quote_name(old_field.column) != self.quote_name(new_field.column) or
1148             (old_path, old_args, old_kwargs) != (new_path, new_args, new_kwargs)
1149         )
1150 
1151     def _field_should_be_indexed(self, model, field):
1152         return field.db_index and not field.unique
1153 
1154     def _field_became_primary_key(self, old_field, new_field):
1155         return not old_field.primary_key and new_field.primary_key
1156 
1157     def _unique_should_be_added(self, old_field, new_field):
1158         return (
1159             not new_field.primary_key and
1160             new_field.unique and
1161             (not old_field.unique or old_field.primary_key)
1162         )
1163 
1164     def _rename_field_sql(self, table, old_field, new_field, new_type):
1165         return self.sql_rename_column % {
1166             "table": self.quote_name(table),
1167             "old_column": self.quote_name(old_field.column),
1168             "new_column": self.quote_name(new_field.column),
1169             "type": new_type,
1170         }
1171 
1172     def _create_fk_sql(self, model, field, suffix):
1173         table = Table(model._meta.db_table, self.quote_name)
1174         name = self._fk_constraint_name(model, field, suffix)
1175         column = Columns(model._meta.db_table, [field.column], self.quote_name)
1176         to_table = Table(field.target_field.model._meta.db_table, self.quote_name)
1177         to_column = Columns(field.target_field.model._meta.db_table, [field.target_field.column], self.quote_name)
1178         deferrable = self.connection.ops.deferrable_sql()
1179         return Statement(
1180             self.sql_create_fk,
1181             table=table,
1182             name=name,
1183             column=column,
1184             to_table=to_table,
1185             to_column=to_column,
1186             deferrable=deferrable,
1187         )
1188 
1189     def _fk_constraint_name(self, model, field, suffix):
1190         def create_fk_name(*args, **kwargs):
1191             return self.quote_name(self._create_index_name(*args, **kwargs))
1192 
1193         return ForeignKeyName(
1194             model._meta.db_table,
1195             [field.column],
1196             split_identifier(field.target_field.model._meta.db_table)[1],
1197             [field.target_field.column],
1198             suffix,
1199             create_fk_name,
1200         )
1201 
1202     def _delete_fk_sql(self, model, name):
1203         return self._delete_constraint_sql(self.sql_delete_fk, model, name)
1204 
1205     def _deferrable_constraint_sql(self, deferrable):
1206         if deferrable is None:
1207             return ''
1208         if deferrable == Deferrable.DEFERRED:
1209             return ' DEFERRABLE INITIALLY DEFERRED'
1210         if deferrable == Deferrable.IMMEDIATE:
1211             return ' DEFERRABLE INITIALLY IMMEDIATE'
1212 
1213     def _unique_sql(
1214         self, model, fields, name, condition=None, deferrable=None,
1215         include=None, opclasses=None, expressions=None,
1216     ):
1217         if (
1218             deferrable and
1219             not self.connection.features.supports_deferrable_unique_constraints
1220         ):
1221             return None
1222         if condition or include or opclasses or expressions:
1223             # Databases support conditional, covering, and functional unique
1224             # constraints via a unique index.
1225             sql = self._create_unique_sql(
1226                 model,
1227                 fields,
1228                 name=name,
1229                 condition=condition,
1230                 include=include,
1231                 opclasses=opclasses,
1232                 expressions=expressions,
1233             )
1234             if sql:
1235                 self.deferred_sql.append(sql)
1236             return None
1237         constraint = self.sql_unique_constraint % {
1238             'columns': ', '.join([self.quote_name(field.column) for field in fields]),
1239             'deferrable': self._deferrable_constraint_sql(deferrable),
1240         }
1241         return self.sql_constraint % {
1242             'name': self.quote_name(name),
1243             'constraint': constraint,
1244         }
1245 
1246     def _create_unique_sql(
1247         self, model, fields, name=None, condition=None, deferrable=None,
1248         include=None, opclasses=None, expressions=None,
1249     ):
1250         if (
1251             (
1252                 deferrable and
1253                 not self.connection.features.supports_deferrable_unique_constraints
1254             ) or
1255             (condition and not self.connection.features.supports_partial_indexes) or
1256             (include and not self.connection.features.supports_covering_indexes) or
1257             (expressions and not self.connection.features.supports_expression_indexes)
1258         ):
1259             return None
1260 
1261         def create_unique_name(*args, **kwargs):
1262             return self.quote_name(self._create_index_name(*args, **kwargs))
1263 
1264         compiler = Query(model, alias_cols=False).get_compiler(connection=self.connection)
1265         table = model._meta.db_table
1266         columns = [field.column for field in fields]
1267         if name is None:
1268             name = IndexName(table, columns, '_uniq', create_unique_name)
1269         else:
1270             name = self.quote_name(name)
1271         if condition or include or opclasses or expressions:
1272             sql = self.sql_create_unique_index
1273         else:
1274             sql = self.sql_create_unique
1275         if columns:
1276             columns = self._index_columns(table, columns, col_suffixes=(), opclasses=opclasses)
1277         else:
1278             columns = Expressions(table, expressions, compiler, self.quote_value)
1279         return Statement(
1280             sql,
1281             table=Table(table, self.quote_name),
1282             name=name,
1283             columns=columns,
1284             condition=self._index_condition_sql(condition),
1285             deferrable=self._deferrable_constraint_sql(deferrable),
1286             include=self._index_include_sql(model, include),
1287         )
1288 
1289     def _delete_unique_sql(
1290         self, model, name, condition=None, deferrable=None, include=None,
1291         opclasses=None, expressions=None,
1292     ):
1293         if (
1294             (
1295                 deferrable and
1296                 not self.connection.features.supports_deferrable_unique_constraints
1297             ) or
1298             (condition and not self.connection.features.supports_partial_indexes) or
1299             (include and not self.connection.features.supports_covering_indexes) or
1300             (expressions and not self.connection.features.supports_expression_indexes)
1301 
1302         ):
1303             return None
1304         if condition or include or opclasses or expressions:
1305             sql = self.sql_delete_index
1306         else:
1307             sql = self.sql_delete_unique
1308         return self._delete_constraint_sql(sql, model, name)
1309 
1310     def _check_sql(self, name, check):
1311         return self.sql_constraint % {
1312             'name': self.quote_name(name),
1313             'constraint': self.sql_check_constraint % {'check': check},
1314         }
1315 
1316     def _create_check_sql(self, model, name, check):
1317         return Statement(
1318             self.sql_create_check,
1319             table=Table(model._meta.db_table, self.quote_name),
1320             name=self.quote_name(name),
1321             check=check,
1322         )
1323 
1324     def _delete_check_sql(self, model, name):
1325         return self._delete_constraint_sql(self.sql_delete_check, model, name)
1326 
1327     def _delete_constraint_sql(self, template, model, name):
1328         return Statement(
1329             template,
1330             table=Table(model._meta.db_table, self.quote_name),
1331             name=self.quote_name(name),
1332         )
1333 
1334     def _constraint_names(self, model, column_names=None, unique=None,
1335                           primary_key=None, index=None, foreign_key=None,
1336                           check=None, type_=None, exclude=None):
1337         """Return all constraint names matching the columns and conditions."""
1338         if column_names is not None:
1339             column_names = [
1340                 self.connection.introspection.identifier_converter(name)
1341                 for name in column_names
1342             ]
1343         with self.connection.cursor() as cursor:
1344             constraints = self.connection.introspection.get_constraints(cursor, model._meta.db_table)
1345         result = []
1346         for name, infodict in constraints.items():
1347             if column_names is None or column_names == infodict['columns']:
1348                 if unique is not None and infodict['unique'] != unique:
1349                     continue
1350                 if primary_key is not None and infodict['primary_key'] != primary_key:
1351                     continue
1352                 if index is not None and infodict['index'] != index:
1353                     continue
1354                 if check is not None and infodict['check'] != check:
1355                     continue
1356                 if foreign_key is not None and not infodict['foreign_key']:
1357                     continue
1358                 if type_ is not None and infodict['type'] != type_:
1359                     continue
1360                 if not exclude or name not in exclude:
1361                     result.append(name)
1362         return result
1363 
1364     def _delete_primary_key(self, model, strict=False):
1365         constraint_names = self._constraint_names(model, primary_key=True)
1366         if strict and len(constraint_names) != 1:
1367             raise ValueError('Found wrong number (%s) of PK constraints for %s' % (
1368                 len(constraint_names),
1369                 model._meta.db_table,
1370             ))
1371         for constraint_name in constraint_names:
1372             self.execute(self._delete_primary_key_sql(model, constraint_name))
1373 
1374     def _create_primary_key_sql(self, model, field):
1375         return Statement(
1376             self.sql_create_pk,
1377             table=Table(model._meta.db_table, self.quote_name),
1378             name=self.quote_name(
1379                 self._create_index_name(model._meta.db_table, [field.column], suffix="_pk")
1380             ),
1381             columns=Columns(model._meta.db_table, [field.column], self.quote_name),
1382         )
1383 
1384     def _delete_primary_key_sql(self, model, name):
1385         return self._delete_constraint_sql(self.sql_delete_pk, model, name)
1386 
1387     def _collate_sql(self, collation):
1388         return 'COLLATE ' + self.quote_name(collation)
1389 
1390     def remove_procedure(self, procedure_name, param_types=()):
1391         sql = self.sql_delete_procedure % {
1392             'procedure': self.quote_name(procedure_name),
1393             'param_types': ','.join(param_types),
1394         }
1395         self.execute(sql)

</code><intended_behavior>Correctly identify when a foreign key references a unique field instead of a primary key in another table, and generate a model field that accurately represents this relationship.</intended_behavior>]
2025-10-15 03:40:39.353 | INFO     | Overall retry 0 succeeded; ending workflow
2025-10-15 03:40:39.353 | INFO     | Search-only: skipping patch selection
2025-10-15 03:40:39.486 | INFO     | Task django__django-15037 completed successfully.
2025-10-15 03:40:39.487 | INFO     | No patch generated. You can try running ACR again.
