[ENH]: Allow override of contour level autoscaling
### Problem

In Matplotlib 3, when using a list of values for the `levels` argument in `contour()`, the list of values is overridden in the case that all requested levels fall outside the data range. While this may be desirable for casually browsing data when the user is unfamiliar with the data range, it causes serious problems for batch applications where the user legitimately intends to use their list of levels but does not know whether every input array will produce contours.

Example:
```
myplot = plt.contour( x , y , data , levels = [100] )
print( myplot.levels )
```

The above prints `[0.0]` when `data` is an array of values ranging from 0 to 50 (i.e., the requested contour level of 100 is outside the data range). As a result, the plot contains erroneous contours around near-zero values, presumably due to floating point precision.

This is a consequence of the change described here (https://matplotlib.org/stable/api/prev_api_changes/api_changes_3.0.0.html?highlight=contour%20levels):

> Selection of contour levels is now the same for contour and contourf; previously, for contour, levels outside the data range were deleted. **(Exception: if no contour levels are found within the data range, the levels attribute is replaced with a list holding only the minimum of the data range.)**

### Proposed solution

Add a kwarg to `contour()` that overrides the autoscaling behavior. When the kwarg is set, it would trigger a flag in `_process_contour_level_args()` (https://github.com/matplotlib/matplotlib/blob/main/lib/matplotlib/contour.py):

```
if not self.filled:
            inside = (self.levels > self.zmin) & (self.levels < self.zmax)
            levels_in = self.levels[inside]
            if len(levels_in) == 0 and not(OVERRIDE_AUTOSCALE_FLAG):
                self.levels = [self.zmin]
                _api.warn_external(
                    "No contour levels were found within the data range.")
```
