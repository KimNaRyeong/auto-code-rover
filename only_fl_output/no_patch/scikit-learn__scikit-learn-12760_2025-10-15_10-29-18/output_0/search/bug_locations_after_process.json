[
    {
        "rel_file_path": "sklearn/metrics/cluster/unsupervised.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/scikit-learn__scikit-learn/setup_scikit-learn__scikit-learn__0.21/sklearn/metrics/cluster/unsupervised.py",
        "start": 299,
        "end": 352,
        "class_name": null,
        "method_name": "davies_bouldin_score",
        "code": "299 def davies_bouldin_score(X, labels):\n300     \"\"\"Computes the Davies-Bouldin score.\n301 \n302     The score is defined as the ratio of within-cluster distances to\n303     between-cluster distances.\n304 \n305     Read more in the :ref:`User Guide <davies-bouldin_index>`.\n306 \n307     Parameters\n308     ----------\n309     X : array-like, shape (``n_samples``, ``n_features``)\n310         List of ``n_features``-dimensional data points. Each row corresponds\n311         to a single data point.\n312 \n313     labels : array-like, shape (``n_samples``,)\n314         Predicted labels for each sample.\n315 \n316     Returns\n317     -------\n318     score: float\n319         The resulting Davies-Bouldin score.\n320 \n321     References\n322     ----------\n323     .. [1] Davies, David L.; Bouldin, Donald W. (1979).\n324        `\"A Cluster Separation Measure\"\n325        <https://ieeexplore.ieee.org/document/4766909>`__.\n326        IEEE Transactions on Pattern Analysis and Machine Intelligence.\n327        PAMI-1 (2): 224-227\n328     \"\"\"\n329     X, labels = check_X_y(X, labels)\n330     le = LabelEncoder()\n331     labels = le.fit_transform(labels)\n332     n_samples, _ = X.shape\n333     n_labels = len(le.classes_)\n334     check_number_of_labels(n_labels, n_samples)\n335 \n336     intra_dists = np.zeros(n_labels)\n337     centroids = np.zeros((n_labels, len(X[0])), dtype=np.float)\n338     for k in range(n_labels):\n339         cluster_k = safe_indexing(X, labels == k)\n340         centroid = cluster_k.mean(axis=0)\n341         centroids[k] = centroid\n342         intra_dists[k] = np.average(pairwise_distances(\n343             cluster_k, [centroid]))\n344 \n345     centroid_distances = pairwise_distances(centroids)\n346 \n347     if np.allclose(intra_dists, 0) or np.allclose(centroid_distances, 0):\n348         return 0.0\n349 \n350     score = (intra_dists[:, None] + intra_dists) / centroid_distances\n351     score[score == np.inf] = np.nan\n352     return np.mean(np.nanmax(score, axis=1))\n",
        "intended_behavior": "The intended behavior here is to accurately compute the Davies-Bouldin score without encountering division by zero errors. To resolve the issue, the code needs to be modified to handle cases where centroid_distances might contain zero values. Before performing division, the code should check if centroid_distances contains zeros and handle it accordingly, possibly by setting those specific scores to np.nan (as it already does for infinite scores) or by using a small epsilon value to avoid direct division by zero. This check should be more refined than the current np.allclose check to address instances where not all, but some, distances are close to or exactly zero. This improvement will ensure the functionality remains intact while avoiding runtime warnings and incorrect infinite scores."
    },
    {
        "rel_file_path": "sklearn/metrics/pairwise.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/scikit-learn__scikit-learn/setup_scikit-learn__scikit-learn__0.21/sklearn/metrics/pairwise.py",
        "start": 1309,
        "end": 1429,
        "class_name": null,
        "method_name": "pairwise_distances",
        "code": "1309 def pairwise_distances(X, Y=None, metric=\"euclidean\", n_jobs=None, **kwds):\n1310     \"\"\" Compute the distance matrix from a vector array X and optional Y.\n1311 \n1312     This method takes either a vector array or a distance matrix, and returns\n1313     a distance matrix. If the input is a vector array, the distances are\n1314     computed. If the input is a distances matrix, it is returned instead.\n1315 \n1316     This method provides a safe way to take a distance matrix as input, while\n1317     preserving compatibility with many other algorithms that take a vector\n1318     array.\n1319 \n1320     If Y is given (default is None), then the returned matrix is the pairwise\n1321     distance between the arrays from both X and Y.\n1322 \n1323     Valid values for metric are:\n1324 \n1325     - From scikit-learn: ['cityblock', 'cosine', 'euclidean', 'l1', 'l2',\n1326       'manhattan']. These metrics support sparse matrix inputs.\n1327 \n1328     - From scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev',\n1329       'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis',\n1330       'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean',\n1331       'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule']\n1332       See the documentation for scipy.spatial.distance for details on these\n1333       metrics. These metrics do not support sparse matrix inputs.\n1334 \n1335     Note that in the case of 'cityblock', 'cosine' and 'euclidean' (which are\n1336     valid scipy.spatial.distance metrics), the scikit-learn implementation\n1337     will be used, which is faster and has support for sparse matrices (except\n1338     for 'cityblock'). For a verbose description of the metrics from\n1339     scikit-learn, see the __doc__ of the sklearn.pairwise.distance_metrics\n1340     function.\n1341 \n1342     Read more in the :ref:`User Guide <metrics>`.\n1343 \n1344     Parameters\n1345     ----------\n1346     X : array [n_samples_a, n_samples_a] if metric == \"precomputed\", or, \\\n1347              [n_samples_a, n_features] otherwise\n1348         Array of pairwise distances between samples, or a feature array.\n1349 \n1350     Y : array [n_samples_b, n_features], optional\n1351         An optional second feature array. Only allowed if\n1352         metric != \"precomputed\".\n1353 \n1354     metric : string, or callable\n1355         The metric to use when calculating distance between instances in a\n1356         feature array. If metric is a string, it must be one of the options\n1357         allowed by scipy.spatial.distance.pdist for its metric parameter, or\n1358         a metric listed in pairwise.PAIRWISE_DISTANCE_FUNCTIONS.\n1359         If metric is \"precomputed\", X is assumed to be a distance matrix.\n1360         Alternatively, if metric is a callable function, it is called on each\n1361         pair of instances (rows) and the resulting value recorded. The callable\n1362         should take two arrays from X as input and return a value indicating\n1363         the distance between them.\n1364 \n1365     n_jobs : int or None, optional (default=None)\n1366         The number of jobs to use for the computation. This works by breaking\n1367         down the pairwise matrix into n_jobs even slices and computing them in\n1368         parallel.\n1369 \n1370         ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n1371         ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n1372         for more details.\n1373 \n1374     **kwds : optional keyword parameters\n1375         Any further parameters are passed directly to the distance function.\n1376         If using a scipy.spatial.distance metric, the parameters are still\n1377         metric dependent. See the scipy docs for usage examples.\n1378 \n1379     Returns\n1380     -------\n1381     D : array [n_samples_a, n_samples_a] or [n_samples_a, n_samples_b]\n1382         A distance matrix D such that D_{i, j} is the distance between the\n1383         ith and jth vectors of the given matrix X, if Y is None.\n1384         If Y is not None, then D_{i, j} is the distance between the ith array\n1385         from X and the jth array from Y.\n1386 \n1387     See also\n1388     --------\n1389     pairwise_distances_chunked : performs the same calculation as this\n1390         function, but returns a generator of chunks of the distance matrix, in\n1391         order to limit memory usage.\n1392     paired_distances : Computes the distances between corresponding\n1393                        elements of two arrays\n1394     \"\"\"\n1395     if (metric not in _VALID_METRICS and\n1396             not callable(metric) and metric != \"precomputed\"):\n1397         raise ValueError(\"Unknown metric %s. \"\n1398                          \"Valid metrics are %s, or 'precomputed', or a \"\n1399                          \"callable\" % (metric, _VALID_METRICS))\n1400 \n1401     if metric == \"precomputed\":\n1402         X, _ = check_pairwise_arrays(X, Y, precomputed=True)\n1403 \n1404         whom = (\"`pairwise_distances`. Precomputed distance \"\n1405                 \" need to have non-negative values.\")\n1406         check_non_negative(X, whom=whom)\n1407         return X\n1408     elif metric in PAIRWISE_DISTANCE_FUNCTIONS:\n1409         func = PAIRWISE_DISTANCE_FUNCTIONS[metric]\n1410     elif callable(metric):\n1411         func = partial(_pairwise_callable, metric=metric, **kwds)\n1412     else:\n1413         if issparse(X) or issparse(Y):\n1414             raise TypeError(\"scipy distance metrics do not\"\n1415                             \" support sparse matrices.\")\n1416 \n1417         dtype = bool if metric in PAIRWISE_BOOLEAN_FUNCTIONS else None\n1418         X, Y = check_pairwise_arrays(X, Y, dtype=dtype)\n1419 \n1420         # precompute data-derived metric params\n1421         params = _precompute_metric_params(X, Y, metric=metric, **kwds)\n1422         kwds.update(**params)\n1423 \n1424         if effective_n_jobs(n_jobs) == 1 and X is Y:\n1425             return distance.squareform(distance.pdist(X, metric=metric,\n1426                                                       **kwds))\n1427         func = partial(distance.cdist, metric=metric, **kwds)\n1428 \n1429     return _parallel_pairwise(X, Y, func, n_jobs, **kwds)\n",
        "intended_behavior": "Although not directly responsible for the division by zero warning, an inspection of the pairwise_distances function's handling of edge cases where the output might be zero could be beneficial. The intended behavior of this method should include ensuring that the distance computation is robust against producing zeros in situations that might lead to division by zero errors downstream (e.g., when calculating the Davies-Bouldin score). However, it's crucial to recognize that fundamentally changing how distances are computed could have widespread impacts beyond this specific use case. Thus, any changes here should be carefully considered, possibly enhancing documentation or integrating warnings when the distance computation could lead to potential division by zero errors in downstream tasks."
    }
]