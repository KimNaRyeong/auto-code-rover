2025-10-15 08:37:18.836 | INFO     | Starting overall retry 0 with model gpt-4-0125-preview
2025-10-15 08:37:20.272 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=94, output_tokens=12, cost=0.001300
2025-10-15 08:37:20.273 | INFO     | Test agent decides that the issue statement does not contain reproduction steps; skipping reproducer tracing
2025-10-15 08:37:20.277 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-15 08:37:24.792 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=403, output_tokens=145, cost=0.008380
2025-10-15 08:37:24.796 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-15 08:37:26.686 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=499, output_tokens=34, cost=0.006010
2025-10-15 08:37:26.688 | DEBUG    | Extracted a valid json.
2025-10-15 08:37:26.688 | DEBUG    | Agent proxy return the following json: {
    "API_calls": ["search_method(\"groupby\")", "search_code(\"groupby(.*name=None.*)\")"],
    "bug_locations": []
}
2025-10-15 08:37:26.726 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-15 08:37:26.727 | DEBUG    | <Agent search> Analyzing search results.
2025-10-15 08:37:43.860 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=2322, output_tokens=642, cost=0.042480
2025-10-15 08:37:43.874 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-15 08:37:57.955 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=3180, output_tokens=493, cost=0.046590
2025-10-15 08:37:57.966 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-15 08:38:02.180 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=847, output_tokens=163, cost=0.013360
2025-10-15 08:38:02.181 | INFO     | Refactored invocation argument parsing gives different result on 'get_code_around_line("xarray/core/common.py", 630, 5)': old result is ['xarray/core/common.py', '630', '5'], new result  is ['xarray/core/common.py', 630, 5]
2025-10-15 08:38:02.183 | DEBUG    | Extracted a valid json.
2025-10-15 08:38:02.183 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_method_in_file(\"_groupby_cls\", \"xarray/core/common.py\")",
        "get_code_around_line(\"xarray/core/common.py\", 630, 5)"
    ],
    "bug_locations": [
        {
            "file": "xarray/core/common.py",
            "class": "",
            "method": "groupby",
            "intended_behavior": "The intended behavior for resolving the issue should include handling the `group` parameter when it is `None`. The method should either perform a default action or provide clear documentation on how `None` values are managed, ensuring the functionality is preserved for grouping by strings, `DataArray`, or `IndexVariable` without crashing or giving uninformative errors."
        }
    ]
}
2025-10-15 08:38:02.186 | INFO     | Refactored invocation argument parsing gives different result on 'get_code_around_line("xarray/core/common.py", 630, 5)': old result is ['xarray/core/common.py', '630', '5'], new result  is ['xarray/core/common.py', 630, 5]
2025-10-15 08:38:02.194 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-15 08:38:02.194 | DEBUG    | <Agent search> Analyzing search results.
2025-10-15 08:38:19.220 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=3970, output_tokens=621, cost=0.058330
2025-10-15 08:38:19.232 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-15 08:38:26.221 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=4807, output_tokens=291, cost=0.056800
2025-10-15 08:38:26.228 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-15 08:38:34.429 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=645, output_tokens=291, cost=0.015180
2025-10-15 08:38:34.430 | DEBUG    | Extracted a valid json.
2025-10-15 08:38:34.430 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [],
    "bug_locations": [
        {
            "file": "xarray/core/common.py",
            "class": "DataWithCoords",
            "method": "groupby",
            "intended_behavior": "The `groupby` method's intended behavior, in this case, is to explicitly handle cases where the `group` parameter might be `None`. This improvement could take two forms:\n- If `group=None` is intended to be a valid use case: The method should define a standard behavior for this case, which might involve grouping all the dataset's elements together as a single group, or any other behavior deemed appropriate by the framework's logic.\n- If `group=None` is not intended to be valid: The method should be updated to check for `None` explicitly and raise a meaningful ValueError or TypeError, indicating that `None` is not a valid value for the `group` parameter. This error message should guide the user towards proper usage of the method.\n\nThis adjustment would enhance the method's robustness and user-friendliness by providing clear guidance or functionality in cases where `group=None`, thereby resolving the issue described. This change should also ensure that the method's existing functionality for handling non-`None` `group` values remains unaffected and that the behavior is consistent with the rest of the `xarray` framework's conventions and expectations."
        }
    ]
}
2025-10-15 08:38:34.438 | DEBUG    | Bug location extracted successfully: [<file>xarray/core/common.py</file>
<class>DataWithCoords</class>
<method>groupby</method>
<code>
630     def groupby(self, group, squeeze: bool = True, restore_coord_dims: bool = None):
631         """Returns a GroupBy object for performing grouped operations.
632 
633         Parameters
634         ----------
635         group : str, DataArray or IndexVariable
636             Array whose unique values should be used to group this array. If a
637             string, must be the name of a variable contained in this dataset.
638         squeeze : boolean, optional
639             If "group" is a dimension of any arrays in this dataset, `squeeze`
640             controls whether the subarrays have a dimension of length 1 along
641             that dimension or if the dimension is squeezed out.
642         restore_coord_dims : bool, optional
643             If True, also restore the dimension order of multi-dimensional
644             coordinates.
645 
646         Returns
647         -------
648         grouped : GroupBy
649             A `GroupBy` object patterned after `pandas.GroupBy` that can be
650             iterated over in the form of `(unique_value, grouped_array)` pairs.
651 
652         Examples
653         --------
654         Calculate daily anomalies for daily data:
655 
656         >>> da = xr.DataArray(
657         ...     np.linspace(0, 1826, num=1827),
658         ...     coords=[pd.date_range("1/1/2000", "31/12/2004", freq="D")],
659         ...     dims="time",
660         ... )
661         >>> da
662         <xarray.DataArray (time: 1827)>
663         array([0.000e+00, 1.000e+00, 2.000e+00, ..., 1.824e+03, 1.825e+03, 1.826e+03])
664         Coordinates:
665           * time     (time) datetime64[ns] 2000-01-01 2000-01-02 2000-01-03 ...
666         >>> da.groupby("time.dayofyear") - da.groupby("time.dayofyear").mean("time")
667         <xarray.DataArray (time: 1827)>
668         array([-730.8, -730.8, -730.8, ...,  730.2,  730.2,  730.5])
669         Coordinates:
670           * time       (time) datetime64[ns] 2000-01-01 2000-01-02 2000-01-03 ...
671             dayofyear  (time) int64 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...
672 
673         See Also
674         --------
675         core.groupby.DataArrayGroupBy
676         core.groupby.DatasetGroupBy
677         """
678         # While we don't generally check the type of every arg, passing
679         # multiple dimensions as multiple arguments is common enough, and the
680         # consequences hidden enough (strings evaluate as true) to warrant
681         # checking here.
682         # A future version could make squeeze kwarg only, but would face
683         # backward-compat issues.
684         if not isinstance(squeeze, bool):
685             raise TypeError(
686                 f"`squeeze` must be True or False, but {squeeze} was supplied"
687             )
688 
689         return self._groupby_cls(
690             self, group, squeeze=squeeze, restore_coord_dims=restore_coord_dims
691         )

</code><intended_behavior>The `groupby` method's intended behavior, in this case, is to explicitly handle cases where the `group` parameter might be `None`. This improvement could take two forms:
- If `group=None` is intended to be a valid use case: The method should define a standard behavior for this case, which might involve grouping all the dataset's elements together as a single group, or any other behavior deemed appropriate by the framework's logic.
- If `group=None` is not intended to be valid: The method should be updated to check for `None` explicitly and raise a meaningful ValueError or TypeError, indicating that `None` is not a valid value for the `group` parameter. This error message should guide the user towards proper usage of the method.

This adjustment would enhance the method's robustness and user-friendliness by providing clear guidance or functionality in cases where `group=None`, thereby resolving the issue described. This change should also ensure that the method's existing functionality for handling non-`None` `group` values remains unaffected and that the behavior is consistent with the rest of the `xarray` framework's conventions and expectations.</intended_behavior>, <file>xarray/core/common.py</file>
<class>DataWithCoords</class>
<method>None</method>
<code>
336 class DataWithCoords(SupportsArithmetic, AttrAccessMixin):
337     """Shared base class for Dataset and DataArray."""
338 
339     __slots__ = ()
340 
341     _rolling_exp_cls = RollingExp
342 
343     def squeeze(
344         self,
345         dim: Union[Hashable, Iterable[Hashable], None] = None,
346         drop: bool = False,
347         axis: Union[int, Iterable[int], None] = None,
348     ):
349         """Return a new object with squeezed data.
350 
351         Parameters
352         ----------
353         dim : None or Hashable or iterable of Hashable, optional
354             Selects a subset of the length one dimensions. If a dimension is
355             selected with length greater than one, an error is raised. If
356             None, all length one dimensions are squeezed.
357         drop : bool, optional
358             If ``drop=True``, drop squeezed coordinates instead of making them
359             scalar.
360         axis : None or int or iterable of int, optional
361             Like dim, but positional.
362 
363         Returns
364         -------
365         squeezed : same type as caller
366             This object, but with with all or a subset of the dimensions of
367             length 1 removed.
368 
369         See Also
370         --------
371         numpy.squeeze
372         """
373         dims = get_squeeze_dims(self, dim, axis)
374         return self.isel(drop=drop, **{d: 0 for d in dims})
375 
376     def get_index(self, key: Hashable) -> pd.Index:
377         """Get an index for a dimension, with fall-back to a default RangeIndex
378         """
379         if key not in self.dims:
380             raise KeyError(key)
381 
382         try:
383             return self.indexes[key]
384         except KeyError:
385             # need to ensure dtype=int64 in case range is empty on Python 2
386             return pd.Index(range(self.sizes[key]), name=key, dtype=np.int64)
387 
388     def _calc_assign_results(
389         self: C, kwargs: Mapping[Hashable, Union[T, Callable[[C], T]]]
390     ) -> Dict[Hashable, T]:
391         return {k: v(self) if callable(v) else v for k, v in kwargs.items()}
392 
393     def assign_coords(self, coords=None, **coords_kwargs):
394         """Assign new coordinates to this object.
395 
396         Returns a new object with all the original data in addition to the new
397         coordinates.
398 
399         Parameters
400         ----------
401         coords : dict, optional
402             A dict where the keys are the names of the coordinates
403             with the new values to assign. If the values are callable, they are
404             computed on this object and assigned to new coordinate variables.
405             If the values are not callable, (e.g. a ``DataArray``, scalar, or
406             array), they are simply assigned. A new coordinate can also be
407             defined and attached to an existing dimension using a tuple with
408             the first element the dimension name and the second element the
409             values for this new coordinate.
410 
411         **coords_kwargs : keyword, value pairs, optional
412             The keyword arguments form of ``coords``.
413             One of ``coords`` or ``coords_kwargs`` must be provided.
414 
415         Returns
416         -------
417         assigned : same type as caller
418             A new object with the new coordinates in addition to the existing
419             data.
420 
421         Examples
422         --------
423         Convert longitude coordinates from 0-359 to -180-179:
424 
425         >>> da = xr.DataArray(
426         ...     np.random.rand(4), coords=[np.array([358, 359, 0, 1])], dims="lon",
427         ... )
428         >>> da
429         <xarray.DataArray (lon: 4)>
430         array([0.28298 , 0.667347, 0.657938, 0.177683])
431         Coordinates:
432           * lon      (lon) int64 358 359 0 1
433         >>> da.assign_coords(lon=(((da.lon + 180) % 360) - 180))
434         <xarray.DataArray (lon: 4)>
435         array([0.28298 , 0.667347, 0.657938, 0.177683])
436         Coordinates:
437           * lon      (lon) int64 -2 -1 0 1
438 
439         The function also accepts dictionary arguments:
440 
441         >>> da.assign_coords({"lon": (((da.lon + 180) % 360) - 180)})
442         <xarray.DataArray (lon: 4)>
443         array([0.28298 , 0.667347, 0.657938, 0.177683])
444         Coordinates:
445           * lon      (lon) int64 -2 -1 0 1
446 
447         New coordinate can also be attached to an existing dimension:
448 
449         >>> lon_2 = np.array([300, 289, 0, 1])
450         >>> da.assign_coords(lon_2=("lon", lon_2))
451         <xarray.DataArray (lon: 4)>
452         array([0.28298 , 0.667347, 0.657938, 0.177683])
453         Coordinates:
454           * lon      (lon) int64 358 359 0 1
455             lon_2    (lon) int64 300 289 0 1
456 
457         Note that the same result can also be obtained with a dict e.g.
458 
459         >>> _ = da.assign_coords({"lon_2": ("lon", lon_2)})
460 
461         Notes
462         -----
463         Since ``coords_kwargs`` is a dictionary, the order of your arguments
464         may not be preserved, and so the order of the new variables is not well
465         defined. Assigning multiple variables within the same ``assign_coords``
466         is possible, but you cannot reference other variables created within
467         the same ``assign_coords`` call.
468 
469         See also
470         --------
471         Dataset.assign
472         Dataset.swap_dims
473         """
474         coords_kwargs = either_dict_or_kwargs(coords, coords_kwargs, "assign_coords")
475         data = self.copy(deep=False)
476         results = self._calc_assign_results(coords_kwargs)
477         data.coords.update(results)
478         return data
479 
480     def assign_attrs(self, *args, **kwargs):
481         """Assign new attrs to this object.
482 
483         Returns a new object equivalent to ``self.attrs.update(*args, **kwargs)``.
484 
485         Parameters
486         ----------
487         args : positional arguments passed into ``attrs.update``.
488         kwargs : keyword arguments passed into ``attrs.update``.
489 
490         Returns
491         -------
492         assigned : same type as caller
493             A new object with the new attrs in addition to the existing data.
494 
495         See also
496         --------
497         Dataset.assign
498         """
499         out = self.copy(deep=False)
500         out.attrs.update(*args, **kwargs)
501         return out
502 
503     def pipe(
504         self,
505         func: Union[Callable[..., T], Tuple[Callable[..., T], str]],
506         *args,
507         **kwargs,
508     ) -> T:
509         """
510         Apply ``func(self, *args, **kwargs)``
511 
512         This method replicates the pandas method of the same name.
513 
514         Parameters
515         ----------
516         func : function
517             function to apply to this xarray object (Dataset/DataArray).
518             ``args``, and ``kwargs`` are passed into ``func``.
519             Alternatively a ``(callable, data_keyword)`` tuple where
520             ``data_keyword`` is a string indicating the keyword of
521             ``callable`` that expects the xarray object.
522         args : positional arguments passed into ``func``.
523         kwargs : a dictionary of keyword arguments passed into ``func``.
524 
525         Returns
526         -------
527         object : the return type of ``func``.
528 
529         Notes
530         -----
531 
532         Use ``.pipe`` when chaining together functions that expect
533         xarray or pandas objects, e.g., instead of writing
534 
535         >>> f(g(h(ds), arg1=a), arg2=b, arg3=c)
536 
537         You can write
538 
539         >>> (ds.pipe(h).pipe(g, arg1=a).pipe(f, arg2=b, arg3=c))
540 
541         If you have a function that takes the data as (say) the second
542         argument, pass a tuple indicating which keyword expects the
543         data. For example, suppose ``f`` takes its data as ``arg2``:
544 
545         >>> (ds.pipe(h).pipe(g, arg1=a).pipe((f, "arg2"), arg1=a, arg3=c))
546 
547         Examples
548         --------
549 
550         >>> import numpy as np
551         >>> import xarray as xr
552         >>> x = xr.Dataset(
553         ...     {
554         ...         "temperature_c": (
555         ...             ("lat", "lon"),
556         ...             20 * np.random.rand(4).reshape(2, 2),
557         ...         ),
558         ...         "precipitation": (("lat", "lon"), np.random.rand(4).reshape(2, 2)),
559         ...     },
560         ...     coords={"lat": [10, 20], "lon": [150, 160]},
561         ... )
562         >>> x
563         <xarray.Dataset>
564         Dimensions:        (lat: 2, lon: 2)
565         Coordinates:
566         * lat            (lat) int64 10 20
567         * lon            (lon) int64 150 160
568         Data variables:
569             temperature_c  (lat, lon) float64 14.53 11.85 19.27 16.37
570             precipitation  (lat, lon) float64 0.7315 0.7189 0.8481 0.4671
571 
572         >>> def adder(data, arg):
573         ...     return data + arg
574         ...
575         >>> def div(data, arg):
576         ...     return data / arg
577         ...
578         >>> def sub_mult(data, sub_arg, mult_arg):
579         ...     return (data * mult_arg) - sub_arg
580         ...
581         >>> x.pipe(adder, 2)
582         <xarray.Dataset>
583         Dimensions:        (lat: 2, lon: 2)
584         Coordinates:
585         * lon            (lon) int64 150 160
586         * lat            (lat) int64 10 20
587         Data variables:
588             temperature_c  (lat, lon) float64 16.53 13.85 21.27 18.37
589             precipitation  (lat, lon) float64 2.731 2.719 2.848 2.467
590 
591         >>> x.pipe(adder, arg=2)
592         <xarray.Dataset>
593         Dimensions:        (lat: 2, lon: 2)
594         Coordinates:
595         * lon            (lon) int64 150 160
596         * lat            (lat) int64 10 20
597         Data variables:
598             temperature_c  (lat, lon) float64 16.53 13.85 21.27 18.37
599             precipitation  (lat, lon) float64 2.731 2.719 2.848 2.467
600 
601         >>> (
602         ...     x.pipe(adder, arg=2)
603         ...     .pipe(div, arg=2)
604         ...     .pipe(sub_mult, sub_arg=2, mult_arg=2)
605         ... )
606         <xarray.Dataset>
607         Dimensions:        (lat: 2, lon: 2)
608         Coordinates:
609         * lon            (lon) int64 150 160
610         * lat            (lat) int64 10 20
611         Data variables:
612             temperature_c  (lat, lon) float64 14.53 11.85 19.27 16.37
613             precipitation  (lat, lon) float64 0.7315 0.7189 0.8481 0.4671
614 
615         See Also
616         --------
617         pandas.DataFrame.pipe
618         """
619         if isinstance(func, tuple):
620             func, target = func
621             if target in kwargs:
622                 raise ValueError(
623                     "%s is both the pipe target and a keyword " "argument" % target
624                 )
625             kwargs[target] = self
626             return func(*args, **kwargs)
627         else:
628             return func(self, *args, **kwargs)
629 
630     def groupby(self, group, squeeze: bool = True, restore_coord_dims: bool = None):
631         """Returns a GroupBy object for performing grouped operations.
632 
633         Parameters
634         ----------
635         group : str, DataArray or IndexVariable
636             Array whose unique values should be used to group this array. If a
637             string, must be the name of a variable contained in this dataset.
638         squeeze : boolean, optional
639             If "group" is a dimension of any arrays in this dataset, `squeeze`
640             controls whether the subarrays have a dimension of length 1 along
641             that dimension or if the dimension is squeezed out.
642         restore_coord_dims : bool, optional
643             If True, also restore the dimension order of multi-dimensional
644             coordinates.
645 
646         Returns
647         -------
648         grouped : GroupBy
649             A `GroupBy` object patterned after `pandas.GroupBy` that can be
650             iterated over in the form of `(unique_value, grouped_array)` pairs.
651 
652         Examples
653         --------
654         Calculate daily anomalies for daily data:
655 
656         >>> da = xr.DataArray(
657         ...     np.linspace(0, 1826, num=1827),
658         ...     coords=[pd.date_range("1/1/2000", "31/12/2004", freq="D")],
659         ...     dims="time",
660         ... )
661         >>> da
662         <xarray.DataArray (time: 1827)>
663         array([0.000e+00, 1.000e+00, 2.000e+00, ..., 1.824e+03, 1.825e+03, 1.826e+03])
664         Coordinates:
665           * time     (time) datetime64[ns] 2000-01-01 2000-01-02 2000-01-03 ...
666         >>> da.groupby("time.dayofyear") - da.groupby("time.dayofyear").mean("time")
667         <xarray.DataArray (time: 1827)>
668         array([-730.8, -730.8, -730.8, ...,  730.2,  730.2,  730.5])
669         Coordinates:
670           * time       (time) datetime64[ns] 2000-01-01 2000-01-02 2000-01-03 ...
671             dayofyear  (time) int64 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...
672 
673         See Also
674         --------
675         core.groupby.DataArrayGroupBy
676         core.groupby.DatasetGroupBy
677         """
678         # While we don't generally check the type of every arg, passing
679         # multiple dimensions as multiple arguments is common enough, and the
680         # consequences hidden enough (strings evaluate as true) to warrant
681         # checking here.
682         # A future version could make squeeze kwarg only, but would face
683         # backward-compat issues.
684         if not isinstance(squeeze, bool):
685             raise TypeError(
686                 f"`squeeze` must be True or False, but {squeeze} was supplied"
687             )
688 
689         return self._groupby_cls(
690             self, group, squeeze=squeeze, restore_coord_dims=restore_coord_dims
691         )
692 
693     def groupby_bins(
694         self,
695         group,
696         bins,
697         right: bool = True,
698         labels=None,
699         precision: int = 3,
700         include_lowest: bool = False,
701         squeeze: bool = True,
702         restore_coord_dims: bool = None,
703     ):
704         """Returns a GroupBy object for performing grouped operations.
705 
706         Rather than using all unique values of `group`, the values are discretized
707         first by applying `pandas.cut` [1]_ to `group`.
708 
709         Parameters
710         ----------
711         group : str, DataArray or IndexVariable
712             Array whose binned values should be used to group this array. If a
713             string, must be the name of a variable contained in this dataset.
714         bins : int or array of scalars
715             If bins is an int, it defines the number of equal-width bins in the
716             range of x. However, in this case, the range of x is extended by .1%
717             on each side to include the min or max values of x. If bins is a
718             sequence it defines the bin edges allowing for non-uniform bin
719             width. No extension of the range of x is done in this case.
720         right : boolean, optional
721             Indicates whether the bins include the rightmost edge or not. If
722             right == True (the default), then the bins [1,2,3,4] indicate
723             (1,2], (2,3], (3,4].
724         labels : array or boolean, default None
725             Used as labels for the resulting bins. Must be of the same length as
726             the resulting bins. If False, string bin labels are assigned by
727             `pandas.cut`.
728         precision : int
729             The precision at which to store and display the bins labels.
730         include_lowest : bool
731             Whether the first interval should be left-inclusive or not.
732         squeeze : boolean, optional
733             If "group" is a dimension of any arrays in this dataset, `squeeze`
734             controls whether the subarrays have a dimension of length 1 along
735             that dimension or if the dimension is squeezed out.
736         restore_coord_dims : bool, optional
737             If True, also restore the dimension order of multi-dimensional
738             coordinates.
739 
740         Returns
741         -------
742         grouped : GroupBy
743             A `GroupBy` object patterned after `pandas.GroupBy` that can be
744             iterated over in the form of `(unique_value, grouped_array)` pairs.
745             The name of the group has the added suffix `_bins` in order to
746             distinguish it from the original variable.
747 
748         References
749         ----------
750         .. [1] http://pandas.pydata.org/pandas-docs/stable/generated/pandas.cut.html
751         """
752         return self._groupby_cls(
753             self,
754             group,
755             squeeze=squeeze,
756             bins=bins,
757             restore_coord_dims=restore_coord_dims,
758             cut_kwargs={
759                 "right": right,
760                 "labels": labels,
761                 "precision": precision,
762                 "include_lowest": include_lowest,
763             },
764         )
765 
766     def weighted(self, weights):
767         """
768         Weighted operations.
769 
770         Parameters
771         ----------
772         weights : DataArray
773             An array of weights associated with the values in this Dataset.
774             Each value in the data contributes to the reduction operation
775             according to its associated weight.
776 
777         Notes
778         -----
779         ``weights`` must be a DataArray and cannot contain missing values.
780         Missing values can be replaced by ``weights.fillna(0)``.
781         """
782 
783         return self._weighted_cls(self, weights)
784 
785     def rolling(
786         self,
787         dim: Mapping[Hashable, int] = None,
788         min_periods: int = None,
789         center: bool = False,
790         keep_attrs: bool = None,
791         **window_kwargs: int,
792     ):
793         """
794         Rolling window object.
795 
796         Parameters
797         ----------
798         dim: dict, optional
799             Mapping from the dimension name to create the rolling iterator
800             along (e.g. `time`) to its moving window size.
801         min_periods : int, default None
802             Minimum number of observations in window required to have a value
803             (otherwise result is NA). The default, None, is equivalent to
804             setting min_periods equal to the size of the window.
805         center : boolean, default False
806             Set the labels at the center of the window.
807         keep_attrs : bool, optional
808             If True, the object's attributes (`attrs`) will be copied from
809             the original object to the new one.  If False (default), the new
810             object will be returned without attributes.
811         **window_kwargs : optional
812             The keyword arguments form of ``dim``.
813             One of dim or window_kwargs must be provided.
814 
815         Returns
816         -------
817         Rolling object (core.rolling.DataArrayRolling for DataArray,
818         core.rolling.DatasetRolling for Dataset.)
819 
820         Examples
821         --------
822         Create rolling seasonal average of monthly data e.g. DJF, JFM, ..., SON:
823 
824         >>> da = xr.DataArray(
825         ...     np.linspace(0, 11, num=12),
826         ...     coords=[
827         ...         pd.date_range(
828         ...             "15/12/1999", periods=12, freq=pd.DateOffset(months=1),
829         ...         )
830         ...     ],
831         ...     dims="time",
832         ... )
833         >>> da
834         <xarray.DataArray (time: 12)>
835         array([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7., 8.,   9.,  10.,  11.])
836         Coordinates:
837           * time     (time) datetime64[ns] 1999-12-15 2000-01-15 2000-02-15 ...
838         >>> da.rolling(time=3, center=True).mean()
839         <xarray.DataArray (time: 12)>
840         array([nan,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., nan])
841         Coordinates:
842           * time     (time) datetime64[ns] 1999-12-15 2000-01-15 2000-02-15 ...
843 
844         Remove the NaNs using ``dropna()``:
845 
846         >>> da.rolling(time=3, center=True).mean().dropna("time")
847         <xarray.DataArray (time: 10)>
848         array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])
849         Coordinates:
850           * time     (time) datetime64[ns] 2000-01-15 2000-02-15 2000-03-15 ...
851 
852         See Also
853         --------
854         core.rolling.DataArrayRolling
855         core.rolling.DatasetRolling
856         """
857         if keep_attrs is None:
858             keep_attrs = _get_keep_attrs(default=False)
859 
860         dim = either_dict_or_kwargs(dim, window_kwargs, "rolling")
861         return self._rolling_cls(
862             self, dim, min_periods=min_periods, center=center, keep_attrs=keep_attrs
863         )
864 
865     def rolling_exp(
866         self,
867         window: Mapping[Hashable, int] = None,
868         window_type: str = "span",
869         **window_kwargs,
870     ):
871         """
872         Exponentially-weighted moving window.
873         Similar to EWM in pandas
874 
875         Requires the optional Numbagg dependency.
876 
877         Parameters
878         ----------
879         window : A single mapping from a dimension name to window value,
880                  optional
881 
882             dim : str
883                 Name of the dimension to create the rolling exponential window
884                 along (e.g., `time`).
885             window : int
886                 Size of the moving window. The type of this is specified in
887                 `window_type`
888         window_type : str, one of ['span', 'com', 'halflife', 'alpha'],
889                       default 'span'
890             The format of the previously supplied window. Each is a simple
891             numerical transformation of the others. Described in detail:
892             https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.ewm.html
893         **window_kwargs : optional
894             The keyword arguments form of ``window``.
895             One of window or window_kwargs must be provided.
896 
897         See Also
898         --------
899         core.rolling_exp.RollingExp
900         """
901         window = either_dict_or_kwargs(window, window_kwargs, "rolling_exp")
902 
903         return self._rolling_exp_cls(self, window, window_type)
904 
905     def coarsen(
906         self,
907         dim: Mapping[Hashable, int] = None,
908         boundary: str = "exact",
909         side: Union[str, Mapping[Hashable, str]] = "left",
910         coord_func: str = "mean",
911         keep_attrs: bool = None,
912         **window_kwargs: int,
913     ):
914         """
915         Coarsen object.
916 
917         Parameters
918         ----------
919         dim: dict, optional
920             Mapping from the dimension name to the window size.
921 
922             dim : str
923                 Name of the dimension to create the rolling iterator
924                 along (e.g., `time`).
925             window : int
926                 Size of the moving window.
927         boundary : 'exact' | 'trim' | 'pad'
928             If 'exact', a ValueError will be raised if dimension size is not a
929             multiple of the window size. If 'trim', the excess entries are
930             dropped. If 'pad', NA will be padded.
931         side : 'left' or 'right' or mapping from dimension to 'left' or 'right'
932         coord_func : function (name) that is applied to the coordinates,
933             or a mapping from coordinate name to function (name).
934         keep_attrs : bool, optional
935             If True, the object's attributes (`attrs`) will be copied from
936             the original object to the new one.  If False (default), the new
937             object will be returned without attributes.
938 
939         Returns
940         -------
941         Coarsen object (core.rolling.DataArrayCoarsen for DataArray,
942         core.rolling.DatasetCoarsen for Dataset.)
943 
944         Examples
945         --------
946         Coarsen the long time series by averaging over every four days.
947 
948         >>> da = xr.DataArray(
949         ...     np.linspace(0, 364, num=364),
950         ...     dims="time",
951         ...     coords={"time": pd.date_range("15/12/1999", periods=364)},
952         ... )
953         >>> da
954         <xarray.DataArray (time: 364)>
955         array([  0.      ,   1.002755,   2.00551 , ..., 361.99449 , 362.997245,
956                364.      ])
957         Coordinates:
958           * time     (time) datetime64[ns] 1999-12-15 1999-12-16 ... 2000-12-12
959         >>>
960         >>> da.coarsen(time=3, boundary="trim").mean()
961         <xarray.DataArray (time: 121)>
962         array([  1.002755,   4.011019,   7.019284,  ...,  358.986226,
963                361.99449 ])
964         Coordinates:
965           * time     (time) datetime64[ns] 1999-12-16 1999-12-19 ... 2000-12-10
966         >>>
967 
968         See Also
969         --------
970         core.rolling.DataArrayCoarsen
971         core.rolling.DatasetCoarsen
972         """
973         if keep_attrs is None:
974             keep_attrs = _get_keep_attrs(default=False)
975 
976         dim = either_dict_or_kwargs(dim, window_kwargs, "coarsen")
977         return self._coarsen_cls(
978             self,
979             dim,
980             boundary=boundary,
981             side=side,
982             coord_func=coord_func,
983             keep_attrs=keep_attrs,
984         )
985 
986     def resample(
987         self,
988         indexer: Mapping[Hashable, str] = None,
989         skipna=None,
990         closed: str = None,
991         label: str = None,
992         base: int = 0,
993         keep_attrs: bool = None,
994         loffset=None,
995         restore_coord_dims: bool = None,
996         **indexer_kwargs: str,
997     ):
998         """Returns a Resample object for performing resampling operations.
999 
1000         Handles both downsampling and upsampling. The resampled
1001         dimension must be a datetime-like coordinate. If any intervals
1002         contain no values from the original object, they will be given
1003         the value ``NaN``.
1004 
1005         Parameters
1006         ----------
1007         indexer : {dim: freq}, optional
1008             Mapping from the dimension name to resample frequency [1]_. The
1009             dimension must be datetime-like.
1010         skipna : bool, optional
1011             Whether to skip missing values when aggregating in downsampling.
1012         closed : 'left' or 'right', optional
1013             Side of each interval to treat as closed.
1014         label : 'left or 'right', optional
1015             Side of each interval to use for labeling.
1016         base : int, optional
1017             For frequencies that evenly subdivide 1 day, the "origin" of the
1018             aggregated intervals. For example, for '24H' frequency, base could
1019             range from 0 through 23.
1020         loffset : timedelta or str, optional
1021             Offset used to adjust the resampled time labels. Some pandas date
1022             offset strings are supported.
1023         keep_attrs : bool, optional
1024             If True, the object's attributes (`attrs`) will be copied from
1025             the original object to the new one.  If False (default), the new
1026             object will be returned without attributes.
1027         restore_coord_dims : bool, optional
1028             If True, also restore the dimension order of multi-dimensional
1029             coordinates.
1030         **indexer_kwargs : {dim: freq}
1031             The keyword arguments form of ``indexer``.
1032             One of indexer or indexer_kwargs must be provided.
1033 
1034         Returns
1035         -------
1036         resampled : same type as caller
1037             This object resampled.
1038 
1039         Examples
1040         --------
1041         Downsample monthly time-series data to seasonal data:
1042 
1043         >>> da = xr.DataArray(
1044         ...     np.linspace(0, 11, num=12),
1045         ...     coords=[
1046         ...         pd.date_range(
1047         ...             "15/12/1999", periods=12, freq=pd.DateOffset(months=1),
1048         ...         )
1049         ...     ],
1050         ...     dims="time",
1051         ... )
1052         >>> da
1053         <xarray.DataArray (time: 12)>
1054         array([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7., 8.,   9.,  10.,  11.])
1055         Coordinates:
1056           * time     (time) datetime64[ns] 1999-12-15 2000-01-15 2000-02-15 ...
1057         >>> da.resample(time="QS-DEC").mean()
1058         <xarray.DataArray (time: 4)>
1059         array([ 1.,  4.,  7., 10.])
1060         Coordinates:
1061           * time     (time) datetime64[ns] 1999-12-01 2000-03-01 2000-06-01 2000-09-01
1062 
1063         Upsample monthly time-series data to daily data:
1064 
1065         >>> da.resample(time="1D").interpolate("linear")
1066         <xarray.DataArray (time: 337)>
1067         array([ 0.      ,  0.032258,  0.064516, ..., 10.935484, 10.967742, 11.      ])
1068         Coordinates:
1069           * time     (time) datetime64[ns] 1999-12-15 1999-12-16 1999-12-17 ...
1070 
1071         Limit scope of upsampling method
1072 
1073         >>> da.resample(time="1D").nearest(tolerance="1D")
1074         <xarray.DataArray (time: 337)>
1075         array([ 0.,  0., nan, ..., nan, 11., 11.])
1076         Coordinates:
1077           * time     (time) datetime64[ns] 1999-12-15 1999-12-16 ... 2000-11-15
1078 
1079         See Also
1080         --------
1081         pandas.Series.resample
1082         pandas.DataFrame.resample
1083 
1084         References
1085         ----------
1086 
1087         .. [1] http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases
1088         """
1089         # TODO support non-string indexer after removing the old API.
1090 
1091         from .dataarray import DataArray
1092         from .resample import RESAMPLE_DIM
1093         from ..coding.cftimeindex import CFTimeIndex
1094 
1095         if keep_attrs is None:
1096             keep_attrs = _get_keep_attrs(default=False)
1097 
1098         # note: the second argument (now 'skipna') use to be 'dim'
1099         if (
1100             (skipna is not None and not isinstance(skipna, bool))
1101             or ("how" in indexer_kwargs and "how" not in self.dims)
1102             or ("dim" in indexer_kwargs and "dim" not in self.dims)
1103         ):
1104             raise TypeError(
1105                 "resample() no longer supports the `how` or "
1106                 "`dim` arguments. Instead call methods on resample "
1107                 "objects, e.g., data.resample(time='1D').mean()"
1108             )
1109 
1110         indexer = either_dict_or_kwargs(indexer, indexer_kwargs, "resample")
1111         if len(indexer) != 1:
1112             raise ValueError("Resampling only supported along single dimensions.")
1113         dim, freq = next(iter(indexer.items()))
1114 
1115         dim_name = dim
1116         dim_coord = self[dim]
1117 
1118         if isinstance(self.indexes[dim_name], CFTimeIndex):
1119             from .resample_cftime import CFTimeGrouper
1120 
1121             grouper = CFTimeGrouper(freq, closed, label, base, loffset)
1122         else:
1123             grouper = pd.Grouper(
1124                 freq=freq, closed=closed, label=label, base=base, loffset=loffset
1125             )
1126         group = DataArray(
1127             dim_coord, coords=dim_coord.coords, dims=dim_coord.dims, name=RESAMPLE_DIM
1128         )
1129         resampler = self._resample_cls(
1130             self,
1131             group=group,
1132             dim=dim_name,
1133             grouper=grouper,
1134             resample_dim=RESAMPLE_DIM,
1135             restore_coord_dims=restore_coord_dims,
1136         )
1137 
1138         return resampler
1139 
1140     def where(self, cond, other=dtypes.NA, drop: bool = False):
1141         """Filter elements from this object according to a condition.
1142 
1143         This operation follows the normal broadcasting and alignment rules that
1144         xarray uses for binary arithmetic.
1145 
1146         Parameters
1147         ----------
1148         cond : DataArray or Dataset with boolean dtype
1149             Locations at which to preserve this object's values.
1150         other : scalar, DataArray or Dataset, optional
1151             Value to use for locations in this object where ``cond`` is False.
1152             By default, these locations filled with NA.
1153         drop : boolean, optional
1154             If True, coordinate labels that only correspond to False values of
1155             the condition are dropped from the result. Mutually exclusive with
1156             ``other``.
1157 
1158         Returns
1159         -------
1160         Same xarray type as caller, with dtype float64.
1161 
1162         Examples
1163         --------
1164 
1165         >>> import numpy as np
1166         >>> a = xr.DataArray(np.arange(25).reshape(5, 5), dims=("x", "y"))
1167         >>> a
1168         <xarray.DataArray (x: 5, y: 5)>
1169         array([[ 0,  1,  2,  3,  4],
1170             [ 5,  6,  7,  8,  9],
1171             [10, 11, 12, 13, 14],
1172             [15, 16, 17, 18, 19],
1173             [20, 21, 22, 23, 24]])
1174         Dimensions without coordinates: x, y
1175 
1176         >>> a.where(a.x + a.y < 4)
1177         <xarray.DataArray (x: 5, y: 5)>
1178         array([[  0.,   1.,   2.,   3.,  nan],
1179                [  5.,   6.,   7.,  nan,  nan],
1180                [ 10.,  11.,  nan,  nan,  nan],
1181                [ 15.,  nan,  nan,  nan,  nan],
1182                [ nan,  nan,  nan,  nan,  nan]])
1183         Dimensions without coordinates: x, y
1184 
1185         >>> a.where(a.x + a.y < 5, -1)
1186         <xarray.DataArray (x: 5, y: 5)>
1187         array([[ 0,  1,  2,  3,  4],
1188                [ 5,  6,  7,  8, -1],
1189                [10, 11, 12, -1, -1],
1190                [15, 16, -1, -1, -1],
1191                [20, -1, -1, -1, -1]])
1192         Dimensions without coordinates: x, y
1193 
1194         >>> a.where(a.x + a.y < 4, drop=True)
1195         <xarray.DataArray (x: 4, y: 4)>
1196         array([[  0.,   1.,   2.,   3.],
1197                [  5.,   6.,   7.,  nan],
1198                [ 10.,  11.,  nan,  nan],
1199                [ 15.,  nan,  nan,  nan]])
1200         Dimensions without coordinates: x, y
1201 
1202         >>> a.where(lambda x: x.x + x.y < 4, drop=True)
1203         <xarray.DataArray (x: 4, y: 4)>
1204         array([[  0.,   1.,   2.,   3.],
1205                [  5.,   6.,   7.,  nan],
1206                [ 10.,  11.,  nan,  nan],
1207                [ 15.,  nan,  nan,  nan]])
1208         Dimensions without coordinates: x, y
1209 
1210         See also
1211         --------
1212         numpy.where : corresponding numpy function
1213         where : equivalent function
1214         """
1215         from .alignment import align
1216         from .dataarray import DataArray
1217         from .dataset import Dataset
1218 
1219         if callable(cond):
1220             cond = cond(self)
1221 
1222         if drop:
1223             if other is not dtypes.NA:
1224                 raise ValueError("cannot set `other` if drop=True")
1225 
1226             if not isinstance(cond, (Dataset, DataArray)):
1227                 raise TypeError(
1228                     "cond argument is %r but must be a %r or %r"
1229                     % (cond, Dataset, DataArray)
1230                 )
1231 
1232             # align so we can use integer indexing
1233             self, cond = align(self, cond)
1234 
1235             # get cond with the minimal size needed for the Dataset
1236             if isinstance(cond, Dataset):
1237                 clipcond = cond.to_array().any("variable")
1238             else:
1239                 clipcond = cond
1240 
1241             # clip the data corresponding to coordinate dims that are not used
1242             nonzeros = zip(clipcond.dims, np.nonzero(clipcond.values))
1243             indexers = {k: np.unique(v) for k, v in nonzeros}
1244 
1245             self = self.isel(**indexers)
1246             cond = cond.isel(**indexers)
1247 
1248         return ops.where_method(self, cond, other)
1249 
1250     def close(self: Any) -> None:
1251         """Close any files linked to this object
1252         """
1253         if self._file_obj is not None:
1254             self._file_obj.close()
1255         self._file_obj = None
1256 
1257     def isin(self, test_elements):
1258         """Tests each value in the array for whether it is in test elements.
1259 
1260         Parameters
1261         ----------
1262         test_elements : array_like
1263             The values against which to test each value of `element`.
1264             This argument is flattened if an array or array_like.
1265             See numpy notes for behavior with non-array-like parameters.
1266 
1267         Returns
1268         -------
1269         isin : same as object, bool
1270             Has the same shape as this object.
1271 
1272         Examples
1273         --------
1274 
1275         >>> array = xr.DataArray([1, 2, 3], dims="x")
1276         >>> array.isin([1, 3])
1277         <xarray.DataArray (x: 3)>
1278         array([ True, False,  True])
1279         Dimensions without coordinates: x
1280 
1281         See also
1282         --------
1283         numpy.isin
1284         """
1285         from .computation import apply_ufunc
1286         from .dataset import Dataset
1287         from .dataarray import DataArray
1288         from .variable import Variable
1289 
1290         if isinstance(test_elements, Dataset):
1291             raise TypeError(
1292                 "isin() argument must be convertible to an array: {}".format(
1293                     test_elements
1294                 )
1295             )
1296         elif isinstance(test_elements, (Variable, DataArray)):
1297             # need to explicitly pull out data to support dask arrays as the
1298             # second argument
1299             test_elements = test_elements.data
1300 
1301         return apply_ufunc(
1302             duck_array_ops.isin,
1303             self,
1304             kwargs=dict(test_elements=test_elements),
1305             dask="allowed",
1306         )
1307 
1308     def __enter__(self: T) -> T:
1309         return self
1310 
1311     def __exit__(self, exc_type, exc_value, traceback) -> None:
1312         self.close()
1313 
1314     def __getitem__(self, value):
1315         # implementations of this class should implement this method
1316         raise NotImplementedError()

</code><intended_behavior>This class provides additional context to the issue.</intended_behavior>]
2025-10-15 08:38:34.439 | INFO     | Search completed. Bug locations: [<file>xarray/core/common.py</file>
<class>DataWithCoords</class>
<method>groupby</method>
<code>
630     def groupby(self, group, squeeze: bool = True, restore_coord_dims: bool = None):
631         """Returns a GroupBy object for performing grouped operations.
632 
633         Parameters
634         ----------
635         group : str, DataArray or IndexVariable
636             Array whose unique values should be used to group this array. If a
637             string, must be the name of a variable contained in this dataset.
638         squeeze : boolean, optional
639             If "group" is a dimension of any arrays in this dataset, `squeeze`
640             controls whether the subarrays have a dimension of length 1 along
641             that dimension or if the dimension is squeezed out.
642         restore_coord_dims : bool, optional
643             If True, also restore the dimension order of multi-dimensional
644             coordinates.
645 
646         Returns
647         -------
648         grouped : GroupBy
649             A `GroupBy` object patterned after `pandas.GroupBy` that can be
650             iterated over in the form of `(unique_value, grouped_array)` pairs.
651 
652         Examples
653         --------
654         Calculate daily anomalies for daily data:
655 
656         >>> da = xr.DataArray(
657         ...     np.linspace(0, 1826, num=1827),
658         ...     coords=[pd.date_range("1/1/2000", "31/12/2004", freq="D")],
659         ...     dims="time",
660         ... )
661         >>> da
662         <xarray.DataArray (time: 1827)>
663         array([0.000e+00, 1.000e+00, 2.000e+00, ..., 1.824e+03, 1.825e+03, 1.826e+03])
664         Coordinates:
665           * time     (time) datetime64[ns] 2000-01-01 2000-01-02 2000-01-03 ...
666         >>> da.groupby("time.dayofyear") - da.groupby("time.dayofyear").mean("time")
667         <xarray.DataArray (time: 1827)>
668         array([-730.8, -730.8, -730.8, ...,  730.2,  730.2,  730.5])
669         Coordinates:
670           * time       (time) datetime64[ns] 2000-01-01 2000-01-02 2000-01-03 ...
671             dayofyear  (time) int64 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...
672 
673         See Also
674         --------
675         core.groupby.DataArrayGroupBy
676         core.groupby.DatasetGroupBy
677         """
678         # While we don't generally check the type of every arg, passing
679         # multiple dimensions as multiple arguments is common enough, and the
680         # consequences hidden enough (strings evaluate as true) to warrant
681         # checking here.
682         # A future version could make squeeze kwarg only, but would face
683         # backward-compat issues.
684         if not isinstance(squeeze, bool):
685             raise TypeError(
686                 f"`squeeze` must be True or False, but {squeeze} was supplied"
687             )
688 
689         return self._groupby_cls(
690             self, group, squeeze=squeeze, restore_coord_dims=restore_coord_dims
691         )

</code><intended_behavior>The `groupby` method's intended behavior, in this case, is to explicitly handle cases where the `group` parameter might be `None`. This improvement could take two forms:
- If `group=None` is intended to be a valid use case: The method should define a standard behavior for this case, which might involve grouping all the dataset's elements together as a single group, or any other behavior deemed appropriate by the framework's logic.
- If `group=None` is not intended to be valid: The method should be updated to check for `None` explicitly and raise a meaningful ValueError or TypeError, indicating that `None` is not a valid value for the `group` parameter. This error message should guide the user towards proper usage of the method.

This adjustment would enhance the method's robustness and user-friendliness by providing clear guidance or functionality in cases where `group=None`, thereby resolving the issue described. This change should also ensure that the method's existing functionality for handling non-`None` `group` values remains unaffected and that the behavior is consistent with the rest of the `xarray` framework's conventions and expectations.</intended_behavior>, <file>xarray/core/common.py</file>
<class>DataWithCoords</class>
<method>None</method>
<code>
336 class DataWithCoords(SupportsArithmetic, AttrAccessMixin):
337     """Shared base class for Dataset and DataArray."""
338 
339     __slots__ = ()
340 
341     _rolling_exp_cls = RollingExp
342 
343     def squeeze(
344         self,
345         dim: Union[Hashable, Iterable[Hashable], None] = None,
346         drop: bool = False,
347         axis: Union[int, Iterable[int], None] = None,
348     ):
349         """Return a new object with squeezed data.
350 
351         Parameters
352         ----------
353         dim : None or Hashable or iterable of Hashable, optional
354             Selects a subset of the length one dimensions. If a dimension is
355             selected with length greater than one, an error is raised. If
356             None, all length one dimensions are squeezed.
357         drop : bool, optional
358             If ``drop=True``, drop squeezed coordinates instead of making them
359             scalar.
360         axis : None or int or iterable of int, optional
361             Like dim, but positional.
362 
363         Returns
364         -------
365         squeezed : same type as caller
366             This object, but with with all or a subset of the dimensions of
367             length 1 removed.
368 
369         See Also
370         --------
371         numpy.squeeze
372         """
373         dims = get_squeeze_dims(self, dim, axis)
374         return self.isel(drop=drop, **{d: 0 for d in dims})
375 
376     def get_index(self, key: Hashable) -> pd.Index:
377         """Get an index for a dimension, with fall-back to a default RangeIndex
378         """
379         if key not in self.dims:
380             raise KeyError(key)
381 
382         try:
383             return self.indexes[key]
384         except KeyError:
385             # need to ensure dtype=int64 in case range is empty on Python 2
386             return pd.Index(range(self.sizes[key]), name=key, dtype=np.int64)
387 
388     def _calc_assign_results(
389         self: C, kwargs: Mapping[Hashable, Union[T, Callable[[C], T]]]
390     ) -> Dict[Hashable, T]:
391         return {k: v(self) if callable(v) else v for k, v in kwargs.items()}
392 
393     def assign_coords(self, coords=None, **coords_kwargs):
394         """Assign new coordinates to this object.
395 
396         Returns a new object with all the original data in addition to the new
397         coordinates.
398 
399         Parameters
400         ----------
401         coords : dict, optional
402             A dict where the keys are the names of the coordinates
403             with the new values to assign. If the values are callable, they are
404             computed on this object and assigned to new coordinate variables.
405             If the values are not callable, (e.g. a ``DataArray``, scalar, or
406             array), they are simply assigned. A new coordinate can also be
407             defined and attached to an existing dimension using a tuple with
408             the first element the dimension name and the second element the
409             values for this new coordinate.
410 
411         **coords_kwargs : keyword, value pairs, optional
412             The keyword arguments form of ``coords``.
413             One of ``coords`` or ``coords_kwargs`` must be provided.
414 
415         Returns
416         -------
417         assigned : same type as caller
418             A new object with the new coordinates in addition to the existing
419             data.
420 
421         Examples
422         --------
423         Convert longitude coordinates from 0-359 to -180-179:
424 
425         >>> da = xr.DataArray(
426         ...     np.random.rand(4), coords=[np.array([358, 359, 0, 1])], dims="lon",
427         ... )
428         >>> da
429         <xarray.DataArray (lon: 4)>
430         array([0.28298 , 0.667347, 0.657938, 0.177683])
431         Coordinates:
432           * lon      (lon) int64 358 359 0 1
433         >>> da.assign_coords(lon=(((da.lon + 180) % 360) - 180))
434         <xarray.DataArray (lon: 4)>
435         array([0.28298 , 0.667347, 0.657938, 0.177683])
436         Coordinates:
437           * lon      (lon) int64 -2 -1 0 1
438 
439         The function also accepts dictionary arguments:
440 
441         >>> da.assign_coords({"lon": (((da.lon + 180) % 360) - 180)})
442         <xarray.DataArray (lon: 4)>
443         array([0.28298 , 0.667347, 0.657938, 0.177683])
444         Coordinates:
445           * lon      (lon) int64 -2 -1 0 1
446 
447         New coordinate can also be attached to an existing dimension:
448 
449         >>> lon_2 = np.array([300, 289, 0, 1])
450         >>> da.assign_coords(lon_2=("lon", lon_2))
451         <xarray.DataArray (lon: 4)>
452         array([0.28298 , 0.667347, 0.657938, 0.177683])
453         Coordinates:
454           * lon      (lon) int64 358 359 0 1
455             lon_2    (lon) int64 300 289 0 1
456 
457         Note that the same result can also be obtained with a dict e.g.
458 
459         >>> _ = da.assign_coords({"lon_2": ("lon", lon_2)})
460 
461         Notes
462         -----
463         Since ``coords_kwargs`` is a dictionary, the order of your arguments
464         may not be preserved, and so the order of the new variables is not well
465         defined. Assigning multiple variables within the same ``assign_coords``
466         is possible, but you cannot reference other variables created within
467         the same ``assign_coords`` call.
468 
469         See also
470         --------
471         Dataset.assign
472         Dataset.swap_dims
473         """
474         coords_kwargs = either_dict_or_kwargs(coords, coords_kwargs, "assign_coords")
475         data = self.copy(deep=False)
476         results = self._calc_assign_results(coords_kwargs)
477         data.coords.update(results)
478         return data
479 
480     def assign_attrs(self, *args, **kwargs):
481         """Assign new attrs to this object.
482 
483         Returns a new object equivalent to ``self.attrs.update(*args, **kwargs)``.
484 
485         Parameters
486         ----------
487         args : positional arguments passed into ``attrs.update``.
488         kwargs : keyword arguments passed into ``attrs.update``.
489 
490         Returns
491         -------
492         assigned : same type as caller
493             A new object with the new attrs in addition to the existing data.
494 
495         See also
496         --------
497         Dataset.assign
498         """
499         out = self.copy(deep=False)
500         out.attrs.update(*args, **kwargs)
501         return out
502 
503     def pipe(
504         self,
505         func: Union[Callable[..., T], Tuple[Callable[..., T], str]],
506         *args,
507         **kwargs,
508     ) -> T:
509         """
510         Apply ``func(self, *args, **kwargs)``
511 
512         This method replicates the pandas method of the same name.
513 
514         Parameters
515         ----------
516         func : function
517             function to apply to this xarray object (Dataset/DataArray).
518             ``args``, and ``kwargs`` are passed into ``func``.
519             Alternatively a ``(callable, data_keyword)`` tuple where
520             ``data_keyword`` is a string indicating the keyword of
521             ``callable`` that expects the xarray object.
522         args : positional arguments passed into ``func``.
523         kwargs : a dictionary of keyword arguments passed into ``func``.
524 
525         Returns
526         -------
527         object : the return type of ``func``.
528 
529         Notes
530         -----
531 
532         Use ``.pipe`` when chaining together functions that expect
533         xarray or pandas objects, e.g., instead of writing
534 
535         >>> f(g(h(ds), arg1=a), arg2=b, arg3=c)
536 
537         You can write
538 
539         >>> (ds.pipe(h).pipe(g, arg1=a).pipe(f, arg2=b, arg3=c))
540 
541         If you have a function that takes the data as (say) the second
542         argument, pass a tuple indicating which keyword expects the
543         data. For example, suppose ``f`` takes its data as ``arg2``:
544 
545         >>> (ds.pipe(h).pipe(g, arg1=a).pipe((f, "arg2"), arg1=a, arg3=c))
546 
547         Examples
548         --------
549 
550         >>> import numpy as np
551         >>> import xarray as xr
552         >>> x = xr.Dataset(
553         ...     {
554         ...         "temperature_c": (
555         ...             ("lat", "lon"),
556         ...             20 * np.random.rand(4).reshape(2, 2),
557         ...         ),
558         ...         "precipitation": (("lat", "lon"), np.random.rand(4).reshape(2, 2)),
559         ...     },
560         ...     coords={"lat": [10, 20], "lon": [150, 160]},
561         ... )
562         >>> x
563         <xarray.Dataset>
564         Dimensions:        (lat: 2, lon: 2)
565         Coordinates:
566         * lat            (lat) int64 10 20
567         * lon            (lon) int64 150 160
568         Data variables:
569             temperature_c  (lat, lon) float64 14.53 11.85 19.27 16.37
570             precipitation  (lat, lon) float64 0.7315 0.7189 0.8481 0.4671
571 
572         >>> def adder(data, arg):
573         ...     return data + arg
574         ...
575         >>> def div(data, arg):
576         ...     return data / arg
577         ...
578         >>> def sub_mult(data, sub_arg, mult_arg):
579         ...     return (data * mult_arg) - sub_arg
580         ...
581         >>> x.pipe(adder, 2)
582         <xarray.Dataset>
583         Dimensions:        (lat: 2, lon: 2)
584         Coordinates:
585         * lon            (lon) int64 150 160
586         * lat            (lat) int64 10 20
587         Data variables:
588             temperature_c  (lat, lon) float64 16.53 13.85 21.27 18.37
589             precipitation  (lat, lon) float64 2.731 2.719 2.848 2.467
590 
591         >>> x.pipe(adder, arg=2)
592         <xarray.Dataset>
593         Dimensions:        (lat: 2, lon: 2)
594         Coordinates:
595         * lon            (lon) int64 150 160
596         * lat            (lat) int64 10 20
597         Data variables:
598             temperature_c  (lat, lon) float64 16.53 13.85 21.27 18.37
599             precipitation  (lat, lon) float64 2.731 2.719 2.848 2.467
600 
601         >>> (
602         ...     x.pipe(adder, arg=2)
603         ...     .pipe(div, arg=2)
604         ...     .pipe(sub_mult, sub_arg=2, mult_arg=2)
605         ... )
606         <xarray.Dataset>
607         Dimensions:        (lat: 2, lon: 2)
608         Coordinates:
609         * lon            (lon) int64 150 160
610         * lat            (lat) int64 10 20
611         Data variables:
612             temperature_c  (lat, lon) float64 14.53 11.85 19.27 16.37
613             precipitation  (lat, lon) float64 0.7315 0.7189 0.8481 0.4671
614 
615         See Also
616         --------
617         pandas.DataFrame.pipe
618         """
619         if isinstance(func, tuple):
620             func, target = func
621             if target in kwargs:
622                 raise ValueError(
623                     "%s is both the pipe target and a keyword " "argument" % target
624                 )
625             kwargs[target] = self
626             return func(*args, **kwargs)
627         else:
628             return func(self, *args, **kwargs)
629 
630     def groupby(self, group, squeeze: bool = True, restore_coord_dims: bool = None):
631         """Returns a GroupBy object for performing grouped operations.
632 
633         Parameters
634         ----------
635         group : str, DataArray or IndexVariable
636             Array whose unique values should be used to group this array. If a
637             string, must be the name of a variable contained in this dataset.
638         squeeze : boolean, optional
639             If "group" is a dimension of any arrays in this dataset, `squeeze`
640             controls whether the subarrays have a dimension of length 1 along
641             that dimension or if the dimension is squeezed out.
642         restore_coord_dims : bool, optional
643             If True, also restore the dimension order of multi-dimensional
644             coordinates.
645 
646         Returns
647         -------
648         grouped : GroupBy
649             A `GroupBy` object patterned after `pandas.GroupBy` that can be
650             iterated over in the form of `(unique_value, grouped_array)` pairs.
651 
652         Examples
653         --------
654         Calculate daily anomalies for daily data:
655 
656         >>> da = xr.DataArray(
657         ...     np.linspace(0, 1826, num=1827),
658         ...     coords=[pd.date_range("1/1/2000", "31/12/2004", freq="D")],
659         ...     dims="time",
660         ... )
661         >>> da
662         <xarray.DataArray (time: 1827)>
663         array([0.000e+00, 1.000e+00, 2.000e+00, ..., 1.824e+03, 1.825e+03, 1.826e+03])
664         Coordinates:
665           * time     (time) datetime64[ns] 2000-01-01 2000-01-02 2000-01-03 ...
666         >>> da.groupby("time.dayofyear") - da.groupby("time.dayofyear").mean("time")
667         <xarray.DataArray (time: 1827)>
668         array([-730.8, -730.8, -730.8, ...,  730.2,  730.2,  730.5])
669         Coordinates:
670           * time       (time) datetime64[ns] 2000-01-01 2000-01-02 2000-01-03 ...
671             dayofyear  (time) int64 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 ...
672 
673         See Also
674         --------
675         core.groupby.DataArrayGroupBy
676         core.groupby.DatasetGroupBy
677         """
678         # While we don't generally check the type of every arg, passing
679         # multiple dimensions as multiple arguments is common enough, and the
680         # consequences hidden enough (strings evaluate as true) to warrant
681         # checking here.
682         # A future version could make squeeze kwarg only, but would face
683         # backward-compat issues.
684         if not isinstance(squeeze, bool):
685             raise TypeError(
686                 f"`squeeze` must be True or False, but {squeeze} was supplied"
687             )
688 
689         return self._groupby_cls(
690             self, group, squeeze=squeeze, restore_coord_dims=restore_coord_dims
691         )
692 
693     def groupby_bins(
694         self,
695         group,
696         bins,
697         right: bool = True,
698         labels=None,
699         precision: int = 3,
700         include_lowest: bool = False,
701         squeeze: bool = True,
702         restore_coord_dims: bool = None,
703     ):
704         """Returns a GroupBy object for performing grouped operations.
705 
706         Rather than using all unique values of `group`, the values are discretized
707         first by applying `pandas.cut` [1]_ to `group`.
708 
709         Parameters
710         ----------
711         group : str, DataArray or IndexVariable
712             Array whose binned values should be used to group this array. If a
713             string, must be the name of a variable contained in this dataset.
714         bins : int or array of scalars
715             If bins is an int, it defines the number of equal-width bins in the
716             range of x. However, in this case, the range of x is extended by .1%
717             on each side to include the min or max values of x. If bins is a
718             sequence it defines the bin edges allowing for non-uniform bin
719             width. No extension of the range of x is done in this case.
720         right : boolean, optional
721             Indicates whether the bins include the rightmost edge or not. If
722             right == True (the default), then the bins [1,2,3,4] indicate
723             (1,2], (2,3], (3,4].
724         labels : array or boolean, default None
725             Used as labels for the resulting bins. Must be of the same length as
726             the resulting bins. If False, string bin labels are assigned by
727             `pandas.cut`.
728         precision : int
729             The precision at which to store and display the bins labels.
730         include_lowest : bool
731             Whether the first interval should be left-inclusive or not.
732         squeeze : boolean, optional
733             If "group" is a dimension of any arrays in this dataset, `squeeze`
734             controls whether the subarrays have a dimension of length 1 along
735             that dimension or if the dimension is squeezed out.
736         restore_coord_dims : bool, optional
737             If True, also restore the dimension order of multi-dimensional
738             coordinates.
739 
740         Returns
741         -------
742         grouped : GroupBy
743             A `GroupBy` object patterned after `pandas.GroupBy` that can be
744             iterated over in the form of `(unique_value, grouped_array)` pairs.
745             The name of the group has the added suffix `_bins` in order to
746             distinguish it from the original variable.
747 
748         References
749         ----------
750         .. [1] http://pandas.pydata.org/pandas-docs/stable/generated/pandas.cut.html
751         """
752         return self._groupby_cls(
753             self,
754             group,
755             squeeze=squeeze,
756             bins=bins,
757             restore_coord_dims=restore_coord_dims,
758             cut_kwargs={
759                 "right": right,
760                 "labels": labels,
761                 "precision": precision,
762                 "include_lowest": include_lowest,
763             },
764         )
765 
766     def weighted(self, weights):
767         """
768         Weighted operations.
769 
770         Parameters
771         ----------
772         weights : DataArray
773             An array of weights associated with the values in this Dataset.
774             Each value in the data contributes to the reduction operation
775             according to its associated weight.
776 
777         Notes
778         -----
779         ``weights`` must be a DataArray and cannot contain missing values.
780         Missing values can be replaced by ``weights.fillna(0)``.
781         """
782 
783         return self._weighted_cls(self, weights)
784 
785     def rolling(
786         self,
787         dim: Mapping[Hashable, int] = None,
788         min_periods: int = None,
789         center: bool = False,
790         keep_attrs: bool = None,
791         **window_kwargs: int,
792     ):
793         """
794         Rolling window object.
795 
796         Parameters
797         ----------
798         dim: dict, optional
799             Mapping from the dimension name to create the rolling iterator
800             along (e.g. `time`) to its moving window size.
801         min_periods : int, default None
802             Minimum number of observations in window required to have a value
803             (otherwise result is NA). The default, None, is equivalent to
804             setting min_periods equal to the size of the window.
805         center : boolean, default False
806             Set the labels at the center of the window.
807         keep_attrs : bool, optional
808             If True, the object's attributes (`attrs`) will be copied from
809             the original object to the new one.  If False (default), the new
810             object will be returned without attributes.
811         **window_kwargs : optional
812             The keyword arguments form of ``dim``.
813             One of dim or window_kwargs must be provided.
814 
815         Returns
816         -------
817         Rolling object (core.rolling.DataArrayRolling for DataArray,
818         core.rolling.DatasetRolling for Dataset.)
819 
820         Examples
821         --------
822         Create rolling seasonal average of monthly data e.g. DJF, JFM, ..., SON:
823 
824         >>> da = xr.DataArray(
825         ...     np.linspace(0, 11, num=12),
826         ...     coords=[
827         ...         pd.date_range(
828         ...             "15/12/1999", periods=12, freq=pd.DateOffset(months=1),
829         ...         )
830         ...     ],
831         ...     dims="time",
832         ... )
833         >>> da
834         <xarray.DataArray (time: 12)>
835         array([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7., 8.,   9.,  10.,  11.])
836         Coordinates:
837           * time     (time) datetime64[ns] 1999-12-15 2000-01-15 2000-02-15 ...
838         >>> da.rolling(time=3, center=True).mean()
839         <xarray.DataArray (time: 12)>
840         array([nan,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., nan])
841         Coordinates:
842           * time     (time) datetime64[ns] 1999-12-15 2000-01-15 2000-02-15 ...
843 
844         Remove the NaNs using ``dropna()``:
845 
846         >>> da.rolling(time=3, center=True).mean().dropna("time")
847         <xarray.DataArray (time: 10)>
848         array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])
849         Coordinates:
850           * time     (time) datetime64[ns] 2000-01-15 2000-02-15 2000-03-15 ...
851 
852         See Also
853         --------
854         core.rolling.DataArrayRolling
855         core.rolling.DatasetRolling
856         """
857         if keep_attrs is None:
858             keep_attrs = _get_keep_attrs(default=False)
859 
860         dim = either_dict_or_kwargs(dim, window_kwargs, "rolling")
861         return self._rolling_cls(
862             self, dim, min_periods=min_periods, center=center, keep_attrs=keep_attrs
863         )
864 
865     def rolling_exp(
866         self,
867         window: Mapping[Hashable, int] = None,
868         window_type: str = "span",
869         **window_kwargs,
870     ):
871         """
872         Exponentially-weighted moving window.
873         Similar to EWM in pandas
874 
875         Requires the optional Numbagg dependency.
876 
877         Parameters
878         ----------
879         window : A single mapping from a dimension name to window value,
880                  optional
881 
882             dim : str
883                 Name of the dimension to create the rolling exponential window
884                 along (e.g., `time`).
885             window : int
886                 Size of the moving window. The type of this is specified in
887                 `window_type`
888         window_type : str, one of ['span', 'com', 'halflife', 'alpha'],
889                       default 'span'
890             The format of the previously supplied window. Each is a simple
891             numerical transformation of the others. Described in detail:
892             https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.ewm.html
893         **window_kwargs : optional
894             The keyword arguments form of ``window``.
895             One of window or window_kwargs must be provided.
896 
897         See Also
898         --------
899         core.rolling_exp.RollingExp
900         """
901         window = either_dict_or_kwargs(window, window_kwargs, "rolling_exp")
902 
903         return self._rolling_exp_cls(self, window, window_type)
904 
905     def coarsen(
906         self,
907         dim: Mapping[Hashable, int] = None,
908         boundary: str = "exact",
909         side: Union[str, Mapping[Hashable, str]] = "left",
910         coord_func: str = "mean",
911         keep_attrs: bool = None,
912         **window_kwargs: int,
913     ):
914         """
915         Coarsen object.
916 
917         Parameters
918         ----------
919         dim: dict, optional
920             Mapping from the dimension name to the window size.
921 
922             dim : str
923                 Name of the dimension to create the rolling iterator
924                 along (e.g., `time`).
925             window : int
926                 Size of the moving window.
927         boundary : 'exact' | 'trim' | 'pad'
928             If 'exact', a ValueError will be raised if dimension size is not a
929             multiple of the window size. If 'trim', the excess entries are
930             dropped. If 'pad', NA will be padded.
931         side : 'left' or 'right' or mapping from dimension to 'left' or 'right'
932         coord_func : function (name) that is applied to the coordinates,
933             or a mapping from coordinate name to function (name).
934         keep_attrs : bool, optional
935             If True, the object's attributes (`attrs`) will be copied from
936             the original object to the new one.  If False (default), the new
937             object will be returned without attributes.
938 
939         Returns
940         -------
941         Coarsen object (core.rolling.DataArrayCoarsen for DataArray,
942         core.rolling.DatasetCoarsen for Dataset.)
943 
944         Examples
945         --------
946         Coarsen the long time series by averaging over every four days.
947 
948         >>> da = xr.DataArray(
949         ...     np.linspace(0, 364, num=364),
950         ...     dims="time",
951         ...     coords={"time": pd.date_range("15/12/1999", periods=364)},
952         ... )
953         >>> da
954         <xarray.DataArray (time: 364)>
955         array([  0.      ,   1.002755,   2.00551 , ..., 361.99449 , 362.997245,
956                364.      ])
957         Coordinates:
958           * time     (time) datetime64[ns] 1999-12-15 1999-12-16 ... 2000-12-12
959         >>>
960         >>> da.coarsen(time=3, boundary="trim").mean()
961         <xarray.DataArray (time: 121)>
962         array([  1.002755,   4.011019,   7.019284,  ...,  358.986226,
963                361.99449 ])
964         Coordinates:
965           * time     (time) datetime64[ns] 1999-12-16 1999-12-19 ... 2000-12-10
966         >>>
967 
968         See Also
969         --------
970         core.rolling.DataArrayCoarsen
971         core.rolling.DatasetCoarsen
972         """
973         if keep_attrs is None:
974             keep_attrs = _get_keep_attrs(default=False)
975 
976         dim = either_dict_or_kwargs(dim, window_kwargs, "coarsen")
977         return self._coarsen_cls(
978             self,
979             dim,
980             boundary=boundary,
981             side=side,
982             coord_func=coord_func,
983             keep_attrs=keep_attrs,
984         )
985 
986     def resample(
987         self,
988         indexer: Mapping[Hashable, str] = None,
989         skipna=None,
990         closed: str = None,
991         label: str = None,
992         base: int = 0,
993         keep_attrs: bool = None,
994         loffset=None,
995         restore_coord_dims: bool = None,
996         **indexer_kwargs: str,
997     ):
998         """Returns a Resample object for performing resampling operations.
999 
1000         Handles both downsampling and upsampling. The resampled
1001         dimension must be a datetime-like coordinate. If any intervals
1002         contain no values from the original object, they will be given
1003         the value ``NaN``.
1004 
1005         Parameters
1006         ----------
1007         indexer : {dim: freq}, optional
1008             Mapping from the dimension name to resample frequency [1]_. The
1009             dimension must be datetime-like.
1010         skipna : bool, optional
1011             Whether to skip missing values when aggregating in downsampling.
1012         closed : 'left' or 'right', optional
1013             Side of each interval to treat as closed.
1014         label : 'left or 'right', optional
1015             Side of each interval to use for labeling.
1016         base : int, optional
1017             For frequencies that evenly subdivide 1 day, the "origin" of the
1018             aggregated intervals. For example, for '24H' frequency, base could
1019             range from 0 through 23.
1020         loffset : timedelta or str, optional
1021             Offset used to adjust the resampled time labels. Some pandas date
1022             offset strings are supported.
1023         keep_attrs : bool, optional
1024             If True, the object's attributes (`attrs`) will be copied from
1025             the original object to the new one.  If False (default), the new
1026             object will be returned without attributes.
1027         restore_coord_dims : bool, optional
1028             If True, also restore the dimension order of multi-dimensional
1029             coordinates.
1030         **indexer_kwargs : {dim: freq}
1031             The keyword arguments form of ``indexer``.
1032             One of indexer or indexer_kwargs must be provided.
1033 
1034         Returns
1035         -------
1036         resampled : same type as caller
1037             This object resampled.
1038 
1039         Examples
1040         --------
1041         Downsample monthly time-series data to seasonal data:
1042 
1043         >>> da = xr.DataArray(
1044         ...     np.linspace(0, 11, num=12),
1045         ...     coords=[
1046         ...         pd.date_range(
1047         ...             "15/12/1999", periods=12, freq=pd.DateOffset(months=1),
1048         ...         )
1049         ...     ],
1050         ...     dims="time",
1051         ... )
1052         >>> da
1053         <xarray.DataArray (time: 12)>
1054         array([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7., 8.,   9.,  10.,  11.])
1055         Coordinates:
1056           * time     (time) datetime64[ns] 1999-12-15 2000-01-15 2000-02-15 ...
1057         >>> da.resample(time="QS-DEC").mean()
1058         <xarray.DataArray (time: 4)>
1059         array([ 1.,  4.,  7., 10.])
1060         Coordinates:
1061           * time     (time) datetime64[ns] 1999-12-01 2000-03-01 2000-06-01 2000-09-01
1062 
1063         Upsample monthly time-series data to daily data:
1064 
1065         >>> da.resample(time="1D").interpolate("linear")
1066         <xarray.DataArray (time: 337)>
1067         array([ 0.      ,  0.032258,  0.064516, ..., 10.935484, 10.967742, 11.      ])
1068         Coordinates:
1069           * time     (time) datetime64[ns] 1999-12-15 1999-12-16 1999-12-17 ...
1070 
1071         Limit scope of upsampling method
1072 
1073         >>> da.resample(time="1D").nearest(tolerance="1D")
1074         <xarray.DataArray (time: 337)>
1075         array([ 0.,  0., nan, ..., nan, 11., 11.])
1076         Coordinates:
1077           * time     (time) datetime64[ns] 1999-12-15 1999-12-16 ... 2000-11-15
1078 
1079         See Also
1080         --------
1081         pandas.Series.resample
1082         pandas.DataFrame.resample
1083 
1084         References
1085         ----------
1086 
1087         .. [1] http://pandas.pydata.org/pandas-docs/stable/timeseries.html#offset-aliases
1088         """
1089         # TODO support non-string indexer after removing the old API.
1090 
1091         from .dataarray import DataArray
1092         from .resample import RESAMPLE_DIM
1093         from ..coding.cftimeindex import CFTimeIndex
1094 
1095         if keep_attrs is None:
1096             keep_attrs = _get_keep_attrs(default=False)
1097 
1098         # note: the second argument (now 'skipna') use to be 'dim'
1099         if (
1100             (skipna is not None and not isinstance(skipna, bool))
1101             or ("how" in indexer_kwargs and "how" not in self.dims)
1102             or ("dim" in indexer_kwargs and "dim" not in self.dims)
1103         ):
1104             raise TypeError(
1105                 "resample() no longer supports the `how` or "
1106                 "`dim` arguments. Instead call methods on resample "
1107                 "objects, e.g., data.resample(time='1D').mean()"
1108             )
1109 
1110         indexer = either_dict_or_kwargs(indexer, indexer_kwargs, "resample")
1111         if len(indexer) != 1:
1112             raise ValueError("Resampling only supported along single dimensions.")
1113         dim, freq = next(iter(indexer.items()))
1114 
1115         dim_name = dim
1116         dim_coord = self[dim]
1117 
1118         if isinstance(self.indexes[dim_name], CFTimeIndex):
1119             from .resample_cftime import CFTimeGrouper
1120 
1121             grouper = CFTimeGrouper(freq, closed, label, base, loffset)
1122         else:
1123             grouper = pd.Grouper(
1124                 freq=freq, closed=closed, label=label, base=base, loffset=loffset
1125             )
1126         group = DataArray(
1127             dim_coord, coords=dim_coord.coords, dims=dim_coord.dims, name=RESAMPLE_DIM
1128         )
1129         resampler = self._resample_cls(
1130             self,
1131             group=group,
1132             dim=dim_name,
1133             grouper=grouper,
1134             resample_dim=RESAMPLE_DIM,
1135             restore_coord_dims=restore_coord_dims,
1136         )
1137 
1138         return resampler
1139 
1140     def where(self, cond, other=dtypes.NA, drop: bool = False):
1141         """Filter elements from this object according to a condition.
1142 
1143         This operation follows the normal broadcasting and alignment rules that
1144         xarray uses for binary arithmetic.
1145 
1146         Parameters
1147         ----------
1148         cond : DataArray or Dataset with boolean dtype
1149             Locations at which to preserve this object's values.
1150         other : scalar, DataArray or Dataset, optional
1151             Value to use for locations in this object where ``cond`` is False.
1152             By default, these locations filled with NA.
1153         drop : boolean, optional
1154             If True, coordinate labels that only correspond to False values of
1155             the condition are dropped from the result. Mutually exclusive with
1156             ``other``.
1157 
1158         Returns
1159         -------
1160         Same xarray type as caller, with dtype float64.
1161 
1162         Examples
1163         --------
1164 
1165         >>> import numpy as np
1166         >>> a = xr.DataArray(np.arange(25).reshape(5, 5), dims=("x", "y"))
1167         >>> a
1168         <xarray.DataArray (x: 5, y: 5)>
1169         array([[ 0,  1,  2,  3,  4],
1170             [ 5,  6,  7,  8,  9],
1171             [10, 11, 12, 13, 14],
1172             [15, 16, 17, 18, 19],
1173             [20, 21, 22, 23, 24]])
1174         Dimensions without coordinates: x, y
1175 
1176         >>> a.where(a.x + a.y < 4)
1177         <xarray.DataArray (x: 5, y: 5)>
1178         array([[  0.,   1.,   2.,   3.,  nan],
1179                [  5.,   6.,   7.,  nan,  nan],
1180                [ 10.,  11.,  nan,  nan,  nan],
1181                [ 15.,  nan,  nan,  nan,  nan],
1182                [ nan,  nan,  nan,  nan,  nan]])
1183         Dimensions without coordinates: x, y
1184 
1185         >>> a.where(a.x + a.y < 5, -1)
1186         <xarray.DataArray (x: 5, y: 5)>
1187         array([[ 0,  1,  2,  3,  4],
1188                [ 5,  6,  7,  8, -1],
1189                [10, 11, 12, -1, -1],
1190                [15, 16, -1, -1, -1],
1191                [20, -1, -1, -1, -1]])
1192         Dimensions without coordinates: x, y
1193 
1194         >>> a.where(a.x + a.y < 4, drop=True)
1195         <xarray.DataArray (x: 4, y: 4)>
1196         array([[  0.,   1.,   2.,   3.],
1197                [  5.,   6.,   7.,  nan],
1198                [ 10.,  11.,  nan,  nan],
1199                [ 15.,  nan,  nan,  nan]])
1200         Dimensions without coordinates: x, y
1201 
1202         >>> a.where(lambda x: x.x + x.y < 4, drop=True)
1203         <xarray.DataArray (x: 4, y: 4)>
1204         array([[  0.,   1.,   2.,   3.],
1205                [  5.,   6.,   7.,  nan],
1206                [ 10.,  11.,  nan,  nan],
1207                [ 15.,  nan,  nan,  nan]])
1208         Dimensions without coordinates: x, y
1209 
1210         See also
1211         --------
1212         numpy.where : corresponding numpy function
1213         where : equivalent function
1214         """
1215         from .alignment import align
1216         from .dataarray import DataArray
1217         from .dataset import Dataset
1218 
1219         if callable(cond):
1220             cond = cond(self)
1221 
1222         if drop:
1223             if other is not dtypes.NA:
1224                 raise ValueError("cannot set `other` if drop=True")
1225 
1226             if not isinstance(cond, (Dataset, DataArray)):
1227                 raise TypeError(
1228                     "cond argument is %r but must be a %r or %r"
1229                     % (cond, Dataset, DataArray)
1230                 )
1231 
1232             # align so we can use integer indexing
1233             self, cond = align(self, cond)
1234 
1235             # get cond with the minimal size needed for the Dataset
1236             if isinstance(cond, Dataset):
1237                 clipcond = cond.to_array().any("variable")
1238             else:
1239                 clipcond = cond
1240 
1241             # clip the data corresponding to coordinate dims that are not used
1242             nonzeros = zip(clipcond.dims, np.nonzero(clipcond.values))
1243             indexers = {k: np.unique(v) for k, v in nonzeros}
1244 
1245             self = self.isel(**indexers)
1246             cond = cond.isel(**indexers)
1247 
1248         return ops.where_method(self, cond, other)
1249 
1250     def close(self: Any) -> None:
1251         """Close any files linked to this object
1252         """
1253         if self._file_obj is not None:
1254             self._file_obj.close()
1255         self._file_obj = None
1256 
1257     def isin(self, test_elements):
1258         """Tests each value in the array for whether it is in test elements.
1259 
1260         Parameters
1261         ----------
1262         test_elements : array_like
1263             The values against which to test each value of `element`.
1264             This argument is flattened if an array or array_like.
1265             See numpy notes for behavior with non-array-like parameters.
1266 
1267         Returns
1268         -------
1269         isin : same as object, bool
1270             Has the same shape as this object.
1271 
1272         Examples
1273         --------
1274 
1275         >>> array = xr.DataArray([1, 2, 3], dims="x")
1276         >>> array.isin([1, 3])
1277         <xarray.DataArray (x: 3)>
1278         array([ True, False,  True])
1279         Dimensions without coordinates: x
1280 
1281         See also
1282         --------
1283         numpy.isin
1284         """
1285         from .computation import apply_ufunc
1286         from .dataset import Dataset
1287         from .dataarray import DataArray
1288         from .variable import Variable
1289 
1290         if isinstance(test_elements, Dataset):
1291             raise TypeError(
1292                 "isin() argument must be convertible to an array: {}".format(
1293                     test_elements
1294                 )
1295             )
1296         elif isinstance(test_elements, (Variable, DataArray)):
1297             # need to explicitly pull out data to support dask arrays as the
1298             # second argument
1299             test_elements = test_elements.data
1300 
1301         return apply_ufunc(
1302             duck_array_ops.isin,
1303             self,
1304             kwargs=dict(test_elements=test_elements),
1305             dask="allowed",
1306         )
1307 
1308     def __enter__(self: T) -> T:
1309         return self
1310 
1311     def __exit__(self, exc_type, exc_value, traceback) -> None:
1312         self.close()
1313 
1314     def __getitem__(self, value):
1315         # implementations of this class should implement this method
1316         raise NotImplementedError()

</code><intended_behavior>This class provides additional context to the issue.</intended_behavior>]
2025-10-15 08:38:34.439 | INFO     | Overall retry 0 succeeded; ending workflow
2025-10-15 08:38:34.439 | INFO     | Search-only: skipping patch selection
2025-10-15 08:38:34.519 | INFO     | Task pydata__xarray-4098 completed successfully.
2025-10-15 08:38:34.520 | INFO     | No patch generated. You can try running ACR again.
