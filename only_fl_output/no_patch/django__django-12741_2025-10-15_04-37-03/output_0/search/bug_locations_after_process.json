[
    {
        "rel_file_path": "django/db/backends/sqlite3/operations.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.1/django/db/backends/sqlite3/operations.py",
        "start": 18,
        "end": 340,
        "class_name": "DatabaseOperations",
        "method_name": null,
        "code": "18 class DatabaseOperations(BaseDatabaseOperations):\n19     cast_char_field_without_max_length = 'text'\n20     cast_data_types = {\n21         'DateField': 'TEXT',\n22         'DateTimeField': 'TEXT',\n23     }\n24     explain_prefix = 'EXPLAIN QUERY PLAN'\n25 \n26     def bulk_batch_size(self, fields, objs):\n27         \"\"\"\n28         SQLite has a compile-time default (SQLITE_LIMIT_VARIABLE_NUMBER) of\n29         999 variables per query.\n30 \n31         If there's only a single field to insert, the limit is 500\n32         (SQLITE_MAX_COMPOUND_SELECT).\n33         \"\"\"\n34         if len(fields) == 1:\n35             return 500\n36         elif len(fields) > 1:\n37             return self.connection.features.max_query_params // len(fields)\n38         else:\n39             return len(objs)\n40 \n41     def check_expression_support(self, expression):\n42         bad_fields = (models.DateField, models.DateTimeField, models.TimeField)\n43         bad_aggregates = (models.Sum, models.Avg, models.Variance, models.StdDev)\n44         if isinstance(expression, bad_aggregates):\n45             for expr in expression.get_source_expressions():\n46                 try:\n47                     output_field = expr.output_field\n48                 except (AttributeError, FieldError):\n49                     # Not every subexpression has an output_field which is fine\n50                     # to ignore.\n51                     pass\n52                 else:\n53                     if isinstance(output_field, bad_fields):\n54                         raise NotSupportedError(\n55                             'You cannot use Sum, Avg, StdDev, and Variance '\n56                             'aggregations on date/time fields in sqlite3 '\n57                             'since date/time is saved as text.'\n58                         )\n59         if (\n60             isinstance(expression, models.Aggregate) and\n61             expression.distinct and\n62             len(expression.source_expressions) > 1\n63         ):\n64             raise NotSupportedError(\n65                 \"SQLite doesn't support DISTINCT on aggregate functions \"\n66                 \"accepting multiple arguments.\"\n67             )\n68 \n69     def date_extract_sql(self, lookup_type, field_name):\n70         \"\"\"\n71         Support EXTRACT with a user-defined function django_date_extract()\n72         that's registered in connect(). Use single quotes because this is a\n73         string and could otherwise cause a collision with a field name.\n74         \"\"\"\n75         return \"django_date_extract('%s', %s)\" % (lookup_type.lower(), field_name)\n76 \n77     def date_interval_sql(self, timedelta):\n78         return str(duration_microseconds(timedelta))\n79 \n80     def format_for_duration_arithmetic(self, sql):\n81         \"\"\"Do nothing since formatting is handled in the custom function.\"\"\"\n82         return sql\n83 \n84     def date_trunc_sql(self, lookup_type, field_name):\n85         return \"django_date_trunc('%s', %s)\" % (lookup_type.lower(), field_name)\n86 \n87     def time_trunc_sql(self, lookup_type, field_name):\n88         return \"django_time_trunc('%s', %s)\" % (lookup_type.lower(), field_name)\n89 \n90     def _convert_tznames_to_sql(self, tzname):\n91         if settings.USE_TZ:\n92             return \"'%s'\" % tzname, \"'%s'\" % self.connection.timezone_name\n93         return 'NULL', 'NULL'\n94 \n95     def datetime_cast_date_sql(self, field_name, tzname):\n96         return 'django_datetime_cast_date(%s, %s, %s)' % (\n97             field_name, *self._convert_tznames_to_sql(tzname),\n98         )\n99 \n100     def datetime_cast_time_sql(self, field_name, tzname):\n101         return 'django_datetime_cast_time(%s, %s, %s)' % (\n102             field_name, *self._convert_tznames_to_sql(tzname),\n103         )\n104 \n105     def datetime_extract_sql(self, lookup_type, field_name, tzname):\n106         return \"django_datetime_extract('%s', %s, %s, %s)\" % (\n107             lookup_type.lower(), field_name, *self._convert_tznames_to_sql(tzname),\n108         )\n109 \n110     def datetime_trunc_sql(self, lookup_type, field_name, tzname):\n111         return \"django_datetime_trunc('%s', %s, %s, %s)\" % (\n112             lookup_type.lower(), field_name, *self._convert_tznames_to_sql(tzname),\n113         )\n114 \n115     def time_extract_sql(self, lookup_type, field_name):\n116         return \"django_time_extract('%s', %s)\" % (lookup_type.lower(), field_name)\n117 \n118     def pk_default_value(self):\n119         return \"NULL\"\n120 \n121     def _quote_params_for_last_executed_query(self, params):\n122         \"\"\"\n123         Only for last_executed_query! Don't use this to execute SQL queries!\n124         \"\"\"\n125         # This function is limited both by SQLITE_LIMIT_VARIABLE_NUMBER (the\n126         # number of parameters, default = 999) and SQLITE_MAX_COLUMN (the\n127         # number of return values, default = 2000). Since Python's sqlite3\n128         # module doesn't expose the get_limit() C API, assume the default\n129         # limits are in effect and split the work in batches if needed.\n130         BATCH_SIZE = 999\n131         if len(params) > BATCH_SIZE:\n132             results = ()\n133             for index in range(0, len(params), BATCH_SIZE):\n134                 chunk = params[index:index + BATCH_SIZE]\n135                 results += self._quote_params_for_last_executed_query(chunk)\n136             return results\n137 \n138         sql = 'SELECT ' + ', '.join(['QUOTE(?)'] * len(params))\n139         # Bypass Django's wrappers and use the underlying sqlite3 connection\n140         # to avoid logging this query - it would trigger infinite recursion.\n141         cursor = self.connection.connection.cursor()\n142         # Native sqlite3 cursors cannot be used as context managers.\n143         try:\n144             return cursor.execute(sql, params).fetchone()\n145         finally:\n146             cursor.close()\n147 \n148     def last_executed_query(self, cursor, sql, params):\n149         # Python substitutes parameters in Modules/_sqlite/cursor.c with:\n150         # pysqlite_statement_bind_parameters(self->statement, parameters, allow_8bit_chars);\n151         # Unfortunately there is no way to reach self->statement from Python,\n152         # so we quote and substitute parameters manually.\n153         if params:\n154             if isinstance(params, (list, tuple)):\n155                 params = self._quote_params_for_last_executed_query(params)\n156             else:\n157                 values = tuple(params.values())\n158                 values = self._quote_params_for_last_executed_query(values)\n159                 params = dict(zip(params, values))\n160             return sql % params\n161         # For consistency with SQLiteCursorWrapper.execute(), just return sql\n162         # when there are no parameters. See #13648 and #17158.\n163         else:\n164             return sql\n165 \n166     def quote_name(self, name):\n167         if name.startswith('\"') and name.endswith('\"'):\n168             return name  # Quoting once is enough.\n169         return '\"%s\"' % name\n170 \n171     def no_limit_value(self):\n172         return -1\n173 \n174     def __references_graph(self, table_name):\n175         query = \"\"\"\n176         WITH tables AS (\n177             SELECT %s name\n178             UNION\n179             SELECT sqlite_master.name\n180             FROM sqlite_master\n181             JOIN tables ON (sql REGEXP %s || tables.name || %s)\n182         ) SELECT name FROM tables;\n183         \"\"\"\n184         params = (\n185             table_name,\n186             r'(?i)\\s+references\\s+(\"|\\')?',\n187             r'(\"|\\')?\\s*\\(',\n188         )\n189         with self.connection.cursor() as cursor:\n190             results = cursor.execute(query, params)\n191             return [row[0] for row in results.fetchall()]\n192 \n193     @cached_property\n194     def _references_graph(self):\n195         # 512 is large enough to fit the ~330 tables (as of this writing) in\n196         # Django's test suite.\n197         return lru_cache(maxsize=512)(self.__references_graph)\n198 \n199     def sql_flush(self, style, tables, *, reset_sequences=False, allow_cascade=False):\n200         if tables and allow_cascade:\n201             # Simulate TRUNCATE CASCADE by recursively collecting the tables\n202             # referencing the tables to be flushed.\n203             tables = set(chain.from_iterable(self._references_graph(table) for table in tables))\n204         # Note: No requirement for reset of auto-incremented indices (cf. other\n205         # sql_flush() implementations). Just return SQL at this point\n206         return ['%s %s %s;' % (\n207             style.SQL_KEYWORD('DELETE'),\n208             style.SQL_KEYWORD('FROM'),\n209             style.SQL_FIELD(self.quote_name(table))\n210         ) for table in tables]\n211 \n212     def adapt_datetimefield_value(self, value):\n213         if value is None:\n214             return None\n215 \n216         # Expression values are adapted by the database.\n217         if hasattr(value, 'resolve_expression'):\n218             return value\n219 \n220         # SQLite doesn't support tz-aware datetimes\n221         if timezone.is_aware(value):\n222             if settings.USE_TZ:\n223                 value = timezone.make_naive(value, self.connection.timezone)\n224             else:\n225                 raise ValueError(\"SQLite backend does not support timezone-aware datetimes when USE_TZ is False.\")\n226 \n227         return str(value)\n228 \n229     def adapt_timefield_value(self, value):\n230         if value is None:\n231             return None\n232 \n233         # Expression values are adapted by the database.\n234         if hasattr(value, 'resolve_expression'):\n235             return value\n236 \n237         # SQLite doesn't support tz-aware datetimes\n238         if timezone.is_aware(value):\n239             raise ValueError(\"SQLite backend does not support timezone-aware times.\")\n240 \n241         return str(value)\n242 \n243     def get_db_converters(self, expression):\n244         converters = super().get_db_converters(expression)\n245         internal_type = expression.output_field.get_internal_type()\n246         if internal_type == 'DateTimeField':\n247             converters.append(self.convert_datetimefield_value)\n248         elif internal_type == 'DateField':\n249             converters.append(self.convert_datefield_value)\n250         elif internal_type == 'TimeField':\n251             converters.append(self.convert_timefield_value)\n252         elif internal_type == 'DecimalField':\n253             converters.append(self.get_decimalfield_converter(expression))\n254         elif internal_type == 'UUIDField':\n255             converters.append(self.convert_uuidfield_value)\n256         elif internal_type in ('NullBooleanField', 'BooleanField'):\n257             converters.append(self.convert_booleanfield_value)\n258         return converters\n259 \n260     def convert_datetimefield_value(self, value, expression, connection):\n261         if value is not None:\n262             if not isinstance(value, datetime.datetime):\n263                 value = parse_datetime(value)\n264             if settings.USE_TZ and not timezone.is_aware(value):\n265                 value = timezone.make_aware(value, self.connection.timezone)\n266         return value\n267 \n268     def convert_datefield_value(self, value, expression, connection):\n269         if value is not None:\n270             if not isinstance(value, datetime.date):\n271                 value = parse_date(value)\n272         return value\n273 \n274     def convert_timefield_value(self, value, expression, connection):\n275         if value is not None:\n276             if not isinstance(value, datetime.time):\n277                 value = parse_time(value)\n278         return value\n279 \n280     def get_decimalfield_converter(self, expression):\n281         # SQLite stores only 15 significant digits. Digits coming from\n282         # float inaccuracy must be removed.\n283         create_decimal = decimal.Context(prec=15).create_decimal_from_float\n284         if isinstance(expression, Col):\n285             quantize_value = decimal.Decimal(1).scaleb(-expression.output_field.decimal_places)\n286 \n287             def converter(value, expression, connection):\n288                 if value is not None:\n289                     return create_decimal(value).quantize(quantize_value, context=expression.output_field.context)\n290         else:\n291             def converter(value, expression, connection):\n292                 if value is not None:\n293                     return create_decimal(value)\n294         return converter\n295 \n296     def convert_uuidfield_value(self, value, expression, connection):\n297         if value is not None:\n298             value = uuid.UUID(value)\n299         return value\n300 \n301     def convert_booleanfield_value(self, value, expression, connection):\n302         return bool(value) if value in (1, 0) else value\n303 \n304     def bulk_insert_sql(self, fields, placeholder_rows):\n305         return \" UNION ALL \".join(\n306             \"SELECT %s\" % \", \".join(row)\n307             for row in placeholder_rows\n308         )\n309 \n310     def combine_expression(self, connector, sub_expressions):\n311         # SQLite doesn't have a ^ operator, so use the user-defined POWER\n312         # function that's registered in connect().\n313         if connector == '^':\n314             return 'POWER(%s)' % ','.join(sub_expressions)\n315         elif connector == '#':\n316             return 'BITXOR(%s)' % ','.join(sub_expressions)\n317         return super().combine_expression(connector, sub_expressions)\n318 \n319     def combine_duration_expression(self, connector, sub_expressions):\n320         if connector not in ['+', '-']:\n321             raise DatabaseError('Invalid connector for timedelta: %s.' % connector)\n322         fn_params = [\"'%s'\" % connector] + sub_expressions\n323         if len(fn_params) > 3:\n324             raise ValueError('Too many params for timedelta operations.')\n325         return \"django_format_dtdelta(%s)\" % ', '.join(fn_params)\n326 \n327     def integer_field_range(self, internal_type):\n328         # SQLite doesn't enforce any integer constraints\n329         return (None, None)\n330 \n331     def subtract_temporals(self, internal_type, lhs, rhs):\n332         lhs_sql, lhs_params = lhs\n333         rhs_sql, rhs_params = rhs\n334         params = (*lhs_params, *rhs_params)\n335         if internal_type == 'TimeField':\n336             return 'django_time_diff(%s, %s)' % (lhs_sql, rhs_sql), params\n337         return 'django_timestamp_diff(%s, %s)' % (lhs_sql, rhs_sql), params\n338 \n339     def insert_statement(self, ignore_conflicts=False):\n340         return 'INSERT OR IGNORE INTO' if ignore_conflicts else super().insert_statement(ignore_conflicts)\n",
        "intended_behavior": "Within each identified `execute_sql_flush` method across the different backends, the `using` parameter should be removed. The method's functionality should be preserved by relying on `self.connection.alias` to access the database alias internally. Ensure that all internal uses of `execute_sql_flush` are refactored to omit the previously required `using` argument, reflecting the simplification of the method's signature."
    },
    {
        "rel_file_path": "django/db/backends/oracle/operations.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.1/django/db/backends/oracle/operations.py",
        "start": 21,
        "end": 652,
        "class_name": "DatabaseOperations",
        "method_name": null,
        "code": "21 class DatabaseOperations(BaseDatabaseOperations):\n22     # Oracle uses NUMBER(5), NUMBER(11), and NUMBER(19) for integer fields.\n23     # SmallIntegerField uses NUMBER(11) instead of NUMBER(5), which is used by\n24     # SmallAutoField, to preserve backward compatibility.\n25     integer_field_ranges = {\n26         'SmallIntegerField': (-99999999999, 99999999999),\n27         'IntegerField': (-99999999999, 99999999999),\n28         'BigIntegerField': (-9999999999999999999, 9999999999999999999),\n29         'PositiveBigIntegerField': (0, 9999999999999999999),\n30         'PositiveSmallIntegerField': (0, 99999999999),\n31         'PositiveIntegerField': (0, 99999999999),\n32         'SmallAutoField': (-99999, 99999),\n33         'AutoField': (-99999999999, 99999999999),\n34         'BigAutoField': (-9999999999999999999, 9999999999999999999),\n35     }\n36     set_operators = {**BaseDatabaseOperations.set_operators, 'difference': 'MINUS'}\n37 \n38     # TODO: colorize this SQL code with style.SQL_KEYWORD(), etc.\n39     _sequence_reset_sql = \"\"\"\n40 DECLARE\n41     table_value integer;\n42     seq_value integer;\n43     seq_name user_tab_identity_cols.sequence_name%%TYPE;\n44 BEGIN\n45     BEGIN\n46         SELECT sequence_name INTO seq_name FROM user_tab_identity_cols\n47         WHERE  table_name = '%(table_name)s' AND\n48                column_name = '%(column_name)s';\n49         EXCEPTION WHEN NO_DATA_FOUND THEN\n50             seq_name := '%(no_autofield_sequence_name)s';\n51     END;\n52 \n53     SELECT NVL(MAX(%(column)s), 0) INTO table_value FROM %(table)s;\n54     SELECT NVL(last_number - cache_size, 0) INTO seq_value FROM user_sequences\n55            WHERE sequence_name = seq_name;\n56     WHILE table_value > seq_value LOOP\n57         EXECUTE IMMEDIATE 'SELECT \"'||seq_name||'\".nextval FROM DUAL'\n58         INTO seq_value;\n59     END LOOP;\n60 END;\n61 /\"\"\"\n62 \n63     # Oracle doesn't support string without precision; use the max string size.\n64     cast_char_field_without_max_length = 'NVARCHAR2(2000)'\n65     cast_data_types = {\n66         'AutoField': 'NUMBER(11)',\n67         'BigAutoField': 'NUMBER(19)',\n68         'SmallAutoField': 'NUMBER(5)',\n69         'TextField': cast_char_field_without_max_length,\n70     }\n71 \n72     def cache_key_culling_sql(self):\n73         return 'SELECT cache_key FROM %s ORDER BY cache_key OFFSET %%s ROWS FETCH FIRST 1 ROWS ONLY'\n74 \n75     def date_extract_sql(self, lookup_type, field_name):\n76         if lookup_type == 'week_day':\n77             # TO_CHAR(field, 'D') returns an integer from 1-7, where 1=Sunday.\n78             return \"TO_CHAR(%s, 'D')\" % field_name\n79         elif lookup_type == 'iso_week_day':\n80             return \"TO_CHAR(%s - 1, 'D')\" % field_name\n81         elif lookup_type == 'week':\n82             # IW = ISO week number\n83             return \"TO_CHAR(%s, 'IW')\" % field_name\n84         elif lookup_type == 'quarter':\n85             return \"TO_CHAR(%s, 'Q')\" % field_name\n86         elif lookup_type == 'iso_year':\n87             return \"TO_CHAR(%s, 'IYYY')\" % field_name\n88         else:\n89             # https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/EXTRACT-datetime.html\n90             return \"EXTRACT(%s FROM %s)\" % (lookup_type.upper(), field_name)\n91 \n92     def date_trunc_sql(self, lookup_type, field_name):\n93         # https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/ROUND-and-TRUNC-Date-Functions.html\n94         if lookup_type in ('year', 'month'):\n95             return \"TRUNC(%s, '%s')\" % (field_name, lookup_type.upper())\n96         elif lookup_type == 'quarter':\n97             return \"TRUNC(%s, 'Q')\" % field_name\n98         elif lookup_type == 'week':\n99             return \"TRUNC(%s, 'IW')\" % field_name\n100         else:\n101             return \"TRUNC(%s)\" % field_name\n102 \n103     # Oracle crashes with \"ORA-03113: end-of-file on communication channel\"\n104     # if the time zone name is passed in parameter. Use interpolation instead.\n105     # https://groups.google.com/forum/#!msg/django-developers/zwQju7hbG78/9l934yelwfsJ\n106     # This regexp matches all time zone names from the zoneinfo database.\n107     _tzname_re = _lazy_re_compile(r'^[\\w/:+-]+$')\n108 \n109     def _prepare_tzname_delta(self, tzname):\n110         if '+' in tzname:\n111             return tzname[tzname.find('+'):]\n112         elif '-' in tzname:\n113             return tzname[tzname.find('-'):]\n114         return tzname\n115 \n116     def _convert_field_to_tz(self, field_name, tzname):\n117         if not settings.USE_TZ:\n118             return field_name\n119         if not self._tzname_re.match(tzname):\n120             raise ValueError(\"Invalid time zone name: %s\" % tzname)\n121         # Convert from connection timezone to the local time, returning\n122         # TIMESTAMP WITH TIME ZONE and cast it back to TIMESTAMP to strip the\n123         # TIME ZONE details.\n124         if self.connection.timezone_name != tzname:\n125             return \"CAST((FROM_TZ(%s, '%s') AT TIME ZONE '%s') AS TIMESTAMP)\" % (\n126                 field_name,\n127                 self.connection.timezone_name,\n128                 self._prepare_tzname_delta(tzname),\n129             )\n130         return field_name\n131 \n132     def datetime_cast_date_sql(self, field_name, tzname):\n133         field_name = self._convert_field_to_tz(field_name, tzname)\n134         return 'TRUNC(%s)' % field_name\n135 \n136     def datetime_cast_time_sql(self, field_name, tzname):\n137         # Since `TimeField` values are stored as TIMESTAMP where only the date\n138         # part is ignored, convert the field to the specified timezone.\n139         return self._convert_field_to_tz(field_name, tzname)\n140 \n141     def datetime_extract_sql(self, lookup_type, field_name, tzname):\n142         field_name = self._convert_field_to_tz(field_name, tzname)\n143         return self.date_extract_sql(lookup_type, field_name)\n144 \n145     def datetime_trunc_sql(self, lookup_type, field_name, tzname):\n146         field_name = self._convert_field_to_tz(field_name, tzname)\n147         # https://docs.oracle.com/en/database/oracle/oracle-database/18/sqlrf/ROUND-and-TRUNC-Date-Functions.html\n148         if lookup_type in ('year', 'month'):\n149             sql = \"TRUNC(%s, '%s')\" % (field_name, lookup_type.upper())\n150         elif lookup_type == 'quarter':\n151             sql = \"TRUNC(%s, 'Q')\" % field_name\n152         elif lookup_type == 'week':\n153             sql = \"TRUNC(%s, 'IW')\" % field_name\n154         elif lookup_type == 'day':\n155             sql = \"TRUNC(%s)\" % field_name\n156         elif lookup_type == 'hour':\n157             sql = \"TRUNC(%s, 'HH24')\" % field_name\n158         elif lookup_type == 'minute':\n159             sql = \"TRUNC(%s, 'MI')\" % field_name\n160         else:\n161             sql = \"CAST(%s AS DATE)\" % field_name  # Cast to DATE removes sub-second precision.\n162         return sql\n163 \n164     def time_trunc_sql(self, lookup_type, field_name):\n165         # The implementation is similar to `datetime_trunc_sql` as both\n166         # `DateTimeField` and `TimeField` are stored as TIMESTAMP where\n167         # the date part of the later is ignored.\n168         if lookup_type == 'hour':\n169             sql = \"TRUNC(%s, 'HH24')\" % field_name\n170         elif lookup_type == 'minute':\n171             sql = \"TRUNC(%s, 'MI')\" % field_name\n172         elif lookup_type == 'second':\n173             sql = \"CAST(%s AS DATE)\" % field_name  # Cast to DATE removes sub-second precision.\n174         return sql\n175 \n176     def get_db_converters(self, expression):\n177         converters = super().get_db_converters(expression)\n178         internal_type = expression.output_field.get_internal_type()\n179         if internal_type == 'TextField':\n180             converters.append(self.convert_textfield_value)\n181         elif internal_type == 'BinaryField':\n182             converters.append(self.convert_binaryfield_value)\n183         elif internal_type in ['BooleanField', 'NullBooleanField']:\n184             converters.append(self.convert_booleanfield_value)\n185         elif internal_type == 'DateTimeField':\n186             if settings.USE_TZ:\n187                 converters.append(self.convert_datetimefield_value)\n188         elif internal_type == 'DateField':\n189             converters.append(self.convert_datefield_value)\n190         elif internal_type == 'TimeField':\n191             converters.append(self.convert_timefield_value)\n192         elif internal_type == 'UUIDField':\n193             converters.append(self.convert_uuidfield_value)\n194         # Oracle stores empty strings as null. If the field accepts the empty\n195         # string, undo this to adhere to the Django convention of using\n196         # the empty string instead of null.\n197         if expression.field.empty_strings_allowed:\n198             converters.append(\n199                 self.convert_empty_bytes\n200                 if internal_type == 'BinaryField' else\n201                 self.convert_empty_string\n202             )\n203         return converters\n204 \n205     def convert_textfield_value(self, value, expression, connection):\n206         if isinstance(value, Database.LOB):\n207             value = value.read()\n208         return value\n209 \n210     def convert_binaryfield_value(self, value, expression, connection):\n211         if isinstance(value, Database.LOB):\n212             value = force_bytes(value.read())\n213         return value\n214 \n215     def convert_booleanfield_value(self, value, expression, connection):\n216         if value in (0, 1):\n217             value = bool(value)\n218         return value\n219 \n220     # cx_Oracle always returns datetime.datetime objects for\n221     # DATE and TIMESTAMP columns, but Django wants to see a\n222     # python datetime.date, .time, or .datetime.\n223 \n224     def convert_datetimefield_value(self, value, expression, connection):\n225         if value is not None:\n226             value = timezone.make_aware(value, self.connection.timezone)\n227         return value\n228 \n229     def convert_datefield_value(self, value, expression, connection):\n230         if isinstance(value, Database.Timestamp):\n231             value = value.date()\n232         return value\n233 \n234     def convert_timefield_value(self, value, expression, connection):\n235         if isinstance(value, Database.Timestamp):\n236             value = value.time()\n237         return value\n238 \n239     def convert_uuidfield_value(self, value, expression, connection):\n240         if value is not None:\n241             value = uuid.UUID(value)\n242         return value\n243 \n244     @staticmethod\n245     def convert_empty_string(value, expression, connection):\n246         return '' if value is None else value\n247 \n248     @staticmethod\n249     def convert_empty_bytes(value, expression, connection):\n250         return b'' if value is None else value\n251 \n252     def deferrable_sql(self):\n253         return \" DEFERRABLE INITIALLY DEFERRED\"\n254 \n255     def fetch_returned_insert_columns(self, cursor, returning_params):\n256         columns = []\n257         for param in returning_params:\n258             value = param.get_value()\n259             if value is None or value == []:\n260                 # cx_Oracle < 6.3 returns None, >= 6.3 returns empty list.\n261                 raise DatabaseError(\n262                     'The database did not return a new row id. Probably '\n263                     '\"ORA-1403: no data found\" was raised internally but was '\n264                     'hidden by the Oracle OCI library (see '\n265                     'https://code.djangoproject.com/ticket/28859).'\n266                 )\n267             # cx_Oracle < 7 returns value, >= 7 returns list with single value.\n268             columns.append(value[0] if isinstance(value, list) else value)\n269         return tuple(columns)\n270 \n271     def field_cast_sql(self, db_type, internal_type):\n272         if db_type and db_type.endswith('LOB'):\n273             return \"DBMS_LOB.SUBSTR(%s)\"\n274         else:\n275             return \"%s\"\n276 \n277     def no_limit_value(self):\n278         return None\n279 \n280     def limit_offset_sql(self, low_mark, high_mark):\n281         fetch, offset = self._get_limit_offset_params(low_mark, high_mark)\n282         return ' '.join(sql for sql in (\n283             ('OFFSET %d ROWS' % offset) if offset else None,\n284             ('FETCH FIRST %d ROWS ONLY' % fetch) if fetch else None,\n285         ) if sql)\n286 \n287     def last_executed_query(self, cursor, sql, params):\n288         # https://cx-oracle.readthedocs.io/en/latest/cursor.html#Cursor.statement\n289         # The DB API definition does not define this attribute.\n290         statement = cursor.statement\n291         # Unlike Psycopg's `query` and MySQLdb`'s `_executed`, cx_Oracle's\n292         # `statement` doesn't contain the query parameters. Substitute\n293         # parameters manually.\n294         if isinstance(params, (tuple, list)):\n295             for i, param in enumerate(params):\n296                 statement = statement.replace(':arg%d' % i, force_str(param, errors='replace'))\n297         elif isinstance(params, dict):\n298             for key, param in params.items():\n299                 statement = statement.replace(':%s' % key, force_str(param, errors='replace'))\n300         return statement\n301 \n302     def last_insert_id(self, cursor, table_name, pk_name):\n303         sq_name = self._get_sequence_name(cursor, strip_quotes(table_name), pk_name)\n304         cursor.execute('\"%s\".currval' % sq_name)\n305         return cursor.fetchone()[0]\n306 \n307     def lookup_cast(self, lookup_type, internal_type=None):\n308         if lookup_type in ('iexact', 'icontains', 'istartswith', 'iendswith'):\n309             return \"UPPER(%s)\"\n310         return \"%s\"\n311 \n312     def max_in_list_size(self):\n313         return 1000\n314 \n315     def max_name_length(self):\n316         return 30\n317 \n318     def pk_default_value(self):\n319         return \"NULL\"\n320 \n321     def prep_for_iexact_query(self, x):\n322         return x\n323 \n324     def process_clob(self, value):\n325         if value is None:\n326             return ''\n327         return value.read()\n328 \n329     def quote_name(self, name):\n330         # SQL92 requires delimited (quoted) names to be case-sensitive.  When\n331         # not quoted, Oracle has case-insensitive behavior for identifiers, but\n332         # always defaults to uppercase.\n333         # We simplify things by making Oracle identifiers always uppercase.\n334         if not name.startswith('\"') and not name.endswith('\"'):\n335             name = '\"%s\"' % truncate_name(name.upper(), self.max_name_length())\n336         # Oracle puts the query text into a (query % args) construct, so % signs\n337         # in names need to be escaped. The '%%' will be collapsed back to '%' at\n338         # that stage so we aren't really making the name longer here.\n339         name = name.replace('%', '%%')\n340         return name.upper()\n341 \n342     def random_function_sql(self):\n343         return \"DBMS_RANDOM.RANDOM\"\n344 \n345     def regex_lookup(self, lookup_type):\n346         if lookup_type == 'regex':\n347             match_option = \"'c'\"\n348         else:\n349             match_option = \"'i'\"\n350         return 'REGEXP_LIKE(%%s, %%s, %s)' % match_option\n351 \n352     def return_insert_columns(self, fields):\n353         if not fields:\n354             return '', ()\n355         field_names = []\n356         params = []\n357         for field in fields:\n358             field_names.append('%s.%s' % (\n359                 self.quote_name(field.model._meta.db_table),\n360                 self.quote_name(field.column),\n361             ))\n362             params.append(InsertVar(field))\n363         return 'RETURNING %s INTO %s' % (\n364             ', '.join(field_names),\n365             ', '.join(['%s'] * len(params)),\n366         ), tuple(params)\n367 \n368     def __foreign_key_constraints(self, table_name, recursive):\n369         with self.connection.cursor() as cursor:\n370             if recursive:\n371                 cursor.execute(\"\"\"\n372                     SELECT\n373                         user_tables.table_name, rcons.constraint_name\n374                     FROM\n375                         user_tables\n376                     JOIN\n377                         user_constraints cons\n378                         ON (user_tables.table_name = cons.table_name AND cons.constraint_type = ANY('P', 'U'))\n379                     LEFT JOIN\n380                         user_constraints rcons\n381                         ON (user_tables.table_name = rcons.table_name AND rcons.constraint_type = 'R')\n382                     START WITH user_tables.table_name = UPPER(%s)\n383                     CONNECT BY NOCYCLE PRIOR cons.constraint_name = rcons.r_constraint_name\n384                     GROUP BY\n385                         user_tables.table_name, rcons.constraint_name\n386                     HAVING user_tables.table_name != UPPER(%s)\n387                     ORDER BY MAX(level) DESC\n388                 \"\"\", (table_name, table_name))\n389             else:\n390                 cursor.execute(\"\"\"\n391                     SELECT\n392                         cons.table_name, cons.constraint_name\n393                     FROM\n394                         user_constraints cons\n395                     WHERE\n396                         cons.constraint_type = 'R'\n397                         AND cons.table_name = UPPER(%s)\n398                 \"\"\", (table_name,))\n399             return cursor.fetchall()\n400 \n401     @cached_property\n402     def _foreign_key_constraints(self):\n403         # 512 is large enough to fit the ~330 tables (as of this writing) in\n404         # Django's test suite.\n405         return lru_cache(maxsize=512)(self.__foreign_key_constraints)\n406 \n407     def sql_flush(self, style, tables, *, reset_sequences=False, allow_cascade=False):\n408         if not tables:\n409             return []\n410 \n411         truncated_tables = {table.upper() for table in tables}\n412         constraints = set()\n413         # Oracle's TRUNCATE CASCADE only works with ON DELETE CASCADE foreign\n414         # keys which Django doesn't define. Emulate the PostgreSQL behavior\n415         # which truncates all dependent tables by manually retrieving all\n416         # foreign key constraints and resolving dependencies.\n417         for table in tables:\n418             for foreign_table, constraint in self._foreign_key_constraints(table, recursive=allow_cascade):\n419                 if allow_cascade:\n420                     truncated_tables.add(foreign_table)\n421                 constraints.add((foreign_table, constraint))\n422         sql = [\n423             '%s %s %s %s %s %s %s %s;' % (\n424                 style.SQL_KEYWORD('ALTER'),\n425                 style.SQL_KEYWORD('TABLE'),\n426                 style.SQL_FIELD(self.quote_name(table)),\n427                 style.SQL_KEYWORD('DISABLE'),\n428                 style.SQL_KEYWORD('CONSTRAINT'),\n429                 style.SQL_FIELD(self.quote_name(constraint)),\n430                 style.SQL_KEYWORD('KEEP'),\n431                 style.SQL_KEYWORD('INDEX'),\n432             ) for table, constraint in constraints\n433         ] + [\n434             '%s %s %s;' % (\n435                 style.SQL_KEYWORD('TRUNCATE'),\n436                 style.SQL_KEYWORD('TABLE'),\n437                 style.SQL_FIELD(self.quote_name(table)),\n438             ) for table in truncated_tables\n439         ] + [\n440             '%s %s %s %s %s %s;' % (\n441                 style.SQL_KEYWORD('ALTER'),\n442                 style.SQL_KEYWORD('TABLE'),\n443                 style.SQL_FIELD(self.quote_name(table)),\n444                 style.SQL_KEYWORD('ENABLE'),\n445                 style.SQL_KEYWORD('CONSTRAINT'),\n446                 style.SQL_FIELD(self.quote_name(constraint)),\n447             ) for table, constraint in constraints\n448         ]\n449         if reset_sequences:\n450             sequences = [\n451                 sequence\n452                 for sequence in self.connection.introspection.sequence_list()\n453                 if sequence['table'].upper() in truncated_tables\n454             ]\n455             # Since we've just deleted all the rows, running our sequence ALTER\n456             # code will reset the sequence to 0.\n457             sql.extend(self.sequence_reset_by_name_sql(style, sequences))\n458         return sql\n459 \n460     def sequence_reset_by_name_sql(self, style, sequences):\n461         sql = []\n462         for sequence_info in sequences:\n463             no_autofield_sequence_name = self._get_no_autofield_sequence_name(sequence_info['table'])\n464             table = self.quote_name(sequence_info['table'])\n465             column = self.quote_name(sequence_info['column'] or 'id')\n466             query = self._sequence_reset_sql % {\n467                 'no_autofield_sequence_name': no_autofield_sequence_name,\n468                 'table': table,\n469                 'column': column,\n470                 'table_name': strip_quotes(table),\n471                 'column_name': strip_quotes(column),\n472             }\n473             sql.append(query)\n474         return sql\n475 \n476     def sequence_reset_sql(self, style, model_list):\n477         output = []\n478         query = self._sequence_reset_sql\n479         for model in model_list:\n480             for f in model._meta.local_fields:\n481                 if isinstance(f, AutoField):\n482                     no_autofield_sequence_name = self._get_no_autofield_sequence_name(model._meta.db_table)\n483                     table = self.quote_name(model._meta.db_table)\n484                     column = self.quote_name(f.column)\n485                     output.append(query % {\n486                         'no_autofield_sequence_name': no_autofield_sequence_name,\n487                         'table': table,\n488                         'column': column,\n489                         'table_name': strip_quotes(table),\n490                         'column_name': strip_quotes(column),\n491                     })\n492                     # Only one AutoField is allowed per model, so don't\n493                     # continue to loop\n494                     break\n495             for f in model._meta.many_to_many:\n496                 if not f.remote_field.through:\n497                     no_autofield_sequence_name = self._get_no_autofield_sequence_name(f.m2m_db_table())\n498                     table = self.quote_name(f.m2m_db_table())\n499                     column = self.quote_name('id')\n500                     output.append(query % {\n501                         'no_autofield_sequence_name': no_autofield_sequence_name,\n502                         'table': table,\n503                         'column': column,\n504                         'table_name': strip_quotes(table),\n505                         'column_name': 'ID',\n506                     })\n507         return output\n508 \n509     def start_transaction_sql(self):\n510         return ''\n511 \n512     def tablespace_sql(self, tablespace, inline=False):\n513         if inline:\n514             return \"USING INDEX TABLESPACE %s\" % self.quote_name(tablespace)\n515         else:\n516             return \"TABLESPACE %s\" % self.quote_name(tablespace)\n517 \n518     def adapt_datefield_value(self, value):\n519         \"\"\"\n520         Transform a date value to an object compatible with what is expected\n521         by the backend driver for date columns.\n522         The default implementation transforms the date to text, but that is not\n523         necessary for Oracle.\n524         \"\"\"\n525         return value\n526 \n527     def adapt_datetimefield_value(self, value):\n528         \"\"\"\n529         Transform a datetime value to an object compatible with what is expected\n530         by the backend driver for datetime columns.\n531 \n532         If naive datetime is passed assumes that is in UTC. Normally Django\n533         models.DateTimeField makes sure that if USE_TZ is True passed datetime\n534         is timezone aware.\n535         \"\"\"\n536 \n537         if value is None:\n538             return None\n539 \n540         # Expression values are adapted by the database.\n541         if hasattr(value, 'resolve_expression'):\n542             return value\n543 \n544         # cx_Oracle doesn't support tz-aware datetimes\n545         if timezone.is_aware(value):\n546             if settings.USE_TZ:\n547                 value = timezone.make_naive(value, self.connection.timezone)\n548             else:\n549                 raise ValueError(\"Oracle backend does not support timezone-aware datetimes when USE_TZ is False.\")\n550 \n551         return Oracle_datetime.from_datetime(value)\n552 \n553     def adapt_timefield_value(self, value):\n554         if value is None:\n555             return None\n556 \n557         # Expression values are adapted by the database.\n558         if hasattr(value, 'resolve_expression'):\n559             return value\n560 \n561         if isinstance(value, str):\n562             return datetime.datetime.strptime(value, '%H:%M:%S')\n563 \n564         # Oracle doesn't support tz-aware times\n565         if timezone.is_aware(value):\n566             raise ValueError(\"Oracle backend does not support timezone-aware times.\")\n567 \n568         return Oracle_datetime(1900, 1, 1, value.hour, value.minute,\n569                                value.second, value.microsecond)\n570 \n571     def combine_expression(self, connector, sub_expressions):\n572         lhs, rhs = sub_expressions\n573         if connector == '%%':\n574             return 'MOD(%s)' % ','.join(sub_expressions)\n575         elif connector == '&':\n576             return 'BITAND(%s)' % ','.join(sub_expressions)\n577         elif connector == '|':\n578             return 'BITAND(-%(lhs)s-1,%(rhs)s)+%(lhs)s' % {'lhs': lhs, 'rhs': rhs}\n579         elif connector == '<<':\n580             return '(%(lhs)s * POWER(2, %(rhs)s))' % {'lhs': lhs, 'rhs': rhs}\n581         elif connector == '>>':\n582             return 'FLOOR(%(lhs)s / POWER(2, %(rhs)s))' % {'lhs': lhs, 'rhs': rhs}\n583         elif connector == '^':\n584             return 'POWER(%s)' % ','.join(sub_expressions)\n585         elif connector == '#':\n586             raise NotSupportedError('Bitwise XOR is not supported in Oracle.')\n587         return super().combine_expression(connector, sub_expressions)\n588 \n589     def _get_no_autofield_sequence_name(self, table):\n590         \"\"\"\n591         Manually created sequence name to keep backward compatibility for\n592         AutoFields that aren't Oracle identity columns.\n593         \"\"\"\n594         name_length = self.max_name_length() - 3\n595         return '%s_SQ' % truncate_name(strip_quotes(table), name_length).upper()\n596 \n597     def _get_sequence_name(self, cursor, table, pk_name):\n598         cursor.execute(\"\"\"\n599             SELECT sequence_name\n600             FROM user_tab_identity_cols\n601             WHERE table_name = UPPER(%s)\n602             AND column_name = UPPER(%s)\"\"\", [table, pk_name])\n603         row = cursor.fetchone()\n604         return self._get_no_autofield_sequence_name(table) if row is None else row[0]\n605 \n606     def bulk_insert_sql(self, fields, placeholder_rows):\n607         query = []\n608         for row in placeholder_rows:\n609             select = []\n610             for i, placeholder in enumerate(row):\n611                 # A model without any fields has fields=[None].\n612                 if fields[i]:\n613                     internal_type = getattr(fields[i], 'target_field', fields[i]).get_internal_type()\n614                     placeholder = BulkInsertMapper.types.get(internal_type, '%s') % placeholder\n615                 # Add columns aliases to the first select to avoid \"ORA-00918:\n616                 # column ambiguously defined\" when two or more columns in the\n617                 # first select have the same value.\n618                 if not query:\n619                     placeholder = '%s col_%s' % (placeholder, i)\n620                 select.append(placeholder)\n621             query.append('SELECT %s FROM DUAL' % ', '.join(select))\n622         # Bulk insert to tables with Oracle identity columns causes Oracle to\n623         # add sequence.nextval to it. Sequence.nextval cannot be used with the\n624         # UNION operator. To prevent incorrect SQL, move UNION to a subquery.\n625         return 'SELECT * FROM (%s)' % ' UNION ALL '.join(query)\n626 \n627     def subtract_temporals(self, internal_type, lhs, rhs):\n628         if internal_type == 'DateField':\n629             lhs_sql, lhs_params = lhs\n630             rhs_sql, rhs_params = rhs\n631             params = (*lhs_params, *rhs_params)\n632             return \"NUMTODSINTERVAL(TO_NUMBER(%s - %s), 'DAY')\" % (lhs_sql, rhs_sql), params\n633         return super().subtract_temporals(internal_type, lhs, rhs)\n634 \n635     def bulk_batch_size(self, fields, objs):\n636         \"\"\"Oracle restricts the number of parameters in a query.\"\"\"\n637         if fields:\n638             return self.connection.features.max_query_params // len(fields)\n639         return len(objs)\n640 \n641     def conditional_expression_supported_in_where_clause(self, expression):\n642         \"\"\"\n643         Oracle supports only EXISTS(...) or filters in the WHERE clause, others\n644         must be compared with True.\n645         \"\"\"\n646         if isinstance(expression, (Exists, WhereNode)):\n647             return True\n648         if isinstance(expression, ExpressionWrapper) and expression.conditional:\n649             return self.conditional_expression_supported_in_where_clause(expression.expression)\n650         if isinstance(expression, RawSQL) and expression.conditional:\n651             return True\n652         return False\n",
        "intended_behavior": "Within each identified `execute_sql_flush` method across the different backends, the `using` parameter should be removed. The method's functionality should be preserved by relying on `self.connection.alias` to access the database alias internally. Ensure that all internal uses of `execute_sql_flush` are refactored to omit the previously required `using` argument, reflecting the simplification of the method's signature."
    }
]