[
    {
        "rel_file_path": "sphinx/builders/linkcheck.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/sphinx-doc__sphinx/setup_sphinx-doc__sphinx__4.1/sphinx/builders/linkcheck.py",
        "start": 1,
        "end": 665,
        "class_name": null,
        "method_name": null,
        "code": "1 \"\"\"\n2     sphinx.builders.linkcheck\n3     ~~~~~~~~~~~~~~~~~~~~~~~~~\n4 \n5     The CheckExternalLinksBuilder class.\n6 \n7     :copyright: Copyright 2007-2021 by the Sphinx team, see AUTHORS.\n8     :license: BSD, see LICENSE for details.\n9 \"\"\"\n10 \n11 import json\n12 import re\n13 import socket\n14 import time\n15 import warnings\n16 from datetime import datetime, timezone\n17 from email.utils import parsedate_to_datetime\n18 from html.parser import HTMLParser\n19 from os import path\n20 from queue import PriorityQueue, Queue\n21 from threading import Thread\n22 from typing import (Any, Dict, Generator, List, NamedTuple, Optional, Pattern, Set, Tuple,\n23                     Union, cast)\n24 from urllib.parse import unquote, urlparse\n25 \n26 from docutils import nodes\n27 from docutils.nodes import Element\n28 from requests import Response\n29 from requests.exceptions import HTTPError, TooManyRedirects\n30 \n31 from sphinx.application import Sphinx\n32 from sphinx.builders.dummy import DummyBuilder\n33 from sphinx.config import Config\n34 from sphinx.deprecation import RemovedInSphinx50Warning\n35 from sphinx.environment import BuildEnvironment\n36 from sphinx.locale import __\n37 from sphinx.transforms.post_transforms import SphinxPostTransform\n38 from sphinx.util import encode_uri, logging, requests\n39 from sphinx.util.console import darkgray, darkgreen, purple, red, turquoise  # type: ignore\n40 from sphinx.util.nodes import get_node_line\n41 \n42 logger = logging.getLogger(__name__)\n43 \n44 uri_re = re.compile('([a-z]+:)?//')  # matches to foo:// and // (a protocol relative URL)\n45 \n46 Hyperlink = NamedTuple('Hyperlink', (('uri', str),\n47                                      ('docname', str),\n48                                      ('lineno', Optional[int])))\n49 CheckRequest = NamedTuple('CheckRequest', (('next_check', float),\n50                                            ('hyperlink', Optional[Hyperlink])))\n51 CheckResult = NamedTuple('CheckResult', (('uri', str),\n52                                          ('docname', str),\n53                                          ('lineno', int),\n54                                          ('status', str),\n55                                          ('message', str),\n56                                          ('code', int)))\n57 RateLimit = NamedTuple('RateLimit', (('delay', float), ('next_check', float)))\n58 \n59 # Tuple is old styled CheckRequest\n60 CheckRequestType = Union[CheckRequest, Tuple[float, str, str, int]]\n61 \n62 DEFAULT_REQUEST_HEADERS = {\n63     'Accept': 'text/html,application/xhtml+xml;q=0.9,*/*;q=0.8',\n64 }\n65 CHECK_IMMEDIATELY = 0\n66 QUEUE_POLL_SECS = 1\n67 DEFAULT_DELAY = 60.0\n68 \n69 \n70 def node_line_or_0(node: Element) -> int:\n71     \"\"\"\n72     PriorityQueue items must be comparable. The line number is part of the\n73     tuple used by the PriorityQueue, keep an homogeneous type for comparison.\n74     \"\"\"\n75     warnings.warn('node_line_or_0() is deprecated.',\n76                   RemovedInSphinx50Warning, stacklevel=2)\n77     return get_node_line(node) or 0\n78 \n79 \n80 class AnchorCheckParser(HTMLParser):\n81     \"\"\"Specialized HTML parser that looks for a specific anchor.\"\"\"\n82 \n83     def __init__(self, search_anchor: str) -> None:\n84         super().__init__()\n85 \n86         self.search_anchor = search_anchor\n87         self.found = False\n88 \n89     def handle_starttag(self, tag: Any, attrs: Any) -> None:\n90         for key, value in attrs:\n91             if key in ('id', 'name') and value == self.search_anchor:\n92                 self.found = True\n93                 break\n94 \n95 \n96 def check_anchor(response: requests.requests.Response, anchor: str) -> bool:\n97     \"\"\"Reads HTML data from a response object `response` searching for `anchor`.\n98     Returns True if anchor was found, False otherwise.\n99     \"\"\"\n100     parser = AnchorCheckParser(anchor)\n101     # Read file in chunks. If we find a matching anchor, we break\n102     # the loop early in hopes not to have to download the whole thing.\n103     for chunk in response.iter_content(chunk_size=4096, decode_unicode=True):\n104         if isinstance(chunk, bytes):    # requests failed to decode\n105             chunk = chunk.decode()      # manually try to decode it\n106 \n107         parser.feed(chunk)\n108         if parser.found:\n109             break\n110     parser.close()\n111     return parser.found\n112 \n113 \n114 class CheckExternalLinksBuilder(DummyBuilder):\n115     \"\"\"\n116     Checks for broken external links.\n117     \"\"\"\n118     name = 'linkcheck'\n119     epilog = __('Look for any errors in the above output or in '\n120                 '%(outdir)s/output.txt')\n121 \n122     def init(self) -> None:\n123         self.hyperlinks: Dict[str, Hyperlink] = {}\n124         self._good: Set[str] = set()\n125         self._broken: Dict[str, str] = {}\n126         self._redirected: Dict[str, Tuple[str, int]] = {}\n127         # set a timeout for non-responding servers\n128         socket.setdefaulttimeout(5.0)\n129 \n130         # create queues and worker threads\n131         self._wqueue: PriorityQueue[CheckRequestType] = PriorityQueue()\n132         self._rqueue: Queue[CheckResult] = Queue()\n133 \n134     @property\n135     def anchors_ignore(self) -> List[Pattern]:\n136         warnings.warn(\n137             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"anchors_ignore\"),\n138             RemovedInSphinx50Warning,\n139             stacklevel=2,\n140         )\n141         return [re.compile(x) for x in self.config.linkcheck_anchors_ignore]\n142 \n143     @property\n144     def auth(self) -> List[Tuple[Pattern, Any]]:\n145         warnings.warn(\n146             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"auth\"),\n147             RemovedInSphinx50Warning,\n148             stacklevel=2,\n149         )\n150         return [(re.compile(pattern), auth_info) for pattern, auth_info\n151                 in self.config.linkcheck_auth]\n152 \n153     @property\n154     def to_ignore(self) -> List[Pattern]:\n155         warnings.warn(\n156             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"to_ignore\"),\n157             RemovedInSphinx50Warning,\n158             stacklevel=2,\n159         )\n160         return [re.compile(x) for x in self.config.linkcheck_ignore]\n161 \n162     @property\n163     def good(self) -> Set[str]:\n164         warnings.warn(\n165             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"good\"),\n166             RemovedInSphinx50Warning,\n167             stacklevel=2,\n168         )\n169         return self._good\n170 \n171     @property\n172     def broken(self) -> Dict[str, str]:\n173         warnings.warn(\n174             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"broken\"),\n175             RemovedInSphinx50Warning,\n176             stacklevel=2,\n177         )\n178         return self._broken\n179 \n180     @property\n181     def redirected(self) -> Dict[str, Tuple[str, int]]:\n182         warnings.warn(\n183             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"redirected\"),\n184             RemovedInSphinx50Warning,\n185             stacklevel=2,\n186         )\n187         return self._redirected\n188 \n189     def check_thread(self) -> None:\n190         warnings.warn(\n191             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"check_thread\"),\n192             RemovedInSphinx50Warning,\n193             stacklevel=2,\n194         )\n195         # do nothing.\n196 \n197     def limit_rate(self, response: Response) -> Optional[float]:\n198         warnings.warn(\n199             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"limit_rate\"),\n200             RemovedInSphinx50Warning,\n201             stacklevel=2,\n202         )\n203         worker = HyperlinkAvailabilityCheckWorker(self.env, self.config,\n204                                                   None, None, {})\n205         return worker.limit_rate(response)\n206 \n207     def rqueue(self, response: Response) -> Queue:\n208         warnings.warn(\n209             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"rqueue\"),\n210             RemovedInSphinx50Warning,\n211             stacklevel=2,\n212         )\n213         return self._rqueue\n214 \n215     def workers(self, response: Response) -> List[Thread]:\n216         warnings.warn(\n217             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"workers\"),\n218             RemovedInSphinx50Warning,\n219             stacklevel=2,\n220         )\n221         return []\n222 \n223     def wqueue(self, response: Response) -> Queue:\n224         warnings.warn(\n225             \"%s.%s is deprecated.\" % (self.__class__.__name__, \"wqueue\"),\n226             RemovedInSphinx50Warning,\n227             stacklevel=2,\n228         )\n229         return self._wqueue\n230 \n231     def process_result(self, result: CheckResult) -> None:\n232         filename = self.env.doc2path(result.docname, None)\n233 \n234         linkstat = dict(filename=filename, lineno=result.lineno,\n235                         status=result.status, code=result.code, uri=result.uri,\n236                         info=result.message)\n237         self.write_linkstat(linkstat)\n238 \n239         if result.status == 'unchecked':\n240             return\n241         if result.status == 'working' and result.message == 'old':\n242             return\n243         if result.lineno:\n244             logger.info('(%16s: line %4d) ', result.docname, result.lineno, nonl=True)\n245         if result.status == 'ignored':\n246             if result.message:\n247                 logger.info(darkgray('-ignored- ') + result.uri + ': ' + result.message)\n248             else:\n249                 logger.info(darkgray('-ignored- ') + result.uri)\n250         elif result.status == 'local':\n251             logger.info(darkgray('-local-   ') + result.uri)\n252             self.write_entry('local', result.docname, filename, result.lineno, result.uri)\n253         elif result.status == 'working':\n254             logger.info(darkgreen('ok        ') + result.uri + result.message)\n255         elif result.status == 'broken':\n256             if self.app.quiet or self.app.warningiserror:\n257                 logger.warning(__('broken link: %s (%s)'), result.uri, result.message,\n258                                location=(filename, result.lineno))\n259             else:\n260                 logger.info(red('broken    ') + result.uri + red(' - ' + result.message))\n261             self.write_entry('broken', result.docname, filename, result.lineno,\n262                              result.uri + ': ' + result.message)\n263         elif result.status == 'redirected':\n264             try:\n265                 text, color = {\n266                     301: ('permanently', purple),\n267                     302: ('with Found', purple),\n268                     303: ('with See Other', purple),\n269                     307: ('temporarily', turquoise),\n270                     308: ('permanently', purple),\n271                 }[result.code]\n272             except KeyError:\n273                 text, color = ('with unknown code', purple)\n274             linkstat['text'] = text\n275             logger.info(color('redirect  ') + result.uri +\n276                         color(' - ' + text + ' to ' + result.message))\n277             self.write_entry('redirected ' + text, result.docname, filename,\n278                              result.lineno, result.uri + ' to ' + result.message)\n279         else:\n280             raise ValueError(\"Unknown status %s.\" % result.status)\n281 \n282     def write_entry(self, what: str, docname: str, filename: str, line: int,\n283                     uri: str) -> None:\n284         self.txt_outfile.write(\"%s:%s: [%s] %s\\n\" % (filename, line, what, uri))\n285 \n286     def write_linkstat(self, data: dict) -> None:\n287         self.json_outfile.write(json.dumps(data))\n288         self.json_outfile.write('\\n')\n289 \n290     def finish(self) -> None:\n291         checker = HyperlinkAvailabilityChecker(self.env, self.config, self)\n292         logger.info('')\n293 \n294         with open(path.join(self.outdir, 'output.txt'), 'w') as self.txt_outfile,\\\n295              open(path.join(self.outdir, 'output.json'), 'w') as self.json_outfile:\n296             for result in checker.check(self.hyperlinks):\n297                 self.process_result(result)\n298 \n299         if self._broken:\n300             self.app.statuscode = 1\n301 \n302 \n303 class HyperlinkAvailabilityChecker:\n304     def __init__(self, env: BuildEnvironment, config: Config,\n305                  builder: CheckExternalLinksBuilder = None) -> None:\n306         # Warning: builder argument will be removed in the sphinx-5.0.\n307         # Don't use it from extensions.\n308         # tag: RemovedInSphinx50Warning\n309         self.builder = builder\n310         self.config = config\n311         self.env = env\n312         self.rate_limits: Dict[str, RateLimit] = {}\n313         self.workers: List[Thread] = []\n314 \n315         self.to_ignore = [re.compile(x) for x in self.config.linkcheck_ignore]\n316 \n317         if builder:\n318             self.rqueue = builder._rqueue\n319             self.wqueue = builder._wqueue\n320         else:\n321             self.rqueue = Queue()\n322             self.wqueue = PriorityQueue()\n323 \n324     def invoke_threads(self) -> None:\n325         for i in range(self.config.linkcheck_workers):\n326             thread = HyperlinkAvailabilityCheckWorker(self.env, self.config,\n327                                                       self.rqueue, self.wqueue,\n328                                                       self.rate_limits, self.builder)\n329             thread.start()\n330             self.workers.append(thread)\n331 \n332     def shutdown_threads(self) -> None:\n333         self.wqueue.join()\n334         for worker in self.workers:\n335             self.wqueue.put(CheckRequest(CHECK_IMMEDIATELY, None), False)\n336 \n337     def check(self, hyperlinks: Dict[str, Hyperlink]) -> Generator[CheckResult, None, None]:\n338         self.invoke_threads()\n339 \n340         total_links = 0\n341         for hyperlink in hyperlinks.values():\n342             if self.is_ignored_uri(hyperlink.uri):\n343                 yield CheckResult(hyperlink.uri, hyperlink.docname, hyperlink.lineno,\n344                                   'ignored', '', 0)\n345             else:\n346                 self.wqueue.put(CheckRequest(CHECK_IMMEDIATELY, hyperlink), False)\n347                 total_links += 1\n348 \n349         done = 0\n350         while done < total_links:\n351             yield self.rqueue.get()\n352             done += 1\n353 \n354         self.shutdown_threads()\n355 \n356     def is_ignored_uri(self, uri: str) -> bool:\n357         return any(pat.match(uri) for pat in self.to_ignore)\n358 \n359 \n360 class HyperlinkAvailabilityCheckWorker(Thread):\n361     \"\"\"A worker class for checking the availability of hyperlinks.\"\"\"\n362 \n363     def __init__(self, env: BuildEnvironment, config: Config, rqueue: Queue,\n364                  wqueue: Queue, rate_limits: Dict[str, RateLimit],\n365                  builder: CheckExternalLinksBuilder = None) -> None:\n366         # Warning: builder argument will be removed in the sphinx-5.0.\n367         # Don't use it from extensions.\n368         # tag: RemovedInSphinx50Warning\n369         self.config = config\n370         self.env = env\n371         self.rate_limits = rate_limits\n372         self.rqueue = rqueue\n373         self.wqueue = wqueue\n374 \n375         self.anchors_ignore = [re.compile(x)\n376                                for x in self.config.linkcheck_anchors_ignore]\n377         self.auth = [(re.compile(pattern), auth_info) for pattern, auth_info\n378                      in self.config.linkcheck_auth]\n379 \n380         if builder:\n381             # if given, fill the result of checks as cache\n382             self._good = builder._good\n383             self._broken = builder._broken\n384             self._redirected = builder._redirected\n385         else:\n386             # only for compatibility. Will be removed in Sphinx-5.0\n387             self._good = set()\n388             self._broken = {}\n389             self._redirected = {}\n390 \n391         super().__init__(daemon=True)\n392 \n393     def run(self) -> None:\n394         kwargs = {}\n395         if self.config.linkcheck_timeout:\n396             kwargs['timeout'] = self.config.linkcheck_timeout\n397 \n398         def get_request_headers() -> Dict:\n399             url = urlparse(uri)\n400             candidates = [\"%s://%s\" % (url.scheme, url.netloc),\n401                           \"%s://%s/\" % (url.scheme, url.netloc),\n402                           uri,\n403                           \"*\"]\n404 \n405             for u in candidates:\n406                 if u in self.config.linkcheck_request_headers:\n407                     headers = dict(DEFAULT_REQUEST_HEADERS)\n408                     headers.update(self.config.linkcheck_request_headers[u])\n409                     return headers\n410 \n411             return {}\n412 \n413         def check_uri() -> Tuple[str, str, int]:\n414             # split off anchor\n415             if '#' in uri:\n416                 req_url, anchor = uri.split('#', 1)\n417                 for rex in self.anchors_ignore:\n418                     if rex.match(anchor):\n419                         anchor = None\n420                         break\n421             else:\n422                 req_url = uri\n423                 anchor = None\n424 \n425             # handle non-ASCII URIs\n426             try:\n427                 req_url.encode('ascii')\n428             except UnicodeError:\n429                 req_url = encode_uri(req_url)\n430 \n431             # Get auth info, if any\n432             for pattern, auth_info in self.auth:\n433                 if pattern.match(uri):\n434                     break\n435             else:\n436                 auth_info = None\n437 \n438             # update request headers for the URL\n439             kwargs['headers'] = get_request_headers()\n440 \n441             try:\n442                 if anchor and self.config.linkcheck_anchors:\n443                     # Read the whole document and see if #anchor exists\n444                     response = requests.get(req_url, stream=True, config=self.config,\n445                                             auth=auth_info, **kwargs)\n446                     response.raise_for_status()\n447                     found = check_anchor(response, unquote(anchor))\n448 \n449                     if not found:\n450                         raise Exception(__(\"Anchor '%s' not found\") % anchor)\n451                 else:\n452                     try:\n453                         # try a HEAD request first, which should be easier on\n454                         # the server and the network\n455                         response = requests.head(req_url, allow_redirects=True,\n456                                                  config=self.config, auth=auth_info,\n457                                                  **kwargs)\n458                         response.raise_for_status()\n459                     except (HTTPError, TooManyRedirects) as err:\n460                         if isinstance(err, HTTPError) and err.response.status_code == 429:\n461                             raise\n462                         # retry with GET request if that fails, some servers\n463                         # don't like HEAD requests.\n464                         response = requests.get(req_url, stream=True,\n465                                                 config=self.config,\n466                                                 auth=auth_info, **kwargs)\n467                         response.raise_for_status()\n468             except HTTPError as err:\n469                 if err.response.status_code == 401:\n470                     # We'll take \"Unauthorized\" as working.\n471                     return 'working', ' - unauthorized', 0\n472                 elif err.response.status_code == 429:\n473                     next_check = self.limit_rate(err.response)\n474                     if next_check is not None:\n475                         self.wqueue.put(CheckRequest(next_check, hyperlink), False)\n476                         return 'rate-limited', '', 0\n477                     return 'broken', str(err), 0\n478                 elif err.response.status_code == 503:\n479                     # We'll take \"Service Unavailable\" as ignored.\n480                     return 'ignored', str(err), 0\n481                 else:\n482                     return 'broken', str(err), 0\n483             except Exception as err:\n484                 return 'broken', str(err), 0\n485             else:\n486                 netloc = urlparse(req_url).netloc\n487                 try:\n488                     del self.rate_limits[netloc]\n489                 except KeyError:\n490                     pass\n491             if response.url.rstrip('/') == req_url.rstrip('/'):\n492                 return 'working', '', 0\n493             else:\n494                 new_url = response.url\n495                 if anchor:\n496                     new_url += '#' + anchor\n497                 # history contains any redirects, get last\n498                 if response.history:\n499                     code = response.history[-1].status_code\n500                     return 'redirected', new_url, code\n501                 else:\n502                     return 'redirected', new_url, 0\n503 \n504         def check(docname: str) -> Tuple[str, str, int]:\n505             # check for various conditions without bothering the network\n506             if len(uri) == 0 or uri.startswith(('#', 'mailto:', 'tel:')):\n507                 return 'unchecked', '', 0\n508             elif not uri.startswith(('http:', 'https:')):\n509                 if uri_re.match(uri):\n510                     # non supported URI schemes (ex. ftp)\n511                     return 'unchecked', '', 0\n512                 else:\n513                     srcdir = path.dirname(self.env.doc2path(docname))\n514                     if path.exists(path.join(srcdir, uri)):\n515                         return 'working', '', 0\n516                     else:\n517                         self._broken[uri] = ''\n518                         return 'broken', '', 0\n519             elif uri in self._good:\n520                 return 'working', 'old', 0\n521             elif uri in self._broken:\n522                 return 'broken', self._broken[uri], 0\n523             elif uri in self._redirected:\n524                 return 'redirected', self._redirected[uri][0], self._redirected[uri][1]\n525 \n526             # need to actually check the URI\n527             for _ in range(self.config.linkcheck_retries):\n528                 status, info, code = check_uri()\n529                 if status != \"broken\":\n530                     break\n531 \n532             if status == \"working\":\n533                 self._good.add(uri)\n534             elif status == \"broken\":\n535                 self._broken[uri] = info\n536             elif status == \"redirected\":\n537                 self._redirected[uri] = (info, code)\n538 \n539             return (status, info, code)\n540 \n541         while True:\n542             check_request = self.wqueue.get()\n543             try:\n544                 next_check, hyperlink = check_request\n545                 if hyperlink is None:\n546                     break\n547 \n548                 uri, docname, lineno = hyperlink\n549             except ValueError:\n550                 # old styled check_request (will be deprecated in Sphinx-5.0)\n551                 next_check, uri, docname, lineno = check_request\n552 \n553             if uri is None:\n554                 break\n555             netloc = urlparse(uri).netloc\n556             try:\n557                 # Refresh rate limit.\n558                 # When there are many links in the queue, workers are all stuck waiting\n559                 # for responses, but the builder keeps queuing. Links in the queue may\n560                 # have been queued before rate limits were discovered.\n561                 next_check = self.rate_limits[netloc].next_check\n562             except KeyError:\n563                 pass\n564             if next_check > time.time():\n565                 # Sleep before putting message back in the queue to avoid\n566                 # waking up other threads.\n567                 time.sleep(QUEUE_POLL_SECS)\n568                 self.wqueue.put(CheckRequest(next_check, hyperlink), False)\n569                 self.wqueue.task_done()\n570                 continue\n571             status, info, code = check(docname)\n572             if status == 'rate-limited':\n573                 logger.info(darkgray('-rate limited-   ') + uri + darkgray(' | sleeping...'))\n574             else:\n575                 self.rqueue.put(CheckResult(uri, docname, lineno, status, info, code))\n576             self.wqueue.task_done()\n577 \n578     def limit_rate(self, response: Response) -> Optional[float]:\n579         next_check = None\n580         retry_after = response.headers.get(\"Retry-After\")\n581         if retry_after:\n582             try:\n583                 # Integer: time to wait before next attempt.\n584                 delay = float(retry_after)\n585             except ValueError:\n586                 try:\n587                     # An HTTP-date: time of next attempt.\n588                     until = parsedate_to_datetime(retry_after)\n589                 except (TypeError, ValueError):\n590                     # TypeError: Invalid date format.\n591                     # ValueError: Invalid date, e.g. Oct 52th.\n592                     pass\n593                 else:\n594                     next_check = datetime.timestamp(until)\n595                     delay = (until - datetime.now(timezone.utc)).total_seconds()\n596             else:\n597                 next_check = time.time() + delay\n598         netloc = urlparse(response.url).netloc\n599         if next_check is None:\n600             max_delay = self.config.linkcheck_rate_limit_timeout\n601             try:\n602                 rate_limit = self.rate_limits[netloc]\n603             except KeyError:\n604                 delay = DEFAULT_DELAY\n605             else:\n606                 last_wait_time = rate_limit.delay\n607                 delay = 2.0 * last_wait_time\n608                 if delay > max_delay and last_wait_time < max_delay:\n609                     delay = max_delay\n610             if delay > max_delay:\n611                 return None\n612             next_check = time.time() + delay\n613         self.rate_limits[netloc] = RateLimit(delay, next_check)\n614         return next_check\n615 \n616 \n617 class HyperlinkCollector(SphinxPostTransform):\n618     builders = ('linkcheck',)\n619     default_priority = 800\n620 \n621     def run(self, **kwargs: Any) -> None:\n622         builder = cast(CheckExternalLinksBuilder, self.app.builder)\n623         hyperlinks = builder.hyperlinks\n624 \n625         # reference nodes\n626         for refnode in self.document.traverse(nodes.reference):\n627             if 'refuri' not in refnode:\n628                 continue\n629             uri = refnode['refuri']\n630             lineno = get_node_line(refnode)\n631             uri_info = Hyperlink(uri, self.env.docname, lineno)\n632             if uri not in hyperlinks:\n633                 hyperlinks[uri] = uri_info\n634 \n635         # image nodes\n636         for imgnode in self.document.traverse(nodes.image):\n637             uri = imgnode['candidates'].get('?')\n638             if uri and '://' in uri:\n639                 lineno = get_node_line(imgnode)\n640                 uri_info = Hyperlink(uri, self.env.docname, lineno)\n641                 if uri not in hyperlinks:\n642                     hyperlinks[uri] = uri_info\n643 \n644 \n645 def setup(app: Sphinx) -> Dict[str, Any]:\n646     app.add_builder(CheckExternalLinksBuilder)\n647     app.add_post_transform(HyperlinkCollector)\n648 \n649     app.add_config_value('linkcheck_ignore', [], None)\n650     app.add_config_value('linkcheck_auth', [], None)\n651     app.add_config_value('linkcheck_request_headers', {}, None)\n652     app.add_config_value('linkcheck_retries', 1, None)\n653     app.add_config_value('linkcheck_timeout', None, None, [int])\n654     app.add_config_value('linkcheck_workers', 5, None)\n655     app.add_config_value('linkcheck_anchors', True, None)\n656     # Anchors starting with ! are ignored since they are\n657     # commonly used for dynamic pages\n658     app.add_config_value('linkcheck_anchors_ignore', [\"^!\"], None)\n659     app.add_config_value('linkcheck_rate_limit_timeout', 300.0, None)\n660 \n661     return {\n662         'version': 'builtin',\n663         'parallel_read_safe': True,\n664         'parallel_write_safe': True,\n665     }\n",
        "intended_behavior": "The code within `linkcheck.py` should correctly handle anchor parsing and matching in a way that is compatible with both GitHub's way of rendering reStructuredText documents (adding `user-content-` prefix to anchors) and traditional anchor naming. This implies the linkchecker logic should be robust enough to recognize and validate anchors in URLs regardless of whether they include the `user-content-` prefix or not. The existing functionality of checking links and anchors for correctness should be preserved while expanding its capability to understand and validate GitHub-specific anchor transformations. This could involve adding a pre-validation step or a normalization process for anchors before attempting to match them with targets in the checked document, ensuring compatibility with GitHub's anchor naming conventions without affecting its ability to validate other types of links and anchors."
    }
]