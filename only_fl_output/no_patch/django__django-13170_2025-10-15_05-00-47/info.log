2025-10-15 05:00:48.148 | INFO     | Starting overall retry 0 with model gpt-4-0125-preview
2025-10-15 05:00:52.250 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=235, output_tokens=12, cost=0.002710
2025-10-15 05:01:08.854 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=415, output_tokens=645, cost=0.023500
2025-10-15 05:01:10.034 | INFO     | registered non reproducing test 0
2025-10-15 05:01:26.296 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=1594, output_tokens=660, cost=0.035740
2025-10-15 05:01:27.438 | INFO     | registered non reproducing test 1
2025-10-15 05:01:42.941 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=1611, output_tokens=695, cost=0.036960
2025-10-15 05:01:44.098 | INFO     | registered non reproducing test 2
2025-10-15 05:01:44.098 | WARNING  | Failed to write a reproducer test; skipping reproducer tracing
2025-10-15 05:01:44.105 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-15 05:01:53.751 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=536, output_tokens=375, cost=0.016610
2025-10-15 05:01:53.761 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-15 05:01:56.731 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=729, output_tokens=62, cost=0.009150
2025-10-15 05:01:56.733 | DEBUG    | Extracted a valid json.
2025-10-15 05:01:56.733 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_class(\"FilteredRelation\")",
        "search_method_in_class(\"__init__\", \"FilteredRelation\")",
        "search_code(\"FilteredRelation\")",
        "search_code(\"doesn't support nested relations\")"
    ],
    "bug_locations": []
}
2025-10-15 05:01:56.808 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-15 05:01:56.809 | DEBUG    | <Agent search> Analyzing search results.
2025-10-15 05:02:15.987 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=1421, output_tokens=857, cost=0.039920
2025-10-15 05:02:15.996 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-15 05:02:24.251 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=2494, output_tokens=311, cost=0.034270
2025-10-15 05:02:24.255 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-15 05:02:32.152 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=665, output_tokens=312, cost=0.016010
2025-10-15 05:02:32.153 | DEBUG    | Extracted a valid json.
2025-10-15 05:02:32.153 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [],
    "bug_locations":[
        {
            "file": "django/db/models/query_utils.py", 
            "class": "FilteredRelation", 
            "method": "", 
            "intended_behavior": "The `FilteredRelation` class should be extended to accurately parse and validate nested relations in its `condition` parameter. This might involve modifying the `__init__` method or adding new methods to handle the complexity of nested queries. The validation logic should be updated to not only accept `Q` objects but also correctly interpret nested fields within those `Q` objects. The enhancement should ensure that nested conditions are transformed into the appropriate SQL JOIN operations, preserving the existing functionality for non-nested conditions."
        }, 
        {
            "file": "django/db/models/sql/query.py", 
            "class": "", 
            "method": "", 
            "intended_behavior": "The methods responsible for constructing SQL queries from `FilteredRelation` objects, particularly those dealing with the `condition` attribute, should be adapted to support nested relations. This might involve the `build_filter` method or other related methods that compile `Q` objects into SQL. The code at this location should ensure that when a `FilteredRelation` includes a nested relation condition, the generated SQL correctly reflects the nested JOIN operations needed to implement such a query. This includes appropriately handling aliases for tables to avoid conflicts and ensuring that the conditions specified in the nested `Q` objects are applied correctly to the resulting SQL."
        }
    ]
}
2025-10-15 05:02:32.170 | DEBUG    | Bug location extracted successfully: [<file>django/db/models/query_utils.py</file>
<class>FilteredRelation</class>
<method>None</method>
<code>
312 class FilteredRelation:
313     """Specify custom filtering in the ON clause of SQL joins."""
314 
315     def __init__(self, relation_name, *, condition=Q()):
316         if not relation_name:
317             raise ValueError('relation_name cannot be empty.')
318         self.relation_name = relation_name
319         self.alias = None
320         if not isinstance(condition, Q):
321             raise ValueError('condition argument must be a Q() instance.')
322         self.condition = condition
323         self.path = []
324 
325     def __eq__(self, other):
326         if not isinstance(other, self.__class__):
327             return NotImplemented
328         return (
329             self.relation_name == other.relation_name and
330             self.alias == other.alias and
331             self.condition == other.condition
332         )
333 
334     def clone(self):
335         clone = FilteredRelation(self.relation_name, condition=self.condition)
336         clone.alias = self.alias
337         clone.path = self.path[:]
338         return clone
339 
340     def resolve_expression(self, *args, **kwargs):
341         """
342         QuerySet.annotate() only accepts expression-like arguments
343         (with a resolve_expression() method).
344         """
345         raise NotImplementedError('FilteredRelation.resolve_expression() is unused.')
346 
347     def as_sql(self, compiler, connection):
348         # Resolve the condition in Join.filtered_relation.
349         query = compiler.query
350         where = query.build_filtered_relation_q(self.condition, reuse=set(self.path))
351         return compiler.compile(where)

</code><intended_behavior>The `FilteredRelation` class should be extended to accurately parse and validate nested relations in its `condition` parameter. This might involve modifying the `__init__` method or adding new methods to handle the complexity of nested queries. The validation logic should be updated to not only accept `Q` objects but also correctly interpret nested fields within those `Q` objects. The enhancement should ensure that nested conditions are transformed into the appropriate SQL JOIN operations, preserving the existing functionality for non-nested conditions.</intended_behavior>, <file>django/db/models/sql/query.py</file>
<class>None</class>
<method>None</method>
<code>
1 """
2 Create SQL statements for QuerySets.
3 
4 The code in here encapsulates all of the SQL construction so that QuerySets
5 themselves do not have to (and could be backed by things other than SQL
6 databases). The abstraction barrier only works one way: this module has to know
7 all about the internals of models in order to get the information it needs.
8 """
9 import copy
10 import difflib
11 import functools
12 import inspect
13 import sys
14 import warnings
15 from collections import Counter, namedtuple
16 from collections.abc import Iterator, Mapping
17 from itertools import chain, count, product
18 from string import ascii_uppercase
19 
20 from django.core.exceptions import (
21     EmptyResultSet, FieldDoesNotExist, FieldError,
22 )
23 from django.db import DEFAULT_DB_ALIAS, NotSupportedError, connections
24 from django.db.models.aggregates import Count
25 from django.db.models.constants import LOOKUP_SEP
26 from django.db.models.expressions import BaseExpression, Col, F, OuterRef, Ref
27 from django.db.models.fields import Field
28 from django.db.models.fields.related_lookups import MultiColSource
29 from django.db.models.lookups import Lookup
30 from django.db.models.query_utils import (
31     Q, check_rel_lookup_compatibility, refs_expression,
32 )
33 from django.db.models.sql.constants import INNER, LOUTER, ORDER_DIR, SINGLE
34 from django.db.models.sql.datastructures import (
35     BaseTable, Empty, Join, MultiJoin,
36 )
37 from django.db.models.sql.where import (
38     AND, OR, ExtraWhere, NothingNode, WhereNode,
39 )
40 from django.utils.deprecation import RemovedInDjango40Warning
41 from django.utils.functional import cached_property
42 from django.utils.tree import Node
43 
44 __all__ = ['Query', 'RawQuery']
45 
46 
47 def get_field_names_from_opts(opts):
48     return set(chain.from_iterable(
49         (f.name, f.attname) if f.concrete else (f.name,)
50         for f in opts.get_fields()
51     ))
52 
53 
54 def get_children_from_q(q):
55     for child in q.children:
56         if isinstance(child, Node):
57             yield from get_children_from_q(child)
58         else:
59             yield child
60 
61 
62 JoinInfo = namedtuple(
63     'JoinInfo',
64     ('final_field', 'targets', 'opts', 'joins', 'path', 'transform_function')
65 )
66 
67 
68 class RawQuery:
69     """A single raw SQL query."""
70 
71     def __init__(self, sql, using, params=None):
72         self.params = params or ()
73         self.sql = sql
74         self.using = using
75         self.cursor = None
76 
77         # Mirror some properties of a normal query so that
78         # the compiler can be used to process results.
79         self.low_mark, self.high_mark = 0, None  # Used for offset/limit
80         self.extra_select = {}
81         self.annotation_select = {}
82 
83     def chain(self, using):
84         return self.clone(using)
85 
86     def clone(self, using):
87         return RawQuery(self.sql, using, params=self.params)
88 
89     def get_columns(self):
90         if self.cursor is None:
91             self._execute_query()
92         converter = connections[self.using].introspection.identifier_converter
93         return [converter(column_meta[0])
94                 for column_meta in self.cursor.description]
95 
96     def __iter__(self):
97         # Always execute a new query for a new iterator.
98         # This could be optimized with a cache at the expense of RAM.
99         self._execute_query()
100         if not connections[self.using].features.can_use_chunked_reads:
101             # If the database can't use chunked reads we need to make sure we
102             # evaluate the entire query up front.
103             result = list(self.cursor)
104         else:
105             result = self.cursor
106         return iter(result)
107 
108     def __repr__(self):
109         return "<%s: %s>" % (self.__class__.__name__, self)
110 
111     @property
112     def params_type(self):
113         return dict if isinstance(self.params, Mapping) else tuple
114 
115     def __str__(self):
116         return self.sql % self.params_type(self.params)
117 
118     def _execute_query(self):
119         connection = connections[self.using]
120 
121         # Adapt parameters to the database, as much as possible considering
122         # that the target type isn't known. See #17755.
123         params_type = self.params_type
124         adapter = connection.ops.adapt_unknown_value
125         if params_type is tuple:
126             params = tuple(adapter(val) for val in self.params)
127         elif params_type is dict:
128             params = {key: adapter(val) for key, val in self.params.items()}
129         else:
130             raise RuntimeError("Unexpected params type: %s" % params_type)
131 
132         self.cursor = connection.cursor()
133         self.cursor.execute(self.sql, params)
134 
135 
136 class Query(BaseExpression):
137     """A single SQL query."""
138 
139     alias_prefix = 'T'
140     subq_aliases = frozenset([alias_prefix])
141 
142     compiler = 'SQLCompiler'
143 
144     def __init__(self, model, where=WhereNode, alias_cols=True):
145         self.model = model
146         self.alias_refcount = {}
147         # alias_map is the most important data structure regarding joins.
148         # It's used for recording which joins exist in the query and what
149         # types they are. The key is the alias of the joined table (possibly
150         # the table name) and the value is a Join-like object (see
151         # sql.datastructures.Join for more information).
152         self.alias_map = {}
153         # Whether to provide alias to columns during reference resolving.
154         self.alias_cols = alias_cols
155         # Sometimes the query contains references to aliases in outer queries (as
156         # a result of split_exclude). Correct alias quoting needs to know these
157         # aliases too.
158         # Map external tables to whether they are aliased.
159         self.external_aliases = {}
160         self.table_map = {}     # Maps table names to list of aliases.
161         self.default_cols = True
162         self.default_ordering = True
163         self.standard_ordering = True
164         self.used_aliases = set()
165         self.filter_is_sticky = False
166         self.subquery = False
167 
168         # SQL-related attributes
169         # Select and related select clauses are expressions to use in the
170         # SELECT clause of the query.
171         # The select is used for cases where we want to set up the select
172         # clause to contain other than default fields (values(), subqueries...)
173         # Note that annotations go to annotations dictionary.
174         self.select = ()
175         self.where = where()
176         self.where_class = where
177         # The group_by attribute can have one of the following forms:
178         #  - None: no group by at all in the query
179         #  - A tuple of expressions: group by (at least) those expressions.
180         #    String refs are also allowed for now.
181         #  - True: group by all select fields of the model
182         # See compiler.get_group_by() for details.
183         self.group_by = None
184         self.order_by = ()
185         self.low_mark, self.high_mark = 0, None  # Used for offset/limit
186         self.distinct = False
187         self.distinct_fields = ()
188         self.select_for_update = False
189         self.select_for_update_nowait = False
190         self.select_for_update_skip_locked = False
191         self.select_for_update_of = ()
192         self.select_for_no_key_update = False
193 
194         self.select_related = False
195         # Arbitrary limit for select_related to prevents infinite recursion.
196         self.max_depth = 5
197 
198         # Holds the selects defined by a call to values() or values_list()
199         # excluding annotation_select and extra_select.
200         self.values_select = ()
201 
202         # SQL annotation-related attributes
203         self.annotations = {}  # Maps alias -> Annotation Expression
204         self.annotation_select_mask = None
205         self._annotation_select_cache = None
206 
207         # Set combination attributes
208         self.combinator = None
209         self.combinator_all = False
210         self.combined_queries = ()
211 
212         # These are for extensions. The contents are more or less appended
213         # verbatim to the appropriate clause.
214         self.extra = {}  # Maps col_alias -> (col_sql, params).
215         self.extra_select_mask = None
216         self._extra_select_cache = None
217 
218         self.extra_tables = ()
219         self.extra_order_by = ()
220 
221         # A tuple that is a set of model field names and either True, if these
222         # are the fields to defer, or False if these are the only fields to
223         # load.
224         self.deferred_loading = (frozenset(), True)
225 
226         self._filtered_relations = {}
227 
228         self.explain_query = False
229         self.explain_format = None
230         self.explain_options = {}
231 
232     @property
233     def output_field(self):
234         if len(self.select) == 1:
235             select = self.select[0]
236             return getattr(select, 'target', None) or select.field
237         elif len(self.annotation_select) == 1:
238             return next(iter(self.annotation_select.values())).output_field
239 
240     @property
241     def has_select_fields(self):
242         return bool(self.select or self.annotation_select_mask or self.extra_select_mask)
243 
244     @cached_property
245     def base_table(self):
246         for alias in self.alias_map:
247             return alias
248 
249     def __str__(self):
250         """
251         Return the query as a string of SQL with the parameter values
252         substituted in (use sql_with_params() to see the unsubstituted string).
253 
254         Parameter values won't necessarily be quoted correctly, since that is
255         done by the database interface at execution time.
256         """
257         sql, params = self.sql_with_params()
258         return sql % params
259 
260     def sql_with_params(self):
261         """
262         Return the query as an SQL string and the parameters that will be
263         substituted into the query.
264         """
265         return self.get_compiler(DEFAULT_DB_ALIAS).as_sql()
266 
267     def __deepcopy__(self, memo):
268         """Limit the amount of work when a Query is deepcopied."""
269         result = self.clone()
270         memo[id(self)] = result
271         return result
272 
273     def get_compiler(self, using=None, connection=None):
274         if using is None and connection is None:
275             raise ValueError("Need either using or connection")
276         if using:
277             connection = connections[using]
278         return connection.ops.compiler(self.compiler)(self, connection, using)
279 
280     def get_meta(self):
281         """
282         Return the Options instance (the model._meta) from which to start
283         processing. Normally, this is self.model._meta, but it can be changed
284         by subclasses.
285         """
286         return self.model._meta
287 
288     def clone(self):
289         """
290         Return a copy of the current Query. A lightweight alternative to
291         to deepcopy().
292         """
293         obj = Empty()
294         obj.__class__ = self.__class__
295         # Copy references to everything.
296         obj.__dict__ = self.__dict__.copy()
297         # Clone attributes that can't use shallow copy.
298         obj.alias_refcount = self.alias_refcount.copy()
299         obj.alias_map = self.alias_map.copy()
300         obj.external_aliases = self.external_aliases.copy()
301         obj.table_map = self.table_map.copy()
302         obj.where = self.where.clone()
303         obj.annotations = self.annotations.copy()
304         if self.annotation_select_mask is None:
305             obj.annotation_select_mask = None
306         else:
307             obj.annotation_select_mask = self.annotation_select_mask.copy()
308         obj.combined_queries = tuple(query.clone() for query in self.combined_queries)
309         # _annotation_select_cache cannot be copied, as doing so breaks the
310         # (necessary) state in which both annotations and
311         # _annotation_select_cache point to the same underlying objects.
312         # It will get re-populated in the cloned queryset the next time it's
313         # used.
314         obj._annotation_select_cache = None
315         obj.extra = self.extra.copy()
316         if self.extra_select_mask is None:
317             obj.extra_select_mask = None
318         else:
319             obj.extra_select_mask = self.extra_select_mask.copy()
320         if self._extra_select_cache is None:
321             obj._extra_select_cache = None
322         else:
323             obj._extra_select_cache = self._extra_select_cache.copy()
324         if self.select_related is not False:
325             # Use deepcopy because select_related stores fields in nested
326             # dicts.
327             obj.select_related = copy.deepcopy(obj.select_related)
328         if 'subq_aliases' in self.__dict__:
329             obj.subq_aliases = self.subq_aliases.copy()
330         obj.used_aliases = self.used_aliases.copy()
331         obj._filtered_relations = self._filtered_relations.copy()
332         # Clear the cached_property
333         try:
334             del obj.base_table
335         except AttributeError:
336             pass
337         return obj
338 
339     def chain(self, klass=None):
340         """
341         Return a copy of the current Query that's ready for another operation.
342         The klass argument changes the type of the Query, e.g. UpdateQuery.
343         """
344         obj = self.clone()
345         if klass and obj.__class__ != klass:
346             obj.__class__ = klass
347         if not obj.filter_is_sticky:
348             obj.used_aliases = set()
349         obj.filter_is_sticky = False
350         if hasattr(obj, '_setup_query'):
351             obj._setup_query()
352         return obj
353 
354     def relabeled_clone(self, change_map):
355         clone = self.clone()
356         clone.change_aliases(change_map)
357         return clone
358 
359     def _get_col(self, target, field, alias):
360         if not self.alias_cols:
361             alias = None
362         return target.get_col(alias, field)
363 
364     def rewrite_cols(self, annotation, col_cnt):
365         # We must make sure the inner query has the referred columns in it.
366         # If we are aggregating over an annotation, then Django uses Ref()
367         # instances to note this. However, if we are annotating over a column
368         # of a related model, then it might be that column isn't part of the
369         # SELECT clause of the inner query, and we must manually make sure
370         # the column is selected. An example case is:
371         #    .aggregate(Sum('author__awards'))
372         # Resolving this expression results in a join to author, but there
373         # is no guarantee the awards column of author is in the select clause
374         # of the query. Thus we must manually add the column to the inner
375         # query.
376         orig_exprs = annotation.get_source_expressions()
377         new_exprs = []
378         for expr in orig_exprs:
379             # FIXME: These conditions are fairly arbitrary. Identify a better
380             # method of having expressions decide which code path they should
381             # take.
382             if isinstance(expr, Ref):
383                 # Its already a Ref to subquery (see resolve_ref() for
384                 # details)
385                 new_exprs.append(expr)
386             elif isinstance(expr, (WhereNode, Lookup)):
387                 # Decompose the subexpressions further. The code here is
388                 # copied from the else clause, but this condition must appear
389                 # before the contains_aggregate/is_summary condition below.
390                 new_expr, col_cnt = self.rewrite_cols(expr, col_cnt)
391                 new_exprs.append(new_expr)
392             else:
393                 # Reuse aliases of expressions already selected in subquery.
394                 for col_alias, selected_annotation in self.annotation_select.items():
395                     if selected_annotation is expr:
396                         new_expr = Ref(col_alias, expr)
397                         break
398                 else:
399                     # An expression that is not selected the subquery.
400                     if isinstance(expr, Col) or (expr.contains_aggregate and not expr.is_summary):
401                         # Reference column or another aggregate. Select it
402                         # under a non-conflicting alias.
403                         col_cnt += 1
404                         col_alias = '__col%d' % col_cnt
405                         self.annotations[col_alias] = expr
406                         self.append_annotation_mask([col_alias])
407                         new_expr = Ref(col_alias, expr)
408                     else:
409                         # Some other expression not referencing database values
410                         # directly. Its subexpression might contain Cols.
411                         new_expr, col_cnt = self.rewrite_cols(expr, col_cnt)
412                 new_exprs.append(new_expr)
413         annotation.set_source_expressions(new_exprs)
414         return annotation, col_cnt
415 
416     def get_aggregation(self, using, added_aggregate_names):
417         """
418         Return the dictionary with the values of the existing aggregations.
419         """
420         if not self.annotation_select:
421             return {}
422         existing_annotations = [
423             annotation for alias, annotation
424             in self.annotations.items()
425             if alias not in added_aggregate_names
426         ]
427         # Decide if we need to use a subquery.
428         #
429         # Existing annotations would cause incorrect results as get_aggregation()
430         # must produce just one result and thus must not use GROUP BY. But we
431         # aren't smart enough to remove the existing annotations from the
432         # query, so those would force us to use GROUP BY.
433         #
434         # If the query has limit or distinct, or uses set operations, then
435         # those operations must be done in a subquery so that the query
436         # aggregates on the limit and/or distinct results instead of applying
437         # the distinct and limit after the aggregation.
438         if (isinstance(self.group_by, tuple) or self.is_sliced or existing_annotations or
439                 self.distinct or self.combinator):
440             from django.db.models.sql.subqueries import AggregateQuery
441             outer_query = AggregateQuery(self.model)
442             inner_query = self.clone()
443             inner_query.select_for_update = False
444             inner_query.select_related = False
445             inner_query.set_annotation_mask(self.annotation_select)
446             if not self.is_sliced and not self.distinct_fields:
447                 # Queries with distinct_fields need ordering and when a limit
448                 # is applied we must take the slice from the ordered query.
449                 # Otherwise no need for ordering.
450                 inner_query.clear_ordering(True)
451             if not inner_query.distinct:
452                 # If the inner query uses default select and it has some
453                 # aggregate annotations, then we must make sure the inner
454                 # query is grouped by the main model's primary key. However,
455                 # clearing the select clause can alter results if distinct is
456                 # used.
457                 has_existing_aggregate_annotations = any(
458                     annotation for annotation in existing_annotations
459                     if getattr(annotation, 'contains_aggregate', True)
460                 )
461                 if inner_query.default_cols and has_existing_aggregate_annotations:
462                     inner_query.group_by = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)
463                 inner_query.default_cols = False
464 
465             relabels = {t: 'subquery' for t in inner_query.alias_map}
466             relabels[None] = 'subquery'
467             # Remove any aggregates marked for reduction from the subquery
468             # and move them to the outer AggregateQuery.
469             col_cnt = 0
470             for alias, expression in list(inner_query.annotation_select.items()):
471                 annotation_select_mask = inner_query.annotation_select_mask
472                 if expression.is_summary:
473                     expression, col_cnt = inner_query.rewrite_cols(expression, col_cnt)
474                     outer_query.annotations[alias] = expression.relabeled_clone(relabels)
475                     del inner_query.annotations[alias]
476                     annotation_select_mask.remove(alias)
477                 # Make sure the annotation_select wont use cached results.
478                 inner_query.set_annotation_mask(inner_query.annotation_select_mask)
479             if inner_query.select == () and not inner_query.default_cols and not inner_query.annotation_select_mask:
480                 # In case of Model.objects[0:3].count(), there would be no
481                 # field selected in the inner query, yet we must use a subquery.
482                 # So, make sure at least one field is selected.
483                 inner_query.select = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)
484             try:
485                 outer_query.add_subquery(inner_query, using)
486             except EmptyResultSet:
487                 return {
488                     alias: None
489                     for alias in outer_query.annotation_select
490                 }
491         else:
492             outer_query = self
493             self.select = ()
494             self.default_cols = False
495             self.extra = {}
496 
497         outer_query.clear_ordering(True)
498         outer_query.clear_limits()
499         outer_query.select_for_update = False
500         outer_query.select_related = False
501         compiler = outer_query.get_compiler(using)
502         result = compiler.execute_sql(SINGLE)
503         if result is None:
504             result = [None] * len(outer_query.annotation_select)
505 
506         converters = compiler.get_converters(outer_query.annotation_select.values())
507         result = next(compiler.apply_converters((result,), converters))
508 
509         return dict(zip(outer_query.annotation_select, result))
510 
511     def get_count(self, using):
512         """
513         Perform a COUNT() query using the current filter constraints.
514         """
515         obj = self.clone()
516         obj.add_annotation(Count('*'), alias='__count', is_summary=True)
517         number = obj.get_aggregation(using, ['__count'])['__count']
518         if number is None:
519             number = 0
520         return number
521 
522     def has_filters(self):
523         return self.where
524 
525     def has_results(self, using):
526         q = self.clone()
527         if not q.distinct:
528             if q.group_by is True:
529                 q.add_fields((f.attname for f in self.model._meta.concrete_fields), False)
530                 # Disable GROUP BY aliases to avoid orphaning references to the
531                 # SELECT clause which is about to be cleared.
532                 q.set_group_by(allow_aliases=False)
533             q.clear_select_clause()
534         q.clear_ordering(True)
535         q.set_limits(high=1)
536         compiler = q.get_compiler(using=using)
537         return compiler.has_results()
538 
539     def explain(self, using, format=None, **options):
540         q = self.clone()
541         q.explain_query = True
542         q.explain_format = format
543         q.explain_options = options
544         compiler = q.get_compiler(using=using)
545         return '\n'.join(compiler.explain_query())
546 
547     def combine(self, rhs, connector):
548         """
549         Merge the 'rhs' query into the current one (with any 'rhs' effects
550         being applied *after* (that is, "to the right of") anything in the
551         current query. 'rhs' is not modified during a call to this function.
552 
553         The 'connector' parameter describes how to connect filters from the
554         'rhs' query.
555         """
556         assert self.model == rhs.model, \
557             "Cannot combine queries on two different base models."
558         assert not self.is_sliced, \
559             "Cannot combine queries once a slice has been taken."
560         assert self.distinct == rhs.distinct, \
561             "Cannot combine a unique query with a non-unique query."
562         assert self.distinct_fields == rhs.distinct_fields, \
563             "Cannot combine queries with different distinct fields."
564 
565         # Work out how to relabel the rhs aliases, if necessary.
566         change_map = {}
567         conjunction = (connector == AND)
568 
569         # Determine which existing joins can be reused. When combining the
570         # query with AND we must recreate all joins for m2m filters. When
571         # combining with OR we can reuse joins. The reason is that in AND
572         # case a single row can't fulfill a condition like:
573         #     revrel__col=1 & revrel__col=2
574         # But, there might be two different related rows matching this
575         # condition. In OR case a single True is enough, so single row is
576         # enough, too.
577         #
578         # Note that we will be creating duplicate joins for non-m2m joins in
579         # the AND case. The results will be correct but this creates too many
580         # joins. This is something that could be fixed later on.
581         reuse = set() if conjunction else set(self.alias_map)
582         # Base table must be present in the query - this is the same
583         # table on both sides.
584         self.get_initial_alias()
585         joinpromoter = JoinPromoter(connector, 2, False)
586         joinpromoter.add_votes(
587             j for j in self.alias_map if self.alias_map[j].join_type == INNER)
588         rhs_votes = set()
589         # Now, add the joins from rhs query into the new query (skipping base
590         # table).
591         rhs_tables = list(rhs.alias_map)[1:]
592         for alias in rhs_tables:
593             join = rhs.alias_map[alias]
594             # If the left side of the join was already relabeled, use the
595             # updated alias.
596             join = join.relabeled_clone(change_map)
597             new_alias = self.join(join, reuse=reuse)
598             if join.join_type == INNER:
599                 rhs_votes.add(new_alias)
600             # We can't reuse the same join again in the query. If we have two
601             # distinct joins for the same connection in rhs query, then the
602             # combined query must have two joins, too.
603             reuse.discard(new_alias)
604             if alias != new_alias:
605                 change_map[alias] = new_alias
606             if not rhs.alias_refcount[alias]:
607                 # The alias was unused in the rhs query. Unref it so that it
608                 # will be unused in the new query, too. We have to add and
609                 # unref the alias so that join promotion has information of
610                 # the join type for the unused alias.
611                 self.unref_alias(new_alias)
612         joinpromoter.add_votes(rhs_votes)
613         joinpromoter.update_join_types(self)
614 
615         # Now relabel a copy of the rhs where-clause and add it to the current
616         # one.
617         w = rhs.where.clone()
618         w.relabel_aliases(change_map)
619         self.where.add(w, connector)
620 
621         # Selection columns and extra extensions are those provided by 'rhs'.
622         if rhs.select:
623             self.set_select([col.relabeled_clone(change_map) for col in rhs.select])
624         else:
625             self.select = ()
626 
627         if connector == OR:
628             # It would be nice to be able to handle this, but the queries don't
629             # really make sense (or return consistent value sets). Not worth
630             # the extra complexity when you can write a real query instead.
631             if self.extra and rhs.extra:
632                 raise ValueError("When merging querysets using 'or', you cannot have extra(select=...) on both sides.")
633         self.extra.update(rhs.extra)
634         extra_select_mask = set()
635         if self.extra_select_mask is not None:
636             extra_select_mask.update(self.extra_select_mask)
637         if rhs.extra_select_mask is not None:
638             extra_select_mask.update(rhs.extra_select_mask)
639         if extra_select_mask:
640             self.set_extra_mask(extra_select_mask)
641         self.extra_tables += rhs.extra_tables
642 
643         # Ordering uses the 'rhs' ordering, unless it has none, in which case
644         # the current ordering is used.
645         self.order_by = rhs.order_by or self.order_by
646         self.extra_order_by = rhs.extra_order_by or self.extra_order_by
647 
648     def deferred_to_data(self, target, callback):
649         """
650         Convert the self.deferred_loading data structure to an alternate data
651         structure, describing the field that *will* be loaded. This is used to
652         compute the columns to select from the database and also by the
653         QuerySet class to work out which fields are being initialized on each
654         model. Models that have all their fields included aren't mentioned in
655         the result, only those that have field restrictions in place.
656 
657         The "target" parameter is the instance that is populated (in place).
658         The "callback" is a function that is called whenever a (model, field)
659         pair need to be added to "target". It accepts three parameters:
660         "target", and the model and list of fields being added for that model.
661         """
662         field_names, defer = self.deferred_loading
663         if not field_names:
664             return
665         orig_opts = self.get_meta()
666         seen = {}
667         must_include = {orig_opts.concrete_model: {orig_opts.pk}}
668         for field_name in field_names:
669             parts = field_name.split(LOOKUP_SEP)
670             cur_model = self.model._meta.concrete_model
671             opts = orig_opts
672             for name in parts[:-1]:
673                 old_model = cur_model
674                 if name in self._filtered_relations:
675                     name = self._filtered_relations[name].relation_name
676                 source = opts.get_field(name)
677                 if is_reverse_o2o(source):
678                     cur_model = source.related_model
679                 else:
680                     cur_model = source.remote_field.model
681                 opts = cur_model._meta
682                 # Even if we're "just passing through" this model, we must add
683                 # both the current model's pk and the related reference field
684                 # (if it's not a reverse relation) to the things we select.
685                 if not is_reverse_o2o(source):
686                     must_include[old_model].add(source)
687                 add_to_dict(must_include, cur_model, opts.pk)
688             field = opts.get_field(parts[-1])
689             is_reverse_object = field.auto_created and not field.concrete
690             model = field.related_model if is_reverse_object else field.model
691             model = model._meta.concrete_model
692             if model == opts.model:
693                 model = cur_model
694             if not is_reverse_o2o(field):
695                 add_to_dict(seen, model, field)
696 
697         if defer:
698             # We need to load all fields for each model, except those that
699             # appear in "seen" (for all models that appear in "seen"). The only
700             # slight complexity here is handling fields that exist on parent
701             # models.
702             workset = {}
703             for model, values in seen.items():
704                 for field in model._meta.local_fields:
705                     if field not in values:
706                         m = field.model._meta.concrete_model
707                         add_to_dict(workset, m, field)
708             for model, values in must_include.items():
709                 # If we haven't included a model in workset, we don't add the
710                 # corresponding must_include fields for that model, since an
711                 # empty set means "include all fields". That's why there's no
712                 # "else" branch here.
713                 if model in workset:
714                     workset[model].update(values)
715             for model, values in workset.items():
716                 callback(target, model, values)
717         else:
718             for model, values in must_include.items():
719                 if model in seen:
720                     seen[model].update(values)
721                 else:
722                     # As we've passed through this model, but not explicitly
723                     # included any fields, we have to make sure it's mentioned
724                     # so that only the "must include" fields are pulled in.
725                     seen[model] = values
726             # Now ensure that every model in the inheritance chain is mentioned
727             # in the parent list. Again, it must be mentioned to ensure that
728             # only "must include" fields are pulled in.
729             for model in orig_opts.get_parent_list():
730                 seen.setdefault(model, set())
731             for model, values in seen.items():
732                 callback(target, model, values)
733 
734     def table_alias(self, table_name, create=False, filtered_relation=None):
735         """
736         Return a table alias for the given table_name and whether this is a
737         new alias or not.
738 
739         If 'create' is true, a new alias is always created. Otherwise, the
740         most recently created alias for the table (if one exists) is reused.
741         """
742         alias_list = self.table_map.get(table_name)
743         if not create and alias_list:
744             alias = alias_list[0]
745             self.alias_refcount[alias] += 1
746             return alias, False
747 
748         # Create a new alias for this table.
749         if alias_list:
750             alias = '%s%d' % (self.alias_prefix, len(self.alias_map) + 1)
751             alias_list.append(alias)
752         else:
753             # The first occurrence of a table uses the table name directly.
754             alias = filtered_relation.alias if filtered_relation is not None else table_name
755             self.table_map[table_name] = [alias]
756         self.alias_refcount[alias] = 1
757         return alias, True
758 
759     def ref_alias(self, alias):
760         """Increases the reference count for this alias."""
761         self.alias_refcount[alias] += 1
762 
763     def unref_alias(self, alias, amount=1):
764         """Decreases the reference count for this alias."""
765         self.alias_refcount[alias] -= amount
766 
767     def promote_joins(self, aliases):
768         """
769         Promote recursively the join type of given aliases and its children to
770         an outer join. If 'unconditional' is False, only promote the join if
771         it is nullable or the parent join is an outer join.
772 
773         The children promotion is done to avoid join chains that contain a LOUTER
774         b INNER c. So, if we have currently a INNER b INNER c and a->b is promoted,
775         then we must also promote b->c automatically, or otherwise the promotion
776         of a->b doesn't actually change anything in the query results.
777         """
778         aliases = list(aliases)
779         while aliases:
780             alias = aliases.pop(0)
781             if self.alias_map[alias].join_type is None:
782                 # This is the base table (first FROM entry) - this table
783                 # isn't really joined at all in the query, so we should not
784                 # alter its join type.
785                 continue
786             # Only the first alias (skipped above) should have None join_type
787             assert self.alias_map[alias].join_type is not None
788             parent_alias = self.alias_map[alias].parent_alias
789             parent_louter = parent_alias and self.alias_map[parent_alias].join_type == LOUTER
790             already_louter = self.alias_map[alias].join_type == LOUTER
791             if ((self.alias_map[alias].nullable or parent_louter) and
792                     not already_louter):
793                 self.alias_map[alias] = self.alias_map[alias].promote()
794                 # Join type of 'alias' changed, so re-examine all aliases that
795                 # refer to this one.
796                 aliases.extend(
797                     join for join in self.alias_map
798                     if self.alias_map[join].parent_alias == alias and join not in aliases
799                 )
800 
801     def demote_joins(self, aliases):
802         """
803         Change join type from LOUTER to INNER for all joins in aliases.
804 
805         Similarly to promote_joins(), this method must ensure no join chains
806         containing first an outer, then an inner join are generated. If we
807         are demoting b->c join in chain a LOUTER b LOUTER c then we must
808         demote a->b automatically, or otherwise the demotion of b->c doesn't
809         actually change anything in the query results. .
810         """
811         aliases = list(aliases)
812         while aliases:
813             alias = aliases.pop(0)
814             if self.alias_map[alias].join_type == LOUTER:
815                 self.alias_map[alias] = self.alias_map[alias].demote()
816                 parent_alias = self.alias_map[alias].parent_alias
817                 if self.alias_map[parent_alias].join_type == INNER:
818                     aliases.append(parent_alias)
819 
820     def reset_refcounts(self, to_counts):
821         """
822         Reset reference counts for aliases so that they match the value passed
823         in `to_counts`.
824         """
825         for alias, cur_refcount in self.alias_refcount.copy().items():
826             unref_amount = cur_refcount - to_counts.get(alias, 0)
827             self.unref_alias(alias, unref_amount)
828 
829     def change_aliases(self, change_map):
830         """
831         Change the aliases in change_map (which maps old-alias -> new-alias),
832         relabelling any references to them in select columns and the where
833         clause.
834         """
835         assert set(change_map).isdisjoint(change_map.values())
836 
837         # 1. Update references in "select" (normal columns plus aliases),
838         # "group by" and "where".
839         self.where.relabel_aliases(change_map)
840         if isinstance(self.group_by, tuple):
841             self.group_by = tuple([col.relabeled_clone(change_map) for col in self.group_by])
842         self.select = tuple([col.relabeled_clone(change_map) for col in self.select])
843         self.annotations = self.annotations and {
844             key: col.relabeled_clone(change_map) for key, col in self.annotations.items()
845         }
846 
847         # 2. Rename the alias in the internal table/alias datastructures.
848         for old_alias, new_alias in change_map.items():
849             if old_alias not in self.alias_map:
850                 continue
851             alias_data = self.alias_map[old_alias].relabeled_clone(change_map)
852             self.alias_map[new_alias] = alias_data
853             self.alias_refcount[new_alias] = self.alias_refcount[old_alias]
854             del self.alias_refcount[old_alias]
855             del self.alias_map[old_alias]
856 
857             table_aliases = self.table_map[alias_data.table_name]
858             for pos, alias in enumerate(table_aliases):
859                 if alias == old_alias:
860                     table_aliases[pos] = new_alias
861                     break
862         self.external_aliases = {
863             # Table is aliased or it's being changed and thus is aliased.
864             change_map.get(alias, alias): (aliased or alias in change_map)
865             for alias, aliased in self.external_aliases.items()
866         }
867 
868     def bump_prefix(self, outer_query):
869         """
870         Change the alias prefix to the next letter in the alphabet in a way
871         that the outer query's aliases and this query's aliases will not
872         conflict. Even tables that previously had no alias will get an alias
873         after this call.
874         """
875         def prefix_gen():
876             """
877             Generate a sequence of characters in alphabetical order:
878                 -> 'A', 'B', 'C', ...
879 
880             When the alphabet is finished, the sequence will continue with the
881             Cartesian product:
882                 -> 'AA', 'AB', 'AC', ...
883             """
884             alphabet = ascii_uppercase
885             prefix = chr(ord(self.alias_prefix) + 1)
886             yield prefix
887             for n in count(1):
888                 seq = alphabet[alphabet.index(prefix):] if prefix else alphabet
889                 for s in product(seq, repeat=n):
890                     yield ''.join(s)
891                 prefix = None
892 
893         if self.alias_prefix != outer_query.alias_prefix:
894             # No clashes between self and outer query should be possible.
895             return
896 
897         # Explicitly avoid infinite loop. The constant divider is based on how
898         # much depth recursive subquery references add to the stack. This value
899         # might need to be adjusted when adding or removing function calls from
900         # the code path in charge of performing these operations.
901         local_recursion_limit = sys.getrecursionlimit() // 16
902         for pos, prefix in enumerate(prefix_gen()):
903             if prefix not in self.subq_aliases:
904                 self.alias_prefix = prefix
905                 break
906             if pos > local_recursion_limit:
907                 raise RecursionError(
908                     'Maximum recursion depth exceeded: too many subqueries.'
909                 )
910         self.subq_aliases = self.subq_aliases.union([self.alias_prefix])
911         outer_query.subq_aliases = outer_query.subq_aliases.union(self.subq_aliases)
912         self.change_aliases({
913             alias: '%s%d' % (self.alias_prefix, pos)
914             for pos, alias in enumerate(self.alias_map)
915         })
916 
917     def get_initial_alias(self):
918         """
919         Return the first alias for this query, after increasing its reference
920         count.
921         """
922         if self.alias_map:
923             alias = self.base_table
924             self.ref_alias(alias)
925         else:
926             alias = self.join(BaseTable(self.get_meta().db_table, None))
927         return alias
928 
929     def count_active_tables(self):
930         """
931         Return the number of tables in this query with a non-zero reference
932         count. After execution, the reference counts are zeroed, so tables
933         added in compiler will not be seen by this method.
934         """
935         return len([1 for count in self.alias_refcount.values() if count])
936 
937     def join(self, join, reuse=None, reuse_with_filtered_relation=False):
938         """
939         Return an alias for the 'join', either reusing an existing alias for
940         that join or creating a new one. 'join' is either a
941         sql.datastructures.BaseTable or Join.
942 
943         The 'reuse' parameter can be either None which means all joins are
944         reusable, or it can be a set containing the aliases that can be reused.
945 
946         The 'reuse_with_filtered_relation' parameter is used when computing
947         FilteredRelation instances.
948 
949         A join is always created as LOUTER if the lhs alias is LOUTER to make
950         sure chains like t1 LOUTER t2 INNER t3 aren't generated. All new
951         joins are created as LOUTER if the join is nullable.
952         """
953         if reuse_with_filtered_relation and reuse:
954             reuse_aliases = [
955                 a for a, j in self.alias_map.items()
956                 if a in reuse and j.equals(join, with_filtered_relation=False)
957             ]
958         else:
959             reuse_aliases = [
960                 a for a, j in self.alias_map.items()
961                 if (reuse is None or a in reuse) and j == join
962             ]
963         if reuse_aliases:
964             if join.table_alias in reuse_aliases:
965                 reuse_alias = join.table_alias
966             else:
967                 # Reuse the most recent alias of the joined table
968                 # (a many-to-many relation may be joined multiple times).
969                 reuse_alias = reuse_aliases[-1]
970             self.ref_alias(reuse_alias)
971             return reuse_alias
972 
973         # No reuse is possible, so we need a new alias.
974         alias, _ = self.table_alias(join.table_name, create=True, filtered_relation=join.filtered_relation)
975         if join.join_type:
976             if self.alias_map[join.parent_alias].join_type == LOUTER or join.nullable:
977                 join_type = LOUTER
978             else:
979                 join_type = INNER
980             join.join_type = join_type
981         join.table_alias = alias
982         self.alias_map[alias] = join
983         return alias
984 
985     def join_parent_model(self, opts, model, alias, seen):
986         """
987         Make sure the given 'model' is joined in the query. If 'model' isn't
988         a parent of 'opts' or if it is None this method is a no-op.
989 
990         The 'alias' is the root alias for starting the join, 'seen' is a dict
991         of model -> alias of existing joins. It must also contain a mapping
992         of None -> some alias. This will be returned in the no-op case.
993         """
994         if model in seen:
995             return seen[model]
996         chain = opts.get_base_chain(model)
997         if not chain:
998             return alias
999         curr_opts = opts
1000         for int_model in chain:
1001             if int_model in seen:
1002                 curr_opts = int_model._meta
1003                 alias = seen[int_model]
1004                 continue
1005             # Proxy model have elements in base chain
1006             # with no parents, assign the new options
1007             # object and skip to the next base in that
1008             # case
1009             if not curr_opts.parents[int_model]:
1010                 curr_opts = int_model._meta
1011                 continue
1012             link_field = curr_opts.get_ancestor_link(int_model)
1013             join_info = self.setup_joins([link_field.name], curr_opts, alias)
1014             curr_opts = int_model._meta
1015             alias = seen[int_model] = join_info.joins[-1]
1016         return alias or seen[None]
1017 
1018     def add_annotation(self, annotation, alias, is_summary=False):
1019         """Add a single annotation expression to the Query."""
1020         annotation = annotation.resolve_expression(self, allow_joins=True, reuse=None,
1021                                                    summarize=is_summary)
1022         self.append_annotation_mask([alias])
1023         self.annotations[alias] = annotation
1024 
1025     def resolve_expression(self, query, *args, **kwargs):
1026         clone = self.clone()
1027         # Subqueries need to use a different set of aliases than the outer query.
1028         clone.bump_prefix(query)
1029         clone.subquery = True
1030         # It's safe to drop ordering if the queryset isn't using slicing,
1031         # distinct(*fields) or select_for_update().
1032         if (self.low_mark == 0 and self.high_mark is None and
1033                 not self.distinct_fields and
1034                 not self.select_for_update):
1035             clone.clear_ordering(True)
1036         clone.where.resolve_expression(query, *args, **kwargs)
1037         for key, value in clone.annotations.items():
1038             resolved = value.resolve_expression(query, *args, **kwargs)
1039             if hasattr(resolved, 'external_aliases'):
1040                 resolved.external_aliases.update(clone.external_aliases)
1041             clone.annotations[key] = resolved
1042         # Outer query's aliases are considered external.
1043         for alias, table in query.alias_map.items():
1044             clone.external_aliases[alias] = (
1045                 (isinstance(table, Join) and table.join_field.related_model._meta.db_table != alias) or
1046                 (isinstance(table, BaseTable) and table.table_name != table.table_alias)
1047             )
1048         return clone
1049 
1050     def get_external_cols(self):
1051         exprs = chain(self.annotations.values(), self.where.children)
1052         return [
1053             col for col in self._gen_cols(exprs)
1054             if col.alias in self.external_aliases
1055         ]
1056 
1057     def as_sql(self, compiler, connection):
1058         sql, params = self.get_compiler(connection=connection).as_sql()
1059         if self.subquery:
1060             sql = '(%s)' % sql
1061         return sql, params
1062 
1063     def resolve_lookup_value(self, value, can_reuse, allow_joins):
1064         if hasattr(value, 'resolve_expression'):
1065             value = value.resolve_expression(
1066                 self, reuse=can_reuse, allow_joins=allow_joins,
1067             )
1068         elif isinstance(value, (list, tuple)):
1069             # The items of the iterable may be expressions and therefore need
1070             # to be resolved independently.
1071             return type(value)(
1072                 self.resolve_lookup_value(sub_value, can_reuse, allow_joins)
1073                 for sub_value in value
1074             )
1075         return value
1076 
1077     def solve_lookup_type(self, lookup):
1078         """
1079         Solve the lookup type from the lookup (e.g.: 'foobar__id__icontains').
1080         """
1081         lookup_splitted = lookup.split(LOOKUP_SEP)
1082         if self.annotations:
1083             expression, expression_lookups = refs_expression(lookup_splitted, self.annotations)
1084             if expression:
1085                 return expression_lookups, (), expression
1086         _, field, _, lookup_parts = self.names_to_path(lookup_splitted, self.get_meta())
1087         field_parts = lookup_splitted[0:len(lookup_splitted) - len(lookup_parts)]
1088         if len(lookup_parts) > 1 and not field_parts:
1089             raise FieldError(
1090                 'Invalid lookup "%s" for model %s".' %
1091                 (lookup, self.get_meta().model.__name__)
1092             )
1093         return lookup_parts, field_parts, False
1094 
1095     def check_query_object_type(self, value, opts, field):
1096         """
1097         Check whether the object passed while querying is of the correct type.
1098         If not, raise a ValueError specifying the wrong object.
1099         """
1100         if hasattr(value, '_meta'):
1101             if not check_rel_lookup_compatibility(value._meta.model, opts, field):
1102                 raise ValueError(
1103                     'Cannot query "%s": Must be "%s" instance.' %
1104                     (value, opts.object_name))
1105 
1106     def check_related_objects(self, field, value, opts):
1107         """Check the type of object passed to query relations."""
1108         if field.is_relation:
1109             # Check that the field and the queryset use the same model in a
1110             # query like .filter(author=Author.objects.all()). For example, the
1111             # opts would be Author's (from the author field) and value.model
1112             # would be Author.objects.all() queryset's .model (Author also).
1113             # The field is the related field on the lhs side.
1114             if (isinstance(value, Query) and not value.has_select_fields and
1115                     not check_rel_lookup_compatibility(value.model, opts, field)):
1116                 raise ValueError(
1117                     'Cannot use QuerySet for "%s": Use a QuerySet for "%s".' %
1118                     (value.model._meta.object_name, opts.object_name)
1119                 )
1120             elif hasattr(value, '_meta'):
1121                 self.check_query_object_type(value, opts, field)
1122             elif hasattr(value, '__iter__'):
1123                 for v in value:
1124                     self.check_query_object_type(v, opts, field)
1125 
1126     def check_filterable(self, expression):
1127         """Raise an error if expression cannot be used in a WHERE clause."""
1128         if (
1129             hasattr(expression, 'resolve_expression') and
1130             not getattr(expression, 'filterable', True)
1131         ):
1132             raise NotSupportedError(
1133                 expression.__class__.__name__ + ' is disallowed in the filter '
1134                 'clause.'
1135             )
1136         if hasattr(expression, 'get_source_expressions'):
1137             for expr in expression.get_source_expressions():
1138                 self.check_filterable(expr)
1139 
1140     def build_lookup(self, lookups, lhs, rhs):
1141         """
1142         Try to extract transforms and lookup from given lhs.
1143 
1144         The lhs value is something that works like SQLExpression.
1145         The rhs value is what the lookup is going to compare against.
1146         The lookups is a list of names to extract using get_lookup()
1147         and get_transform().
1148         """
1149         # __exact is the default lookup if one isn't given.
1150         *transforms, lookup_name = lookups or ['exact']
1151         for name in transforms:
1152             lhs = self.try_transform(lhs, name)
1153         # First try get_lookup() so that the lookup takes precedence if the lhs
1154         # supports both transform and lookup for the name.
1155         lookup_class = lhs.get_lookup(lookup_name)
1156         if not lookup_class:
1157             if lhs.field.is_relation:
1158                 raise FieldError('Related Field got invalid lookup: {}'.format(lookup_name))
1159             # A lookup wasn't found. Try to interpret the name as a transform
1160             # and do an Exact lookup against it.
1161             lhs = self.try_transform(lhs, lookup_name)
1162             lookup_name = 'exact'
1163             lookup_class = lhs.get_lookup(lookup_name)
1164             if not lookup_class:
1165                 return
1166 
1167         lookup = lookup_class(lhs, rhs)
1168         # Interpret '__exact=None' as the sql 'is NULL'; otherwise, reject all
1169         # uses of None as a query value unless the lookup supports it.
1170         if lookup.rhs is None and not lookup.can_use_none_as_rhs:
1171             if lookup_name not in ('exact', 'iexact'):
1172                 raise ValueError("Cannot use None as a query value")
1173             return lhs.get_lookup('isnull')(lhs, True)
1174 
1175         # For Oracle '' is equivalent to null. The check must be done at this
1176         # stage because join promotion can't be done in the compiler. Using
1177         # DEFAULT_DB_ALIAS isn't nice but it's the best that can be done here.
1178         # A similar thing is done in is_nullable(), too.
1179         if (connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls and
1180                 lookup_name == 'exact' and lookup.rhs == ''):
1181             return lhs.get_lookup('isnull')(lhs, True)
1182 
1183         return lookup
1184 
1185     def try_transform(self, lhs, name):
1186         """
1187         Helper method for build_lookup(). Try to fetch and initialize
1188         a transform for name parameter from lhs.
1189         """
1190         transform_class = lhs.get_transform(name)
1191         if transform_class:
1192             return transform_class(lhs)
1193         else:
1194             output_field = lhs.output_field.__class__
1195             suggested_lookups = difflib.get_close_matches(name, output_field.get_lookups())
1196             if suggested_lookups:
1197                 suggestion = ', perhaps you meant %s?' % ' or '.join(suggested_lookups)
1198             else:
1199                 suggestion = '.'
1200             raise FieldError(
1201                 "Unsupported lookup '%s' for %s or join on the field not "
1202                 "permitted%s" % (name, output_field.__name__, suggestion)
1203             )
1204 
1205     def build_filter(self, filter_expr, branch_negated=False, current_negated=False,
1206                      can_reuse=None, allow_joins=True, split_subq=True,
1207                      reuse_with_filtered_relation=False, check_filterable=True):
1208         """
1209         Build a WhereNode for a single filter clause but don't add it
1210         to this Query. Query.add_q() will then add this filter to the where
1211         Node.
1212 
1213         The 'branch_negated' tells us if the current branch contains any
1214         negations. This will be used to determine if subqueries are needed.
1215 
1216         The 'current_negated' is used to determine if the current filter is
1217         negated or not and this will be used to determine if IS NULL filtering
1218         is needed.
1219 
1220         The difference between current_negated and branch_negated is that
1221         branch_negated is set on first negation, but current_negated is
1222         flipped for each negation.
1223 
1224         Note that add_filter will not do any negating itself, that is done
1225         upper in the code by add_q().
1226 
1227         The 'can_reuse' is a set of reusable joins for multijoins.
1228 
1229         If 'reuse_with_filtered_relation' is True, then only joins in can_reuse
1230         will be reused.
1231 
1232         The method will create a filter clause that can be added to the current
1233         query. However, if the filter isn't added to the query then the caller
1234         is responsible for unreffing the joins used.
1235         """
1236         if isinstance(filter_expr, dict):
1237             raise FieldError("Cannot parse keyword query as dict")
1238         if isinstance(filter_expr, Q):
1239             return self._add_q(
1240                 filter_expr,
1241                 branch_negated=branch_negated,
1242                 current_negated=current_negated,
1243                 used_aliases=can_reuse,
1244                 allow_joins=allow_joins,
1245                 split_subq=split_subq,
1246                 check_filterable=check_filterable,
1247             )
1248         if hasattr(filter_expr, 'resolve_expression'):
1249             if not getattr(filter_expr, 'conditional', False):
1250                 raise TypeError('Cannot filter against a non-conditional expression.')
1251             condition = self.build_lookup(
1252                 ['exact'], filter_expr.resolve_expression(self, allow_joins=allow_joins), True
1253             )
1254             clause = self.where_class()
1255             clause.add(condition, AND)
1256             return clause, []
1257         arg, value = filter_expr
1258         if not arg:
1259             raise FieldError("Cannot parse keyword query %r" % arg)
1260         lookups, parts, reffed_expression = self.solve_lookup_type(arg)
1261 
1262         if check_filterable:
1263             self.check_filterable(reffed_expression)
1264 
1265         if not allow_joins and len(parts) > 1:
1266             raise FieldError("Joined field references are not permitted in this query")
1267 
1268         pre_joins = self.alias_refcount.copy()
1269         value = self.resolve_lookup_value(value, can_reuse, allow_joins)
1270         used_joins = {k for k, v in self.alias_refcount.items() if v > pre_joins.get(k, 0)}
1271 
1272         if check_filterable:
1273             self.check_filterable(value)
1274 
1275         clause = self.where_class()
1276         if reffed_expression:
1277             condition = self.build_lookup(lookups, reffed_expression, value)
1278             clause.add(condition, AND)
1279             return clause, []
1280 
1281         opts = self.get_meta()
1282         alias = self.get_initial_alias()
1283         allow_many = not branch_negated or not split_subq
1284 
1285         try:
1286             join_info = self.setup_joins(
1287                 parts, opts, alias, can_reuse=can_reuse, allow_many=allow_many,
1288                 reuse_with_filtered_relation=reuse_with_filtered_relation,
1289             )
1290 
1291             # Prevent iterator from being consumed by check_related_objects()
1292             if isinstance(value, Iterator):
1293                 value = list(value)
1294             self.check_related_objects(join_info.final_field, value, join_info.opts)
1295 
1296             # split_exclude() needs to know which joins were generated for the
1297             # lookup parts
1298             self._lookup_joins = join_info.joins
1299         except MultiJoin as e:
1300             return self.split_exclude(filter_expr, can_reuse, e.names_with_path)
1301 
1302         # Update used_joins before trimming since they are reused to determine
1303         # which joins could be later promoted to INNER.
1304         used_joins.update(join_info.joins)
1305         targets, alias, join_list = self.trim_joins(join_info.targets, join_info.joins, join_info.path)
1306         if can_reuse is not None:
1307             can_reuse.update(join_list)
1308 
1309         if join_info.final_field.is_relation:
1310             # No support for transforms for relational fields
1311             num_lookups = len(lookups)
1312             if num_lookups > 1:
1313                 raise FieldError('Related Field got invalid lookup: {}'.format(lookups[0]))
1314             if len(targets) == 1:
1315                 col = self._get_col(targets[0], join_info.final_field, alias)
1316             else:
1317                 col = MultiColSource(alias, targets, join_info.targets, join_info.final_field)
1318         else:
1319             col = self._get_col(targets[0], join_info.final_field, alias)
1320 
1321         condition = self.build_lookup(lookups, col, value)
1322         lookup_type = condition.lookup_name
1323         clause.add(condition, AND)
1324 
1325         require_outer = lookup_type == 'isnull' and condition.rhs is True and not current_negated
1326         if current_negated and (lookup_type != 'isnull' or condition.rhs is False) and condition.rhs is not None:
1327             require_outer = True
1328             if lookup_type != 'isnull':
1329                 # The condition added here will be SQL like this:
1330                 # NOT (col IS NOT NULL), where the first NOT is added in
1331                 # upper layers of code. The reason for addition is that if col
1332                 # is null, then col != someval will result in SQL "unknown"
1333                 # which isn't the same as in Python. The Python None handling
1334                 # is wanted, and it can be gotten by
1335                 # (col IS NULL OR col != someval)
1336                 #   <=>
1337                 # NOT (col IS NOT NULL AND col = someval).
1338                 if (
1339                     self.is_nullable(targets[0]) or
1340                     self.alias_map[join_list[-1]].join_type == LOUTER
1341                 ):
1342                     lookup_class = targets[0].get_lookup('isnull')
1343                     col = self._get_col(targets[0], join_info.targets[0], alias)
1344                     clause.add(lookup_class(col, False), AND)
1345                 # If someval is a nullable column, someval IS NOT NULL is
1346                 # added.
1347                 if isinstance(value, Col) and self.is_nullable(value.target):
1348                     lookup_class = value.target.get_lookup('isnull')
1349                     clause.add(lookup_class(value, False), AND)
1350         return clause, used_joins if not require_outer else ()
1351 
1352     def add_filter(self, filter_clause):
1353         self.add_q(Q(**{filter_clause[0]: filter_clause[1]}))
1354 
1355     def add_q(self, q_object):
1356         """
1357         A preprocessor for the internal _add_q(). Responsible for doing final
1358         join promotion.
1359         """
1360         # For join promotion this case is doing an AND for the added q_object
1361         # and existing conditions. So, any existing inner join forces the join
1362         # type to remain inner. Existing outer joins can however be demoted.
1363         # (Consider case where rel_a is LOUTER and rel_a__col=1 is added - if
1364         # rel_a doesn't produce any rows, then the whole condition must fail.
1365         # So, demotion is OK.
1366         existing_inner = {a for a in self.alias_map if self.alias_map[a].join_type == INNER}
1367         clause, _ = self._add_q(q_object, self.used_aliases)
1368         if clause:
1369             self.where.add(clause, AND)
1370         self.demote_joins(existing_inner)
1371 
1372     def build_where(self, filter_expr):
1373         return self.build_filter(filter_expr, allow_joins=False)[0]
1374 
1375     def _add_q(self, q_object, used_aliases, branch_negated=False,
1376                current_negated=False, allow_joins=True, split_subq=True,
1377                check_filterable=True):
1378         """Add a Q-object to the current filter."""
1379         connector = q_object.connector
1380         current_negated = current_negated ^ q_object.negated
1381         branch_negated = branch_negated or q_object.negated
1382         target_clause = self.where_class(connector=connector,
1383                                          negated=q_object.negated)
1384         joinpromoter = JoinPromoter(q_object.connector, len(q_object.children), current_negated)
1385         for child in q_object.children:
1386             child_clause, needed_inner = self.build_filter(
1387                 child, can_reuse=used_aliases, branch_negated=branch_negated,
1388                 current_negated=current_negated, allow_joins=allow_joins,
1389                 split_subq=split_subq, check_filterable=check_filterable,
1390             )
1391             joinpromoter.add_votes(needed_inner)
1392             if child_clause:
1393                 target_clause.add(child_clause, connector)
1394         needed_inner = joinpromoter.update_join_types(self)
1395         return target_clause, needed_inner
1396 
1397     def build_filtered_relation_q(self, q_object, reuse, branch_negated=False, current_negated=False):
1398         """Add a FilteredRelation object to the current filter."""
1399         connector = q_object.connector
1400         current_negated ^= q_object.negated
1401         branch_negated = branch_negated or q_object.negated
1402         target_clause = self.where_class(connector=connector, negated=q_object.negated)
1403         for child in q_object.children:
1404             if isinstance(child, Node):
1405                 child_clause = self.build_filtered_relation_q(
1406                     child, reuse=reuse, branch_negated=branch_negated,
1407                     current_negated=current_negated,
1408                 )
1409             else:
1410                 child_clause, _ = self.build_filter(
1411                     child, can_reuse=reuse, branch_negated=branch_negated,
1412                     current_negated=current_negated,
1413                     allow_joins=True, split_subq=False,
1414                     reuse_with_filtered_relation=True,
1415                 )
1416             target_clause.add(child_clause, connector)
1417         return target_clause
1418 
1419     def add_filtered_relation(self, filtered_relation, alias):
1420         filtered_relation.alias = alias
1421         lookups = dict(get_children_from_q(filtered_relation.condition))
1422         for lookup in chain((filtered_relation.relation_name,), lookups):
1423             lookup_parts, field_parts, _ = self.solve_lookup_type(lookup)
1424             shift = 2 if not lookup_parts else 1
1425             if len(field_parts) > (shift + len(lookup_parts)):
1426                 raise ValueError(
1427                     "FilteredRelation's condition doesn't support nested "
1428                     "relations (got %r)." % lookup
1429                 )
1430         self._filtered_relations[filtered_relation.alias] = filtered_relation
1431 
1432     def names_to_path(self, names, opts, allow_many=True, fail_on_missing=False):
1433         """
1434         Walk the list of names and turns them into PathInfo tuples. A single
1435         name in 'names' can generate multiple PathInfos (m2m, for example).
1436 
1437         'names' is the path of names to travel, 'opts' is the model Options we
1438         start the name resolving from, 'allow_many' is as for setup_joins().
1439         If fail_on_missing is set to True, then a name that can't be resolved
1440         will generate a FieldError.
1441 
1442         Return a list of PathInfo tuples. In addition return the final field
1443         (the last used join field) and target (which is a field guaranteed to
1444         contain the same value as the final field). Finally, return those names
1445         that weren't found (which are likely transforms and the final lookup).
1446         """
1447         path, names_with_path = [], []
1448         for pos, name in enumerate(names):
1449             cur_names_with_path = (name, [])
1450             if name == 'pk':
1451                 name = opts.pk.name
1452 
1453             field = None
1454             filtered_relation = None
1455             try:
1456                 field = opts.get_field(name)
1457             except FieldDoesNotExist:
1458                 if name in self.annotation_select:
1459                     field = self.annotation_select[name].output_field
1460                 elif name in self._filtered_relations and pos == 0:
1461                     filtered_relation = self._filtered_relations[name]
1462                     field = opts.get_field(filtered_relation.relation_name)
1463             if field is not None:
1464                 # Fields that contain one-to-many relations with a generic
1465                 # model (like a GenericForeignKey) cannot generate reverse
1466                 # relations and therefore cannot be used for reverse querying.
1467                 if field.is_relation and not field.related_model:
1468                     raise FieldError(
1469                         "Field %r does not generate an automatic reverse "
1470                         "relation and therefore cannot be used for reverse "
1471                         "querying. If it is a GenericForeignKey, consider "
1472                         "adding a GenericRelation." % name
1473                     )
1474                 try:
1475                     model = field.model._meta.concrete_model
1476                 except AttributeError:
1477                     # QuerySet.annotate() may introduce fields that aren't
1478                     # attached to a model.
1479                     model = None
1480             else:
1481                 # We didn't find the current field, so move position back
1482                 # one step.
1483                 pos -= 1
1484                 if pos == -1 or fail_on_missing:
1485                     available = sorted([
1486                         *get_field_names_from_opts(opts),
1487                         *self.annotation_select,
1488                         *self._filtered_relations,
1489                     ])
1490                     raise FieldError("Cannot resolve keyword '%s' into field. "
1491                                      "Choices are: %s" % (name, ", ".join(available)))
1492                 break
1493             # Check if we need any joins for concrete inheritance cases (the
1494             # field lives in parent, but we are currently in one of its
1495             # children)
1496             if model is not opts.model:
1497                 path_to_parent = opts.get_path_to_parent(model)
1498                 if path_to_parent:
1499                     path.extend(path_to_parent)
1500                     cur_names_with_path[1].extend(path_to_parent)
1501                     opts = path_to_parent[-1].to_opts
1502             if hasattr(field, 'get_path_info'):
1503                 pathinfos = field.get_path_info(filtered_relation)
1504                 if not allow_many:
1505                     for inner_pos, p in enumerate(pathinfos):
1506                         if p.m2m:
1507                             cur_names_with_path[1].extend(pathinfos[0:inner_pos + 1])
1508                             names_with_path.append(cur_names_with_path)
1509                             raise MultiJoin(pos + 1, names_with_path)
1510                 last = pathinfos[-1]
1511                 path.extend(pathinfos)
1512                 final_field = last.join_field
1513                 opts = last.to_opts
1514                 targets = last.target_fields
1515                 cur_names_with_path[1].extend(pathinfos)
1516                 names_with_path.append(cur_names_with_path)
1517             else:
1518                 # Local non-relational field.
1519                 final_field = field
1520                 targets = (field,)
1521                 if fail_on_missing and pos + 1 != len(names):
1522                     raise FieldError(
1523                         "Cannot resolve keyword %r into field. Join on '%s'"
1524                         " not permitted." % (names[pos + 1], name))
1525                 break
1526         return path, final_field, targets, names[pos + 1:]
1527 
1528     def setup_joins(self, names, opts, alias, can_reuse=None, allow_many=True,
1529                     reuse_with_filtered_relation=False):
1530         """
1531         Compute the necessary table joins for the passage through the fields
1532         given in 'names'. 'opts' is the Options class for the current model
1533         (which gives the table we are starting from), 'alias' is the alias for
1534         the table to start the joining from.
1535 
1536         The 'can_reuse' defines the reverse foreign key joins we can reuse. It
1537         can be None in which case all joins are reusable or a set of aliases
1538         that can be reused. Note that non-reverse foreign keys are always
1539         reusable when using setup_joins().
1540 
1541         The 'reuse_with_filtered_relation' can be used to force 'can_reuse'
1542         parameter and force the relation on the given connections.
1543 
1544         If 'allow_many' is False, then any reverse foreign key seen will
1545         generate a MultiJoin exception.
1546 
1547         Return the final field involved in the joins, the target field (used
1548         for any 'where' constraint), the final 'opts' value, the joins, the
1549         field path traveled to generate the joins, and a transform function
1550         that takes a field and alias and is equivalent to `field.get_col(alias)`
1551         in the simple case but wraps field transforms if they were included in
1552         names.
1553 
1554         The target field is the field containing the concrete value. Final
1555         field can be something different, for example foreign key pointing to
1556         that value. Final field is needed for example in some value
1557         conversions (convert 'obj' in fk__id=obj to pk val using the foreign
1558         key field for example).
1559         """
1560         joins = [alias]
1561         # The transform can't be applied yet, as joins must be trimmed later.
1562         # To avoid making every caller of this method look up transforms
1563         # directly, compute transforms here and create a partial that converts
1564         # fields to the appropriate wrapped version.
1565 
1566         def final_transformer(field, alias):
1567             return field.get_col(alias)
1568 
1569         # Try resolving all the names as fields first. If there's an error,
1570         # treat trailing names as lookups until a field can be resolved.
1571         last_field_exception = None
1572         for pivot in range(len(names), 0, -1):
1573             try:
1574                 path, final_field, targets, rest = self.names_to_path(
1575                     names[:pivot], opts, allow_many, fail_on_missing=True,
1576                 )
1577             except FieldError as exc:
1578                 if pivot == 1:
1579                     # The first item cannot be a lookup, so it's safe
1580                     # to raise the field error here.
1581                     raise
1582                 else:
1583                     last_field_exception = exc
1584             else:
1585                 # The transforms are the remaining items that couldn't be
1586                 # resolved into fields.
1587                 transforms = names[pivot:]
1588                 break
1589         for name in transforms:
1590             def transform(field, alias, *, name, previous):
1591                 try:
1592                     wrapped = previous(field, alias)
1593                     return self.try_transform(wrapped, name)
1594                 except FieldError:
1595                     # FieldError is raised if the transform doesn't exist.
1596                     if isinstance(final_field, Field) and last_field_exception:
1597                         raise last_field_exception
1598                     else:
1599                         raise
1600             final_transformer = functools.partial(transform, name=name, previous=final_transformer)
1601         # Then, add the path to the query's joins. Note that we can't trim
1602         # joins at this stage - we will need the information about join type
1603         # of the trimmed joins.
1604         for join in path:
1605             if join.filtered_relation:
1606                 filtered_relation = join.filtered_relation.clone()
1607                 table_alias = filtered_relation.alias
1608             else:
1609                 filtered_relation = None
1610                 table_alias = None
1611             opts = join.to_opts
1612             if join.direct:
1613                 nullable = self.is_nullable(join.join_field)
1614             else:
1615                 nullable = True
1616             connection = Join(
1617                 opts.db_table, alias, table_alias, INNER, join.join_field,
1618                 nullable, filtered_relation=filtered_relation,
1619             )
1620             reuse = can_reuse if join.m2m or reuse_with_filtered_relation else None
1621             alias = self.join(
1622                 connection, reuse=reuse,
1623                 reuse_with_filtered_relation=reuse_with_filtered_relation,
1624             )
1625             joins.append(alias)
1626             if filtered_relation:
1627                 filtered_relation.path = joins[:]
1628         return JoinInfo(final_field, targets, opts, joins, path, final_transformer)
1629 
1630     def trim_joins(self, targets, joins, path):
1631         """
1632         The 'target' parameter is the final field being joined to, 'joins'
1633         is the full list of join aliases. The 'path' contain the PathInfos
1634         used to create the joins.
1635 
1636         Return the final target field and table alias and the new active
1637         joins.
1638 
1639         Always trim any direct join if the target column is already in the
1640         previous table. Can't trim reverse joins as it's unknown if there's
1641         anything on the other side of the join.
1642         """
1643         joins = joins[:]
1644         for pos, info in enumerate(reversed(path)):
1645             if len(joins) == 1 or not info.direct:
1646                 break
1647             if info.filtered_relation:
1648                 break
1649             join_targets = {t.column for t in info.join_field.foreign_related_fields}
1650             cur_targets = {t.column for t in targets}
1651             if not cur_targets.issubset(join_targets):
1652                 break
1653             targets_dict = {r[1].column: r[0] for r in info.join_field.related_fields if r[1].column in cur_targets}
1654             targets = tuple(targets_dict[t.column] for t in targets)
1655             self.unref_alias(joins.pop())
1656         return targets, joins[-1], joins
1657 
1658     @classmethod
1659     def _gen_cols(cls, exprs):
1660         for expr in exprs:
1661             if isinstance(expr, Col):
1662                 yield expr
1663             else:
1664                 yield from cls._gen_cols(expr.get_source_expressions())
1665 
1666     @classmethod
1667     def _gen_col_aliases(cls, exprs):
1668         yield from (expr.alias for expr in cls._gen_cols(exprs))
1669 
1670     def resolve_ref(self, name, allow_joins=True, reuse=None, summarize=False):
1671         if not allow_joins and LOOKUP_SEP in name:
1672             raise FieldError("Joined field references are not permitted in this query")
1673         annotation = self.annotations.get(name)
1674         if annotation is not None:
1675             if not allow_joins:
1676                 for alias in self._gen_col_aliases([annotation]):
1677                     if isinstance(self.alias_map[alias], Join):
1678                         raise FieldError(
1679                             'Joined field references are not permitted in '
1680                             'this query'
1681                         )
1682             if summarize:
1683                 # Summarize currently means we are doing an aggregate() query
1684                 # which is executed as a wrapped subquery if any of the
1685                 # aggregate() elements reference an existing annotation. In
1686                 # that case we need to return a Ref to the subquery's annotation.
1687                 return Ref(name, self.annotation_select[name])
1688             else:
1689                 return annotation
1690         else:
1691             field_list = name.split(LOOKUP_SEP)
1692             join_info = self.setup_joins(field_list, self.get_meta(), self.get_initial_alias(), can_reuse=reuse)
1693             targets, final_alias, join_list = self.trim_joins(join_info.targets, join_info.joins, join_info.path)
1694             if not allow_joins and len(join_list) > 1:
1695                 raise FieldError('Joined field references are not permitted in this query')
1696             if len(targets) > 1:
1697                 raise FieldError("Referencing multicolumn fields with F() objects "
1698                                  "isn't supported")
1699             # Verify that the last lookup in name is a field or a transform:
1700             # transform_function() raises FieldError if not.
1701             join_info.transform_function(targets[0], final_alias)
1702             if reuse is not None:
1703                 reuse.update(join_list)
1704             return self._get_col(targets[0], join_info.targets[0], join_list[-1])
1705 
1706     def split_exclude(self, filter_expr, can_reuse, names_with_path):
1707         """
1708         When doing an exclude against any kind of N-to-many relation, we need
1709         to use a subquery. This method constructs the nested query, given the
1710         original exclude filter (filter_expr) and the portion up to the first
1711         N-to-many relation field.
1712 
1713         For example, if the origin filter is ~Q(child__name='foo'), filter_expr
1714         is ('child__name', 'foo') and can_reuse is a set of joins usable for
1715         filters in the original query.
1716 
1717         We will turn this into equivalent of:
1718             WHERE NOT (pk IN (SELECT parent_id FROM thetable
1719                               WHERE name = 'foo' AND parent_id IS NOT NULL))
1720 
1721         It might be worth it to consider using WHERE NOT EXISTS as that has
1722         saner null handling, and is easier for the backend's optimizer to
1723         handle.
1724         """
1725         filter_lhs, filter_rhs = filter_expr
1726         if isinstance(filter_rhs, OuterRef):
1727             filter_expr = (filter_lhs, OuterRef(filter_rhs))
1728         elif isinstance(filter_rhs, F):
1729             filter_expr = (filter_lhs, OuterRef(filter_rhs.name))
1730         # Generate the inner query.
1731         query = Query(self.model)
1732         query._filtered_relations = self._filtered_relations
1733         query.add_filter(filter_expr)
1734         query.clear_ordering(True)
1735         # Try to have as simple as possible subquery -> trim leading joins from
1736         # the subquery.
1737         trimmed_prefix, contains_louter = query.trim_start(names_with_path)
1738 
1739         # Add extra check to make sure the selected field will not be null
1740         # since we are adding an IN <subquery> clause. This prevents the
1741         # database from tripping over IN (...,NULL,...) selects and returning
1742         # nothing
1743         col = query.select[0]
1744         select_field = col.target
1745         alias = col.alias
1746         if self.is_nullable(select_field):
1747             lookup_class = select_field.get_lookup('isnull')
1748             lookup = lookup_class(select_field.get_col(alias), False)
1749             query.where.add(lookup, AND)
1750         if alias in can_reuse:
1751             pk = select_field.model._meta.pk
1752             # Need to add a restriction so that outer query's filters are in effect for
1753             # the subquery, too.
1754             query.bump_prefix(self)
1755             lookup_class = select_field.get_lookup('exact')
1756             # Note that the query.select[0].alias is different from alias
1757             # due to bump_prefix above.
1758             lookup = lookup_class(pk.get_col(query.select[0].alias),
1759                                   pk.get_col(alias))
1760             query.where.add(lookup, AND)
1761             query.external_aliases[alias] = True
1762 
1763         condition, needed_inner = self.build_filter(
1764             ('%s__in' % trimmed_prefix, query),
1765             current_negated=True, branch_negated=True, can_reuse=can_reuse)
1766         if contains_louter:
1767             or_null_condition, _ = self.build_filter(
1768                 ('%s__isnull' % trimmed_prefix, True),
1769                 current_negated=True, branch_negated=True, can_reuse=can_reuse)
1770             condition.add(or_null_condition, OR)
1771             # Note that the end result will be:
1772             # (outercol NOT IN innerq AND outercol IS NOT NULL) OR outercol IS NULL.
1773             # This might look crazy but due to how IN works, this seems to be
1774             # correct. If the IS NOT NULL check is removed then outercol NOT
1775             # IN will return UNKNOWN. If the IS NULL check is removed, then if
1776             # outercol IS NULL we will not match the row.
1777         return condition, needed_inner
1778 
1779     def set_empty(self):
1780         self.where.add(NothingNode(), AND)
1781         for query in self.combined_queries:
1782             query.set_empty()
1783 
1784     def is_empty(self):
1785         return any(isinstance(c, NothingNode) for c in self.where.children)
1786 
1787     def set_limits(self, low=None, high=None):
1788         """
1789         Adjust the limits on the rows retrieved. Use low/high to set these,
1790         as it makes it more Pythonic to read and write. When the SQL query is
1791         created, convert them to the appropriate offset and limit values.
1792 
1793         Apply any limits passed in here to the existing constraints. Add low
1794         to the current low value and clamp both to any existing high value.
1795         """
1796         if high is not None:
1797             if self.high_mark is not None:
1798                 self.high_mark = min(self.high_mark, self.low_mark + high)
1799             else:
1800                 self.high_mark = self.low_mark + high
1801         if low is not None:
1802             if self.high_mark is not None:
1803                 self.low_mark = min(self.high_mark, self.low_mark + low)
1804             else:
1805                 self.low_mark = self.low_mark + low
1806 
1807         if self.low_mark == self.high_mark:
1808             self.set_empty()
1809 
1810     def clear_limits(self):
1811         """Clear any existing limits."""
1812         self.low_mark, self.high_mark = 0, None
1813 
1814     @property
1815     def is_sliced(self):
1816         return self.low_mark != 0 or self.high_mark is not None
1817 
1818     def has_limit_one(self):
1819         return self.high_mark is not None and (self.high_mark - self.low_mark) == 1
1820 
1821     def can_filter(self):
1822         """
1823         Return True if adding filters to this instance is still possible.
1824 
1825         Typically, this means no limits or offsets have been put on the results.
1826         """
1827         return not self.is_sliced
1828 
1829     def clear_select_clause(self):
1830         """Remove all fields from SELECT clause."""
1831         self.select = ()
1832         self.default_cols = False
1833         self.select_related = False
1834         self.set_extra_mask(())
1835         self.set_annotation_mask(())
1836 
1837     def clear_select_fields(self):
1838         """
1839         Clear the list of fields to select (but not extra_select columns).
1840         Some queryset types completely replace any existing list of select
1841         columns.
1842         """
1843         self.select = ()
1844         self.values_select = ()
1845 
1846     def add_select_col(self, col):
1847         self.select += col,
1848         self.values_select += col.output_field.name,
1849 
1850     def set_select(self, cols):
1851         self.default_cols = False
1852         self.select = tuple(cols)
1853 
1854     def add_distinct_fields(self, *field_names):
1855         """
1856         Add and resolve the given fields to the query's "distinct on" clause.
1857         """
1858         self.distinct_fields = field_names
1859         self.distinct = True
1860 
1861     def add_fields(self, field_names, allow_m2m=True):
1862         """
1863         Add the given (model) fields to the select set. Add the field names in
1864         the order specified.
1865         """
1866         alias = self.get_initial_alias()
1867         opts = self.get_meta()
1868 
1869         try:
1870             cols = []
1871             for name in field_names:
1872                 # Join promotion note - we must not remove any rows here, so
1873                 # if there is no existing joins, use outer join.
1874                 join_info = self.setup_joins(name.split(LOOKUP_SEP), opts, alias, allow_many=allow_m2m)
1875                 targets, final_alias, joins = self.trim_joins(
1876                     join_info.targets,
1877                     join_info.joins,
1878                     join_info.path,
1879                 )
1880                 for target in targets:
1881                     cols.append(join_info.transform_function(target, final_alias))
1882             if cols:
1883                 self.set_select(cols)
1884         except MultiJoin:
1885             raise FieldError("Invalid field name: '%s'" % name)
1886         except FieldError:
1887             if LOOKUP_SEP in name:
1888                 # For lookups spanning over relationships, show the error
1889                 # from the model on which the lookup failed.
1890                 raise
1891             else:
1892                 names = sorted([
1893                     *get_field_names_from_opts(opts), *self.extra,
1894                     *self.annotation_select, *self._filtered_relations
1895                 ])
1896                 raise FieldError("Cannot resolve keyword %r into field. "
1897                                  "Choices are: %s" % (name, ", ".join(names)))
1898 
1899     def add_ordering(self, *ordering):
1900         """
1901         Add items from the 'ordering' sequence to the query's "order by"
1902         clause. These items are either field names (not column names) --
1903         possibly with a direction prefix ('-' or '?') -- or OrderBy
1904         expressions.
1905 
1906         If 'ordering' is empty, clear all ordering from the query.
1907         """
1908         errors = []
1909         for item in ordering:
1910             if isinstance(item, str):
1911                 if '.' in item:
1912                     warnings.warn(
1913                         'Passing column raw column aliases to order_by() is '
1914                         'deprecated. Wrap %r in a RawSQL expression before '
1915                         'passing it to order_by().' % item,
1916                         category=RemovedInDjango40Warning,
1917                         stacklevel=3,
1918                     )
1919                     continue
1920                 if item == '?':
1921                     continue
1922                 if item.startswith('-'):
1923                     item = item[1:]
1924                 if item in self.annotations:
1925                     continue
1926                 if self.extra and item in self.extra:
1927                     continue
1928                 # names_to_path() validates the lookup. A descriptive
1929                 # FieldError will be raise if it's not.
1930                 self.names_to_path(item.split(LOOKUP_SEP), self.model._meta)
1931             elif not hasattr(item, 'resolve_expression'):
1932                 errors.append(item)
1933             if getattr(item, 'contains_aggregate', False):
1934                 raise FieldError(
1935                     'Using an aggregate in order_by() without also including '
1936                     'it in annotate() is not allowed: %s' % item
1937                 )
1938         if errors:
1939             raise FieldError('Invalid order_by arguments: %s' % errors)
1940         if ordering:
1941             self.order_by += ordering
1942         else:
1943             self.default_ordering = False
1944 
1945     def clear_ordering(self, force_empty):
1946         """
1947         Remove any ordering settings. If 'force_empty' is True, there will be
1948         no ordering in the resulting query (not even the model's default).
1949         """
1950         self.order_by = ()
1951         self.extra_order_by = ()
1952         if force_empty:
1953             self.default_ordering = False
1954 
1955     def set_group_by(self, allow_aliases=True):
1956         """
1957         Expand the GROUP BY clause required by the query.
1958 
1959         This will usually be the set of all non-aggregate fields in the
1960         return data. If the database backend supports grouping by the
1961         primary key, and the query would be equivalent, the optimization
1962         will be made automatically.
1963         """
1964         # Column names from JOINs to check collisions with aliases.
1965         if allow_aliases:
1966             column_names = set()
1967             seen_models = set()
1968             for join in list(self.alias_map.values())[1:]:  # Skip base table.
1969                 model = join.join_field.related_model
1970                 if model not in seen_models:
1971                     column_names.update({
1972                         field.column
1973                         for field in model._meta.local_concrete_fields
1974                     })
1975                     seen_models.add(model)
1976 
1977         group_by = list(self.select)
1978         if self.annotation_select:
1979             for alias, annotation in self.annotation_select.items():
1980                 signature = inspect.signature(annotation.get_group_by_cols)
1981                 if 'alias' not in signature.parameters:
1982                     annotation_class = annotation.__class__
1983                     msg = (
1984                         '`alias=None` must be added to the signature of '
1985                         '%s.%s.get_group_by_cols().'
1986                     ) % (annotation_class.__module__, annotation_class.__qualname__)
1987                     warnings.warn(msg, category=RemovedInDjango40Warning)
1988                     group_by_cols = annotation.get_group_by_cols()
1989                 else:
1990                     if not allow_aliases or alias in column_names:
1991                         alias = None
1992                     group_by_cols = annotation.get_group_by_cols(alias=alias)
1993                 group_by.extend(group_by_cols)
1994         self.group_by = tuple(group_by)
1995 
1996     def add_select_related(self, fields):
1997         """
1998         Set up the select_related data structure so that we only select
1999         certain related models (as opposed to all models, when
2000         self.select_related=True).
2001         """
2002         if isinstance(self.select_related, bool):
2003             field_dict = {}
2004         else:
2005             field_dict = self.select_related
2006         for field in fields:
2007             d = field_dict
2008             for part in field.split(LOOKUP_SEP):
2009                 d = d.setdefault(part, {})
2010         self.select_related = field_dict
2011 
2012     def add_extra(self, select, select_params, where, params, tables, order_by):
2013         """
2014         Add data to the various extra_* attributes for user-created additions
2015         to the query.
2016         """
2017         if select:
2018             # We need to pair any placeholder markers in the 'select'
2019             # dictionary with their parameters in 'select_params' so that
2020             # subsequent updates to the select dictionary also adjust the
2021             # parameters appropriately.
2022             select_pairs = {}
2023             if select_params:
2024                 param_iter = iter(select_params)
2025             else:
2026                 param_iter = iter([])
2027             for name, entry in select.items():
2028                 entry = str(entry)
2029                 entry_params = []
2030                 pos = entry.find("%s")
2031                 while pos != -1:
2032                     if pos == 0 or entry[pos - 1] != '%':
2033                         entry_params.append(next(param_iter))
2034                     pos = entry.find("%s", pos + 2)
2035                 select_pairs[name] = (entry, entry_params)
2036             self.extra.update(select_pairs)
2037         if where or params:
2038             self.where.add(ExtraWhere(where, params), AND)
2039         if tables:
2040             self.extra_tables += tuple(tables)
2041         if order_by:
2042             self.extra_order_by = order_by
2043 
2044     def clear_deferred_loading(self):
2045         """Remove any fields from the deferred loading set."""
2046         self.deferred_loading = (frozenset(), True)
2047 
2048     def add_deferred_loading(self, field_names):
2049         """
2050         Add the given list of model field names to the set of fields to
2051         exclude from loading from the database when automatic column selection
2052         is done. Add the new field names to any existing field names that
2053         are deferred (or removed from any existing field names that are marked
2054         as the only ones for immediate loading).
2055         """
2056         # Fields on related models are stored in the literal double-underscore
2057         # format, so that we can use a set datastructure. We do the foo__bar
2058         # splitting and handling when computing the SQL column names (as part of
2059         # get_columns()).
2060         existing, defer = self.deferred_loading
2061         if defer:
2062             # Add to existing deferred names.
2063             self.deferred_loading = existing.union(field_names), True
2064         else:
2065             # Remove names from the set of any existing "immediate load" names.
2066             self.deferred_loading = existing.difference(field_names), False
2067 
2068     def add_immediate_loading(self, field_names):
2069         """
2070         Add the given list of model field names to the set of fields to
2071         retrieve when the SQL is executed ("immediate loading" fields). The
2072         field names replace any existing immediate loading field names. If
2073         there are field names already specified for deferred loading, remove
2074         those names from the new field_names before storing the new names
2075         for immediate loading. (That is, immediate loading overrides any
2076         existing immediate values, but respects existing deferrals.)
2077         """
2078         existing, defer = self.deferred_loading
2079         field_names = set(field_names)
2080         if 'pk' in field_names:
2081             field_names.remove('pk')
2082             field_names.add(self.get_meta().pk.name)
2083 
2084         if defer:
2085             # Remove any existing deferred names from the current set before
2086             # setting the new names.
2087             self.deferred_loading = field_names.difference(existing), False
2088         else:
2089             # Replace any existing "immediate load" field names.
2090             self.deferred_loading = frozenset(field_names), False
2091 
2092     def get_loaded_field_names(self):
2093         """
2094         If any fields are marked to be deferred, return a dictionary mapping
2095         models to a set of names in those fields that will be loaded. If a
2096         model is not in the returned dictionary, none of its fields are
2097         deferred.
2098 
2099         If no fields are marked for deferral, return an empty dictionary.
2100         """
2101         # We cache this because we call this function multiple times
2102         # (compiler.fill_related_selections, query.iterator)
2103         try:
2104             return self._loaded_field_names_cache
2105         except AttributeError:
2106             collection = {}
2107             self.deferred_to_data(collection, self.get_loaded_field_names_cb)
2108             self._loaded_field_names_cache = collection
2109             return collection
2110 
2111     def get_loaded_field_names_cb(self, target, model, fields):
2112         """Callback used by get_deferred_field_names()."""
2113         target[model] = {f.attname for f in fields}
2114 
2115     def set_annotation_mask(self, names):
2116         """Set the mask of annotations that will be returned by the SELECT."""
2117         if names is None:
2118             self.annotation_select_mask = None
2119         else:
2120             self.annotation_select_mask = set(names)
2121         self._annotation_select_cache = None
2122 
2123     def append_annotation_mask(self, names):
2124         if self.annotation_select_mask is not None:
2125             self.set_annotation_mask(self.annotation_select_mask.union(names))
2126 
2127     def set_extra_mask(self, names):
2128         """
2129         Set the mask of extra select items that will be returned by SELECT.
2130         Don't remove them from the Query since they might be used later.
2131         """
2132         if names is None:
2133             self.extra_select_mask = None
2134         else:
2135             self.extra_select_mask = set(names)
2136         self._extra_select_cache = None
2137 
2138     def set_values(self, fields):
2139         self.select_related = False
2140         self.clear_deferred_loading()
2141         self.clear_select_fields()
2142 
2143         if fields:
2144             field_names = []
2145             extra_names = []
2146             annotation_names = []
2147             if not self.extra and not self.annotations:
2148                 # Shortcut - if there are no extra or annotations, then
2149                 # the values() clause must be just field names.
2150                 field_names = list(fields)
2151             else:
2152                 self.default_cols = False
2153                 for f in fields:
2154                     if f in self.extra_select:
2155                         extra_names.append(f)
2156                     elif f in self.annotation_select:
2157                         annotation_names.append(f)
2158                     else:
2159                         field_names.append(f)
2160             self.set_extra_mask(extra_names)
2161             self.set_annotation_mask(annotation_names)
2162         else:
2163             field_names = [f.attname for f in self.model._meta.concrete_fields]
2164         # Selected annotations must be known before setting the GROUP BY
2165         # clause.
2166         if self.group_by is True:
2167             self.add_fields((f.attname for f in self.model._meta.concrete_fields), False)
2168             # Disable GROUP BY aliases to avoid orphaning references to the
2169             # SELECT clause which is about to be cleared.
2170             self.set_group_by(allow_aliases=False)
2171             self.clear_select_fields()
2172         elif self.group_by:
2173             # Resolve GROUP BY annotation references if they are not part of
2174             # the selected fields anymore.
2175             group_by = []
2176             for expr in self.group_by:
2177                 if isinstance(expr, Ref) and expr.refs not in field_names:
2178                     expr = self.annotations[expr.refs]
2179                 group_by.append(expr)
2180             self.group_by = tuple(group_by)
2181 
2182         self.values_select = tuple(field_names)
2183         self.add_fields(field_names, True)
2184 
2185     @property
2186     def annotation_select(self):
2187         """
2188         Return the dictionary of aggregate columns that are not masked and
2189         should be used in the SELECT clause. Cache this result for performance.
2190         """
2191         if self._annotation_select_cache is not None:
2192             return self._annotation_select_cache
2193         elif not self.annotations:
2194             return {}
2195         elif self.annotation_select_mask is not None:
2196             self._annotation_select_cache = {
2197                 k: v for k, v in self.annotations.items()
2198                 if k in self.annotation_select_mask
2199             }
2200             return self._annotation_select_cache
2201         else:
2202             return self.annotations
2203 
2204     @property
2205     def extra_select(self):
2206         if self._extra_select_cache is not None:
2207             return self._extra_select_cache
2208         if not self.extra:
2209             return {}
2210         elif self.extra_select_mask is not None:
2211             self._extra_select_cache = {
2212                 k: v for k, v in self.extra.items()
2213                 if k in self.extra_select_mask
2214             }
2215             return self._extra_select_cache
2216         else:
2217             return self.extra
2218 
2219     def trim_start(self, names_with_path):
2220         """
2221         Trim joins from the start of the join path. The candidates for trim
2222         are the PathInfos in names_with_path structure that are m2m joins.
2223 
2224         Also set the select column so the start matches the join.
2225 
2226         This method is meant to be used for generating the subquery joins &
2227         cols in split_exclude().
2228 
2229         Return a lookup usable for doing outerq.filter(lookup=self) and a
2230         boolean indicating if the joins in the prefix contain a LEFT OUTER join.
2231         _"""
2232         all_paths = []
2233         for _, paths in names_with_path:
2234             all_paths.extend(paths)
2235         contains_louter = False
2236         # Trim and operate only on tables that were generated for
2237         # the lookup part of the query. That is, avoid trimming
2238         # joins generated for F() expressions.
2239         lookup_tables = [
2240             t for t in self.alias_map
2241             if t in self._lookup_joins or t == self.base_table
2242         ]
2243         for trimmed_paths, path in enumerate(all_paths):
2244             if path.m2m:
2245                 break
2246             if self.alias_map[lookup_tables[trimmed_paths + 1]].join_type == LOUTER:
2247                 contains_louter = True
2248             alias = lookup_tables[trimmed_paths]
2249             self.unref_alias(alias)
2250         # The path.join_field is a Rel, lets get the other side's field
2251         join_field = path.join_field.field
2252         # Build the filter prefix.
2253         paths_in_prefix = trimmed_paths
2254         trimmed_prefix = []
2255         for name, path in names_with_path:
2256             if paths_in_prefix - len(path) < 0:
2257                 break
2258             trimmed_prefix.append(name)
2259             paths_in_prefix -= len(path)
2260         trimmed_prefix.append(
2261             join_field.foreign_related_fields[0].name)
2262         trimmed_prefix = LOOKUP_SEP.join(trimmed_prefix)
2263         # Lets still see if we can trim the first join from the inner query
2264         # (that is, self). We can't do this for:
2265         # - LEFT JOINs because we would miss those rows that have nothing on
2266         #   the outer side,
2267         # - INNER JOINs from filtered relations because we would miss their
2268         #   filters.
2269         first_join = self.alias_map[lookup_tables[trimmed_paths + 1]]
2270         if first_join.join_type != LOUTER and not first_join.filtered_relation:
2271             select_fields = [r[0] for r in join_field.related_fields]
2272             select_alias = lookup_tables[trimmed_paths + 1]
2273             self.unref_alias(lookup_tables[trimmed_paths])
2274             extra_restriction = join_field.get_extra_restriction(
2275                 self.where_class, None, lookup_tables[trimmed_paths + 1])
2276             if extra_restriction:
2277                 self.where.add(extra_restriction, AND)
2278         else:
2279             # TODO: It might be possible to trim more joins from the start of the
2280             # inner query if it happens to have a longer join chain containing the
2281             # values in select_fields. Lets punt this one for now.
2282             select_fields = [r[1] for r in join_field.related_fields]
2283             select_alias = lookup_tables[trimmed_paths]
2284         # The found starting point is likely a Join instead of a BaseTable reference.
2285         # But the first entry in the query's FROM clause must not be a JOIN.
2286         for table in self.alias_map:
2287             if self.alias_refcount[table] > 0:
2288                 self.alias_map[table] = BaseTable(self.alias_map[table].table_name, table)
2289                 break
2290         self.set_select([f.get_col(select_alias) for f in select_fields])
2291         return trimmed_prefix, contains_louter
2292 
2293     def is_nullable(self, field):
2294         """
2295         Check if the given field should be treated as nullable.
2296 
2297         Some backends treat '' as null and Django treats such fields as
2298         nullable for those backends. In such situations field.null can be
2299         False even if we should treat the field as nullable.
2300         """
2301         # We need to use DEFAULT_DB_ALIAS here, as QuerySet does not have
2302         # (nor should it have) knowledge of which connection is going to be
2303         # used. The proper fix would be to defer all decisions where
2304         # is_nullable() is needed to the compiler stage, but that is not easy
2305         # to do currently.
2306         return (
2307             connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls and
2308             field.empty_strings_allowed
2309         ) or field.null
2310 
2311 
2312 def get_order_dir(field, default='ASC'):
2313     """
2314     Return the field name and direction for an order specification. For
2315     example, '-foo' is returned as ('foo', 'DESC').
2316 
2317     The 'default' param is used to indicate which way no prefix (or a '+'
2318     prefix) should sort. The '-' prefix always sorts the opposite way.
2319     """
2320     dirn = ORDER_DIR[default]
2321     if field[0] == '-':
2322         return field[1:], dirn[1]
2323     return field, dirn[0]
2324 
2325 
2326 def add_to_dict(data, key, value):
2327     """
2328     Add "value" to the set of values for "key", whether or not "key" already
2329     exists.
2330     """
2331     if key in data:
2332         data[key].add(value)
2333     else:
2334         data[key] = {value}
2335 
2336 
2337 def is_reverse_o2o(field):
2338     """
2339     Check if the given field is reverse-o2o. The field is expected to be some
2340     sort of relation field or related object.
2341     """
2342     return field.is_relation and field.one_to_one and not field.concrete
2343 
2344 
2345 class JoinPromoter:
2346     """
2347     A class to abstract away join promotion problems for complex filter
2348     conditions.
2349     """
2350 
2351     def __init__(self, connector, num_children, negated):
2352         self.connector = connector
2353         self.negated = negated
2354         if self.negated:
2355             if connector == AND:
2356                 self.effective_connector = OR
2357             else:
2358                 self.effective_connector = AND
2359         else:
2360             self.effective_connector = self.connector
2361         self.num_children = num_children
2362         # Maps of table alias to how many times it is seen as required for
2363         # inner and/or outer joins.
2364         self.votes = Counter()
2365 
2366     def add_votes(self, votes):
2367         """
2368         Add single vote per item to self.votes. Parameter can be any
2369         iterable.
2370         """
2371         self.votes.update(votes)
2372 
2373     def update_join_types(self, query):
2374         """
2375         Change join types so that the generated query is as efficient as
2376         possible, but still correct. So, change as many joins as possible
2377         to INNER, but don't make OUTER joins INNER if that could remove
2378         results from the query.
2379         """
2380         to_promote = set()
2381         to_demote = set()
2382         # The effective_connector is used so that NOT (a AND b) is treated
2383         # similarly to (a OR b) for join promotion.
2384         for table, votes in self.votes.items():
2385             # We must use outer joins in OR case when the join isn't contained
2386             # in all of the joins. Otherwise the INNER JOIN itself could remove
2387             # valid results. Consider the case where a model with rel_a and
2388             # rel_b relations is queried with rel_a__col=1 | rel_b__col=2. Now,
2389             # if rel_a join doesn't produce any results is null (for example
2390             # reverse foreign key or null value in direct foreign key), and
2391             # there is a matching row in rel_b with col=2, then an INNER join
2392             # to rel_a would remove a valid match from the query. So, we need
2393             # to promote any existing INNER to LOUTER (it is possible this
2394             # promotion in turn will be demoted later on).
2395             if self.effective_connector == 'OR' and votes < self.num_children:
2396                 to_promote.add(table)
2397             # If connector is AND and there is a filter that can match only
2398             # when there is a joinable row, then use INNER. For example, in
2399             # rel_a__col=1 & rel_b__col=2, if either of the rels produce NULL
2400             # as join output, then the col=1 or col=2 can't match (as
2401             # NULL=anything is always false).
2402             # For the OR case, if all children voted for a join to be inner,
2403             # then we can use INNER for the join. For example:
2404             #     (rel_a__col__icontains=Alex | rel_a__col__icontains=Russell)
2405             # then if rel_a doesn't produce any rows, the whole condition
2406             # can't match. Hence we can safely use INNER join.
2407             if self.effective_connector == 'AND' or (
2408                     self.effective_connector == 'OR' and votes == self.num_children):
2409                 to_demote.add(table)
2410             # Finally, what happens in cases where we have:
2411             #    (rel_a__col=1|rel_b__col=2) & rel_a__col__gte=0
2412             # Now, we first generate the OR clause, and promote joins for it
2413             # in the first if branch above. Both rel_a and rel_b are promoted
2414             # to LOUTER joins. After that we do the AND case. The OR case
2415             # voted no inner joins but the rel_a__col__gte=0 votes inner join
2416             # for rel_a. We demote it back to INNER join (in AND case a single
2417             # vote is enough). The demotion is OK, if rel_a doesn't produce
2418             # rows, then the rel_a__col__gte=0 clause can't be true, and thus
2419             # the whole clause must be false. So, it is safe to use INNER
2420             # join.
2421             # Note that in this example we could just as well have the __gte
2422             # clause and the OR clause swapped. Or we could replace the __gte
2423             # clause with an OR clause containing rel_a__col=1|rel_a__col=2,
2424             # and again we could safely demote to INNER.
2425         query.promote_joins(to_promote)
2426         query.demote_joins(to_demote)
2427         return to_demote

</code><intended_behavior>The methods responsible for constructing SQL queries from `FilteredRelation` objects, particularly those dealing with the `condition` attribute, should be adapted to support nested relations. This might involve the `build_filter` method or other related methods that compile `Q` objects into SQL. The code at this location should ensure that when a `FilteredRelation` includes a nested relation condition, the generated SQL correctly reflects the nested JOIN operations needed to implement such a query. This includes appropriately handling aliases for tables to avoid conflicts and ensuring that the conditions specified in the nested `Q` objects are applied correctly to the resulting SQL.</intended_behavior>]
2025-10-15 05:02:32.171 | INFO     | Search completed. Bug locations: [<file>django/db/models/query_utils.py</file>
<class>FilteredRelation</class>
<method>None</method>
<code>
312 class FilteredRelation:
313     """Specify custom filtering in the ON clause of SQL joins."""
314 
315     def __init__(self, relation_name, *, condition=Q()):
316         if not relation_name:
317             raise ValueError('relation_name cannot be empty.')
318         self.relation_name = relation_name
319         self.alias = None
320         if not isinstance(condition, Q):
321             raise ValueError('condition argument must be a Q() instance.')
322         self.condition = condition
323         self.path = []
324 
325     def __eq__(self, other):
326         if not isinstance(other, self.__class__):
327             return NotImplemented
328         return (
329             self.relation_name == other.relation_name and
330             self.alias == other.alias and
331             self.condition == other.condition
332         )
333 
334     def clone(self):
335         clone = FilteredRelation(self.relation_name, condition=self.condition)
336         clone.alias = self.alias
337         clone.path = self.path[:]
338         return clone
339 
340     def resolve_expression(self, *args, **kwargs):
341         """
342         QuerySet.annotate() only accepts expression-like arguments
343         (with a resolve_expression() method).
344         """
345         raise NotImplementedError('FilteredRelation.resolve_expression() is unused.')
346 
347     def as_sql(self, compiler, connection):
348         # Resolve the condition in Join.filtered_relation.
349         query = compiler.query
350         where = query.build_filtered_relation_q(self.condition, reuse=set(self.path))
351         return compiler.compile(where)

</code><intended_behavior>The `FilteredRelation` class should be extended to accurately parse and validate nested relations in its `condition` parameter. This might involve modifying the `__init__` method or adding new methods to handle the complexity of nested queries. The validation logic should be updated to not only accept `Q` objects but also correctly interpret nested fields within those `Q` objects. The enhancement should ensure that nested conditions are transformed into the appropriate SQL JOIN operations, preserving the existing functionality for non-nested conditions.</intended_behavior>, <file>django/db/models/sql/query.py</file>
<class>None</class>
<method>None</method>
<code>
1 """
2 Create SQL statements for QuerySets.
3 
4 The code in here encapsulates all of the SQL construction so that QuerySets
5 themselves do not have to (and could be backed by things other than SQL
6 databases). The abstraction barrier only works one way: this module has to know
7 all about the internals of models in order to get the information it needs.
8 """
9 import copy
10 import difflib
11 import functools
12 import inspect
13 import sys
14 import warnings
15 from collections import Counter, namedtuple
16 from collections.abc import Iterator, Mapping
17 from itertools import chain, count, product
18 from string import ascii_uppercase
19 
20 from django.core.exceptions import (
21     EmptyResultSet, FieldDoesNotExist, FieldError,
22 )
23 from django.db import DEFAULT_DB_ALIAS, NotSupportedError, connections
24 from django.db.models.aggregates import Count
25 from django.db.models.constants import LOOKUP_SEP
26 from django.db.models.expressions import BaseExpression, Col, F, OuterRef, Ref
27 from django.db.models.fields import Field
28 from django.db.models.fields.related_lookups import MultiColSource
29 from django.db.models.lookups import Lookup
30 from django.db.models.query_utils import (
31     Q, check_rel_lookup_compatibility, refs_expression,
32 )
33 from django.db.models.sql.constants import INNER, LOUTER, ORDER_DIR, SINGLE
34 from django.db.models.sql.datastructures import (
35     BaseTable, Empty, Join, MultiJoin,
36 )
37 from django.db.models.sql.where import (
38     AND, OR, ExtraWhere, NothingNode, WhereNode,
39 )
40 from django.utils.deprecation import RemovedInDjango40Warning
41 from django.utils.functional import cached_property
42 from django.utils.tree import Node
43 
44 __all__ = ['Query', 'RawQuery']
45 
46 
47 def get_field_names_from_opts(opts):
48     return set(chain.from_iterable(
49         (f.name, f.attname) if f.concrete else (f.name,)
50         for f in opts.get_fields()
51     ))
52 
53 
54 def get_children_from_q(q):
55     for child in q.children:
56         if isinstance(child, Node):
57             yield from get_children_from_q(child)
58         else:
59             yield child
60 
61 
62 JoinInfo = namedtuple(
63     'JoinInfo',
64     ('final_field', 'targets', 'opts', 'joins', 'path', 'transform_function')
65 )
66 
67 
68 class RawQuery:
69     """A single raw SQL query."""
70 
71     def __init__(self, sql, using, params=None):
72         self.params = params or ()
73         self.sql = sql
74         self.using = using
75         self.cursor = None
76 
77         # Mirror some properties of a normal query so that
78         # the compiler can be used to process results.
79         self.low_mark, self.high_mark = 0, None  # Used for offset/limit
80         self.extra_select = {}
81         self.annotation_select = {}
82 
83     def chain(self, using):
84         return self.clone(using)
85 
86     def clone(self, using):
87         return RawQuery(self.sql, using, params=self.params)
88 
89     def get_columns(self):
90         if self.cursor is None:
91             self._execute_query()
92         converter = connections[self.using].introspection.identifier_converter
93         return [converter(column_meta[0])
94                 for column_meta in self.cursor.description]
95 
96     def __iter__(self):
97         # Always execute a new query for a new iterator.
98         # This could be optimized with a cache at the expense of RAM.
99         self._execute_query()
100         if not connections[self.using].features.can_use_chunked_reads:
101             # If the database can't use chunked reads we need to make sure we
102             # evaluate the entire query up front.
103             result = list(self.cursor)
104         else:
105             result = self.cursor
106         return iter(result)
107 
108     def __repr__(self):
109         return "<%s: %s>" % (self.__class__.__name__, self)
110 
111     @property
112     def params_type(self):
113         return dict if isinstance(self.params, Mapping) else tuple
114 
115     def __str__(self):
116         return self.sql % self.params_type(self.params)
117 
118     def _execute_query(self):
119         connection = connections[self.using]
120 
121         # Adapt parameters to the database, as much as possible considering
122         # that the target type isn't known. See #17755.
123         params_type = self.params_type
124         adapter = connection.ops.adapt_unknown_value
125         if params_type is tuple:
126             params = tuple(adapter(val) for val in self.params)
127         elif params_type is dict:
128             params = {key: adapter(val) for key, val in self.params.items()}
129         else:
130             raise RuntimeError("Unexpected params type: %s" % params_type)
131 
132         self.cursor = connection.cursor()
133         self.cursor.execute(self.sql, params)
134 
135 
136 class Query(BaseExpression):
137     """A single SQL query."""
138 
139     alias_prefix = 'T'
140     subq_aliases = frozenset([alias_prefix])
141 
142     compiler = 'SQLCompiler'
143 
144     def __init__(self, model, where=WhereNode, alias_cols=True):
145         self.model = model
146         self.alias_refcount = {}
147         # alias_map is the most important data structure regarding joins.
148         # It's used for recording which joins exist in the query and what
149         # types they are. The key is the alias of the joined table (possibly
150         # the table name) and the value is a Join-like object (see
151         # sql.datastructures.Join for more information).
152         self.alias_map = {}
153         # Whether to provide alias to columns during reference resolving.
154         self.alias_cols = alias_cols
155         # Sometimes the query contains references to aliases in outer queries (as
156         # a result of split_exclude). Correct alias quoting needs to know these
157         # aliases too.
158         # Map external tables to whether they are aliased.
159         self.external_aliases = {}
160         self.table_map = {}     # Maps table names to list of aliases.
161         self.default_cols = True
162         self.default_ordering = True
163         self.standard_ordering = True
164         self.used_aliases = set()
165         self.filter_is_sticky = False
166         self.subquery = False
167 
168         # SQL-related attributes
169         # Select and related select clauses are expressions to use in the
170         # SELECT clause of the query.
171         # The select is used for cases where we want to set up the select
172         # clause to contain other than default fields (values(), subqueries...)
173         # Note that annotations go to annotations dictionary.
174         self.select = ()
175         self.where = where()
176         self.where_class = where
177         # The group_by attribute can have one of the following forms:
178         #  - None: no group by at all in the query
179         #  - A tuple of expressions: group by (at least) those expressions.
180         #    String refs are also allowed for now.
181         #  - True: group by all select fields of the model
182         # See compiler.get_group_by() for details.
183         self.group_by = None
184         self.order_by = ()
185         self.low_mark, self.high_mark = 0, None  # Used for offset/limit
186         self.distinct = False
187         self.distinct_fields = ()
188         self.select_for_update = False
189         self.select_for_update_nowait = False
190         self.select_for_update_skip_locked = False
191         self.select_for_update_of = ()
192         self.select_for_no_key_update = False
193 
194         self.select_related = False
195         # Arbitrary limit for select_related to prevents infinite recursion.
196         self.max_depth = 5
197 
198         # Holds the selects defined by a call to values() or values_list()
199         # excluding annotation_select and extra_select.
200         self.values_select = ()
201 
202         # SQL annotation-related attributes
203         self.annotations = {}  # Maps alias -> Annotation Expression
204         self.annotation_select_mask = None
205         self._annotation_select_cache = None
206 
207         # Set combination attributes
208         self.combinator = None
209         self.combinator_all = False
210         self.combined_queries = ()
211 
212         # These are for extensions. The contents are more or less appended
213         # verbatim to the appropriate clause.
214         self.extra = {}  # Maps col_alias -> (col_sql, params).
215         self.extra_select_mask = None
216         self._extra_select_cache = None
217 
218         self.extra_tables = ()
219         self.extra_order_by = ()
220 
221         # A tuple that is a set of model field names and either True, if these
222         # are the fields to defer, or False if these are the only fields to
223         # load.
224         self.deferred_loading = (frozenset(), True)
225 
226         self._filtered_relations = {}
227 
228         self.explain_query = False
229         self.explain_format = None
230         self.explain_options = {}
231 
232     @property
233     def output_field(self):
234         if len(self.select) == 1:
235             select = self.select[0]
236             return getattr(select, 'target', None) or select.field
237         elif len(self.annotation_select) == 1:
238             return next(iter(self.annotation_select.values())).output_field
239 
240     @property
241     def has_select_fields(self):
242         return bool(self.select or self.annotation_select_mask or self.extra_select_mask)
243 
244     @cached_property
245     def base_table(self):
246         for alias in self.alias_map:
247             return alias
248 
249     def __str__(self):
250         """
251         Return the query as a string of SQL with the parameter values
252         substituted in (use sql_with_params() to see the unsubstituted string).
253 
254         Parameter values won't necessarily be quoted correctly, since that is
255         done by the database interface at execution time.
256         """
257         sql, params = self.sql_with_params()
258         return sql % params
259 
260     def sql_with_params(self):
261         """
262         Return the query as an SQL string and the parameters that will be
263         substituted into the query.
264         """
265         return self.get_compiler(DEFAULT_DB_ALIAS).as_sql()
266 
267     def __deepcopy__(self, memo):
268         """Limit the amount of work when a Query is deepcopied."""
269         result = self.clone()
270         memo[id(self)] = result
271         return result
272 
273     def get_compiler(self, using=None, connection=None):
274         if using is None and connection is None:
275             raise ValueError("Need either using or connection")
276         if using:
277             connection = connections[using]
278         return connection.ops.compiler(self.compiler)(self, connection, using)
279 
280     def get_meta(self):
281         """
282         Return the Options instance (the model._meta) from which to start
283         processing. Normally, this is self.model._meta, but it can be changed
284         by subclasses.
285         """
286         return self.model._meta
287 
288     def clone(self):
289         """
290         Return a copy of the current Query. A lightweight alternative to
291         to deepcopy().
292         """
293         obj = Empty()
294         obj.__class__ = self.__class__
295         # Copy references to everything.
296         obj.__dict__ = self.__dict__.copy()
297         # Clone attributes that can't use shallow copy.
298         obj.alias_refcount = self.alias_refcount.copy()
299         obj.alias_map = self.alias_map.copy()
300         obj.external_aliases = self.external_aliases.copy()
301         obj.table_map = self.table_map.copy()
302         obj.where = self.where.clone()
303         obj.annotations = self.annotations.copy()
304         if self.annotation_select_mask is None:
305             obj.annotation_select_mask = None
306         else:
307             obj.annotation_select_mask = self.annotation_select_mask.copy()
308         obj.combined_queries = tuple(query.clone() for query in self.combined_queries)
309         # _annotation_select_cache cannot be copied, as doing so breaks the
310         # (necessary) state in which both annotations and
311         # _annotation_select_cache point to the same underlying objects.
312         # It will get re-populated in the cloned queryset the next time it's
313         # used.
314         obj._annotation_select_cache = None
315         obj.extra = self.extra.copy()
316         if self.extra_select_mask is None:
317             obj.extra_select_mask = None
318         else:
319             obj.extra_select_mask = self.extra_select_mask.copy()
320         if self._extra_select_cache is None:
321             obj._extra_select_cache = None
322         else:
323             obj._extra_select_cache = self._extra_select_cache.copy()
324         if self.select_related is not False:
325             # Use deepcopy because select_related stores fields in nested
326             # dicts.
327             obj.select_related = copy.deepcopy(obj.select_related)
328         if 'subq_aliases' in self.__dict__:
329             obj.subq_aliases = self.subq_aliases.copy()
330         obj.used_aliases = self.used_aliases.copy()
331         obj._filtered_relations = self._filtered_relations.copy()
332         # Clear the cached_property
333         try:
334             del obj.base_table
335         except AttributeError:
336             pass
337         return obj
338 
339     def chain(self, klass=None):
340         """
341         Return a copy of the current Query that's ready for another operation.
342         The klass argument changes the type of the Query, e.g. UpdateQuery.
343         """
344         obj = self.clone()
345         if klass and obj.__class__ != klass:
346             obj.__class__ = klass
347         if not obj.filter_is_sticky:
348             obj.used_aliases = set()
349         obj.filter_is_sticky = False
350         if hasattr(obj, '_setup_query'):
351             obj._setup_query()
352         return obj
353 
354     def relabeled_clone(self, change_map):
355         clone = self.clone()
356         clone.change_aliases(change_map)
357         return clone
358 
359     def _get_col(self, target, field, alias):
360         if not self.alias_cols:
361             alias = None
362         return target.get_col(alias, field)
363 
364     def rewrite_cols(self, annotation, col_cnt):
365         # We must make sure the inner query has the referred columns in it.
366         # If we are aggregating over an annotation, then Django uses Ref()
367         # instances to note this. However, if we are annotating over a column
368         # of a related model, then it might be that column isn't part of the
369         # SELECT clause of the inner query, and we must manually make sure
370         # the column is selected. An example case is:
371         #    .aggregate(Sum('author__awards'))
372         # Resolving this expression results in a join to author, but there
373         # is no guarantee the awards column of author is in the select clause
374         # of the query. Thus we must manually add the column to the inner
375         # query.
376         orig_exprs = annotation.get_source_expressions()
377         new_exprs = []
378         for expr in orig_exprs:
379             # FIXME: These conditions are fairly arbitrary. Identify a better
380             # method of having expressions decide which code path they should
381             # take.
382             if isinstance(expr, Ref):
383                 # Its already a Ref to subquery (see resolve_ref() for
384                 # details)
385                 new_exprs.append(expr)
386             elif isinstance(expr, (WhereNode, Lookup)):
387                 # Decompose the subexpressions further. The code here is
388                 # copied from the else clause, but this condition must appear
389                 # before the contains_aggregate/is_summary condition below.
390                 new_expr, col_cnt = self.rewrite_cols(expr, col_cnt)
391                 new_exprs.append(new_expr)
392             else:
393                 # Reuse aliases of expressions already selected in subquery.
394                 for col_alias, selected_annotation in self.annotation_select.items():
395                     if selected_annotation is expr:
396                         new_expr = Ref(col_alias, expr)
397                         break
398                 else:
399                     # An expression that is not selected the subquery.
400                     if isinstance(expr, Col) or (expr.contains_aggregate and not expr.is_summary):
401                         # Reference column or another aggregate. Select it
402                         # under a non-conflicting alias.
403                         col_cnt += 1
404                         col_alias = '__col%d' % col_cnt
405                         self.annotations[col_alias] = expr
406                         self.append_annotation_mask([col_alias])
407                         new_expr = Ref(col_alias, expr)
408                     else:
409                         # Some other expression not referencing database values
410                         # directly. Its subexpression might contain Cols.
411                         new_expr, col_cnt = self.rewrite_cols(expr, col_cnt)
412                 new_exprs.append(new_expr)
413         annotation.set_source_expressions(new_exprs)
414         return annotation, col_cnt
415 
416     def get_aggregation(self, using, added_aggregate_names):
417         """
418         Return the dictionary with the values of the existing aggregations.
419         """
420         if not self.annotation_select:
421             return {}
422         existing_annotations = [
423             annotation for alias, annotation
424             in self.annotations.items()
425             if alias not in added_aggregate_names
426         ]
427         # Decide if we need to use a subquery.
428         #
429         # Existing annotations would cause incorrect results as get_aggregation()
430         # must produce just one result and thus must not use GROUP BY. But we
431         # aren't smart enough to remove the existing annotations from the
432         # query, so those would force us to use GROUP BY.
433         #
434         # If the query has limit or distinct, or uses set operations, then
435         # those operations must be done in a subquery so that the query
436         # aggregates on the limit and/or distinct results instead of applying
437         # the distinct and limit after the aggregation.
438         if (isinstance(self.group_by, tuple) or self.is_sliced or existing_annotations or
439                 self.distinct or self.combinator):
440             from django.db.models.sql.subqueries import AggregateQuery
441             outer_query = AggregateQuery(self.model)
442             inner_query = self.clone()
443             inner_query.select_for_update = False
444             inner_query.select_related = False
445             inner_query.set_annotation_mask(self.annotation_select)
446             if not self.is_sliced and not self.distinct_fields:
447                 # Queries with distinct_fields need ordering and when a limit
448                 # is applied we must take the slice from the ordered query.
449                 # Otherwise no need for ordering.
450                 inner_query.clear_ordering(True)
451             if not inner_query.distinct:
452                 # If the inner query uses default select and it has some
453                 # aggregate annotations, then we must make sure the inner
454                 # query is grouped by the main model's primary key. However,
455                 # clearing the select clause can alter results if distinct is
456                 # used.
457                 has_existing_aggregate_annotations = any(
458                     annotation for annotation in existing_annotations
459                     if getattr(annotation, 'contains_aggregate', True)
460                 )
461                 if inner_query.default_cols and has_existing_aggregate_annotations:
462                     inner_query.group_by = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)
463                 inner_query.default_cols = False
464 
465             relabels = {t: 'subquery' for t in inner_query.alias_map}
466             relabels[None] = 'subquery'
467             # Remove any aggregates marked for reduction from the subquery
468             # and move them to the outer AggregateQuery.
469             col_cnt = 0
470             for alias, expression in list(inner_query.annotation_select.items()):
471                 annotation_select_mask = inner_query.annotation_select_mask
472                 if expression.is_summary:
473                     expression, col_cnt = inner_query.rewrite_cols(expression, col_cnt)
474                     outer_query.annotations[alias] = expression.relabeled_clone(relabels)
475                     del inner_query.annotations[alias]
476                     annotation_select_mask.remove(alias)
477                 # Make sure the annotation_select wont use cached results.
478                 inner_query.set_annotation_mask(inner_query.annotation_select_mask)
479             if inner_query.select == () and not inner_query.default_cols and not inner_query.annotation_select_mask:
480                 # In case of Model.objects[0:3].count(), there would be no
481                 # field selected in the inner query, yet we must use a subquery.
482                 # So, make sure at least one field is selected.
483                 inner_query.select = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)
484             try:
485                 outer_query.add_subquery(inner_query, using)
486             except EmptyResultSet:
487                 return {
488                     alias: None
489                     for alias in outer_query.annotation_select
490                 }
491         else:
492             outer_query = self
493             self.select = ()
494             self.default_cols = False
495             self.extra = {}
496 
497         outer_query.clear_ordering(True)
498         outer_query.clear_limits()
499         outer_query.select_for_update = False
500         outer_query.select_related = False
501         compiler = outer_query.get_compiler(using)
502         result = compiler.execute_sql(SINGLE)
503         if result is None:
504             result = [None] * len(outer_query.annotation_select)
505 
506         converters = compiler.get_converters(outer_query.annotation_select.values())
507         result = next(compiler.apply_converters((result,), converters))
508 
509         return dict(zip(outer_query.annotation_select, result))
510 
511     def get_count(self, using):
512         """
513         Perform a COUNT() query using the current filter constraints.
514         """
515         obj = self.clone()
516         obj.add_annotation(Count('*'), alias='__count', is_summary=True)
517         number = obj.get_aggregation(using, ['__count'])['__count']
518         if number is None:
519             number = 0
520         return number
521 
522     def has_filters(self):
523         return self.where
524 
525     def has_results(self, using):
526         q = self.clone()
527         if not q.distinct:
528             if q.group_by is True:
529                 q.add_fields((f.attname for f in self.model._meta.concrete_fields), False)
530                 # Disable GROUP BY aliases to avoid orphaning references to the
531                 # SELECT clause which is about to be cleared.
532                 q.set_group_by(allow_aliases=False)
533             q.clear_select_clause()
534         q.clear_ordering(True)
535         q.set_limits(high=1)
536         compiler = q.get_compiler(using=using)
537         return compiler.has_results()
538 
539     def explain(self, using, format=None, **options):
540         q = self.clone()
541         q.explain_query = True
542         q.explain_format = format
543         q.explain_options = options
544         compiler = q.get_compiler(using=using)
545         return '\n'.join(compiler.explain_query())
546 
547     def combine(self, rhs, connector):
548         """
549         Merge the 'rhs' query into the current one (with any 'rhs' effects
550         being applied *after* (that is, "to the right of") anything in the
551         current query. 'rhs' is not modified during a call to this function.
552 
553         The 'connector' parameter describes how to connect filters from the
554         'rhs' query.
555         """
556         assert self.model == rhs.model, \
557             "Cannot combine queries on two different base models."
558         assert not self.is_sliced, \
559             "Cannot combine queries once a slice has been taken."
560         assert self.distinct == rhs.distinct, \
561             "Cannot combine a unique query with a non-unique query."
562         assert self.distinct_fields == rhs.distinct_fields, \
563             "Cannot combine queries with different distinct fields."
564 
565         # Work out how to relabel the rhs aliases, if necessary.
566         change_map = {}
567         conjunction = (connector == AND)
568 
569         # Determine which existing joins can be reused. When combining the
570         # query with AND we must recreate all joins for m2m filters. When
571         # combining with OR we can reuse joins. The reason is that in AND
572         # case a single row can't fulfill a condition like:
573         #     revrel__col=1 & revrel__col=2
574         # But, there might be two different related rows matching this
575         # condition. In OR case a single True is enough, so single row is
576         # enough, too.
577         #
578         # Note that we will be creating duplicate joins for non-m2m joins in
579         # the AND case. The results will be correct but this creates too many
580         # joins. This is something that could be fixed later on.
581         reuse = set() if conjunction else set(self.alias_map)
582         # Base table must be present in the query - this is the same
583         # table on both sides.
584         self.get_initial_alias()
585         joinpromoter = JoinPromoter(connector, 2, False)
586         joinpromoter.add_votes(
587             j for j in self.alias_map if self.alias_map[j].join_type == INNER)
588         rhs_votes = set()
589         # Now, add the joins from rhs query into the new query (skipping base
590         # table).
591         rhs_tables = list(rhs.alias_map)[1:]
592         for alias in rhs_tables:
593             join = rhs.alias_map[alias]
594             # If the left side of the join was already relabeled, use the
595             # updated alias.
596             join = join.relabeled_clone(change_map)
597             new_alias = self.join(join, reuse=reuse)
598             if join.join_type == INNER:
599                 rhs_votes.add(new_alias)
600             # We can't reuse the same join again in the query. If we have two
601             # distinct joins for the same connection in rhs query, then the
602             # combined query must have two joins, too.
603             reuse.discard(new_alias)
604             if alias != new_alias:
605                 change_map[alias] = new_alias
606             if not rhs.alias_refcount[alias]:
607                 # The alias was unused in the rhs query. Unref it so that it
608                 # will be unused in the new query, too. We have to add and
609                 # unref the alias so that join promotion has information of
610                 # the join type for the unused alias.
611                 self.unref_alias(new_alias)
612         joinpromoter.add_votes(rhs_votes)
613         joinpromoter.update_join_types(self)
614 
615         # Now relabel a copy of the rhs where-clause and add it to the current
616         # one.
617         w = rhs.where.clone()
618         w.relabel_aliases(change_map)
619         self.where.add(w, connector)
620 
621         # Selection columns and extra extensions are those provided by 'rhs'.
622         if rhs.select:
623             self.set_select([col.relabeled_clone(change_map) for col in rhs.select])
624         else:
625             self.select = ()
626 
627         if connector == OR:
628             # It would be nice to be able to handle this, but the queries don't
629             # really make sense (or return consistent value sets). Not worth
630             # the extra complexity when you can write a real query instead.
631             if self.extra and rhs.extra:
632                 raise ValueError("When merging querysets using 'or', you cannot have extra(select=...) on both sides.")
633         self.extra.update(rhs.extra)
634         extra_select_mask = set()
635         if self.extra_select_mask is not None:
636             extra_select_mask.update(self.extra_select_mask)
637         if rhs.extra_select_mask is not None:
638             extra_select_mask.update(rhs.extra_select_mask)
639         if extra_select_mask:
640             self.set_extra_mask(extra_select_mask)
641         self.extra_tables += rhs.extra_tables
642 
643         # Ordering uses the 'rhs' ordering, unless it has none, in which case
644         # the current ordering is used.
645         self.order_by = rhs.order_by or self.order_by
646         self.extra_order_by = rhs.extra_order_by or self.extra_order_by
647 
648     def deferred_to_data(self, target, callback):
649         """
650         Convert the self.deferred_loading data structure to an alternate data
651         structure, describing the field that *will* be loaded. This is used to
652         compute the columns to select from the database and also by the
653         QuerySet class to work out which fields are being initialized on each
654         model. Models that have all their fields included aren't mentioned in
655         the result, only those that have field restrictions in place.
656 
657         The "target" parameter is the instance that is populated (in place).
658         The "callback" is a function that is called whenever a (model, field)
659         pair need to be added to "target". It accepts three parameters:
660         "target", and the model and list of fields being added for that model.
661         """
662         field_names, defer = self.deferred_loading
663         if not field_names:
664             return
665         orig_opts = self.get_meta()
666         seen = {}
667         must_include = {orig_opts.concrete_model: {orig_opts.pk}}
668         for field_name in field_names:
669             parts = field_name.split(LOOKUP_SEP)
670             cur_model = self.model._meta.concrete_model
671             opts = orig_opts
672             for name in parts[:-1]:
673                 old_model = cur_model
674                 if name in self._filtered_relations:
675                     name = self._filtered_relations[name].relation_name
676                 source = opts.get_field(name)
677                 if is_reverse_o2o(source):
678                     cur_model = source.related_model
679                 else:
680                     cur_model = source.remote_field.model
681                 opts = cur_model._meta
682                 # Even if we're "just passing through" this model, we must add
683                 # both the current model's pk and the related reference field
684                 # (if it's not a reverse relation) to the things we select.
685                 if not is_reverse_o2o(source):
686                     must_include[old_model].add(source)
687                 add_to_dict(must_include, cur_model, opts.pk)
688             field = opts.get_field(parts[-1])
689             is_reverse_object = field.auto_created and not field.concrete
690             model = field.related_model if is_reverse_object else field.model
691             model = model._meta.concrete_model
692             if model == opts.model:
693                 model = cur_model
694             if not is_reverse_o2o(field):
695                 add_to_dict(seen, model, field)
696 
697         if defer:
698             # We need to load all fields for each model, except those that
699             # appear in "seen" (for all models that appear in "seen"). The only
700             # slight complexity here is handling fields that exist on parent
701             # models.
702             workset = {}
703             for model, values in seen.items():
704                 for field in model._meta.local_fields:
705                     if field not in values:
706                         m = field.model._meta.concrete_model
707                         add_to_dict(workset, m, field)
708             for model, values in must_include.items():
709                 # If we haven't included a model in workset, we don't add the
710                 # corresponding must_include fields for that model, since an
711                 # empty set means "include all fields". That's why there's no
712                 # "else" branch here.
713                 if model in workset:
714                     workset[model].update(values)
715             for model, values in workset.items():
716                 callback(target, model, values)
717         else:
718             for model, values in must_include.items():
719                 if model in seen:
720                     seen[model].update(values)
721                 else:
722                     # As we've passed through this model, but not explicitly
723                     # included any fields, we have to make sure it's mentioned
724                     # so that only the "must include" fields are pulled in.
725                     seen[model] = values
726             # Now ensure that every model in the inheritance chain is mentioned
727             # in the parent list. Again, it must be mentioned to ensure that
728             # only "must include" fields are pulled in.
729             for model in orig_opts.get_parent_list():
730                 seen.setdefault(model, set())
731             for model, values in seen.items():
732                 callback(target, model, values)
733 
734     def table_alias(self, table_name, create=False, filtered_relation=None):
735         """
736         Return a table alias for the given table_name and whether this is a
737         new alias or not.
738 
739         If 'create' is true, a new alias is always created. Otherwise, the
740         most recently created alias for the table (if one exists) is reused.
741         """
742         alias_list = self.table_map.get(table_name)
743         if not create and alias_list:
744             alias = alias_list[0]
745             self.alias_refcount[alias] += 1
746             return alias, False
747 
748         # Create a new alias for this table.
749         if alias_list:
750             alias = '%s%d' % (self.alias_prefix, len(self.alias_map) + 1)
751             alias_list.append(alias)
752         else:
753             # The first occurrence of a table uses the table name directly.
754             alias = filtered_relation.alias if filtered_relation is not None else table_name
755             self.table_map[table_name] = [alias]
756         self.alias_refcount[alias] = 1
757         return alias, True
758 
759     def ref_alias(self, alias):
760         """Increases the reference count for this alias."""
761         self.alias_refcount[alias] += 1
762 
763     def unref_alias(self, alias, amount=1):
764         """Decreases the reference count for this alias."""
765         self.alias_refcount[alias] -= amount
766 
767     def promote_joins(self, aliases):
768         """
769         Promote recursively the join type of given aliases and its children to
770         an outer join. If 'unconditional' is False, only promote the join if
771         it is nullable or the parent join is an outer join.
772 
773         The children promotion is done to avoid join chains that contain a LOUTER
774         b INNER c. So, if we have currently a INNER b INNER c and a->b is promoted,
775         then we must also promote b->c automatically, or otherwise the promotion
776         of a->b doesn't actually change anything in the query results.
777         """
778         aliases = list(aliases)
779         while aliases:
780             alias = aliases.pop(0)
781             if self.alias_map[alias].join_type is None:
782                 # This is the base table (first FROM entry) - this table
783                 # isn't really joined at all in the query, so we should not
784                 # alter its join type.
785                 continue
786             # Only the first alias (skipped above) should have None join_type
787             assert self.alias_map[alias].join_type is not None
788             parent_alias = self.alias_map[alias].parent_alias
789             parent_louter = parent_alias and self.alias_map[parent_alias].join_type == LOUTER
790             already_louter = self.alias_map[alias].join_type == LOUTER
791             if ((self.alias_map[alias].nullable or parent_louter) and
792                     not already_louter):
793                 self.alias_map[alias] = self.alias_map[alias].promote()
794                 # Join type of 'alias' changed, so re-examine all aliases that
795                 # refer to this one.
796                 aliases.extend(
797                     join for join in self.alias_map
798                     if self.alias_map[join].parent_alias == alias and join not in aliases
799                 )
800 
801     def demote_joins(self, aliases):
802         """
803         Change join type from LOUTER to INNER for all joins in aliases.
804 
805         Similarly to promote_joins(), this method must ensure no join chains
806         containing first an outer, then an inner join are generated. If we
807         are demoting b->c join in chain a LOUTER b LOUTER c then we must
808         demote a->b automatically, or otherwise the demotion of b->c doesn't
809         actually change anything in the query results. .
810         """
811         aliases = list(aliases)
812         while aliases:
813             alias = aliases.pop(0)
814             if self.alias_map[alias].join_type == LOUTER:
815                 self.alias_map[alias] = self.alias_map[alias].demote()
816                 parent_alias = self.alias_map[alias].parent_alias
817                 if self.alias_map[parent_alias].join_type == INNER:
818                     aliases.append(parent_alias)
819 
820     def reset_refcounts(self, to_counts):
821         """
822         Reset reference counts for aliases so that they match the value passed
823         in `to_counts`.
824         """
825         for alias, cur_refcount in self.alias_refcount.copy().items():
826             unref_amount = cur_refcount - to_counts.get(alias, 0)
827             self.unref_alias(alias, unref_amount)
828 
829     def change_aliases(self, change_map):
830         """
831         Change the aliases in change_map (which maps old-alias -> new-alias),
832         relabelling any references to them in select columns and the where
833         clause.
834         """
835         assert set(change_map).isdisjoint(change_map.values())
836 
837         # 1. Update references in "select" (normal columns plus aliases),
838         # "group by" and "where".
839         self.where.relabel_aliases(change_map)
840         if isinstance(self.group_by, tuple):
841             self.group_by = tuple([col.relabeled_clone(change_map) for col in self.group_by])
842         self.select = tuple([col.relabeled_clone(change_map) for col in self.select])
843         self.annotations = self.annotations and {
844             key: col.relabeled_clone(change_map) for key, col in self.annotations.items()
845         }
846 
847         # 2. Rename the alias in the internal table/alias datastructures.
848         for old_alias, new_alias in change_map.items():
849             if old_alias not in self.alias_map:
850                 continue
851             alias_data = self.alias_map[old_alias].relabeled_clone(change_map)
852             self.alias_map[new_alias] = alias_data
853             self.alias_refcount[new_alias] = self.alias_refcount[old_alias]
854             del self.alias_refcount[old_alias]
855             del self.alias_map[old_alias]
856 
857             table_aliases = self.table_map[alias_data.table_name]
858             for pos, alias in enumerate(table_aliases):
859                 if alias == old_alias:
860                     table_aliases[pos] = new_alias
861                     break
862         self.external_aliases = {
863             # Table is aliased or it's being changed and thus is aliased.
864             change_map.get(alias, alias): (aliased or alias in change_map)
865             for alias, aliased in self.external_aliases.items()
866         }
867 
868     def bump_prefix(self, outer_query):
869         """
870         Change the alias prefix to the next letter in the alphabet in a way
871         that the outer query's aliases and this query's aliases will not
872         conflict. Even tables that previously had no alias will get an alias
873         after this call.
874         """
875         def prefix_gen():
876             """
877             Generate a sequence of characters in alphabetical order:
878                 -> 'A', 'B', 'C', ...
879 
880             When the alphabet is finished, the sequence will continue with the
881             Cartesian product:
882                 -> 'AA', 'AB', 'AC', ...
883             """
884             alphabet = ascii_uppercase
885             prefix = chr(ord(self.alias_prefix) + 1)
886             yield prefix
887             for n in count(1):
888                 seq = alphabet[alphabet.index(prefix):] if prefix else alphabet
889                 for s in product(seq, repeat=n):
890                     yield ''.join(s)
891                 prefix = None
892 
893         if self.alias_prefix != outer_query.alias_prefix:
894             # No clashes between self and outer query should be possible.
895             return
896 
897         # Explicitly avoid infinite loop. The constant divider is based on how
898         # much depth recursive subquery references add to the stack. This value
899         # might need to be adjusted when adding or removing function calls from
900         # the code path in charge of performing these operations.
901         local_recursion_limit = sys.getrecursionlimit() // 16
902         for pos, prefix in enumerate(prefix_gen()):
903             if prefix not in self.subq_aliases:
904                 self.alias_prefix = prefix
905                 break
906             if pos > local_recursion_limit:
907                 raise RecursionError(
908                     'Maximum recursion depth exceeded: too many subqueries.'
909                 )
910         self.subq_aliases = self.subq_aliases.union([self.alias_prefix])
911         outer_query.subq_aliases = outer_query.subq_aliases.union(self.subq_aliases)
912         self.change_aliases({
913             alias: '%s%d' % (self.alias_prefix, pos)
914             for pos, alias in enumerate(self.alias_map)
915         })
916 
917     def get_initial_alias(self):
918         """
919         Return the first alias for this query, after increasing its reference
920         count.
921         """
922         if self.alias_map:
923             alias = self.base_table
924             self.ref_alias(alias)
925         else:
926             alias = self.join(BaseTable(self.get_meta().db_table, None))
927         return alias
928 
929     def count_active_tables(self):
930         """
931         Return the number of tables in this query with a non-zero reference
932         count. After execution, the reference counts are zeroed, so tables
933         added in compiler will not be seen by this method.
934         """
935         return len([1 for count in self.alias_refcount.values() if count])
936 
937     def join(self, join, reuse=None, reuse_with_filtered_relation=False):
938         """
939         Return an alias for the 'join', either reusing an existing alias for
940         that join or creating a new one. 'join' is either a
941         sql.datastructures.BaseTable or Join.
942 
943         The 'reuse' parameter can be either None which means all joins are
944         reusable, or it can be a set containing the aliases that can be reused.
945 
946         The 'reuse_with_filtered_relation' parameter is used when computing
947         FilteredRelation instances.
948 
949         A join is always created as LOUTER if the lhs alias is LOUTER to make
950         sure chains like t1 LOUTER t2 INNER t3 aren't generated. All new
951         joins are created as LOUTER if the join is nullable.
952         """
953         if reuse_with_filtered_relation and reuse:
954             reuse_aliases = [
955                 a for a, j in self.alias_map.items()
956                 if a in reuse and j.equals(join, with_filtered_relation=False)
957             ]
958         else:
959             reuse_aliases = [
960                 a for a, j in self.alias_map.items()
961                 if (reuse is None or a in reuse) and j == join
962             ]
963         if reuse_aliases:
964             if join.table_alias in reuse_aliases:
965                 reuse_alias = join.table_alias
966             else:
967                 # Reuse the most recent alias of the joined table
968                 # (a many-to-many relation may be joined multiple times).
969                 reuse_alias = reuse_aliases[-1]
970             self.ref_alias(reuse_alias)
971             return reuse_alias
972 
973         # No reuse is possible, so we need a new alias.
974         alias, _ = self.table_alias(join.table_name, create=True, filtered_relation=join.filtered_relation)
975         if join.join_type:
976             if self.alias_map[join.parent_alias].join_type == LOUTER or join.nullable:
977                 join_type = LOUTER
978             else:
979                 join_type = INNER
980             join.join_type = join_type
981         join.table_alias = alias
982         self.alias_map[alias] = join
983         return alias
984 
985     def join_parent_model(self, opts, model, alias, seen):
986         """
987         Make sure the given 'model' is joined in the query. If 'model' isn't
988         a parent of 'opts' or if it is None this method is a no-op.
989 
990         The 'alias' is the root alias for starting the join, 'seen' is a dict
991         of model -> alias of existing joins. It must also contain a mapping
992         of None -> some alias. This will be returned in the no-op case.
993         """
994         if model in seen:
995             return seen[model]
996         chain = opts.get_base_chain(model)
997         if not chain:
998             return alias
999         curr_opts = opts
1000         for int_model in chain:
1001             if int_model in seen:
1002                 curr_opts = int_model._meta
1003                 alias = seen[int_model]
1004                 continue
1005             # Proxy model have elements in base chain
1006             # with no parents, assign the new options
1007             # object and skip to the next base in that
1008             # case
1009             if not curr_opts.parents[int_model]:
1010                 curr_opts = int_model._meta
1011                 continue
1012             link_field = curr_opts.get_ancestor_link(int_model)
1013             join_info = self.setup_joins([link_field.name], curr_opts, alias)
1014             curr_opts = int_model._meta
1015             alias = seen[int_model] = join_info.joins[-1]
1016         return alias or seen[None]
1017 
1018     def add_annotation(self, annotation, alias, is_summary=False):
1019         """Add a single annotation expression to the Query."""
1020         annotation = annotation.resolve_expression(self, allow_joins=True, reuse=None,
1021                                                    summarize=is_summary)
1022         self.append_annotation_mask([alias])
1023         self.annotations[alias] = annotation
1024 
1025     def resolve_expression(self, query, *args, **kwargs):
1026         clone = self.clone()
1027         # Subqueries need to use a different set of aliases than the outer query.
1028         clone.bump_prefix(query)
1029         clone.subquery = True
1030         # It's safe to drop ordering if the queryset isn't using slicing,
1031         # distinct(*fields) or select_for_update().
1032         if (self.low_mark == 0 and self.high_mark is None and
1033                 not self.distinct_fields and
1034                 not self.select_for_update):
1035             clone.clear_ordering(True)
1036         clone.where.resolve_expression(query, *args, **kwargs)
1037         for key, value in clone.annotations.items():
1038             resolved = value.resolve_expression(query, *args, **kwargs)
1039             if hasattr(resolved, 'external_aliases'):
1040                 resolved.external_aliases.update(clone.external_aliases)
1041             clone.annotations[key] = resolved
1042         # Outer query's aliases are considered external.
1043         for alias, table in query.alias_map.items():
1044             clone.external_aliases[alias] = (
1045                 (isinstance(table, Join) and table.join_field.related_model._meta.db_table != alias) or
1046                 (isinstance(table, BaseTable) and table.table_name != table.table_alias)
1047             )
1048         return clone
1049 
1050     def get_external_cols(self):
1051         exprs = chain(self.annotations.values(), self.where.children)
1052         return [
1053             col for col in self._gen_cols(exprs)
1054             if col.alias in self.external_aliases
1055         ]
1056 
1057     def as_sql(self, compiler, connection):
1058         sql, params = self.get_compiler(connection=connection).as_sql()
1059         if self.subquery:
1060             sql = '(%s)' % sql
1061         return sql, params
1062 
1063     def resolve_lookup_value(self, value, can_reuse, allow_joins):
1064         if hasattr(value, 'resolve_expression'):
1065             value = value.resolve_expression(
1066                 self, reuse=can_reuse, allow_joins=allow_joins,
1067             )
1068         elif isinstance(value, (list, tuple)):
1069             # The items of the iterable may be expressions and therefore need
1070             # to be resolved independently.
1071             return type(value)(
1072                 self.resolve_lookup_value(sub_value, can_reuse, allow_joins)
1073                 for sub_value in value
1074             )
1075         return value
1076 
1077     def solve_lookup_type(self, lookup):
1078         """
1079         Solve the lookup type from the lookup (e.g.: 'foobar__id__icontains').
1080         """
1081         lookup_splitted = lookup.split(LOOKUP_SEP)
1082         if self.annotations:
1083             expression, expression_lookups = refs_expression(lookup_splitted, self.annotations)
1084             if expression:
1085                 return expression_lookups, (), expression
1086         _, field, _, lookup_parts = self.names_to_path(lookup_splitted, self.get_meta())
1087         field_parts = lookup_splitted[0:len(lookup_splitted) - len(lookup_parts)]
1088         if len(lookup_parts) > 1 and not field_parts:
1089             raise FieldError(
1090                 'Invalid lookup "%s" for model %s".' %
1091                 (lookup, self.get_meta().model.__name__)
1092             )
1093         return lookup_parts, field_parts, False
1094 
1095     def check_query_object_type(self, value, opts, field):
1096         """
1097         Check whether the object passed while querying is of the correct type.
1098         If not, raise a ValueError specifying the wrong object.
1099         """
1100         if hasattr(value, '_meta'):
1101             if not check_rel_lookup_compatibility(value._meta.model, opts, field):
1102                 raise ValueError(
1103                     'Cannot query "%s": Must be "%s" instance.' %
1104                     (value, opts.object_name))
1105 
1106     def check_related_objects(self, field, value, opts):
1107         """Check the type of object passed to query relations."""
1108         if field.is_relation:
1109             # Check that the field and the queryset use the same model in a
1110             # query like .filter(author=Author.objects.all()). For example, the
1111             # opts would be Author's (from the author field) and value.model
1112             # would be Author.objects.all() queryset's .model (Author also).
1113             # The field is the related field on the lhs side.
1114             if (isinstance(value, Query) and not value.has_select_fields and
1115                     not check_rel_lookup_compatibility(value.model, opts, field)):
1116                 raise ValueError(
1117                     'Cannot use QuerySet for "%s": Use a QuerySet for "%s".' %
1118                     (value.model._meta.object_name, opts.object_name)
1119                 )
1120             elif hasattr(value, '_meta'):
1121                 self.check_query_object_type(value, opts, field)
1122             elif hasattr(value, '__iter__'):
1123                 for v in value:
1124                     self.check_query_object_type(v, opts, field)
1125 
1126     def check_filterable(self, expression):
1127         """Raise an error if expression cannot be used in a WHERE clause."""
1128         if (
1129             hasattr(expression, 'resolve_expression') and
1130             not getattr(expression, 'filterable', True)
1131         ):
1132             raise NotSupportedError(
1133                 expression.__class__.__name__ + ' is disallowed in the filter '
1134                 'clause.'
1135             )
1136         if hasattr(expression, 'get_source_expressions'):
1137             for expr in expression.get_source_expressions():
1138                 self.check_filterable(expr)
1139 
1140     def build_lookup(self, lookups, lhs, rhs):
1141         """
1142         Try to extract transforms and lookup from given lhs.
1143 
1144         The lhs value is something that works like SQLExpression.
1145         The rhs value is what the lookup is going to compare against.
1146         The lookups is a list of names to extract using get_lookup()
1147         and get_transform().
1148         """
1149         # __exact is the default lookup if one isn't given.
1150         *transforms, lookup_name = lookups or ['exact']
1151         for name in transforms:
1152             lhs = self.try_transform(lhs, name)
1153         # First try get_lookup() so that the lookup takes precedence if the lhs
1154         # supports both transform and lookup for the name.
1155         lookup_class = lhs.get_lookup(lookup_name)
1156         if not lookup_class:
1157             if lhs.field.is_relation:
1158                 raise FieldError('Related Field got invalid lookup: {}'.format(lookup_name))
1159             # A lookup wasn't found. Try to interpret the name as a transform
1160             # and do an Exact lookup against it.
1161             lhs = self.try_transform(lhs, lookup_name)
1162             lookup_name = 'exact'
1163             lookup_class = lhs.get_lookup(lookup_name)
1164             if not lookup_class:
1165                 return
1166 
1167         lookup = lookup_class(lhs, rhs)
1168         # Interpret '__exact=None' as the sql 'is NULL'; otherwise, reject all
1169         # uses of None as a query value unless the lookup supports it.
1170         if lookup.rhs is None and not lookup.can_use_none_as_rhs:
1171             if lookup_name not in ('exact', 'iexact'):
1172                 raise ValueError("Cannot use None as a query value")
1173             return lhs.get_lookup('isnull')(lhs, True)
1174 
1175         # For Oracle '' is equivalent to null. The check must be done at this
1176         # stage because join promotion can't be done in the compiler. Using
1177         # DEFAULT_DB_ALIAS isn't nice but it's the best that can be done here.
1178         # A similar thing is done in is_nullable(), too.
1179         if (connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls and
1180                 lookup_name == 'exact' and lookup.rhs == ''):
1181             return lhs.get_lookup('isnull')(lhs, True)
1182 
1183         return lookup
1184 
1185     def try_transform(self, lhs, name):
1186         """
1187         Helper method for build_lookup(). Try to fetch and initialize
1188         a transform for name parameter from lhs.
1189         """
1190         transform_class = lhs.get_transform(name)
1191         if transform_class:
1192             return transform_class(lhs)
1193         else:
1194             output_field = lhs.output_field.__class__
1195             suggested_lookups = difflib.get_close_matches(name, output_field.get_lookups())
1196             if suggested_lookups:
1197                 suggestion = ', perhaps you meant %s?' % ' or '.join(suggested_lookups)
1198             else:
1199                 suggestion = '.'
1200             raise FieldError(
1201                 "Unsupported lookup '%s' for %s or join on the field not "
1202                 "permitted%s" % (name, output_field.__name__, suggestion)
1203             )
1204 
1205     def build_filter(self, filter_expr, branch_negated=False, current_negated=False,
1206                      can_reuse=None, allow_joins=True, split_subq=True,
1207                      reuse_with_filtered_relation=False, check_filterable=True):
1208         """
1209         Build a WhereNode for a single filter clause but don't add it
1210         to this Query. Query.add_q() will then add this filter to the where
1211         Node.
1212 
1213         The 'branch_negated' tells us if the current branch contains any
1214         negations. This will be used to determine if subqueries are needed.
1215 
1216         The 'current_negated' is used to determine if the current filter is
1217         negated or not and this will be used to determine if IS NULL filtering
1218         is needed.
1219 
1220         The difference between current_negated and branch_negated is that
1221         branch_negated is set on first negation, but current_negated is
1222         flipped for each negation.
1223 
1224         Note that add_filter will not do any negating itself, that is done
1225         upper in the code by add_q().
1226 
1227         The 'can_reuse' is a set of reusable joins for multijoins.
1228 
1229         If 'reuse_with_filtered_relation' is True, then only joins in can_reuse
1230         will be reused.
1231 
1232         The method will create a filter clause that can be added to the current
1233         query. However, if the filter isn't added to the query then the caller
1234         is responsible for unreffing the joins used.
1235         """
1236         if isinstance(filter_expr, dict):
1237             raise FieldError("Cannot parse keyword query as dict")
1238         if isinstance(filter_expr, Q):
1239             return self._add_q(
1240                 filter_expr,
1241                 branch_negated=branch_negated,
1242                 current_negated=current_negated,
1243                 used_aliases=can_reuse,
1244                 allow_joins=allow_joins,
1245                 split_subq=split_subq,
1246                 check_filterable=check_filterable,
1247             )
1248         if hasattr(filter_expr, 'resolve_expression'):
1249             if not getattr(filter_expr, 'conditional', False):
1250                 raise TypeError('Cannot filter against a non-conditional expression.')
1251             condition = self.build_lookup(
1252                 ['exact'], filter_expr.resolve_expression(self, allow_joins=allow_joins), True
1253             )
1254             clause = self.where_class()
1255             clause.add(condition, AND)
1256             return clause, []
1257         arg, value = filter_expr
1258         if not arg:
1259             raise FieldError("Cannot parse keyword query %r" % arg)
1260         lookups, parts, reffed_expression = self.solve_lookup_type(arg)
1261 
1262         if check_filterable:
1263             self.check_filterable(reffed_expression)
1264 
1265         if not allow_joins and len(parts) > 1:
1266             raise FieldError("Joined field references are not permitted in this query")
1267 
1268         pre_joins = self.alias_refcount.copy()
1269         value = self.resolve_lookup_value(value, can_reuse, allow_joins)
1270         used_joins = {k for k, v in self.alias_refcount.items() if v > pre_joins.get(k, 0)}
1271 
1272         if check_filterable:
1273             self.check_filterable(value)
1274 
1275         clause = self.where_class()
1276         if reffed_expression:
1277             condition = self.build_lookup(lookups, reffed_expression, value)
1278             clause.add(condition, AND)
1279             return clause, []
1280 
1281         opts = self.get_meta()
1282         alias = self.get_initial_alias()
1283         allow_many = not branch_negated or not split_subq
1284 
1285         try:
1286             join_info = self.setup_joins(
1287                 parts, opts, alias, can_reuse=can_reuse, allow_many=allow_many,
1288                 reuse_with_filtered_relation=reuse_with_filtered_relation,
1289             )
1290 
1291             # Prevent iterator from being consumed by check_related_objects()
1292             if isinstance(value, Iterator):
1293                 value = list(value)
1294             self.check_related_objects(join_info.final_field, value, join_info.opts)
1295 
1296             # split_exclude() needs to know which joins were generated for the
1297             # lookup parts
1298             self._lookup_joins = join_info.joins
1299         except MultiJoin as e:
1300             return self.split_exclude(filter_expr, can_reuse, e.names_with_path)
1301 
1302         # Update used_joins before trimming since they are reused to determine
1303         # which joins could be later promoted to INNER.
1304         used_joins.update(join_info.joins)
1305         targets, alias, join_list = self.trim_joins(join_info.targets, join_info.joins, join_info.path)
1306         if can_reuse is not None:
1307             can_reuse.update(join_list)
1308 
1309         if join_info.final_field.is_relation:
1310             # No support for transforms for relational fields
1311             num_lookups = len(lookups)
1312             if num_lookups > 1:
1313                 raise FieldError('Related Field got invalid lookup: {}'.format(lookups[0]))
1314             if len(targets) == 1:
1315                 col = self._get_col(targets[0], join_info.final_field, alias)
1316             else:
1317                 col = MultiColSource(alias, targets, join_info.targets, join_info.final_field)
1318         else:
1319             col = self._get_col(targets[0], join_info.final_field, alias)
1320 
1321         condition = self.build_lookup(lookups, col, value)
1322         lookup_type = condition.lookup_name
1323         clause.add(condition, AND)
1324 
1325         require_outer = lookup_type == 'isnull' and condition.rhs is True and not current_negated
1326         if current_negated and (lookup_type != 'isnull' or condition.rhs is False) and condition.rhs is not None:
1327             require_outer = True
1328             if lookup_type != 'isnull':
1329                 # The condition added here will be SQL like this:
1330                 # NOT (col IS NOT NULL), where the first NOT is added in
1331                 # upper layers of code. The reason for addition is that if col
1332                 # is null, then col != someval will result in SQL "unknown"
1333                 # which isn't the same as in Python. The Python None handling
1334                 # is wanted, and it can be gotten by
1335                 # (col IS NULL OR col != someval)
1336                 #   <=>
1337                 # NOT (col IS NOT NULL AND col = someval).
1338                 if (
1339                     self.is_nullable(targets[0]) or
1340                     self.alias_map[join_list[-1]].join_type == LOUTER
1341                 ):
1342                     lookup_class = targets[0].get_lookup('isnull')
1343                     col = self._get_col(targets[0], join_info.targets[0], alias)
1344                     clause.add(lookup_class(col, False), AND)
1345                 # If someval is a nullable column, someval IS NOT NULL is
1346                 # added.
1347                 if isinstance(value, Col) and self.is_nullable(value.target):
1348                     lookup_class = value.target.get_lookup('isnull')
1349                     clause.add(lookup_class(value, False), AND)
1350         return clause, used_joins if not require_outer else ()
1351 
1352     def add_filter(self, filter_clause):
1353         self.add_q(Q(**{filter_clause[0]: filter_clause[1]}))
1354 
1355     def add_q(self, q_object):
1356         """
1357         A preprocessor for the internal _add_q(). Responsible for doing final
1358         join promotion.
1359         """
1360         # For join promotion this case is doing an AND for the added q_object
1361         # and existing conditions. So, any existing inner join forces the join
1362         # type to remain inner. Existing outer joins can however be demoted.
1363         # (Consider case where rel_a is LOUTER and rel_a__col=1 is added - if
1364         # rel_a doesn't produce any rows, then the whole condition must fail.
1365         # So, demotion is OK.
1366         existing_inner = {a for a in self.alias_map if self.alias_map[a].join_type == INNER}
1367         clause, _ = self._add_q(q_object, self.used_aliases)
1368         if clause:
1369             self.where.add(clause, AND)
1370         self.demote_joins(existing_inner)
1371 
1372     def build_where(self, filter_expr):
1373         return self.build_filter(filter_expr, allow_joins=False)[0]
1374 
1375     def _add_q(self, q_object, used_aliases, branch_negated=False,
1376                current_negated=False, allow_joins=True, split_subq=True,
1377                check_filterable=True):
1378         """Add a Q-object to the current filter."""
1379         connector = q_object.connector
1380         current_negated = current_negated ^ q_object.negated
1381         branch_negated = branch_negated or q_object.negated
1382         target_clause = self.where_class(connector=connector,
1383                                          negated=q_object.negated)
1384         joinpromoter = JoinPromoter(q_object.connector, len(q_object.children), current_negated)
1385         for child in q_object.children:
1386             child_clause, needed_inner = self.build_filter(
1387                 child, can_reuse=used_aliases, branch_negated=branch_negated,
1388                 current_negated=current_negated, allow_joins=allow_joins,
1389                 split_subq=split_subq, check_filterable=check_filterable,
1390             )
1391             joinpromoter.add_votes(needed_inner)
1392             if child_clause:
1393                 target_clause.add(child_clause, connector)
1394         needed_inner = joinpromoter.update_join_types(self)
1395         return target_clause, needed_inner
1396 
1397     def build_filtered_relation_q(self, q_object, reuse, branch_negated=False, current_negated=False):
1398         """Add a FilteredRelation object to the current filter."""
1399         connector = q_object.connector
1400         current_negated ^= q_object.negated
1401         branch_negated = branch_negated or q_object.negated
1402         target_clause = self.where_class(connector=connector, negated=q_object.negated)
1403         for child in q_object.children:
1404             if isinstance(child, Node):
1405                 child_clause = self.build_filtered_relation_q(
1406                     child, reuse=reuse, branch_negated=branch_negated,
1407                     current_negated=current_negated,
1408                 )
1409             else:
1410                 child_clause, _ = self.build_filter(
1411                     child, can_reuse=reuse, branch_negated=branch_negated,
1412                     current_negated=current_negated,
1413                     allow_joins=True, split_subq=False,
1414                     reuse_with_filtered_relation=True,
1415                 )
1416             target_clause.add(child_clause, connector)
1417         return target_clause
1418 
1419     def add_filtered_relation(self, filtered_relation, alias):
1420         filtered_relation.alias = alias
1421         lookups = dict(get_children_from_q(filtered_relation.condition))
1422         for lookup in chain((filtered_relation.relation_name,), lookups):
1423             lookup_parts, field_parts, _ = self.solve_lookup_type(lookup)
1424             shift = 2 if not lookup_parts else 1
1425             if len(field_parts) > (shift + len(lookup_parts)):
1426                 raise ValueError(
1427                     "FilteredRelation's condition doesn't support nested "
1428                     "relations (got %r)." % lookup
1429                 )
1430         self._filtered_relations[filtered_relation.alias] = filtered_relation
1431 
1432     def names_to_path(self, names, opts, allow_many=True, fail_on_missing=False):
1433         """
1434         Walk the list of names and turns them into PathInfo tuples. A single
1435         name in 'names' can generate multiple PathInfos (m2m, for example).
1436 
1437         'names' is the path of names to travel, 'opts' is the model Options we
1438         start the name resolving from, 'allow_many' is as for setup_joins().
1439         If fail_on_missing is set to True, then a name that can't be resolved
1440         will generate a FieldError.
1441 
1442         Return a list of PathInfo tuples. In addition return the final field
1443         (the last used join field) and target (which is a field guaranteed to
1444         contain the same value as the final field). Finally, return those names
1445         that weren't found (which are likely transforms and the final lookup).
1446         """
1447         path, names_with_path = [], []
1448         for pos, name in enumerate(names):
1449             cur_names_with_path = (name, [])
1450             if name == 'pk':
1451                 name = opts.pk.name
1452 
1453             field = None
1454             filtered_relation = None
1455             try:
1456                 field = opts.get_field(name)
1457             except FieldDoesNotExist:
1458                 if name in self.annotation_select:
1459                     field = self.annotation_select[name].output_field
1460                 elif name in self._filtered_relations and pos == 0:
1461                     filtered_relation = self._filtered_relations[name]
1462                     field = opts.get_field(filtered_relation.relation_name)
1463             if field is not None:
1464                 # Fields that contain one-to-many relations with a generic
1465                 # model (like a GenericForeignKey) cannot generate reverse
1466                 # relations and therefore cannot be used for reverse querying.
1467                 if field.is_relation and not field.related_model:
1468                     raise FieldError(
1469                         "Field %r does not generate an automatic reverse "
1470                         "relation and therefore cannot be used for reverse "
1471                         "querying. If it is a GenericForeignKey, consider "
1472                         "adding a GenericRelation." % name
1473                     )
1474                 try:
1475                     model = field.model._meta.concrete_model
1476                 except AttributeError:
1477                     # QuerySet.annotate() may introduce fields that aren't
1478                     # attached to a model.
1479                     model = None
1480             else:
1481                 # We didn't find the current field, so move position back
1482                 # one step.
1483                 pos -= 1
1484                 if pos == -1 or fail_on_missing:
1485                     available = sorted([
1486                         *get_field_names_from_opts(opts),
1487                         *self.annotation_select,
1488                         *self._filtered_relations,
1489                     ])
1490                     raise FieldError("Cannot resolve keyword '%s' into field. "
1491                                      "Choices are: %s" % (name, ", ".join(available)))
1492                 break
1493             # Check if we need any joins for concrete inheritance cases (the
1494             # field lives in parent, but we are currently in one of its
1495             # children)
1496             if model is not opts.model:
1497                 path_to_parent = opts.get_path_to_parent(model)
1498                 if path_to_parent:
1499                     path.extend(path_to_parent)
1500                     cur_names_with_path[1].extend(path_to_parent)
1501                     opts = path_to_parent[-1].to_opts
1502             if hasattr(field, 'get_path_info'):
1503                 pathinfos = field.get_path_info(filtered_relation)
1504                 if not allow_many:
1505                     for inner_pos, p in enumerate(pathinfos):
1506                         if p.m2m:
1507                             cur_names_with_path[1].extend(pathinfos[0:inner_pos + 1])
1508                             names_with_path.append(cur_names_with_path)
1509                             raise MultiJoin(pos + 1, names_with_path)
1510                 last = pathinfos[-1]
1511                 path.extend(pathinfos)
1512                 final_field = last.join_field
1513                 opts = last.to_opts
1514                 targets = last.target_fields
1515                 cur_names_with_path[1].extend(pathinfos)
1516                 names_with_path.append(cur_names_with_path)
1517             else:
1518                 # Local non-relational field.
1519                 final_field = field
1520                 targets = (field,)
1521                 if fail_on_missing and pos + 1 != len(names):
1522                     raise FieldError(
1523                         "Cannot resolve keyword %r into field. Join on '%s'"
1524                         " not permitted." % (names[pos + 1], name))
1525                 break
1526         return path, final_field, targets, names[pos + 1:]
1527 
1528     def setup_joins(self, names, opts, alias, can_reuse=None, allow_many=True,
1529                     reuse_with_filtered_relation=False):
1530         """
1531         Compute the necessary table joins for the passage through the fields
1532         given in 'names'. 'opts' is the Options class for the current model
1533         (which gives the table we are starting from), 'alias' is the alias for
1534         the table to start the joining from.
1535 
1536         The 'can_reuse' defines the reverse foreign key joins we can reuse. It
1537         can be None in which case all joins are reusable or a set of aliases
1538         that can be reused. Note that non-reverse foreign keys are always
1539         reusable when using setup_joins().
1540 
1541         The 'reuse_with_filtered_relation' can be used to force 'can_reuse'
1542         parameter and force the relation on the given connections.
1543 
1544         If 'allow_many' is False, then any reverse foreign key seen will
1545         generate a MultiJoin exception.
1546 
1547         Return the final field involved in the joins, the target field (used
1548         for any 'where' constraint), the final 'opts' value, the joins, the
1549         field path traveled to generate the joins, and a transform function
1550         that takes a field and alias and is equivalent to `field.get_col(alias)`
1551         in the simple case but wraps field transforms if they were included in
1552         names.
1553 
1554         The target field is the field containing the concrete value. Final
1555         field can be something different, for example foreign key pointing to
1556         that value. Final field is needed for example in some value
1557         conversions (convert 'obj' in fk__id=obj to pk val using the foreign
1558         key field for example).
1559         """
1560         joins = [alias]
1561         # The transform can't be applied yet, as joins must be trimmed later.
1562         # To avoid making every caller of this method look up transforms
1563         # directly, compute transforms here and create a partial that converts
1564         # fields to the appropriate wrapped version.
1565 
1566         def final_transformer(field, alias):
1567             return field.get_col(alias)
1568 
1569         # Try resolving all the names as fields first. If there's an error,
1570         # treat trailing names as lookups until a field can be resolved.
1571         last_field_exception = None
1572         for pivot in range(len(names), 0, -1):
1573             try:
1574                 path, final_field, targets, rest = self.names_to_path(
1575                     names[:pivot], opts, allow_many, fail_on_missing=True,
1576                 )
1577             except FieldError as exc:
1578                 if pivot == 1:
1579                     # The first item cannot be a lookup, so it's safe
1580                     # to raise the field error here.
1581                     raise
1582                 else:
1583                     last_field_exception = exc
1584             else:
1585                 # The transforms are the remaining items that couldn't be
1586                 # resolved into fields.
1587                 transforms = names[pivot:]
1588                 break
1589         for name in transforms:
1590             def transform(field, alias, *, name, previous):
1591                 try:
1592                     wrapped = previous(field, alias)
1593                     return self.try_transform(wrapped, name)
1594                 except FieldError:
1595                     # FieldError is raised if the transform doesn't exist.
1596                     if isinstance(final_field, Field) and last_field_exception:
1597                         raise last_field_exception
1598                     else:
1599                         raise
1600             final_transformer = functools.partial(transform, name=name, previous=final_transformer)
1601         # Then, add the path to the query's joins. Note that we can't trim
1602         # joins at this stage - we will need the information about join type
1603         # of the trimmed joins.
1604         for join in path:
1605             if join.filtered_relation:
1606                 filtered_relation = join.filtered_relation.clone()
1607                 table_alias = filtered_relation.alias
1608             else:
1609                 filtered_relation = None
1610                 table_alias = None
1611             opts = join.to_opts
1612             if join.direct:
1613                 nullable = self.is_nullable(join.join_field)
1614             else:
1615                 nullable = True
1616             connection = Join(
1617                 opts.db_table, alias, table_alias, INNER, join.join_field,
1618                 nullable, filtered_relation=filtered_relation,
1619             )
1620             reuse = can_reuse if join.m2m or reuse_with_filtered_relation else None
1621             alias = self.join(
1622                 connection, reuse=reuse,
1623                 reuse_with_filtered_relation=reuse_with_filtered_relation,
1624             )
1625             joins.append(alias)
1626             if filtered_relation:
1627                 filtered_relation.path = joins[:]
1628         return JoinInfo(final_field, targets, opts, joins, path, final_transformer)
1629 
1630     def trim_joins(self, targets, joins, path):
1631         """
1632         The 'target' parameter is the final field being joined to, 'joins'
1633         is the full list of join aliases. The 'path' contain the PathInfos
1634         used to create the joins.
1635 
1636         Return the final target field and table alias and the new active
1637         joins.
1638 
1639         Always trim any direct join if the target column is already in the
1640         previous table. Can't trim reverse joins as it's unknown if there's
1641         anything on the other side of the join.
1642         """
1643         joins = joins[:]
1644         for pos, info in enumerate(reversed(path)):
1645             if len(joins) == 1 or not info.direct:
1646                 break
1647             if info.filtered_relation:
1648                 break
1649             join_targets = {t.column for t in info.join_field.foreign_related_fields}
1650             cur_targets = {t.column for t in targets}
1651             if not cur_targets.issubset(join_targets):
1652                 break
1653             targets_dict = {r[1].column: r[0] for r in info.join_field.related_fields if r[1].column in cur_targets}
1654             targets = tuple(targets_dict[t.column] for t in targets)
1655             self.unref_alias(joins.pop())
1656         return targets, joins[-1], joins
1657 
1658     @classmethod
1659     def _gen_cols(cls, exprs):
1660         for expr in exprs:
1661             if isinstance(expr, Col):
1662                 yield expr
1663             else:
1664                 yield from cls._gen_cols(expr.get_source_expressions())
1665 
1666     @classmethod
1667     def _gen_col_aliases(cls, exprs):
1668         yield from (expr.alias for expr in cls._gen_cols(exprs))
1669 
1670     def resolve_ref(self, name, allow_joins=True, reuse=None, summarize=False):
1671         if not allow_joins and LOOKUP_SEP in name:
1672             raise FieldError("Joined field references are not permitted in this query")
1673         annotation = self.annotations.get(name)
1674         if annotation is not None:
1675             if not allow_joins:
1676                 for alias in self._gen_col_aliases([annotation]):
1677                     if isinstance(self.alias_map[alias], Join):
1678                         raise FieldError(
1679                             'Joined field references are not permitted in '
1680                             'this query'
1681                         )
1682             if summarize:
1683                 # Summarize currently means we are doing an aggregate() query
1684                 # which is executed as a wrapped subquery if any of the
1685                 # aggregate() elements reference an existing annotation. In
1686                 # that case we need to return a Ref to the subquery's annotation.
1687                 return Ref(name, self.annotation_select[name])
1688             else:
1689                 return annotation
1690         else:
1691             field_list = name.split(LOOKUP_SEP)
1692             join_info = self.setup_joins(field_list, self.get_meta(), self.get_initial_alias(), can_reuse=reuse)
1693             targets, final_alias, join_list = self.trim_joins(join_info.targets, join_info.joins, join_info.path)
1694             if not allow_joins and len(join_list) > 1:
1695                 raise FieldError('Joined field references are not permitted in this query')
1696             if len(targets) > 1:
1697                 raise FieldError("Referencing multicolumn fields with F() objects "
1698                                  "isn't supported")
1699             # Verify that the last lookup in name is a field or a transform:
1700             # transform_function() raises FieldError if not.
1701             join_info.transform_function(targets[0], final_alias)
1702             if reuse is not None:
1703                 reuse.update(join_list)
1704             return self._get_col(targets[0], join_info.targets[0], join_list[-1])
1705 
1706     def split_exclude(self, filter_expr, can_reuse, names_with_path):
1707         """
1708         When doing an exclude against any kind of N-to-many relation, we need
1709         to use a subquery. This method constructs the nested query, given the
1710         original exclude filter (filter_expr) and the portion up to the first
1711         N-to-many relation field.
1712 
1713         For example, if the origin filter is ~Q(child__name='foo'), filter_expr
1714         is ('child__name', 'foo') and can_reuse is a set of joins usable for
1715         filters in the original query.
1716 
1717         We will turn this into equivalent of:
1718             WHERE NOT (pk IN (SELECT parent_id FROM thetable
1719                               WHERE name = 'foo' AND parent_id IS NOT NULL))
1720 
1721         It might be worth it to consider using WHERE NOT EXISTS as that has
1722         saner null handling, and is easier for the backend's optimizer to
1723         handle.
1724         """
1725         filter_lhs, filter_rhs = filter_expr
1726         if isinstance(filter_rhs, OuterRef):
1727             filter_expr = (filter_lhs, OuterRef(filter_rhs))
1728         elif isinstance(filter_rhs, F):
1729             filter_expr = (filter_lhs, OuterRef(filter_rhs.name))
1730         # Generate the inner query.
1731         query = Query(self.model)
1732         query._filtered_relations = self._filtered_relations
1733         query.add_filter(filter_expr)
1734         query.clear_ordering(True)
1735         # Try to have as simple as possible subquery -> trim leading joins from
1736         # the subquery.
1737         trimmed_prefix, contains_louter = query.trim_start(names_with_path)
1738 
1739         # Add extra check to make sure the selected field will not be null
1740         # since we are adding an IN <subquery> clause. This prevents the
1741         # database from tripping over IN (...,NULL,...) selects and returning
1742         # nothing
1743         col = query.select[0]
1744         select_field = col.target
1745         alias = col.alias
1746         if self.is_nullable(select_field):
1747             lookup_class = select_field.get_lookup('isnull')
1748             lookup = lookup_class(select_field.get_col(alias), False)
1749             query.where.add(lookup, AND)
1750         if alias in can_reuse:
1751             pk = select_field.model._meta.pk
1752             # Need to add a restriction so that outer query's filters are in effect for
1753             # the subquery, too.
1754             query.bump_prefix(self)
1755             lookup_class = select_field.get_lookup('exact')
1756             # Note that the query.select[0].alias is different from alias
1757             # due to bump_prefix above.
1758             lookup = lookup_class(pk.get_col(query.select[0].alias),
1759                                   pk.get_col(alias))
1760             query.where.add(lookup, AND)
1761             query.external_aliases[alias] = True
1762 
1763         condition, needed_inner = self.build_filter(
1764             ('%s__in' % trimmed_prefix, query),
1765             current_negated=True, branch_negated=True, can_reuse=can_reuse)
1766         if contains_louter:
1767             or_null_condition, _ = self.build_filter(
1768                 ('%s__isnull' % trimmed_prefix, True),
1769                 current_negated=True, branch_negated=True, can_reuse=can_reuse)
1770             condition.add(or_null_condition, OR)
1771             # Note that the end result will be:
1772             # (outercol NOT IN innerq AND outercol IS NOT NULL) OR outercol IS NULL.
1773             # This might look crazy but due to how IN works, this seems to be
1774             # correct. If the IS NOT NULL check is removed then outercol NOT
1775             # IN will return UNKNOWN. If the IS NULL check is removed, then if
1776             # outercol IS NULL we will not match the row.
1777         return condition, needed_inner
1778 
1779     def set_empty(self):
1780         self.where.add(NothingNode(), AND)
1781         for query in self.combined_queries:
1782             query.set_empty()
1783 
1784     def is_empty(self):
1785         return any(isinstance(c, NothingNode) for c in self.where.children)
1786 
1787     def set_limits(self, low=None, high=None):
1788         """
1789         Adjust the limits on the rows retrieved. Use low/high to set these,
1790         as it makes it more Pythonic to read and write. When the SQL query is
1791         created, convert them to the appropriate offset and limit values.
1792 
1793         Apply any limits passed in here to the existing constraints. Add low
1794         to the current low value and clamp both to any existing high value.
1795         """
1796         if high is not None:
1797             if self.high_mark is not None:
1798                 self.high_mark = min(self.high_mark, self.low_mark + high)
1799             else:
1800                 self.high_mark = self.low_mark + high
1801         if low is not None:
1802             if self.high_mark is not None:
1803                 self.low_mark = min(self.high_mark, self.low_mark + low)
1804             else:
1805                 self.low_mark = self.low_mark + low
1806 
1807         if self.low_mark == self.high_mark:
1808             self.set_empty()
1809 
1810     def clear_limits(self):
1811         """Clear any existing limits."""
1812         self.low_mark, self.high_mark = 0, None
1813 
1814     @property
1815     def is_sliced(self):
1816         return self.low_mark != 0 or self.high_mark is not None
1817 
1818     def has_limit_one(self):
1819         return self.high_mark is not None and (self.high_mark - self.low_mark) == 1
1820 
1821     def can_filter(self):
1822         """
1823         Return True if adding filters to this instance is still possible.
1824 
1825         Typically, this means no limits or offsets have been put on the results.
1826         """
1827         return not self.is_sliced
1828 
1829     def clear_select_clause(self):
1830         """Remove all fields from SELECT clause."""
1831         self.select = ()
1832         self.default_cols = False
1833         self.select_related = False
1834         self.set_extra_mask(())
1835         self.set_annotation_mask(())
1836 
1837     def clear_select_fields(self):
1838         """
1839         Clear the list of fields to select (but not extra_select columns).
1840         Some queryset types completely replace any existing list of select
1841         columns.
1842         """
1843         self.select = ()
1844         self.values_select = ()
1845 
1846     def add_select_col(self, col):
1847         self.select += col,
1848         self.values_select += col.output_field.name,
1849 
1850     def set_select(self, cols):
1851         self.default_cols = False
1852         self.select = tuple(cols)
1853 
1854     def add_distinct_fields(self, *field_names):
1855         """
1856         Add and resolve the given fields to the query's "distinct on" clause.
1857         """
1858         self.distinct_fields = field_names
1859         self.distinct = True
1860 
1861     def add_fields(self, field_names, allow_m2m=True):
1862         """
1863         Add the given (model) fields to the select set. Add the field names in
1864         the order specified.
1865         """
1866         alias = self.get_initial_alias()
1867         opts = self.get_meta()
1868 
1869         try:
1870             cols = []
1871             for name in field_names:
1872                 # Join promotion note - we must not remove any rows here, so
1873                 # if there is no existing joins, use outer join.
1874                 join_info = self.setup_joins(name.split(LOOKUP_SEP), opts, alias, allow_many=allow_m2m)
1875                 targets, final_alias, joins = self.trim_joins(
1876                     join_info.targets,
1877                     join_info.joins,
1878                     join_info.path,
1879                 )
1880                 for target in targets:
1881                     cols.append(join_info.transform_function(target, final_alias))
1882             if cols:
1883                 self.set_select(cols)
1884         except MultiJoin:
1885             raise FieldError("Invalid field name: '%s'" % name)
1886         except FieldError:
1887             if LOOKUP_SEP in name:
1888                 # For lookups spanning over relationships, show the error
1889                 # from the model on which the lookup failed.
1890                 raise
1891             else:
1892                 names = sorted([
1893                     *get_field_names_from_opts(opts), *self.extra,
1894                     *self.annotation_select, *self._filtered_relations
1895                 ])
1896                 raise FieldError("Cannot resolve keyword %r into field. "
1897                                  "Choices are: %s" % (name, ", ".join(names)))
1898 
1899     def add_ordering(self, *ordering):
1900         """
1901         Add items from the 'ordering' sequence to the query's "order by"
1902         clause. These items are either field names (not column names) --
1903         possibly with a direction prefix ('-' or '?') -- or OrderBy
1904         expressions.
1905 
1906         If 'ordering' is empty, clear all ordering from the query.
1907         """
1908         errors = []
1909         for item in ordering:
1910             if isinstance(item, str):
1911                 if '.' in item:
1912                     warnings.warn(
1913                         'Passing column raw column aliases to order_by() is '
1914                         'deprecated. Wrap %r in a RawSQL expression before '
1915                         'passing it to order_by().' % item,
1916                         category=RemovedInDjango40Warning,
1917                         stacklevel=3,
1918                     )
1919                     continue
1920                 if item == '?':
1921                     continue
1922                 if item.startswith('-'):
1923                     item = item[1:]
1924                 if item in self.annotations:
1925                     continue
1926                 if self.extra and item in self.extra:
1927                     continue
1928                 # names_to_path() validates the lookup. A descriptive
1929                 # FieldError will be raise if it's not.
1930                 self.names_to_path(item.split(LOOKUP_SEP), self.model._meta)
1931             elif not hasattr(item, 'resolve_expression'):
1932                 errors.append(item)
1933             if getattr(item, 'contains_aggregate', False):
1934                 raise FieldError(
1935                     'Using an aggregate in order_by() without also including '
1936                     'it in annotate() is not allowed: %s' % item
1937                 )
1938         if errors:
1939             raise FieldError('Invalid order_by arguments: %s' % errors)
1940         if ordering:
1941             self.order_by += ordering
1942         else:
1943             self.default_ordering = False
1944 
1945     def clear_ordering(self, force_empty):
1946         """
1947         Remove any ordering settings. If 'force_empty' is True, there will be
1948         no ordering in the resulting query (not even the model's default).
1949         """
1950         self.order_by = ()
1951         self.extra_order_by = ()
1952         if force_empty:
1953             self.default_ordering = False
1954 
1955     def set_group_by(self, allow_aliases=True):
1956         """
1957         Expand the GROUP BY clause required by the query.
1958 
1959         This will usually be the set of all non-aggregate fields in the
1960         return data. If the database backend supports grouping by the
1961         primary key, and the query would be equivalent, the optimization
1962         will be made automatically.
1963         """
1964         # Column names from JOINs to check collisions with aliases.
1965         if allow_aliases:
1966             column_names = set()
1967             seen_models = set()
1968             for join in list(self.alias_map.values())[1:]:  # Skip base table.
1969                 model = join.join_field.related_model
1970                 if model not in seen_models:
1971                     column_names.update({
1972                         field.column
1973                         for field in model._meta.local_concrete_fields
1974                     })
1975                     seen_models.add(model)
1976 
1977         group_by = list(self.select)
1978         if self.annotation_select:
1979             for alias, annotation in self.annotation_select.items():
1980                 signature = inspect.signature(annotation.get_group_by_cols)
1981                 if 'alias' not in signature.parameters:
1982                     annotation_class = annotation.__class__
1983                     msg = (
1984                         '`alias=None` must be added to the signature of '
1985                         '%s.%s.get_group_by_cols().'
1986                     ) % (annotation_class.__module__, annotation_class.__qualname__)
1987                     warnings.warn(msg, category=RemovedInDjango40Warning)
1988                     group_by_cols = annotation.get_group_by_cols()
1989                 else:
1990                     if not allow_aliases or alias in column_names:
1991                         alias = None
1992                     group_by_cols = annotation.get_group_by_cols(alias=alias)
1993                 group_by.extend(group_by_cols)
1994         self.group_by = tuple(group_by)
1995 
1996     def add_select_related(self, fields):
1997         """
1998         Set up the select_related data structure so that we only select
1999         certain related models (as opposed to all models, when
2000         self.select_related=True).
2001         """
2002         if isinstance(self.select_related, bool):
2003             field_dict = {}
2004         else:
2005             field_dict = self.select_related
2006         for field in fields:
2007             d = field_dict
2008             for part in field.split(LOOKUP_SEP):
2009                 d = d.setdefault(part, {})
2010         self.select_related = field_dict
2011 
2012     def add_extra(self, select, select_params, where, params, tables, order_by):
2013         """
2014         Add data to the various extra_* attributes for user-created additions
2015         to the query.
2016         """
2017         if select:
2018             # We need to pair any placeholder markers in the 'select'
2019             # dictionary with their parameters in 'select_params' so that
2020             # subsequent updates to the select dictionary also adjust the
2021             # parameters appropriately.
2022             select_pairs = {}
2023             if select_params:
2024                 param_iter = iter(select_params)
2025             else:
2026                 param_iter = iter([])
2027             for name, entry in select.items():
2028                 entry = str(entry)
2029                 entry_params = []
2030                 pos = entry.find("%s")
2031                 while pos != -1:
2032                     if pos == 0 or entry[pos - 1] != '%':
2033                         entry_params.append(next(param_iter))
2034                     pos = entry.find("%s", pos + 2)
2035                 select_pairs[name] = (entry, entry_params)
2036             self.extra.update(select_pairs)
2037         if where or params:
2038             self.where.add(ExtraWhere(where, params), AND)
2039         if tables:
2040             self.extra_tables += tuple(tables)
2041         if order_by:
2042             self.extra_order_by = order_by
2043 
2044     def clear_deferred_loading(self):
2045         """Remove any fields from the deferred loading set."""
2046         self.deferred_loading = (frozenset(), True)
2047 
2048     def add_deferred_loading(self, field_names):
2049         """
2050         Add the given list of model field names to the set of fields to
2051         exclude from loading from the database when automatic column selection
2052         is done. Add the new field names to any existing field names that
2053         are deferred (or removed from any existing field names that are marked
2054         as the only ones for immediate loading).
2055         """
2056         # Fields on related models are stored in the literal double-underscore
2057         # format, so that we can use a set datastructure. We do the foo__bar
2058         # splitting and handling when computing the SQL column names (as part of
2059         # get_columns()).
2060         existing, defer = self.deferred_loading
2061         if defer:
2062             # Add to existing deferred names.
2063             self.deferred_loading = existing.union(field_names), True
2064         else:
2065             # Remove names from the set of any existing "immediate load" names.
2066             self.deferred_loading = existing.difference(field_names), False
2067 
2068     def add_immediate_loading(self, field_names):
2069         """
2070         Add the given list of model field names to the set of fields to
2071         retrieve when the SQL is executed ("immediate loading" fields). The
2072         field names replace any existing immediate loading field names. If
2073         there are field names already specified for deferred loading, remove
2074         those names from the new field_names before storing the new names
2075         for immediate loading. (That is, immediate loading overrides any
2076         existing immediate values, but respects existing deferrals.)
2077         """
2078         existing, defer = self.deferred_loading
2079         field_names = set(field_names)
2080         if 'pk' in field_names:
2081             field_names.remove('pk')
2082             field_names.add(self.get_meta().pk.name)
2083 
2084         if defer:
2085             # Remove any existing deferred names from the current set before
2086             # setting the new names.
2087             self.deferred_loading = field_names.difference(existing), False
2088         else:
2089             # Replace any existing "immediate load" field names.
2090             self.deferred_loading = frozenset(field_names), False
2091 
2092     def get_loaded_field_names(self):
2093         """
2094         If any fields are marked to be deferred, return a dictionary mapping
2095         models to a set of names in those fields that will be loaded. If a
2096         model is not in the returned dictionary, none of its fields are
2097         deferred.
2098 
2099         If no fields are marked for deferral, return an empty dictionary.
2100         """
2101         # We cache this because we call this function multiple times
2102         # (compiler.fill_related_selections, query.iterator)
2103         try:
2104             return self._loaded_field_names_cache
2105         except AttributeError:
2106             collection = {}
2107             self.deferred_to_data(collection, self.get_loaded_field_names_cb)
2108             self._loaded_field_names_cache = collection
2109             return collection
2110 
2111     def get_loaded_field_names_cb(self, target, model, fields):
2112         """Callback used by get_deferred_field_names()."""
2113         target[model] = {f.attname for f in fields}
2114 
2115     def set_annotation_mask(self, names):
2116         """Set the mask of annotations that will be returned by the SELECT."""
2117         if names is None:
2118             self.annotation_select_mask = None
2119         else:
2120             self.annotation_select_mask = set(names)
2121         self._annotation_select_cache = None
2122 
2123     def append_annotation_mask(self, names):
2124         if self.annotation_select_mask is not None:
2125             self.set_annotation_mask(self.annotation_select_mask.union(names))
2126 
2127     def set_extra_mask(self, names):
2128         """
2129         Set the mask of extra select items that will be returned by SELECT.
2130         Don't remove them from the Query since they might be used later.
2131         """
2132         if names is None:
2133             self.extra_select_mask = None
2134         else:
2135             self.extra_select_mask = set(names)
2136         self._extra_select_cache = None
2137 
2138     def set_values(self, fields):
2139         self.select_related = False
2140         self.clear_deferred_loading()
2141         self.clear_select_fields()
2142 
2143         if fields:
2144             field_names = []
2145             extra_names = []
2146             annotation_names = []
2147             if not self.extra and not self.annotations:
2148                 # Shortcut - if there are no extra or annotations, then
2149                 # the values() clause must be just field names.
2150                 field_names = list(fields)
2151             else:
2152                 self.default_cols = False
2153                 for f in fields:
2154                     if f in self.extra_select:
2155                         extra_names.append(f)
2156                     elif f in self.annotation_select:
2157                         annotation_names.append(f)
2158                     else:
2159                         field_names.append(f)
2160             self.set_extra_mask(extra_names)
2161             self.set_annotation_mask(annotation_names)
2162         else:
2163             field_names = [f.attname for f in self.model._meta.concrete_fields]
2164         # Selected annotations must be known before setting the GROUP BY
2165         # clause.
2166         if self.group_by is True:
2167             self.add_fields((f.attname for f in self.model._meta.concrete_fields), False)
2168             # Disable GROUP BY aliases to avoid orphaning references to the
2169             # SELECT clause which is about to be cleared.
2170             self.set_group_by(allow_aliases=False)
2171             self.clear_select_fields()
2172         elif self.group_by:
2173             # Resolve GROUP BY annotation references if they are not part of
2174             # the selected fields anymore.
2175             group_by = []
2176             for expr in self.group_by:
2177                 if isinstance(expr, Ref) and expr.refs not in field_names:
2178                     expr = self.annotations[expr.refs]
2179                 group_by.append(expr)
2180             self.group_by = tuple(group_by)
2181 
2182         self.values_select = tuple(field_names)
2183         self.add_fields(field_names, True)
2184 
2185     @property
2186     def annotation_select(self):
2187         """
2188         Return the dictionary of aggregate columns that are not masked and
2189         should be used in the SELECT clause. Cache this result for performance.
2190         """
2191         if self._annotation_select_cache is not None:
2192             return self._annotation_select_cache
2193         elif not self.annotations:
2194             return {}
2195         elif self.annotation_select_mask is not None:
2196             self._annotation_select_cache = {
2197                 k: v for k, v in self.annotations.items()
2198                 if k in self.annotation_select_mask
2199             }
2200             return self._annotation_select_cache
2201         else:
2202             return self.annotations
2203 
2204     @property
2205     def extra_select(self):
2206         if self._extra_select_cache is not None:
2207             return self._extra_select_cache
2208         if not self.extra:
2209             return {}
2210         elif self.extra_select_mask is not None:
2211             self._extra_select_cache = {
2212                 k: v for k, v in self.extra.items()
2213                 if k in self.extra_select_mask
2214             }
2215             return self._extra_select_cache
2216         else:
2217             return self.extra
2218 
2219     def trim_start(self, names_with_path):
2220         """
2221         Trim joins from the start of the join path. The candidates for trim
2222         are the PathInfos in names_with_path structure that are m2m joins.
2223 
2224         Also set the select column so the start matches the join.
2225 
2226         This method is meant to be used for generating the subquery joins &
2227         cols in split_exclude().
2228 
2229         Return a lookup usable for doing outerq.filter(lookup=self) and a
2230         boolean indicating if the joins in the prefix contain a LEFT OUTER join.
2231         _"""
2232         all_paths = []
2233         for _, paths in names_with_path:
2234             all_paths.extend(paths)
2235         contains_louter = False
2236         # Trim and operate only on tables that were generated for
2237         # the lookup part of the query. That is, avoid trimming
2238         # joins generated for F() expressions.
2239         lookup_tables = [
2240             t for t in self.alias_map
2241             if t in self._lookup_joins or t == self.base_table
2242         ]
2243         for trimmed_paths, path in enumerate(all_paths):
2244             if path.m2m:
2245                 break
2246             if self.alias_map[lookup_tables[trimmed_paths + 1]].join_type == LOUTER:
2247                 contains_louter = True
2248             alias = lookup_tables[trimmed_paths]
2249             self.unref_alias(alias)
2250         # The path.join_field is a Rel, lets get the other side's field
2251         join_field = path.join_field.field
2252         # Build the filter prefix.
2253         paths_in_prefix = trimmed_paths
2254         trimmed_prefix = []
2255         for name, path in names_with_path:
2256             if paths_in_prefix - len(path) < 0:
2257                 break
2258             trimmed_prefix.append(name)
2259             paths_in_prefix -= len(path)
2260         trimmed_prefix.append(
2261             join_field.foreign_related_fields[0].name)
2262         trimmed_prefix = LOOKUP_SEP.join(trimmed_prefix)
2263         # Lets still see if we can trim the first join from the inner query
2264         # (that is, self). We can't do this for:
2265         # - LEFT JOINs because we would miss those rows that have nothing on
2266         #   the outer side,
2267         # - INNER JOINs from filtered relations because we would miss their
2268         #   filters.
2269         first_join = self.alias_map[lookup_tables[trimmed_paths + 1]]
2270         if first_join.join_type != LOUTER and not first_join.filtered_relation:
2271             select_fields = [r[0] for r in join_field.related_fields]
2272             select_alias = lookup_tables[trimmed_paths + 1]
2273             self.unref_alias(lookup_tables[trimmed_paths])
2274             extra_restriction = join_field.get_extra_restriction(
2275                 self.where_class, None, lookup_tables[trimmed_paths + 1])
2276             if extra_restriction:
2277                 self.where.add(extra_restriction, AND)
2278         else:
2279             # TODO: It might be possible to trim more joins from the start of the
2280             # inner query if it happens to have a longer join chain containing the
2281             # values in select_fields. Lets punt this one for now.
2282             select_fields = [r[1] for r in join_field.related_fields]
2283             select_alias = lookup_tables[trimmed_paths]
2284         # The found starting point is likely a Join instead of a BaseTable reference.
2285         # But the first entry in the query's FROM clause must not be a JOIN.
2286         for table in self.alias_map:
2287             if self.alias_refcount[table] > 0:
2288                 self.alias_map[table] = BaseTable(self.alias_map[table].table_name, table)
2289                 break
2290         self.set_select([f.get_col(select_alias) for f in select_fields])
2291         return trimmed_prefix, contains_louter
2292 
2293     def is_nullable(self, field):
2294         """
2295         Check if the given field should be treated as nullable.
2296 
2297         Some backends treat '' as null and Django treats such fields as
2298         nullable for those backends. In such situations field.null can be
2299         False even if we should treat the field as nullable.
2300         """
2301         # We need to use DEFAULT_DB_ALIAS here, as QuerySet does not have
2302         # (nor should it have) knowledge of which connection is going to be
2303         # used. The proper fix would be to defer all decisions where
2304         # is_nullable() is needed to the compiler stage, but that is not easy
2305         # to do currently.
2306         return (
2307             connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls and
2308             field.empty_strings_allowed
2309         ) or field.null
2310 
2311 
2312 def get_order_dir(field, default='ASC'):
2313     """
2314     Return the field name and direction for an order specification. For
2315     example, '-foo' is returned as ('foo', 'DESC').
2316 
2317     The 'default' param is used to indicate which way no prefix (or a '+'
2318     prefix) should sort. The '-' prefix always sorts the opposite way.
2319     """
2320     dirn = ORDER_DIR[default]
2321     if field[0] == '-':
2322         return field[1:], dirn[1]
2323     return field, dirn[0]
2324 
2325 
2326 def add_to_dict(data, key, value):
2327     """
2328     Add "value" to the set of values for "key", whether or not "key" already
2329     exists.
2330     """
2331     if key in data:
2332         data[key].add(value)
2333     else:
2334         data[key] = {value}
2335 
2336 
2337 def is_reverse_o2o(field):
2338     """
2339     Check if the given field is reverse-o2o. The field is expected to be some
2340     sort of relation field or related object.
2341     """
2342     return field.is_relation and field.one_to_one and not field.concrete
2343 
2344 
2345 class JoinPromoter:
2346     """
2347     A class to abstract away join promotion problems for complex filter
2348     conditions.
2349     """
2350 
2351     def __init__(self, connector, num_children, negated):
2352         self.connector = connector
2353         self.negated = negated
2354         if self.negated:
2355             if connector == AND:
2356                 self.effective_connector = OR
2357             else:
2358                 self.effective_connector = AND
2359         else:
2360             self.effective_connector = self.connector
2361         self.num_children = num_children
2362         # Maps of table alias to how many times it is seen as required for
2363         # inner and/or outer joins.
2364         self.votes = Counter()
2365 
2366     def add_votes(self, votes):
2367         """
2368         Add single vote per item to self.votes. Parameter can be any
2369         iterable.
2370         """
2371         self.votes.update(votes)
2372 
2373     def update_join_types(self, query):
2374         """
2375         Change join types so that the generated query is as efficient as
2376         possible, but still correct. So, change as many joins as possible
2377         to INNER, but don't make OUTER joins INNER if that could remove
2378         results from the query.
2379         """
2380         to_promote = set()
2381         to_demote = set()
2382         # The effective_connector is used so that NOT (a AND b) is treated
2383         # similarly to (a OR b) for join promotion.
2384         for table, votes in self.votes.items():
2385             # We must use outer joins in OR case when the join isn't contained
2386             # in all of the joins. Otherwise the INNER JOIN itself could remove
2387             # valid results. Consider the case where a model with rel_a and
2388             # rel_b relations is queried with rel_a__col=1 | rel_b__col=2. Now,
2389             # if rel_a join doesn't produce any results is null (for example
2390             # reverse foreign key or null value in direct foreign key), and
2391             # there is a matching row in rel_b with col=2, then an INNER join
2392             # to rel_a would remove a valid match from the query. So, we need
2393             # to promote any existing INNER to LOUTER (it is possible this
2394             # promotion in turn will be demoted later on).
2395             if self.effective_connector == 'OR' and votes < self.num_children:
2396                 to_promote.add(table)
2397             # If connector is AND and there is a filter that can match only
2398             # when there is a joinable row, then use INNER. For example, in
2399             # rel_a__col=1 & rel_b__col=2, if either of the rels produce NULL
2400             # as join output, then the col=1 or col=2 can't match (as
2401             # NULL=anything is always false).
2402             # For the OR case, if all children voted for a join to be inner,
2403             # then we can use INNER for the join. For example:
2404             #     (rel_a__col__icontains=Alex | rel_a__col__icontains=Russell)
2405             # then if rel_a doesn't produce any rows, the whole condition
2406             # can't match. Hence we can safely use INNER join.
2407             if self.effective_connector == 'AND' or (
2408                     self.effective_connector == 'OR' and votes == self.num_children):
2409                 to_demote.add(table)
2410             # Finally, what happens in cases where we have:
2411             #    (rel_a__col=1|rel_b__col=2) & rel_a__col__gte=0
2412             # Now, we first generate the OR clause, and promote joins for it
2413             # in the first if branch above. Both rel_a and rel_b are promoted
2414             # to LOUTER joins. After that we do the AND case. The OR case
2415             # voted no inner joins but the rel_a__col__gte=0 votes inner join
2416             # for rel_a. We demote it back to INNER join (in AND case a single
2417             # vote is enough). The demotion is OK, if rel_a doesn't produce
2418             # rows, then the rel_a__col__gte=0 clause can't be true, and thus
2419             # the whole clause must be false. So, it is safe to use INNER
2420             # join.
2421             # Note that in this example we could just as well have the __gte
2422             # clause and the OR clause swapped. Or we could replace the __gte
2423             # clause with an OR clause containing rel_a__col=1|rel_a__col=2,
2424             # and again we could safely demote to INNER.
2425         query.promote_joins(to_promote)
2426         query.demote_joins(to_demote)
2427         return to_demote

</code><intended_behavior>The methods responsible for constructing SQL queries from `FilteredRelation` objects, particularly those dealing with the `condition` attribute, should be adapted to support nested relations. This might involve the `build_filter` method or other related methods that compile `Q` objects into SQL. The code at this location should ensure that when a `FilteredRelation` includes a nested relation condition, the generated SQL correctly reflects the nested JOIN operations needed to implement such a query. This includes appropriately handling aliases for tables to avoid conflicts and ensuring that the conditions specified in the nested `Q` objects are applied correctly to the resulting SQL.</intended_behavior>]
2025-10-15 05:02:32.171 | INFO     | Overall retry 0 succeeded; ending workflow
2025-10-15 05:02:32.171 | INFO     | Search-only: skipping patch selection
2025-10-15 05:02:32.304 | INFO     | Task django__django-13170 completed successfully.
2025-10-15 05:02:32.305 | INFO     | No patch generated. You can try running ACR again.
