2025-10-15 04:21:28.035 | INFO     | Starting overall retry 0 with model gpt-4-0125-preview
2025-10-15 04:21:31.550 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=269, output_tokens=12, cost=0.003050
2025-10-15 04:21:47.622 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=449, output_tokens=694, cost=0.025310
2025-10-15 04:22:01.516 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=449, output_tokens=528, cost=0.020330
2025-10-15 04:22:02.801 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-15 04:22:12.890 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=567, output_tokens=432, cost=0.018630
2025-10-15 04:22:12.901 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-15 04:22:15.083 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=786, output_tokens=58, cost=0.009600
2025-10-15 04:22:15.084 | DEBUG    | Extracted a valid json.
2025-10-15 04:22:15.085 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_code(\"NotSupportedError\")",
        "search_class(\"Window\")",
        "search_class(\"Case\")",
        "search_class(\"When\")",
        "search_method(\"annotate\")"
    ],
    "bug_locations": []
}
2025-10-15 04:22:15.208 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-15 04:22:15.208 | DEBUG    | <Agent search> Analyzing search results.
2025-10-15 04:22:32.711 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=3032, output_tokens=763, cost=0.053210
2025-10-15 04:22:32.726 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-15 04:22:40.258 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=4011, output_tokens=337, cost=0.050220
2025-10-15 04:22:40.264 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-15 04:22:46.515 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=691, output_tokens=235, cost=0.013960
2025-10-15 04:22:46.515 | DEBUG    | Extracted a valid json.
2025-10-15 04:22:46.515 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [],
    "bug_locations": [
        {
            "file": "django/db/models/sql/compiler.py",
            "class": "",
            "method": "",
            "intended_behavior": "The code here should properly distinguish contexts where window functions are used, especially in 'SELECT' clauses. The fix should ensure that window expressions within annotations are compiled into SQL without incorrectly raising a 'NotSupportedError'. This adjustment must keep the validation against the use of window functions in prohibited clauses (like 'WHERE'), while allowing them in 'SELECT' clauses as per SQL standards."
        },
        {
            "file": "django/db/models/expressions.py",
            "class": "Window",
            "method": "",
            "intended_behavior": "Ensure that when a 'Window' expression is used within an 'annotate' call, it is flagged in a way that prevents 'NotSupportedError' from being incorrectly raised. This may involve adding additional checks or flags to indicate that the window expression is used in a supported context (i.e., within the 'SELECT' clause) and should not be treated as an error."
        }
    ]
}
2025-10-15 04:22:46.528 | DEBUG    | Bug location extracted successfully: [<file>django/db/models/sql/compiler.py</file>
<class>None</class>
<method>None</method>
<code>
1 import collections
2 import re
3 from functools import partial
4 from itertools import chain
5 
6 from django.core.exceptions import EmptyResultSet, FieldError
7 from django.db.models.constants import LOOKUP_SEP
8 from django.db.models.expressions import OrderBy, Random, RawSQL, Ref, Value
9 from django.db.models.functions import Cast
10 from django.db.models.query_utils import Q, select_related_descend
11 from django.db.models.sql.constants import (
12     CURSOR, GET_ITERATOR_CHUNK_SIZE, MULTI, NO_RESULTS, ORDER_DIR, SINGLE,
13 )
14 from django.db.models.sql.query import Query, get_order_dir
15 from django.db.transaction import TransactionManagementError
16 from django.db.utils import DatabaseError, NotSupportedError
17 from django.utils.functional import cached_property
18 from django.utils.hashable import make_hashable
19 
20 
21 class SQLCompiler:
22     def __init__(self, query, connection, using):
23         self.query = query
24         self.connection = connection
25         self.using = using
26         self.quote_cache = {'*': '*'}
27         # The select, klass_info, and annotations are needed by QuerySet.iterator()
28         # these are set as a side-effect of executing the query. Note that we calculate
29         # separately a list of extra select columns needed for grammatical correctness
30         # of the query, but these columns are not included in self.select.
31         self.select = None
32         self.annotation_col_map = None
33         self.klass_info = None
34         # Multiline ordering SQL clause may appear from RawSQL.
35         self.ordering_parts = re.compile(r'^(.*)\s(ASC|DESC)(.*)', re.MULTILINE | re.DOTALL)
36         self._meta_ordering = None
37 
38     def setup_query(self):
39         if all(self.query.alias_refcount[a] == 0 for a in self.query.alias_map):
40             self.query.get_initial_alias()
41         self.select, self.klass_info, self.annotation_col_map = self.get_select()
42         self.col_count = len(self.select)
43 
44     def pre_sql_setup(self):
45         """
46         Do any necessary class setup immediately prior to producing SQL. This
47         is for things that can't necessarily be done in __init__ because we
48         might not have all the pieces in place at that time.
49         """
50         self.setup_query()
51         order_by = self.get_order_by()
52         self.where, self.having = self.query.where.split_having()
53         extra_select = self.get_extra_select(order_by, self.select)
54         self.has_extra_select = bool(extra_select)
55         group_by = self.get_group_by(self.select + extra_select, order_by)
56         return extra_select, order_by, group_by
57 
58     def get_group_by(self, select, order_by):
59         """
60         Return a list of 2-tuples of form (sql, params).
61 
62         The logic of what exactly the GROUP BY clause contains is hard
63         to describe in other words than "if it passes the test suite,
64         then it is correct".
65         """
66         # Some examples:
67         #     SomeModel.objects.annotate(Count('somecol'))
68         #     GROUP BY: all fields of the model
69         #
70         #    SomeModel.objects.values('name').annotate(Count('somecol'))
71         #    GROUP BY: name
72         #
73         #    SomeModel.objects.annotate(Count('somecol')).values('name')
74         #    GROUP BY: all cols of the model
75         #
76         #    SomeModel.objects.values('name', 'pk').annotate(Count('somecol')).values('pk')
77         #    GROUP BY: name, pk
78         #
79         #    SomeModel.objects.values('name').annotate(Count('somecol')).values('pk')
80         #    GROUP BY: name, pk
81         #
82         # In fact, the self.query.group_by is the minimal set to GROUP BY. It
83         # can't be ever restricted to a smaller set, but additional columns in
84         # HAVING, ORDER BY, and SELECT clauses are added to it. Unfortunately
85         # the end result is that it is impossible to force the query to have
86         # a chosen GROUP BY clause - you can almost do this by using the form:
87         #     .values(*wanted_cols).annotate(AnAggregate())
88         # but any later annotations, extra selects, values calls that
89         # refer some column outside of the wanted_cols, order_by, or even
90         # filter calls can alter the GROUP BY clause.
91 
92         # The query.group_by is either None (no GROUP BY at all), True
93         # (group by select fields), or a list of expressions to be added
94         # to the group by.
95         if self.query.group_by is None:
96             return []
97         expressions = []
98         if self.query.group_by is not True:
99             # If the group by is set to a list (by .values() call most likely),
100             # then we need to add everything in it to the GROUP BY clause.
101             # Backwards compatibility hack for setting query.group_by. Remove
102             # when  we have public API way of forcing the GROUP BY clause.
103             # Converts string references to expressions.
104             for expr in self.query.group_by:
105                 if not hasattr(expr, 'as_sql'):
106                     expressions.append(self.query.resolve_ref(expr))
107                 else:
108                     expressions.append(expr)
109         # Note that even if the group_by is set, it is only the minimal
110         # set to group by. So, we need to add cols in select, order_by, and
111         # having into the select in any case.
112         for expr, _, _ in select:
113             cols = expr.get_group_by_cols()
114             for col in cols:
115                 expressions.append(col)
116         for expr, (sql, params, is_ref) in order_by:
117             # Skip References to the select clause, as all expressions in the
118             # select clause are already part of the group by.
119             if not expr.contains_aggregate and not is_ref:
120                 expressions.extend(expr.get_source_expressions())
121         having_group_by = self.having.get_group_by_cols() if self.having else ()
122         for expr in having_group_by:
123             expressions.append(expr)
124         result = []
125         seen = set()
126         expressions = self.collapse_group_by(expressions, having_group_by)
127 
128         for expr in expressions:
129             sql, params = self.compile(expr)
130             params_hash = make_hashable(params)
131             if (sql, params_hash) not in seen:
132                 result.append((sql, params))
133                 seen.add((sql, params_hash))
134         return result
135 
136     def collapse_group_by(self, expressions, having):
137         # If the DB can group by primary key, then group by the primary key of
138         # query's main model. Note that for PostgreSQL the GROUP BY clause must
139         # include the primary key of every table, but for MySQL it is enough to
140         # have the main table's primary key.
141         if self.connection.features.allows_group_by_pk:
142             # Determine if the main model's primary key is in the query.
143             pk = None
144             for expr in expressions:
145                 # Is this a reference to query's base table primary key? If the
146                 # expression isn't a Col-like, then skip the expression.
147                 if (getattr(expr, 'target', None) == self.query.model._meta.pk and
148                         getattr(expr, 'alias', None) == self.query.base_table):
149                     pk = expr
150                     break
151             # If the main model's primary key is in the query, group by that
152             # field, HAVING expressions, and expressions associated with tables
153             # that don't have a primary key included in the grouped columns.
154             if pk:
155                 pk_aliases = {
156                     expr.alias for expr in expressions
157                     if hasattr(expr, 'target') and expr.target.primary_key
158                 }
159                 expressions = [pk] + [
160                     expr for expr in expressions
161                     if expr in having or (
162                         getattr(expr, 'alias', None) is not None and expr.alias not in pk_aliases
163                     )
164                 ]
165         elif self.connection.features.allows_group_by_selected_pks:
166             # Filter out all expressions associated with a table's primary key
167             # present in the grouped columns. This is done by identifying all
168             # tables that have their primary key included in the grouped
169             # columns and removing non-primary key columns referring to them.
170             # Unmanaged models are excluded because they could be representing
171             # database views on which the optimization might not be allowed.
172             pks = {
173                 expr for expr in expressions
174                 if (
175                     hasattr(expr, 'target') and
176                     expr.target.primary_key and
177                     self.connection.features.allows_group_by_selected_pks_on_model(expr.target.model)
178                 )
179             }
180             aliases = {expr.alias for expr in pks}
181             expressions = [
182                 expr for expr in expressions if expr in pks or getattr(expr, 'alias', None) not in aliases
183             ]
184         return expressions
185 
186     def get_select(self):
187         """
188         Return three values:
189         - a list of 3-tuples of (expression, (sql, params), alias)
190         - a klass_info structure,
191         - a dictionary of annotations
192 
193         The (sql, params) is what the expression will produce, and alias is the
194         "AS alias" for the column (possibly None).
195 
196         The klass_info structure contains the following information:
197         - The base model of the query.
198         - Which columns for that model are present in the query (by
199           position of the select clause).
200         - related_klass_infos: [f, klass_info] to descent into
201 
202         The annotations is a dictionary of {'attname': column position} values.
203         """
204         select = []
205         klass_info = None
206         annotations = {}
207         select_idx = 0
208         for alias, (sql, params) in self.query.extra_select.items():
209             annotations[alias] = select_idx
210             select.append((RawSQL(sql, params), alias))
211             select_idx += 1
212         assert not (self.query.select and self.query.default_cols)
213         if self.query.default_cols:
214             cols = self.get_default_columns()
215         else:
216             # self.query.select is a special case. These columns never go to
217             # any model.
218             cols = self.query.select
219         if cols:
220             select_list = []
221             for col in cols:
222                 select_list.append(select_idx)
223                 select.append((col, None))
224                 select_idx += 1
225             klass_info = {
226                 'model': self.query.model,
227                 'select_fields': select_list,
228             }
229         for alias, annotation in self.query.annotation_select.items():
230             annotations[alias] = select_idx
231             select.append((annotation, alias))
232             select_idx += 1
233 
234         if self.query.select_related:
235             related_klass_infos = self.get_related_selections(select)
236             klass_info['related_klass_infos'] = related_klass_infos
237 
238             def get_select_from_parent(klass_info):
239                 for ki in klass_info['related_klass_infos']:
240                     if ki['from_parent']:
241                         ki['select_fields'] = (klass_info['select_fields'] +
242                                                ki['select_fields'])
243                     get_select_from_parent(ki)
244             get_select_from_parent(klass_info)
245 
246         ret = []
247         for col, alias in select:
248             try:
249                 sql, params = self.compile(col)
250             except EmptyResultSet:
251                 # Select a predicate that's always False.
252                 sql, params = '0', ()
253             else:
254                 sql, params = col.select_format(self, sql, params)
255             ret.append((col, (sql, params), alias))
256         return ret, klass_info, annotations
257 
258     def get_order_by(self):
259         """
260         Return a list of 2-tuples of form (expr, (sql, params, is_ref)) for the
261         ORDER BY clause.
262 
263         The order_by clause can alter the select clause (for example it
264         can add aliases to clauses that do not yet have one, or it can
265         add totally new select clauses).
266         """
267         if self.query.extra_order_by:
268             ordering = self.query.extra_order_by
269         elif not self.query.default_ordering:
270             ordering = self.query.order_by
271         elif self.query.order_by:
272             ordering = self.query.order_by
273         elif self.query.get_meta().ordering:
274             ordering = self.query.get_meta().ordering
275             self._meta_ordering = ordering
276         else:
277             ordering = []
278         if self.query.standard_ordering:
279             asc, desc = ORDER_DIR['ASC']
280         else:
281             asc, desc = ORDER_DIR['DESC']
282 
283         order_by = []
284         for field in ordering:
285             if hasattr(field, 'resolve_expression'):
286                 if isinstance(field, Value):
287                     # output_field must be resolved for constants.
288                     field = Cast(field, field.output_field)
289                 if not isinstance(field, OrderBy):
290                     field = field.asc()
291                 if not self.query.standard_ordering:
292                     field = field.copy()
293                     field.reverse_ordering()
294                 order_by.append((field, False))
295                 continue
296             if field == '?':  # random
297                 order_by.append((OrderBy(Random()), False))
298                 continue
299 
300             col, order = get_order_dir(field, asc)
301             descending = order == 'DESC'
302 
303             if col in self.query.annotation_select:
304                 # Reference to expression in SELECT clause
305                 order_by.append((
306                     OrderBy(Ref(col, self.query.annotation_select[col]), descending=descending),
307                     True))
308                 continue
309             if col in self.query.annotations:
310                 # References to an expression which is masked out of the SELECT
311                 # clause.
312                 expr = self.query.annotations[col]
313                 if isinstance(expr, Value):
314                     # output_field must be resolved for constants.
315                     expr = Cast(expr, expr.output_field)
316                 order_by.append((OrderBy(expr, descending=descending), False))
317                 continue
318 
319             if '.' in field:
320                 # This came in through an extra(order_by=...) addition. Pass it
321                 # on verbatim.
322                 table, col = col.split('.', 1)
323                 order_by.append((
324                     OrderBy(
325                         RawSQL('%s.%s' % (self.quote_name_unless_alias(table), col), []),
326                         descending=descending
327                     ), False))
328                 continue
329 
330             if not self.query.extra or col not in self.query.extra:
331                 # 'col' is of the form 'field' or 'field1__field2' or
332                 # '-field1__field2__field', etc.
333                 order_by.extend(self.find_ordering_name(
334                     field, self.query.get_meta(), default_order=asc))
335             else:
336                 if col not in self.query.extra_select:
337                     order_by.append((
338                         OrderBy(RawSQL(*self.query.extra[col]), descending=descending),
339                         False))
340                 else:
341                     order_by.append((
342                         OrderBy(Ref(col, RawSQL(*self.query.extra[col])), descending=descending),
343                         True))
344         result = []
345         seen = set()
346 
347         for expr, is_ref in order_by:
348             resolved = expr.resolve_expression(self.query, allow_joins=True, reuse=None)
349             if self.query.combinator:
350                 src = resolved.get_source_expressions()[0]
351                 # Relabel order by columns to raw numbers if this is a combined
352                 # query; necessary since the columns can't be referenced by the
353                 # fully qualified name and the simple column names may collide.
354                 for idx, (sel_expr, _, col_alias) in enumerate(self.select):
355                     if is_ref and col_alias == src.refs:
356                         src = src.source
357                     elif col_alias:
358                         continue
359                     if src == sel_expr:
360                         resolved.set_source_expressions([RawSQL('%d' % (idx + 1), ())])
361                         break
362                 else:
363                     if col_alias:
364                         raise DatabaseError('ORDER BY term does not match any column in the result set.')
365                     # Add column used in ORDER BY clause without an alias to
366                     # the selected columns.
367                     self.query.add_select_col(src)
368                     resolved.set_source_expressions([RawSQL('%d' % len(self.query.select), ())])
369             sql, params = self.compile(resolved)
370             # Don't add the same column twice, but the order direction is
371             # not taken into account so we strip it. When this entire method
372             # is refactored into expressions, then we can check each part as we
373             # generate it.
374             without_ordering = self.ordering_parts.search(sql).group(1)
375             params_hash = make_hashable(params)
376             if (without_ordering, params_hash) in seen:
377                 continue
378             seen.add((without_ordering, params_hash))
379             result.append((resolved, (sql, params, is_ref)))
380         return result
381 
382     def get_extra_select(self, order_by, select):
383         extra_select = []
384         if self.query.distinct and not self.query.distinct_fields:
385             select_sql = [t[1] for t in select]
386             for expr, (sql, params, is_ref) in order_by:
387                 without_ordering = self.ordering_parts.search(sql).group(1)
388                 if not is_ref and (without_ordering, params) not in select_sql:
389                     extra_select.append((expr, (without_ordering, params), None))
390         return extra_select
391 
392     def quote_name_unless_alias(self, name):
393         """
394         A wrapper around connection.ops.quote_name that doesn't quote aliases
395         for table names. This avoids problems with some SQL dialects that treat
396         quoted strings specially (e.g. PostgreSQL).
397         """
398         if name in self.quote_cache:
399             return self.quote_cache[name]
400         if ((name in self.query.alias_map and name not in self.query.table_map) or
401                 name in self.query.extra_select or (
402                     name in self.query.external_aliases and name not in self.query.table_map)):
403             self.quote_cache[name] = name
404             return name
405         r = self.connection.ops.quote_name(name)
406         self.quote_cache[name] = r
407         return r
408 
409     def compile(self, node):
410         vendor_impl = getattr(node, 'as_' + self.connection.vendor, None)
411         if vendor_impl:
412             sql, params = vendor_impl(self, self.connection)
413         else:
414             sql, params = node.as_sql(self, self.connection)
415         return sql, params
416 
417     def get_combinator_sql(self, combinator, all):
418         features = self.connection.features
419         compilers = [
420             query.get_compiler(self.using, self.connection)
421             for query in self.query.combined_queries if not query.is_empty()
422         ]
423         if not features.supports_slicing_ordering_in_compound:
424             for query, compiler in zip(self.query.combined_queries, compilers):
425                 if query.low_mark or query.high_mark:
426                     raise DatabaseError('LIMIT/OFFSET not allowed in subqueries of compound statements.')
427                 if compiler.get_order_by():
428                     raise DatabaseError('ORDER BY not allowed in subqueries of compound statements.')
429         parts = ()
430         for compiler in compilers:
431             try:
432                 # If the columns list is limited, then all combined queries
433                 # must have the same columns list. Set the selects defined on
434                 # the query on all combined queries, if not already set.
435                 if not compiler.query.values_select and self.query.values_select:
436                     compiler.query = compiler.query.clone()
437                     compiler.query.set_values((
438                         *self.query.extra_select,
439                         *self.query.values_select,
440                         *self.query.annotation_select,
441                     ))
442                 part_sql, part_args = compiler.as_sql()
443                 if compiler.query.combinator:
444                     # Wrap in a subquery if wrapping in parentheses isn't
445                     # supported.
446                     if not features.supports_parentheses_in_compound:
447                         part_sql = 'SELECT * FROM ({})'.format(part_sql)
448                     # Add parentheses when combining with compound query if not
449                     # already added for all compound queries.
450                     elif not features.supports_slicing_ordering_in_compound:
451                         part_sql = '({})'.format(part_sql)
452                 parts += ((part_sql, part_args),)
453             except EmptyResultSet:
454                 # Omit the empty queryset with UNION and with DIFFERENCE if the
455                 # first queryset is nonempty.
456                 if combinator == 'union' or (combinator == 'difference' and parts):
457                     continue
458                 raise
459         if not parts:
460             raise EmptyResultSet
461         combinator_sql = self.connection.ops.set_operators[combinator]
462         if all and combinator == 'union':
463             combinator_sql += ' ALL'
464         braces = '({})' if features.supports_slicing_ordering_in_compound else '{}'
465         sql_parts, args_parts = zip(*((braces.format(sql), args) for sql, args in parts))
466         result = [' {} '.format(combinator_sql).join(sql_parts)]
467         params = []
468         for part in args_parts:
469             params.extend(part)
470         return result, params
471 
472     def as_sql(self, with_limits=True, with_col_aliases=False):
473         """
474         Create the SQL for this query. Return the SQL string and list of
475         parameters.
476 
477         If 'with_limits' is False, any limit/offset information is not included
478         in the query.
479         """
480         refcounts_before = self.query.alias_refcount.copy()
481         try:
482             extra_select, order_by, group_by = self.pre_sql_setup()
483             for_update_part = None
484             # Is a LIMIT/OFFSET clause needed?
485             with_limit_offset = with_limits and (self.query.high_mark is not None or self.query.low_mark)
486             combinator = self.query.combinator
487             features = self.connection.features
488             if combinator:
489                 if not getattr(features, 'supports_select_{}'.format(combinator)):
490                     raise NotSupportedError('{} is not supported on this database backend.'.format(combinator))
491                 result, params = self.get_combinator_sql(combinator, self.query.combinator_all)
492             else:
493                 distinct_fields, distinct_params = self.get_distinct()
494                 # This must come after 'select', 'ordering', and 'distinct'
495                 # (see docstring of get_from_clause() for details).
496                 from_, f_params = self.get_from_clause()
497                 where, w_params = self.compile(self.where) if self.where is not None else ("", [])
498                 having, h_params = self.compile(self.having) if self.having is not None else ("", [])
499                 result = ['SELECT']
500                 params = []
501 
502                 if self.query.distinct:
503                     distinct_result, distinct_params = self.connection.ops.distinct_sql(
504                         distinct_fields,
505                         distinct_params,
506                     )
507                     result += distinct_result
508                     params += distinct_params
509 
510                 out_cols = []
511                 col_idx = 1
512                 for _, (s_sql, s_params), alias in self.select + extra_select:
513                     if alias:
514                         s_sql = '%s AS %s' % (s_sql, self.connection.ops.quote_name(alias))
515                     elif with_col_aliases:
516                         s_sql = '%s AS %s' % (s_sql, 'Col%d' % col_idx)
517                         col_idx += 1
518                     params.extend(s_params)
519                     out_cols.append(s_sql)
520 
521                 result += [', '.join(out_cols), 'FROM', *from_]
522                 params.extend(f_params)
523 
524                 if self.query.select_for_update and self.connection.features.has_select_for_update:
525                     if self.connection.get_autocommit():
526                         raise TransactionManagementError('select_for_update cannot be used outside of a transaction.')
527 
528                     if with_limit_offset and not self.connection.features.supports_select_for_update_with_limit:
529                         raise NotSupportedError(
530                             'LIMIT/OFFSET is not supported with '
531                             'select_for_update on this database backend.'
532                         )
533                     nowait = self.query.select_for_update_nowait
534                     skip_locked = self.query.select_for_update_skip_locked
535                     of = self.query.select_for_update_of
536                     # If it's a NOWAIT/SKIP LOCKED/OF query but the backend
537                     # doesn't support it, raise NotSupportedError to prevent a
538                     # possible deadlock.
539                     if nowait and not self.connection.features.has_select_for_update_nowait:
540                         raise NotSupportedError('NOWAIT is not supported on this database backend.')
541                     elif skip_locked and not self.connection.features.has_select_for_update_skip_locked:
542                         raise NotSupportedError('SKIP LOCKED is not supported on this database backend.')
543                     elif of and not self.connection.features.has_select_for_update_of:
544                         raise NotSupportedError('FOR UPDATE OF is not supported on this database backend.')
545                     for_update_part = self.connection.ops.for_update_sql(
546                         nowait=nowait,
547                         skip_locked=skip_locked,
548                         of=self.get_select_for_update_of_arguments(),
549                     )
550 
551                 if for_update_part and self.connection.features.for_update_after_from:
552                     result.append(for_update_part)
553 
554                 if where:
555                     result.append('WHERE %s' % where)
556                     params.extend(w_params)
557 
558                 grouping = []
559                 for g_sql, g_params in group_by:
560                     grouping.append(g_sql)
561                     params.extend(g_params)
562                 if grouping:
563                     if distinct_fields:
564                         raise NotImplementedError('annotate() + distinct(fields) is not implemented.')
565                     order_by = order_by or self.connection.ops.force_no_ordering()
566                     result.append('GROUP BY %s' % ', '.join(grouping))
567                     if self._meta_ordering:
568                         order_by = None
569                 if having:
570                     result.append('HAVING %s' % having)
571                     params.extend(h_params)
572 
573             if self.query.explain_query:
574                 result.insert(0, self.connection.ops.explain_query_prefix(
575                     self.query.explain_format,
576                     **self.query.explain_options
577                 ))
578 
579             if order_by:
580                 ordering = []
581                 for _, (o_sql, o_params, _) in order_by:
582                     ordering.append(o_sql)
583                     params.extend(o_params)
584                 result.append('ORDER BY %s' % ', '.join(ordering))
585 
586             if with_limit_offset:
587                 result.append(self.connection.ops.limit_offset_sql(self.query.low_mark, self.query.high_mark))
588 
589             if for_update_part and not self.connection.features.for_update_after_from:
590                 result.append(for_update_part)
591 
592             if self.query.subquery and extra_select:
593                 # If the query is used as a subquery, the extra selects would
594                 # result in more columns than the left-hand side expression is
595                 # expecting. This can happen when a subquery uses a combination
596                 # of order_by() and distinct(), forcing the ordering expressions
597                 # to be selected as well. Wrap the query in another subquery
598                 # to exclude extraneous selects.
599                 sub_selects = []
600                 sub_params = []
601                 for index, (select, _, alias) in enumerate(self.select, start=1):
602                     if not alias and with_col_aliases:
603                         alias = 'col%d' % index
604                     if alias:
605                         sub_selects.append("%s.%s" % (
606                             self.connection.ops.quote_name('subquery'),
607                             self.connection.ops.quote_name(alias),
608                         ))
609                     else:
610                         select_clone = select.relabeled_clone({select.alias: 'subquery'})
611                         subselect, subparams = select_clone.as_sql(self, self.connection)
612                         sub_selects.append(subselect)
613                         sub_params.extend(subparams)
614                 return 'SELECT %s FROM (%s) subquery' % (
615                     ', '.join(sub_selects),
616                     ' '.join(result),
617                 ), tuple(sub_params + params)
618 
619             return ' '.join(result), tuple(params)
620         finally:
621             # Finally do cleanup - get rid of the joins we created above.
622             self.query.reset_refcounts(refcounts_before)
623 
624     def get_default_columns(self, start_alias=None, opts=None, from_parent=None):
625         """
626         Compute the default columns for selecting every field in the base
627         model. Will sometimes be called to pull in related models (e.g. via
628         select_related), in which case "opts" and "start_alias" will be given
629         to provide a starting point for the traversal.
630 
631         Return a list of strings, quoted appropriately for use in SQL
632         directly, as well as a set of aliases used in the select statement (if
633         'as_pairs' is True, return a list of (alias, col_name) pairs instead
634         of strings as the first component and None as the second component).
635         """
636         result = []
637         if opts is None:
638             opts = self.query.get_meta()
639         only_load = self.deferred_to_columns()
640         start_alias = start_alias or self.query.get_initial_alias()
641         # The 'seen_models' is used to optimize checking the needed parent
642         # alias for a given field. This also includes None -> start_alias to
643         # be used by local fields.
644         seen_models = {None: start_alias}
645 
646         for field in opts.concrete_fields:
647             model = field.model._meta.concrete_model
648             # A proxy model will have a different model and concrete_model. We
649             # will assign None if the field belongs to this model.
650             if model == opts.model:
651                 model = None
652             if from_parent and model is not None and issubclass(
653                     from_parent._meta.concrete_model, model._meta.concrete_model):
654                 # Avoid loading data for already loaded parents.
655                 # We end up here in the case select_related() resolution
656                 # proceeds from parent model to child model. In that case the
657                 # parent model data is already present in the SELECT clause,
658                 # and we want to avoid reloading the same data again.
659                 continue
660             if field.model in only_load and field.attname not in only_load[field.model]:
661                 continue
662             alias = self.query.join_parent_model(opts, model, start_alias,
663                                                  seen_models)
664             column = field.get_col(alias)
665             result.append(column)
666         return result
667 
668     def get_distinct(self):
669         """
670         Return a quoted list of fields to use in DISTINCT ON part of the query.
671 
672         This method can alter the tables in the query, and thus it must be
673         called before get_from_clause().
674         """
675         result = []
676         params = []
677         opts = self.query.get_meta()
678 
679         for name in self.query.distinct_fields:
680             parts = name.split(LOOKUP_SEP)
681             _, targets, alias, joins, path, _, transform_function = self._setup_joins(parts, opts, None)
682             targets, alias, _ = self.query.trim_joins(targets, joins, path)
683             for target in targets:
684                 if name in self.query.annotation_select:
685                     result.append(name)
686                 else:
687                     r, p = self.compile(transform_function(target, alias))
688                     result.append(r)
689                     params.append(p)
690         return result, params
691 
692     def find_ordering_name(self, name, opts, alias=None, default_order='ASC',
693                            already_seen=None):
694         """
695         Return the table alias (the name might be ambiguous, the alias will
696         not be) and column name for ordering by the given 'name' parameter.
697         The 'name' is of the form 'field1__field2__...__fieldN'.
698         """
699         name, order = get_order_dir(name, default_order)
700         descending = order == 'DESC'
701         pieces = name.split(LOOKUP_SEP)
702         field, targets, alias, joins, path, opts, transform_function = self._setup_joins(pieces, opts, alias)
703 
704         # If we get to this point and the field is a relation to another model,
705         # append the default ordering for that model unless the attribute name
706         # of the field is specified.
707         if field.is_relation and opts.ordering and getattr(field, 'attname', None) != name:
708             # Firstly, avoid infinite loops.
709             already_seen = already_seen or set()
710             join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)
711             if join_tuple in already_seen:
712                 raise FieldError('Infinite loop caused by ordering.')
713             already_seen.add(join_tuple)
714 
715             results = []
716             for item in opts.ordering:
717                 if hasattr(item, 'resolve_expression') and not isinstance(item, OrderBy):
718                     item = item.desc() if descending else item.asc()
719                 if isinstance(item, OrderBy):
720                     results.append((item, False))
721                     continue
722                 results.extend(self.find_ordering_name(item, opts, alias,
723                                                        order, already_seen))
724             return results
725         targets, alias, _ = self.query.trim_joins(targets, joins, path)
726         return [(OrderBy(transform_function(t, alias), descending=descending), False) for t in targets]
727 
728     def _setup_joins(self, pieces, opts, alias):
729         """
730         Helper method for get_order_by() and get_distinct().
731 
732         get_ordering() and get_distinct() must produce same target columns on
733         same input, as the prefixes of get_ordering() and get_distinct() must
734         match. Executing SQL where this is not true is an error.
735         """
736         alias = alias or self.query.get_initial_alias()
737         field, targets, opts, joins, path, transform_function = self.query.setup_joins(pieces, opts, alias)
738         alias = joins[-1]
739         return field, targets, alias, joins, path, opts, transform_function
740 
741     def get_from_clause(self):
742         """
743         Return a list of strings that are joined together to go after the
744         "FROM" part of the query, as well as a list any extra parameters that
745         need to be included. Subclasses, can override this to create a
746         from-clause via a "select".
747 
748         This should only be called after any SQL construction methods that
749         might change the tables that are needed. This means the select columns,
750         ordering, and distinct must be done first.
751         """
752         result = []
753         params = []
754         for alias in tuple(self.query.alias_map):
755             if not self.query.alias_refcount[alias]:
756                 continue
757             try:
758                 from_clause = self.query.alias_map[alias]
759             except KeyError:
760                 # Extra tables can end up in self.tables, but not in the
761                 # alias_map if they aren't in a join. That's OK. We skip them.
762                 continue
763             clause_sql, clause_params = self.compile(from_clause)
764             result.append(clause_sql)
765             params.extend(clause_params)
766         for t in self.query.extra_tables:
767             alias, _ = self.query.table_alias(t)
768             # Only add the alias if it's not already present (the table_alias()
769             # call increments the refcount, so an alias refcount of one means
770             # this is the only reference).
771             if alias not in self.query.alias_map or self.query.alias_refcount[alias] == 1:
772                 result.append(', %s' % self.quote_name_unless_alias(alias))
773         return result, params
774 
775     def get_related_selections(self, select, opts=None, root_alias=None, cur_depth=1,
776                                requested=None, restricted=None):
777         """
778         Fill in the information needed for a select_related query. The current
779         depth is measured as the number of connections away from the root model
780         (for example, cur_depth=1 means we are looking at models with direct
781         connections to the root model).
782         """
783         def _get_field_choices():
784             direct_choices = (f.name for f in opts.fields if f.is_relation)
785             reverse_choices = (
786                 f.field.related_query_name()
787                 for f in opts.related_objects if f.field.unique
788             )
789             return chain(direct_choices, reverse_choices, self.query._filtered_relations)
790 
791         related_klass_infos = []
792         if not restricted and cur_depth > self.query.max_depth:
793             # We've recursed far enough; bail out.
794             return related_klass_infos
795 
796         if not opts:
797             opts = self.query.get_meta()
798             root_alias = self.query.get_initial_alias()
799         only_load = self.query.get_loaded_field_names()
800 
801         # Setup for the case when only particular related fields should be
802         # included in the related selection.
803         fields_found = set()
804         if requested is None:
805             restricted = isinstance(self.query.select_related, dict)
806             if restricted:
807                 requested = self.query.select_related
808 
809         def get_related_klass_infos(klass_info, related_klass_infos):
810             klass_info['related_klass_infos'] = related_klass_infos
811 
812         for f in opts.fields:
813             field_model = f.model._meta.concrete_model
814             fields_found.add(f.name)
815 
816             if restricted:
817                 next = requested.get(f.name, {})
818                 if not f.is_relation:
819                     # If a non-related field is used like a relation,
820                     # or if a single non-relational field is given.
821                     if next or f.name in requested:
822                         raise FieldError(
823                             "Non-relational field given in select_related: '%s'. "
824                             "Choices are: %s" % (
825                                 f.name,
826                                 ", ".join(_get_field_choices()) or '(none)',
827                             )
828                         )
829             else:
830                 next = False
831 
832             if not select_related_descend(f, restricted, requested,
833                                           only_load.get(field_model)):
834                 continue
835             klass_info = {
836                 'model': f.remote_field.model,
837                 'field': f,
838                 'reverse': False,
839                 'local_setter': f.set_cached_value,
840                 'remote_setter': f.remote_field.set_cached_value if f.unique else lambda x, y: None,
841                 'from_parent': False,
842             }
843             related_klass_infos.append(klass_info)
844             select_fields = []
845             _, _, _, joins, _, _ = self.query.setup_joins(
846                 [f.name], opts, root_alias)
847             alias = joins[-1]
848             columns = self.get_default_columns(start_alias=alias, opts=f.remote_field.model._meta)
849             for col in columns:
850                 select_fields.append(len(select))
851                 select.append((col, None))
852             klass_info['select_fields'] = select_fields
853             next_klass_infos = self.get_related_selections(
854                 select, f.remote_field.model._meta, alias, cur_depth + 1, next, restricted)
855             get_related_klass_infos(klass_info, next_klass_infos)
856 
857         if restricted:
858             related_fields = [
859                 (o.field, o.related_model)
860                 for o in opts.related_objects
861                 if o.field.unique and not o.many_to_many
862             ]
863             for f, model in related_fields:
864                 if not select_related_descend(f, restricted, requested,
865                                               only_load.get(model), reverse=True):
866                     continue
867 
868                 related_field_name = f.related_query_name()
869                 fields_found.add(related_field_name)
870 
871                 join_info = self.query.setup_joins([related_field_name], opts, root_alias)
872                 alias = join_info.joins[-1]
873                 from_parent = issubclass(model, opts.model) and model is not opts.model
874                 klass_info = {
875                     'model': model,
876                     'field': f,
877                     'reverse': True,
878                     'local_setter': f.remote_field.set_cached_value,
879                     'remote_setter': f.set_cached_value,
880                     'from_parent': from_parent,
881                 }
882                 related_klass_infos.append(klass_info)
883                 select_fields = []
884                 columns = self.get_default_columns(
885                     start_alias=alias, opts=model._meta, from_parent=opts.model)
886                 for col in columns:
887                     select_fields.append(len(select))
888                     select.append((col, None))
889                 klass_info['select_fields'] = select_fields
890                 next = requested.get(f.related_query_name(), {})
891                 next_klass_infos = self.get_related_selections(
892                     select, model._meta, alias, cur_depth + 1,
893                     next, restricted)
894                 get_related_klass_infos(klass_info, next_klass_infos)
895 
896             def local_setter(obj, from_obj):
897                 # Set a reverse fk object when relation is non-empty.
898                 if from_obj:
899                     f.remote_field.set_cached_value(from_obj, obj)
900 
901             def remote_setter(name, obj, from_obj):
902                 setattr(from_obj, name, obj)
903 
904             for name in list(requested):
905                 # Filtered relations work only on the topmost level.
906                 if cur_depth > 1:
907                     break
908                 if name in self.query._filtered_relations:
909                     fields_found.add(name)
910                     f, _, join_opts, joins, _, _ = self.query.setup_joins([name], opts, root_alias)
911                     model = join_opts.model
912                     alias = joins[-1]
913                     from_parent = issubclass(model, opts.model) and model is not opts.model
914                     klass_info = {
915                         'model': model,
916                         'field': f,
917                         'reverse': True,
918                         'local_setter': local_setter,
919                         'remote_setter': partial(remote_setter, name),
920                         'from_parent': from_parent,
921                     }
922                     related_klass_infos.append(klass_info)
923                     select_fields = []
924                     columns = self.get_default_columns(
925                         start_alias=alias, opts=model._meta,
926                         from_parent=opts.model,
927                     )
928                     for col in columns:
929                         select_fields.append(len(select))
930                         select.append((col, None))
931                     klass_info['select_fields'] = select_fields
932                     next_requested = requested.get(name, {})
933                     next_klass_infos = self.get_related_selections(
934                         select, opts=model._meta, root_alias=alias,
935                         cur_depth=cur_depth + 1, requested=next_requested,
936                         restricted=restricted,
937                     )
938                     get_related_klass_infos(klass_info, next_klass_infos)
939             fields_not_found = set(requested).difference(fields_found)
940             if fields_not_found:
941                 invalid_fields = ("'%s'" % s for s in fields_not_found)
942                 raise FieldError(
943                     'Invalid field name(s) given in select_related: %s. '
944                     'Choices are: %s' % (
945                         ', '.join(invalid_fields),
946                         ', '.join(_get_field_choices()) or '(none)',
947                     )
948                 )
949         return related_klass_infos
950 
951     def get_select_for_update_of_arguments(self):
952         """
953         Return a quoted list of arguments for the SELECT FOR UPDATE OF part of
954         the query.
955         """
956         def _get_parent_klass_info(klass_info):
957             return (
958                 {
959                     'model': parent_model,
960                     'field': parent_link,
961                     'reverse': False,
962                     'select_fields': [
963                         select_index
964                         for select_index in klass_info['select_fields']
965                         if self.select[select_index][0].target.model == parent_model
966                     ],
967                 }
968                 for parent_model, parent_link in klass_info['model']._meta.parents.items()
969             )
970 
971         def _get_field_choices():
972             """Yield all allowed field paths in breadth-first search order."""
973             queue = collections.deque([(None, self.klass_info)])
974             while queue:
975                 parent_path, klass_info = queue.popleft()
976                 if parent_path is None:
977                     path = []
978                     yield 'self'
979                 else:
980                     field = klass_info['field']
981                     if klass_info['reverse']:
982                         field = field.remote_field
983                     path = parent_path + [field.name]
984                     yield LOOKUP_SEP.join(path)
985                 queue.extend(
986                     (path, klass_info)
987                     for klass_info in _get_parent_klass_info(klass_info)
988                 )
989                 queue.extend(
990                     (path, klass_info)
991                     for klass_info in klass_info.get('related_klass_infos', [])
992                 )
993         result = []
994         invalid_names = []
995         for name in self.query.select_for_update_of:
996             klass_info = self.klass_info
997             if name == 'self':
998                 # Find the first selected column from a base model. If it
999                 # doesn't exist, don't lock a base model.
1000                 for select_index in klass_info['select_fields']:
1001                     if self.select[select_index][0].target.model == klass_info['model']:
1002                         col = self.select[select_index][0]
1003                         break
1004                 else:
1005                     col = None
1006             else:
1007                 for part in name.split(LOOKUP_SEP):
1008                     klass_infos = (
1009                         *klass_info.get('related_klass_infos', []),
1010                         *_get_parent_klass_info(klass_info),
1011                     )
1012                     for related_klass_info in klass_infos:
1013                         field = related_klass_info['field']
1014                         if related_klass_info['reverse']:
1015                             field = field.remote_field
1016                         if field.name == part:
1017                             klass_info = related_klass_info
1018                             break
1019                     else:
1020                         klass_info = None
1021                         break
1022                 if klass_info is None:
1023                     invalid_names.append(name)
1024                     continue
1025                 select_index = klass_info['select_fields'][0]
1026                 col = self.select[select_index][0]
1027             if col is not None:
1028                 if self.connection.features.select_for_update_of_column:
1029                     result.append(self.compile(col)[0])
1030                 else:
1031                     result.append(self.quote_name_unless_alias(col.alias))
1032         if invalid_names:
1033             raise FieldError(
1034                 'Invalid field name(s) given in select_for_update(of=(...)): %s. '
1035                 'Only relational fields followed in the query are allowed. '
1036                 'Choices are: %s.' % (
1037                     ', '.join(invalid_names),
1038                     ', '.join(_get_field_choices()),
1039                 )
1040             )
1041         return result
1042 
1043     def deferred_to_columns(self):
1044         """
1045         Convert the self.deferred_loading data structure to mapping of table
1046         names to sets of column names which are to be loaded. Return the
1047         dictionary.
1048         """
1049         columns = {}
1050         self.query.deferred_to_data(columns, self.query.get_loaded_field_names_cb)
1051         return columns
1052 
1053     def get_converters(self, expressions):
1054         converters = {}
1055         for i, expression in enumerate(expressions):
1056             if expression:
1057                 backend_converters = self.connection.ops.get_db_converters(expression)
1058                 field_converters = expression.get_db_converters(self.connection)
1059                 if backend_converters or field_converters:
1060                     converters[i] = (backend_converters + field_converters, expression)
1061         return converters
1062 
1063     def apply_converters(self, rows, converters):
1064         connection = self.connection
1065         converters = list(converters.items())
1066         for row in map(list, rows):
1067             for pos, (convs, expression) in converters:
1068                 value = row[pos]
1069                 for converter in convs:
1070                     value = converter(value, expression, connection)
1071                 row[pos] = value
1072             yield row
1073 
1074     def results_iter(self, results=None, tuple_expected=False, chunked_fetch=False,
1075                      chunk_size=GET_ITERATOR_CHUNK_SIZE):
1076         """Return an iterator over the results from executing this query."""
1077         if results is None:
1078             results = self.execute_sql(MULTI, chunked_fetch=chunked_fetch, chunk_size=chunk_size)
1079         fields = [s[0] for s in self.select[0:self.col_count]]
1080         converters = self.get_converters(fields)
1081         rows = chain.from_iterable(results)
1082         if converters:
1083             rows = self.apply_converters(rows, converters)
1084             if tuple_expected:
1085                 rows = map(tuple, rows)
1086         return rows
1087 
1088     def has_results(self):
1089         """
1090         Backends (e.g. NoSQL) can override this in order to use optimized
1091         versions of "query has any results."
1092         """
1093         # This is always executed on a query clone, so we can modify self.query
1094         self.query.add_extra({'a': 1}, None, None, None, None, None)
1095         self.query.set_extra_mask(['a'])
1096         return bool(self.execute_sql(SINGLE))
1097 
1098     def execute_sql(self, result_type=MULTI, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE):
1099         """
1100         Run the query against the database and return the result(s). The
1101         return value is a single data item if result_type is SINGLE, or an
1102         iterator over the results if the result_type is MULTI.
1103 
1104         result_type is either MULTI (use fetchmany() to retrieve all rows),
1105         SINGLE (only retrieve a single row), or None. In this last case, the
1106         cursor is returned if any query is executed, since it's used by
1107         subclasses such as InsertQuery). It's possible, however, that no query
1108         is needed, as the filters describe an empty set. In that case, None is
1109         returned, to avoid any unnecessary database interaction.
1110         """
1111         result_type = result_type or NO_RESULTS
1112         try:
1113             sql, params = self.as_sql()
1114             if not sql:
1115                 raise EmptyResultSet
1116         except EmptyResultSet:
1117             if result_type == MULTI:
1118                 return iter([])
1119             else:
1120                 return
1121         if chunked_fetch:
1122             cursor = self.connection.chunked_cursor()
1123         else:
1124             cursor = self.connection.cursor()
1125         try:
1126             cursor.execute(sql, params)
1127         except Exception:
1128             # Might fail for server-side cursors (e.g. connection closed)
1129             cursor.close()
1130             raise
1131 
1132         if result_type == CURSOR:
1133             # Give the caller the cursor to process and close.
1134             return cursor
1135         if result_type == SINGLE:
1136             try:
1137                 val = cursor.fetchone()
1138                 if val:
1139                     return val[0:self.col_count]
1140                 return val
1141             finally:
1142                 # done with the cursor
1143                 cursor.close()
1144         if result_type == NO_RESULTS:
1145             cursor.close()
1146             return
1147 
1148         result = cursor_iter(
1149             cursor, self.connection.features.empty_fetchmany_value,
1150             self.col_count if self.has_extra_select else None,
1151             chunk_size,
1152         )
1153         if not chunked_fetch or not self.connection.features.can_use_chunked_reads:
1154             try:
1155                 # If we are using non-chunked reads, we return the same data
1156                 # structure as normally, but ensure it is all read into memory
1157                 # before going any further. Use chunked_fetch if requested,
1158                 # unless the database doesn't support it.
1159                 return list(result)
1160             finally:
1161                 # done with the cursor
1162                 cursor.close()
1163         return result
1164 
1165     def as_subquery_condition(self, alias, columns, compiler):
1166         qn = compiler.quote_name_unless_alias
1167         qn2 = self.connection.ops.quote_name
1168 
1169         for index, select_col in enumerate(self.query.select):
1170             lhs_sql, lhs_params = self.compile(select_col)
1171             rhs = '%s.%s' % (qn(alias), qn2(columns[index]))
1172             self.query.where.add(
1173                 RawSQL('%s = %s' % (lhs_sql, rhs), lhs_params), 'AND')
1174 
1175         sql, params = self.as_sql()
1176         return 'EXISTS (%s)' % sql, params
1177 
1178     def explain_query(self):
1179         result = list(self.execute_sql())
1180         # Some backends return 1 item tuples with strings, and others return
1181         # tuples with integers and strings. Flatten them out into strings.
1182         for row in result[0]:
1183             if not isinstance(row, str):
1184                 yield ' '.join(str(c) for c in row)
1185             else:
1186                 yield row
1187 
1188 
1189 class SQLInsertCompiler(SQLCompiler):
1190     returning_fields = None
1191     returning_params = tuple()
1192 
1193     def field_as_sql(self, field, val):
1194         """
1195         Take a field and a value intended to be saved on that field, and
1196         return placeholder SQL and accompanying params. Check for raw values,
1197         expressions, and fields with get_placeholder() defined in that order.
1198 
1199         When field is None, consider the value raw and use it as the
1200         placeholder, with no corresponding parameters returned.
1201         """
1202         if field is None:
1203             # A field value of None means the value is raw.
1204             sql, params = val, []
1205         elif hasattr(val, 'as_sql'):
1206             # This is an expression, let's compile it.
1207             sql, params = self.compile(val)
1208         elif hasattr(field, 'get_placeholder'):
1209             # Some fields (e.g. geo fields) need special munging before
1210             # they can be inserted.
1211             sql, params = field.get_placeholder(val, self, self.connection), [val]
1212         else:
1213             # Return the common case for the placeholder
1214             sql, params = '%s', [val]
1215 
1216         # The following hook is only used by Oracle Spatial, which sometimes
1217         # needs to yield 'NULL' and [] as its placeholder and params instead
1218         # of '%s' and [None]. The 'NULL' placeholder is produced earlier by
1219         # OracleOperations.get_geom_placeholder(). The following line removes
1220         # the corresponding None parameter. See ticket #10888.
1221         params = self.connection.ops.modify_insert_params(sql, params)
1222 
1223         return sql, params
1224 
1225     def prepare_value(self, field, value):
1226         """
1227         Prepare a value to be used in a query by resolving it if it is an
1228         expression and otherwise calling the field's get_db_prep_save().
1229         """
1230         if hasattr(value, 'resolve_expression'):
1231             value = value.resolve_expression(self.query, allow_joins=False, for_save=True)
1232             # Don't allow values containing Col expressions. They refer to
1233             # existing columns on a row, but in the case of insert the row
1234             # doesn't exist yet.
1235             if value.contains_column_references:
1236                 raise ValueError(
1237                     'Failed to insert expression "%s" on %s. F() expressions '
1238                     'can only be used to update, not to insert.' % (value, field)
1239                 )
1240             if value.contains_aggregate:
1241                 raise FieldError(
1242                     'Aggregate functions are not allowed in this query '
1243                     '(%s=%r).' % (field.name, value)
1244                 )
1245             if value.contains_over_clause:
1246                 raise FieldError(
1247                     'Window expressions are not allowed in this query (%s=%r).'
1248                     % (field.name, value)
1249                 )
1250         else:
1251             value = field.get_db_prep_save(value, connection=self.connection)
1252         return value
1253 
1254     def pre_save_val(self, field, obj):
1255         """
1256         Get the given field's value off the given obj. pre_save() is used for
1257         things like auto_now on DateTimeField. Skip it if this is a raw query.
1258         """
1259         if self.query.raw:
1260             return getattr(obj, field.attname)
1261         return field.pre_save(obj, add=True)
1262 
1263     def assemble_as_sql(self, fields, value_rows):
1264         """
1265         Take a sequence of N fields and a sequence of M rows of values, and
1266         generate placeholder SQL and parameters for each field and value.
1267         Return a pair containing:
1268          * a sequence of M rows of N SQL placeholder strings, and
1269          * a sequence of M rows of corresponding parameter values.
1270 
1271         Each placeholder string may contain any number of '%s' interpolation
1272         strings, and each parameter row will contain exactly as many params
1273         as the total number of '%s's in the corresponding placeholder row.
1274         """
1275         if not value_rows:
1276             return [], []
1277 
1278         # list of (sql, [params]) tuples for each object to be saved
1279         # Shape: [n_objs][n_fields][2]
1280         rows_of_fields_as_sql = (
1281             (self.field_as_sql(field, v) for field, v in zip(fields, row))
1282             for row in value_rows
1283         )
1284 
1285         # tuple like ([sqls], [[params]s]) for each object to be saved
1286         # Shape: [n_objs][2][n_fields]
1287         sql_and_param_pair_rows = (zip(*row) for row in rows_of_fields_as_sql)
1288 
1289         # Extract separate lists for placeholders and params.
1290         # Each of these has shape [n_objs][n_fields]
1291         placeholder_rows, param_rows = zip(*sql_and_param_pair_rows)
1292 
1293         # Params for each field are still lists, and need to be flattened.
1294         param_rows = [[p for ps in row for p in ps] for row in param_rows]
1295 
1296         return placeholder_rows, param_rows
1297 
1298     def as_sql(self):
1299         # We don't need quote_name_unless_alias() here, since these are all
1300         # going to be column names (so we can avoid the extra overhead).
1301         qn = self.connection.ops.quote_name
1302         opts = self.query.get_meta()
1303         insert_statement = self.connection.ops.insert_statement(ignore_conflicts=self.query.ignore_conflicts)
1304         result = ['%s %s' % (insert_statement, qn(opts.db_table))]
1305         fields = self.query.fields or [opts.pk]
1306         result.append('(%s)' % ', '.join(qn(f.column) for f in fields))
1307 
1308         if self.query.fields:
1309             value_rows = [
1310                 [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
1311                 for obj in self.query.objs
1312             ]
1313         else:
1314             # An empty object.
1315             value_rows = [[self.connection.ops.pk_default_value()] for _ in self.query.objs]
1316             fields = [None]
1317 
1318         # Currently the backends just accept values when generating bulk
1319         # queries and generate their own placeholders. Doing that isn't
1320         # necessary and it should be possible to use placeholders and
1321         # expressions in bulk inserts too.
1322         can_bulk = (not self.returning_fields and self.connection.features.has_bulk_insert)
1323 
1324         placeholder_rows, param_rows = self.assemble_as_sql(fields, value_rows)
1325 
1326         ignore_conflicts_suffix_sql = self.connection.ops.ignore_conflicts_suffix_sql(
1327             ignore_conflicts=self.query.ignore_conflicts
1328         )
1329         if self.returning_fields and self.connection.features.can_return_columns_from_insert:
1330             if self.connection.features.can_return_rows_from_bulk_insert:
1331                 result.append(self.connection.ops.bulk_insert_sql(fields, placeholder_rows))
1332                 params = param_rows
1333             else:
1334                 result.append("VALUES (%s)" % ", ".join(placeholder_rows[0]))
1335                 params = [param_rows[0]]
1336             if ignore_conflicts_suffix_sql:
1337                 result.append(ignore_conflicts_suffix_sql)
1338             # Skip empty r_sql to allow subclasses to customize behavior for
1339             # 3rd party backends. Refs #19096.
1340             r_sql, self.returning_params = self.connection.ops.return_insert_columns(self.returning_fields)
1341             if r_sql:
1342                 result.append(r_sql)
1343                 params += [self.returning_params]
1344             return [(" ".join(result), tuple(chain.from_iterable(params)))]
1345 
1346         if can_bulk:
1347             result.append(self.connection.ops.bulk_insert_sql(fields, placeholder_rows))
1348             if ignore_conflicts_suffix_sql:
1349                 result.append(ignore_conflicts_suffix_sql)
1350             return [(" ".join(result), tuple(p for ps in param_rows for p in ps))]
1351         else:
1352             if ignore_conflicts_suffix_sql:
1353                 result.append(ignore_conflicts_suffix_sql)
1354             return [
1355                 (" ".join(result + ["VALUES (%s)" % ", ".join(p)]), vals)
1356                 for p, vals in zip(placeholder_rows, param_rows)
1357             ]
1358 
1359     def execute_sql(self, returning_fields=None):
1360         assert not (
1361             returning_fields and len(self.query.objs) != 1 and
1362             not self.connection.features.can_return_rows_from_bulk_insert
1363         )
1364         self.returning_fields = returning_fields
1365         with self.connection.cursor() as cursor:
1366             for sql, params in self.as_sql():
1367                 cursor.execute(sql, params)
1368             if not self.returning_fields:
1369                 return []
1370             if self.connection.features.can_return_rows_from_bulk_insert and len(self.query.objs) > 1:
1371                 return self.connection.ops.fetch_returned_insert_rows(cursor)
1372             if self.connection.features.can_return_columns_from_insert:
1373                 assert len(self.query.objs) == 1
1374                 return self.connection.ops.fetch_returned_insert_columns(cursor, self.returning_params)
1375             return [self.connection.ops.last_insert_id(
1376                 cursor, self.query.get_meta().db_table, self.query.get_meta().pk.column
1377             )]
1378 
1379 
1380 class SQLDeleteCompiler(SQLCompiler):
1381     @cached_property
1382     def single_alias(self):
1383         return sum(self.query.alias_refcount[t] > 0 for t in self.query.alias_map) == 1
1384 
1385     def _as_sql(self, query):
1386         result = [
1387             'DELETE FROM %s' % self.quote_name_unless_alias(query.base_table)
1388         ]
1389         where, params = self.compile(query.where)
1390         if where:
1391             result.append('WHERE %s' % where)
1392         return ' '.join(result), tuple(params)
1393 
1394     def as_sql(self):
1395         """
1396         Create the SQL for this query. Return the SQL string and list of
1397         parameters.
1398         """
1399         if self.single_alias:
1400             return self._as_sql(self.query)
1401         innerq = self.query.clone()
1402         innerq.__class__ = Query
1403         innerq.clear_select_clause()
1404         pk = self.query.model._meta.pk
1405         innerq.select = [
1406             pk.get_col(self.query.get_initial_alias())
1407         ]
1408         outerq = Query(self.query.model)
1409         outerq.where = self.query.where_class()
1410         outerq.add_q(Q(pk__in=innerq))
1411         return self._as_sql(outerq)
1412 
1413 
1414 class SQLUpdateCompiler(SQLCompiler):
1415     def as_sql(self):
1416         """
1417         Create the SQL for this query. Return the SQL string and list of
1418         parameters.
1419         """
1420         self.pre_sql_setup()
1421         if not self.query.values:
1422             return '', ()
1423         qn = self.quote_name_unless_alias
1424         values, update_params = [], []
1425         for field, model, val in self.query.values:
1426             if hasattr(val, 'resolve_expression'):
1427                 val = val.resolve_expression(self.query, allow_joins=False, for_save=True)
1428                 if val.contains_aggregate:
1429                     raise FieldError(
1430                         'Aggregate functions are not allowed in this query '
1431                         '(%s=%r).' % (field.name, val)
1432                     )
1433                 if val.contains_over_clause:
1434                     raise FieldError(
1435                         'Window expressions are not allowed in this query '
1436                         '(%s=%r).' % (field.name, val)
1437                     )
1438             elif hasattr(val, 'prepare_database_save'):
1439                 if field.remote_field:
1440                     val = field.get_db_prep_save(
1441                         val.prepare_database_save(field),
1442                         connection=self.connection,
1443                     )
1444                 else:
1445                     raise TypeError(
1446                         "Tried to update field %s with a model instance, %r. "
1447                         "Use a value compatible with %s."
1448                         % (field, val, field.__class__.__name__)
1449                     )
1450             else:
1451                 val = field.get_db_prep_save(val, connection=self.connection)
1452 
1453             # Getting the placeholder for the field.
1454             if hasattr(field, 'get_placeholder'):
1455                 placeholder = field.get_placeholder(val, self, self.connection)
1456             else:
1457                 placeholder = '%s'
1458             name = field.column
1459             if hasattr(val, 'as_sql'):
1460                 sql, params = self.compile(val)
1461                 values.append('%s = %s' % (qn(name), placeholder % sql))
1462                 update_params.extend(params)
1463             elif val is not None:
1464                 values.append('%s = %s' % (qn(name), placeholder))
1465                 update_params.append(val)
1466             else:
1467                 values.append('%s = NULL' % qn(name))
1468         table = self.query.base_table
1469         result = [
1470             'UPDATE %s SET' % qn(table),
1471             ', '.join(values),
1472         ]
1473         where, params = self.compile(self.query.where)
1474         if where:
1475             result.append('WHERE %s' % where)
1476         return ' '.join(result), tuple(update_params + params)
1477 
1478     def execute_sql(self, result_type):
1479         """
1480         Execute the specified update. Return the number of rows affected by
1481         the primary update query. The "primary update query" is the first
1482         non-empty query that is executed. Row counts for any subsequent,
1483         related queries are not available.
1484         """
1485         cursor = super().execute_sql(result_type)
1486         try:
1487             rows = cursor.rowcount if cursor else 0
1488             is_empty = cursor is None
1489         finally:
1490             if cursor:
1491                 cursor.close()
1492         for query in self.query.get_related_updates():
1493             aux_rows = query.get_compiler(self.using).execute_sql(result_type)
1494             if is_empty and aux_rows:
1495                 rows = aux_rows
1496                 is_empty = False
1497         return rows
1498 
1499     def pre_sql_setup(self):
1500         """
1501         If the update depends on results from other tables, munge the "where"
1502         conditions to match the format required for (portable) SQL updates.
1503 
1504         If multiple updates are required, pull out the id values to update at
1505         this point so that they don't change as a result of the progressive
1506         updates.
1507         """
1508         refcounts_before = self.query.alias_refcount.copy()
1509         # Ensure base table is in the query
1510         self.query.get_initial_alias()
1511         count = self.query.count_active_tables()
1512         if not self.query.related_updates and count == 1:
1513             return
1514         query = self.query.chain(klass=Query)
1515         query.select_related = False
1516         query.clear_ordering(True)
1517         query.extra = {}
1518         query.select = []
1519         query.add_fields([query.get_meta().pk.name])
1520         super().pre_sql_setup()
1521 
1522         must_pre_select = count > 1 and not self.connection.features.update_can_self_select
1523 
1524         # Now we adjust the current query: reset the where clause and get rid
1525         # of all the tables we don't need (since they're in the sub-select).
1526         self.query.where = self.query.where_class()
1527         if self.query.related_updates or must_pre_select:
1528             # Either we're using the idents in multiple update queries (so
1529             # don't want them to change), or the db backend doesn't support
1530             # selecting from the updating table (e.g. MySQL).
1531             idents = []
1532             for rows in query.get_compiler(self.using).execute_sql(MULTI):
1533                 idents.extend(r[0] for r in rows)
1534             self.query.add_filter(('pk__in', idents))
1535             self.query.related_ids = idents
1536         else:
1537             # The fast path. Filters and updates in one query.
1538             self.query.add_filter(('pk__in', query))
1539         self.query.reset_refcounts(refcounts_before)
1540 
1541 
1542 class SQLAggregateCompiler(SQLCompiler):
1543     def as_sql(self):
1544         """
1545         Create the SQL for this query. Return the SQL string and list of
1546         parameters.
1547         """
1548         sql, params = [], []
1549         for annotation in self.query.annotation_select.values():
1550             ann_sql, ann_params = self.compile(annotation)
1551             ann_sql, ann_params = annotation.select_format(self, ann_sql, ann_params)
1552             sql.append(ann_sql)
1553             params.extend(ann_params)
1554         self.col_count = len(self.query.annotation_select)
1555         sql = ', '.join(sql)
1556         params = tuple(params)
1557 
1558         sql = 'SELECT %s FROM (%s) subquery' % (sql, self.query.subquery)
1559         params = params + self.query.sub_params
1560         return sql, params
1561 
1562 
1563 def cursor_iter(cursor, sentinel, col_count, itersize):
1564     """
1565     Yield blocks of rows from a cursor and ensure the cursor is closed when
1566     done.
1567     """
1568     try:
1569         for rows in iter((lambda: cursor.fetchmany(itersize)), sentinel):
1570             yield rows if col_count is None else [r[:col_count] for r in rows]
1571     finally:
1572         cursor.close()

</code><intended_behavior>The code here should properly distinguish contexts where window functions are used, especially in 'SELECT' clauses. The fix should ensure that window expressions within annotations are compiled into SQL without incorrectly raising a 'NotSupportedError'. This adjustment must keep the validation against the use of window functions in prohibited clauses (like 'WHERE'), while allowing them in 'SELECT' clauses as per SQL standards.</intended_behavior>, <file>django/db/models/expressions.py</file>
<class>Window</class>
<method>None</method>
<code>
1156 class Window(Expression):
1157     template = '%(expression)s OVER (%(window)s)'
1158     # Although the main expression may either be an aggregate or an
1159     # expression with an aggregate function, the GROUP BY that will
1160     # be introduced in the query as a result is not desired.
1161     contains_aggregate = False
1162     contains_over_clause = True
1163     filterable = False
1164 
1165     def __init__(self, expression, partition_by=None, order_by=None, frame=None, output_field=None):
1166         self.partition_by = partition_by
1167         self.order_by = order_by
1168         self.frame = frame
1169 
1170         if not getattr(expression, 'window_compatible', False):
1171             raise ValueError(
1172                 "Expression '%s' isn't compatible with OVER clauses." %
1173                 expression.__class__.__name__
1174             )
1175 
1176         if self.partition_by is not None:
1177             if not isinstance(self.partition_by, (tuple, list)):
1178                 self.partition_by = (self.partition_by,)
1179             self.partition_by = ExpressionList(*self.partition_by)
1180 
1181         if self.order_by is not None:
1182             if isinstance(self.order_by, (list, tuple)):
1183                 self.order_by = ExpressionList(*self.order_by)
1184             elif not isinstance(self.order_by, BaseExpression):
1185                 raise ValueError(
1186                     'order_by must be either an Expression or a sequence of '
1187                     'expressions.'
1188                 )
1189         super().__init__(output_field=output_field)
1190         self.source_expression = self._parse_expressions(expression)[0]
1191 
1192     def _resolve_output_field(self):
1193         return self.source_expression.output_field
1194 
1195     def get_source_expressions(self):
1196         return [self.source_expression, self.partition_by, self.order_by, self.frame]
1197 
1198     def set_source_expressions(self, exprs):
1199         self.source_expression, self.partition_by, self.order_by, self.frame = exprs
1200 
1201     def as_sql(self, compiler, connection, template=None):
1202         connection.ops.check_expression_support(self)
1203         if not connection.features.supports_over_clause:
1204             raise NotSupportedError('This backend does not support window expressions.')
1205         expr_sql, params = compiler.compile(self.source_expression)
1206         window_sql, window_params = [], []
1207 
1208         if self.partition_by is not None:
1209             sql_expr, sql_params = self.partition_by.as_sql(
1210                 compiler=compiler, connection=connection,
1211                 template='PARTITION BY %(expressions)s',
1212             )
1213             window_sql.extend(sql_expr)
1214             window_params.extend(sql_params)
1215 
1216         if self.order_by is not None:
1217             window_sql.append(' ORDER BY ')
1218             order_sql, order_params = compiler.compile(self.order_by)
1219             window_sql.extend(order_sql)
1220             window_params.extend(order_params)
1221 
1222         if self.frame:
1223             frame_sql, frame_params = compiler.compile(self.frame)
1224             window_sql.append(' ' + frame_sql)
1225             window_params.extend(frame_params)
1226 
1227         params.extend(window_params)
1228         template = template or self.template
1229 
1230         return template % {
1231             'expression': expr_sql,
1232             'window': ''.join(window_sql).strip()
1233         }, params
1234 
1235     def __str__(self):
1236         return '{} OVER ({}{}{})'.format(
1237             str(self.source_expression),
1238             'PARTITION BY ' + str(self.partition_by) if self.partition_by else '',
1239             'ORDER BY ' + str(self.order_by) if self.order_by else '',
1240             str(self.frame or ''),
1241         )
1242 
1243     def __repr__(self):
1244         return '<%s: %s>' % (self.__class__.__name__, self)
1245 
1246     def get_group_by_cols(self, alias=None):
1247         return []

</code><intended_behavior>Ensure that when a 'Window' expression is used within an 'annotate' call, it is flagged in a way that prevents 'NotSupportedError' from being incorrectly raised. This may involve adding additional checks or flags to indicate that the window expression is used in a supported context (i.e., within the 'SELECT' clause) and should not be treated as an error.</intended_behavior>]
2025-10-15 04:22:46.528 | INFO     | Search completed. Bug locations: [<file>django/db/models/sql/compiler.py</file>
<class>None</class>
<method>None</method>
<code>
1 import collections
2 import re
3 from functools import partial
4 from itertools import chain
5 
6 from django.core.exceptions import EmptyResultSet, FieldError
7 from django.db.models.constants import LOOKUP_SEP
8 from django.db.models.expressions import OrderBy, Random, RawSQL, Ref, Value
9 from django.db.models.functions import Cast
10 from django.db.models.query_utils import Q, select_related_descend
11 from django.db.models.sql.constants import (
12     CURSOR, GET_ITERATOR_CHUNK_SIZE, MULTI, NO_RESULTS, ORDER_DIR, SINGLE,
13 )
14 from django.db.models.sql.query import Query, get_order_dir
15 from django.db.transaction import TransactionManagementError
16 from django.db.utils import DatabaseError, NotSupportedError
17 from django.utils.functional import cached_property
18 from django.utils.hashable import make_hashable
19 
20 
21 class SQLCompiler:
22     def __init__(self, query, connection, using):
23         self.query = query
24         self.connection = connection
25         self.using = using
26         self.quote_cache = {'*': '*'}
27         # The select, klass_info, and annotations are needed by QuerySet.iterator()
28         # these are set as a side-effect of executing the query. Note that we calculate
29         # separately a list of extra select columns needed for grammatical correctness
30         # of the query, but these columns are not included in self.select.
31         self.select = None
32         self.annotation_col_map = None
33         self.klass_info = None
34         # Multiline ordering SQL clause may appear from RawSQL.
35         self.ordering_parts = re.compile(r'^(.*)\s(ASC|DESC)(.*)', re.MULTILINE | re.DOTALL)
36         self._meta_ordering = None
37 
38     def setup_query(self):
39         if all(self.query.alias_refcount[a] == 0 for a in self.query.alias_map):
40             self.query.get_initial_alias()
41         self.select, self.klass_info, self.annotation_col_map = self.get_select()
42         self.col_count = len(self.select)
43 
44     def pre_sql_setup(self):
45         """
46         Do any necessary class setup immediately prior to producing SQL. This
47         is for things that can't necessarily be done in __init__ because we
48         might not have all the pieces in place at that time.
49         """
50         self.setup_query()
51         order_by = self.get_order_by()
52         self.where, self.having = self.query.where.split_having()
53         extra_select = self.get_extra_select(order_by, self.select)
54         self.has_extra_select = bool(extra_select)
55         group_by = self.get_group_by(self.select + extra_select, order_by)
56         return extra_select, order_by, group_by
57 
58     def get_group_by(self, select, order_by):
59         """
60         Return a list of 2-tuples of form (sql, params).
61 
62         The logic of what exactly the GROUP BY clause contains is hard
63         to describe in other words than "if it passes the test suite,
64         then it is correct".
65         """
66         # Some examples:
67         #     SomeModel.objects.annotate(Count('somecol'))
68         #     GROUP BY: all fields of the model
69         #
70         #    SomeModel.objects.values('name').annotate(Count('somecol'))
71         #    GROUP BY: name
72         #
73         #    SomeModel.objects.annotate(Count('somecol')).values('name')
74         #    GROUP BY: all cols of the model
75         #
76         #    SomeModel.objects.values('name', 'pk').annotate(Count('somecol')).values('pk')
77         #    GROUP BY: name, pk
78         #
79         #    SomeModel.objects.values('name').annotate(Count('somecol')).values('pk')
80         #    GROUP BY: name, pk
81         #
82         # In fact, the self.query.group_by is the minimal set to GROUP BY. It
83         # can't be ever restricted to a smaller set, but additional columns in
84         # HAVING, ORDER BY, and SELECT clauses are added to it. Unfortunately
85         # the end result is that it is impossible to force the query to have
86         # a chosen GROUP BY clause - you can almost do this by using the form:
87         #     .values(*wanted_cols).annotate(AnAggregate())
88         # but any later annotations, extra selects, values calls that
89         # refer some column outside of the wanted_cols, order_by, or even
90         # filter calls can alter the GROUP BY clause.
91 
92         # The query.group_by is either None (no GROUP BY at all), True
93         # (group by select fields), or a list of expressions to be added
94         # to the group by.
95         if self.query.group_by is None:
96             return []
97         expressions = []
98         if self.query.group_by is not True:
99             # If the group by is set to a list (by .values() call most likely),
100             # then we need to add everything in it to the GROUP BY clause.
101             # Backwards compatibility hack for setting query.group_by. Remove
102             # when  we have public API way of forcing the GROUP BY clause.
103             # Converts string references to expressions.
104             for expr in self.query.group_by:
105                 if not hasattr(expr, 'as_sql'):
106                     expressions.append(self.query.resolve_ref(expr))
107                 else:
108                     expressions.append(expr)
109         # Note that even if the group_by is set, it is only the minimal
110         # set to group by. So, we need to add cols in select, order_by, and
111         # having into the select in any case.
112         for expr, _, _ in select:
113             cols = expr.get_group_by_cols()
114             for col in cols:
115                 expressions.append(col)
116         for expr, (sql, params, is_ref) in order_by:
117             # Skip References to the select clause, as all expressions in the
118             # select clause are already part of the group by.
119             if not expr.contains_aggregate and not is_ref:
120                 expressions.extend(expr.get_source_expressions())
121         having_group_by = self.having.get_group_by_cols() if self.having else ()
122         for expr in having_group_by:
123             expressions.append(expr)
124         result = []
125         seen = set()
126         expressions = self.collapse_group_by(expressions, having_group_by)
127 
128         for expr in expressions:
129             sql, params = self.compile(expr)
130             params_hash = make_hashable(params)
131             if (sql, params_hash) not in seen:
132                 result.append((sql, params))
133                 seen.add((sql, params_hash))
134         return result
135 
136     def collapse_group_by(self, expressions, having):
137         # If the DB can group by primary key, then group by the primary key of
138         # query's main model. Note that for PostgreSQL the GROUP BY clause must
139         # include the primary key of every table, but for MySQL it is enough to
140         # have the main table's primary key.
141         if self.connection.features.allows_group_by_pk:
142             # Determine if the main model's primary key is in the query.
143             pk = None
144             for expr in expressions:
145                 # Is this a reference to query's base table primary key? If the
146                 # expression isn't a Col-like, then skip the expression.
147                 if (getattr(expr, 'target', None) == self.query.model._meta.pk and
148                         getattr(expr, 'alias', None) == self.query.base_table):
149                     pk = expr
150                     break
151             # If the main model's primary key is in the query, group by that
152             # field, HAVING expressions, and expressions associated with tables
153             # that don't have a primary key included in the grouped columns.
154             if pk:
155                 pk_aliases = {
156                     expr.alias for expr in expressions
157                     if hasattr(expr, 'target') and expr.target.primary_key
158                 }
159                 expressions = [pk] + [
160                     expr for expr in expressions
161                     if expr in having or (
162                         getattr(expr, 'alias', None) is not None and expr.alias not in pk_aliases
163                     )
164                 ]
165         elif self.connection.features.allows_group_by_selected_pks:
166             # Filter out all expressions associated with a table's primary key
167             # present in the grouped columns. This is done by identifying all
168             # tables that have their primary key included in the grouped
169             # columns and removing non-primary key columns referring to them.
170             # Unmanaged models are excluded because they could be representing
171             # database views on which the optimization might not be allowed.
172             pks = {
173                 expr for expr in expressions
174                 if (
175                     hasattr(expr, 'target') and
176                     expr.target.primary_key and
177                     self.connection.features.allows_group_by_selected_pks_on_model(expr.target.model)
178                 )
179             }
180             aliases = {expr.alias for expr in pks}
181             expressions = [
182                 expr for expr in expressions if expr in pks or getattr(expr, 'alias', None) not in aliases
183             ]
184         return expressions
185 
186     def get_select(self):
187         """
188         Return three values:
189         - a list of 3-tuples of (expression, (sql, params), alias)
190         - a klass_info structure,
191         - a dictionary of annotations
192 
193         The (sql, params) is what the expression will produce, and alias is the
194         "AS alias" for the column (possibly None).
195 
196         The klass_info structure contains the following information:
197         - The base model of the query.
198         - Which columns for that model are present in the query (by
199           position of the select clause).
200         - related_klass_infos: [f, klass_info] to descent into
201 
202         The annotations is a dictionary of {'attname': column position} values.
203         """
204         select = []
205         klass_info = None
206         annotations = {}
207         select_idx = 0
208         for alias, (sql, params) in self.query.extra_select.items():
209             annotations[alias] = select_idx
210             select.append((RawSQL(sql, params), alias))
211             select_idx += 1
212         assert not (self.query.select and self.query.default_cols)
213         if self.query.default_cols:
214             cols = self.get_default_columns()
215         else:
216             # self.query.select is a special case. These columns never go to
217             # any model.
218             cols = self.query.select
219         if cols:
220             select_list = []
221             for col in cols:
222                 select_list.append(select_idx)
223                 select.append((col, None))
224                 select_idx += 1
225             klass_info = {
226                 'model': self.query.model,
227                 'select_fields': select_list,
228             }
229         for alias, annotation in self.query.annotation_select.items():
230             annotations[alias] = select_idx
231             select.append((annotation, alias))
232             select_idx += 1
233 
234         if self.query.select_related:
235             related_klass_infos = self.get_related_selections(select)
236             klass_info['related_klass_infos'] = related_klass_infos
237 
238             def get_select_from_parent(klass_info):
239                 for ki in klass_info['related_klass_infos']:
240                     if ki['from_parent']:
241                         ki['select_fields'] = (klass_info['select_fields'] +
242                                                ki['select_fields'])
243                     get_select_from_parent(ki)
244             get_select_from_parent(klass_info)
245 
246         ret = []
247         for col, alias in select:
248             try:
249                 sql, params = self.compile(col)
250             except EmptyResultSet:
251                 # Select a predicate that's always False.
252                 sql, params = '0', ()
253             else:
254                 sql, params = col.select_format(self, sql, params)
255             ret.append((col, (sql, params), alias))
256         return ret, klass_info, annotations
257 
258     def get_order_by(self):
259         """
260         Return a list of 2-tuples of form (expr, (sql, params, is_ref)) for the
261         ORDER BY clause.
262 
263         The order_by clause can alter the select clause (for example it
264         can add aliases to clauses that do not yet have one, or it can
265         add totally new select clauses).
266         """
267         if self.query.extra_order_by:
268             ordering = self.query.extra_order_by
269         elif not self.query.default_ordering:
270             ordering = self.query.order_by
271         elif self.query.order_by:
272             ordering = self.query.order_by
273         elif self.query.get_meta().ordering:
274             ordering = self.query.get_meta().ordering
275             self._meta_ordering = ordering
276         else:
277             ordering = []
278         if self.query.standard_ordering:
279             asc, desc = ORDER_DIR['ASC']
280         else:
281             asc, desc = ORDER_DIR['DESC']
282 
283         order_by = []
284         for field in ordering:
285             if hasattr(field, 'resolve_expression'):
286                 if isinstance(field, Value):
287                     # output_field must be resolved for constants.
288                     field = Cast(field, field.output_field)
289                 if not isinstance(field, OrderBy):
290                     field = field.asc()
291                 if not self.query.standard_ordering:
292                     field = field.copy()
293                     field.reverse_ordering()
294                 order_by.append((field, False))
295                 continue
296             if field == '?':  # random
297                 order_by.append((OrderBy(Random()), False))
298                 continue
299 
300             col, order = get_order_dir(field, asc)
301             descending = order == 'DESC'
302 
303             if col in self.query.annotation_select:
304                 # Reference to expression in SELECT clause
305                 order_by.append((
306                     OrderBy(Ref(col, self.query.annotation_select[col]), descending=descending),
307                     True))
308                 continue
309             if col in self.query.annotations:
310                 # References to an expression which is masked out of the SELECT
311                 # clause.
312                 expr = self.query.annotations[col]
313                 if isinstance(expr, Value):
314                     # output_field must be resolved for constants.
315                     expr = Cast(expr, expr.output_field)
316                 order_by.append((OrderBy(expr, descending=descending), False))
317                 continue
318 
319             if '.' in field:
320                 # This came in through an extra(order_by=...) addition. Pass it
321                 # on verbatim.
322                 table, col = col.split('.', 1)
323                 order_by.append((
324                     OrderBy(
325                         RawSQL('%s.%s' % (self.quote_name_unless_alias(table), col), []),
326                         descending=descending
327                     ), False))
328                 continue
329 
330             if not self.query.extra or col not in self.query.extra:
331                 # 'col' is of the form 'field' or 'field1__field2' or
332                 # '-field1__field2__field', etc.
333                 order_by.extend(self.find_ordering_name(
334                     field, self.query.get_meta(), default_order=asc))
335             else:
336                 if col not in self.query.extra_select:
337                     order_by.append((
338                         OrderBy(RawSQL(*self.query.extra[col]), descending=descending),
339                         False))
340                 else:
341                     order_by.append((
342                         OrderBy(Ref(col, RawSQL(*self.query.extra[col])), descending=descending),
343                         True))
344         result = []
345         seen = set()
346 
347         for expr, is_ref in order_by:
348             resolved = expr.resolve_expression(self.query, allow_joins=True, reuse=None)
349             if self.query.combinator:
350                 src = resolved.get_source_expressions()[0]
351                 # Relabel order by columns to raw numbers if this is a combined
352                 # query; necessary since the columns can't be referenced by the
353                 # fully qualified name and the simple column names may collide.
354                 for idx, (sel_expr, _, col_alias) in enumerate(self.select):
355                     if is_ref and col_alias == src.refs:
356                         src = src.source
357                     elif col_alias:
358                         continue
359                     if src == sel_expr:
360                         resolved.set_source_expressions([RawSQL('%d' % (idx + 1), ())])
361                         break
362                 else:
363                     if col_alias:
364                         raise DatabaseError('ORDER BY term does not match any column in the result set.')
365                     # Add column used in ORDER BY clause without an alias to
366                     # the selected columns.
367                     self.query.add_select_col(src)
368                     resolved.set_source_expressions([RawSQL('%d' % len(self.query.select), ())])
369             sql, params = self.compile(resolved)
370             # Don't add the same column twice, but the order direction is
371             # not taken into account so we strip it. When this entire method
372             # is refactored into expressions, then we can check each part as we
373             # generate it.
374             without_ordering = self.ordering_parts.search(sql).group(1)
375             params_hash = make_hashable(params)
376             if (without_ordering, params_hash) in seen:
377                 continue
378             seen.add((without_ordering, params_hash))
379             result.append((resolved, (sql, params, is_ref)))
380         return result
381 
382     def get_extra_select(self, order_by, select):
383         extra_select = []
384         if self.query.distinct and not self.query.distinct_fields:
385             select_sql = [t[1] for t in select]
386             for expr, (sql, params, is_ref) in order_by:
387                 without_ordering = self.ordering_parts.search(sql).group(1)
388                 if not is_ref and (without_ordering, params) not in select_sql:
389                     extra_select.append((expr, (without_ordering, params), None))
390         return extra_select
391 
392     def quote_name_unless_alias(self, name):
393         """
394         A wrapper around connection.ops.quote_name that doesn't quote aliases
395         for table names. This avoids problems with some SQL dialects that treat
396         quoted strings specially (e.g. PostgreSQL).
397         """
398         if name in self.quote_cache:
399             return self.quote_cache[name]
400         if ((name in self.query.alias_map and name not in self.query.table_map) or
401                 name in self.query.extra_select or (
402                     name in self.query.external_aliases and name not in self.query.table_map)):
403             self.quote_cache[name] = name
404             return name
405         r = self.connection.ops.quote_name(name)
406         self.quote_cache[name] = r
407         return r
408 
409     def compile(self, node):
410         vendor_impl = getattr(node, 'as_' + self.connection.vendor, None)
411         if vendor_impl:
412             sql, params = vendor_impl(self, self.connection)
413         else:
414             sql, params = node.as_sql(self, self.connection)
415         return sql, params
416 
417     def get_combinator_sql(self, combinator, all):
418         features = self.connection.features
419         compilers = [
420             query.get_compiler(self.using, self.connection)
421             for query in self.query.combined_queries if not query.is_empty()
422         ]
423         if not features.supports_slicing_ordering_in_compound:
424             for query, compiler in zip(self.query.combined_queries, compilers):
425                 if query.low_mark or query.high_mark:
426                     raise DatabaseError('LIMIT/OFFSET not allowed in subqueries of compound statements.')
427                 if compiler.get_order_by():
428                     raise DatabaseError('ORDER BY not allowed in subqueries of compound statements.')
429         parts = ()
430         for compiler in compilers:
431             try:
432                 # If the columns list is limited, then all combined queries
433                 # must have the same columns list. Set the selects defined on
434                 # the query on all combined queries, if not already set.
435                 if not compiler.query.values_select and self.query.values_select:
436                     compiler.query = compiler.query.clone()
437                     compiler.query.set_values((
438                         *self.query.extra_select,
439                         *self.query.values_select,
440                         *self.query.annotation_select,
441                     ))
442                 part_sql, part_args = compiler.as_sql()
443                 if compiler.query.combinator:
444                     # Wrap in a subquery if wrapping in parentheses isn't
445                     # supported.
446                     if not features.supports_parentheses_in_compound:
447                         part_sql = 'SELECT * FROM ({})'.format(part_sql)
448                     # Add parentheses when combining with compound query if not
449                     # already added for all compound queries.
450                     elif not features.supports_slicing_ordering_in_compound:
451                         part_sql = '({})'.format(part_sql)
452                 parts += ((part_sql, part_args),)
453             except EmptyResultSet:
454                 # Omit the empty queryset with UNION and with DIFFERENCE if the
455                 # first queryset is nonempty.
456                 if combinator == 'union' or (combinator == 'difference' and parts):
457                     continue
458                 raise
459         if not parts:
460             raise EmptyResultSet
461         combinator_sql = self.connection.ops.set_operators[combinator]
462         if all and combinator == 'union':
463             combinator_sql += ' ALL'
464         braces = '({})' if features.supports_slicing_ordering_in_compound else '{}'
465         sql_parts, args_parts = zip(*((braces.format(sql), args) for sql, args in parts))
466         result = [' {} '.format(combinator_sql).join(sql_parts)]
467         params = []
468         for part in args_parts:
469             params.extend(part)
470         return result, params
471 
472     def as_sql(self, with_limits=True, with_col_aliases=False):
473         """
474         Create the SQL for this query. Return the SQL string and list of
475         parameters.
476 
477         If 'with_limits' is False, any limit/offset information is not included
478         in the query.
479         """
480         refcounts_before = self.query.alias_refcount.copy()
481         try:
482             extra_select, order_by, group_by = self.pre_sql_setup()
483             for_update_part = None
484             # Is a LIMIT/OFFSET clause needed?
485             with_limit_offset = with_limits and (self.query.high_mark is not None or self.query.low_mark)
486             combinator = self.query.combinator
487             features = self.connection.features
488             if combinator:
489                 if not getattr(features, 'supports_select_{}'.format(combinator)):
490                     raise NotSupportedError('{} is not supported on this database backend.'.format(combinator))
491                 result, params = self.get_combinator_sql(combinator, self.query.combinator_all)
492             else:
493                 distinct_fields, distinct_params = self.get_distinct()
494                 # This must come after 'select', 'ordering', and 'distinct'
495                 # (see docstring of get_from_clause() for details).
496                 from_, f_params = self.get_from_clause()
497                 where, w_params = self.compile(self.where) if self.where is not None else ("", [])
498                 having, h_params = self.compile(self.having) if self.having is not None else ("", [])
499                 result = ['SELECT']
500                 params = []
501 
502                 if self.query.distinct:
503                     distinct_result, distinct_params = self.connection.ops.distinct_sql(
504                         distinct_fields,
505                         distinct_params,
506                     )
507                     result += distinct_result
508                     params += distinct_params
509 
510                 out_cols = []
511                 col_idx = 1
512                 for _, (s_sql, s_params), alias in self.select + extra_select:
513                     if alias:
514                         s_sql = '%s AS %s' % (s_sql, self.connection.ops.quote_name(alias))
515                     elif with_col_aliases:
516                         s_sql = '%s AS %s' % (s_sql, 'Col%d' % col_idx)
517                         col_idx += 1
518                     params.extend(s_params)
519                     out_cols.append(s_sql)
520 
521                 result += [', '.join(out_cols), 'FROM', *from_]
522                 params.extend(f_params)
523 
524                 if self.query.select_for_update and self.connection.features.has_select_for_update:
525                     if self.connection.get_autocommit():
526                         raise TransactionManagementError('select_for_update cannot be used outside of a transaction.')
527 
528                     if with_limit_offset and not self.connection.features.supports_select_for_update_with_limit:
529                         raise NotSupportedError(
530                             'LIMIT/OFFSET is not supported with '
531                             'select_for_update on this database backend.'
532                         )
533                     nowait = self.query.select_for_update_nowait
534                     skip_locked = self.query.select_for_update_skip_locked
535                     of = self.query.select_for_update_of
536                     # If it's a NOWAIT/SKIP LOCKED/OF query but the backend
537                     # doesn't support it, raise NotSupportedError to prevent a
538                     # possible deadlock.
539                     if nowait and not self.connection.features.has_select_for_update_nowait:
540                         raise NotSupportedError('NOWAIT is not supported on this database backend.')
541                     elif skip_locked and not self.connection.features.has_select_for_update_skip_locked:
542                         raise NotSupportedError('SKIP LOCKED is not supported on this database backend.')
543                     elif of and not self.connection.features.has_select_for_update_of:
544                         raise NotSupportedError('FOR UPDATE OF is not supported on this database backend.')
545                     for_update_part = self.connection.ops.for_update_sql(
546                         nowait=nowait,
547                         skip_locked=skip_locked,
548                         of=self.get_select_for_update_of_arguments(),
549                     )
550 
551                 if for_update_part and self.connection.features.for_update_after_from:
552                     result.append(for_update_part)
553 
554                 if where:
555                     result.append('WHERE %s' % where)
556                     params.extend(w_params)
557 
558                 grouping = []
559                 for g_sql, g_params in group_by:
560                     grouping.append(g_sql)
561                     params.extend(g_params)
562                 if grouping:
563                     if distinct_fields:
564                         raise NotImplementedError('annotate() + distinct(fields) is not implemented.')
565                     order_by = order_by or self.connection.ops.force_no_ordering()
566                     result.append('GROUP BY %s' % ', '.join(grouping))
567                     if self._meta_ordering:
568                         order_by = None
569                 if having:
570                     result.append('HAVING %s' % having)
571                     params.extend(h_params)
572 
573             if self.query.explain_query:
574                 result.insert(0, self.connection.ops.explain_query_prefix(
575                     self.query.explain_format,
576                     **self.query.explain_options
577                 ))
578 
579             if order_by:
580                 ordering = []
581                 for _, (o_sql, o_params, _) in order_by:
582                     ordering.append(o_sql)
583                     params.extend(o_params)
584                 result.append('ORDER BY %s' % ', '.join(ordering))
585 
586             if with_limit_offset:
587                 result.append(self.connection.ops.limit_offset_sql(self.query.low_mark, self.query.high_mark))
588 
589             if for_update_part and not self.connection.features.for_update_after_from:
590                 result.append(for_update_part)
591 
592             if self.query.subquery and extra_select:
593                 # If the query is used as a subquery, the extra selects would
594                 # result in more columns than the left-hand side expression is
595                 # expecting. This can happen when a subquery uses a combination
596                 # of order_by() and distinct(), forcing the ordering expressions
597                 # to be selected as well. Wrap the query in another subquery
598                 # to exclude extraneous selects.
599                 sub_selects = []
600                 sub_params = []
601                 for index, (select, _, alias) in enumerate(self.select, start=1):
602                     if not alias and with_col_aliases:
603                         alias = 'col%d' % index
604                     if alias:
605                         sub_selects.append("%s.%s" % (
606                             self.connection.ops.quote_name('subquery'),
607                             self.connection.ops.quote_name(alias),
608                         ))
609                     else:
610                         select_clone = select.relabeled_clone({select.alias: 'subquery'})
611                         subselect, subparams = select_clone.as_sql(self, self.connection)
612                         sub_selects.append(subselect)
613                         sub_params.extend(subparams)
614                 return 'SELECT %s FROM (%s) subquery' % (
615                     ', '.join(sub_selects),
616                     ' '.join(result),
617                 ), tuple(sub_params + params)
618 
619             return ' '.join(result), tuple(params)
620         finally:
621             # Finally do cleanup - get rid of the joins we created above.
622             self.query.reset_refcounts(refcounts_before)
623 
624     def get_default_columns(self, start_alias=None, opts=None, from_parent=None):
625         """
626         Compute the default columns for selecting every field in the base
627         model. Will sometimes be called to pull in related models (e.g. via
628         select_related), in which case "opts" and "start_alias" will be given
629         to provide a starting point for the traversal.
630 
631         Return a list of strings, quoted appropriately for use in SQL
632         directly, as well as a set of aliases used in the select statement (if
633         'as_pairs' is True, return a list of (alias, col_name) pairs instead
634         of strings as the first component and None as the second component).
635         """
636         result = []
637         if opts is None:
638             opts = self.query.get_meta()
639         only_load = self.deferred_to_columns()
640         start_alias = start_alias or self.query.get_initial_alias()
641         # The 'seen_models' is used to optimize checking the needed parent
642         # alias for a given field. This also includes None -> start_alias to
643         # be used by local fields.
644         seen_models = {None: start_alias}
645 
646         for field in opts.concrete_fields:
647             model = field.model._meta.concrete_model
648             # A proxy model will have a different model and concrete_model. We
649             # will assign None if the field belongs to this model.
650             if model == opts.model:
651                 model = None
652             if from_parent and model is not None and issubclass(
653                     from_parent._meta.concrete_model, model._meta.concrete_model):
654                 # Avoid loading data for already loaded parents.
655                 # We end up here in the case select_related() resolution
656                 # proceeds from parent model to child model. In that case the
657                 # parent model data is already present in the SELECT clause,
658                 # and we want to avoid reloading the same data again.
659                 continue
660             if field.model in only_load and field.attname not in only_load[field.model]:
661                 continue
662             alias = self.query.join_parent_model(opts, model, start_alias,
663                                                  seen_models)
664             column = field.get_col(alias)
665             result.append(column)
666         return result
667 
668     def get_distinct(self):
669         """
670         Return a quoted list of fields to use in DISTINCT ON part of the query.
671 
672         This method can alter the tables in the query, and thus it must be
673         called before get_from_clause().
674         """
675         result = []
676         params = []
677         opts = self.query.get_meta()
678 
679         for name in self.query.distinct_fields:
680             parts = name.split(LOOKUP_SEP)
681             _, targets, alias, joins, path, _, transform_function = self._setup_joins(parts, opts, None)
682             targets, alias, _ = self.query.trim_joins(targets, joins, path)
683             for target in targets:
684                 if name in self.query.annotation_select:
685                     result.append(name)
686                 else:
687                     r, p = self.compile(transform_function(target, alias))
688                     result.append(r)
689                     params.append(p)
690         return result, params
691 
692     def find_ordering_name(self, name, opts, alias=None, default_order='ASC',
693                            already_seen=None):
694         """
695         Return the table alias (the name might be ambiguous, the alias will
696         not be) and column name for ordering by the given 'name' parameter.
697         The 'name' is of the form 'field1__field2__...__fieldN'.
698         """
699         name, order = get_order_dir(name, default_order)
700         descending = order == 'DESC'
701         pieces = name.split(LOOKUP_SEP)
702         field, targets, alias, joins, path, opts, transform_function = self._setup_joins(pieces, opts, alias)
703 
704         # If we get to this point and the field is a relation to another model,
705         # append the default ordering for that model unless the attribute name
706         # of the field is specified.
707         if field.is_relation and opts.ordering and getattr(field, 'attname', None) != name:
708             # Firstly, avoid infinite loops.
709             already_seen = already_seen or set()
710             join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)
711             if join_tuple in already_seen:
712                 raise FieldError('Infinite loop caused by ordering.')
713             already_seen.add(join_tuple)
714 
715             results = []
716             for item in opts.ordering:
717                 if hasattr(item, 'resolve_expression') and not isinstance(item, OrderBy):
718                     item = item.desc() if descending else item.asc()
719                 if isinstance(item, OrderBy):
720                     results.append((item, False))
721                     continue
722                 results.extend(self.find_ordering_name(item, opts, alias,
723                                                        order, already_seen))
724             return results
725         targets, alias, _ = self.query.trim_joins(targets, joins, path)
726         return [(OrderBy(transform_function(t, alias), descending=descending), False) for t in targets]
727 
728     def _setup_joins(self, pieces, opts, alias):
729         """
730         Helper method for get_order_by() and get_distinct().
731 
732         get_ordering() and get_distinct() must produce same target columns on
733         same input, as the prefixes of get_ordering() and get_distinct() must
734         match. Executing SQL where this is not true is an error.
735         """
736         alias = alias or self.query.get_initial_alias()
737         field, targets, opts, joins, path, transform_function = self.query.setup_joins(pieces, opts, alias)
738         alias = joins[-1]
739         return field, targets, alias, joins, path, opts, transform_function
740 
741     def get_from_clause(self):
742         """
743         Return a list of strings that are joined together to go after the
744         "FROM" part of the query, as well as a list any extra parameters that
745         need to be included. Subclasses, can override this to create a
746         from-clause via a "select".
747 
748         This should only be called after any SQL construction methods that
749         might change the tables that are needed. This means the select columns,
750         ordering, and distinct must be done first.
751         """
752         result = []
753         params = []
754         for alias in tuple(self.query.alias_map):
755             if not self.query.alias_refcount[alias]:
756                 continue
757             try:
758                 from_clause = self.query.alias_map[alias]
759             except KeyError:
760                 # Extra tables can end up in self.tables, but not in the
761                 # alias_map if they aren't in a join. That's OK. We skip them.
762                 continue
763             clause_sql, clause_params = self.compile(from_clause)
764             result.append(clause_sql)
765             params.extend(clause_params)
766         for t in self.query.extra_tables:
767             alias, _ = self.query.table_alias(t)
768             # Only add the alias if it's not already present (the table_alias()
769             # call increments the refcount, so an alias refcount of one means
770             # this is the only reference).
771             if alias not in self.query.alias_map or self.query.alias_refcount[alias] == 1:
772                 result.append(', %s' % self.quote_name_unless_alias(alias))
773         return result, params
774 
775     def get_related_selections(self, select, opts=None, root_alias=None, cur_depth=1,
776                                requested=None, restricted=None):
777         """
778         Fill in the information needed for a select_related query. The current
779         depth is measured as the number of connections away from the root model
780         (for example, cur_depth=1 means we are looking at models with direct
781         connections to the root model).
782         """
783         def _get_field_choices():
784             direct_choices = (f.name for f in opts.fields if f.is_relation)
785             reverse_choices = (
786                 f.field.related_query_name()
787                 for f in opts.related_objects if f.field.unique
788             )
789             return chain(direct_choices, reverse_choices, self.query._filtered_relations)
790 
791         related_klass_infos = []
792         if not restricted and cur_depth > self.query.max_depth:
793             # We've recursed far enough; bail out.
794             return related_klass_infos
795 
796         if not opts:
797             opts = self.query.get_meta()
798             root_alias = self.query.get_initial_alias()
799         only_load = self.query.get_loaded_field_names()
800 
801         # Setup for the case when only particular related fields should be
802         # included in the related selection.
803         fields_found = set()
804         if requested is None:
805             restricted = isinstance(self.query.select_related, dict)
806             if restricted:
807                 requested = self.query.select_related
808 
809         def get_related_klass_infos(klass_info, related_klass_infos):
810             klass_info['related_klass_infos'] = related_klass_infos
811 
812         for f in opts.fields:
813             field_model = f.model._meta.concrete_model
814             fields_found.add(f.name)
815 
816             if restricted:
817                 next = requested.get(f.name, {})
818                 if not f.is_relation:
819                     # If a non-related field is used like a relation,
820                     # or if a single non-relational field is given.
821                     if next or f.name in requested:
822                         raise FieldError(
823                             "Non-relational field given in select_related: '%s'. "
824                             "Choices are: %s" % (
825                                 f.name,
826                                 ", ".join(_get_field_choices()) or '(none)',
827                             )
828                         )
829             else:
830                 next = False
831 
832             if not select_related_descend(f, restricted, requested,
833                                           only_load.get(field_model)):
834                 continue
835             klass_info = {
836                 'model': f.remote_field.model,
837                 'field': f,
838                 'reverse': False,
839                 'local_setter': f.set_cached_value,
840                 'remote_setter': f.remote_field.set_cached_value if f.unique else lambda x, y: None,
841                 'from_parent': False,
842             }
843             related_klass_infos.append(klass_info)
844             select_fields = []
845             _, _, _, joins, _, _ = self.query.setup_joins(
846                 [f.name], opts, root_alias)
847             alias = joins[-1]
848             columns = self.get_default_columns(start_alias=alias, opts=f.remote_field.model._meta)
849             for col in columns:
850                 select_fields.append(len(select))
851                 select.append((col, None))
852             klass_info['select_fields'] = select_fields
853             next_klass_infos = self.get_related_selections(
854                 select, f.remote_field.model._meta, alias, cur_depth + 1, next, restricted)
855             get_related_klass_infos(klass_info, next_klass_infos)
856 
857         if restricted:
858             related_fields = [
859                 (o.field, o.related_model)
860                 for o in opts.related_objects
861                 if o.field.unique and not o.many_to_many
862             ]
863             for f, model in related_fields:
864                 if not select_related_descend(f, restricted, requested,
865                                               only_load.get(model), reverse=True):
866                     continue
867 
868                 related_field_name = f.related_query_name()
869                 fields_found.add(related_field_name)
870 
871                 join_info = self.query.setup_joins([related_field_name], opts, root_alias)
872                 alias = join_info.joins[-1]
873                 from_parent = issubclass(model, opts.model) and model is not opts.model
874                 klass_info = {
875                     'model': model,
876                     'field': f,
877                     'reverse': True,
878                     'local_setter': f.remote_field.set_cached_value,
879                     'remote_setter': f.set_cached_value,
880                     'from_parent': from_parent,
881                 }
882                 related_klass_infos.append(klass_info)
883                 select_fields = []
884                 columns = self.get_default_columns(
885                     start_alias=alias, opts=model._meta, from_parent=opts.model)
886                 for col in columns:
887                     select_fields.append(len(select))
888                     select.append((col, None))
889                 klass_info['select_fields'] = select_fields
890                 next = requested.get(f.related_query_name(), {})
891                 next_klass_infos = self.get_related_selections(
892                     select, model._meta, alias, cur_depth + 1,
893                     next, restricted)
894                 get_related_klass_infos(klass_info, next_klass_infos)
895 
896             def local_setter(obj, from_obj):
897                 # Set a reverse fk object when relation is non-empty.
898                 if from_obj:
899                     f.remote_field.set_cached_value(from_obj, obj)
900 
901             def remote_setter(name, obj, from_obj):
902                 setattr(from_obj, name, obj)
903 
904             for name in list(requested):
905                 # Filtered relations work only on the topmost level.
906                 if cur_depth > 1:
907                     break
908                 if name in self.query._filtered_relations:
909                     fields_found.add(name)
910                     f, _, join_opts, joins, _, _ = self.query.setup_joins([name], opts, root_alias)
911                     model = join_opts.model
912                     alias = joins[-1]
913                     from_parent = issubclass(model, opts.model) and model is not opts.model
914                     klass_info = {
915                         'model': model,
916                         'field': f,
917                         'reverse': True,
918                         'local_setter': local_setter,
919                         'remote_setter': partial(remote_setter, name),
920                         'from_parent': from_parent,
921                     }
922                     related_klass_infos.append(klass_info)
923                     select_fields = []
924                     columns = self.get_default_columns(
925                         start_alias=alias, opts=model._meta,
926                         from_parent=opts.model,
927                     )
928                     for col in columns:
929                         select_fields.append(len(select))
930                         select.append((col, None))
931                     klass_info['select_fields'] = select_fields
932                     next_requested = requested.get(name, {})
933                     next_klass_infos = self.get_related_selections(
934                         select, opts=model._meta, root_alias=alias,
935                         cur_depth=cur_depth + 1, requested=next_requested,
936                         restricted=restricted,
937                     )
938                     get_related_klass_infos(klass_info, next_klass_infos)
939             fields_not_found = set(requested).difference(fields_found)
940             if fields_not_found:
941                 invalid_fields = ("'%s'" % s for s in fields_not_found)
942                 raise FieldError(
943                     'Invalid field name(s) given in select_related: %s. '
944                     'Choices are: %s' % (
945                         ', '.join(invalid_fields),
946                         ', '.join(_get_field_choices()) or '(none)',
947                     )
948                 )
949         return related_klass_infos
950 
951     def get_select_for_update_of_arguments(self):
952         """
953         Return a quoted list of arguments for the SELECT FOR UPDATE OF part of
954         the query.
955         """
956         def _get_parent_klass_info(klass_info):
957             return (
958                 {
959                     'model': parent_model,
960                     'field': parent_link,
961                     'reverse': False,
962                     'select_fields': [
963                         select_index
964                         for select_index in klass_info['select_fields']
965                         if self.select[select_index][0].target.model == parent_model
966                     ],
967                 }
968                 for parent_model, parent_link in klass_info['model']._meta.parents.items()
969             )
970 
971         def _get_field_choices():
972             """Yield all allowed field paths in breadth-first search order."""
973             queue = collections.deque([(None, self.klass_info)])
974             while queue:
975                 parent_path, klass_info = queue.popleft()
976                 if parent_path is None:
977                     path = []
978                     yield 'self'
979                 else:
980                     field = klass_info['field']
981                     if klass_info['reverse']:
982                         field = field.remote_field
983                     path = parent_path + [field.name]
984                     yield LOOKUP_SEP.join(path)
985                 queue.extend(
986                     (path, klass_info)
987                     for klass_info in _get_parent_klass_info(klass_info)
988                 )
989                 queue.extend(
990                     (path, klass_info)
991                     for klass_info in klass_info.get('related_klass_infos', [])
992                 )
993         result = []
994         invalid_names = []
995         for name in self.query.select_for_update_of:
996             klass_info = self.klass_info
997             if name == 'self':
998                 # Find the first selected column from a base model. If it
999                 # doesn't exist, don't lock a base model.
1000                 for select_index in klass_info['select_fields']:
1001                     if self.select[select_index][0].target.model == klass_info['model']:
1002                         col = self.select[select_index][0]
1003                         break
1004                 else:
1005                     col = None
1006             else:
1007                 for part in name.split(LOOKUP_SEP):
1008                     klass_infos = (
1009                         *klass_info.get('related_klass_infos', []),
1010                         *_get_parent_klass_info(klass_info),
1011                     )
1012                     for related_klass_info in klass_infos:
1013                         field = related_klass_info['field']
1014                         if related_klass_info['reverse']:
1015                             field = field.remote_field
1016                         if field.name == part:
1017                             klass_info = related_klass_info
1018                             break
1019                     else:
1020                         klass_info = None
1021                         break
1022                 if klass_info is None:
1023                     invalid_names.append(name)
1024                     continue
1025                 select_index = klass_info['select_fields'][0]
1026                 col = self.select[select_index][0]
1027             if col is not None:
1028                 if self.connection.features.select_for_update_of_column:
1029                     result.append(self.compile(col)[0])
1030                 else:
1031                     result.append(self.quote_name_unless_alias(col.alias))
1032         if invalid_names:
1033             raise FieldError(
1034                 'Invalid field name(s) given in select_for_update(of=(...)): %s. '
1035                 'Only relational fields followed in the query are allowed. '
1036                 'Choices are: %s.' % (
1037                     ', '.join(invalid_names),
1038                     ', '.join(_get_field_choices()),
1039                 )
1040             )
1041         return result
1042 
1043     def deferred_to_columns(self):
1044         """
1045         Convert the self.deferred_loading data structure to mapping of table
1046         names to sets of column names which are to be loaded. Return the
1047         dictionary.
1048         """
1049         columns = {}
1050         self.query.deferred_to_data(columns, self.query.get_loaded_field_names_cb)
1051         return columns
1052 
1053     def get_converters(self, expressions):
1054         converters = {}
1055         for i, expression in enumerate(expressions):
1056             if expression:
1057                 backend_converters = self.connection.ops.get_db_converters(expression)
1058                 field_converters = expression.get_db_converters(self.connection)
1059                 if backend_converters or field_converters:
1060                     converters[i] = (backend_converters + field_converters, expression)
1061         return converters
1062 
1063     def apply_converters(self, rows, converters):
1064         connection = self.connection
1065         converters = list(converters.items())
1066         for row in map(list, rows):
1067             for pos, (convs, expression) in converters:
1068                 value = row[pos]
1069                 for converter in convs:
1070                     value = converter(value, expression, connection)
1071                 row[pos] = value
1072             yield row
1073 
1074     def results_iter(self, results=None, tuple_expected=False, chunked_fetch=False,
1075                      chunk_size=GET_ITERATOR_CHUNK_SIZE):
1076         """Return an iterator over the results from executing this query."""
1077         if results is None:
1078             results = self.execute_sql(MULTI, chunked_fetch=chunked_fetch, chunk_size=chunk_size)
1079         fields = [s[0] for s in self.select[0:self.col_count]]
1080         converters = self.get_converters(fields)
1081         rows = chain.from_iterable(results)
1082         if converters:
1083             rows = self.apply_converters(rows, converters)
1084             if tuple_expected:
1085                 rows = map(tuple, rows)
1086         return rows
1087 
1088     def has_results(self):
1089         """
1090         Backends (e.g. NoSQL) can override this in order to use optimized
1091         versions of "query has any results."
1092         """
1093         # This is always executed on a query clone, so we can modify self.query
1094         self.query.add_extra({'a': 1}, None, None, None, None, None)
1095         self.query.set_extra_mask(['a'])
1096         return bool(self.execute_sql(SINGLE))
1097 
1098     def execute_sql(self, result_type=MULTI, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE):
1099         """
1100         Run the query against the database and return the result(s). The
1101         return value is a single data item if result_type is SINGLE, or an
1102         iterator over the results if the result_type is MULTI.
1103 
1104         result_type is either MULTI (use fetchmany() to retrieve all rows),
1105         SINGLE (only retrieve a single row), or None. In this last case, the
1106         cursor is returned if any query is executed, since it's used by
1107         subclasses such as InsertQuery). It's possible, however, that no query
1108         is needed, as the filters describe an empty set. In that case, None is
1109         returned, to avoid any unnecessary database interaction.
1110         """
1111         result_type = result_type or NO_RESULTS
1112         try:
1113             sql, params = self.as_sql()
1114             if not sql:
1115                 raise EmptyResultSet
1116         except EmptyResultSet:
1117             if result_type == MULTI:
1118                 return iter([])
1119             else:
1120                 return
1121         if chunked_fetch:
1122             cursor = self.connection.chunked_cursor()
1123         else:
1124             cursor = self.connection.cursor()
1125         try:
1126             cursor.execute(sql, params)
1127         except Exception:
1128             # Might fail for server-side cursors (e.g. connection closed)
1129             cursor.close()
1130             raise
1131 
1132         if result_type == CURSOR:
1133             # Give the caller the cursor to process and close.
1134             return cursor
1135         if result_type == SINGLE:
1136             try:
1137                 val = cursor.fetchone()
1138                 if val:
1139                     return val[0:self.col_count]
1140                 return val
1141             finally:
1142                 # done with the cursor
1143                 cursor.close()
1144         if result_type == NO_RESULTS:
1145             cursor.close()
1146             return
1147 
1148         result = cursor_iter(
1149             cursor, self.connection.features.empty_fetchmany_value,
1150             self.col_count if self.has_extra_select else None,
1151             chunk_size,
1152         )
1153         if not chunked_fetch or not self.connection.features.can_use_chunked_reads:
1154             try:
1155                 # If we are using non-chunked reads, we return the same data
1156                 # structure as normally, but ensure it is all read into memory
1157                 # before going any further. Use chunked_fetch if requested,
1158                 # unless the database doesn't support it.
1159                 return list(result)
1160             finally:
1161                 # done with the cursor
1162                 cursor.close()
1163         return result
1164 
1165     def as_subquery_condition(self, alias, columns, compiler):
1166         qn = compiler.quote_name_unless_alias
1167         qn2 = self.connection.ops.quote_name
1168 
1169         for index, select_col in enumerate(self.query.select):
1170             lhs_sql, lhs_params = self.compile(select_col)
1171             rhs = '%s.%s' % (qn(alias), qn2(columns[index]))
1172             self.query.where.add(
1173                 RawSQL('%s = %s' % (lhs_sql, rhs), lhs_params), 'AND')
1174 
1175         sql, params = self.as_sql()
1176         return 'EXISTS (%s)' % sql, params
1177 
1178     def explain_query(self):
1179         result = list(self.execute_sql())
1180         # Some backends return 1 item tuples with strings, and others return
1181         # tuples with integers and strings. Flatten them out into strings.
1182         for row in result[0]:
1183             if not isinstance(row, str):
1184                 yield ' '.join(str(c) for c in row)
1185             else:
1186                 yield row
1187 
1188 
1189 class SQLInsertCompiler(SQLCompiler):
1190     returning_fields = None
1191     returning_params = tuple()
1192 
1193     def field_as_sql(self, field, val):
1194         """
1195         Take a field and a value intended to be saved on that field, and
1196         return placeholder SQL and accompanying params. Check for raw values,
1197         expressions, and fields with get_placeholder() defined in that order.
1198 
1199         When field is None, consider the value raw and use it as the
1200         placeholder, with no corresponding parameters returned.
1201         """
1202         if field is None:
1203             # A field value of None means the value is raw.
1204             sql, params = val, []
1205         elif hasattr(val, 'as_sql'):
1206             # This is an expression, let's compile it.
1207             sql, params = self.compile(val)
1208         elif hasattr(field, 'get_placeholder'):
1209             # Some fields (e.g. geo fields) need special munging before
1210             # they can be inserted.
1211             sql, params = field.get_placeholder(val, self, self.connection), [val]
1212         else:
1213             # Return the common case for the placeholder
1214             sql, params = '%s', [val]
1215 
1216         # The following hook is only used by Oracle Spatial, which sometimes
1217         # needs to yield 'NULL' and [] as its placeholder and params instead
1218         # of '%s' and [None]. The 'NULL' placeholder is produced earlier by
1219         # OracleOperations.get_geom_placeholder(). The following line removes
1220         # the corresponding None parameter. See ticket #10888.
1221         params = self.connection.ops.modify_insert_params(sql, params)
1222 
1223         return sql, params
1224 
1225     def prepare_value(self, field, value):
1226         """
1227         Prepare a value to be used in a query by resolving it if it is an
1228         expression and otherwise calling the field's get_db_prep_save().
1229         """
1230         if hasattr(value, 'resolve_expression'):
1231             value = value.resolve_expression(self.query, allow_joins=False, for_save=True)
1232             # Don't allow values containing Col expressions. They refer to
1233             # existing columns on a row, but in the case of insert the row
1234             # doesn't exist yet.
1235             if value.contains_column_references:
1236                 raise ValueError(
1237                     'Failed to insert expression "%s" on %s. F() expressions '
1238                     'can only be used to update, not to insert.' % (value, field)
1239                 )
1240             if value.contains_aggregate:
1241                 raise FieldError(
1242                     'Aggregate functions are not allowed in this query '
1243                     '(%s=%r).' % (field.name, value)
1244                 )
1245             if value.contains_over_clause:
1246                 raise FieldError(
1247                     'Window expressions are not allowed in this query (%s=%r).'
1248                     % (field.name, value)
1249                 )
1250         else:
1251             value = field.get_db_prep_save(value, connection=self.connection)
1252         return value
1253 
1254     def pre_save_val(self, field, obj):
1255         """
1256         Get the given field's value off the given obj. pre_save() is used for
1257         things like auto_now on DateTimeField. Skip it if this is a raw query.
1258         """
1259         if self.query.raw:
1260             return getattr(obj, field.attname)
1261         return field.pre_save(obj, add=True)
1262 
1263     def assemble_as_sql(self, fields, value_rows):
1264         """
1265         Take a sequence of N fields and a sequence of M rows of values, and
1266         generate placeholder SQL and parameters for each field and value.
1267         Return a pair containing:
1268          * a sequence of M rows of N SQL placeholder strings, and
1269          * a sequence of M rows of corresponding parameter values.
1270 
1271         Each placeholder string may contain any number of '%s' interpolation
1272         strings, and each parameter row will contain exactly as many params
1273         as the total number of '%s's in the corresponding placeholder row.
1274         """
1275         if not value_rows:
1276             return [], []
1277 
1278         # list of (sql, [params]) tuples for each object to be saved
1279         # Shape: [n_objs][n_fields][2]
1280         rows_of_fields_as_sql = (
1281             (self.field_as_sql(field, v) for field, v in zip(fields, row))
1282             for row in value_rows
1283         )
1284 
1285         # tuple like ([sqls], [[params]s]) for each object to be saved
1286         # Shape: [n_objs][2][n_fields]
1287         sql_and_param_pair_rows = (zip(*row) for row in rows_of_fields_as_sql)
1288 
1289         # Extract separate lists for placeholders and params.
1290         # Each of these has shape [n_objs][n_fields]
1291         placeholder_rows, param_rows = zip(*sql_and_param_pair_rows)
1292 
1293         # Params for each field are still lists, and need to be flattened.
1294         param_rows = [[p for ps in row for p in ps] for row in param_rows]
1295 
1296         return placeholder_rows, param_rows
1297 
1298     def as_sql(self):
1299         # We don't need quote_name_unless_alias() here, since these are all
1300         # going to be column names (so we can avoid the extra overhead).
1301         qn = self.connection.ops.quote_name
1302         opts = self.query.get_meta()
1303         insert_statement = self.connection.ops.insert_statement(ignore_conflicts=self.query.ignore_conflicts)
1304         result = ['%s %s' % (insert_statement, qn(opts.db_table))]
1305         fields = self.query.fields or [opts.pk]
1306         result.append('(%s)' % ', '.join(qn(f.column) for f in fields))
1307 
1308         if self.query.fields:
1309             value_rows = [
1310                 [self.prepare_value(field, self.pre_save_val(field, obj)) for field in fields]
1311                 for obj in self.query.objs
1312             ]
1313         else:
1314             # An empty object.
1315             value_rows = [[self.connection.ops.pk_default_value()] for _ in self.query.objs]
1316             fields = [None]
1317 
1318         # Currently the backends just accept values when generating bulk
1319         # queries and generate their own placeholders. Doing that isn't
1320         # necessary and it should be possible to use placeholders and
1321         # expressions in bulk inserts too.
1322         can_bulk = (not self.returning_fields and self.connection.features.has_bulk_insert)
1323 
1324         placeholder_rows, param_rows = self.assemble_as_sql(fields, value_rows)
1325 
1326         ignore_conflicts_suffix_sql = self.connection.ops.ignore_conflicts_suffix_sql(
1327             ignore_conflicts=self.query.ignore_conflicts
1328         )
1329         if self.returning_fields and self.connection.features.can_return_columns_from_insert:
1330             if self.connection.features.can_return_rows_from_bulk_insert:
1331                 result.append(self.connection.ops.bulk_insert_sql(fields, placeholder_rows))
1332                 params = param_rows
1333             else:
1334                 result.append("VALUES (%s)" % ", ".join(placeholder_rows[0]))
1335                 params = [param_rows[0]]
1336             if ignore_conflicts_suffix_sql:
1337                 result.append(ignore_conflicts_suffix_sql)
1338             # Skip empty r_sql to allow subclasses to customize behavior for
1339             # 3rd party backends. Refs #19096.
1340             r_sql, self.returning_params = self.connection.ops.return_insert_columns(self.returning_fields)
1341             if r_sql:
1342                 result.append(r_sql)
1343                 params += [self.returning_params]
1344             return [(" ".join(result), tuple(chain.from_iterable(params)))]
1345 
1346         if can_bulk:
1347             result.append(self.connection.ops.bulk_insert_sql(fields, placeholder_rows))
1348             if ignore_conflicts_suffix_sql:
1349                 result.append(ignore_conflicts_suffix_sql)
1350             return [(" ".join(result), tuple(p for ps in param_rows for p in ps))]
1351         else:
1352             if ignore_conflicts_suffix_sql:
1353                 result.append(ignore_conflicts_suffix_sql)
1354             return [
1355                 (" ".join(result + ["VALUES (%s)" % ", ".join(p)]), vals)
1356                 for p, vals in zip(placeholder_rows, param_rows)
1357             ]
1358 
1359     def execute_sql(self, returning_fields=None):
1360         assert not (
1361             returning_fields and len(self.query.objs) != 1 and
1362             not self.connection.features.can_return_rows_from_bulk_insert
1363         )
1364         self.returning_fields = returning_fields
1365         with self.connection.cursor() as cursor:
1366             for sql, params in self.as_sql():
1367                 cursor.execute(sql, params)
1368             if not self.returning_fields:
1369                 return []
1370             if self.connection.features.can_return_rows_from_bulk_insert and len(self.query.objs) > 1:
1371                 return self.connection.ops.fetch_returned_insert_rows(cursor)
1372             if self.connection.features.can_return_columns_from_insert:
1373                 assert len(self.query.objs) == 1
1374                 return self.connection.ops.fetch_returned_insert_columns(cursor, self.returning_params)
1375             return [self.connection.ops.last_insert_id(
1376                 cursor, self.query.get_meta().db_table, self.query.get_meta().pk.column
1377             )]
1378 
1379 
1380 class SQLDeleteCompiler(SQLCompiler):
1381     @cached_property
1382     def single_alias(self):
1383         return sum(self.query.alias_refcount[t] > 0 for t in self.query.alias_map) == 1
1384 
1385     def _as_sql(self, query):
1386         result = [
1387             'DELETE FROM %s' % self.quote_name_unless_alias(query.base_table)
1388         ]
1389         where, params = self.compile(query.where)
1390         if where:
1391             result.append('WHERE %s' % where)
1392         return ' '.join(result), tuple(params)
1393 
1394     def as_sql(self):
1395         """
1396         Create the SQL for this query. Return the SQL string and list of
1397         parameters.
1398         """
1399         if self.single_alias:
1400             return self._as_sql(self.query)
1401         innerq = self.query.clone()
1402         innerq.__class__ = Query
1403         innerq.clear_select_clause()
1404         pk = self.query.model._meta.pk
1405         innerq.select = [
1406             pk.get_col(self.query.get_initial_alias())
1407         ]
1408         outerq = Query(self.query.model)
1409         outerq.where = self.query.where_class()
1410         outerq.add_q(Q(pk__in=innerq))
1411         return self._as_sql(outerq)
1412 
1413 
1414 class SQLUpdateCompiler(SQLCompiler):
1415     def as_sql(self):
1416         """
1417         Create the SQL for this query. Return the SQL string and list of
1418         parameters.
1419         """
1420         self.pre_sql_setup()
1421         if not self.query.values:
1422             return '', ()
1423         qn = self.quote_name_unless_alias
1424         values, update_params = [], []
1425         for field, model, val in self.query.values:
1426             if hasattr(val, 'resolve_expression'):
1427                 val = val.resolve_expression(self.query, allow_joins=False, for_save=True)
1428                 if val.contains_aggregate:
1429                     raise FieldError(
1430                         'Aggregate functions are not allowed in this query '
1431                         '(%s=%r).' % (field.name, val)
1432                     )
1433                 if val.contains_over_clause:
1434                     raise FieldError(
1435                         'Window expressions are not allowed in this query '
1436                         '(%s=%r).' % (field.name, val)
1437                     )
1438             elif hasattr(val, 'prepare_database_save'):
1439                 if field.remote_field:
1440                     val = field.get_db_prep_save(
1441                         val.prepare_database_save(field),
1442                         connection=self.connection,
1443                     )
1444                 else:
1445                     raise TypeError(
1446                         "Tried to update field %s with a model instance, %r. "
1447                         "Use a value compatible with %s."
1448                         % (field, val, field.__class__.__name__)
1449                     )
1450             else:
1451                 val = field.get_db_prep_save(val, connection=self.connection)
1452 
1453             # Getting the placeholder for the field.
1454             if hasattr(field, 'get_placeholder'):
1455                 placeholder = field.get_placeholder(val, self, self.connection)
1456             else:
1457                 placeholder = '%s'
1458             name = field.column
1459             if hasattr(val, 'as_sql'):
1460                 sql, params = self.compile(val)
1461                 values.append('%s = %s' % (qn(name), placeholder % sql))
1462                 update_params.extend(params)
1463             elif val is not None:
1464                 values.append('%s = %s' % (qn(name), placeholder))
1465                 update_params.append(val)
1466             else:
1467                 values.append('%s = NULL' % qn(name))
1468         table = self.query.base_table
1469         result = [
1470             'UPDATE %s SET' % qn(table),
1471             ', '.join(values),
1472         ]
1473         where, params = self.compile(self.query.where)
1474         if where:
1475             result.append('WHERE %s' % where)
1476         return ' '.join(result), tuple(update_params + params)
1477 
1478     def execute_sql(self, result_type):
1479         """
1480         Execute the specified update. Return the number of rows affected by
1481         the primary update query. The "primary update query" is the first
1482         non-empty query that is executed. Row counts for any subsequent,
1483         related queries are not available.
1484         """
1485         cursor = super().execute_sql(result_type)
1486         try:
1487             rows = cursor.rowcount if cursor else 0
1488             is_empty = cursor is None
1489         finally:
1490             if cursor:
1491                 cursor.close()
1492         for query in self.query.get_related_updates():
1493             aux_rows = query.get_compiler(self.using).execute_sql(result_type)
1494             if is_empty and aux_rows:
1495                 rows = aux_rows
1496                 is_empty = False
1497         return rows
1498 
1499     def pre_sql_setup(self):
1500         """
1501         If the update depends on results from other tables, munge the "where"
1502         conditions to match the format required for (portable) SQL updates.
1503 
1504         If multiple updates are required, pull out the id values to update at
1505         this point so that they don't change as a result of the progressive
1506         updates.
1507         """
1508         refcounts_before = self.query.alias_refcount.copy()
1509         # Ensure base table is in the query
1510         self.query.get_initial_alias()
1511         count = self.query.count_active_tables()
1512         if not self.query.related_updates and count == 1:
1513             return
1514         query = self.query.chain(klass=Query)
1515         query.select_related = False
1516         query.clear_ordering(True)
1517         query.extra = {}
1518         query.select = []
1519         query.add_fields([query.get_meta().pk.name])
1520         super().pre_sql_setup()
1521 
1522         must_pre_select = count > 1 and not self.connection.features.update_can_self_select
1523 
1524         # Now we adjust the current query: reset the where clause and get rid
1525         # of all the tables we don't need (since they're in the sub-select).
1526         self.query.where = self.query.where_class()
1527         if self.query.related_updates or must_pre_select:
1528             # Either we're using the idents in multiple update queries (so
1529             # don't want them to change), or the db backend doesn't support
1530             # selecting from the updating table (e.g. MySQL).
1531             idents = []
1532             for rows in query.get_compiler(self.using).execute_sql(MULTI):
1533                 idents.extend(r[0] for r in rows)
1534             self.query.add_filter(('pk__in', idents))
1535             self.query.related_ids = idents
1536         else:
1537             # The fast path. Filters and updates in one query.
1538             self.query.add_filter(('pk__in', query))
1539         self.query.reset_refcounts(refcounts_before)
1540 
1541 
1542 class SQLAggregateCompiler(SQLCompiler):
1543     def as_sql(self):
1544         """
1545         Create the SQL for this query. Return the SQL string and list of
1546         parameters.
1547         """
1548         sql, params = [], []
1549         for annotation in self.query.annotation_select.values():
1550             ann_sql, ann_params = self.compile(annotation)
1551             ann_sql, ann_params = annotation.select_format(self, ann_sql, ann_params)
1552             sql.append(ann_sql)
1553             params.extend(ann_params)
1554         self.col_count = len(self.query.annotation_select)
1555         sql = ', '.join(sql)
1556         params = tuple(params)
1557 
1558         sql = 'SELECT %s FROM (%s) subquery' % (sql, self.query.subquery)
1559         params = params + self.query.sub_params
1560         return sql, params
1561 
1562 
1563 def cursor_iter(cursor, sentinel, col_count, itersize):
1564     """
1565     Yield blocks of rows from a cursor and ensure the cursor is closed when
1566     done.
1567     """
1568     try:
1569         for rows in iter((lambda: cursor.fetchmany(itersize)), sentinel):
1570             yield rows if col_count is None else [r[:col_count] for r in rows]
1571     finally:
1572         cursor.close()

</code><intended_behavior>The code here should properly distinguish contexts where window functions are used, especially in 'SELECT' clauses. The fix should ensure that window expressions within annotations are compiled into SQL without incorrectly raising a 'NotSupportedError'. This adjustment must keep the validation against the use of window functions in prohibited clauses (like 'WHERE'), while allowing them in 'SELECT' clauses as per SQL standards.</intended_behavior>, <file>django/db/models/expressions.py</file>
<class>Window</class>
<method>None</method>
<code>
1156 class Window(Expression):
1157     template = '%(expression)s OVER (%(window)s)'
1158     # Although the main expression may either be an aggregate or an
1159     # expression with an aggregate function, the GROUP BY that will
1160     # be introduced in the query as a result is not desired.
1161     contains_aggregate = False
1162     contains_over_clause = True
1163     filterable = False
1164 
1165     def __init__(self, expression, partition_by=None, order_by=None, frame=None, output_field=None):
1166         self.partition_by = partition_by
1167         self.order_by = order_by
1168         self.frame = frame
1169 
1170         if not getattr(expression, 'window_compatible', False):
1171             raise ValueError(
1172                 "Expression '%s' isn't compatible with OVER clauses." %
1173                 expression.__class__.__name__
1174             )
1175 
1176         if self.partition_by is not None:
1177             if not isinstance(self.partition_by, (tuple, list)):
1178                 self.partition_by = (self.partition_by,)
1179             self.partition_by = ExpressionList(*self.partition_by)
1180 
1181         if self.order_by is not None:
1182             if isinstance(self.order_by, (list, tuple)):
1183                 self.order_by = ExpressionList(*self.order_by)
1184             elif not isinstance(self.order_by, BaseExpression):
1185                 raise ValueError(
1186                     'order_by must be either an Expression or a sequence of '
1187                     'expressions.'
1188                 )
1189         super().__init__(output_field=output_field)
1190         self.source_expression = self._parse_expressions(expression)[0]
1191 
1192     def _resolve_output_field(self):
1193         return self.source_expression.output_field
1194 
1195     def get_source_expressions(self):
1196         return [self.source_expression, self.partition_by, self.order_by, self.frame]
1197 
1198     def set_source_expressions(self, exprs):
1199         self.source_expression, self.partition_by, self.order_by, self.frame = exprs
1200 
1201     def as_sql(self, compiler, connection, template=None):
1202         connection.ops.check_expression_support(self)
1203         if not connection.features.supports_over_clause:
1204             raise NotSupportedError('This backend does not support window expressions.')
1205         expr_sql, params = compiler.compile(self.source_expression)
1206         window_sql, window_params = [], []
1207 
1208         if self.partition_by is not None:
1209             sql_expr, sql_params = self.partition_by.as_sql(
1210                 compiler=compiler, connection=connection,
1211                 template='PARTITION BY %(expressions)s',
1212             )
1213             window_sql.extend(sql_expr)
1214             window_params.extend(sql_params)
1215 
1216         if self.order_by is not None:
1217             window_sql.append(' ORDER BY ')
1218             order_sql, order_params = compiler.compile(self.order_by)
1219             window_sql.extend(order_sql)
1220             window_params.extend(order_params)
1221 
1222         if self.frame:
1223             frame_sql, frame_params = compiler.compile(self.frame)
1224             window_sql.append(' ' + frame_sql)
1225             window_params.extend(frame_params)
1226 
1227         params.extend(window_params)
1228         template = template or self.template
1229 
1230         return template % {
1231             'expression': expr_sql,
1232             'window': ''.join(window_sql).strip()
1233         }, params
1234 
1235     def __str__(self):
1236         return '{} OVER ({}{}{})'.format(
1237             str(self.source_expression),
1238             'PARTITION BY ' + str(self.partition_by) if self.partition_by else '',
1239             'ORDER BY ' + str(self.order_by) if self.order_by else '',
1240             str(self.frame or ''),
1241         )
1242 
1243     def __repr__(self):
1244         return '<%s: %s>' % (self.__class__.__name__, self)
1245 
1246     def get_group_by_cols(self, alias=None):
1247         return []

</code><intended_behavior>Ensure that when a 'Window' expression is used within an 'annotate' call, it is flagged in a way that prevents 'NotSupportedError' from being incorrectly raised. This may involve adding additional checks or flags to indicate that the window expression is used in a supported context (i.e., within the 'SELECT' clause) and should not be treated as an error.</intended_behavior>]
2025-10-15 04:22:46.529 | INFO     | Overall retry 0 succeeded; ending workflow
2025-10-15 04:22:46.529 | INFO     | Search-only: skipping patch selection
2025-10-15 04:22:46.655 | INFO     | Task django__django-12185 completed successfully.
2025-10-15 04:22:46.656 | INFO     | No patch generated. You can try running ACR again.
