diff --git a/sklearn/ensemble/gradient_boosting.py b/sklearn/ensemble/gradient_boosting.py
--- a/sklearn/ensemble/gradient_boosting.py
+++ b/sklearn/ensemble/gradient_boosting.py
@@ -1476,20 +1476,25 @@ def fit(self, X, y, sample_weight=None, monitor=None):
                 raw_predictions = np.zeros(shape=(X.shape[0], self.loss_.K),
                                            dtype=np.float64)
             else:
-                try:
-                    self.init_.fit(X, y, sample_weight=sample_weight)
-                except TypeError:
-                    if sample_weight_is_none:
-                        self.init_.fit(X, y)
-                    else:
-                        raise ValueError(
-                            "The initial estimator {} does not support sample "
-                            "weights.".format(self.init_.__class__.__name__))
+                # XXX clean this once we have a support_sample_weight tag
+                if sample_weight_is_none:
+                    self.init_.fit(X, y)
+                else:
+                    msg = ("The initial estimator {} does not support sample "
+                           "weights.".format(self.init_.__class__.__name__))
+                    try:
+                        self.init_.fit(X, y, sample_weight=sample_weight)
+                    except TypeError:  # regular estimator without SW support
+                        raise ValueError(msg)
+                    except ValueError as e:
+                        if 'not enough values to unpack' in str(e):  # pipeline
+                            raise ValueError(msg) from e
+                        else:  # regular estimator whose input checking failed
+                            raise
 
                 raw_predictions = \
                     self.loss_.get_init_raw_predictions(X, self.init_)
 
-
             begin_at_stage = 0
 
             # The rng state must be preserved if warm_start is True
