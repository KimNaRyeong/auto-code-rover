[
    {
        "rel_file_path": "django/db/models/base.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.2/django/db/models/base.py",
        "start": 1,
        "end": 2083,
        "class_name": null,
        "method_name": null,
        "code": "1 import copy\n2 import inspect\n3 import warnings\n4 from functools import partialmethod\n5 from itertools import chain\n6 \n7 import django\n8 from django.apps import apps\n9 from django.conf import settings\n10 from django.core import checks\n11 from django.core.exceptions import (\n12     NON_FIELD_ERRORS, FieldDoesNotExist, FieldError, MultipleObjectsReturned,\n13     ObjectDoesNotExist, ValidationError,\n14 )\n15 from django.db import (\n16     DEFAULT_DB_ALIAS, DJANGO_VERSION_PICKLE_KEY, DatabaseError, connection,\n17     connections, router, transaction,\n18 )\n19 from django.db.models import (\n20     NOT_PROVIDED, ExpressionWrapper, IntegerField, Max, Value,\n21 )\n22 from django.db.models.constants import LOOKUP_SEP\n23 from django.db.models.constraints import CheckConstraint, UniqueConstraint\n24 from django.db.models.deletion import CASCADE, Collector\n25 from django.db.models.fields.related import (\n26     ForeignObjectRel, OneToOneField, lazy_related_operation, resolve_relation,\n27 )\n28 from django.db.models.functions import Coalesce\n29 from django.db.models.manager import Manager\n30 from django.db.models.options import Options\n31 from django.db.models.query import F, Q\n32 from django.db.models.signals import (\n33     class_prepared, post_init, post_save, pre_init, pre_save,\n34 )\n35 from django.db.models.utils import make_model_tuple\n36 from django.utils.encoding import force_str\n37 from django.utils.hashable import make_hashable\n38 from django.utils.text import capfirst, get_text_list\n39 from django.utils.translation import gettext_lazy as _\n40 \n41 \n42 class Deferred:\n43     def __repr__(self):\n44         return '<Deferred field>'\n45 \n46     def __str__(self):\n47         return '<Deferred field>'\n48 \n49 \n50 DEFERRED = Deferred()\n51 \n52 \n53 def subclass_exception(name, bases, module, attached_to):\n54     \"\"\"\n55     Create exception subclass. Used by ModelBase below.\n56 \n57     The exception is created in a way that allows it to be pickled, assuming\n58     that the returned exception class will be added as an attribute to the\n59     'attached_to' class.\n60     \"\"\"\n61     return type(name, bases, {\n62         '__module__': module,\n63         '__qualname__': '%s.%s' % (attached_to.__qualname__, name),\n64     })\n65 \n66 \n67 def _has_contribute_to_class(value):\n68     # Only call contribute_to_class() if it's bound.\n69     return not inspect.isclass(value) and hasattr(value, 'contribute_to_class')\n70 \n71 \n72 class ModelBase(type):\n73     \"\"\"Metaclass for all models.\"\"\"\n74     def __new__(cls, name, bases, attrs, **kwargs):\n75         super_new = super().__new__\n76 \n77         # Also ensure initialization is only performed for subclasses of Model\n78         # (excluding Model class itself).\n79         parents = [b for b in bases if isinstance(b, ModelBase)]\n80         if not parents:\n81             return super_new(cls, name, bases, attrs)\n82 \n83         # Create the class.\n84         module = attrs.pop('__module__')\n85         new_attrs = {'__module__': module}\n86         classcell = attrs.pop('__classcell__', None)\n87         if classcell is not None:\n88             new_attrs['__classcell__'] = classcell\n89         attr_meta = attrs.pop('Meta', None)\n90         # Pass all attrs without a (Django-specific) contribute_to_class()\n91         # method to type.__new__() so that they're properly initialized\n92         # (i.e. __set_name__()).\n93         contributable_attrs = {}\n94         for obj_name, obj in attrs.items():\n95             if _has_contribute_to_class(obj):\n96                 contributable_attrs[obj_name] = obj\n97             else:\n98                 new_attrs[obj_name] = obj\n99         new_class = super_new(cls, name, bases, new_attrs, **kwargs)\n100 \n101         abstract = getattr(attr_meta, 'abstract', False)\n102         meta = attr_meta or getattr(new_class, 'Meta', None)\n103         base_meta = getattr(new_class, '_meta', None)\n104 \n105         app_label = None\n106 \n107         # Look for an application configuration to attach the model to.\n108         app_config = apps.get_containing_app_config(module)\n109 \n110         if getattr(meta, 'app_label', None) is None:\n111             if app_config is None:\n112                 if not abstract:\n113                     raise RuntimeError(\n114                         \"Model class %s.%s doesn't declare an explicit \"\n115                         \"app_label and isn't in an application in \"\n116                         \"INSTALLED_APPS.\" % (module, name)\n117                     )\n118 \n119             else:\n120                 app_label = app_config.label\n121 \n122         new_class.add_to_class('_meta', Options(meta, app_label))\n123         if not abstract:\n124             new_class.add_to_class(\n125                 'DoesNotExist',\n126                 subclass_exception(\n127                     'DoesNotExist',\n128                     tuple(\n129                         x.DoesNotExist for x in parents if hasattr(x, '_meta') and not x._meta.abstract\n130                     ) or (ObjectDoesNotExist,),\n131                     module,\n132                     attached_to=new_class))\n133             new_class.add_to_class(\n134                 'MultipleObjectsReturned',\n135                 subclass_exception(\n136                     'MultipleObjectsReturned',\n137                     tuple(\n138                         x.MultipleObjectsReturned for x in parents if hasattr(x, '_meta') and not x._meta.abstract\n139                     ) or (MultipleObjectsReturned,),\n140                     module,\n141                     attached_to=new_class))\n142             if base_meta and not base_meta.abstract:\n143                 # Non-abstract child classes inherit some attributes from their\n144                 # non-abstract parent (unless an ABC comes before it in the\n145                 # method resolution order).\n146                 if not hasattr(meta, 'ordering'):\n147                     new_class._meta.ordering = base_meta.ordering\n148                 if not hasattr(meta, 'get_latest_by'):\n149                     new_class._meta.get_latest_by = base_meta.get_latest_by\n150 \n151         is_proxy = new_class._meta.proxy\n152 \n153         # If the model is a proxy, ensure that the base class\n154         # hasn't been swapped out.\n155         if is_proxy and base_meta and base_meta.swapped:\n156             raise TypeError(\"%s cannot proxy the swapped model '%s'.\" % (name, base_meta.swapped))\n157 \n158         # Add remaining attributes (those with a contribute_to_class() method)\n159         # to the class.\n160         for obj_name, obj in contributable_attrs.items():\n161             new_class.add_to_class(obj_name, obj)\n162 \n163         # All the fields of any type declared on this model\n164         new_fields = chain(\n165             new_class._meta.local_fields,\n166             new_class._meta.local_many_to_many,\n167             new_class._meta.private_fields\n168         )\n169         field_names = {f.name for f in new_fields}\n170 \n171         # Basic setup for proxy models.\n172         if is_proxy:\n173             base = None\n174             for parent in [kls for kls in parents if hasattr(kls, '_meta')]:\n175                 if parent._meta.abstract:\n176                     if parent._meta.fields:\n177                         raise TypeError(\n178                             \"Abstract base class containing model fields not \"\n179                             \"permitted for proxy model '%s'.\" % name\n180                         )\n181                     else:\n182                         continue\n183                 if base is None:\n184                     base = parent\n185                 elif parent._meta.concrete_model is not base._meta.concrete_model:\n186                     raise TypeError(\"Proxy model '%s' has more than one non-abstract model base class.\" % name)\n187             if base is None:\n188                 raise TypeError(\"Proxy model '%s' has no non-abstract model base class.\" % name)\n189             new_class._meta.setup_proxy(base)\n190             new_class._meta.concrete_model = base._meta.concrete_model\n191         else:\n192             new_class._meta.concrete_model = new_class\n193 \n194         # Collect the parent links for multi-table inheritance.\n195         parent_links = {}\n196         for base in reversed([new_class] + parents):\n197             # Conceptually equivalent to `if base is Model`.\n198             if not hasattr(base, '_meta'):\n199                 continue\n200             # Skip concrete parent classes.\n201             if base != new_class and not base._meta.abstract:\n202                 continue\n203             # Locate OneToOneField instances.\n204             for field in base._meta.local_fields:\n205                 if isinstance(field, OneToOneField) and field.remote_field.parent_link:\n206                     related = resolve_relation(new_class, field.remote_field.model)\n207                     parent_links[make_model_tuple(related)] = field\n208 \n209         # Track fields inherited from base models.\n210         inherited_attributes = set()\n211         # Do the appropriate setup for any model parents.\n212         for base in new_class.mro():\n213             if base not in parents or not hasattr(base, '_meta'):\n214                 # Things without _meta aren't functional models, so they're\n215                 # uninteresting parents.\n216                 inherited_attributes.update(base.__dict__)\n217                 continue\n218 \n219             parent_fields = base._meta.local_fields + base._meta.local_many_to_many\n220             if not base._meta.abstract:\n221                 # Check for clashes between locally declared fields and those\n222                 # on the base classes.\n223                 for field in parent_fields:\n224                     if field.name in field_names:\n225                         raise FieldError(\n226                             'Local field %r in class %r clashes with field of '\n227                             'the same name from base class %r.' % (\n228                                 field.name,\n229                                 name,\n230                                 base.__name__,\n231                             )\n232                         )\n233                     else:\n234                         inherited_attributes.add(field.name)\n235 \n236                 # Concrete classes...\n237                 base = base._meta.concrete_model\n238                 base_key = make_model_tuple(base)\n239                 if base_key in parent_links:\n240                     field = parent_links[base_key]\n241                 elif not is_proxy:\n242                     attr_name = '%s_ptr' % base._meta.model_name\n243                     field = OneToOneField(\n244                         base,\n245                         on_delete=CASCADE,\n246                         name=attr_name,\n247                         auto_created=True,\n248                         parent_link=True,\n249                     )\n250 \n251                     if attr_name in field_names:\n252                         raise FieldError(\n253                             \"Auto-generated field '%s' in class %r for \"\n254                             \"parent_link to base class %r clashes with \"\n255                             \"declared field of the same name.\" % (\n256                                 attr_name,\n257                                 name,\n258                                 base.__name__,\n259                             )\n260                         )\n261 \n262                     # Only add the ptr field if it's not already present;\n263                     # e.g. migrations will already have it specified\n264                     if not hasattr(new_class, attr_name):\n265                         new_class.add_to_class(attr_name, field)\n266                 else:\n267                     field = None\n268                 new_class._meta.parents[base] = field\n269             else:\n270                 base_parents = base._meta.parents.copy()\n271 \n272                 # Add fields from abstract base class if it wasn't overridden.\n273                 for field in parent_fields:\n274                     if (field.name not in field_names and\n275                             field.name not in new_class.__dict__ and\n276                             field.name not in inherited_attributes):\n277                         new_field = copy.deepcopy(field)\n278                         new_class.add_to_class(field.name, new_field)\n279                         # Replace parent links defined on this base by the new\n280                         # field. It will be appropriately resolved if required.\n281                         if field.one_to_one:\n282                             for parent, parent_link in base_parents.items():\n283                                 if field == parent_link:\n284                                     base_parents[parent] = new_field\n285 \n286                 # Pass any non-abstract parent classes onto child.\n287                 new_class._meta.parents.update(base_parents)\n288 \n289             # Inherit private fields (like GenericForeignKey) from the parent\n290             # class\n291             for field in base._meta.private_fields:\n292                 if field.name in field_names:\n293                     if not base._meta.abstract:\n294                         raise FieldError(\n295                             'Local field %r in class %r clashes with field of '\n296                             'the same name from base class %r.' % (\n297                                 field.name,\n298                                 name,\n299                                 base.__name__,\n300                             )\n301                         )\n302                 else:\n303                     field = copy.deepcopy(field)\n304                     if not base._meta.abstract:\n305                         field.mti_inherited = True\n306                     new_class.add_to_class(field.name, field)\n307 \n308         # Copy indexes so that index names are unique when models extend an\n309         # abstract model.\n310         new_class._meta.indexes = [copy.deepcopy(idx) for idx in new_class._meta.indexes]\n311 \n312         if abstract:\n313             # Abstract base models can't be instantiated and don't appear in\n314             # the list of models for an app. We do the final setup for them a\n315             # little differently from normal models.\n316             attr_meta.abstract = False\n317             new_class.Meta = attr_meta\n318             return new_class\n319 \n320         new_class._prepare()\n321         new_class._meta.apps.register_model(new_class._meta.app_label, new_class)\n322         return new_class\n323 \n324     def add_to_class(cls, name, value):\n325         if _has_contribute_to_class(value):\n326             value.contribute_to_class(cls, name)\n327         else:\n328             setattr(cls, name, value)\n329 \n330     def _prepare(cls):\n331         \"\"\"Create some methods once self._meta has been populated.\"\"\"\n332         opts = cls._meta\n333         opts._prepare(cls)\n334 \n335         if opts.order_with_respect_to:\n336             cls.get_next_in_order = partialmethod(cls._get_next_or_previous_in_order, is_next=True)\n337             cls.get_previous_in_order = partialmethod(cls._get_next_or_previous_in_order, is_next=False)\n338 \n339             # Defer creating accessors on the foreign class until it has been\n340             # created and registered. If remote_field is None, we're ordering\n341             # with respect to a GenericForeignKey and don't know what the\n342             # foreign class is - we'll add those accessors later in\n343             # contribute_to_class().\n344             if opts.order_with_respect_to.remote_field:\n345                 wrt = opts.order_with_respect_to\n346                 remote = wrt.remote_field.model\n347                 lazy_related_operation(make_foreign_order_accessors, cls, remote)\n348 \n349         # Give the class a docstring -- its definition.\n350         if cls.__doc__ is None:\n351             cls.__doc__ = \"%s(%s)\" % (cls.__name__, \", \".join(f.name for f in opts.fields))\n352 \n353         get_absolute_url_override = settings.ABSOLUTE_URL_OVERRIDES.get(opts.label_lower)\n354         if get_absolute_url_override:\n355             setattr(cls, 'get_absolute_url', get_absolute_url_override)\n356 \n357         if not opts.managers:\n358             if any(f.name == 'objects' for f in opts.fields):\n359                 raise ValueError(\n360                     \"Model %s must specify a custom Manager, because it has a \"\n361                     \"field named 'objects'.\" % cls.__name__\n362                 )\n363             manager = Manager()\n364             manager.auto_created = True\n365             cls.add_to_class('objects', manager)\n366 \n367         # Set the name of _meta.indexes. This can't be done in\n368         # Options.contribute_to_class() because fields haven't been added to\n369         # the model at that point.\n370         for index in cls._meta.indexes:\n371             if not index.name:\n372                 index.set_name_with_model(cls)\n373 \n374         class_prepared.send(sender=cls)\n375 \n376     @property\n377     def _base_manager(cls):\n378         return cls._meta.base_manager\n379 \n380     @property\n381     def _default_manager(cls):\n382         return cls._meta.default_manager\n383 \n384 \n385 class ModelStateFieldsCacheDescriptor:\n386     def __get__(self, instance, cls=None):\n387         if instance is None:\n388             return self\n389         res = instance.fields_cache = {}\n390         return res\n391 \n392 \n393 class ModelState:\n394     \"\"\"Store model instance state.\"\"\"\n395     db = None\n396     # If true, uniqueness validation checks will consider this a new, unsaved\n397     # object. Necessary for correct validation of new instances of objects with\n398     # explicit (non-auto) PKs. This impacts validation only; it has no effect\n399     # on the actual save.\n400     adding = True\n401     fields_cache = ModelStateFieldsCacheDescriptor()\n402 \n403 \n404 class Model(metaclass=ModelBase):\n405 \n406     def __init__(self, *args, **kwargs):\n407         # Alias some things as locals to avoid repeat global lookups\n408         cls = self.__class__\n409         opts = self._meta\n410         _setattr = setattr\n411         _DEFERRED = DEFERRED\n412         if opts.abstract:\n413             raise TypeError('Abstract models cannot be instantiated.')\n414 \n415         pre_init.send(sender=cls, args=args, kwargs=kwargs)\n416 \n417         # Set up the storage for instance state\n418         self._state = ModelState()\n419 \n420         # There is a rather weird disparity here; if kwargs, it's set, then args\n421         # overrides it. It should be one or the other; don't duplicate the work\n422         # The reason for the kwargs check is that standard iterator passes in by\n423         # args, and instantiation for iteration is 33% faster.\n424         if len(args) > len(opts.concrete_fields):\n425             # Daft, but matches old exception sans the err msg.\n426             raise IndexError(\"Number of args exceeds number of fields\")\n427 \n428         if not kwargs:\n429             fields_iter = iter(opts.concrete_fields)\n430             # The ordering of the zip calls matter - zip throws StopIteration\n431             # when an iter throws it. So if the first iter throws it, the second\n432             # is *not* consumed. We rely on this, so don't change the order\n433             # without changing the logic.\n434             for val, field in zip(args, fields_iter):\n435                 if val is _DEFERRED:\n436                     continue\n437                 _setattr(self, field.attname, val)\n438         else:\n439             # Slower, kwargs-ready version.\n440             fields_iter = iter(opts.fields)\n441             for val, field in zip(args, fields_iter):\n442                 if val is _DEFERRED:\n443                     continue\n444                 _setattr(self, field.attname, val)\n445                 kwargs.pop(field.name, None)\n446 \n447         # Now we're left with the unprocessed fields that *must* come from\n448         # keywords, or default.\n449 \n450         for field in fields_iter:\n451             is_related_object = False\n452             # Virtual field\n453             if field.attname not in kwargs and field.column is None:\n454                 continue\n455             if kwargs:\n456                 if isinstance(field.remote_field, ForeignObjectRel):\n457                     try:\n458                         # Assume object instance was passed in.\n459                         rel_obj = kwargs.pop(field.name)\n460                         is_related_object = True\n461                     except KeyError:\n462                         try:\n463                             # Object instance wasn't passed in -- must be an ID.\n464                             val = kwargs.pop(field.attname)\n465                         except KeyError:\n466                             val = field.get_default()\n467                 else:\n468                     try:\n469                         val = kwargs.pop(field.attname)\n470                     except KeyError:\n471                         # This is done with an exception rather than the\n472                         # default argument on pop because we don't want\n473                         # get_default() to be evaluated, and then not used.\n474                         # Refs #12057.\n475                         val = field.get_default()\n476             else:\n477                 val = field.get_default()\n478 \n479             if is_related_object:\n480                 # If we are passed a related instance, set it using the\n481                 # field.name instead of field.attname (e.g. \"user\" instead of\n482                 # \"user_id\") so that the object gets properly cached (and type\n483                 # checked) by the RelatedObjectDescriptor.\n484                 if rel_obj is not _DEFERRED:\n485                     _setattr(self, field.name, rel_obj)\n486             else:\n487                 if val is not _DEFERRED:\n488                     _setattr(self, field.attname, val)\n489 \n490         if kwargs:\n491             property_names = opts._property_names\n492             for prop in tuple(kwargs):\n493                 try:\n494                     # Any remaining kwargs must correspond to properties or\n495                     # virtual fields.\n496                     if prop in property_names or opts.get_field(prop):\n497                         if kwargs[prop] is not _DEFERRED:\n498                             _setattr(self, prop, kwargs[prop])\n499                         del kwargs[prop]\n500                 except (AttributeError, FieldDoesNotExist):\n501                     pass\n502             for kwarg in kwargs:\n503                 raise TypeError(\"%s() got an unexpected keyword argument '%s'\" % (cls.__name__, kwarg))\n504         super().__init__()\n505         post_init.send(sender=cls, instance=self)\n506 \n507     @classmethod\n508     def from_db(cls, db, field_names, values):\n509         if len(values) != len(cls._meta.concrete_fields):\n510             values_iter = iter(values)\n511             values = [\n512                 next(values_iter) if f.attname in field_names else DEFERRED\n513                 for f in cls._meta.concrete_fields\n514             ]\n515         new = cls(*values)\n516         new._state.adding = False\n517         new._state.db = db\n518         return new\n519 \n520     def __repr__(self):\n521         return '<%s: %s>' % (self.__class__.__name__, self)\n522 \n523     def __str__(self):\n524         return '%s object (%s)' % (self.__class__.__name__, self.pk)\n525 \n526     def __eq__(self, other):\n527         if not isinstance(other, Model):\n528             return NotImplemented\n529         if self._meta.concrete_model != other._meta.concrete_model:\n530             return False\n531         my_pk = self.pk\n532         if my_pk is None:\n533             return self is other\n534         return my_pk == other.pk\n535 \n536     def __hash__(self):\n537         if self.pk is None:\n538             raise TypeError(\"Model instances without primary key value are unhashable\")\n539         return hash(self.pk)\n540 \n541     def __reduce__(self):\n542         data = self.__getstate__()\n543         data[DJANGO_VERSION_PICKLE_KEY] = django.__version__\n544         class_id = self._meta.app_label, self._meta.object_name\n545         return model_unpickle, (class_id,), data\n546 \n547     def __getstate__(self):\n548         \"\"\"Hook to allow choosing the attributes to pickle.\"\"\"\n549         return self.__dict__\n550 \n551     def __setstate__(self, state):\n552         pickled_version = state.get(DJANGO_VERSION_PICKLE_KEY)\n553         if pickled_version:\n554             if pickled_version != django.__version__:\n555                 warnings.warn(\n556                     \"Pickled model instance's Django version %s does not \"\n557                     \"match the current version %s.\"\n558                     % (pickled_version, django.__version__),\n559                     RuntimeWarning,\n560                     stacklevel=2,\n561                 )\n562         else:\n563             warnings.warn(\n564                 \"Pickled model instance's Django version is not specified.\",\n565                 RuntimeWarning,\n566                 stacklevel=2,\n567             )\n568         self.__dict__.update(state)\n569 \n570     def _get_pk_val(self, meta=None):\n571         meta = meta or self._meta\n572         return getattr(self, meta.pk.attname)\n573 \n574     def _set_pk_val(self, value):\n575         for parent_link in self._meta.parents.values():\n576             if parent_link and parent_link != self._meta.pk:\n577                 setattr(self, parent_link.target_field.attname, value)\n578         return setattr(self, self._meta.pk.attname, value)\n579 \n580     pk = property(_get_pk_val, _set_pk_val)\n581 \n582     def get_deferred_fields(self):\n583         \"\"\"\n584         Return a set containing names of deferred fields for this instance.\n585         \"\"\"\n586         return {\n587             f.attname for f in self._meta.concrete_fields\n588             if f.attname not in self.__dict__\n589         }\n590 \n591     def refresh_from_db(self, using=None, fields=None):\n592         \"\"\"\n593         Reload field values from the database.\n594 \n595         By default, the reloading happens from the database this instance was\n596         loaded from, or by the read router if this instance wasn't loaded from\n597         any database. The using parameter will override the default.\n598 \n599         Fields can be used to specify which fields to reload. The fields\n600         should be an iterable of field attnames. If fields is None, then\n601         all non-deferred fields are reloaded.\n602 \n603         When accessing deferred fields of an instance, the deferred loading\n604         of the field will call this method.\n605         \"\"\"\n606         if fields is None:\n607             self._prefetched_objects_cache = {}\n608         else:\n609             prefetched_objects_cache = getattr(self, '_prefetched_objects_cache', ())\n610             for field in fields:\n611                 if field in prefetched_objects_cache:\n612                     del prefetched_objects_cache[field]\n613                     fields.remove(field)\n614             if not fields:\n615                 return\n616             if any(LOOKUP_SEP in f for f in fields):\n617                 raise ValueError(\n618                     'Found \"%s\" in fields argument. Relations and transforms '\n619                     'are not allowed in fields.' % LOOKUP_SEP)\n620 \n621         hints = {'instance': self}\n622         db_instance_qs = self.__class__._base_manager.db_manager(using, hints=hints).filter(pk=self.pk)\n623 \n624         # Use provided fields, if not set then reload all non-deferred fields.\n625         deferred_fields = self.get_deferred_fields()\n626         if fields is not None:\n627             fields = list(fields)\n628             db_instance_qs = db_instance_qs.only(*fields)\n629         elif deferred_fields:\n630             fields = [f.attname for f in self._meta.concrete_fields\n631                       if f.attname not in deferred_fields]\n632             db_instance_qs = db_instance_qs.only(*fields)\n633 \n634         db_instance = db_instance_qs.get()\n635         non_loaded_fields = db_instance.get_deferred_fields()\n636         for field in self._meta.concrete_fields:\n637             if field.attname in non_loaded_fields:\n638                 # This field wasn't refreshed - skip ahead.\n639                 continue\n640             setattr(self, field.attname, getattr(db_instance, field.attname))\n641             # Clear cached foreign keys.\n642             if field.is_relation and field.is_cached(self):\n643                 field.delete_cached_value(self)\n644 \n645         # Clear cached relations.\n646         for field in self._meta.related_objects:\n647             if field.is_cached(self):\n648                 field.delete_cached_value(self)\n649 \n650         self._state.db = db_instance._state.db\n651 \n652     def serializable_value(self, field_name):\n653         \"\"\"\n654         Return the value of the field name for this instance. If the field is\n655         a foreign key, return the id value instead of the object. If there's\n656         no Field object with this name on the model, return the model\n657         attribute's value.\n658 \n659         Used to serialize a field's value (in the serializer, or form output,\n660         for example). Normally, you would just access the attribute directly\n661         and not use this method.\n662         \"\"\"\n663         try:\n664             field = self._meta.get_field(field_name)\n665         except FieldDoesNotExist:\n666             return getattr(self, field_name)\n667         return getattr(self, field.attname)\n668 \n669     def save(self, force_insert=False, force_update=False, using=None,\n670              update_fields=None):\n671         \"\"\"\n672         Save the current instance. Override this in a subclass if you want to\n673         control the saving process.\n674 \n675         The 'force_insert' and 'force_update' parameters can be used to insist\n676         that the \"save\" must be an SQL insert or update (or equivalent for\n677         non-SQL backends), respectively. Normally, they should not be set.\n678         \"\"\"\n679         # Ensure that a model instance without a PK hasn't been assigned to\n680         # a ForeignKey or OneToOneField on this model. If the field is\n681         # nullable, allowing the save() would result in silent data loss.\n682         for field in self._meta.concrete_fields:\n683             # If the related field isn't cached, then an instance hasn't\n684             # been assigned and there's no need to worry about this check.\n685             if field.is_relation and field.is_cached(self):\n686                 obj = getattr(self, field.name, None)\n687                 if not obj:\n688                     continue\n689                 # A pk may have been assigned manually to a model instance not\n690                 # saved to the database (or auto-generated in a case like\n691                 # UUIDField), but we allow the save to proceed and rely on the\n692                 # database to raise an IntegrityError if applicable. If\n693                 # constraints aren't supported by the database, there's the\n694                 # unavoidable risk of data corruption.\n695                 if obj.pk is None:\n696                     # Remove the object from a related instance cache.\n697                     if not field.remote_field.multiple:\n698                         field.remote_field.delete_cached_value(obj)\n699                     raise ValueError(\n700                         \"save() prohibited to prevent data loss due to \"\n701                         \"unsaved related object '%s'.\" % field.name\n702                     )\n703                 elif getattr(self, field.attname) is None:\n704                     # Use pk from related object if it has been saved after\n705                     # an assignment.\n706                     setattr(self, field.attname, obj.pk)\n707                 # If the relationship's pk/to_field was changed, clear the\n708                 # cached relationship.\n709                 if getattr(obj, field.target_field.attname) != getattr(self, field.attname):\n710                     field.delete_cached_value(self)\n711 \n712         using = using or router.db_for_write(self.__class__, instance=self)\n713         if force_insert and (force_update or update_fields):\n714             raise ValueError(\"Cannot force both insert and updating in model saving.\")\n715 \n716         deferred_fields = self.get_deferred_fields()\n717         if update_fields is not None:\n718             # If update_fields is empty, skip the save. We do also check for\n719             # no-op saves later on for inheritance cases. This bailout is\n720             # still needed for skipping signal sending.\n721             if not update_fields:\n722                 return\n723 \n724             update_fields = frozenset(update_fields)\n725             field_names = set()\n726 \n727             for field in self._meta.fields:\n728                 if not field.primary_key:\n729                     field_names.add(field.name)\n730 \n731                     if field.name != field.attname:\n732                         field_names.add(field.attname)\n733 \n734             non_model_fields = update_fields.difference(field_names)\n735 \n736             if non_model_fields:\n737                 raise ValueError(\"The following fields do not exist in this \"\n738                                  \"model or are m2m fields: %s\"\n739                                  % ', '.join(non_model_fields))\n740 \n741         # If saving to the same database, and this model is deferred, then\n742         # automatically do an \"update_fields\" save on the loaded fields.\n743         elif not force_insert and deferred_fields and using == self._state.db:\n744             field_names = set()\n745             for field in self._meta.concrete_fields:\n746                 if not field.primary_key and not hasattr(field, 'through'):\n747                     field_names.add(field.attname)\n748             loaded_fields = field_names.difference(deferred_fields)\n749             if loaded_fields:\n750                 update_fields = frozenset(loaded_fields)\n751 \n752         self.save_base(using=using, force_insert=force_insert,\n753                        force_update=force_update, update_fields=update_fields)\n754     save.alters_data = True\n755 \n756     def save_base(self, raw=False, force_insert=False,\n757                   force_update=False, using=None, update_fields=None):\n758         \"\"\"\n759         Handle the parts of saving which should be done only once per save,\n760         yet need to be done in raw saves, too. This includes some sanity\n761         checks and signal sending.\n762 \n763         The 'raw' argument is telling save_base not to save any parent\n764         models and not to do any changes to the values before save. This\n765         is used by fixture loading.\n766         \"\"\"\n767         using = using or router.db_for_write(self.__class__, instance=self)\n768         assert not (force_insert and (force_update or update_fields))\n769         assert update_fields is None or update_fields\n770         cls = origin = self.__class__\n771         # Skip proxies, but keep the origin as the proxy model.\n772         if cls._meta.proxy:\n773             cls = cls._meta.concrete_model\n774         meta = cls._meta\n775         if not meta.auto_created:\n776             pre_save.send(\n777                 sender=origin, instance=self, raw=raw, using=using,\n778                 update_fields=update_fields,\n779             )\n780         # A transaction isn't needed if one query is issued.\n781         if meta.parents:\n782             context_manager = transaction.atomic(using=using, savepoint=False)\n783         else:\n784             context_manager = transaction.mark_for_rollback_on_error(using=using)\n785         with context_manager:\n786             parent_inserted = False\n787             if not raw:\n788                 parent_inserted = self._save_parents(cls, using, update_fields)\n789             updated = self._save_table(\n790                 raw, cls, force_insert or parent_inserted,\n791                 force_update, using, update_fields,\n792             )\n793         # Store the database on which the object was saved\n794         self._state.db = using\n795         # Once saved, this is no longer a to-be-added instance.\n796         self._state.adding = False\n797 \n798         # Signal that the save is complete\n799         if not meta.auto_created:\n800             post_save.send(\n801                 sender=origin, instance=self, created=(not updated),\n802                 update_fields=update_fields, raw=raw, using=using,\n803             )\n804 \n805     save_base.alters_data = True\n806 \n807     def _save_parents(self, cls, using, update_fields):\n808         \"\"\"Save all the parents of cls using values from self.\"\"\"\n809         meta = cls._meta\n810         inserted = False\n811         for parent, field in meta.parents.items():\n812             # Make sure the link fields are synced between parent and self.\n813             if (field and getattr(self, parent._meta.pk.attname) is None and\n814                     getattr(self, field.attname) is not None):\n815                 setattr(self, parent._meta.pk.attname, getattr(self, field.attname))\n816             parent_inserted = self._save_parents(cls=parent, using=using, update_fields=update_fields)\n817             updated = self._save_table(\n818                 cls=parent, using=using, update_fields=update_fields,\n819                 force_insert=parent_inserted,\n820             )\n821             if not updated:\n822                 inserted = True\n823             # Set the parent's PK value to self.\n824             if field:\n825                 setattr(self, field.attname, self._get_pk_val(parent._meta))\n826                 # Since we didn't have an instance of the parent handy set\n827                 # attname directly, bypassing the descriptor. Invalidate\n828                 # the related object cache, in case it's been accidentally\n829                 # populated. A fresh instance will be re-built from the\n830                 # database if necessary.\n831                 if field.is_cached(self):\n832                     field.delete_cached_value(self)\n833         return inserted\n834 \n835     def _save_table(self, raw=False, cls=None, force_insert=False,\n836                     force_update=False, using=None, update_fields=None):\n837         \"\"\"\n838         Do the heavy-lifting involved in saving. Update or insert the data\n839         for a single table.\n840         \"\"\"\n841         meta = cls._meta\n842         non_pks = [f for f in meta.local_concrete_fields if not f.primary_key]\n843 \n844         if update_fields:\n845             non_pks = [f for f in non_pks\n846                        if f.name in update_fields or f.attname in update_fields]\n847 \n848         pk_val = self._get_pk_val(meta)\n849         if pk_val is None:\n850             pk_val = meta.pk.get_pk_value_on_save(self)\n851             setattr(self, meta.pk.attname, pk_val)\n852         pk_set = pk_val is not None\n853         if not pk_set and (force_update or update_fields):\n854             raise ValueError(\"Cannot force an update in save() with no primary key.\")\n855         updated = False\n856         # Skip an UPDATE when adding an instance and primary key has a default.\n857         if (\n858             not raw and\n859             not force_insert and\n860             self._state.adding and\n861             meta.pk.default and\n862             meta.pk.default is not NOT_PROVIDED\n863         ):\n864             force_insert = True\n865         # If possible, try an UPDATE. If that doesn't update anything, do an INSERT.\n866         if pk_set and not force_insert:\n867             base_qs = cls._base_manager.using(using)\n868             values = [(f, None, (getattr(self, f.attname) if raw else f.pre_save(self, False)))\n869                       for f in non_pks]\n870             forced_update = update_fields or force_update\n871             updated = self._do_update(base_qs, using, pk_val, values, update_fields,\n872                                       forced_update)\n873             if force_update and not updated:\n874                 raise DatabaseError(\"Forced update did not affect any rows.\")\n875             if update_fields and not updated:\n876                 raise DatabaseError(\"Save with update_fields did not affect any rows.\")\n877         if not updated:\n878             if meta.order_with_respect_to:\n879                 # If this is a model with an order_with_respect_to\n880                 # autopopulate the _order field\n881                 field = meta.order_with_respect_to\n882                 filter_args = field.get_filter_kwargs_for_object(self)\n883                 self._order = cls._base_manager.using(using).filter(**filter_args).aggregate(\n884                     _order__max=Coalesce(\n885                         ExpressionWrapper(Max('_order') + Value(1), output_field=IntegerField()),\n886                         Value(0),\n887                     ),\n888                 )['_order__max']\n889             fields = meta.local_concrete_fields\n890             if not pk_set:\n891                 fields = [f for f in fields if f is not meta.auto_field]\n892 \n893             returning_fields = meta.db_returning_fields\n894             results = self._do_insert(cls._base_manager, using, fields, returning_fields, raw)\n895             if results:\n896                 for value, field in zip(results[0], returning_fields):\n897                     setattr(self, field.attname, value)\n898         return updated\n899 \n900     def _do_update(self, base_qs, using, pk_val, values, update_fields, forced_update):\n901         \"\"\"\n902         Try to update the model. Return True if the model was updated (if an\n903         update query was done and a matching row was found in the DB).\n904         \"\"\"\n905         filtered = base_qs.filter(pk=pk_val)\n906         if not values:\n907             # We can end up here when saving a model in inheritance chain where\n908             # update_fields doesn't target any field in current model. In that\n909             # case we just say the update succeeded. Another case ending up here\n910             # is a model with just PK - in that case check that the PK still\n911             # exists.\n912             return update_fields is not None or filtered.exists()\n913         if self._meta.select_on_save and not forced_update:\n914             return (\n915                 filtered.exists() and\n916                 # It may happen that the object is deleted from the DB right after\n917                 # this check, causing the subsequent UPDATE to return zero matching\n918                 # rows. The same result can occur in some rare cases when the\n919                 # database returns zero despite the UPDATE being executed\n920                 # successfully (a row is matched and updated). In order to\n921                 # distinguish these two cases, the object's existence in the\n922                 # database is again checked for if the UPDATE query returns 0.\n923                 (filtered._update(values) > 0 or filtered.exists())\n924             )\n925         return filtered._update(values) > 0\n926 \n927     def _do_insert(self, manager, using, fields, returning_fields, raw):\n928         \"\"\"\n929         Do an INSERT. If returning_fields is defined then this method should\n930         return the newly created data for the model.\n931         \"\"\"\n932         return manager._insert(\n933             [self], fields=fields, returning_fields=returning_fields,\n934             using=using, raw=raw,\n935         )\n936 \n937     def delete(self, using=None, keep_parents=False):\n938         using = using or router.db_for_write(self.__class__, instance=self)\n939         assert self.pk is not None, (\n940             \"%s object can't be deleted because its %s attribute is set to None.\" %\n941             (self._meta.object_name, self._meta.pk.attname)\n942         )\n943 \n944         collector = Collector(using=using)\n945         collector.collect([self], keep_parents=keep_parents)\n946         return collector.delete()\n947 \n948     delete.alters_data = True\n949 \n950     def _get_FIELD_display(self, field):\n951         value = getattr(self, field.attname)\n952         choices_dict = dict(make_hashable(field.flatchoices))\n953         # force_str() to coerce lazy strings.\n954         return force_str(choices_dict.get(make_hashable(value), value), strings_only=True)\n955 \n956     def _get_next_or_previous_by_FIELD(self, field, is_next, **kwargs):\n957         if not self.pk:\n958             raise ValueError(\"get_next/get_previous cannot be used on unsaved objects.\")\n959         op = 'gt' if is_next else 'lt'\n960         order = '' if is_next else '-'\n961         param = getattr(self, field.attname)\n962         q = Q(**{'%s__%s' % (field.name, op): param})\n963         q = q | Q(**{field.name: param, 'pk__%s' % op: self.pk})\n964         qs = self.__class__._default_manager.using(self._state.db).filter(**kwargs).filter(q).order_by(\n965             '%s%s' % (order, field.name), '%spk' % order\n966         )\n967         try:\n968             return qs[0]\n969         except IndexError:\n970             raise self.DoesNotExist(\"%s matching query does not exist.\" % self.__class__._meta.object_name)\n971 \n972     def _get_next_or_previous_in_order(self, is_next):\n973         cachename = \"__%s_order_cache\" % is_next\n974         if not hasattr(self, cachename):\n975             op = 'gt' if is_next else 'lt'\n976             order = '_order' if is_next else '-_order'\n977             order_field = self._meta.order_with_respect_to\n978             filter_args = order_field.get_filter_kwargs_for_object(self)\n979             obj = self.__class__._default_manager.filter(**filter_args).filter(**{\n980                 '_order__%s' % op: self.__class__._default_manager.values('_order').filter(**{\n981                     self._meta.pk.name: self.pk\n982                 })\n983             }).order_by(order)[:1].get()\n984             setattr(self, cachename, obj)\n985         return getattr(self, cachename)\n986 \n987     def prepare_database_save(self, field):\n988         if self.pk is None:\n989             raise ValueError(\"Unsaved model instance %r cannot be used in an ORM query.\" % self)\n990         return getattr(self, field.remote_field.get_related_field().attname)\n991 \n992     def clean(self):\n993         \"\"\"\n994         Hook for doing any extra model-wide validation after clean() has been\n995         called on every field by self.clean_fields. Any ValidationError raised\n996         by this method will not be associated with a particular field; it will\n997         have a special-case association with the field defined by NON_FIELD_ERRORS.\n998         \"\"\"\n999         pass\n1000 \n1001     def validate_unique(self, exclude=None):\n1002         \"\"\"\n1003         Check unique constraints on the model and raise ValidationError if any\n1004         failed.\n1005         \"\"\"\n1006         unique_checks, date_checks = self._get_unique_checks(exclude=exclude)\n1007 \n1008         errors = self._perform_unique_checks(unique_checks)\n1009         date_errors = self._perform_date_checks(date_checks)\n1010 \n1011         for k, v in date_errors.items():\n1012             errors.setdefault(k, []).extend(v)\n1013 \n1014         if errors:\n1015             raise ValidationError(errors)\n1016 \n1017     def _get_unique_checks(self, exclude=None):\n1018         \"\"\"\n1019         Return a list of checks to perform. Since validate_unique() could be\n1020         called from a ModelForm, some fields may have been excluded; we can't\n1021         perform a unique check on a model that is missing fields involved\n1022         in that check. Fields that did not validate should also be excluded,\n1023         but they need to be passed in via the exclude argument.\n1024         \"\"\"\n1025         if exclude is None:\n1026             exclude = []\n1027         unique_checks = []\n1028 \n1029         unique_togethers = [(self.__class__, self._meta.unique_together)]\n1030         constraints = [(self.__class__, self._meta.total_unique_constraints)]\n1031         for parent_class in self._meta.get_parent_list():\n1032             if parent_class._meta.unique_together:\n1033                 unique_togethers.append((parent_class, parent_class._meta.unique_together))\n1034             if parent_class._meta.total_unique_constraints:\n1035                 constraints.append(\n1036                     (parent_class, parent_class._meta.total_unique_constraints)\n1037                 )\n1038 \n1039         for model_class, unique_together in unique_togethers:\n1040             for check in unique_together:\n1041                 if not any(name in exclude for name in check):\n1042                     # Add the check if the field isn't excluded.\n1043                     unique_checks.append((model_class, tuple(check)))\n1044 \n1045         for model_class, model_constraints in constraints:\n1046             for constraint in model_constraints:\n1047                 if not any(name in exclude for name in constraint.fields):\n1048                     unique_checks.append((model_class, constraint.fields))\n1049 \n1050         # These are checks for the unique_for_<date/year/month>.\n1051         date_checks = []\n1052 \n1053         # Gather a list of checks for fields declared as unique and add them to\n1054         # the list of checks.\n1055 \n1056         fields_with_class = [(self.__class__, self._meta.local_fields)]\n1057         for parent_class in self._meta.get_parent_list():\n1058             fields_with_class.append((parent_class, parent_class._meta.local_fields))\n1059 \n1060         for model_class, fields in fields_with_class:\n1061             for f in fields:\n1062                 name = f.name\n1063                 if name in exclude:\n1064                     continue\n1065                 if f.unique:\n1066                     unique_checks.append((model_class, (name,)))\n1067                 if f.unique_for_date and f.unique_for_date not in exclude:\n1068                     date_checks.append((model_class, 'date', name, f.unique_for_date))\n1069                 if f.unique_for_year and f.unique_for_year not in exclude:\n1070                     date_checks.append((model_class, 'year', name, f.unique_for_year))\n1071                 if f.unique_for_month and f.unique_for_month not in exclude:\n1072                     date_checks.append((model_class, 'month', name, f.unique_for_month))\n1073         return unique_checks, date_checks\n1074 \n1075     def _perform_unique_checks(self, unique_checks):\n1076         errors = {}\n1077 \n1078         for model_class, unique_check in unique_checks:\n1079             # Try to look up an existing object with the same values as this\n1080             # object's values for all the unique field.\n1081 \n1082             lookup_kwargs = {}\n1083             for field_name in unique_check:\n1084                 f = self._meta.get_field(field_name)\n1085                 lookup_value = getattr(self, f.attname)\n1086                 # TODO: Handle multiple backends with different feature flags.\n1087                 if (lookup_value is None or\n1088                         (lookup_value == '' and connection.features.interprets_empty_strings_as_nulls)):\n1089                     # no value, skip the lookup\n1090                     continue\n1091                 if f.primary_key and not self._state.adding:\n1092                     # no need to check for unique primary key when editing\n1093                     continue\n1094                 lookup_kwargs[str(field_name)] = lookup_value\n1095 \n1096             # some fields were skipped, no reason to do the check\n1097             if len(unique_check) != len(lookup_kwargs):\n1098                 continue\n1099 \n1100             qs = model_class._default_manager.filter(**lookup_kwargs)\n1101 \n1102             # Exclude the current object from the query if we are editing an\n1103             # instance (as opposed to creating a new one)\n1104             # Note that we need to use the pk as defined by model_class, not\n1105             # self.pk. These can be different fields because model inheritance\n1106             # allows single model to have effectively multiple primary keys.\n1107             # Refs #17615.\n1108             model_class_pk = self._get_pk_val(model_class._meta)\n1109             if not self._state.adding and model_class_pk is not None:\n1110                 qs = qs.exclude(pk=model_class_pk)\n1111             if qs.exists():\n1112                 if len(unique_check) == 1:\n1113                     key = unique_check[0]\n1114                 else:\n1115                     key = NON_FIELD_ERRORS\n1116                 errors.setdefault(key, []).append(self.unique_error_message(model_class, unique_check))\n1117 \n1118         return errors\n1119 \n1120     def _perform_date_checks(self, date_checks):\n1121         errors = {}\n1122         for model_class, lookup_type, field, unique_for in date_checks:\n1123             lookup_kwargs = {}\n1124             # there's a ticket to add a date lookup, we can remove this special\n1125             # case if that makes it's way in\n1126             date = getattr(self, unique_for)\n1127             if date is None:\n1128                 continue\n1129             if lookup_type == 'date':\n1130                 lookup_kwargs['%s__day' % unique_for] = date.day\n1131                 lookup_kwargs['%s__month' % unique_for] = date.month\n1132                 lookup_kwargs['%s__year' % unique_for] = date.year\n1133             else:\n1134                 lookup_kwargs['%s__%s' % (unique_for, lookup_type)] = getattr(date, lookup_type)\n1135             lookup_kwargs[field] = getattr(self, field)\n1136 \n1137             qs = model_class._default_manager.filter(**lookup_kwargs)\n1138             # Exclude the current object from the query if we are editing an\n1139             # instance (as opposed to creating a new one)\n1140             if not self._state.adding and self.pk is not None:\n1141                 qs = qs.exclude(pk=self.pk)\n1142 \n1143             if qs.exists():\n1144                 errors.setdefault(field, []).append(\n1145                     self.date_error_message(lookup_type, field, unique_for)\n1146                 )\n1147         return errors\n1148 \n1149     def date_error_message(self, lookup_type, field_name, unique_for):\n1150         opts = self._meta\n1151         field = opts.get_field(field_name)\n1152         return ValidationError(\n1153             message=field.error_messages['unique_for_date'],\n1154             code='unique_for_date',\n1155             params={\n1156                 'model': self,\n1157                 'model_name': capfirst(opts.verbose_name),\n1158                 'lookup_type': lookup_type,\n1159                 'field': field_name,\n1160                 'field_label': capfirst(field.verbose_name),\n1161                 'date_field': unique_for,\n1162                 'date_field_label': capfirst(opts.get_field(unique_for).verbose_name),\n1163             }\n1164         )\n1165 \n1166     def unique_error_message(self, model_class, unique_check):\n1167         opts = model_class._meta\n1168 \n1169         params = {\n1170             'model': self,\n1171             'model_class': model_class,\n1172             'model_name': capfirst(opts.verbose_name),\n1173             'unique_check': unique_check,\n1174         }\n1175 \n1176         # A unique field\n1177         if len(unique_check) == 1:\n1178             field = opts.get_field(unique_check[0])\n1179             params['field_label'] = capfirst(field.verbose_name)\n1180             return ValidationError(\n1181                 message=field.error_messages['unique'],\n1182                 code='unique',\n1183                 params=params,\n1184             )\n1185 \n1186         # unique_together\n1187         else:\n1188             field_labels = [capfirst(opts.get_field(f).verbose_name) for f in unique_check]\n1189             params['field_labels'] = get_text_list(field_labels, _('and'))\n1190             return ValidationError(\n1191                 message=_(\"%(model_name)s with this %(field_labels)s already exists.\"),\n1192                 code='unique_together',\n1193                 params=params,\n1194             )\n1195 \n1196     def full_clean(self, exclude=None, validate_unique=True):\n1197         \"\"\"\n1198         Call clean_fields(), clean(), and validate_unique() on the model.\n1199         Raise a ValidationError for any errors that occur.\n1200         \"\"\"\n1201         errors = {}\n1202         if exclude is None:\n1203             exclude = []\n1204         else:\n1205             exclude = list(exclude)\n1206 \n1207         try:\n1208             self.clean_fields(exclude=exclude)\n1209         except ValidationError as e:\n1210             errors = e.update_error_dict(errors)\n1211 \n1212         # Form.clean() is run even if other validation fails, so do the\n1213         # same with Model.clean() for consistency.\n1214         try:\n1215             self.clean()\n1216         except ValidationError as e:\n1217             errors = e.update_error_dict(errors)\n1218 \n1219         # Run unique checks, but only for fields that passed validation.\n1220         if validate_unique:\n1221             for name in errors:\n1222                 if name != NON_FIELD_ERRORS and name not in exclude:\n1223                     exclude.append(name)\n1224             try:\n1225                 self.validate_unique(exclude=exclude)\n1226             except ValidationError as e:\n1227                 errors = e.update_error_dict(errors)\n1228 \n1229         if errors:\n1230             raise ValidationError(errors)\n1231 \n1232     def clean_fields(self, exclude=None):\n1233         \"\"\"\n1234         Clean all fields and raise a ValidationError containing a dict\n1235         of all validation errors if any occur.\n1236         \"\"\"\n1237         if exclude is None:\n1238             exclude = []\n1239 \n1240         errors = {}\n1241         for f in self._meta.fields:\n1242             if f.name in exclude:\n1243                 continue\n1244             # Skip validation for empty fields with blank=True. The developer\n1245             # is responsible for making sure they have a valid value.\n1246             raw_value = getattr(self, f.attname)\n1247             if f.blank and raw_value in f.empty_values:\n1248                 continue\n1249             try:\n1250                 setattr(self, f.attname, f.clean(raw_value, self))\n1251             except ValidationError as e:\n1252                 errors[f.name] = e.error_list\n1253 \n1254         if errors:\n1255             raise ValidationError(errors)\n1256 \n1257     @classmethod\n1258     def check(cls, **kwargs):\n1259         errors = [*cls._check_swappable(), *cls._check_model(), *cls._check_managers(**kwargs)]\n1260         if not cls._meta.swapped:\n1261             databases = kwargs.get('databases') or []\n1262             errors += [\n1263                 *cls._check_fields(**kwargs),\n1264                 *cls._check_m2m_through_same_relationship(),\n1265                 *cls._check_long_column_names(databases),\n1266             ]\n1267             clash_errors = (\n1268                 *cls._check_id_field(),\n1269                 *cls._check_field_name_clashes(),\n1270                 *cls._check_model_name_db_lookup_clashes(),\n1271                 *cls._check_property_name_related_field_accessor_clashes(),\n1272                 *cls._check_single_primary_key(),\n1273             )\n1274             errors.extend(clash_errors)\n1275             # If there are field name clashes, hide consequent column name\n1276             # clashes.\n1277             if not clash_errors:\n1278                 errors.extend(cls._check_column_name_clashes())\n1279             errors += [\n1280                 *cls._check_index_together(),\n1281                 *cls._check_unique_together(),\n1282                 *cls._check_indexes(databases),\n1283                 *cls._check_ordering(),\n1284                 *cls._check_constraints(databases),\n1285             ]\n1286 \n1287         return errors\n1288 \n1289     @classmethod\n1290     def _check_swappable(cls):\n1291         \"\"\"Check if the swapped model exists.\"\"\"\n1292         errors = []\n1293         if cls._meta.swapped:\n1294             try:\n1295                 apps.get_model(cls._meta.swapped)\n1296             except ValueError:\n1297                 errors.append(\n1298                     checks.Error(\n1299                         \"'%s' is not of the form 'app_label.app_name'.\" % cls._meta.swappable,\n1300                         id='models.E001',\n1301                     )\n1302                 )\n1303             except LookupError:\n1304                 app_label, model_name = cls._meta.swapped.split('.')\n1305                 errors.append(\n1306                     checks.Error(\n1307                         \"'%s' references '%s.%s', which has not been \"\n1308                         \"installed, or is abstract.\" % (\n1309                             cls._meta.swappable, app_label, model_name\n1310                         ),\n1311                         id='models.E002',\n1312                     )\n1313                 )\n1314         return errors\n1315 \n1316     @classmethod\n1317     def _check_model(cls):\n1318         errors = []\n1319         if cls._meta.proxy:\n1320             if cls._meta.local_fields or cls._meta.local_many_to_many:\n1321                 errors.append(\n1322                     checks.Error(\n1323                         \"Proxy model '%s' contains model fields.\" % cls.__name__,\n1324                         id='models.E017',\n1325                     )\n1326                 )\n1327         return errors\n1328 \n1329     @classmethod\n1330     def _check_managers(cls, **kwargs):\n1331         \"\"\"Perform all manager checks.\"\"\"\n1332         errors = []\n1333         for manager in cls._meta.managers:\n1334             errors.extend(manager.check(**kwargs))\n1335         return errors\n1336 \n1337     @classmethod\n1338     def _check_fields(cls, **kwargs):\n1339         \"\"\"Perform all field checks.\"\"\"\n1340         errors = []\n1341         for field in cls._meta.local_fields:\n1342             errors.extend(field.check(**kwargs))\n1343         for field in cls._meta.local_many_to_many:\n1344             errors.extend(field.check(from_model=cls, **kwargs))\n1345         return errors\n1346 \n1347     @classmethod\n1348     def _check_m2m_through_same_relationship(cls):\n1349         \"\"\" Check if no relationship model is used by more than one m2m field.\n1350         \"\"\"\n1351 \n1352         errors = []\n1353         seen_intermediary_signatures = []\n1354 \n1355         fields = cls._meta.local_many_to_many\n1356 \n1357         # Skip when the target model wasn't found.\n1358         fields = (f for f in fields if isinstance(f.remote_field.model, ModelBase))\n1359 \n1360         # Skip when the relationship model wasn't found.\n1361         fields = (f for f in fields if isinstance(f.remote_field.through, ModelBase))\n1362 \n1363         for f in fields:\n1364             signature = (f.remote_field.model, cls, f.remote_field.through, f.remote_field.through_fields)\n1365             if signature in seen_intermediary_signatures:\n1366                 errors.append(\n1367                     checks.Error(\n1368                         \"The model has two identical many-to-many relations \"\n1369                         \"through the intermediate model '%s'.\" %\n1370                         f.remote_field.through._meta.label,\n1371                         obj=cls,\n1372                         id='models.E003',\n1373                     )\n1374                 )\n1375             else:\n1376                 seen_intermediary_signatures.append(signature)\n1377         return errors\n1378 \n1379     @classmethod\n1380     def _check_id_field(cls):\n1381         \"\"\"Check if `id` field is a primary key.\"\"\"\n1382         fields = [f for f in cls._meta.local_fields if f.name == 'id' and f != cls._meta.pk]\n1383         # fields is empty or consists of the invalid \"id\" field\n1384         if fields and not fields[0].primary_key and cls._meta.pk.name == 'id':\n1385             return [\n1386                 checks.Error(\n1387                     \"'id' can only be used as a field name if the field also \"\n1388                     \"sets 'primary_key=True'.\",\n1389                     obj=cls,\n1390                     id='models.E004',\n1391                 )\n1392             ]\n1393         else:\n1394             return []\n1395 \n1396     @classmethod\n1397     def _check_field_name_clashes(cls):\n1398         \"\"\"Forbid field shadowing in multi-table inheritance.\"\"\"\n1399         errors = []\n1400         used_fields = {}  # name or attname -> field\n1401 \n1402         # Check that multi-inheritance doesn't cause field name shadowing.\n1403         for parent in cls._meta.get_parent_list():\n1404             for f in parent._meta.local_fields:\n1405                 clash = used_fields.get(f.name) or used_fields.get(f.attname) or None\n1406                 if clash:\n1407                     errors.append(\n1408                         checks.Error(\n1409                             \"The field '%s' from parent model \"\n1410                             \"'%s' clashes with the field '%s' \"\n1411                             \"from parent model '%s'.\" % (\n1412                                 clash.name, clash.model._meta,\n1413                                 f.name, f.model._meta\n1414                             ),\n1415                             obj=cls,\n1416                             id='models.E005',\n1417                         )\n1418                     )\n1419                 used_fields[f.name] = f\n1420                 used_fields[f.attname] = f\n1421 \n1422         # Check that fields defined in the model don't clash with fields from\n1423         # parents, including auto-generated fields like multi-table inheritance\n1424         # child accessors.\n1425         for parent in cls._meta.get_parent_list():\n1426             for f in parent._meta.get_fields():\n1427                 if f not in used_fields:\n1428                     used_fields[f.name] = f\n1429 \n1430         for f in cls._meta.local_fields:\n1431             clash = used_fields.get(f.name) or used_fields.get(f.attname) or None\n1432             # Note that we may detect clash between user-defined non-unique\n1433             # field \"id\" and automatically added unique field \"id\", both\n1434             # defined at the same model. This special case is considered in\n1435             # _check_id_field and here we ignore it.\n1436             id_conflict = f.name == \"id\" and clash and clash.name == \"id\" and clash.model == cls\n1437             if clash and not id_conflict:\n1438                 errors.append(\n1439                     checks.Error(\n1440                         \"The field '%s' clashes with the field '%s' \"\n1441                         \"from model '%s'.\" % (\n1442                             f.name, clash.name, clash.model._meta\n1443                         ),\n1444                         obj=f,\n1445                         id='models.E006',\n1446                     )\n1447                 )\n1448             used_fields[f.name] = f\n1449             used_fields[f.attname] = f\n1450 \n1451         return errors\n1452 \n1453     @classmethod\n1454     def _check_column_name_clashes(cls):\n1455         # Store a list of column names which have already been used by other fields.\n1456         used_column_names = []\n1457         errors = []\n1458 \n1459         for f in cls._meta.local_fields:\n1460             _, column_name = f.get_attname_column()\n1461 \n1462             # Ensure the column name is not already in use.\n1463             if column_name and column_name in used_column_names:\n1464                 errors.append(\n1465                     checks.Error(\n1466                         \"Field '%s' has column name '%s' that is used by \"\n1467                         \"another field.\" % (f.name, column_name),\n1468                         hint=\"Specify a 'db_column' for the field.\",\n1469                         obj=cls,\n1470                         id='models.E007'\n1471                     )\n1472                 )\n1473             else:\n1474                 used_column_names.append(column_name)\n1475 \n1476         return errors\n1477 \n1478     @classmethod\n1479     def _check_model_name_db_lookup_clashes(cls):\n1480         errors = []\n1481         model_name = cls.__name__\n1482         if model_name.startswith('_') or model_name.endswith('_'):\n1483             errors.append(\n1484                 checks.Error(\n1485                     \"The model name '%s' cannot start or end with an underscore \"\n1486                     \"as it collides with the query lookup syntax.\" % model_name,\n1487                     obj=cls,\n1488                     id='models.E023'\n1489                 )\n1490             )\n1491         elif LOOKUP_SEP in model_name:\n1492             errors.append(\n1493                 checks.Error(\n1494                     \"The model name '%s' cannot contain double underscores as \"\n1495                     \"it collides with the query lookup syntax.\" % model_name,\n1496                     obj=cls,\n1497                     id='models.E024'\n1498                 )\n1499             )\n1500         return errors\n1501 \n1502     @classmethod\n1503     def _check_property_name_related_field_accessor_clashes(cls):\n1504         errors = []\n1505         property_names = cls._meta._property_names\n1506         related_field_accessors = (\n1507             f.get_attname() for f in cls._meta._get_fields(reverse=False)\n1508             if f.is_relation and f.related_model is not None\n1509         )\n1510         for accessor in related_field_accessors:\n1511             if accessor in property_names:\n1512                 errors.append(\n1513                     checks.Error(\n1514                         \"The property '%s' clashes with a related field \"\n1515                         \"accessor.\" % accessor,\n1516                         obj=cls,\n1517                         id='models.E025',\n1518                     )\n1519                 )\n1520         return errors\n1521 \n1522     @classmethod\n1523     def _check_single_primary_key(cls):\n1524         errors = []\n1525         if sum(1 for f in cls._meta.local_fields if f.primary_key) > 1:\n1526             errors.append(\n1527                 checks.Error(\n1528                     \"The model cannot have more than one field with \"\n1529                     \"'primary_key=True'.\",\n1530                     obj=cls,\n1531                     id='models.E026',\n1532                 )\n1533             )\n1534         return errors\n1535 \n1536     @classmethod\n1537     def _check_index_together(cls):\n1538         \"\"\"Check the value of \"index_together\" option.\"\"\"\n1539         if not isinstance(cls._meta.index_together, (tuple, list)):\n1540             return [\n1541                 checks.Error(\n1542                     \"'index_together' must be a list or tuple.\",\n1543                     obj=cls,\n1544                     id='models.E008',\n1545                 )\n1546             ]\n1547 \n1548         elif any(not isinstance(fields, (tuple, list)) for fields in cls._meta.index_together):\n1549             return [\n1550                 checks.Error(\n1551                     \"All 'index_together' elements must be lists or tuples.\",\n1552                     obj=cls,\n1553                     id='models.E009',\n1554                 )\n1555             ]\n1556 \n1557         else:\n1558             errors = []\n1559             for fields in cls._meta.index_together:\n1560                 errors.extend(cls._check_local_fields(fields, \"index_together\"))\n1561             return errors\n1562 \n1563     @classmethod\n1564     def _check_unique_together(cls):\n1565         \"\"\"Check the value of \"unique_together\" option.\"\"\"\n1566         if not isinstance(cls._meta.unique_together, (tuple, list)):\n1567             return [\n1568                 checks.Error(\n1569                     \"'unique_together' must be a list or tuple.\",\n1570                     obj=cls,\n1571                     id='models.E010',\n1572                 )\n1573             ]\n1574 \n1575         elif any(not isinstance(fields, (tuple, list)) for fields in cls._meta.unique_together):\n1576             return [\n1577                 checks.Error(\n1578                     \"All 'unique_together' elements must be lists or tuples.\",\n1579                     obj=cls,\n1580                     id='models.E011',\n1581                 )\n1582             ]\n1583 \n1584         else:\n1585             errors = []\n1586             for fields in cls._meta.unique_together:\n1587                 errors.extend(cls._check_local_fields(fields, \"unique_together\"))\n1588             return errors\n1589 \n1590     @classmethod\n1591     def _check_indexes(cls, databases):\n1592         \"\"\"Check fields, names, and conditions of indexes.\"\"\"\n1593         errors = []\n1594         for index in cls._meta.indexes:\n1595             # Index name can't start with an underscore or a number, restricted\n1596             # for cross-database compatibility with Oracle.\n1597             if index.name[0] == '_' or index.name[0].isdigit():\n1598                 errors.append(\n1599                     checks.Error(\n1600                         \"The index name '%s' cannot start with an underscore \"\n1601                         \"or a number.\" % index.name,\n1602                         obj=cls,\n1603                         id='models.E033',\n1604                     ),\n1605                 )\n1606             if len(index.name) > index.max_name_length:\n1607                 errors.append(\n1608                     checks.Error(\n1609                         \"The index name '%s' cannot be longer than %d \"\n1610                         \"characters.\" % (index.name, index.max_name_length),\n1611                         obj=cls,\n1612                         id='models.E034',\n1613                     ),\n1614                 )\n1615         for db in databases:\n1616             if not router.allow_migrate_model(db, cls):\n1617                 continue\n1618             connection = connections[db]\n1619             if not (\n1620                 connection.features.supports_partial_indexes or\n1621                 'supports_partial_indexes' in cls._meta.required_db_features\n1622             ) and any(index.condition is not None for index in cls._meta.indexes):\n1623                 errors.append(\n1624                     checks.Warning(\n1625                         '%s does not support indexes with conditions.'\n1626                         % connection.display_name,\n1627                         hint=(\n1628                             \"Conditions will be ignored. Silence this warning \"\n1629                             \"if you don't care about it.\"\n1630                         ),\n1631                         obj=cls,\n1632                         id='models.W037',\n1633                     )\n1634                 )\n1635             if not (\n1636                 connection.features.supports_covering_indexes or\n1637                 'supports_covering_indexes' in cls._meta.required_db_features\n1638             ) and any(index.include for index in cls._meta.indexes):\n1639                 errors.append(\n1640                     checks.Warning(\n1641                         '%s does not support indexes with non-key columns.'\n1642                         % connection.display_name,\n1643                         hint=(\n1644                             \"Non-key columns will be ignored. Silence this \"\n1645                             \"warning if you don't care about it.\"\n1646                         ),\n1647                         obj=cls,\n1648                         id='models.W040',\n1649                     )\n1650                 )\n1651         fields = [field for index in cls._meta.indexes for field, _ in index.fields_orders]\n1652         fields += [include for index in cls._meta.indexes for include in index.include]\n1653         errors.extend(cls._check_local_fields(fields, 'indexes'))\n1654         return errors\n1655 \n1656     @classmethod\n1657     def _check_local_fields(cls, fields, option):\n1658         from django.db import models\n1659 \n1660         # In order to avoid hitting the relation tree prematurely, we use our\n1661         # own fields_map instead of using get_field()\n1662         forward_fields_map = {}\n1663         for field in cls._meta._get_fields(reverse=False):\n1664             forward_fields_map[field.name] = field\n1665             if hasattr(field, 'attname'):\n1666                 forward_fields_map[field.attname] = field\n1667 \n1668         errors = []\n1669         for field_name in fields:\n1670             try:\n1671                 field = forward_fields_map[field_name]\n1672             except KeyError:\n1673                 errors.append(\n1674                     checks.Error(\n1675                         \"'%s' refers to the nonexistent field '%s'.\" % (\n1676                             option, field_name,\n1677                         ),\n1678                         obj=cls,\n1679                         id='models.E012',\n1680                     )\n1681                 )\n1682             else:\n1683                 if isinstance(field.remote_field, models.ManyToManyRel):\n1684                     errors.append(\n1685                         checks.Error(\n1686                             \"'%s' refers to a ManyToManyField '%s', but \"\n1687                             \"ManyToManyFields are not permitted in '%s'.\" % (\n1688                                 option, field_name, option,\n1689                             ),\n1690                             obj=cls,\n1691                             id='models.E013',\n1692                         )\n1693                     )\n1694                 elif field not in cls._meta.local_fields:\n1695                     errors.append(\n1696                         checks.Error(\n1697                             \"'%s' refers to field '%s' which is not local to model '%s'.\"\n1698                             % (option, field_name, cls._meta.object_name),\n1699                             hint=\"This issue may be caused by multi-table inheritance.\",\n1700                             obj=cls,\n1701                             id='models.E016',\n1702                         )\n1703                     )\n1704         return errors\n1705 \n1706     @classmethod\n1707     def _check_ordering(cls):\n1708         \"\"\"\n1709         Check \"ordering\" option -- is it a list of strings and do all fields\n1710         exist?\n1711         \"\"\"\n1712         if cls._meta._ordering_clash:\n1713             return [\n1714                 checks.Error(\n1715                     \"'ordering' and 'order_with_respect_to' cannot be used together.\",\n1716                     obj=cls,\n1717                     id='models.E021',\n1718                 ),\n1719             ]\n1720 \n1721         if cls._meta.order_with_respect_to or not cls._meta.ordering:\n1722             return []\n1723 \n1724         if not isinstance(cls._meta.ordering, (list, tuple)):\n1725             return [\n1726                 checks.Error(\n1727                     \"'ordering' must be a tuple or list (even if you want to order by only one field).\",\n1728                     obj=cls,\n1729                     id='models.E014',\n1730                 )\n1731             ]\n1732 \n1733         errors = []\n1734         fields = cls._meta.ordering\n1735 \n1736         # Skip expressions and '?' fields.\n1737         fields = (f for f in fields if isinstance(f, str) and f != '?')\n1738 \n1739         # Convert \"-field\" to \"field\".\n1740         fields = ((f[1:] if f.startswith('-') else f) for f in fields)\n1741 \n1742         # Separate related fields and non-related fields.\n1743         _fields = []\n1744         related_fields = []\n1745         for f in fields:\n1746             if LOOKUP_SEP in f:\n1747                 related_fields.append(f)\n1748             else:\n1749                 _fields.append(f)\n1750         fields = _fields\n1751 \n1752         # Check related fields.\n1753         for field in related_fields:\n1754             _cls = cls\n1755             fld = None\n1756             for part in field.split(LOOKUP_SEP):\n1757                 try:\n1758                     # pk is an alias that won't be found by opts.get_field.\n1759                     if part == 'pk':\n1760                         fld = _cls._meta.pk\n1761                     else:\n1762                         fld = _cls._meta.get_field(part)\n1763                     if fld.is_relation:\n1764                         _cls = fld.get_path_info()[-1].to_opts.model\n1765                     else:\n1766                         _cls = None\n1767                 except (FieldDoesNotExist, AttributeError):\n1768                     if fld is None or (\n1769                         fld.get_transform(part) is None and fld.get_lookup(part) is None\n1770                     ):\n1771                         errors.append(\n1772                             checks.Error(\n1773                                 \"'ordering' refers to the nonexistent field, \"\n1774                                 \"related field, or lookup '%s'.\" % field,\n1775                                 obj=cls,\n1776                                 id='models.E015',\n1777                             )\n1778                         )\n1779 \n1780         # Skip ordering on pk. This is always a valid order_by field\n1781         # but is an alias and therefore won't be found by opts.get_field.\n1782         fields = {f for f in fields if f != 'pk'}\n1783 \n1784         # Check for invalid or nonexistent fields in ordering.\n1785         invalid_fields = []\n1786 \n1787         # Any field name that is not present in field_names does not exist.\n1788         # Also, ordering by m2m fields is not allowed.\n1789         opts = cls._meta\n1790         valid_fields = set(chain.from_iterable(\n1791             (f.name, f.attname) if not (f.auto_created and not f.concrete) else (f.field.related_query_name(),)\n1792             for f in chain(opts.fields, opts.related_objects)\n1793         ))\n1794 \n1795         invalid_fields.extend(fields - valid_fields)\n1796 \n1797         for invalid_field in invalid_fields:\n1798             errors.append(\n1799                 checks.Error(\n1800                     \"'ordering' refers to the nonexistent field, related \"\n1801                     \"field, or lookup '%s'.\" % invalid_field,\n1802                     obj=cls,\n1803                     id='models.E015',\n1804                 )\n1805             )\n1806         return errors\n1807 \n1808     @classmethod\n1809     def _check_long_column_names(cls, databases):\n1810         \"\"\"\n1811         Check that any auto-generated column names are shorter than the limits\n1812         for each database in which the model will be created.\n1813         \"\"\"\n1814         if not databases:\n1815             return []\n1816         errors = []\n1817         allowed_len = None\n1818         db_alias = None\n1819 \n1820         # Find the minimum max allowed length among all specified db_aliases.\n1821         for db in databases:\n1822             # skip databases where the model won't be created\n1823             if not router.allow_migrate_model(db, cls):\n1824                 continue\n1825             connection = connections[db]\n1826             max_name_length = connection.ops.max_name_length()\n1827             if max_name_length is None or connection.features.truncates_names:\n1828                 continue\n1829             else:\n1830                 if allowed_len is None:\n1831                     allowed_len = max_name_length\n1832                     db_alias = db\n1833                 elif max_name_length < allowed_len:\n1834                     allowed_len = max_name_length\n1835                     db_alias = db\n1836 \n1837         if allowed_len is None:\n1838             return errors\n1839 \n1840         for f in cls._meta.local_fields:\n1841             _, column_name = f.get_attname_column()\n1842 \n1843             # Check if auto-generated name for the field is too long\n1844             # for the database.\n1845             if f.db_column is None and column_name is not None and len(column_name) > allowed_len:\n1846                 errors.append(\n1847                     checks.Error(\n1848                         'Autogenerated column name too long for field \"%s\". '\n1849                         'Maximum length is \"%s\" for database \"%s\".'\n1850                         % (column_name, allowed_len, db_alias),\n1851                         hint=\"Set the column name manually using 'db_column'.\",\n1852                         obj=cls,\n1853                         id='models.E018',\n1854                     )\n1855                 )\n1856 \n1857         for f in cls._meta.local_many_to_many:\n1858             # Skip nonexistent models.\n1859             if isinstance(f.remote_field.through, str):\n1860                 continue\n1861 \n1862             # Check if auto-generated name for the M2M field is too long\n1863             # for the database.\n1864             for m2m in f.remote_field.through._meta.local_fields:\n1865                 _, rel_name = m2m.get_attname_column()\n1866                 if m2m.db_column is None and rel_name is not None and len(rel_name) > allowed_len:\n1867                     errors.append(\n1868                         checks.Error(\n1869                             'Autogenerated column name too long for M2M field '\n1870                             '\"%s\". Maximum length is \"%s\" for database \"%s\".'\n1871                             % (rel_name, allowed_len, db_alias),\n1872                             hint=(\n1873                                 \"Use 'through' to create a separate model for \"\n1874                                 \"M2M and then set column_name using 'db_column'.\"\n1875                             ),\n1876                             obj=cls,\n1877                             id='models.E019',\n1878                         )\n1879                     )\n1880 \n1881         return errors\n1882 \n1883     @classmethod\n1884     def _get_expr_references(cls, expr):\n1885         if isinstance(expr, Q):\n1886             for child in expr.children:\n1887                 if isinstance(child, tuple):\n1888                     lookup, value = child\n1889                     yield tuple(lookup.split(LOOKUP_SEP))\n1890                     yield from cls._get_expr_references(value)\n1891                 else:\n1892                     yield from cls._get_expr_references(child)\n1893         elif isinstance(expr, F):\n1894             yield tuple(expr.name.split(LOOKUP_SEP))\n1895         elif hasattr(expr, 'get_source_expressions'):\n1896             for src_expr in expr.get_source_expressions():\n1897                 yield from cls._get_expr_references(src_expr)\n1898 \n1899     @classmethod\n1900     def _check_constraints(cls, databases):\n1901         errors = []\n1902         for db in databases:\n1903             if not router.allow_migrate_model(db, cls):\n1904                 continue\n1905             connection = connections[db]\n1906             if not (\n1907                 connection.features.supports_table_check_constraints or\n1908                 'supports_table_check_constraints' in cls._meta.required_db_features\n1909             ) and any(\n1910                 isinstance(constraint, CheckConstraint)\n1911                 for constraint in cls._meta.constraints\n1912             ):\n1913                 errors.append(\n1914                     checks.Warning(\n1915                         '%s does not support check constraints.' % connection.display_name,\n1916                         hint=(\n1917                             \"A constraint won't be created. Silence this \"\n1918                             \"warning if you don't care about it.\"\n1919                         ),\n1920                         obj=cls,\n1921                         id='models.W027',\n1922                     )\n1923                 )\n1924             if not (\n1925                 connection.features.supports_partial_indexes or\n1926                 'supports_partial_indexes' in cls._meta.required_db_features\n1927             ) and any(\n1928                 isinstance(constraint, UniqueConstraint) and constraint.condition is not None\n1929                 for constraint in cls._meta.constraints\n1930             ):\n1931                 errors.append(\n1932                     checks.Warning(\n1933                         '%s does not support unique constraints with '\n1934                         'conditions.' % connection.display_name,\n1935                         hint=(\n1936                             \"A constraint won't be created. Silence this \"\n1937                             \"warning if you don't care about it.\"\n1938                         ),\n1939                         obj=cls,\n1940                         id='models.W036',\n1941                     )\n1942                 )\n1943             if not (\n1944                 connection.features.supports_deferrable_unique_constraints or\n1945                 'supports_deferrable_unique_constraints' in cls._meta.required_db_features\n1946             ) and any(\n1947                 isinstance(constraint, UniqueConstraint) and constraint.deferrable is not None\n1948                 for constraint in cls._meta.constraints\n1949             ):\n1950                 errors.append(\n1951                     checks.Warning(\n1952                         '%s does not support deferrable unique constraints.'\n1953                         % connection.display_name,\n1954                         hint=(\n1955                             \"A constraint won't be created. Silence this \"\n1956                             \"warning if you don't care about it.\"\n1957                         ),\n1958                         obj=cls,\n1959                         id='models.W038',\n1960                     )\n1961                 )\n1962             if not (\n1963                 connection.features.supports_covering_indexes or\n1964                 'supports_covering_indexes' in cls._meta.required_db_features\n1965             ) and any(\n1966                 isinstance(constraint, UniqueConstraint) and constraint.include\n1967                 for constraint in cls._meta.constraints\n1968             ):\n1969                 errors.append(\n1970                     checks.Warning(\n1971                         '%s does not support unique constraints with non-key '\n1972                         'columns.' % connection.display_name,\n1973                         hint=(\n1974                             \"A constraint won't be created. Silence this \"\n1975                             \"warning if you don't care about it.\"\n1976                         ),\n1977                         obj=cls,\n1978                         id='models.W039',\n1979                     )\n1980                 )\n1981             fields = set(chain.from_iterable(\n1982                 (*constraint.fields, *constraint.include)\n1983                 for constraint in cls._meta.constraints if isinstance(constraint, UniqueConstraint)\n1984             ))\n1985             references = set()\n1986             for constraint in cls._meta.constraints:\n1987                 if isinstance(constraint, UniqueConstraint):\n1988                     if (\n1989                         connection.features.supports_partial_indexes or\n1990                         'supports_partial_indexes' not in cls._meta.required_db_features\n1991                     ) and isinstance(constraint.condition, Q):\n1992                         references.update(cls._get_expr_references(constraint.condition))\n1993                 elif isinstance(constraint, CheckConstraint):\n1994                     if (\n1995                         connection.features.supports_table_check_constraints or\n1996                         'supports_table_check_constraints' not in cls._meta.required_db_features\n1997                     ) and isinstance(constraint.check, Q):\n1998                         references.update(cls._get_expr_references(constraint.check))\n1999             for field_name, *lookups in references:\n2000                 # pk is an alias that won't be found by opts.get_field.\n2001                 if field_name != 'pk':\n2002                     fields.add(field_name)\n2003                 if not lookups:\n2004                     # If it has no lookups it cannot result in a JOIN.\n2005                     continue\n2006                 try:\n2007                     if field_name == 'pk':\n2008                         field = cls._meta.pk\n2009                     else:\n2010                         field = cls._meta.get_field(field_name)\n2011                     if not field.is_relation or field.many_to_many or field.one_to_many:\n2012                         continue\n2013                 except FieldDoesNotExist:\n2014                     continue\n2015                 # JOIN must happen at the first lookup.\n2016                 first_lookup = lookups[0]\n2017                 if (\n2018                     field.get_transform(first_lookup) is None and\n2019                     field.get_lookup(first_lookup) is None\n2020                 ):\n2021                     errors.append(\n2022                         checks.Error(\n2023                             \"'constraints' refers to the joined field '%s'.\"\n2024                             % LOOKUP_SEP.join([field_name] + lookups),\n2025                             obj=cls,\n2026                             id='models.E041',\n2027                         )\n2028                     )\n2029             errors.extend(cls._check_local_fields(fields, 'constraints'))\n2030         return errors\n2031 \n2032 \n2033 ############################################\n2034 # HELPER FUNCTIONS (CURRIED MODEL METHODS) #\n2035 ############################################\n2036 \n2037 # ORDERING METHODS #########################\n2038 \n2039 def method_set_order(self, ordered_obj, id_list, using=None):\n2040     if using is None:\n2041         using = DEFAULT_DB_ALIAS\n2042     order_wrt = ordered_obj._meta.order_with_respect_to\n2043     filter_args = order_wrt.get_forward_related_filter(self)\n2044     ordered_obj.objects.db_manager(using).filter(**filter_args).bulk_update([\n2045         ordered_obj(pk=pk, _order=order) for order, pk in enumerate(id_list)\n2046     ], ['_order'])\n2047 \n2048 \n2049 def method_get_order(self, ordered_obj):\n2050     order_wrt = ordered_obj._meta.order_with_respect_to\n2051     filter_args = order_wrt.get_forward_related_filter(self)\n2052     pk_name = ordered_obj._meta.pk.name\n2053     return ordered_obj.objects.filter(**filter_args).values_list(pk_name, flat=True)\n2054 \n2055 \n2056 def make_foreign_order_accessors(model, related_model):\n2057     setattr(\n2058         related_model,\n2059         'get_%s_order' % model.__name__.lower(),\n2060         partialmethod(method_get_order, model)\n2061     )\n2062     setattr(\n2063         related_model,\n2064         'set_%s_order' % model.__name__.lower(),\n2065         partialmethod(method_set_order, model)\n2066     )\n2067 \n2068 ########\n2069 # MISC #\n2070 ########\n2071 \n2072 \n2073 def model_unpickle(model_id):\n2074     \"\"\"Used to unpickle Model subclasses with deferred fields.\"\"\"\n2075     if isinstance(model_id, tuple):\n2076         model = apps.get_model(*model_id)\n2077     else:\n2078         # Backwards compat - the model was cached directly in earlier versions.\n2079         model = model_id\n2080     return model.__new__(model)\n2081 \n2082 \n2083 model_unpickle.__safe_for_unpickle__ = True\n",
        "intended_behavior": "The part of the code responsible for handling model instance copying or state management needs to be updated or examined for Django versions >= 2.0. The code should ensure that when a model instance is copied (using Python's standard copy.copy or copy.deepcopy), all relevant state data, including foreign keys (FK) and caching mechanisms (_state and fields_cache), are correctly cloned. This includes the preservation of FK relationships and cache integrity so that changes to a cloned instance do not affect the original instance. This might involve examining or adjusting how _state (especially fields_cache) is copied between instances to ensure behavior consistent with versions < 2.0, thus preserving the expected functionality while also embracing any architectural changes introduced in Django 2.x."
    },
    {
        "rel_file_path": "django/db/models/fields/related_descriptors.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.2/django/db/models/fields/related_descriptors.py",
        "start": 1,
        "end": 1204,
        "class_name": null,
        "method_name": null,
        "code": "1 \"\"\"\n2 Accessors for related objects.\n3 \n4 When a field defines a relation between two models, each model class provides\n5 an attribute to access related instances of the other model class (unless the\n6 reverse accessor has been disabled with related_name='+').\n7 \n8 Accessors are implemented as descriptors in order to customize access and\n9 assignment. This module defines the descriptor classes.\n10 \n11 Forward accessors follow foreign keys. Reverse accessors trace them back. For\n12 example, with the following models::\n13 \n14     class Parent(Model):\n15         pass\n16 \n17     class Child(Model):\n18         parent = ForeignKey(Parent, related_name='children')\n19 \n20  ``child.parent`` is a forward many-to-one relation. ``parent.children`` is a\n21 reverse many-to-one relation.\n22 \n23 There are three types of relations (many-to-one, one-to-one, and many-to-many)\n24 and two directions (forward and reverse) for a total of six combinations.\n25 \n26 1. Related instance on the forward side of a many-to-one relation:\n27    ``ForwardManyToOneDescriptor``.\n28 \n29    Uniqueness of foreign key values is irrelevant to accessing the related\n30    instance, making the many-to-one and one-to-one cases identical as far as\n31    the descriptor is concerned. The constraint is checked upstream (unicity\n32    validation in forms) or downstream (unique indexes in the database).\n33 \n34 2. Related instance on the forward side of a one-to-one\n35    relation: ``ForwardOneToOneDescriptor``.\n36 \n37    It avoids querying the database when accessing the parent link field in\n38    a multi-table inheritance scenario.\n39 \n40 3. Related instance on the reverse side of a one-to-one relation:\n41    ``ReverseOneToOneDescriptor``.\n42 \n43    One-to-one relations are asymmetrical, despite the apparent symmetry of the\n44    name, because they're implemented in the database with a foreign key from\n45    one table to another. As a consequence ``ReverseOneToOneDescriptor`` is\n46    slightly different from ``ForwardManyToOneDescriptor``.\n47 \n48 4. Related objects manager for related instances on the reverse side of a\n49    many-to-one relation: ``ReverseManyToOneDescriptor``.\n50 \n51    Unlike the previous two classes, this one provides access to a collection\n52    of objects. It returns a manager rather than an instance.\n53 \n54 5. Related objects manager for related instances on the forward or reverse\n55    sides of a many-to-many relation: ``ManyToManyDescriptor``.\n56 \n57    Many-to-many relations are symmetrical. The syntax of Django models\n58    requires declaring them on one side but that's an implementation detail.\n59    They could be declared on the other side without any change in behavior.\n60    Therefore the forward and reverse descriptors can be the same.\n61 \n62    If you're looking for ``ForwardManyToManyDescriptor`` or\n63    ``ReverseManyToManyDescriptor``, use ``ManyToManyDescriptor`` instead.\n64 \"\"\"\n65 \n66 from django.core.exceptions import FieldError\n67 from django.db import connections, router, transaction\n68 from django.db.models import Q, signals\n69 from django.db.models.query import QuerySet\n70 from django.db.models.query_utils import DeferredAttribute\n71 from django.db.models.utils import resolve_callables\n72 from django.utils.functional import cached_property\n73 \n74 \n75 class ForeignKeyDeferredAttribute(DeferredAttribute):\n76     def __set__(self, instance, value):\n77         if instance.__dict__.get(self.field.attname) != value and self.field.is_cached(instance):\n78             self.field.delete_cached_value(instance)\n79         instance.__dict__[self.field.attname] = value\n80 \n81 \n82 class ForwardManyToOneDescriptor:\n83     \"\"\"\n84     Accessor to the related object on the forward side of a many-to-one or\n85     one-to-one (via ForwardOneToOneDescriptor subclass) relation.\n86 \n87     In the example::\n88 \n89         class Child(Model):\n90             parent = ForeignKey(Parent, related_name='children')\n91 \n92     ``Child.parent`` is a ``ForwardManyToOneDescriptor`` instance.\n93     \"\"\"\n94 \n95     def __init__(self, field_with_rel):\n96         self.field = field_with_rel\n97 \n98     @cached_property\n99     def RelatedObjectDoesNotExist(self):\n100         # The exception can't be created at initialization time since the\n101         # related model might not be resolved yet; `self.field.model` might\n102         # still be a string model reference.\n103         return type(\n104             'RelatedObjectDoesNotExist',\n105             (self.field.remote_field.model.DoesNotExist, AttributeError), {\n106                 '__module__': self.field.model.__module__,\n107                 '__qualname__': '%s.%s.RelatedObjectDoesNotExist' % (\n108                     self.field.model.__qualname__,\n109                     self.field.name,\n110                 ),\n111             }\n112         )\n113 \n114     def is_cached(self, instance):\n115         return self.field.is_cached(instance)\n116 \n117     def get_queryset(self, **hints):\n118         return self.field.remote_field.model._base_manager.db_manager(hints=hints).all()\n119 \n120     def get_prefetch_queryset(self, instances, queryset=None):\n121         if queryset is None:\n122             queryset = self.get_queryset()\n123         queryset._add_hints(instance=instances[0])\n124 \n125         rel_obj_attr = self.field.get_foreign_related_value\n126         instance_attr = self.field.get_local_related_value\n127         instances_dict = {instance_attr(inst): inst for inst in instances}\n128         related_field = self.field.foreign_related_fields[0]\n129         remote_field = self.field.remote_field\n130 \n131         # FIXME: This will need to be revisited when we introduce support for\n132         # composite fields. In the meantime we take this practical approach to\n133         # solve a regression on 1.6 when the reverse manager in hidden\n134         # (related_name ends with a '+'). Refs #21410.\n135         # The check for len(...) == 1 is a special case that allows the query\n136         # to be join-less and smaller. Refs #21760.\n137         if remote_field.is_hidden() or len(self.field.foreign_related_fields) == 1:\n138             query = {'%s__in' % related_field.name: {instance_attr(inst)[0] for inst in instances}}\n139         else:\n140             query = {'%s__in' % self.field.related_query_name(): instances}\n141         queryset = queryset.filter(**query)\n142 \n143         # Since we're going to assign directly in the cache,\n144         # we must manage the reverse relation cache manually.\n145         if not remote_field.multiple:\n146             for rel_obj in queryset:\n147                 instance = instances_dict[rel_obj_attr(rel_obj)]\n148                 remote_field.set_cached_value(rel_obj, instance)\n149         return queryset, rel_obj_attr, instance_attr, True, self.field.get_cache_name(), False\n150 \n151     def get_object(self, instance):\n152         qs = self.get_queryset(instance=instance)\n153         # Assuming the database enforces foreign keys, this won't fail.\n154         return qs.get(self.field.get_reverse_related_filter(instance))\n155 \n156     def __get__(self, instance, cls=None):\n157         \"\"\"\n158         Get the related instance through the forward relation.\n159 \n160         With the example above, when getting ``child.parent``:\n161 \n162         - ``self`` is the descriptor managing the ``parent`` attribute\n163         - ``instance`` is the ``child`` instance\n164         - ``cls`` is the ``Child`` class (we don't need it)\n165         \"\"\"\n166         if instance is None:\n167             return self\n168 \n169         # The related instance is loaded from the database and then cached\n170         # by the field on the model instance state. It can also be pre-cached\n171         # by the reverse accessor (ReverseOneToOneDescriptor).\n172         try:\n173             rel_obj = self.field.get_cached_value(instance)\n174         except KeyError:\n175             has_value = None not in self.field.get_local_related_value(instance)\n176             ancestor_link = instance._meta.get_ancestor_link(self.field.model) if has_value else None\n177             if ancestor_link and ancestor_link.is_cached(instance):\n178                 # An ancestor link will exist if this field is defined on a\n179                 # multi-table inheritance parent of the instance's class.\n180                 ancestor = ancestor_link.get_cached_value(instance)\n181                 # The value might be cached on an ancestor if the instance\n182                 # originated from walking down the inheritance chain.\n183                 rel_obj = self.field.get_cached_value(ancestor, default=None)\n184             else:\n185                 rel_obj = None\n186             if rel_obj is None and has_value:\n187                 rel_obj = self.get_object(instance)\n188                 remote_field = self.field.remote_field\n189                 # If this is a one-to-one relation, set the reverse accessor\n190                 # cache on the related object to the current instance to avoid\n191                 # an extra SQL query if it's accessed later on.\n192                 if not remote_field.multiple:\n193                     remote_field.set_cached_value(rel_obj, instance)\n194             self.field.set_cached_value(instance, rel_obj)\n195 \n196         if rel_obj is None and not self.field.null:\n197             raise self.RelatedObjectDoesNotExist(\n198                 \"%s has no %s.\" % (self.field.model.__name__, self.field.name)\n199             )\n200         else:\n201             return rel_obj\n202 \n203     def __set__(self, instance, value):\n204         \"\"\"\n205         Set the related instance through the forward relation.\n206 \n207         With the example above, when setting ``child.parent = parent``:\n208 \n209         - ``self`` is the descriptor managing the ``parent`` attribute\n210         - ``instance`` is the ``child`` instance\n211         - ``value`` is the ``parent`` instance on the right of the equal sign\n212         \"\"\"\n213         # An object must be an instance of the related class.\n214         if value is not None and not isinstance(value, self.field.remote_field.model._meta.concrete_model):\n215             raise ValueError(\n216                 'Cannot assign \"%r\": \"%s.%s\" must be a \"%s\" instance.' % (\n217                     value,\n218                     instance._meta.object_name,\n219                     self.field.name,\n220                     self.field.remote_field.model._meta.object_name,\n221                 )\n222             )\n223         elif value is not None:\n224             if instance._state.db is None:\n225                 instance._state.db = router.db_for_write(instance.__class__, instance=value)\n226             if value._state.db is None:\n227                 value._state.db = router.db_for_write(value.__class__, instance=instance)\n228             if not router.allow_relation(value, instance):\n229                 raise ValueError('Cannot assign \"%r\": the current database router prevents this relation.' % value)\n230 \n231         remote_field = self.field.remote_field\n232         # If we're setting the value of a OneToOneField to None, we need to clear\n233         # out the cache on any old related object. Otherwise, deleting the\n234         # previously-related object will also cause this object to be deleted,\n235         # which is wrong.\n236         if value is None:\n237             # Look up the previously-related object, which may still be available\n238             # since we've not yet cleared out the related field.\n239             # Use the cache directly, instead of the accessor; if we haven't\n240             # populated the cache, then we don't care - we're only accessing\n241             # the object to invalidate the accessor cache, so there's no\n242             # need to populate the cache just to expire it again.\n243             related = self.field.get_cached_value(instance, default=None)\n244 \n245             # If we've got an old related object, we need to clear out its\n246             # cache. This cache also might not exist if the related object\n247             # hasn't been accessed yet.\n248             if related is not None:\n249                 remote_field.set_cached_value(related, None)\n250 \n251             for lh_field, rh_field in self.field.related_fields:\n252                 setattr(instance, lh_field.attname, None)\n253 \n254         # Set the values of the related field.\n255         else:\n256             for lh_field, rh_field in self.field.related_fields:\n257                 setattr(instance, lh_field.attname, getattr(value, rh_field.attname))\n258 \n259         # Set the related instance cache used by __get__ to avoid an SQL query\n260         # when accessing the attribute we just set.\n261         self.field.set_cached_value(instance, value)\n262 \n263         # If this is a one-to-one relation, set the reverse accessor cache on\n264         # the related object to the current instance to avoid an extra SQL\n265         # query if it's accessed later on.\n266         if value is not None and not remote_field.multiple:\n267             remote_field.set_cached_value(value, instance)\n268 \n269     def __reduce__(self):\n270         \"\"\"\n271         Pickling should return the instance attached by self.field on the\n272         model, not a new copy of that descriptor. Use getattr() to retrieve\n273         the instance directly from the model.\n274         \"\"\"\n275         return getattr, (self.field.model, self.field.name)\n276 \n277 \n278 class ForwardOneToOneDescriptor(ForwardManyToOneDescriptor):\n279     \"\"\"\n280     Accessor to the related object on the forward side of a one-to-one relation.\n281 \n282     In the example::\n283 \n284         class Restaurant(Model):\n285             place = OneToOneField(Place, related_name='restaurant')\n286 \n287     ``Restaurant.place`` is a ``ForwardOneToOneDescriptor`` instance.\n288     \"\"\"\n289 \n290     def get_object(self, instance):\n291         if self.field.remote_field.parent_link:\n292             deferred = instance.get_deferred_fields()\n293             # Because it's a parent link, all the data is available in the\n294             # instance, so populate the parent model with this data.\n295             rel_model = self.field.remote_field.model\n296             fields = [field.attname for field in rel_model._meta.concrete_fields]\n297 \n298             # If any of the related model's fields are deferred, fallback to\n299             # fetching all fields from the related model. This avoids a query\n300             # on the related model for every deferred field.\n301             if not any(field in fields for field in deferred):\n302                 kwargs = {field: getattr(instance, field) for field in fields}\n303                 obj = rel_model(**kwargs)\n304                 obj._state.adding = instance._state.adding\n305                 obj._state.db = instance._state.db\n306                 return obj\n307         return super().get_object(instance)\n308 \n309     def __set__(self, instance, value):\n310         super().__set__(instance, value)\n311         # If the primary key is a link to a parent model and a parent instance\n312         # is being set, update the value of the inherited pk(s).\n313         if self.field.primary_key and self.field.remote_field.parent_link:\n314             opts = instance._meta\n315             # Inherited primary key fields from this object's base classes.\n316             inherited_pk_fields = [\n317                 field for field in opts.concrete_fields\n318                 if field.primary_key and field.remote_field\n319             ]\n320             for field in inherited_pk_fields:\n321                 rel_model_pk_name = field.remote_field.model._meta.pk.attname\n322                 raw_value = getattr(value, rel_model_pk_name) if value is not None else None\n323                 setattr(instance, rel_model_pk_name, raw_value)\n324 \n325 \n326 class ReverseOneToOneDescriptor:\n327     \"\"\"\n328     Accessor to the related object on the reverse side of a one-to-one\n329     relation.\n330 \n331     In the example::\n332 \n333         class Restaurant(Model):\n334             place = OneToOneField(Place, related_name='restaurant')\n335 \n336     ``Place.restaurant`` is a ``ReverseOneToOneDescriptor`` instance.\n337     \"\"\"\n338 \n339     def __init__(self, related):\n340         # Following the example above, `related` is an instance of OneToOneRel\n341         # which represents the reverse restaurant field (place.restaurant).\n342         self.related = related\n343 \n344     @cached_property\n345     def RelatedObjectDoesNotExist(self):\n346         # The exception isn't created at initialization time for the sake of\n347         # consistency with `ForwardManyToOneDescriptor`.\n348         return type(\n349             'RelatedObjectDoesNotExist',\n350             (self.related.related_model.DoesNotExist, AttributeError), {\n351                 '__module__': self.related.model.__module__,\n352                 '__qualname__': '%s.%s.RelatedObjectDoesNotExist' % (\n353                     self.related.model.__qualname__,\n354                     self.related.name,\n355                 )\n356             },\n357         )\n358 \n359     def is_cached(self, instance):\n360         return self.related.is_cached(instance)\n361 \n362     def get_queryset(self, **hints):\n363         return self.related.related_model._base_manager.db_manager(hints=hints).all()\n364 \n365     def get_prefetch_queryset(self, instances, queryset=None):\n366         if queryset is None:\n367             queryset = self.get_queryset()\n368         queryset._add_hints(instance=instances[0])\n369 \n370         rel_obj_attr = self.related.field.get_local_related_value\n371         instance_attr = self.related.field.get_foreign_related_value\n372         instances_dict = {instance_attr(inst): inst for inst in instances}\n373         query = {'%s__in' % self.related.field.name: instances}\n374         queryset = queryset.filter(**query)\n375 \n376         # Since we're going to assign directly in the cache,\n377         # we must manage the reverse relation cache manually.\n378         for rel_obj in queryset:\n379             instance = instances_dict[rel_obj_attr(rel_obj)]\n380             self.related.field.set_cached_value(rel_obj, instance)\n381         return queryset, rel_obj_attr, instance_attr, True, self.related.get_cache_name(), False\n382 \n383     def __get__(self, instance, cls=None):\n384         \"\"\"\n385         Get the related instance through the reverse relation.\n386 \n387         With the example above, when getting ``place.restaurant``:\n388 \n389         - ``self`` is the descriptor managing the ``restaurant`` attribute\n390         - ``instance`` is the ``place`` instance\n391         - ``cls`` is the ``Place`` class (unused)\n392 \n393         Keep in mind that ``Restaurant`` holds the foreign key to ``Place``.\n394         \"\"\"\n395         if instance is None:\n396             return self\n397 \n398         # The related instance is loaded from the database and then cached\n399         # by the field on the model instance state. It can also be pre-cached\n400         # by the forward accessor (ForwardManyToOneDescriptor).\n401         try:\n402             rel_obj = self.related.get_cached_value(instance)\n403         except KeyError:\n404             related_pk = instance.pk\n405             if related_pk is None:\n406                 rel_obj = None\n407             else:\n408                 filter_args = self.related.field.get_forward_related_filter(instance)\n409                 try:\n410                     rel_obj = self.get_queryset(instance=instance).get(**filter_args)\n411                 except self.related.related_model.DoesNotExist:\n412                     rel_obj = None\n413                 else:\n414                     # Set the forward accessor cache on the related object to\n415                     # the current instance to avoid an extra SQL query if it's\n416                     # accessed later on.\n417                     self.related.field.set_cached_value(rel_obj, instance)\n418             self.related.set_cached_value(instance, rel_obj)\n419 \n420         if rel_obj is None:\n421             raise self.RelatedObjectDoesNotExist(\n422                 \"%s has no %s.\" % (\n423                     instance.__class__.__name__,\n424                     self.related.get_accessor_name()\n425                 )\n426             )\n427         else:\n428             return rel_obj\n429 \n430     def __set__(self, instance, value):\n431         \"\"\"\n432         Set the related instance through the reverse relation.\n433 \n434         With the example above, when setting ``place.restaurant = restaurant``:\n435 \n436         - ``self`` is the descriptor managing the ``restaurant`` attribute\n437         - ``instance`` is the ``place`` instance\n438         - ``value`` is the ``restaurant`` instance on the right of the equal sign\n439 \n440         Keep in mind that ``Restaurant`` holds the foreign key to ``Place``.\n441         \"\"\"\n442         # The similarity of the code below to the code in\n443         # ForwardManyToOneDescriptor is annoying, but there's a bunch\n444         # of small differences that would make a common base class convoluted.\n445 \n446         if value is None:\n447             # Update the cached related instance (if any) & clear the cache.\n448             # Following the example above, this would be the cached\n449             # ``restaurant`` instance (if any).\n450             rel_obj = self.related.get_cached_value(instance, default=None)\n451             if rel_obj is not None:\n452                 # Remove the ``restaurant`` instance from the ``place``\n453                 # instance cache.\n454                 self.related.delete_cached_value(instance)\n455                 # Set the ``place`` field on the ``restaurant``\n456                 # instance to None.\n457                 setattr(rel_obj, self.related.field.name, None)\n458         elif not isinstance(value, self.related.related_model):\n459             # An object must be an instance of the related class.\n460             raise ValueError(\n461                 'Cannot assign \"%r\": \"%s.%s\" must be a \"%s\" instance.' % (\n462                     value,\n463                     instance._meta.object_name,\n464                     self.related.get_accessor_name(),\n465                     self.related.related_model._meta.object_name,\n466                 )\n467             )\n468         else:\n469             if instance._state.db is None:\n470                 instance._state.db = router.db_for_write(instance.__class__, instance=value)\n471             if value._state.db is None:\n472                 value._state.db = router.db_for_write(value.__class__, instance=instance)\n473             if not router.allow_relation(value, instance):\n474                 raise ValueError('Cannot assign \"%r\": the current database router prevents this relation.' % value)\n475 \n476             related_pk = tuple(getattr(instance, field.attname) for field in self.related.field.foreign_related_fields)\n477             # Set the value of the related field to the value of the related object's related field\n478             for index, field in enumerate(self.related.field.local_related_fields):\n479                 setattr(value, field.attname, related_pk[index])\n480 \n481             # Set the related instance cache used by __get__ to avoid an SQL query\n482             # when accessing the attribute we just set.\n483             self.related.set_cached_value(instance, value)\n484 \n485             # Set the forward accessor cache on the related object to the current\n486             # instance to avoid an extra SQL query if it's accessed later on.\n487             self.related.field.set_cached_value(value, instance)\n488 \n489     def __reduce__(self):\n490         # Same purpose as ForwardManyToOneDescriptor.__reduce__().\n491         return getattr, (self.related.model, self.related.name)\n492 \n493 \n494 class ReverseManyToOneDescriptor:\n495     \"\"\"\n496     Accessor to the related objects manager on the reverse side of a\n497     many-to-one relation.\n498 \n499     In the example::\n500 \n501         class Child(Model):\n502             parent = ForeignKey(Parent, related_name='children')\n503 \n504     ``Parent.children`` is a ``ReverseManyToOneDescriptor`` instance.\n505 \n506     Most of the implementation is delegated to a dynamically defined manager\n507     class built by ``create_forward_many_to_many_manager()`` defined below.\n508     \"\"\"\n509 \n510     def __init__(self, rel):\n511         self.rel = rel\n512         self.field = rel.field\n513 \n514     @cached_property\n515     def related_manager_cls(self):\n516         related_model = self.rel.related_model\n517 \n518         return create_reverse_many_to_one_manager(\n519             related_model._default_manager.__class__,\n520             self.rel,\n521         )\n522 \n523     def __get__(self, instance, cls=None):\n524         \"\"\"\n525         Get the related objects through the reverse relation.\n526 \n527         With the example above, when getting ``parent.children``:\n528 \n529         - ``self`` is the descriptor managing the ``children`` attribute\n530         - ``instance`` is the ``parent`` instance\n531         - ``cls`` is the ``Parent`` class (unused)\n532         \"\"\"\n533         if instance is None:\n534             return self\n535 \n536         return self.related_manager_cls(instance)\n537 \n538     def _get_set_deprecation_msg_params(self):\n539         return (\n540             'reverse side of a related set',\n541             self.rel.get_accessor_name(),\n542         )\n543 \n544     def __set__(self, instance, value):\n545         raise TypeError(\n546             'Direct assignment to the %s is prohibited. Use %s.set() instead.'\n547             % self._get_set_deprecation_msg_params(),\n548         )\n549 \n550 \n551 def create_reverse_many_to_one_manager(superclass, rel):\n552     \"\"\"\n553     Create a manager for the reverse side of a many-to-one relation.\n554 \n555     This manager subclasses another manager, generally the default manager of\n556     the related model, and adds behaviors specific to many-to-one relations.\n557     \"\"\"\n558 \n559     class RelatedManager(superclass):\n560         def __init__(self, instance):\n561             super().__init__()\n562 \n563             self.instance = instance\n564             self.model = rel.related_model\n565             self.field = rel.field\n566 \n567             self.core_filters = {self.field.name: instance}\n568 \n569         def __call__(self, *, manager):\n570             manager = getattr(self.model, manager)\n571             manager_class = create_reverse_many_to_one_manager(manager.__class__, rel)\n572             return manager_class(self.instance)\n573         do_not_call_in_templates = True\n574 \n575         def _apply_rel_filters(self, queryset):\n576             \"\"\"\n577             Filter the queryset for the instance this manager is bound to.\n578             \"\"\"\n579             db = self._db or router.db_for_read(self.model, instance=self.instance)\n580             empty_strings_as_null = connections[db].features.interprets_empty_strings_as_nulls\n581             queryset._add_hints(instance=self.instance)\n582             if self._db:\n583                 queryset = queryset.using(self._db)\n584             queryset = queryset.filter(**self.core_filters)\n585             for field in self.field.foreign_related_fields:\n586                 val = getattr(self.instance, field.attname)\n587                 if val is None or (val == '' and empty_strings_as_null):\n588                     return queryset.none()\n589             if self.field.many_to_one:\n590                 # Guard against field-like objects such as GenericRelation\n591                 # that abuse create_reverse_many_to_one_manager() with reverse\n592                 # one-to-many relationships instead and break known related\n593                 # objects assignment.\n594                 try:\n595                     target_field = self.field.target_field\n596                 except FieldError:\n597                     # The relationship has multiple target fields. Use a tuple\n598                     # for related object id.\n599                     rel_obj_id = tuple([\n600                         getattr(self.instance, target_field.attname)\n601                         for target_field in self.field.get_path_info()[-1].target_fields\n602                     ])\n603                 else:\n604                     rel_obj_id = getattr(self.instance, target_field.attname)\n605                 queryset._known_related_objects = {self.field: {rel_obj_id: self.instance}}\n606             return queryset\n607 \n608         def _remove_prefetched_objects(self):\n609             try:\n610                 self.instance._prefetched_objects_cache.pop(self.field.remote_field.get_cache_name())\n611             except (AttributeError, KeyError):\n612                 pass  # nothing to clear from cache\n613 \n614         def get_queryset(self):\n615             try:\n616                 return self.instance._prefetched_objects_cache[self.field.remote_field.get_cache_name()]\n617             except (AttributeError, KeyError):\n618                 queryset = super().get_queryset()\n619                 return self._apply_rel_filters(queryset)\n620 \n621         def get_prefetch_queryset(self, instances, queryset=None):\n622             if queryset is None:\n623                 queryset = super().get_queryset()\n624 \n625             queryset._add_hints(instance=instances[0])\n626             queryset = queryset.using(queryset._db or self._db)\n627 \n628             rel_obj_attr = self.field.get_local_related_value\n629             instance_attr = self.field.get_foreign_related_value\n630             instances_dict = {instance_attr(inst): inst for inst in instances}\n631             query = {'%s__in' % self.field.name: instances}\n632             queryset = queryset.filter(**query)\n633 \n634             # Since we just bypassed this class' get_queryset(), we must manage\n635             # the reverse relation manually.\n636             for rel_obj in queryset:\n637                 instance = instances_dict[rel_obj_attr(rel_obj)]\n638                 setattr(rel_obj, self.field.name, instance)\n639             cache_name = self.field.remote_field.get_cache_name()\n640             return queryset, rel_obj_attr, instance_attr, False, cache_name, False\n641 \n642         def add(self, *objs, bulk=True):\n643             self._remove_prefetched_objects()\n644             db = router.db_for_write(self.model, instance=self.instance)\n645 \n646             def check_and_update_obj(obj):\n647                 if not isinstance(obj, self.model):\n648                     raise TypeError(\"'%s' instance expected, got %r\" % (\n649                         self.model._meta.object_name, obj,\n650                     ))\n651                 setattr(obj, self.field.name, self.instance)\n652 \n653             if bulk:\n654                 pks = []\n655                 for obj in objs:\n656                     check_and_update_obj(obj)\n657                     if obj._state.adding or obj._state.db != db:\n658                         raise ValueError(\n659                             \"%r instance isn't saved. Use bulk=False or save \"\n660                             \"the object first.\" % obj\n661                         )\n662                     pks.append(obj.pk)\n663                 self.model._base_manager.using(db).filter(pk__in=pks).update(**{\n664                     self.field.name: self.instance,\n665                 })\n666             else:\n667                 with transaction.atomic(using=db, savepoint=False):\n668                     for obj in objs:\n669                         check_and_update_obj(obj)\n670                         obj.save()\n671         add.alters_data = True\n672 \n673         def create(self, **kwargs):\n674             kwargs[self.field.name] = self.instance\n675             db = router.db_for_write(self.model, instance=self.instance)\n676             return super(RelatedManager, self.db_manager(db)).create(**kwargs)\n677         create.alters_data = True\n678 \n679         def get_or_create(self, **kwargs):\n680             kwargs[self.field.name] = self.instance\n681             db = router.db_for_write(self.model, instance=self.instance)\n682             return super(RelatedManager, self.db_manager(db)).get_or_create(**kwargs)\n683         get_or_create.alters_data = True\n684 \n685         def update_or_create(self, **kwargs):\n686             kwargs[self.field.name] = self.instance\n687             db = router.db_for_write(self.model, instance=self.instance)\n688             return super(RelatedManager, self.db_manager(db)).update_or_create(**kwargs)\n689         update_or_create.alters_data = True\n690 \n691         # remove() and clear() are only provided if the ForeignKey can have a value of null.\n692         if rel.field.null:\n693             def remove(self, *objs, bulk=True):\n694                 if not objs:\n695                     return\n696                 val = self.field.get_foreign_related_value(self.instance)\n697                 old_ids = set()\n698                 for obj in objs:\n699                     if not isinstance(obj, self.model):\n700                         raise TypeError(\"'%s' instance expected, got %r\" % (\n701                             self.model._meta.object_name, obj,\n702                         ))\n703                     # Is obj actually part of this descriptor set?\n704                     if self.field.get_local_related_value(obj) == val:\n705                         old_ids.add(obj.pk)\n706                     else:\n707                         raise self.field.remote_field.model.DoesNotExist(\n708                             \"%r is not related to %r.\" % (obj, self.instance)\n709                         )\n710                 self._clear(self.filter(pk__in=old_ids), bulk)\n711             remove.alters_data = True\n712 \n713             def clear(self, *, bulk=True):\n714                 self._clear(self, bulk)\n715             clear.alters_data = True\n716 \n717             def _clear(self, queryset, bulk):\n718                 self._remove_prefetched_objects()\n719                 db = router.db_for_write(self.model, instance=self.instance)\n720                 queryset = queryset.using(db)\n721                 if bulk:\n722                     # `QuerySet.update()` is intrinsically atomic.\n723                     queryset.update(**{self.field.name: None})\n724                 else:\n725                     with transaction.atomic(using=db, savepoint=False):\n726                         for obj in queryset:\n727                             setattr(obj, self.field.name, None)\n728                             obj.save(update_fields=[self.field.name])\n729             _clear.alters_data = True\n730 \n731         def set(self, objs, *, bulk=True, clear=False):\n732             # Force evaluation of `objs` in case it's a queryset whose value\n733             # could be affected by `manager.clear()`. Refs #19816.\n734             objs = tuple(objs)\n735 \n736             if self.field.null:\n737                 db = router.db_for_write(self.model, instance=self.instance)\n738                 with transaction.atomic(using=db, savepoint=False):\n739                     if clear:\n740                         self.clear(bulk=bulk)\n741                         self.add(*objs, bulk=bulk)\n742                     else:\n743                         old_objs = set(self.using(db).all())\n744                         new_objs = []\n745                         for obj in objs:\n746                             if obj in old_objs:\n747                                 old_objs.remove(obj)\n748                             else:\n749                                 new_objs.append(obj)\n750 \n751                         self.remove(*old_objs, bulk=bulk)\n752                         self.add(*new_objs, bulk=bulk)\n753             else:\n754                 self.add(*objs, bulk=bulk)\n755         set.alters_data = True\n756 \n757     return RelatedManager\n758 \n759 \n760 class ManyToManyDescriptor(ReverseManyToOneDescriptor):\n761     \"\"\"\n762     Accessor to the related objects manager on the forward and reverse sides of\n763     a many-to-many relation.\n764 \n765     In the example::\n766 \n767         class Pizza(Model):\n768             toppings = ManyToManyField(Topping, related_name='pizzas')\n769 \n770     ``Pizza.toppings`` and ``Topping.pizzas`` are ``ManyToManyDescriptor``\n771     instances.\n772 \n773     Most of the implementation is delegated to a dynamically defined manager\n774     class built by ``create_forward_many_to_many_manager()`` defined below.\n775     \"\"\"\n776 \n777     def __init__(self, rel, reverse=False):\n778         super().__init__(rel)\n779 \n780         self.reverse = reverse\n781 \n782     @property\n783     def through(self):\n784         # through is provided so that you have easy access to the through\n785         # model (Book.authors.through) for inlines, etc. This is done as\n786         # a property to ensure that the fully resolved value is returned.\n787         return self.rel.through\n788 \n789     @cached_property\n790     def related_manager_cls(self):\n791         related_model = self.rel.related_model if self.reverse else self.rel.model\n792 \n793         return create_forward_many_to_many_manager(\n794             related_model._default_manager.__class__,\n795             self.rel,\n796             reverse=self.reverse,\n797         )\n798 \n799     def _get_set_deprecation_msg_params(self):\n800         return (\n801             '%s side of a many-to-many set' % ('reverse' if self.reverse else 'forward'),\n802             self.rel.get_accessor_name() if self.reverse else self.field.name,\n803         )\n804 \n805 \n806 def create_forward_many_to_many_manager(superclass, rel, reverse):\n807     \"\"\"\n808     Create a manager for the either side of a many-to-many relation.\n809 \n810     This manager subclasses another manager, generally the default manager of\n811     the related model, and adds behaviors specific to many-to-many relations.\n812     \"\"\"\n813 \n814     class ManyRelatedManager(superclass):\n815         def __init__(self, instance=None):\n816             super().__init__()\n817 \n818             self.instance = instance\n819 \n820             if not reverse:\n821                 self.model = rel.model\n822                 self.query_field_name = rel.field.related_query_name()\n823                 self.prefetch_cache_name = rel.field.name\n824                 self.source_field_name = rel.field.m2m_field_name()\n825                 self.target_field_name = rel.field.m2m_reverse_field_name()\n826                 self.symmetrical = rel.symmetrical\n827             else:\n828                 self.model = rel.related_model\n829                 self.query_field_name = rel.field.name\n830                 self.prefetch_cache_name = rel.field.related_query_name()\n831                 self.source_field_name = rel.field.m2m_reverse_field_name()\n832                 self.target_field_name = rel.field.m2m_field_name()\n833                 self.symmetrical = False\n834 \n835             self.through = rel.through\n836             self.reverse = reverse\n837 \n838             self.source_field = self.through._meta.get_field(self.source_field_name)\n839             self.target_field = self.through._meta.get_field(self.target_field_name)\n840 \n841             self.core_filters = {}\n842             self.pk_field_names = {}\n843             for lh_field, rh_field in self.source_field.related_fields:\n844                 core_filter_key = '%s__%s' % (self.query_field_name, rh_field.name)\n845                 self.core_filters[core_filter_key] = getattr(instance, rh_field.attname)\n846                 self.pk_field_names[lh_field.name] = rh_field.name\n847 \n848             self.related_val = self.source_field.get_foreign_related_value(instance)\n849             if None in self.related_val:\n850                 raise ValueError('\"%r\" needs to have a value for field \"%s\" before '\n851                                  'this many-to-many relationship can be used.' %\n852                                  (instance, self.pk_field_names[self.source_field_name]))\n853             # Even if this relation is not to pk, we require still pk value.\n854             # The wish is that the instance has been already saved to DB,\n855             # although having a pk value isn't a guarantee of that.\n856             if instance.pk is None:\n857                 raise ValueError(\"%r instance needs to have a primary key value before \"\n858                                  \"a many-to-many relationship can be used.\" %\n859                                  instance.__class__.__name__)\n860 \n861         def __call__(self, *, manager):\n862             manager = getattr(self.model, manager)\n863             manager_class = create_forward_many_to_many_manager(manager.__class__, rel, reverse)\n864             return manager_class(instance=self.instance)\n865         do_not_call_in_templates = True\n866 \n867         def _build_remove_filters(self, removed_vals):\n868             filters = Q(**{self.source_field_name: self.related_val})\n869             # No need to add a subquery condition if removed_vals is a QuerySet without\n870             # filters.\n871             removed_vals_filters = (not isinstance(removed_vals, QuerySet) or\n872                                     removed_vals._has_filters())\n873             if removed_vals_filters:\n874                 filters &= Q(**{'%s__in' % self.target_field_name: removed_vals})\n875             if self.symmetrical:\n876                 symmetrical_filters = Q(**{self.target_field_name: self.related_val})\n877                 if removed_vals_filters:\n878                     symmetrical_filters &= Q(\n879                         **{'%s__in' % self.source_field_name: removed_vals})\n880                 filters |= symmetrical_filters\n881             return filters\n882 \n883         def _apply_rel_filters(self, queryset):\n884             \"\"\"\n885             Filter the queryset for the instance this manager is bound to.\n886             \"\"\"\n887             queryset._add_hints(instance=self.instance)\n888             if self._db:\n889                 queryset = queryset.using(self._db)\n890             queryset._defer_next_filter = True\n891             return queryset._next_is_sticky().filter(**self.core_filters)\n892 \n893         def _remove_prefetched_objects(self):\n894             try:\n895                 self.instance._prefetched_objects_cache.pop(self.prefetch_cache_name)\n896             except (AttributeError, KeyError):\n897                 pass  # nothing to clear from cache\n898 \n899         def get_queryset(self):\n900             try:\n901                 return self.instance._prefetched_objects_cache[self.prefetch_cache_name]\n902             except (AttributeError, KeyError):\n903                 queryset = super().get_queryset()\n904                 return self._apply_rel_filters(queryset)\n905 \n906         def get_prefetch_queryset(self, instances, queryset=None):\n907             if queryset is None:\n908                 queryset = super().get_queryset()\n909 \n910             queryset._add_hints(instance=instances[0])\n911             queryset = queryset.using(queryset._db or self._db)\n912 \n913             query = {'%s__in' % self.query_field_name: instances}\n914             queryset = queryset._next_is_sticky().filter(**query)\n915 \n916             # M2M: need to annotate the query in order to get the primary model\n917             # that the secondary model was actually related to. We know that\n918             # there will already be a join on the join table, so we can just add\n919             # the select.\n920 \n921             # For non-autocreated 'through' models, can't assume we are\n922             # dealing with PK values.\n923             fk = self.through._meta.get_field(self.source_field_name)\n924             join_table = fk.model._meta.db_table\n925             connection = connections[queryset.db]\n926             qn = connection.ops.quote_name\n927             queryset = queryset.extra(select={\n928                 '_prefetch_related_val_%s' % f.attname:\n929                 '%s.%s' % (qn(join_table), qn(f.column)) for f in fk.local_related_fields})\n930             return (\n931                 queryset,\n932                 lambda result: tuple(\n933                     getattr(result, '_prefetch_related_val_%s' % f.attname)\n934                     for f in fk.local_related_fields\n935                 ),\n936                 lambda inst: tuple(\n937                     f.get_db_prep_value(getattr(inst, f.attname), connection)\n938                     for f in fk.foreign_related_fields\n939                 ),\n940                 False,\n941                 self.prefetch_cache_name,\n942                 False,\n943             )\n944 \n945         def add(self, *objs, through_defaults=None):\n946             self._remove_prefetched_objects()\n947             db = router.db_for_write(self.through, instance=self.instance)\n948             with transaction.atomic(using=db, savepoint=False):\n949                 self._add_items(\n950                     self.source_field_name, self.target_field_name, *objs,\n951                     through_defaults=through_defaults,\n952                 )\n953                 # If this is a symmetrical m2m relation to self, add the mirror\n954                 # entry in the m2m table.\n955                 if self.symmetrical:\n956                     self._add_items(\n957                         self.target_field_name,\n958                         self.source_field_name,\n959                         *objs,\n960                         through_defaults=through_defaults,\n961                     )\n962         add.alters_data = True\n963 \n964         def remove(self, *objs):\n965             self._remove_prefetched_objects()\n966             self._remove_items(self.source_field_name, self.target_field_name, *objs)\n967         remove.alters_data = True\n968 \n969         def clear(self):\n970             db = router.db_for_write(self.through, instance=self.instance)\n971             with transaction.atomic(using=db, savepoint=False):\n972                 signals.m2m_changed.send(\n973                     sender=self.through, action=\"pre_clear\",\n974                     instance=self.instance, reverse=self.reverse,\n975                     model=self.model, pk_set=None, using=db,\n976                 )\n977                 self._remove_prefetched_objects()\n978                 filters = self._build_remove_filters(super().get_queryset().using(db))\n979                 self.through._default_manager.using(db).filter(filters).delete()\n980 \n981                 signals.m2m_changed.send(\n982                     sender=self.through, action=\"post_clear\",\n983                     instance=self.instance, reverse=self.reverse,\n984                     model=self.model, pk_set=None, using=db,\n985                 )\n986         clear.alters_data = True\n987 \n988         def set(self, objs, *, clear=False, through_defaults=None):\n989             # Force evaluation of `objs` in case it's a queryset whose value\n990             # could be affected by `manager.clear()`. Refs #19816.\n991             objs = tuple(objs)\n992 \n993             db = router.db_for_write(self.through, instance=self.instance)\n994             with transaction.atomic(using=db, savepoint=False):\n995                 if clear:\n996                     self.clear()\n997                     self.add(*objs, through_defaults=through_defaults)\n998                 else:\n999                     old_ids = set(self.using(db).values_list(self.target_field.target_field.attname, flat=True))\n1000 \n1001                     new_objs = []\n1002                     for obj in objs:\n1003                         fk_val = (\n1004                             self.target_field.get_foreign_related_value(obj)[0]\n1005                             if isinstance(obj, self.model)\n1006                             else self.target_field.get_prep_value(obj)\n1007                         )\n1008                         if fk_val in old_ids:\n1009                             old_ids.remove(fk_val)\n1010                         else:\n1011                             new_objs.append(obj)\n1012 \n1013                     self.remove(*old_ids)\n1014                     self.add(*new_objs, through_defaults=through_defaults)\n1015         set.alters_data = True\n1016 \n1017         def create(self, *, through_defaults=None, **kwargs):\n1018             db = router.db_for_write(self.instance.__class__, instance=self.instance)\n1019             new_obj = super(ManyRelatedManager, self.db_manager(db)).create(**kwargs)\n1020             self.add(new_obj, through_defaults=through_defaults)\n1021             return new_obj\n1022         create.alters_data = True\n1023 \n1024         def get_or_create(self, *, through_defaults=None, **kwargs):\n1025             db = router.db_for_write(self.instance.__class__, instance=self.instance)\n1026             obj, created = super(ManyRelatedManager, self.db_manager(db)).get_or_create(**kwargs)\n1027             # We only need to add() if created because if we got an object back\n1028             # from get() then the relationship already exists.\n1029             if created:\n1030                 self.add(obj, through_defaults=through_defaults)\n1031             return obj, created\n1032         get_or_create.alters_data = True\n1033 \n1034         def update_or_create(self, *, through_defaults=None, **kwargs):\n1035             db = router.db_for_write(self.instance.__class__, instance=self.instance)\n1036             obj, created = super(ManyRelatedManager, self.db_manager(db)).update_or_create(**kwargs)\n1037             # We only need to add() if created because if we got an object back\n1038             # from get() then the relationship already exists.\n1039             if created:\n1040                 self.add(obj, through_defaults=through_defaults)\n1041             return obj, created\n1042         update_or_create.alters_data = True\n1043 \n1044         def _get_target_ids(self, target_field_name, objs):\n1045             \"\"\"\n1046             Return the set of ids of `objs` that the target field references.\n1047             \"\"\"\n1048             from django.db.models import Model\n1049             target_ids = set()\n1050             target_field = self.through._meta.get_field(target_field_name)\n1051             for obj in objs:\n1052                 if isinstance(obj, self.model):\n1053                     if not router.allow_relation(obj, self.instance):\n1054                         raise ValueError(\n1055                             'Cannot add \"%r\": instance is on database \"%s\", '\n1056                             'value is on database \"%s\"' %\n1057                             (obj, self.instance._state.db, obj._state.db)\n1058                         )\n1059                     target_id = target_field.get_foreign_related_value(obj)[0]\n1060                     if target_id is None:\n1061                         raise ValueError(\n1062                             'Cannot add \"%r\": the value for field \"%s\" is None' %\n1063                             (obj, target_field_name)\n1064                         )\n1065                     target_ids.add(target_id)\n1066                 elif isinstance(obj, Model):\n1067                     raise TypeError(\n1068                         \"'%s' instance expected, got %r\" %\n1069                         (self.model._meta.object_name, obj)\n1070                     )\n1071                 else:\n1072                     target_ids.add(target_field.get_prep_value(obj))\n1073             return target_ids\n1074 \n1075         def _get_missing_target_ids(self, source_field_name, target_field_name, db, target_ids):\n1076             \"\"\"\n1077             Return the subset of ids of `objs` that aren't already assigned to\n1078             this relationship.\n1079             \"\"\"\n1080             vals = self.through._default_manager.using(db).values_list(\n1081                 target_field_name, flat=True\n1082             ).filter(**{\n1083                 source_field_name: self.related_val[0],\n1084                 '%s__in' % target_field_name: target_ids,\n1085             })\n1086             return target_ids.difference(vals)\n1087 \n1088         def _get_add_plan(self, db, source_field_name):\n1089             \"\"\"\n1090             Return a boolean triple of the way the add should be performed.\n1091 \n1092             The first element is whether or not bulk_create(ignore_conflicts)\n1093             can be used, the second whether or not signals must be sent, and\n1094             the third element is whether or not the immediate bulk insertion\n1095             with conflicts ignored can be performed.\n1096             \"\"\"\n1097             # Conflicts can be ignored when the intermediary model is\n1098             # auto-created as the only possible collision is on the\n1099             # (source_id, target_id) tuple. The same assertion doesn't hold for\n1100             # user-defined intermediary models as they could have other fields\n1101             # causing conflicts which must be surfaced.\n1102             can_ignore_conflicts = (\n1103                 connections[db].features.supports_ignore_conflicts and\n1104                 self.through._meta.auto_created is not False\n1105             )\n1106             # Don't send the signal when inserting duplicate data row\n1107             # for symmetrical reverse entries.\n1108             must_send_signals = (self.reverse or source_field_name == self.source_field_name) and (\n1109                 signals.m2m_changed.has_listeners(self.through)\n1110             )\n1111             # Fast addition through bulk insertion can only be performed\n1112             # if no m2m_changed listeners are connected for self.through\n1113             # as they require the added set of ids to be provided via\n1114             # pk_set.\n1115             return can_ignore_conflicts, must_send_signals, (can_ignore_conflicts and not must_send_signals)\n1116 \n1117         def _add_items(self, source_field_name, target_field_name, *objs, through_defaults=None):\n1118             # source_field_name: the PK fieldname in join table for the source object\n1119             # target_field_name: the PK fieldname in join table for the target object\n1120             # *objs - objects to add. Either object instances, or primary keys of object instances.\n1121             if not objs:\n1122                 return\n1123 \n1124             through_defaults = dict(resolve_callables(through_defaults or {}))\n1125             target_ids = self._get_target_ids(target_field_name, objs)\n1126             db = router.db_for_write(self.through, instance=self.instance)\n1127             can_ignore_conflicts, must_send_signals, can_fast_add = self._get_add_plan(db, source_field_name)\n1128             if can_fast_add:\n1129                 self.through._default_manager.using(db).bulk_create([\n1130                     self.through(**{\n1131                         '%s_id' % source_field_name: self.related_val[0],\n1132                         '%s_id' % target_field_name: target_id,\n1133                     })\n1134                     for target_id in target_ids\n1135                 ], ignore_conflicts=True)\n1136                 return\n1137 \n1138             missing_target_ids = self._get_missing_target_ids(\n1139                 source_field_name, target_field_name, db, target_ids\n1140             )\n1141             with transaction.atomic(using=db, savepoint=False):\n1142                 if must_send_signals:\n1143                     signals.m2m_changed.send(\n1144                         sender=self.through, action='pre_add',\n1145                         instance=self.instance, reverse=self.reverse,\n1146                         model=self.model, pk_set=missing_target_ids, using=db,\n1147                     )\n1148                 # Add the ones that aren't there already.\n1149                 self.through._default_manager.using(db).bulk_create([\n1150                     self.through(**through_defaults, **{\n1151                         '%s_id' % source_field_name: self.related_val[0],\n1152                         '%s_id' % target_field_name: target_id,\n1153                     })\n1154                     for target_id in missing_target_ids\n1155                 ], ignore_conflicts=can_ignore_conflicts)\n1156 \n1157                 if must_send_signals:\n1158                     signals.m2m_changed.send(\n1159                         sender=self.through, action='post_add',\n1160                         instance=self.instance, reverse=self.reverse,\n1161                         model=self.model, pk_set=missing_target_ids, using=db,\n1162                     )\n1163 \n1164         def _remove_items(self, source_field_name, target_field_name, *objs):\n1165             # source_field_name: the PK colname in join table for the source object\n1166             # target_field_name: the PK colname in join table for the target object\n1167             # *objs - objects to remove. Either object instances, or primary\n1168             # keys of object instances.\n1169             if not objs:\n1170                 return\n1171 \n1172             # Check that all the objects are of the right type\n1173             old_ids = set()\n1174             for obj in objs:\n1175                 if isinstance(obj, self.model):\n1176                     fk_val = self.target_field.get_foreign_related_value(obj)[0]\n1177                     old_ids.add(fk_val)\n1178                 else:\n1179                     old_ids.add(obj)\n1180 \n1181             db = router.db_for_write(self.through, instance=self.instance)\n1182             with transaction.atomic(using=db, savepoint=False):\n1183                 # Send a signal to the other end if need be.\n1184                 signals.m2m_changed.send(\n1185                     sender=self.through, action=\"pre_remove\",\n1186                     instance=self.instance, reverse=self.reverse,\n1187                     model=self.model, pk_set=old_ids, using=db,\n1188                 )\n1189                 target_model_qs = super().get_queryset()\n1190                 if target_model_qs._has_filters():\n1191                     old_vals = target_model_qs.using(db).filter(**{\n1192                         '%s__in' % self.target_field.target_field.attname: old_ids})\n1193                 else:\n1194                     old_vals = old_ids\n1195                 filters = self._build_remove_filters(old_vals)\n1196                 self.through._default_manager.using(db).filter(filters).delete()\n1197 \n1198                 signals.m2m_changed.send(\n1199                     sender=self.through, action=\"post_remove\",\n1200                     instance=self.instance, reverse=self.reverse,\n1201                     model=self.model, pk_set=old_ids, using=db,\n1202                 )\n1203 \n1204     return ManyRelatedManager\n",
        "intended_behavior": "Assess and possibly modify the handling of FK fields in the context of model instance copying. Since FK relationships are a central concern in the reported issue, ensure that any copying or cloning of model instances properly updates FK references in the newly created instance without inadvertently altering the original instance's state. This might require implementing deep copy logic specific to FK fields or enhancing how Django's model layer treats FK fields during any form of instance duplication."
    }
]