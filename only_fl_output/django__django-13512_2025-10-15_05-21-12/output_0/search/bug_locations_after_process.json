[
    {
        "rel_file_path": "django/db/models/fields/json.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.2/django/db/models/fields/json.py",
        "start": 1,
        "end": 520,
        "class_name": null,
        "method_name": null,
        "code": "1 import json\n2 \n3 from django import forms\n4 from django.core import checks, exceptions\n5 from django.db import NotSupportedError, connections, router\n6 from django.db.models import lookups\n7 from django.db.models.lookups import PostgresOperatorLookup, Transform\n8 from django.utils.translation import gettext_lazy as _\n9 \n10 from . import Field\n11 from .mixins import CheckFieldDefaultMixin\n12 \n13 __all__ = ['JSONField']\n14 \n15 \n16 class JSONField(CheckFieldDefaultMixin, Field):\n17     empty_strings_allowed = False\n18     description = _('A JSON object')\n19     default_error_messages = {\n20         'invalid': _('Value must be valid JSON.'),\n21     }\n22     _default_hint = ('dict', '{}')\n23 \n24     def __init__(\n25         self, verbose_name=None, name=None, encoder=None, decoder=None,\n26         **kwargs,\n27     ):\n28         if encoder and not callable(encoder):\n29             raise ValueError('The encoder parameter must be a callable object.')\n30         if decoder and not callable(decoder):\n31             raise ValueError('The decoder parameter must be a callable object.')\n32         self.encoder = encoder\n33         self.decoder = decoder\n34         super().__init__(verbose_name, name, **kwargs)\n35 \n36     def check(self, **kwargs):\n37         errors = super().check(**kwargs)\n38         databases = kwargs.get('databases') or []\n39         errors.extend(self._check_supported(databases))\n40         return errors\n41 \n42     def _check_supported(self, databases):\n43         errors = []\n44         for db in databases:\n45             if not router.allow_migrate_model(db, self.model):\n46                 continue\n47             connection = connections[db]\n48             if not (\n49                 'supports_json_field' in self.model._meta.required_db_features or\n50                 connection.features.supports_json_field\n51             ):\n52                 errors.append(\n53                     checks.Error(\n54                         '%s does not support JSONFields.'\n55                         % connection.display_name,\n56                         obj=self.model,\n57                         id='fields.E180',\n58                     )\n59                 )\n60         return errors\n61 \n62     def deconstruct(self):\n63         name, path, args, kwargs = super().deconstruct()\n64         if self.encoder is not None:\n65             kwargs['encoder'] = self.encoder\n66         if self.decoder is not None:\n67             kwargs['decoder'] = self.decoder\n68         return name, path, args, kwargs\n69 \n70     def from_db_value(self, value, expression, connection):\n71         if value is None:\n72             return value\n73         try:\n74             return json.loads(value, cls=self.decoder)\n75         except json.JSONDecodeError:\n76             return value\n77 \n78     def get_internal_type(self):\n79         return 'JSONField'\n80 \n81     def get_prep_value(self, value):\n82         if value is None:\n83             return value\n84         return json.dumps(value, cls=self.encoder)\n85 \n86     def get_transform(self, name):\n87         transform = super().get_transform(name)\n88         if transform:\n89             return transform\n90         return KeyTransformFactory(name)\n91 \n92     def validate(self, value, model_instance):\n93         super().validate(value, model_instance)\n94         try:\n95             json.dumps(value, cls=self.encoder)\n96         except TypeError:\n97             raise exceptions.ValidationError(\n98                 self.error_messages['invalid'],\n99                 code='invalid',\n100                 params={'value': value},\n101             )\n102 \n103     def value_to_string(self, obj):\n104         return self.value_from_object(obj)\n105 \n106     def formfield(self, **kwargs):\n107         return super().formfield(**{\n108             'form_class': forms.JSONField,\n109             'encoder': self.encoder,\n110             'decoder': self.decoder,\n111             **kwargs,\n112         })\n113 \n114 \n115 def compile_json_path(key_transforms, include_root=True):\n116     path = ['$'] if include_root else []\n117     for key_transform in key_transforms:\n118         try:\n119             num = int(key_transform)\n120         except ValueError:  # non-integer\n121             path.append('.')\n122             path.append(json.dumps(key_transform))\n123         else:\n124             path.append('[%s]' % num)\n125     return ''.join(path)\n126 \n127 \n128 class DataContains(PostgresOperatorLookup):\n129     lookup_name = 'contains'\n130     postgres_operator = '@>'\n131 \n132     def as_sql(self, compiler, connection):\n133         if not connection.features.supports_json_field_contains:\n134             raise NotSupportedError(\n135                 'contains lookup is not supported on this database backend.'\n136             )\n137         lhs, lhs_params = self.process_lhs(compiler, connection)\n138         rhs, rhs_params = self.process_rhs(compiler, connection)\n139         params = tuple(lhs_params) + tuple(rhs_params)\n140         return 'JSON_CONTAINS(%s, %s)' % (lhs, rhs), params\n141 \n142 \n143 class ContainedBy(PostgresOperatorLookup):\n144     lookup_name = 'contained_by'\n145     postgres_operator = '<@'\n146 \n147     def as_sql(self, compiler, connection):\n148         if not connection.features.supports_json_field_contains:\n149             raise NotSupportedError(\n150                 'contained_by lookup is not supported on this database backend.'\n151             )\n152         lhs, lhs_params = self.process_lhs(compiler, connection)\n153         rhs, rhs_params = self.process_rhs(compiler, connection)\n154         params = tuple(rhs_params) + tuple(lhs_params)\n155         return 'JSON_CONTAINS(%s, %s)' % (rhs, lhs), params\n156 \n157 \n158 class HasKeyLookup(PostgresOperatorLookup):\n159     logical_operator = None\n160 \n161     def as_sql(self, compiler, connection, template=None):\n162         # Process JSON path from the left-hand side.\n163         if isinstance(self.lhs, KeyTransform):\n164             lhs, lhs_params, lhs_key_transforms = self.lhs.preprocess_lhs(compiler, connection)\n165             lhs_json_path = compile_json_path(lhs_key_transforms)\n166         else:\n167             lhs, lhs_params = self.process_lhs(compiler, connection)\n168             lhs_json_path = '$'\n169         sql = template % lhs\n170         # Process JSON path from the right-hand side.\n171         rhs = self.rhs\n172         rhs_params = []\n173         if not isinstance(rhs, (list, tuple)):\n174             rhs = [rhs]\n175         for key in rhs:\n176             if isinstance(key, KeyTransform):\n177                 *_, rhs_key_transforms = key.preprocess_lhs(compiler, connection)\n178             else:\n179                 rhs_key_transforms = [key]\n180             rhs_params.append('%s%s' % (\n181                 lhs_json_path,\n182                 compile_json_path(rhs_key_transforms, include_root=False),\n183             ))\n184         # Add condition for each key.\n185         if self.logical_operator:\n186             sql = '(%s)' % self.logical_operator.join([sql] * len(rhs_params))\n187         return sql, tuple(lhs_params) + tuple(rhs_params)\n188 \n189     def as_mysql(self, compiler, connection):\n190         return self.as_sql(compiler, connection, template=\"JSON_CONTAINS_PATH(%s, 'one', %%s)\")\n191 \n192     def as_oracle(self, compiler, connection):\n193         sql, params = self.as_sql(compiler, connection, template=\"JSON_EXISTS(%s, '%%s')\")\n194         # Add paths directly into SQL because path expressions cannot be passed\n195         # as bind variables on Oracle.\n196         return sql % tuple(params), []\n197 \n198     def as_postgresql(self, compiler, connection):\n199         if isinstance(self.rhs, KeyTransform):\n200             *_, rhs_key_transforms = self.rhs.preprocess_lhs(compiler, connection)\n201             for key in rhs_key_transforms[:-1]:\n202                 self.lhs = KeyTransform(key, self.lhs)\n203             self.rhs = rhs_key_transforms[-1]\n204         return super().as_postgresql(compiler, connection)\n205 \n206     def as_sqlite(self, compiler, connection):\n207         return self.as_sql(compiler, connection, template='JSON_TYPE(%s, %%s) IS NOT NULL')\n208 \n209 \n210 class HasKey(HasKeyLookup):\n211     lookup_name = 'has_key'\n212     postgres_operator = '?'\n213     prepare_rhs = False\n214 \n215 \n216 class HasKeys(HasKeyLookup):\n217     lookup_name = 'has_keys'\n218     postgres_operator = '?&'\n219     logical_operator = ' AND '\n220 \n221     def get_prep_lookup(self):\n222         return [str(item) for item in self.rhs]\n223 \n224 \n225 class HasAnyKeys(HasKeys):\n226     lookup_name = 'has_any_keys'\n227     postgres_operator = '?|'\n228     logical_operator = ' OR '\n229 \n230 \n231 class JSONExact(lookups.Exact):\n232     can_use_none_as_rhs = True\n233 \n234     def process_lhs(self, compiler, connection):\n235         lhs, lhs_params = super().process_lhs(compiler, connection)\n236         if connection.vendor == 'sqlite':\n237             rhs, rhs_params = super().process_rhs(compiler, connection)\n238             if rhs == '%s' and rhs_params == [None]:\n239                 # Use JSON_TYPE instead of JSON_EXTRACT for NULLs.\n240                 lhs = \"JSON_TYPE(%s, '$')\" % lhs\n241         return lhs, lhs_params\n242 \n243     def process_rhs(self, compiler, connection):\n244         rhs, rhs_params = super().process_rhs(compiler, connection)\n245         # Treat None lookup values as null.\n246         if rhs == '%s' and rhs_params == [None]:\n247             rhs_params = ['null']\n248         if connection.vendor == 'mysql':\n249             func = [\"JSON_EXTRACT(%s, '$')\"] * len(rhs_params)\n250             rhs = rhs % tuple(func)\n251         return rhs, rhs_params\n252 \n253 \n254 JSONField.register_lookup(DataContains)\n255 JSONField.register_lookup(ContainedBy)\n256 JSONField.register_lookup(HasKey)\n257 JSONField.register_lookup(HasKeys)\n258 JSONField.register_lookup(HasAnyKeys)\n259 JSONField.register_lookup(JSONExact)\n260 \n261 \n262 class KeyTransform(Transform):\n263     postgres_operator = '->'\n264     postgres_nested_operator = '#>'\n265 \n266     def __init__(self, key_name, *args, **kwargs):\n267         super().__init__(*args, **kwargs)\n268         self.key_name = str(key_name)\n269 \n270     def preprocess_lhs(self, compiler, connection, lhs_only=False):\n271         if not lhs_only:\n272             key_transforms = [self.key_name]\n273         previous = self.lhs\n274         while isinstance(previous, KeyTransform):\n275             if not lhs_only:\n276                 key_transforms.insert(0, previous.key_name)\n277             previous = previous.lhs\n278         lhs, params = compiler.compile(previous)\n279         if connection.vendor == 'oracle':\n280             # Escape string-formatting.\n281             key_transforms = [key.replace('%', '%%') for key in key_transforms]\n282         return (lhs, params, key_transforms) if not lhs_only else (lhs, params)\n283 \n284     def as_mysql(self, compiler, connection):\n285         lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)\n286         json_path = compile_json_path(key_transforms)\n287         return 'JSON_EXTRACT(%s, %%s)' % lhs, tuple(params) + (json_path,)\n288 \n289     def as_oracle(self, compiler, connection):\n290         lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)\n291         json_path = compile_json_path(key_transforms)\n292         return (\n293             \"COALESCE(JSON_QUERY(%s, '%s'), JSON_VALUE(%s, '%s'))\" %\n294             ((lhs, json_path) * 2)\n295         ), tuple(params) * 2\n296 \n297     def as_postgresql(self, compiler, connection):\n298         lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)\n299         if len(key_transforms) > 1:\n300             return '(%s %s %%s)' % (lhs, self.postgres_nested_operator), params + [key_transforms]\n301         try:\n302             lookup = int(self.key_name)\n303         except ValueError:\n304             lookup = self.key_name\n305         return '(%s %s %%s)' % (lhs, self.postgres_operator), tuple(params) + (lookup,)\n306 \n307     def as_sqlite(self, compiler, connection):\n308         lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)\n309         json_path = compile_json_path(key_transforms)\n310         return 'JSON_EXTRACT(%s, %%s)' % lhs, tuple(params) + (json_path,)\n311 \n312 \n313 class KeyTextTransform(KeyTransform):\n314     postgres_operator = '->>'\n315     postgres_nested_operator = '#>>'\n316 \n317 \n318 class KeyTransformTextLookupMixin:\n319     \"\"\"\n320     Mixin for combining with a lookup expecting a text lhs from a JSONField\n321     key lookup. On PostgreSQL, make use of the ->> operator instead of casting\n322     key values to text and performing the lookup on the resulting\n323     representation.\n324     \"\"\"\n325     def __init__(self, key_transform, *args, **kwargs):\n326         if not isinstance(key_transform, KeyTransform):\n327             raise TypeError(\n328                 'Transform should be an instance of KeyTransform in order to '\n329                 'use this lookup.'\n330             )\n331         key_text_transform = KeyTextTransform(\n332             key_transform.key_name, *key_transform.source_expressions,\n333             **key_transform.extra,\n334         )\n335         super().__init__(key_text_transform, *args, **kwargs)\n336 \n337 \n338 class CaseInsensitiveMixin:\n339     \"\"\"\n340     Mixin to allow case-insensitive comparison of JSON values on MySQL.\n341     MySQL handles strings used in JSON context using the utf8mb4_bin collation.\n342     Because utf8mb4_bin is a binary collation, comparison of JSON values is\n343     case-sensitive.\n344     \"\"\"\n345     def process_lhs(self, compiler, connection):\n346         lhs, lhs_params = super().process_lhs(compiler, connection)\n347         if connection.vendor == 'mysql':\n348             return 'LOWER(%s)' % lhs, lhs_params\n349         return lhs, lhs_params\n350 \n351     def process_rhs(self, compiler, connection):\n352         rhs, rhs_params = super().process_rhs(compiler, connection)\n353         if connection.vendor == 'mysql':\n354             return 'LOWER(%s)' % rhs, rhs_params\n355         return rhs, rhs_params\n356 \n357 \n358 class KeyTransformIsNull(lookups.IsNull):\n359     # key__isnull=False is the same as has_key='key'\n360     def as_oracle(self, compiler, connection):\n361         if not self.rhs:\n362             return HasKey(self.lhs.lhs, self.lhs.key_name).as_oracle(compiler, connection)\n363         return super().as_sql(compiler, connection)\n364 \n365     def as_sqlite(self, compiler, connection):\n366         if not self.rhs:\n367             return HasKey(self.lhs.lhs, self.lhs.key_name).as_sqlite(compiler, connection)\n368         return super().as_sql(compiler, connection)\n369 \n370 \n371 class KeyTransformIn(lookups.In):\n372     def process_rhs(self, compiler, connection):\n373         rhs, rhs_params = super().process_rhs(compiler, connection)\n374         if not connection.features.has_native_json_field:\n375             func = ()\n376             if connection.vendor == 'oracle':\n377                 func = []\n378                 for value in rhs_params:\n379                     value = json.loads(value)\n380                     function = 'JSON_QUERY' if isinstance(value, (list, dict)) else 'JSON_VALUE'\n381                     func.append(\"%s('%s', '$.value')\" % (\n382                         function,\n383                         json.dumps({'value': value}),\n384                     ))\n385                 func = tuple(func)\n386                 rhs_params = ()\n387             elif connection.vendor == 'mysql' and connection.mysql_is_mariadb:\n388                 func = (\"JSON_UNQUOTE(JSON_EXTRACT(%s, '$'))\",) * len(rhs_params)\n389             elif connection.vendor in {'sqlite', 'mysql'}:\n390                 func = (\"JSON_EXTRACT(%s, '$')\",) * len(rhs_params)\n391             rhs = rhs % func\n392         return rhs, rhs_params\n393 \n394 \n395 class KeyTransformExact(JSONExact):\n396     def process_lhs(self, compiler, connection):\n397         lhs, lhs_params = super().process_lhs(compiler, connection)\n398         if connection.vendor == 'sqlite':\n399             rhs, rhs_params = super().process_rhs(compiler, connection)\n400             if rhs == '%s' and rhs_params == ['null']:\n401                 lhs, _ = self.lhs.preprocess_lhs(compiler, connection, lhs_only=True)\n402                 lhs = 'JSON_TYPE(%s, %%s)' % lhs\n403         return lhs, lhs_params\n404 \n405     def process_rhs(self, compiler, connection):\n406         if isinstance(self.rhs, KeyTransform):\n407             return super(lookups.Exact, self).process_rhs(compiler, connection)\n408         rhs, rhs_params = super().process_rhs(compiler, connection)\n409         if connection.vendor == 'oracle':\n410             func = []\n411             for value in rhs_params:\n412                 value = json.loads(value)\n413                 function = 'JSON_QUERY' if isinstance(value, (list, dict)) else 'JSON_VALUE'\n414                 func.append(\"%s('%s', '$.value')\" % (\n415                     function,\n416                     json.dumps({'value': value}),\n417                 ))\n418             rhs = rhs % tuple(func)\n419             rhs_params = []\n420         elif connection.vendor == 'sqlite':\n421             func = [\"JSON_EXTRACT(%s, '$')\" if value != 'null' else '%s' for value in rhs_params]\n422             rhs = rhs % tuple(func)\n423         return rhs, rhs_params\n424 \n425     def as_oracle(self, compiler, connection):\n426         rhs, rhs_params = super().process_rhs(compiler, connection)\n427         if rhs_params == ['null']:\n428             # Field has key and it's NULL.\n429             has_key_expr = HasKey(self.lhs.lhs, self.lhs.key_name)\n430             has_key_sql, has_key_params = has_key_expr.as_oracle(compiler, connection)\n431             is_null_expr = self.lhs.get_lookup('isnull')(self.lhs, True)\n432             is_null_sql, is_null_params = is_null_expr.as_sql(compiler, connection)\n433             return (\n434                 '%s AND %s' % (has_key_sql, is_null_sql),\n435                 tuple(has_key_params) + tuple(is_null_params),\n436             )\n437         return super().as_sql(compiler, connection)\n438 \n439 \n440 class KeyTransformIExact(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IExact):\n441     pass\n442 \n443 \n444 class KeyTransformIContains(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IContains):\n445     pass\n446 \n447 \n448 class KeyTransformStartsWith(KeyTransformTextLookupMixin, lookups.StartsWith):\n449     pass\n450 \n451 \n452 class KeyTransformIStartsWith(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IStartsWith):\n453     pass\n454 \n455 \n456 class KeyTransformEndsWith(KeyTransformTextLookupMixin, lookups.EndsWith):\n457     pass\n458 \n459 \n460 class KeyTransformIEndsWith(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IEndsWith):\n461     pass\n462 \n463 \n464 class KeyTransformRegex(KeyTransformTextLookupMixin, lookups.Regex):\n465     pass\n466 \n467 \n468 class KeyTransformIRegex(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IRegex):\n469     pass\n470 \n471 \n472 class KeyTransformNumericLookupMixin:\n473     def process_rhs(self, compiler, connection):\n474         rhs, rhs_params = super().process_rhs(compiler, connection)\n475         if not connection.features.has_native_json_field:\n476             rhs_params = [json.loads(value) for value in rhs_params]\n477         return rhs, rhs_params\n478 \n479 \n480 class KeyTransformLt(KeyTransformNumericLookupMixin, lookups.LessThan):\n481     pass\n482 \n483 \n484 class KeyTransformLte(KeyTransformNumericLookupMixin, lookups.LessThanOrEqual):\n485     pass\n486 \n487 \n488 class KeyTransformGt(KeyTransformNumericLookupMixin, lookups.GreaterThan):\n489     pass\n490 \n491 \n492 class KeyTransformGte(KeyTransformNumericLookupMixin, lookups.GreaterThanOrEqual):\n493     pass\n494 \n495 \n496 KeyTransform.register_lookup(KeyTransformIn)\n497 KeyTransform.register_lookup(KeyTransformExact)\n498 KeyTransform.register_lookup(KeyTransformIExact)\n499 KeyTransform.register_lookup(KeyTransformIsNull)\n500 KeyTransform.register_lookup(KeyTransformIContains)\n501 KeyTransform.register_lookup(KeyTransformStartsWith)\n502 KeyTransform.register_lookup(KeyTransformIStartsWith)\n503 KeyTransform.register_lookup(KeyTransformEndsWith)\n504 KeyTransform.register_lookup(KeyTransformIEndsWith)\n505 KeyTransform.register_lookup(KeyTransformRegex)\n506 KeyTransform.register_lookup(KeyTransformIRegex)\n507 \n508 KeyTransform.register_lookup(KeyTransformLt)\n509 KeyTransform.register_lookup(KeyTransformLte)\n510 KeyTransform.register_lookup(KeyTransformGt)\n511 KeyTransform.register_lookup(KeyTransformGte)\n512 \n513 \n514 class KeyTransformFactory:\n515 \n516     def __init__(self, key_name):\n517         self.key_name = key_name\n518 \n519     def __call__(self, *args, **kwargs):\n520         return KeyTransform(self.key_name, *args, **kwargs)\n",
        "intended_behavior": "The code in this location should ensure that when `json.dumps` is used for serializing JSONField data, it supports non-ASCII characters (like Chinese) properly. The default behavior of `json.dumps` is to escape non-ASCII characters, which results in the ASCII representation. To address the issue, ensure the serialization uses `ensure_ascii=False` argument with `json.dumps` to allow Unicode characters to be encoded and displayed correctly. This change should preserve all existing functionalities of JSONField serialization and deserialization in Django but enhance it to properly handle and display Unicode characters in Django admin."
    }
]