2025-10-15 05:21:13.111 | INFO     | Starting overall retry 0 with model gpt-4-0125-preview
2025-10-15 05:21:16.623 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=196, output_tokens=12, cost=0.002320
2025-10-15 05:21:16.624 | INFO     | Test agent decides that the issue statement does not contain reproduction steps; skipping reproducer tracing
2025-10-15 05:21:16.628 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-15 05:21:26.272 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=501, output_tokens=390, cost=0.016710
2025-10-15 05:21:26.281 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-15 05:21:28.239 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=744, output_tokens=53, cost=0.009030
2025-10-15 05:21:28.240 | DEBUG    | Extracted a valid json.
2025-10-15 05:21:28.240 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_code(\"json.dumps\")",
        "search_class(\"JsonField\")",
        "search_code(\"admin.ModelAdmin\")",
        "search_code(\"django-mysql\")"
    ],
    "bug_locations": []
}
2025-10-15 05:21:28.344 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-15 05:21:28.345 | DEBUG    | <Agent search> Analyzing search results.
2025-10-15 05:21:45.617 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=1536, output_tokens=711, cost=0.036690
2025-10-15 05:21:45.625 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-15 05:21:54.276 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=2463, output_tokens=281, cost=0.033060
2025-10-15 05:21:54.279 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-15 05:21:59.733 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=635, output_tokens=157, cost=0.011060
2025-10-15 05:21:59.734 | DEBUG    | Extracted a valid json.
2025-10-15 05:21:59.734 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [],
    "bug_locations":[{"file": "django/db/models/fields/json.py", "class": "", "method": "", "intended_behavior": "The code in this location should ensure that when `json.dumps` is used for serializing JSONField data, it supports non-ASCII characters (like Chinese) properly. The default behavior of `json.dumps` is to escape non-ASCII characters, which results in the ASCII representation. To address the issue, ensure the serialization uses `ensure_ascii=False` argument with `json.dumps` to allow Unicode characters to be encoded and displayed correctly. This change should preserve all existing functionalities of JSONField serialization and deserialization in Django but enhance it to properly handle and display Unicode characters in Django admin."}]
}
2025-10-15 05:21:59.738 | DEBUG    | Bug location extracted successfully: [<file>django/db/models/fields/json.py</file>
<class>None</class>
<method>None</method>
<code>
1 import json
2 
3 from django import forms
4 from django.core import checks, exceptions
5 from django.db import NotSupportedError, connections, router
6 from django.db.models import lookups
7 from django.db.models.lookups import PostgresOperatorLookup, Transform
8 from django.utils.translation import gettext_lazy as _
9 
10 from . import Field
11 from .mixins import CheckFieldDefaultMixin
12 
13 __all__ = ['JSONField']
14 
15 
16 class JSONField(CheckFieldDefaultMixin, Field):
17     empty_strings_allowed = False
18     description = _('A JSON object')
19     default_error_messages = {
20         'invalid': _('Value must be valid JSON.'),
21     }
22     _default_hint = ('dict', '{}')
23 
24     def __init__(
25         self, verbose_name=None, name=None, encoder=None, decoder=None,
26         **kwargs,
27     ):
28         if encoder and not callable(encoder):
29             raise ValueError('The encoder parameter must be a callable object.')
30         if decoder and not callable(decoder):
31             raise ValueError('The decoder parameter must be a callable object.')
32         self.encoder = encoder
33         self.decoder = decoder
34         super().__init__(verbose_name, name, **kwargs)
35 
36     def check(self, **kwargs):
37         errors = super().check(**kwargs)
38         databases = kwargs.get('databases') or []
39         errors.extend(self._check_supported(databases))
40         return errors
41 
42     def _check_supported(self, databases):
43         errors = []
44         for db in databases:
45             if not router.allow_migrate_model(db, self.model):
46                 continue
47             connection = connections[db]
48             if not (
49                 'supports_json_field' in self.model._meta.required_db_features or
50                 connection.features.supports_json_field
51             ):
52                 errors.append(
53                     checks.Error(
54                         '%s does not support JSONFields.'
55                         % connection.display_name,
56                         obj=self.model,
57                         id='fields.E180',
58                     )
59                 )
60         return errors
61 
62     def deconstruct(self):
63         name, path, args, kwargs = super().deconstruct()
64         if self.encoder is not None:
65             kwargs['encoder'] = self.encoder
66         if self.decoder is not None:
67             kwargs['decoder'] = self.decoder
68         return name, path, args, kwargs
69 
70     def from_db_value(self, value, expression, connection):
71         if value is None:
72             return value
73         try:
74             return json.loads(value, cls=self.decoder)
75         except json.JSONDecodeError:
76             return value
77 
78     def get_internal_type(self):
79         return 'JSONField'
80 
81     def get_prep_value(self, value):
82         if value is None:
83             return value
84         return json.dumps(value, cls=self.encoder)
85 
86     def get_transform(self, name):
87         transform = super().get_transform(name)
88         if transform:
89             return transform
90         return KeyTransformFactory(name)
91 
92     def validate(self, value, model_instance):
93         super().validate(value, model_instance)
94         try:
95             json.dumps(value, cls=self.encoder)
96         except TypeError:
97             raise exceptions.ValidationError(
98                 self.error_messages['invalid'],
99                 code='invalid',
100                 params={'value': value},
101             )
102 
103     def value_to_string(self, obj):
104         return self.value_from_object(obj)
105 
106     def formfield(self, **kwargs):
107         return super().formfield(**{
108             'form_class': forms.JSONField,
109             'encoder': self.encoder,
110             'decoder': self.decoder,
111             **kwargs,
112         })
113 
114 
115 def compile_json_path(key_transforms, include_root=True):
116     path = ['$'] if include_root else []
117     for key_transform in key_transforms:
118         try:
119             num = int(key_transform)
120         except ValueError:  # non-integer
121             path.append('.')
122             path.append(json.dumps(key_transform))
123         else:
124             path.append('[%s]' % num)
125     return ''.join(path)
126 
127 
128 class DataContains(PostgresOperatorLookup):
129     lookup_name = 'contains'
130     postgres_operator = '@>'
131 
132     def as_sql(self, compiler, connection):
133         if not connection.features.supports_json_field_contains:
134             raise NotSupportedError(
135                 'contains lookup is not supported on this database backend.'
136             )
137         lhs, lhs_params = self.process_lhs(compiler, connection)
138         rhs, rhs_params = self.process_rhs(compiler, connection)
139         params = tuple(lhs_params) + tuple(rhs_params)
140         return 'JSON_CONTAINS(%s, %s)' % (lhs, rhs), params
141 
142 
143 class ContainedBy(PostgresOperatorLookup):
144     lookup_name = 'contained_by'
145     postgres_operator = '<@'
146 
147     def as_sql(self, compiler, connection):
148         if not connection.features.supports_json_field_contains:
149             raise NotSupportedError(
150                 'contained_by lookup is not supported on this database backend.'
151             )
152         lhs, lhs_params = self.process_lhs(compiler, connection)
153         rhs, rhs_params = self.process_rhs(compiler, connection)
154         params = tuple(rhs_params) + tuple(lhs_params)
155         return 'JSON_CONTAINS(%s, %s)' % (rhs, lhs), params
156 
157 
158 class HasKeyLookup(PostgresOperatorLookup):
159     logical_operator = None
160 
161     def as_sql(self, compiler, connection, template=None):
162         # Process JSON path from the left-hand side.
163         if isinstance(self.lhs, KeyTransform):
164             lhs, lhs_params, lhs_key_transforms = self.lhs.preprocess_lhs(compiler, connection)
165             lhs_json_path = compile_json_path(lhs_key_transforms)
166         else:
167             lhs, lhs_params = self.process_lhs(compiler, connection)
168             lhs_json_path = '$'
169         sql = template % lhs
170         # Process JSON path from the right-hand side.
171         rhs = self.rhs
172         rhs_params = []
173         if not isinstance(rhs, (list, tuple)):
174             rhs = [rhs]
175         for key in rhs:
176             if isinstance(key, KeyTransform):
177                 *_, rhs_key_transforms = key.preprocess_lhs(compiler, connection)
178             else:
179                 rhs_key_transforms = [key]
180             rhs_params.append('%s%s' % (
181                 lhs_json_path,
182                 compile_json_path(rhs_key_transforms, include_root=False),
183             ))
184         # Add condition for each key.
185         if self.logical_operator:
186             sql = '(%s)' % self.logical_operator.join([sql] * len(rhs_params))
187         return sql, tuple(lhs_params) + tuple(rhs_params)
188 
189     def as_mysql(self, compiler, connection):
190         return self.as_sql(compiler, connection, template="JSON_CONTAINS_PATH(%s, 'one', %%s)")
191 
192     def as_oracle(self, compiler, connection):
193         sql, params = self.as_sql(compiler, connection, template="JSON_EXISTS(%s, '%%s')")
194         # Add paths directly into SQL because path expressions cannot be passed
195         # as bind variables on Oracle.
196         return sql % tuple(params), []
197 
198     def as_postgresql(self, compiler, connection):
199         if isinstance(self.rhs, KeyTransform):
200             *_, rhs_key_transforms = self.rhs.preprocess_lhs(compiler, connection)
201             for key in rhs_key_transforms[:-1]:
202                 self.lhs = KeyTransform(key, self.lhs)
203             self.rhs = rhs_key_transforms[-1]
204         return super().as_postgresql(compiler, connection)
205 
206     def as_sqlite(self, compiler, connection):
207         return self.as_sql(compiler, connection, template='JSON_TYPE(%s, %%s) IS NOT NULL')
208 
209 
210 class HasKey(HasKeyLookup):
211     lookup_name = 'has_key'
212     postgres_operator = '?'
213     prepare_rhs = False
214 
215 
216 class HasKeys(HasKeyLookup):
217     lookup_name = 'has_keys'
218     postgres_operator = '?&'
219     logical_operator = ' AND '
220 
221     def get_prep_lookup(self):
222         return [str(item) for item in self.rhs]
223 
224 
225 class HasAnyKeys(HasKeys):
226     lookup_name = 'has_any_keys'
227     postgres_operator = '?|'
228     logical_operator = ' OR '
229 
230 
231 class JSONExact(lookups.Exact):
232     can_use_none_as_rhs = True
233 
234     def process_lhs(self, compiler, connection):
235         lhs, lhs_params = super().process_lhs(compiler, connection)
236         if connection.vendor == 'sqlite':
237             rhs, rhs_params = super().process_rhs(compiler, connection)
238             if rhs == '%s' and rhs_params == [None]:
239                 # Use JSON_TYPE instead of JSON_EXTRACT for NULLs.
240                 lhs = "JSON_TYPE(%s, '$')" % lhs
241         return lhs, lhs_params
242 
243     def process_rhs(self, compiler, connection):
244         rhs, rhs_params = super().process_rhs(compiler, connection)
245         # Treat None lookup values as null.
246         if rhs == '%s' and rhs_params == [None]:
247             rhs_params = ['null']
248         if connection.vendor == 'mysql':
249             func = ["JSON_EXTRACT(%s, '$')"] * len(rhs_params)
250             rhs = rhs % tuple(func)
251         return rhs, rhs_params
252 
253 
254 JSONField.register_lookup(DataContains)
255 JSONField.register_lookup(ContainedBy)
256 JSONField.register_lookup(HasKey)
257 JSONField.register_lookup(HasKeys)
258 JSONField.register_lookup(HasAnyKeys)
259 JSONField.register_lookup(JSONExact)
260 
261 
262 class KeyTransform(Transform):
263     postgres_operator = '->'
264     postgres_nested_operator = '#>'
265 
266     def __init__(self, key_name, *args, **kwargs):
267         super().__init__(*args, **kwargs)
268         self.key_name = str(key_name)
269 
270     def preprocess_lhs(self, compiler, connection, lhs_only=False):
271         if not lhs_only:
272             key_transforms = [self.key_name]
273         previous = self.lhs
274         while isinstance(previous, KeyTransform):
275             if not lhs_only:
276                 key_transforms.insert(0, previous.key_name)
277             previous = previous.lhs
278         lhs, params = compiler.compile(previous)
279         if connection.vendor == 'oracle':
280             # Escape string-formatting.
281             key_transforms = [key.replace('%', '%%') for key in key_transforms]
282         return (lhs, params, key_transforms) if not lhs_only else (lhs, params)
283 
284     def as_mysql(self, compiler, connection):
285         lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)
286         json_path = compile_json_path(key_transforms)
287         return 'JSON_EXTRACT(%s, %%s)' % lhs, tuple(params) + (json_path,)
288 
289     def as_oracle(self, compiler, connection):
290         lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)
291         json_path = compile_json_path(key_transforms)
292         return (
293             "COALESCE(JSON_QUERY(%s, '%s'), JSON_VALUE(%s, '%s'))" %
294             ((lhs, json_path) * 2)
295         ), tuple(params) * 2
296 
297     def as_postgresql(self, compiler, connection):
298         lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)
299         if len(key_transforms) > 1:
300             return '(%s %s %%s)' % (lhs, self.postgres_nested_operator), params + [key_transforms]
301         try:
302             lookup = int(self.key_name)
303         except ValueError:
304             lookup = self.key_name
305         return '(%s %s %%s)' % (lhs, self.postgres_operator), tuple(params) + (lookup,)
306 
307     def as_sqlite(self, compiler, connection):
308         lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)
309         json_path = compile_json_path(key_transforms)
310         return 'JSON_EXTRACT(%s, %%s)' % lhs, tuple(params) + (json_path,)
311 
312 
313 class KeyTextTransform(KeyTransform):
314     postgres_operator = '->>'
315     postgres_nested_operator = '#>>'
316 
317 
318 class KeyTransformTextLookupMixin:
319     """
320     Mixin for combining with a lookup expecting a text lhs from a JSONField
321     key lookup. On PostgreSQL, make use of the ->> operator instead of casting
322     key values to text and performing the lookup on the resulting
323     representation.
324     """
325     def __init__(self, key_transform, *args, **kwargs):
326         if not isinstance(key_transform, KeyTransform):
327             raise TypeError(
328                 'Transform should be an instance of KeyTransform in order to '
329                 'use this lookup.'
330             )
331         key_text_transform = KeyTextTransform(
332             key_transform.key_name, *key_transform.source_expressions,
333             **key_transform.extra,
334         )
335         super().__init__(key_text_transform, *args, **kwargs)
336 
337 
338 class CaseInsensitiveMixin:
339     """
340     Mixin to allow case-insensitive comparison of JSON values on MySQL.
341     MySQL handles strings used in JSON context using the utf8mb4_bin collation.
342     Because utf8mb4_bin is a binary collation, comparison of JSON values is
343     case-sensitive.
344     """
345     def process_lhs(self, compiler, connection):
346         lhs, lhs_params = super().process_lhs(compiler, connection)
347         if connection.vendor == 'mysql':
348             return 'LOWER(%s)' % lhs, lhs_params
349         return lhs, lhs_params
350 
351     def process_rhs(self, compiler, connection):
352         rhs, rhs_params = super().process_rhs(compiler, connection)
353         if connection.vendor == 'mysql':
354             return 'LOWER(%s)' % rhs, rhs_params
355         return rhs, rhs_params
356 
357 
358 class KeyTransformIsNull(lookups.IsNull):
359     # key__isnull=False is the same as has_key='key'
360     def as_oracle(self, compiler, connection):
361         if not self.rhs:
362             return HasKey(self.lhs.lhs, self.lhs.key_name).as_oracle(compiler, connection)
363         return super().as_sql(compiler, connection)
364 
365     def as_sqlite(self, compiler, connection):
366         if not self.rhs:
367             return HasKey(self.lhs.lhs, self.lhs.key_name).as_sqlite(compiler, connection)
368         return super().as_sql(compiler, connection)
369 
370 
371 class KeyTransformIn(lookups.In):
372     def process_rhs(self, compiler, connection):
373         rhs, rhs_params = super().process_rhs(compiler, connection)
374         if not connection.features.has_native_json_field:
375             func = ()
376             if connection.vendor == 'oracle':
377                 func = []
378                 for value in rhs_params:
379                     value = json.loads(value)
380                     function = 'JSON_QUERY' if isinstance(value, (list, dict)) else 'JSON_VALUE'
381                     func.append("%s('%s', '$.value')" % (
382                         function,
383                         json.dumps({'value': value}),
384                     ))
385                 func = tuple(func)
386                 rhs_params = ()
387             elif connection.vendor == 'mysql' and connection.mysql_is_mariadb:
388                 func = ("JSON_UNQUOTE(JSON_EXTRACT(%s, '$'))",) * len(rhs_params)
389             elif connection.vendor in {'sqlite', 'mysql'}:
390                 func = ("JSON_EXTRACT(%s, '$')",) * len(rhs_params)
391             rhs = rhs % func
392         return rhs, rhs_params
393 
394 
395 class KeyTransformExact(JSONExact):
396     def process_lhs(self, compiler, connection):
397         lhs, lhs_params = super().process_lhs(compiler, connection)
398         if connection.vendor == 'sqlite':
399             rhs, rhs_params = super().process_rhs(compiler, connection)
400             if rhs == '%s' and rhs_params == ['null']:
401                 lhs, _ = self.lhs.preprocess_lhs(compiler, connection, lhs_only=True)
402                 lhs = 'JSON_TYPE(%s, %%s)' % lhs
403         return lhs, lhs_params
404 
405     def process_rhs(self, compiler, connection):
406         if isinstance(self.rhs, KeyTransform):
407             return super(lookups.Exact, self).process_rhs(compiler, connection)
408         rhs, rhs_params = super().process_rhs(compiler, connection)
409         if connection.vendor == 'oracle':
410             func = []
411             for value in rhs_params:
412                 value = json.loads(value)
413                 function = 'JSON_QUERY' if isinstance(value, (list, dict)) else 'JSON_VALUE'
414                 func.append("%s('%s', '$.value')" % (
415                     function,
416                     json.dumps({'value': value}),
417                 ))
418             rhs = rhs % tuple(func)
419             rhs_params = []
420         elif connection.vendor == 'sqlite':
421             func = ["JSON_EXTRACT(%s, '$')" if value != 'null' else '%s' for value in rhs_params]
422             rhs = rhs % tuple(func)
423         return rhs, rhs_params
424 
425     def as_oracle(self, compiler, connection):
426         rhs, rhs_params = super().process_rhs(compiler, connection)
427         if rhs_params == ['null']:
428             # Field has key and it's NULL.
429             has_key_expr = HasKey(self.lhs.lhs, self.lhs.key_name)
430             has_key_sql, has_key_params = has_key_expr.as_oracle(compiler, connection)
431             is_null_expr = self.lhs.get_lookup('isnull')(self.lhs, True)
432             is_null_sql, is_null_params = is_null_expr.as_sql(compiler, connection)
433             return (
434                 '%s AND %s' % (has_key_sql, is_null_sql),
435                 tuple(has_key_params) + tuple(is_null_params),
436             )
437         return super().as_sql(compiler, connection)
438 
439 
440 class KeyTransformIExact(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IExact):
441     pass
442 
443 
444 class KeyTransformIContains(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IContains):
445     pass
446 
447 
448 class KeyTransformStartsWith(KeyTransformTextLookupMixin, lookups.StartsWith):
449     pass
450 
451 
452 class KeyTransformIStartsWith(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IStartsWith):
453     pass
454 
455 
456 class KeyTransformEndsWith(KeyTransformTextLookupMixin, lookups.EndsWith):
457     pass
458 
459 
460 class KeyTransformIEndsWith(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IEndsWith):
461     pass
462 
463 
464 class KeyTransformRegex(KeyTransformTextLookupMixin, lookups.Regex):
465     pass
466 
467 
468 class KeyTransformIRegex(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IRegex):
469     pass
470 
471 
472 class KeyTransformNumericLookupMixin:
473     def process_rhs(self, compiler, connection):
474         rhs, rhs_params = super().process_rhs(compiler, connection)
475         if not connection.features.has_native_json_field:
476             rhs_params = [json.loads(value) for value in rhs_params]
477         return rhs, rhs_params
478 
479 
480 class KeyTransformLt(KeyTransformNumericLookupMixin, lookups.LessThan):
481     pass
482 
483 
484 class KeyTransformLte(KeyTransformNumericLookupMixin, lookups.LessThanOrEqual):
485     pass
486 
487 
488 class KeyTransformGt(KeyTransformNumericLookupMixin, lookups.GreaterThan):
489     pass
490 
491 
492 class KeyTransformGte(KeyTransformNumericLookupMixin, lookups.GreaterThanOrEqual):
493     pass
494 
495 
496 KeyTransform.register_lookup(KeyTransformIn)
497 KeyTransform.register_lookup(KeyTransformExact)
498 KeyTransform.register_lookup(KeyTransformIExact)
499 KeyTransform.register_lookup(KeyTransformIsNull)
500 KeyTransform.register_lookup(KeyTransformIContains)
501 KeyTransform.register_lookup(KeyTransformStartsWith)
502 KeyTransform.register_lookup(KeyTransformIStartsWith)
503 KeyTransform.register_lookup(KeyTransformEndsWith)
504 KeyTransform.register_lookup(KeyTransformIEndsWith)
505 KeyTransform.register_lookup(KeyTransformRegex)
506 KeyTransform.register_lookup(KeyTransformIRegex)
507 
508 KeyTransform.register_lookup(KeyTransformLt)
509 KeyTransform.register_lookup(KeyTransformLte)
510 KeyTransform.register_lookup(KeyTransformGt)
511 KeyTransform.register_lookup(KeyTransformGte)
512 
513 
514 class KeyTransformFactory:
515 
516     def __init__(self, key_name):
517         self.key_name = key_name
518 
519     def __call__(self, *args, **kwargs):
520         return KeyTransform(self.key_name, *args, **kwargs)

</code><intended_behavior>The code in this location should ensure that when `json.dumps` is used for serializing JSONField data, it supports non-ASCII characters (like Chinese) properly. The default behavior of `json.dumps` is to escape non-ASCII characters, which results in the ASCII representation. To address the issue, ensure the serialization uses `ensure_ascii=False` argument with `json.dumps` to allow Unicode characters to be encoded and displayed correctly. This change should preserve all existing functionalities of JSONField serialization and deserialization in Django but enhance it to properly handle and display Unicode characters in Django admin.</intended_behavior>]
2025-10-15 05:21:59.739 | INFO     | Search completed. Bug locations: [<file>django/db/models/fields/json.py</file>
<class>None</class>
<method>None</method>
<code>
1 import json
2 
3 from django import forms
4 from django.core import checks, exceptions
5 from django.db import NotSupportedError, connections, router
6 from django.db.models import lookups
7 from django.db.models.lookups import PostgresOperatorLookup, Transform
8 from django.utils.translation import gettext_lazy as _
9 
10 from . import Field
11 from .mixins import CheckFieldDefaultMixin
12 
13 __all__ = ['JSONField']
14 
15 
16 class JSONField(CheckFieldDefaultMixin, Field):
17     empty_strings_allowed = False
18     description = _('A JSON object')
19     default_error_messages = {
20         'invalid': _('Value must be valid JSON.'),
21     }
22     _default_hint = ('dict', '{}')
23 
24     def __init__(
25         self, verbose_name=None, name=None, encoder=None, decoder=None,
26         **kwargs,
27     ):
28         if encoder and not callable(encoder):
29             raise ValueError('The encoder parameter must be a callable object.')
30         if decoder and not callable(decoder):
31             raise ValueError('The decoder parameter must be a callable object.')
32         self.encoder = encoder
33         self.decoder = decoder
34         super().__init__(verbose_name, name, **kwargs)
35 
36     def check(self, **kwargs):
37         errors = super().check(**kwargs)
38         databases = kwargs.get('databases') or []
39         errors.extend(self._check_supported(databases))
40         return errors
41 
42     def _check_supported(self, databases):
43         errors = []
44         for db in databases:
45             if not router.allow_migrate_model(db, self.model):
46                 continue
47             connection = connections[db]
48             if not (
49                 'supports_json_field' in self.model._meta.required_db_features or
50                 connection.features.supports_json_field
51             ):
52                 errors.append(
53                     checks.Error(
54                         '%s does not support JSONFields.'
55                         % connection.display_name,
56                         obj=self.model,
57                         id='fields.E180',
58                     )
59                 )
60         return errors
61 
62     def deconstruct(self):
63         name, path, args, kwargs = super().deconstruct()
64         if self.encoder is not None:
65             kwargs['encoder'] = self.encoder
66         if self.decoder is not None:
67             kwargs['decoder'] = self.decoder
68         return name, path, args, kwargs
69 
70     def from_db_value(self, value, expression, connection):
71         if value is None:
72             return value
73         try:
74             return json.loads(value, cls=self.decoder)
75         except json.JSONDecodeError:
76             return value
77 
78     def get_internal_type(self):
79         return 'JSONField'
80 
81     def get_prep_value(self, value):
82         if value is None:
83             return value
84         return json.dumps(value, cls=self.encoder)
85 
86     def get_transform(self, name):
87         transform = super().get_transform(name)
88         if transform:
89             return transform
90         return KeyTransformFactory(name)
91 
92     def validate(self, value, model_instance):
93         super().validate(value, model_instance)
94         try:
95             json.dumps(value, cls=self.encoder)
96         except TypeError:
97             raise exceptions.ValidationError(
98                 self.error_messages['invalid'],
99                 code='invalid',
100                 params={'value': value},
101             )
102 
103     def value_to_string(self, obj):
104         return self.value_from_object(obj)
105 
106     def formfield(self, **kwargs):
107         return super().formfield(**{
108             'form_class': forms.JSONField,
109             'encoder': self.encoder,
110             'decoder': self.decoder,
111             **kwargs,
112         })
113 
114 
115 def compile_json_path(key_transforms, include_root=True):
116     path = ['$'] if include_root else []
117     for key_transform in key_transforms:
118         try:
119             num = int(key_transform)
120         except ValueError:  # non-integer
121             path.append('.')
122             path.append(json.dumps(key_transform))
123         else:
124             path.append('[%s]' % num)
125     return ''.join(path)
126 
127 
128 class DataContains(PostgresOperatorLookup):
129     lookup_name = 'contains'
130     postgres_operator = '@>'
131 
132     def as_sql(self, compiler, connection):
133         if not connection.features.supports_json_field_contains:
134             raise NotSupportedError(
135                 'contains lookup is not supported on this database backend.'
136             )
137         lhs, lhs_params = self.process_lhs(compiler, connection)
138         rhs, rhs_params = self.process_rhs(compiler, connection)
139         params = tuple(lhs_params) + tuple(rhs_params)
140         return 'JSON_CONTAINS(%s, %s)' % (lhs, rhs), params
141 
142 
143 class ContainedBy(PostgresOperatorLookup):
144     lookup_name = 'contained_by'
145     postgres_operator = '<@'
146 
147     def as_sql(self, compiler, connection):
148         if not connection.features.supports_json_field_contains:
149             raise NotSupportedError(
150                 'contained_by lookup is not supported on this database backend.'
151             )
152         lhs, lhs_params = self.process_lhs(compiler, connection)
153         rhs, rhs_params = self.process_rhs(compiler, connection)
154         params = tuple(rhs_params) + tuple(lhs_params)
155         return 'JSON_CONTAINS(%s, %s)' % (rhs, lhs), params
156 
157 
158 class HasKeyLookup(PostgresOperatorLookup):
159     logical_operator = None
160 
161     def as_sql(self, compiler, connection, template=None):
162         # Process JSON path from the left-hand side.
163         if isinstance(self.lhs, KeyTransform):
164             lhs, lhs_params, lhs_key_transforms = self.lhs.preprocess_lhs(compiler, connection)
165             lhs_json_path = compile_json_path(lhs_key_transforms)
166         else:
167             lhs, lhs_params = self.process_lhs(compiler, connection)
168             lhs_json_path = '$'
169         sql = template % lhs
170         # Process JSON path from the right-hand side.
171         rhs = self.rhs
172         rhs_params = []
173         if not isinstance(rhs, (list, tuple)):
174             rhs = [rhs]
175         for key in rhs:
176             if isinstance(key, KeyTransform):
177                 *_, rhs_key_transforms = key.preprocess_lhs(compiler, connection)
178             else:
179                 rhs_key_transforms = [key]
180             rhs_params.append('%s%s' % (
181                 lhs_json_path,
182                 compile_json_path(rhs_key_transforms, include_root=False),
183             ))
184         # Add condition for each key.
185         if self.logical_operator:
186             sql = '(%s)' % self.logical_operator.join([sql] * len(rhs_params))
187         return sql, tuple(lhs_params) + tuple(rhs_params)
188 
189     def as_mysql(self, compiler, connection):
190         return self.as_sql(compiler, connection, template="JSON_CONTAINS_PATH(%s, 'one', %%s)")
191 
192     def as_oracle(self, compiler, connection):
193         sql, params = self.as_sql(compiler, connection, template="JSON_EXISTS(%s, '%%s')")
194         # Add paths directly into SQL because path expressions cannot be passed
195         # as bind variables on Oracle.
196         return sql % tuple(params), []
197 
198     def as_postgresql(self, compiler, connection):
199         if isinstance(self.rhs, KeyTransform):
200             *_, rhs_key_transforms = self.rhs.preprocess_lhs(compiler, connection)
201             for key in rhs_key_transforms[:-1]:
202                 self.lhs = KeyTransform(key, self.lhs)
203             self.rhs = rhs_key_transforms[-1]
204         return super().as_postgresql(compiler, connection)
205 
206     def as_sqlite(self, compiler, connection):
207         return self.as_sql(compiler, connection, template='JSON_TYPE(%s, %%s) IS NOT NULL')
208 
209 
210 class HasKey(HasKeyLookup):
211     lookup_name = 'has_key'
212     postgres_operator = '?'
213     prepare_rhs = False
214 
215 
216 class HasKeys(HasKeyLookup):
217     lookup_name = 'has_keys'
218     postgres_operator = '?&'
219     logical_operator = ' AND '
220 
221     def get_prep_lookup(self):
222         return [str(item) for item in self.rhs]
223 
224 
225 class HasAnyKeys(HasKeys):
226     lookup_name = 'has_any_keys'
227     postgres_operator = '?|'
228     logical_operator = ' OR '
229 
230 
231 class JSONExact(lookups.Exact):
232     can_use_none_as_rhs = True
233 
234     def process_lhs(self, compiler, connection):
235         lhs, lhs_params = super().process_lhs(compiler, connection)
236         if connection.vendor == 'sqlite':
237             rhs, rhs_params = super().process_rhs(compiler, connection)
238             if rhs == '%s' and rhs_params == [None]:
239                 # Use JSON_TYPE instead of JSON_EXTRACT for NULLs.
240                 lhs = "JSON_TYPE(%s, '$')" % lhs
241         return lhs, lhs_params
242 
243     def process_rhs(self, compiler, connection):
244         rhs, rhs_params = super().process_rhs(compiler, connection)
245         # Treat None lookup values as null.
246         if rhs == '%s' and rhs_params == [None]:
247             rhs_params = ['null']
248         if connection.vendor == 'mysql':
249             func = ["JSON_EXTRACT(%s, '$')"] * len(rhs_params)
250             rhs = rhs % tuple(func)
251         return rhs, rhs_params
252 
253 
254 JSONField.register_lookup(DataContains)
255 JSONField.register_lookup(ContainedBy)
256 JSONField.register_lookup(HasKey)
257 JSONField.register_lookup(HasKeys)
258 JSONField.register_lookup(HasAnyKeys)
259 JSONField.register_lookup(JSONExact)
260 
261 
262 class KeyTransform(Transform):
263     postgres_operator = '->'
264     postgres_nested_operator = '#>'
265 
266     def __init__(self, key_name, *args, **kwargs):
267         super().__init__(*args, **kwargs)
268         self.key_name = str(key_name)
269 
270     def preprocess_lhs(self, compiler, connection, lhs_only=False):
271         if not lhs_only:
272             key_transforms = [self.key_name]
273         previous = self.lhs
274         while isinstance(previous, KeyTransform):
275             if not lhs_only:
276                 key_transforms.insert(0, previous.key_name)
277             previous = previous.lhs
278         lhs, params = compiler.compile(previous)
279         if connection.vendor == 'oracle':
280             # Escape string-formatting.
281             key_transforms = [key.replace('%', '%%') for key in key_transforms]
282         return (lhs, params, key_transforms) if not lhs_only else (lhs, params)
283 
284     def as_mysql(self, compiler, connection):
285         lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)
286         json_path = compile_json_path(key_transforms)
287         return 'JSON_EXTRACT(%s, %%s)' % lhs, tuple(params) + (json_path,)
288 
289     def as_oracle(self, compiler, connection):
290         lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)
291         json_path = compile_json_path(key_transforms)
292         return (
293             "COALESCE(JSON_QUERY(%s, '%s'), JSON_VALUE(%s, '%s'))" %
294             ((lhs, json_path) * 2)
295         ), tuple(params) * 2
296 
297     def as_postgresql(self, compiler, connection):
298         lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)
299         if len(key_transforms) > 1:
300             return '(%s %s %%s)' % (lhs, self.postgres_nested_operator), params + [key_transforms]
301         try:
302             lookup = int(self.key_name)
303         except ValueError:
304             lookup = self.key_name
305         return '(%s %s %%s)' % (lhs, self.postgres_operator), tuple(params) + (lookup,)
306 
307     def as_sqlite(self, compiler, connection):
308         lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)
309         json_path = compile_json_path(key_transforms)
310         return 'JSON_EXTRACT(%s, %%s)' % lhs, tuple(params) + (json_path,)
311 
312 
313 class KeyTextTransform(KeyTransform):
314     postgres_operator = '->>'
315     postgres_nested_operator = '#>>'
316 
317 
318 class KeyTransformTextLookupMixin:
319     """
320     Mixin for combining with a lookup expecting a text lhs from a JSONField
321     key lookup. On PostgreSQL, make use of the ->> operator instead of casting
322     key values to text and performing the lookup on the resulting
323     representation.
324     """
325     def __init__(self, key_transform, *args, **kwargs):
326         if not isinstance(key_transform, KeyTransform):
327             raise TypeError(
328                 'Transform should be an instance of KeyTransform in order to '
329                 'use this lookup.'
330             )
331         key_text_transform = KeyTextTransform(
332             key_transform.key_name, *key_transform.source_expressions,
333             **key_transform.extra,
334         )
335         super().__init__(key_text_transform, *args, **kwargs)
336 
337 
338 class CaseInsensitiveMixin:
339     """
340     Mixin to allow case-insensitive comparison of JSON values on MySQL.
341     MySQL handles strings used in JSON context using the utf8mb4_bin collation.
342     Because utf8mb4_bin is a binary collation, comparison of JSON values is
343     case-sensitive.
344     """
345     def process_lhs(self, compiler, connection):
346         lhs, lhs_params = super().process_lhs(compiler, connection)
347         if connection.vendor == 'mysql':
348             return 'LOWER(%s)' % lhs, lhs_params
349         return lhs, lhs_params
350 
351     def process_rhs(self, compiler, connection):
352         rhs, rhs_params = super().process_rhs(compiler, connection)
353         if connection.vendor == 'mysql':
354             return 'LOWER(%s)' % rhs, rhs_params
355         return rhs, rhs_params
356 
357 
358 class KeyTransformIsNull(lookups.IsNull):
359     # key__isnull=False is the same as has_key='key'
360     def as_oracle(self, compiler, connection):
361         if not self.rhs:
362             return HasKey(self.lhs.lhs, self.lhs.key_name).as_oracle(compiler, connection)
363         return super().as_sql(compiler, connection)
364 
365     def as_sqlite(self, compiler, connection):
366         if not self.rhs:
367             return HasKey(self.lhs.lhs, self.lhs.key_name).as_sqlite(compiler, connection)
368         return super().as_sql(compiler, connection)
369 
370 
371 class KeyTransformIn(lookups.In):
372     def process_rhs(self, compiler, connection):
373         rhs, rhs_params = super().process_rhs(compiler, connection)
374         if not connection.features.has_native_json_field:
375             func = ()
376             if connection.vendor == 'oracle':
377                 func = []
378                 for value in rhs_params:
379                     value = json.loads(value)
380                     function = 'JSON_QUERY' if isinstance(value, (list, dict)) else 'JSON_VALUE'
381                     func.append("%s('%s', '$.value')" % (
382                         function,
383                         json.dumps({'value': value}),
384                     ))
385                 func = tuple(func)
386                 rhs_params = ()
387             elif connection.vendor == 'mysql' and connection.mysql_is_mariadb:
388                 func = ("JSON_UNQUOTE(JSON_EXTRACT(%s, '$'))",) * len(rhs_params)
389             elif connection.vendor in {'sqlite', 'mysql'}:
390                 func = ("JSON_EXTRACT(%s, '$')",) * len(rhs_params)
391             rhs = rhs % func
392         return rhs, rhs_params
393 
394 
395 class KeyTransformExact(JSONExact):
396     def process_lhs(self, compiler, connection):
397         lhs, lhs_params = super().process_lhs(compiler, connection)
398         if connection.vendor == 'sqlite':
399             rhs, rhs_params = super().process_rhs(compiler, connection)
400             if rhs == '%s' and rhs_params == ['null']:
401                 lhs, _ = self.lhs.preprocess_lhs(compiler, connection, lhs_only=True)
402                 lhs = 'JSON_TYPE(%s, %%s)' % lhs
403         return lhs, lhs_params
404 
405     def process_rhs(self, compiler, connection):
406         if isinstance(self.rhs, KeyTransform):
407             return super(lookups.Exact, self).process_rhs(compiler, connection)
408         rhs, rhs_params = super().process_rhs(compiler, connection)
409         if connection.vendor == 'oracle':
410             func = []
411             for value in rhs_params:
412                 value = json.loads(value)
413                 function = 'JSON_QUERY' if isinstance(value, (list, dict)) else 'JSON_VALUE'
414                 func.append("%s('%s', '$.value')" % (
415                     function,
416                     json.dumps({'value': value}),
417                 ))
418             rhs = rhs % tuple(func)
419             rhs_params = []
420         elif connection.vendor == 'sqlite':
421             func = ["JSON_EXTRACT(%s, '$')" if value != 'null' else '%s' for value in rhs_params]
422             rhs = rhs % tuple(func)
423         return rhs, rhs_params
424 
425     def as_oracle(self, compiler, connection):
426         rhs, rhs_params = super().process_rhs(compiler, connection)
427         if rhs_params == ['null']:
428             # Field has key and it's NULL.
429             has_key_expr = HasKey(self.lhs.lhs, self.lhs.key_name)
430             has_key_sql, has_key_params = has_key_expr.as_oracle(compiler, connection)
431             is_null_expr = self.lhs.get_lookup('isnull')(self.lhs, True)
432             is_null_sql, is_null_params = is_null_expr.as_sql(compiler, connection)
433             return (
434                 '%s AND %s' % (has_key_sql, is_null_sql),
435                 tuple(has_key_params) + tuple(is_null_params),
436             )
437         return super().as_sql(compiler, connection)
438 
439 
440 class KeyTransformIExact(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IExact):
441     pass
442 
443 
444 class KeyTransformIContains(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IContains):
445     pass
446 
447 
448 class KeyTransformStartsWith(KeyTransformTextLookupMixin, lookups.StartsWith):
449     pass
450 
451 
452 class KeyTransformIStartsWith(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IStartsWith):
453     pass
454 
455 
456 class KeyTransformEndsWith(KeyTransformTextLookupMixin, lookups.EndsWith):
457     pass
458 
459 
460 class KeyTransformIEndsWith(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IEndsWith):
461     pass
462 
463 
464 class KeyTransformRegex(KeyTransformTextLookupMixin, lookups.Regex):
465     pass
466 
467 
468 class KeyTransformIRegex(CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IRegex):
469     pass
470 
471 
472 class KeyTransformNumericLookupMixin:
473     def process_rhs(self, compiler, connection):
474         rhs, rhs_params = super().process_rhs(compiler, connection)
475         if not connection.features.has_native_json_field:
476             rhs_params = [json.loads(value) for value in rhs_params]
477         return rhs, rhs_params
478 
479 
480 class KeyTransformLt(KeyTransformNumericLookupMixin, lookups.LessThan):
481     pass
482 
483 
484 class KeyTransformLte(KeyTransformNumericLookupMixin, lookups.LessThanOrEqual):
485     pass
486 
487 
488 class KeyTransformGt(KeyTransformNumericLookupMixin, lookups.GreaterThan):
489     pass
490 
491 
492 class KeyTransformGte(KeyTransformNumericLookupMixin, lookups.GreaterThanOrEqual):
493     pass
494 
495 
496 KeyTransform.register_lookup(KeyTransformIn)
497 KeyTransform.register_lookup(KeyTransformExact)
498 KeyTransform.register_lookup(KeyTransformIExact)
499 KeyTransform.register_lookup(KeyTransformIsNull)
500 KeyTransform.register_lookup(KeyTransformIContains)
501 KeyTransform.register_lookup(KeyTransformStartsWith)
502 KeyTransform.register_lookup(KeyTransformIStartsWith)
503 KeyTransform.register_lookup(KeyTransformEndsWith)
504 KeyTransform.register_lookup(KeyTransformIEndsWith)
505 KeyTransform.register_lookup(KeyTransformRegex)
506 KeyTransform.register_lookup(KeyTransformIRegex)
507 
508 KeyTransform.register_lookup(KeyTransformLt)
509 KeyTransform.register_lookup(KeyTransformLte)
510 KeyTransform.register_lookup(KeyTransformGt)
511 KeyTransform.register_lookup(KeyTransformGte)
512 
513 
514 class KeyTransformFactory:
515 
516     def __init__(self, key_name):
517         self.key_name = key_name
518 
519     def __call__(self, *args, **kwargs):
520         return KeyTransform(self.key_name, *args, **kwargs)

</code><intended_behavior>The code in this location should ensure that when `json.dumps` is used for serializing JSONField data, it supports non-ASCII characters (like Chinese) properly. The default behavior of `json.dumps` is to escape non-ASCII characters, which results in the ASCII representation. To address the issue, ensure the serialization uses `ensure_ascii=False` argument with `json.dumps` to allow Unicode characters to be encoded and displayed correctly. This change should preserve all existing functionalities of JSONField serialization and deserialization in Django but enhance it to properly handle and display Unicode characters in Django admin.</intended_behavior>]
2025-10-15 05:21:59.739 | INFO     | Overall retry 0 succeeded; ending workflow
2025-10-15 05:21:59.739 | INFO     | Search-only: skipping patch selection
2025-10-15 05:21:59.869 | INFO     | Task django__django-13512 completed successfully.
2025-10-15 05:21:59.870 | INFO     | No patch generated. You can try running ACR again.
