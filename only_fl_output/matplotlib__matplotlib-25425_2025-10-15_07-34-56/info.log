2025-10-15 07:34:57.018 | INFO     | Starting overall retry 0 with model gpt-4-0125-preview
2025-10-15 07:35:02.262 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=297, output_tokens=12, cost=0.003330
2025-10-15 07:35:02.263 | INFO     | Test agent decides that the issue statement does not contain reproduction steps; skipping reproducer tracing
2025-10-15 07:35:02.266 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-15 07:35:12.354 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=604, output_tokens=302, cost=0.015100
2025-10-15 07:35:12.358 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-15 07:35:15.213 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=656, output_tokens=71, cost=0.008690
2025-10-15 07:35:15.215 | DEBUG    | Extracted a valid json.
2025-10-15 07:35:15.215 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_class(\"AxesImage\")",
        "search_method_in_class(\"get_size\", \"AxesImage\")",
        "search_method_in_class(\"__str__\", \"AxesImage\")",
        "search_method_in_class(\"get_shape\", \"AxesImage\")"
    ],
    "bug_locations": []
}
2025-10-15 07:35:15.241 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-15 07:35:15.242 | DEBUG    | <Agent search> Analyzing search results.
2025-10-15 07:35:29.780 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=1284, output_tokens=632, cost=0.031800
2025-10-15 07:35:29.794 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-15 07:35:40.898 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=2132, output_tokens=364, cost=0.032240
2025-10-15 07:35:40.906 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-15 07:35:50.782 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=718, output_tokens=322, cost=0.016840
2025-10-15 07:35:50.783 | DEBUG    | Extracted a valid json.
2025-10-15 07:35:50.783 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_class(\"_ImageBase\")",
        "search_code_in_file(\"self._A\", \"lib/matplotlib/image.py\")"
    ],
    "bug_locations": [
        {
            "file": "lib/matplotlib/image.py",
            "class": "AxesImage",
            "method": "",
            "intended_behavior": "Implement a new method, `get_shape`, which returns the dimensions of the image stored in `AxesImage`, akin to how numpy's shape attribute works. This method should return `self._A.shape` if `_A` is the internal data structure representing the image, including width, height, and potentially depth (for color images). The method should handle scenarios where `_A` is not yet defined, returning an appropriate default value or raising a clear error. Modify or add an `__str__` method to include the image's shape information in its string representation, formatted as `AxesImage(shape=(nrows, ncols[,...]))`, where `[,...]` is optional and represents additional dimensions such as color channels. This change aims to enhance the clarity and utility of the object's string representation by providing more detailed information about its size and structure, making it consistent with numpy's API where relevant and useful. The structure and content of the `__str__` method should also maintain backward compatibility with any existing functionalities that depend on the current string format. This modification should enhance understanding and debugging capabilities for users working with `AxesImage` instances by aligning more closely with standard shape representation practices."
        }
    ]
}
2025-10-15 07:35:50.818 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-15 07:35:50.819 | DEBUG    | <Agent search> Analyzing search results.
2025-10-15 07:36:05.710 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=3223, output_tokens=660, cost=0.052030
2025-10-15 07:36:05.717 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-15 07:36:13.882 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=4099, output_tokens=357, cost=0.051700
2025-10-15 07:36:13.891 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-15 07:36:24.093 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=711, output_tokens=307, cost=0.016320
2025-10-15 07:36:24.094 | DEBUG    | Extracted a valid json.
2025-10-15 07:36:24.094 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [],
    "bug_locations": [
        {
            "file": "lib/matplotlib/image.py",
            "class": "_ImageBase",
            "method": "__str__",
            "intended_behavior": "Modify the __str__ method to represent the AxesImage object using shape dimensions including depth when relevant. This means formatting the string to show dimensions similar to how numpy's shape attribute works, i.e., shape=(nrows, ncols[, depth]) for images with depth such as RGB(A). This adaptation makes the string representation more informative by including both the width and height, and, where applicable, the depth of the image data. It aligns with user expectations coming from a numpy background and improves usability and comprehensibility of the image objects' string representation."
        },
        {
            "file": "lib/matplotlib/image.py",
            "class": "_ImageBase",
            "method": "",
            "intended_behavior": "Implement a new method, get_shape, that accurately provides the dimensions of the image, potentially including depth for color images. This method should leverage the image's internal representation (likely stored in self._A) to return a tuple reflecting the imageâ€™s width, height, and, if applicable, color channel count. This addresses the enhancement proposal directly by introducing a method with a numpy-consistent naming convention and functionality. It improves the API consistency with numpy and better communicates the capabilities of the AxesImage and related classes to the library users."
        }
    ]
}
2025-10-15 07:36:24.103 | DEBUG    | Bug location extracted successfully: [<file>lib/matplotlib/image.py</file>
<class>_ImageBase</class>
<method>__str__</method>
<code>
276     def __str__(self):
277         try:
278             size = self.get_size()
279             return f"{type(self).__name__}(size={size!r})"
280         except RuntimeError:
281             return type(self).__name__

</code><intended_behavior>Modify the __str__ method to represent the AxesImage object using shape dimensions including depth when relevant. This means formatting the string to show dimensions similar to how numpy's shape attribute works, i.e., shape=(nrows, ncols[, depth]) for images with depth such as RGB(A). This adaptation makes the string representation more informative by including both the width and height, and, where applicable, the depth of the image data. It aligns with user expectations coming from a numpy background and improves usability and comprehensibility of the image objects' string representation.</intended_behavior>, <file>lib/matplotlib/image.py</file>
<class>_ImageBase</class>
<method>None</method>
<code>
230 class _ImageBase(martist.Artist, cm.ScalarMappable):
231     """
232     Base class for images.
233 
234     interpolation and cmap default to their rc settings
235 
236     cmap is a colors.Colormap instance
237     norm is a colors.Normalize instance to map luminance to 0-1
238 
239     extent is data axes (left, right, bottom, top) for making image plots
240     registered with data plots.  Default is to label the pixel
241     centers with the zero-based row and column indices.
242 
243     Additional kwargs are matplotlib.artist properties
244     """
245     zorder = 0
246 
247     def __init__(self, ax,
248                  cmap=None,
249                  norm=None,
250                  interpolation=None,
251                  origin=None,
252                  filternorm=True,
253                  filterrad=4.0,
254                  resample=False,
255                  *,
256                  interpolation_stage=None,
257                  **kwargs
258                  ):
259         martist.Artist.__init__(self)
260         cm.ScalarMappable.__init__(self, norm, cmap)
261         if origin is None:
262             origin = mpl.rcParams['image.origin']
263         _api.check_in_list(["upper", "lower"], origin=origin)
264         self.origin = origin
265         self.set_filternorm(filternorm)
266         self.set_filterrad(filterrad)
267         self.set_interpolation(interpolation)
268         self.set_interpolation_stage(interpolation_stage)
269         self.set_resample(resample)
270         self.axes = ax
271 
272         self._imcache = None
273 
274         self._internal_update(kwargs)
275 
276     def __str__(self):
277         try:
278             size = self.get_size()
279             return f"{type(self).__name__}(size={size!r})"
280         except RuntimeError:
281             return type(self).__name__
282 
283     def __getstate__(self):
284         # Save some space on the pickle by not saving the cache.
285         return {**super().__getstate__(), "_imcache": None}
286 
287     def get_size(self):
288         """Return the size of the image as tuple (numrows, numcols)."""
289         if self._A is None:
290             raise RuntimeError('You must first set the image array')
291 
292         return self._A.shape[:2]
293 
294     def set_alpha(self, alpha):
295         """
296         Set the alpha value used for blending - not supported on all backends.
297 
298         Parameters
299         ----------
300         alpha : float or 2D array-like or None
301         """
302         martist.Artist._set_alpha_for_array(self, alpha)
303         if np.ndim(alpha) not in (0, 2):
304             raise TypeError('alpha must be a float, two-dimensional '
305                             'array, or None')
306         self._imcache = None
307 
308     def _get_scalar_alpha(self):
309         """
310         Get a scalar alpha value to be applied to the artist as a whole.
311 
312         If the alpha value is a matrix, the method returns 1.0 because pixels
313         have individual alpha values (see `~._ImageBase._make_image` for
314         details). If the alpha value is a scalar, the method returns said value
315         to be applied to the artist as a whole because pixels do not have
316         individual alpha values.
317         """
318         return 1.0 if self._alpha is None or np.ndim(self._alpha) > 0 \
319             else self._alpha
320 
321     def changed(self):
322         """
323         Call this whenever the mappable is changed so observers can update.
324         """
325         self._imcache = None
326         cm.ScalarMappable.changed(self)
327 
328     def _make_image(self, A, in_bbox, out_bbox, clip_bbox, magnification=1.0,
329                     unsampled=False, round_to_pixel_border=True):
330         """
331         Normalize, rescale, and colormap the image *A* from the given *in_bbox*
332         (in data space), to the given *out_bbox* (in pixel space) clipped to
333         the given *clip_bbox* (also in pixel space), and magnified by the
334         *magnification* factor.
335 
336         *A* may be a greyscale image (M, N) with a dtype of `~numpy.float32`,
337         `~numpy.float64`, `~numpy.float128`, `~numpy.uint16` or `~numpy.uint8`,
338         or an (M, N, 4) RGBA image with a dtype of `~numpy.float32`,
339         `~numpy.float64`, `~numpy.float128`, or `~numpy.uint8`.
340 
341         If *unsampled* is True, the image will not be scaled, but an
342         appropriate affine transformation will be returned instead.
343 
344         If *round_to_pixel_border* is True, the output image size will be
345         rounded to the nearest pixel boundary.  This makes the images align
346         correctly with the axes.  It should not be used if exact scaling is
347         needed, such as for `FigureImage`.
348 
349         Returns
350         -------
351         image : (M, N, 4) `numpy.uint8` array
352             The RGBA image, resampled unless *unsampled* is True.
353         x, y : float
354             The upper left corner where the image should be drawn, in pixel
355             space.
356         trans : `~matplotlib.transforms.Affine2D`
357             The affine transformation from image to pixel space.
358         """
359         if A is None:
360             raise RuntimeError('You must first set the image '
361                                'array or the image attribute')
362         if A.size == 0:
363             raise RuntimeError("_make_image must get a non-empty image. "
364                                "Your Artist's draw method must filter before "
365                                "this method is called.")
366 
367         clipped_bbox = Bbox.intersection(out_bbox, clip_bbox)
368 
369         if clipped_bbox is None:
370             return None, 0, 0, None
371 
372         out_width_base = clipped_bbox.width * magnification
373         out_height_base = clipped_bbox.height * magnification
374 
375         if out_width_base == 0 or out_height_base == 0:
376             return None, 0, 0, None
377 
378         if self.origin == 'upper':
379             # Flip the input image using a transform.  This avoids the
380             # problem with flipping the array, which results in a copy
381             # when it is converted to contiguous in the C wrapper
382             t0 = Affine2D().translate(0, -A.shape[0]).scale(1, -1)
383         else:
384             t0 = IdentityTransform()
385 
386         t0 += (
387             Affine2D()
388             .scale(
389                 in_bbox.width / A.shape[1],
390                 in_bbox.height / A.shape[0])
391             .translate(in_bbox.x0, in_bbox.y0)
392             + self.get_transform())
393 
394         t = (t0
395              + (Affine2D()
396                 .translate(-clipped_bbox.x0, -clipped_bbox.y0)
397                 .scale(magnification)))
398 
399         # So that the image is aligned with the edge of the axes, we want to
400         # round up the output width to the next integer.  This also means
401         # scaling the transform slightly to account for the extra subpixel.
402         if (t.is_affine and round_to_pixel_border and
403                 (out_width_base % 1.0 != 0.0 or out_height_base % 1.0 != 0.0)):
404             out_width = math.ceil(out_width_base)
405             out_height = math.ceil(out_height_base)
406             extra_width = (out_width - out_width_base) / out_width_base
407             extra_height = (out_height - out_height_base) / out_height_base
408             t += Affine2D().scale(1.0 + extra_width, 1.0 + extra_height)
409         else:
410             out_width = int(out_width_base)
411             out_height = int(out_height_base)
412         out_shape = (out_height, out_width)
413 
414         if not unsampled:
415             if not (A.ndim == 2 or A.ndim == 3 and A.shape[-1] in (3, 4)):
416                 raise ValueError(f"Invalid shape {A.shape} for image data")
417             if A.ndim == 2 and self._interpolation_stage != 'rgba':
418                 # if we are a 2D array, then we are running through the
419                 # norm + colormap transformation.  However, in general the
420                 # input data is not going to match the size on the screen so we
421                 # have to resample to the correct number of pixels
422 
423                 # TODO slice input array first
424                 a_min = A.min()
425                 a_max = A.max()
426                 if a_min is np.ma.masked:  # All masked; values don't matter.
427                     a_min, a_max = np.int32(0), np.int32(1)
428                 if A.dtype.kind == 'f':  # Float dtype: scale to same dtype.
429                     scaled_dtype = np.dtype(
430                         np.float64 if A.dtype.itemsize > 4 else np.float32)
431                     if scaled_dtype.itemsize < A.dtype.itemsize:
432                         _api.warn_external(f"Casting input data from {A.dtype}"
433                                            f" to {scaled_dtype} for imshow.")
434                 else:  # Int dtype, likely.
435                     # Scale to appropriately sized float: use float32 if the
436                     # dynamic range is small, to limit the memory footprint.
437                     da = a_max.astype(np.float64) - a_min.astype(np.float64)
438                     scaled_dtype = np.float64 if da > 1e8 else np.float32
439 
440                 # Scale the input data to [.1, .9].  The Agg interpolators clip
441                 # to [0, 1] internally, and we use a smaller input scale to
442                 # identify the interpolated points that need to be flagged as
443                 # over/under.  This may introduce numeric instabilities in very
444                 # broadly scaled data.
445 
446                 # Always copy, and don't allow array subtypes.
447                 A_scaled = np.array(A, dtype=scaled_dtype)
448                 # Clip scaled data around norm if necessary.  This is necessary
449                 # for big numbers at the edge of float64's ability to represent
450                 # changes.  Applying a norm first would be good, but ruins the
451                 # interpolation of over numbers.
452                 self.norm.autoscale_None(A)
453                 dv = np.float64(self.norm.vmax) - np.float64(self.norm.vmin)
454                 vmid = np.float64(self.norm.vmin) + dv / 2
455                 fact = 1e7 if scaled_dtype == np.float64 else 1e4
456                 newmin = vmid - dv * fact
457                 if newmin < a_min:
458                     newmin = None
459                 else:
460                     a_min = np.float64(newmin)
461                 newmax = vmid + dv * fact
462                 if newmax > a_max:
463                     newmax = None
464                 else:
465                     a_max = np.float64(newmax)
466                 if newmax is not None or newmin is not None:
467                     np.clip(A_scaled, newmin, newmax, out=A_scaled)
468 
469                 # Rescale the raw data to [offset, 1-offset] so that the
470                 # resampling code will run cleanly.  Using dyadic numbers here
471                 # could reduce the error, but would not fully eliminate it and
472                 # breaks a number of tests (due to the slightly different
473                 # error bouncing some pixels across a boundary in the (very
474                 # quantized) colormapping step).
475                 offset = .1
476                 frac = .8
477                 # Run vmin/vmax through the same rescaling as the raw data;
478                 # otherwise, data values close or equal to the boundaries can
479                 # end up on the wrong side due to floating point error.
480                 vmin, vmax = self.norm.vmin, self.norm.vmax
481                 if vmin is np.ma.masked:
482                     vmin, vmax = a_min, a_max
483                 vrange = np.array([vmin, vmax], dtype=scaled_dtype)
484 
485                 A_scaled -= a_min
486                 vrange -= a_min
487                 # .item() handles a_min/a_max being ndarray subclasses.
488                 a_min = a_min.astype(scaled_dtype).item()
489                 a_max = a_max.astype(scaled_dtype).item()
490 
491                 if a_min != a_max:
492                     A_scaled /= ((a_max - a_min) / frac)
493                     vrange /= ((a_max - a_min) / frac)
494                 A_scaled += offset
495                 vrange += offset
496                 # resample the input data to the correct resolution and shape
497                 A_resampled = _resample(self, A_scaled, out_shape, t)
498                 del A_scaled  # Make sure we don't use A_scaled anymore!
499                 # Un-scale the resampled data to approximately the original
500                 # range. Things that interpolated to outside the original range
501                 # will still be outside, but possibly clipped in the case of
502                 # higher order interpolation + drastically changing data.
503                 A_resampled -= offset
504                 vrange -= offset
505                 if a_min != a_max:
506                     A_resampled *= ((a_max - a_min) / frac)
507                     vrange *= ((a_max - a_min) / frac)
508                 A_resampled += a_min
509                 vrange += a_min
510                 # if using NoNorm, cast back to the original datatype
511                 if isinstance(self.norm, mcolors.NoNorm):
512                     A_resampled = A_resampled.astype(A.dtype)
513 
514                 mask = (np.where(A.mask, np.float32(np.nan), np.float32(1))
515                         if A.mask.shape == A.shape  # nontrivial mask
516                         else np.ones_like(A, np.float32))
517                 # we always have to interpolate the mask to account for
518                 # non-affine transformations
519                 out_alpha = _resample(self, mask, out_shape, t, resample=True)
520                 del mask  # Make sure we don't use mask anymore!
521                 # Agg updates out_alpha in place.  If the pixel has no image
522                 # data it will not be updated (and still be 0 as we initialized
523                 # it), if input data that would go into that output pixel than
524                 # it will be `nan`, if all the input data for a pixel is good
525                 # it will be 1, and if there is _some_ good data in that output
526                 # pixel it will be between [0, 1] (such as a rotated image).
527                 out_mask = np.isnan(out_alpha)
528                 out_alpha[out_mask] = 1
529                 # Apply the pixel-by-pixel alpha values if present
530                 alpha = self.get_alpha()
531                 if alpha is not None and np.ndim(alpha) > 0:
532                     out_alpha *= _resample(self, alpha, out_shape,
533                                            t, resample=True)
534                 # mask and run through the norm
535                 resampled_masked = np.ma.masked_array(A_resampled, out_mask)
536                 # we have re-set the vmin/vmax to account for small errors
537                 # that may have moved input values in/out of range
538                 s_vmin, s_vmax = vrange
539                 if isinstance(self.norm, mcolors.LogNorm) and s_vmin <= 0:
540                     # Don't give 0 or negative values to LogNorm
541                     s_vmin = np.finfo(scaled_dtype).eps
542                 # Block the norm from sending an update signal during the
543                 # temporary vmin/vmax change
544                 with self.norm.callbacks.blocked(), \
545                      cbook._setattr_cm(self.norm, vmin=s_vmin, vmax=s_vmax):
546                     output = self.norm(resampled_masked)
547             else:
548                 if A.ndim == 2:  # _interpolation_stage == 'rgba'
549                     self.norm.autoscale_None(A)
550                     A = self.to_rgba(A)
551                 if A.shape[2] == 3:
552                     A = _rgb_to_rgba(A)
553                 alpha = self._get_scalar_alpha()
554                 output_alpha = _resample(  # resample alpha channel
555                     self, A[..., 3], out_shape, t, alpha=alpha)
556                 output = _resample(  # resample rgb channels
557                     self, _rgb_to_rgba(A[..., :3]), out_shape, t, alpha=alpha)
558                 output[..., 3] = output_alpha  # recombine rgb and alpha
559 
560             # output is now either a 2D array of normed (int or float) data
561             # or an RGBA array of re-sampled input
562             output = self.to_rgba(output, bytes=True, norm=False)
563             # output is now a correctly sized RGBA array of uint8
564 
565             # Apply alpha *after* if the input was greyscale without a mask
566             if A.ndim == 2:
567                 alpha = self._get_scalar_alpha()
568                 alpha_channel = output[:, :, 3]
569                 alpha_channel[:] = (  # Assignment will cast to uint8.
570                     alpha_channel.astype(np.float32) * out_alpha * alpha)
571 
572         else:
573             if self._imcache is None:
574                 self._imcache = self.to_rgba(A, bytes=True, norm=(A.ndim == 2))
575             output = self._imcache
576 
577             # Subset the input image to only the part that will be displayed.
578             subset = TransformedBbox(clip_bbox, t0.inverted()).frozen()
579             output = output[
580                 int(max(subset.ymin, 0)):
581                 int(min(subset.ymax + 1, output.shape[0])),
582                 int(max(subset.xmin, 0)):
583                 int(min(subset.xmax + 1, output.shape[1]))]
584 
585             t = Affine2D().translate(
586                 int(max(subset.xmin, 0)), int(max(subset.ymin, 0))) + t
587 
588         return output, clipped_bbox.x0, clipped_bbox.y0, t
589 
590     def make_image(self, renderer, magnification=1.0, unsampled=False):
591         """
592         Normalize, rescale, and colormap this image's data for rendering using
593         *renderer*, with the given *magnification*.
594 
595         If *unsampled* is True, the image will not be scaled, but an
596         appropriate affine transformation will be returned instead.
597 
598         Returns
599         -------
600         image : (M, N, 4) `numpy.uint8` array
601             The RGBA image, resampled unless *unsampled* is True.
602         x, y : float
603             The upper left corner where the image should be drawn, in pixel
604             space.
605         trans : `~matplotlib.transforms.Affine2D`
606             The affine transformation from image to pixel space.
607         """
608         raise NotImplementedError('The make_image method must be overridden')
609 
610     def _check_unsampled_image(self):
611         """
612         Return whether the image is better to be drawn unsampled.
613 
614         The derived class needs to override it.
615         """
616         return False
617 
618     @martist.allow_rasterization
619     def draw(self, renderer, *args, **kwargs):
620         # if not visible, declare victory and return
621         if not self.get_visible():
622             self.stale = False
623             return
624         # for empty images, there is nothing to draw!
625         if self.get_array().size == 0:
626             self.stale = False
627             return
628         # actually render the image.
629         gc = renderer.new_gc()
630         self._set_gc_clip(gc)
631         gc.set_alpha(self._get_scalar_alpha())
632         gc.set_url(self.get_url())
633         gc.set_gid(self.get_gid())
634         if (renderer.option_scale_image()  # Renderer supports transform kwarg.
635                 and self._check_unsampled_image()
636                 and self.get_transform().is_affine):
637             im, l, b, trans = self.make_image(renderer, unsampled=True)
638             if im is not None:
639                 trans = Affine2D().scale(im.shape[1], im.shape[0]) + trans
640                 renderer.draw_image(gc, l, b, im, trans)
641         else:
642             im, l, b, trans = self.make_image(
643                 renderer, renderer.get_image_magnification())
644             if im is not None:
645                 renderer.draw_image(gc, l, b, im)
646         gc.restore()
647         self.stale = False
648 
649     def contains(self, mouseevent):
650         """Test whether the mouse event occurred within the image."""
651         inside, info = self._default_contains(mouseevent)
652         if inside is not None:
653             return inside, info
654         # 1) This doesn't work for figimage; but figimage also needs a fix
655         #    below (as the check cannot use x/ydata and extents).
656         # 2) As long as the check below uses x/ydata, we need to test axes
657         #    identity instead of `self.axes.contains(event)` because even if
658         #    axes overlap, x/ydata is only valid for event.inaxes anyways.
659         if self.axes is not mouseevent.inaxes:
660             return False, {}
661         # TODO: make sure this is consistent with patch and patch
662         # collection on nonlinear transformed coordinates.
663         # TODO: consider returning image coordinates (shouldn't
664         # be too difficult given that the image is rectilinear
665         trans = self.get_transform().inverted()
666         x, y = trans.transform([mouseevent.x, mouseevent.y])
667         xmin, xmax, ymin, ymax = self.get_extent()
668         if xmin > xmax:
669             xmin, xmax = xmax, xmin
670         if ymin > ymax:
671             ymin, ymax = ymax, ymin
672 
673         if x is not None and y is not None:
674             inside = (xmin <= x <= xmax) and (ymin <= y <= ymax)
675         else:
676             inside = False
677 
678         return inside, {}
679 
680     def write_png(self, fname):
681         """Write the image to png file *fname*."""
682         im = self.to_rgba(self._A[::-1] if self.origin == 'lower' else self._A,
683                           bytes=True, norm=True)
684         PIL.Image.fromarray(im).save(fname, format="png")
685 
686     def set_data(self, A):
687         """
688         Set the image array.
689 
690         Note that this function does *not* update the normalization used.
691 
692         Parameters
693         ----------
694         A : array-like or `PIL.Image.Image`
695         """
696         if isinstance(A, PIL.Image.Image):
697             A = pil_to_array(A)  # Needed e.g. to apply png palette.
698         self._A = cbook.safe_masked_invalid(A, copy=True)
699 
700         if (self._A.dtype != np.uint8 and
701                 not np.can_cast(self._A.dtype, float, "same_kind")):
702             raise TypeError(f"Image data of dtype {self._A.dtype} cannot be "
703                             "converted to float")
704 
705         if self._A.ndim == 3 and self._A.shape[-1] == 1:
706             # If just one dimension assume scalar and apply colormap
707             self._A = self._A[:, :, 0]
708 
709         if not (self._A.ndim == 2
710                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):
711             raise TypeError(f"Invalid shape {self._A.shape} for image data")
712 
713         if self._A.ndim == 3:
714             # If the input data has values outside the valid range (after
715             # normalisation), we issue a warning and then clip X to the bounds
716             # - otherwise casting wraps extreme values, hiding outliers and
717             # making reliable interpretation impossible.
718             high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1
719             if self._A.min() < 0 or high < self._A.max():
720                 _log.warning(
721                     'Clipping input data to the valid range for imshow with '
722                     'RGB data ([0..1] for floats or [0..255] for integers).'
723                 )
724                 self._A = np.clip(self._A, 0, high)
725             # Cast unsupported integer types to uint8
726             if self._A.dtype != np.uint8 and np.issubdtype(self._A.dtype,
727                                                            np.integer):
728                 self._A = self._A.astype(np.uint8)
729 
730         self._imcache = None
731         self.stale = True
732 
733     def set_array(self, A):
734         """
735         Retained for backwards compatibility - use set_data instead.
736 
737         Parameters
738         ----------
739         A : array-like
740         """
741         # This also needs to be here to override the inherited
742         # cm.ScalarMappable.set_array method so it is not invoked by mistake.
743         self.set_data(A)
744 
745     def get_interpolation(self):
746         """
747         Return the interpolation method the image uses when resizing.
748 
749         One of 'antialiased', 'nearest', 'bilinear', 'bicubic', 'spline16',
750         'spline36', 'hanning', 'hamming', 'hermite', 'kaiser', 'quadric',
751         'catrom', 'gaussian', 'bessel', 'mitchell', 'sinc', 'lanczos',
752         or 'none'.
753         """
754         return self._interpolation
755 
756     def set_interpolation(self, s):
757         """
758         Set the interpolation method the image uses when resizing.
759 
760         If None, use :rc:`image.interpolation`. If 'none', the image is
761         shown as is without interpolating. 'none' is only supported in
762         agg, ps and pdf backends and will fall back to 'nearest' mode
763         for other backends.
764 
765         Parameters
766         ----------
767         s : {'antialiased', 'nearest', 'bilinear', 'bicubic', 'spline16', \
768 'spline36', 'hanning', 'hamming', 'hermite', 'kaiser', 'quadric', 'catrom', \
769 'gaussian', 'bessel', 'mitchell', 'sinc', 'lanczos', 'none'} or None
770         """
771         if s is None:
772             s = mpl.rcParams['image.interpolation']
773         s = s.lower()
774         _api.check_in_list(_interpd_, interpolation=s)
775         self._interpolation = s
776         self.stale = True
777 
778     def set_interpolation_stage(self, s):
779         """
780         Set when interpolation happens during the transform to RGBA.
781 
782         Parameters
783         ----------
784         s : {'data', 'rgba'} or None
785             Whether to apply up/downsampling interpolation in data or RGBA
786             space.
787         """
788         if s is None:
789             s = "data"  # placeholder for maybe having rcParam
790         _api.check_in_list(['data', 'rgba'], s=s)
791         self._interpolation_stage = s
792         self.stale = True
793 
794     def can_composite(self):
795         """Return whether the image can be composited with its neighbors."""
796         trans = self.get_transform()
797         return (
798             self._interpolation != 'none' and
799             trans.is_affine and
800             trans.is_separable)
801 
802     def set_resample(self, v):
803         """
804         Set whether image resampling is used.
805 
806         Parameters
807         ----------
808         v : bool or None
809             If None, use :rc:`image.resample`.
810         """
811         if v is None:
812             v = mpl.rcParams['image.resample']
813         self._resample = v
814         self.stale = True
815 
816     def get_resample(self):
817         """Return whether image resampling is used."""
818         return self._resample
819 
820     def set_filternorm(self, filternorm):
821         """
822         Set whether the resize filter normalizes the weights.
823 
824         See help for `~.Axes.imshow`.
825 
826         Parameters
827         ----------
828         filternorm : bool
829         """
830         self._filternorm = bool(filternorm)
831         self.stale = True
832 
833     def get_filternorm(self):
834         """Return whether the resize filter normalizes the weights."""
835         return self._filternorm
836 
837     def set_filterrad(self, filterrad):
838         """
839         Set the resize filter radius only applicable to some
840         interpolation schemes -- see help for imshow
841 
842         Parameters
843         ----------
844         filterrad : positive float
845         """
846         r = float(filterrad)
847         if r <= 0:
848             raise ValueError("The filter radius must be a positive number")
849         self._filterrad = r
850         self.stale = True
851 
852     def get_filterrad(self):
853         """Return the filterrad setting."""
854         return self._filterrad

</code><intended_behavior>This class provides additional context to the issue.</intended_behavior>, <file>lib/matplotlib/image.py</file>
<class>_ImageBase</class>
<method>None</method>
<code>
230 class _ImageBase(martist.Artist, cm.ScalarMappable):
231     """
232     Base class for images.
233 
234     interpolation and cmap default to their rc settings
235 
236     cmap is a colors.Colormap instance
237     norm is a colors.Normalize instance to map luminance to 0-1
238 
239     extent is data axes (left, right, bottom, top) for making image plots
240     registered with data plots.  Default is to label the pixel
241     centers with the zero-based row and column indices.
242 
243     Additional kwargs are matplotlib.artist properties
244     """
245     zorder = 0
246 
247     def __init__(self, ax,
248                  cmap=None,
249                  norm=None,
250                  interpolation=None,
251                  origin=None,
252                  filternorm=True,
253                  filterrad=4.0,
254                  resample=False,
255                  *,
256                  interpolation_stage=None,
257                  **kwargs
258                  ):
259         martist.Artist.__init__(self)
260         cm.ScalarMappable.__init__(self, norm, cmap)
261         if origin is None:
262             origin = mpl.rcParams['image.origin']
263         _api.check_in_list(["upper", "lower"], origin=origin)
264         self.origin = origin
265         self.set_filternorm(filternorm)
266         self.set_filterrad(filterrad)
267         self.set_interpolation(interpolation)
268         self.set_interpolation_stage(interpolation_stage)
269         self.set_resample(resample)
270         self.axes = ax
271 
272         self._imcache = None
273 
274         self._internal_update(kwargs)
275 
276     def __str__(self):
277         try:
278             size = self.get_size()
279             return f"{type(self).__name__}(size={size!r})"
280         except RuntimeError:
281             return type(self).__name__
282 
283     def __getstate__(self):
284         # Save some space on the pickle by not saving the cache.
285         return {**super().__getstate__(), "_imcache": None}
286 
287     def get_size(self):
288         """Return the size of the image as tuple (numrows, numcols)."""
289         if self._A is None:
290             raise RuntimeError('You must first set the image array')
291 
292         return self._A.shape[:2]
293 
294     def set_alpha(self, alpha):
295         """
296         Set the alpha value used for blending - not supported on all backends.
297 
298         Parameters
299         ----------
300         alpha : float or 2D array-like or None
301         """
302         martist.Artist._set_alpha_for_array(self, alpha)
303         if np.ndim(alpha) not in (0, 2):
304             raise TypeError('alpha must be a float, two-dimensional '
305                             'array, or None')
306         self._imcache = None
307 
308     def _get_scalar_alpha(self):
309         """
310         Get a scalar alpha value to be applied to the artist as a whole.
311 
312         If the alpha value is a matrix, the method returns 1.0 because pixels
313         have individual alpha values (see `~._ImageBase._make_image` for
314         details). If the alpha value is a scalar, the method returns said value
315         to be applied to the artist as a whole because pixels do not have
316         individual alpha values.
317         """
318         return 1.0 if self._alpha is None or np.ndim(self._alpha) > 0 \
319             else self._alpha
320 
321     def changed(self):
322         """
323         Call this whenever the mappable is changed so observers can update.
324         """
325         self._imcache = None
326         cm.ScalarMappable.changed(self)
327 
328     def _make_image(self, A, in_bbox, out_bbox, clip_bbox, magnification=1.0,
329                     unsampled=False, round_to_pixel_border=True):
330         """
331         Normalize, rescale, and colormap the image *A* from the given *in_bbox*
332         (in data space), to the given *out_bbox* (in pixel space) clipped to
333         the given *clip_bbox* (also in pixel space), and magnified by the
334         *magnification* factor.
335 
336         *A* may be a greyscale image (M, N) with a dtype of `~numpy.float32`,
337         `~numpy.float64`, `~numpy.float128`, `~numpy.uint16` or `~numpy.uint8`,
338         or an (M, N, 4) RGBA image with a dtype of `~numpy.float32`,
339         `~numpy.float64`, `~numpy.float128`, or `~numpy.uint8`.
340 
341         If *unsampled* is True, the image will not be scaled, but an
342         appropriate affine transformation will be returned instead.
343 
344         If *round_to_pixel_border* is True, the output image size will be
345         rounded to the nearest pixel boundary.  This makes the images align
346         correctly with the axes.  It should not be used if exact scaling is
347         needed, such as for `FigureImage`.
348 
349         Returns
350         -------
351         image : (M, N, 4) `numpy.uint8` array
352             The RGBA image, resampled unless *unsampled* is True.
353         x, y : float
354             The upper left corner where the image should be drawn, in pixel
355             space.
356         trans : `~matplotlib.transforms.Affine2D`
357             The affine transformation from image to pixel space.
358         """
359         if A is None:
360             raise RuntimeError('You must first set the image '
361                                'array or the image attribute')
362         if A.size == 0:
363             raise RuntimeError("_make_image must get a non-empty image. "
364                                "Your Artist's draw method must filter before "
365                                "this method is called.")
366 
367         clipped_bbox = Bbox.intersection(out_bbox, clip_bbox)
368 
369         if clipped_bbox is None:
370             return None, 0, 0, None
371 
372         out_width_base = clipped_bbox.width * magnification
373         out_height_base = clipped_bbox.height * magnification
374 
375         if out_width_base == 0 or out_height_base == 0:
376             return None, 0, 0, None
377 
378         if self.origin == 'upper':
379             # Flip the input image using a transform.  This avoids the
380             # problem with flipping the array, which results in a copy
381             # when it is converted to contiguous in the C wrapper
382             t0 = Affine2D().translate(0, -A.shape[0]).scale(1, -1)
383         else:
384             t0 = IdentityTransform()
385 
386         t0 += (
387             Affine2D()
388             .scale(
389                 in_bbox.width / A.shape[1],
390                 in_bbox.height / A.shape[0])
391             .translate(in_bbox.x0, in_bbox.y0)
392             + self.get_transform())
393 
394         t = (t0
395              + (Affine2D()
396                 .translate(-clipped_bbox.x0, -clipped_bbox.y0)
397                 .scale(magnification)))
398 
399         # So that the image is aligned with the edge of the axes, we want to
400         # round up the output width to the next integer.  This also means
401         # scaling the transform slightly to account for the extra subpixel.
402         if (t.is_affine and round_to_pixel_border and
403                 (out_width_base % 1.0 != 0.0 or out_height_base % 1.0 != 0.0)):
404             out_width = math.ceil(out_width_base)
405             out_height = math.ceil(out_height_base)
406             extra_width = (out_width - out_width_base) / out_width_base
407             extra_height = (out_height - out_height_base) / out_height_base
408             t += Affine2D().scale(1.0 + extra_width, 1.0 + extra_height)
409         else:
410             out_width = int(out_width_base)
411             out_height = int(out_height_base)
412         out_shape = (out_height, out_width)
413 
414         if not unsampled:
415             if not (A.ndim == 2 or A.ndim == 3 and A.shape[-1] in (3, 4)):
416                 raise ValueError(f"Invalid shape {A.shape} for image data")
417             if A.ndim == 2 and self._interpolation_stage != 'rgba':
418                 # if we are a 2D array, then we are running through the
419                 # norm + colormap transformation.  However, in general the
420                 # input data is not going to match the size on the screen so we
421                 # have to resample to the correct number of pixels
422 
423                 # TODO slice input array first
424                 a_min = A.min()
425                 a_max = A.max()
426                 if a_min is np.ma.masked:  # All masked; values don't matter.
427                     a_min, a_max = np.int32(0), np.int32(1)
428                 if A.dtype.kind == 'f':  # Float dtype: scale to same dtype.
429                     scaled_dtype = np.dtype(
430                         np.float64 if A.dtype.itemsize > 4 else np.float32)
431                     if scaled_dtype.itemsize < A.dtype.itemsize:
432                         _api.warn_external(f"Casting input data from {A.dtype}"
433                                            f" to {scaled_dtype} for imshow.")
434                 else:  # Int dtype, likely.
435                     # Scale to appropriately sized float: use float32 if the
436                     # dynamic range is small, to limit the memory footprint.
437                     da = a_max.astype(np.float64) - a_min.astype(np.float64)
438                     scaled_dtype = np.float64 if da > 1e8 else np.float32
439 
440                 # Scale the input data to [.1, .9].  The Agg interpolators clip
441                 # to [0, 1] internally, and we use a smaller input scale to
442                 # identify the interpolated points that need to be flagged as
443                 # over/under.  This may introduce numeric instabilities in very
444                 # broadly scaled data.
445 
446                 # Always copy, and don't allow array subtypes.
447                 A_scaled = np.array(A, dtype=scaled_dtype)
448                 # Clip scaled data around norm if necessary.  This is necessary
449                 # for big numbers at the edge of float64's ability to represent
450                 # changes.  Applying a norm first would be good, but ruins the
451                 # interpolation of over numbers.
452                 self.norm.autoscale_None(A)
453                 dv = np.float64(self.norm.vmax) - np.float64(self.norm.vmin)
454                 vmid = np.float64(self.norm.vmin) + dv / 2
455                 fact = 1e7 if scaled_dtype == np.float64 else 1e4
456                 newmin = vmid - dv * fact
457                 if newmin < a_min:
458                     newmin = None
459                 else:
460                     a_min = np.float64(newmin)
461                 newmax = vmid + dv * fact
462                 if newmax > a_max:
463                     newmax = None
464                 else:
465                     a_max = np.float64(newmax)
466                 if newmax is not None or newmin is not None:
467                     np.clip(A_scaled, newmin, newmax, out=A_scaled)
468 
469                 # Rescale the raw data to [offset, 1-offset] so that the
470                 # resampling code will run cleanly.  Using dyadic numbers here
471                 # could reduce the error, but would not fully eliminate it and
472                 # breaks a number of tests (due to the slightly different
473                 # error bouncing some pixels across a boundary in the (very
474                 # quantized) colormapping step).
475                 offset = .1
476                 frac = .8
477                 # Run vmin/vmax through the same rescaling as the raw data;
478                 # otherwise, data values close or equal to the boundaries can
479                 # end up on the wrong side due to floating point error.
480                 vmin, vmax = self.norm.vmin, self.norm.vmax
481                 if vmin is np.ma.masked:
482                     vmin, vmax = a_min, a_max
483                 vrange = np.array([vmin, vmax], dtype=scaled_dtype)
484 
485                 A_scaled -= a_min
486                 vrange -= a_min
487                 # .item() handles a_min/a_max being ndarray subclasses.
488                 a_min = a_min.astype(scaled_dtype).item()
489                 a_max = a_max.astype(scaled_dtype).item()
490 
491                 if a_min != a_max:
492                     A_scaled /= ((a_max - a_min) / frac)
493                     vrange /= ((a_max - a_min) / frac)
494                 A_scaled += offset
495                 vrange += offset
496                 # resample the input data to the correct resolution and shape
497                 A_resampled = _resample(self, A_scaled, out_shape, t)
498                 del A_scaled  # Make sure we don't use A_scaled anymore!
499                 # Un-scale the resampled data to approximately the original
500                 # range. Things that interpolated to outside the original range
501                 # will still be outside, but possibly clipped in the case of
502                 # higher order interpolation + drastically changing data.
503                 A_resampled -= offset
504                 vrange -= offset
505                 if a_min != a_max:
506                     A_resampled *= ((a_max - a_min) / frac)
507                     vrange *= ((a_max - a_min) / frac)
508                 A_resampled += a_min
509                 vrange += a_min
510                 # if using NoNorm, cast back to the original datatype
511                 if isinstance(self.norm, mcolors.NoNorm):
512                     A_resampled = A_resampled.astype(A.dtype)
513 
514                 mask = (np.where(A.mask, np.float32(np.nan), np.float32(1))
515                         if A.mask.shape == A.shape  # nontrivial mask
516                         else np.ones_like(A, np.float32))
517                 # we always have to interpolate the mask to account for
518                 # non-affine transformations
519                 out_alpha = _resample(self, mask, out_shape, t, resample=True)
520                 del mask  # Make sure we don't use mask anymore!
521                 # Agg updates out_alpha in place.  If the pixel has no image
522                 # data it will not be updated (and still be 0 as we initialized
523                 # it), if input data that would go into that output pixel than
524                 # it will be `nan`, if all the input data for a pixel is good
525                 # it will be 1, and if there is _some_ good data in that output
526                 # pixel it will be between [0, 1] (such as a rotated image).
527                 out_mask = np.isnan(out_alpha)
528                 out_alpha[out_mask] = 1
529                 # Apply the pixel-by-pixel alpha values if present
530                 alpha = self.get_alpha()
531                 if alpha is not None and np.ndim(alpha) > 0:
532                     out_alpha *= _resample(self, alpha, out_shape,
533                                            t, resample=True)
534                 # mask and run through the norm
535                 resampled_masked = np.ma.masked_array(A_resampled, out_mask)
536                 # we have re-set the vmin/vmax to account for small errors
537                 # that may have moved input values in/out of range
538                 s_vmin, s_vmax = vrange
539                 if isinstance(self.norm, mcolors.LogNorm) and s_vmin <= 0:
540                     # Don't give 0 or negative values to LogNorm
541                     s_vmin = np.finfo(scaled_dtype).eps
542                 # Block the norm from sending an update signal during the
543                 # temporary vmin/vmax change
544                 with self.norm.callbacks.blocked(), \
545                      cbook._setattr_cm(self.norm, vmin=s_vmin, vmax=s_vmax):
546                     output = self.norm(resampled_masked)
547             else:
548                 if A.ndim == 2:  # _interpolation_stage == 'rgba'
549                     self.norm.autoscale_None(A)
550                     A = self.to_rgba(A)
551                 if A.shape[2] == 3:
552                     A = _rgb_to_rgba(A)
553                 alpha = self._get_scalar_alpha()
554                 output_alpha = _resample(  # resample alpha channel
555                     self, A[..., 3], out_shape, t, alpha=alpha)
556                 output = _resample(  # resample rgb channels
557                     self, _rgb_to_rgba(A[..., :3]), out_shape, t, alpha=alpha)
558                 output[..., 3] = output_alpha  # recombine rgb and alpha
559 
560             # output is now either a 2D array of normed (int or float) data
561             # or an RGBA array of re-sampled input
562             output = self.to_rgba(output, bytes=True, norm=False)
563             # output is now a correctly sized RGBA array of uint8
564 
565             # Apply alpha *after* if the input was greyscale without a mask
566             if A.ndim == 2:
567                 alpha = self._get_scalar_alpha()
568                 alpha_channel = output[:, :, 3]
569                 alpha_channel[:] = (  # Assignment will cast to uint8.
570                     alpha_channel.astype(np.float32) * out_alpha * alpha)
571 
572         else:
573             if self._imcache is None:
574                 self._imcache = self.to_rgba(A, bytes=True, norm=(A.ndim == 2))
575             output = self._imcache
576 
577             # Subset the input image to only the part that will be displayed.
578             subset = TransformedBbox(clip_bbox, t0.inverted()).frozen()
579             output = output[
580                 int(max(subset.ymin, 0)):
581                 int(min(subset.ymax + 1, output.shape[0])),
582                 int(max(subset.xmin, 0)):
583                 int(min(subset.xmax + 1, output.shape[1]))]
584 
585             t = Affine2D().translate(
586                 int(max(subset.xmin, 0)), int(max(subset.ymin, 0))) + t
587 
588         return output, clipped_bbox.x0, clipped_bbox.y0, t
589 
590     def make_image(self, renderer, magnification=1.0, unsampled=False):
591         """
592         Normalize, rescale, and colormap this image's data for rendering using
593         *renderer*, with the given *magnification*.
594 
595         If *unsampled* is True, the image will not be scaled, but an
596         appropriate affine transformation will be returned instead.
597 
598         Returns
599         -------
600         image : (M, N, 4) `numpy.uint8` array
601             The RGBA image, resampled unless *unsampled* is True.
602         x, y : float
603             The upper left corner where the image should be drawn, in pixel
604             space.
605         trans : `~matplotlib.transforms.Affine2D`
606             The affine transformation from image to pixel space.
607         """
608         raise NotImplementedError('The make_image method must be overridden')
609 
610     def _check_unsampled_image(self):
611         """
612         Return whether the image is better to be drawn unsampled.
613 
614         The derived class needs to override it.
615         """
616         return False
617 
618     @martist.allow_rasterization
619     def draw(self, renderer, *args, **kwargs):
620         # if not visible, declare victory and return
621         if not self.get_visible():
622             self.stale = False
623             return
624         # for empty images, there is nothing to draw!
625         if self.get_array().size == 0:
626             self.stale = False
627             return
628         # actually render the image.
629         gc = renderer.new_gc()
630         self._set_gc_clip(gc)
631         gc.set_alpha(self._get_scalar_alpha())
632         gc.set_url(self.get_url())
633         gc.set_gid(self.get_gid())
634         if (renderer.option_scale_image()  # Renderer supports transform kwarg.
635                 and self._check_unsampled_image()
636                 and self.get_transform().is_affine):
637             im, l, b, trans = self.make_image(renderer, unsampled=True)
638             if im is not None:
639                 trans = Affine2D().scale(im.shape[1], im.shape[0]) + trans
640                 renderer.draw_image(gc, l, b, im, trans)
641         else:
642             im, l, b, trans = self.make_image(
643                 renderer, renderer.get_image_magnification())
644             if im is not None:
645                 renderer.draw_image(gc, l, b, im)
646         gc.restore()
647         self.stale = False
648 
649     def contains(self, mouseevent):
650         """Test whether the mouse event occurred within the image."""
651         inside, info = self._default_contains(mouseevent)
652         if inside is not None:
653             return inside, info
654         # 1) This doesn't work for figimage; but figimage also needs a fix
655         #    below (as the check cannot use x/ydata and extents).
656         # 2) As long as the check below uses x/ydata, we need to test axes
657         #    identity instead of `self.axes.contains(event)` because even if
658         #    axes overlap, x/ydata is only valid for event.inaxes anyways.
659         if self.axes is not mouseevent.inaxes:
660             return False, {}
661         # TODO: make sure this is consistent with patch and patch
662         # collection on nonlinear transformed coordinates.
663         # TODO: consider returning image coordinates (shouldn't
664         # be too difficult given that the image is rectilinear
665         trans = self.get_transform().inverted()
666         x, y = trans.transform([mouseevent.x, mouseevent.y])
667         xmin, xmax, ymin, ymax = self.get_extent()
668         if xmin > xmax:
669             xmin, xmax = xmax, xmin
670         if ymin > ymax:
671             ymin, ymax = ymax, ymin
672 
673         if x is not None and y is not None:
674             inside = (xmin <= x <= xmax) and (ymin <= y <= ymax)
675         else:
676             inside = False
677 
678         return inside, {}
679 
680     def write_png(self, fname):
681         """Write the image to png file *fname*."""
682         im = self.to_rgba(self._A[::-1] if self.origin == 'lower' else self._A,
683                           bytes=True, norm=True)
684         PIL.Image.fromarray(im).save(fname, format="png")
685 
686     def set_data(self, A):
687         """
688         Set the image array.
689 
690         Note that this function does *not* update the normalization used.
691 
692         Parameters
693         ----------
694         A : array-like or `PIL.Image.Image`
695         """
696         if isinstance(A, PIL.Image.Image):
697             A = pil_to_array(A)  # Needed e.g. to apply png palette.
698         self._A = cbook.safe_masked_invalid(A, copy=True)
699 
700         if (self._A.dtype != np.uint8 and
701                 not np.can_cast(self._A.dtype, float, "same_kind")):
702             raise TypeError(f"Image data of dtype {self._A.dtype} cannot be "
703                             "converted to float")
704 
705         if self._A.ndim == 3 and self._A.shape[-1] == 1:
706             # If just one dimension assume scalar and apply colormap
707             self._A = self._A[:, :, 0]
708 
709         if not (self._A.ndim == 2
710                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):
711             raise TypeError(f"Invalid shape {self._A.shape} for image data")
712 
713         if self._A.ndim == 3:
714             # If the input data has values outside the valid range (after
715             # normalisation), we issue a warning and then clip X to the bounds
716             # - otherwise casting wraps extreme values, hiding outliers and
717             # making reliable interpretation impossible.
718             high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1
719             if self._A.min() < 0 or high < self._A.max():
720                 _log.warning(
721                     'Clipping input data to the valid range for imshow with '
722                     'RGB data ([0..1] for floats or [0..255] for integers).'
723                 )
724                 self._A = np.clip(self._A, 0, high)
725             # Cast unsupported integer types to uint8
726             if self._A.dtype != np.uint8 and np.issubdtype(self._A.dtype,
727                                                            np.integer):
728                 self._A = self._A.astype(np.uint8)
729 
730         self._imcache = None
731         self.stale = True
732 
733     def set_array(self, A):
734         """
735         Retained for backwards compatibility - use set_data instead.
736 
737         Parameters
738         ----------
739         A : array-like
740         """
741         # This also needs to be here to override the inherited
742         # cm.ScalarMappable.set_array method so it is not invoked by mistake.
743         self.set_data(A)
744 
745     def get_interpolation(self):
746         """
747         Return the interpolation method the image uses when resizing.
748 
749         One of 'antialiased', 'nearest', 'bilinear', 'bicubic', 'spline16',
750         'spline36', 'hanning', 'hamming', 'hermite', 'kaiser', 'quadric',
751         'catrom', 'gaussian', 'bessel', 'mitchell', 'sinc', 'lanczos',
752         or 'none'.
753         """
754         return self._interpolation
755 
756     def set_interpolation(self, s):
757         """
758         Set the interpolation method the image uses when resizing.
759 
760         If None, use :rc:`image.interpolation`. If 'none', the image is
761         shown as is without interpolating. 'none' is only supported in
762         agg, ps and pdf backends and will fall back to 'nearest' mode
763         for other backends.
764 
765         Parameters
766         ----------
767         s : {'antialiased', 'nearest', 'bilinear', 'bicubic', 'spline16', \
768 'spline36', 'hanning', 'hamming', 'hermite', 'kaiser', 'quadric', 'catrom', \
769 'gaussian', 'bessel', 'mitchell', 'sinc', 'lanczos', 'none'} or None
770         """
771         if s is None:
772             s = mpl.rcParams['image.interpolation']
773         s = s.lower()
774         _api.check_in_list(_interpd_, interpolation=s)
775         self._interpolation = s
776         self.stale = True
777 
778     def set_interpolation_stage(self, s):
779         """
780         Set when interpolation happens during the transform to RGBA.
781 
782         Parameters
783         ----------
784         s : {'data', 'rgba'} or None
785             Whether to apply up/downsampling interpolation in data or RGBA
786             space.
787         """
788         if s is None:
789             s = "data"  # placeholder for maybe having rcParam
790         _api.check_in_list(['data', 'rgba'], s=s)
791         self._interpolation_stage = s
792         self.stale = True
793 
794     def can_composite(self):
795         """Return whether the image can be composited with its neighbors."""
796         trans = self.get_transform()
797         return (
798             self._interpolation != 'none' and
799             trans.is_affine and
800             trans.is_separable)
801 
802     def set_resample(self, v):
803         """
804         Set whether image resampling is used.
805 
806         Parameters
807         ----------
808         v : bool or None
809             If None, use :rc:`image.resample`.
810         """
811         if v is None:
812             v = mpl.rcParams['image.resample']
813         self._resample = v
814         self.stale = True
815 
816     def get_resample(self):
817         """Return whether image resampling is used."""
818         return self._resample
819 
820     def set_filternorm(self, filternorm):
821         """
822         Set whether the resize filter normalizes the weights.
823 
824         See help for `~.Axes.imshow`.
825 
826         Parameters
827         ----------
828         filternorm : bool
829         """
830         self._filternorm = bool(filternorm)
831         self.stale = True
832 
833     def get_filternorm(self):
834         """Return whether the resize filter normalizes the weights."""
835         return self._filternorm
836 
837     def set_filterrad(self, filterrad):
838         """
839         Set the resize filter radius only applicable to some
840         interpolation schemes -- see help for imshow
841 
842         Parameters
843         ----------
844         filterrad : positive float
845         """
846         r = float(filterrad)
847         if r <= 0:
848             raise ValueError("The filter radius must be a positive number")
849         self._filterrad = r
850         self.stale = True
851 
852     def get_filterrad(self):
853         """Return the filterrad setting."""
854         return self._filterrad

</code><intended_behavior>Implement a new method, get_shape, that accurately provides the dimensions of the image, potentially including depth for color images. This method should leverage the image's internal representation (likely stored in self._A) to return a tuple reflecting the imageâ€™s width, height, and, if applicable, color channel count. This addresses the enhancement proposal directly by introducing a method with a numpy-consistent naming convention and functionality. It improves the API consistency with numpy and better communicates the capabilities of the AxesImage and related classes to the library users.</intended_behavior>]
2025-10-15 07:36:24.103 | INFO     | Search completed. Bug locations: [<file>lib/matplotlib/image.py</file>
<class>_ImageBase</class>
<method>__str__</method>
<code>
276     def __str__(self):
277         try:
278             size = self.get_size()
279             return f"{type(self).__name__}(size={size!r})"
280         except RuntimeError:
281             return type(self).__name__

</code><intended_behavior>Modify the __str__ method to represent the AxesImage object using shape dimensions including depth when relevant. This means formatting the string to show dimensions similar to how numpy's shape attribute works, i.e., shape=(nrows, ncols[, depth]) for images with depth such as RGB(A). This adaptation makes the string representation more informative by including both the width and height, and, where applicable, the depth of the image data. It aligns with user expectations coming from a numpy background and improves usability and comprehensibility of the image objects' string representation.</intended_behavior>, <file>lib/matplotlib/image.py</file>
<class>_ImageBase</class>
<method>None</method>
<code>
230 class _ImageBase(martist.Artist, cm.ScalarMappable):
231     """
232     Base class for images.
233 
234     interpolation and cmap default to their rc settings
235 
236     cmap is a colors.Colormap instance
237     norm is a colors.Normalize instance to map luminance to 0-1
238 
239     extent is data axes (left, right, bottom, top) for making image plots
240     registered with data plots.  Default is to label the pixel
241     centers with the zero-based row and column indices.
242 
243     Additional kwargs are matplotlib.artist properties
244     """
245     zorder = 0
246 
247     def __init__(self, ax,
248                  cmap=None,
249                  norm=None,
250                  interpolation=None,
251                  origin=None,
252                  filternorm=True,
253                  filterrad=4.0,
254                  resample=False,
255                  *,
256                  interpolation_stage=None,
257                  **kwargs
258                  ):
259         martist.Artist.__init__(self)
260         cm.ScalarMappable.__init__(self, norm, cmap)
261         if origin is None:
262             origin = mpl.rcParams['image.origin']
263         _api.check_in_list(["upper", "lower"], origin=origin)
264         self.origin = origin
265         self.set_filternorm(filternorm)
266         self.set_filterrad(filterrad)
267         self.set_interpolation(interpolation)
268         self.set_interpolation_stage(interpolation_stage)
269         self.set_resample(resample)
270         self.axes = ax
271 
272         self._imcache = None
273 
274         self._internal_update(kwargs)
275 
276     def __str__(self):
277         try:
278             size = self.get_size()
279             return f"{type(self).__name__}(size={size!r})"
280         except RuntimeError:
281             return type(self).__name__
282 
283     def __getstate__(self):
284         # Save some space on the pickle by not saving the cache.
285         return {**super().__getstate__(), "_imcache": None}
286 
287     def get_size(self):
288         """Return the size of the image as tuple (numrows, numcols)."""
289         if self._A is None:
290             raise RuntimeError('You must first set the image array')
291 
292         return self._A.shape[:2]
293 
294     def set_alpha(self, alpha):
295         """
296         Set the alpha value used for blending - not supported on all backends.
297 
298         Parameters
299         ----------
300         alpha : float or 2D array-like or None
301         """
302         martist.Artist._set_alpha_for_array(self, alpha)
303         if np.ndim(alpha) not in (0, 2):
304             raise TypeError('alpha must be a float, two-dimensional '
305                             'array, or None')
306         self._imcache = None
307 
308     def _get_scalar_alpha(self):
309         """
310         Get a scalar alpha value to be applied to the artist as a whole.
311 
312         If the alpha value is a matrix, the method returns 1.0 because pixels
313         have individual alpha values (see `~._ImageBase._make_image` for
314         details). If the alpha value is a scalar, the method returns said value
315         to be applied to the artist as a whole because pixels do not have
316         individual alpha values.
317         """
318         return 1.0 if self._alpha is None or np.ndim(self._alpha) > 0 \
319             else self._alpha
320 
321     def changed(self):
322         """
323         Call this whenever the mappable is changed so observers can update.
324         """
325         self._imcache = None
326         cm.ScalarMappable.changed(self)
327 
328     def _make_image(self, A, in_bbox, out_bbox, clip_bbox, magnification=1.0,
329                     unsampled=False, round_to_pixel_border=True):
330         """
331         Normalize, rescale, and colormap the image *A* from the given *in_bbox*
332         (in data space), to the given *out_bbox* (in pixel space) clipped to
333         the given *clip_bbox* (also in pixel space), and magnified by the
334         *magnification* factor.
335 
336         *A* may be a greyscale image (M, N) with a dtype of `~numpy.float32`,
337         `~numpy.float64`, `~numpy.float128`, `~numpy.uint16` or `~numpy.uint8`,
338         or an (M, N, 4) RGBA image with a dtype of `~numpy.float32`,
339         `~numpy.float64`, `~numpy.float128`, or `~numpy.uint8`.
340 
341         If *unsampled* is True, the image will not be scaled, but an
342         appropriate affine transformation will be returned instead.
343 
344         If *round_to_pixel_border* is True, the output image size will be
345         rounded to the nearest pixel boundary.  This makes the images align
346         correctly with the axes.  It should not be used if exact scaling is
347         needed, such as for `FigureImage`.
348 
349         Returns
350         -------
351         image : (M, N, 4) `numpy.uint8` array
352             The RGBA image, resampled unless *unsampled* is True.
353         x, y : float
354             The upper left corner where the image should be drawn, in pixel
355             space.
356         trans : `~matplotlib.transforms.Affine2D`
357             The affine transformation from image to pixel space.
358         """
359         if A is None:
360             raise RuntimeError('You must first set the image '
361                                'array or the image attribute')
362         if A.size == 0:
363             raise RuntimeError("_make_image must get a non-empty image. "
364                                "Your Artist's draw method must filter before "
365                                "this method is called.")
366 
367         clipped_bbox = Bbox.intersection(out_bbox, clip_bbox)
368 
369         if clipped_bbox is None:
370             return None, 0, 0, None
371 
372         out_width_base = clipped_bbox.width * magnification
373         out_height_base = clipped_bbox.height * magnification
374 
375         if out_width_base == 0 or out_height_base == 0:
376             return None, 0, 0, None
377 
378         if self.origin == 'upper':
379             # Flip the input image using a transform.  This avoids the
380             # problem with flipping the array, which results in a copy
381             # when it is converted to contiguous in the C wrapper
382             t0 = Affine2D().translate(0, -A.shape[0]).scale(1, -1)
383         else:
384             t0 = IdentityTransform()
385 
386         t0 += (
387             Affine2D()
388             .scale(
389                 in_bbox.width / A.shape[1],
390                 in_bbox.height / A.shape[0])
391             .translate(in_bbox.x0, in_bbox.y0)
392             + self.get_transform())
393 
394         t = (t0
395              + (Affine2D()
396                 .translate(-clipped_bbox.x0, -clipped_bbox.y0)
397                 .scale(magnification)))
398 
399         # So that the image is aligned with the edge of the axes, we want to
400         # round up the output width to the next integer.  This also means
401         # scaling the transform slightly to account for the extra subpixel.
402         if (t.is_affine and round_to_pixel_border and
403                 (out_width_base % 1.0 != 0.0 or out_height_base % 1.0 != 0.0)):
404             out_width = math.ceil(out_width_base)
405             out_height = math.ceil(out_height_base)
406             extra_width = (out_width - out_width_base) / out_width_base
407             extra_height = (out_height - out_height_base) / out_height_base
408             t += Affine2D().scale(1.0 + extra_width, 1.0 + extra_height)
409         else:
410             out_width = int(out_width_base)
411             out_height = int(out_height_base)
412         out_shape = (out_height, out_width)
413 
414         if not unsampled:
415             if not (A.ndim == 2 or A.ndim == 3 and A.shape[-1] in (3, 4)):
416                 raise ValueError(f"Invalid shape {A.shape} for image data")
417             if A.ndim == 2 and self._interpolation_stage != 'rgba':
418                 # if we are a 2D array, then we are running through the
419                 # norm + colormap transformation.  However, in general the
420                 # input data is not going to match the size on the screen so we
421                 # have to resample to the correct number of pixels
422 
423                 # TODO slice input array first
424                 a_min = A.min()
425                 a_max = A.max()
426                 if a_min is np.ma.masked:  # All masked; values don't matter.
427                     a_min, a_max = np.int32(0), np.int32(1)
428                 if A.dtype.kind == 'f':  # Float dtype: scale to same dtype.
429                     scaled_dtype = np.dtype(
430                         np.float64 if A.dtype.itemsize > 4 else np.float32)
431                     if scaled_dtype.itemsize < A.dtype.itemsize:
432                         _api.warn_external(f"Casting input data from {A.dtype}"
433                                            f" to {scaled_dtype} for imshow.")
434                 else:  # Int dtype, likely.
435                     # Scale to appropriately sized float: use float32 if the
436                     # dynamic range is small, to limit the memory footprint.
437                     da = a_max.astype(np.float64) - a_min.astype(np.float64)
438                     scaled_dtype = np.float64 if da > 1e8 else np.float32
439 
440                 # Scale the input data to [.1, .9].  The Agg interpolators clip
441                 # to [0, 1] internally, and we use a smaller input scale to
442                 # identify the interpolated points that need to be flagged as
443                 # over/under.  This may introduce numeric instabilities in very
444                 # broadly scaled data.
445 
446                 # Always copy, and don't allow array subtypes.
447                 A_scaled = np.array(A, dtype=scaled_dtype)
448                 # Clip scaled data around norm if necessary.  This is necessary
449                 # for big numbers at the edge of float64's ability to represent
450                 # changes.  Applying a norm first would be good, but ruins the
451                 # interpolation of over numbers.
452                 self.norm.autoscale_None(A)
453                 dv = np.float64(self.norm.vmax) - np.float64(self.norm.vmin)
454                 vmid = np.float64(self.norm.vmin) + dv / 2
455                 fact = 1e7 if scaled_dtype == np.float64 else 1e4
456                 newmin = vmid - dv * fact
457                 if newmin < a_min:
458                     newmin = None
459                 else:
460                     a_min = np.float64(newmin)
461                 newmax = vmid + dv * fact
462                 if newmax > a_max:
463                     newmax = None
464                 else:
465                     a_max = np.float64(newmax)
466                 if newmax is not None or newmin is not None:
467                     np.clip(A_scaled, newmin, newmax, out=A_scaled)
468 
469                 # Rescale the raw data to [offset, 1-offset] so that the
470                 # resampling code will run cleanly.  Using dyadic numbers here
471                 # could reduce the error, but would not fully eliminate it and
472                 # breaks a number of tests (due to the slightly different
473                 # error bouncing some pixels across a boundary in the (very
474                 # quantized) colormapping step).
475                 offset = .1
476                 frac = .8
477                 # Run vmin/vmax through the same rescaling as the raw data;
478                 # otherwise, data values close or equal to the boundaries can
479                 # end up on the wrong side due to floating point error.
480                 vmin, vmax = self.norm.vmin, self.norm.vmax
481                 if vmin is np.ma.masked:
482                     vmin, vmax = a_min, a_max
483                 vrange = np.array([vmin, vmax], dtype=scaled_dtype)
484 
485                 A_scaled -= a_min
486                 vrange -= a_min
487                 # .item() handles a_min/a_max being ndarray subclasses.
488                 a_min = a_min.astype(scaled_dtype).item()
489                 a_max = a_max.astype(scaled_dtype).item()
490 
491                 if a_min != a_max:
492                     A_scaled /= ((a_max - a_min) / frac)
493                     vrange /= ((a_max - a_min) / frac)
494                 A_scaled += offset
495                 vrange += offset
496                 # resample the input data to the correct resolution and shape
497                 A_resampled = _resample(self, A_scaled, out_shape, t)
498                 del A_scaled  # Make sure we don't use A_scaled anymore!
499                 # Un-scale the resampled data to approximately the original
500                 # range. Things that interpolated to outside the original range
501                 # will still be outside, but possibly clipped in the case of
502                 # higher order interpolation + drastically changing data.
503                 A_resampled -= offset
504                 vrange -= offset
505                 if a_min != a_max:
506                     A_resampled *= ((a_max - a_min) / frac)
507                     vrange *= ((a_max - a_min) / frac)
508                 A_resampled += a_min
509                 vrange += a_min
510                 # if using NoNorm, cast back to the original datatype
511                 if isinstance(self.norm, mcolors.NoNorm):
512                     A_resampled = A_resampled.astype(A.dtype)
513 
514                 mask = (np.where(A.mask, np.float32(np.nan), np.float32(1))
515                         if A.mask.shape == A.shape  # nontrivial mask
516                         else np.ones_like(A, np.float32))
517                 # we always have to interpolate the mask to account for
518                 # non-affine transformations
519                 out_alpha = _resample(self, mask, out_shape, t, resample=True)
520                 del mask  # Make sure we don't use mask anymore!
521                 # Agg updates out_alpha in place.  If the pixel has no image
522                 # data it will not be updated (and still be 0 as we initialized
523                 # it), if input data that would go into that output pixel than
524                 # it will be `nan`, if all the input data for a pixel is good
525                 # it will be 1, and if there is _some_ good data in that output
526                 # pixel it will be between [0, 1] (such as a rotated image).
527                 out_mask = np.isnan(out_alpha)
528                 out_alpha[out_mask] = 1
529                 # Apply the pixel-by-pixel alpha values if present
530                 alpha = self.get_alpha()
531                 if alpha is not None and np.ndim(alpha) > 0:
532                     out_alpha *= _resample(self, alpha, out_shape,
533                                            t, resample=True)
534                 # mask and run through the norm
535                 resampled_masked = np.ma.masked_array(A_resampled, out_mask)
536                 # we have re-set the vmin/vmax to account for small errors
537                 # that may have moved input values in/out of range
538                 s_vmin, s_vmax = vrange
539                 if isinstance(self.norm, mcolors.LogNorm) and s_vmin <= 0:
540                     # Don't give 0 or negative values to LogNorm
541                     s_vmin = np.finfo(scaled_dtype).eps
542                 # Block the norm from sending an update signal during the
543                 # temporary vmin/vmax change
544                 with self.norm.callbacks.blocked(), \
545                      cbook._setattr_cm(self.norm, vmin=s_vmin, vmax=s_vmax):
546                     output = self.norm(resampled_masked)
547             else:
548                 if A.ndim == 2:  # _interpolation_stage == 'rgba'
549                     self.norm.autoscale_None(A)
550                     A = self.to_rgba(A)
551                 if A.shape[2] == 3:
552                     A = _rgb_to_rgba(A)
553                 alpha = self._get_scalar_alpha()
554                 output_alpha = _resample(  # resample alpha channel
555                     self, A[..., 3], out_shape, t, alpha=alpha)
556                 output = _resample(  # resample rgb channels
557                     self, _rgb_to_rgba(A[..., :3]), out_shape, t, alpha=alpha)
558                 output[..., 3] = output_alpha  # recombine rgb and alpha
559 
560             # output is now either a 2D array of normed (int or float) data
561             # or an RGBA array of re-sampled input
562             output = self.to_rgba(output, bytes=True, norm=False)
563             # output is now a correctly sized RGBA array of uint8
564 
565             # Apply alpha *after* if the input was greyscale without a mask
566             if A.ndim == 2:
567                 alpha = self._get_scalar_alpha()
568                 alpha_channel = output[:, :, 3]
569                 alpha_channel[:] = (  # Assignment will cast to uint8.
570                     alpha_channel.astype(np.float32) * out_alpha * alpha)
571 
572         else:
573             if self._imcache is None:
574                 self._imcache = self.to_rgba(A, bytes=True, norm=(A.ndim == 2))
575             output = self._imcache
576 
577             # Subset the input image to only the part that will be displayed.
578             subset = TransformedBbox(clip_bbox, t0.inverted()).frozen()
579             output = output[
580                 int(max(subset.ymin, 0)):
581                 int(min(subset.ymax + 1, output.shape[0])),
582                 int(max(subset.xmin, 0)):
583                 int(min(subset.xmax + 1, output.shape[1]))]
584 
585             t = Affine2D().translate(
586                 int(max(subset.xmin, 0)), int(max(subset.ymin, 0))) + t
587 
588         return output, clipped_bbox.x0, clipped_bbox.y0, t
589 
590     def make_image(self, renderer, magnification=1.0, unsampled=False):
591         """
592         Normalize, rescale, and colormap this image's data for rendering using
593         *renderer*, with the given *magnification*.
594 
595         If *unsampled* is True, the image will not be scaled, but an
596         appropriate affine transformation will be returned instead.
597 
598         Returns
599         -------
600         image : (M, N, 4) `numpy.uint8` array
601             The RGBA image, resampled unless *unsampled* is True.
602         x, y : float
603             The upper left corner where the image should be drawn, in pixel
604             space.
605         trans : `~matplotlib.transforms.Affine2D`
606             The affine transformation from image to pixel space.
607         """
608         raise NotImplementedError('The make_image method must be overridden')
609 
610     def _check_unsampled_image(self):
611         """
612         Return whether the image is better to be drawn unsampled.
613 
614         The derived class needs to override it.
615         """
616         return False
617 
618     @martist.allow_rasterization
619     def draw(self, renderer, *args, **kwargs):
620         # if not visible, declare victory and return
621         if not self.get_visible():
622             self.stale = False
623             return
624         # for empty images, there is nothing to draw!
625         if self.get_array().size == 0:
626             self.stale = False
627             return
628         # actually render the image.
629         gc = renderer.new_gc()
630         self._set_gc_clip(gc)
631         gc.set_alpha(self._get_scalar_alpha())
632         gc.set_url(self.get_url())
633         gc.set_gid(self.get_gid())
634         if (renderer.option_scale_image()  # Renderer supports transform kwarg.
635                 and self._check_unsampled_image()
636                 and self.get_transform().is_affine):
637             im, l, b, trans = self.make_image(renderer, unsampled=True)
638             if im is not None:
639                 trans = Affine2D().scale(im.shape[1], im.shape[0]) + trans
640                 renderer.draw_image(gc, l, b, im, trans)
641         else:
642             im, l, b, trans = self.make_image(
643                 renderer, renderer.get_image_magnification())
644             if im is not None:
645                 renderer.draw_image(gc, l, b, im)
646         gc.restore()
647         self.stale = False
648 
649     def contains(self, mouseevent):
650         """Test whether the mouse event occurred within the image."""
651         inside, info = self._default_contains(mouseevent)
652         if inside is not None:
653             return inside, info
654         # 1) This doesn't work for figimage; but figimage also needs a fix
655         #    below (as the check cannot use x/ydata and extents).
656         # 2) As long as the check below uses x/ydata, we need to test axes
657         #    identity instead of `self.axes.contains(event)` because even if
658         #    axes overlap, x/ydata is only valid for event.inaxes anyways.
659         if self.axes is not mouseevent.inaxes:
660             return False, {}
661         # TODO: make sure this is consistent with patch and patch
662         # collection on nonlinear transformed coordinates.
663         # TODO: consider returning image coordinates (shouldn't
664         # be too difficult given that the image is rectilinear
665         trans = self.get_transform().inverted()
666         x, y = trans.transform([mouseevent.x, mouseevent.y])
667         xmin, xmax, ymin, ymax = self.get_extent()
668         if xmin > xmax:
669             xmin, xmax = xmax, xmin
670         if ymin > ymax:
671             ymin, ymax = ymax, ymin
672 
673         if x is not None and y is not None:
674             inside = (xmin <= x <= xmax) and (ymin <= y <= ymax)
675         else:
676             inside = False
677 
678         return inside, {}
679 
680     def write_png(self, fname):
681         """Write the image to png file *fname*."""
682         im = self.to_rgba(self._A[::-1] if self.origin == 'lower' else self._A,
683                           bytes=True, norm=True)
684         PIL.Image.fromarray(im).save(fname, format="png")
685 
686     def set_data(self, A):
687         """
688         Set the image array.
689 
690         Note that this function does *not* update the normalization used.
691 
692         Parameters
693         ----------
694         A : array-like or `PIL.Image.Image`
695         """
696         if isinstance(A, PIL.Image.Image):
697             A = pil_to_array(A)  # Needed e.g. to apply png palette.
698         self._A = cbook.safe_masked_invalid(A, copy=True)
699 
700         if (self._A.dtype != np.uint8 and
701                 not np.can_cast(self._A.dtype, float, "same_kind")):
702             raise TypeError(f"Image data of dtype {self._A.dtype} cannot be "
703                             "converted to float")
704 
705         if self._A.ndim == 3 and self._A.shape[-1] == 1:
706             # If just one dimension assume scalar and apply colormap
707             self._A = self._A[:, :, 0]
708 
709         if not (self._A.ndim == 2
710                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):
711             raise TypeError(f"Invalid shape {self._A.shape} for image data")
712 
713         if self._A.ndim == 3:
714             # If the input data has values outside the valid range (after
715             # normalisation), we issue a warning and then clip X to the bounds
716             # - otherwise casting wraps extreme values, hiding outliers and
717             # making reliable interpretation impossible.
718             high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1
719             if self._A.min() < 0 or high < self._A.max():
720                 _log.warning(
721                     'Clipping input data to the valid range for imshow with '
722                     'RGB data ([0..1] for floats or [0..255] for integers).'
723                 )
724                 self._A = np.clip(self._A, 0, high)
725             # Cast unsupported integer types to uint8
726             if self._A.dtype != np.uint8 and np.issubdtype(self._A.dtype,
727                                                            np.integer):
728                 self._A = self._A.astype(np.uint8)
729 
730         self._imcache = None
731         self.stale = True
732 
733     def set_array(self, A):
734         """
735         Retained for backwards compatibility - use set_data instead.
736 
737         Parameters
738         ----------
739         A : array-like
740         """
741         # This also needs to be here to override the inherited
742         # cm.ScalarMappable.set_array method so it is not invoked by mistake.
743         self.set_data(A)
744 
745     def get_interpolation(self):
746         """
747         Return the interpolation method the image uses when resizing.
748 
749         One of 'antialiased', 'nearest', 'bilinear', 'bicubic', 'spline16',
750         'spline36', 'hanning', 'hamming', 'hermite', 'kaiser', 'quadric',
751         'catrom', 'gaussian', 'bessel', 'mitchell', 'sinc', 'lanczos',
752         or 'none'.
753         """
754         return self._interpolation
755 
756     def set_interpolation(self, s):
757         """
758         Set the interpolation method the image uses when resizing.
759 
760         If None, use :rc:`image.interpolation`. If 'none', the image is
761         shown as is without interpolating. 'none' is only supported in
762         agg, ps and pdf backends and will fall back to 'nearest' mode
763         for other backends.
764 
765         Parameters
766         ----------
767         s : {'antialiased', 'nearest', 'bilinear', 'bicubic', 'spline16', \
768 'spline36', 'hanning', 'hamming', 'hermite', 'kaiser', 'quadric', 'catrom', \
769 'gaussian', 'bessel', 'mitchell', 'sinc', 'lanczos', 'none'} or None
770         """
771         if s is None:
772             s = mpl.rcParams['image.interpolation']
773         s = s.lower()
774         _api.check_in_list(_interpd_, interpolation=s)
775         self._interpolation = s
776         self.stale = True
777 
778     def set_interpolation_stage(self, s):
779         """
780         Set when interpolation happens during the transform to RGBA.
781 
782         Parameters
783         ----------
784         s : {'data', 'rgba'} or None
785             Whether to apply up/downsampling interpolation in data or RGBA
786             space.
787         """
788         if s is None:
789             s = "data"  # placeholder for maybe having rcParam
790         _api.check_in_list(['data', 'rgba'], s=s)
791         self._interpolation_stage = s
792         self.stale = True
793 
794     def can_composite(self):
795         """Return whether the image can be composited with its neighbors."""
796         trans = self.get_transform()
797         return (
798             self._interpolation != 'none' and
799             trans.is_affine and
800             trans.is_separable)
801 
802     def set_resample(self, v):
803         """
804         Set whether image resampling is used.
805 
806         Parameters
807         ----------
808         v : bool or None
809             If None, use :rc:`image.resample`.
810         """
811         if v is None:
812             v = mpl.rcParams['image.resample']
813         self._resample = v
814         self.stale = True
815 
816     def get_resample(self):
817         """Return whether image resampling is used."""
818         return self._resample
819 
820     def set_filternorm(self, filternorm):
821         """
822         Set whether the resize filter normalizes the weights.
823 
824         See help for `~.Axes.imshow`.
825 
826         Parameters
827         ----------
828         filternorm : bool
829         """
830         self._filternorm = bool(filternorm)
831         self.stale = True
832 
833     def get_filternorm(self):
834         """Return whether the resize filter normalizes the weights."""
835         return self._filternorm
836 
837     def set_filterrad(self, filterrad):
838         """
839         Set the resize filter radius only applicable to some
840         interpolation schemes -- see help for imshow
841 
842         Parameters
843         ----------
844         filterrad : positive float
845         """
846         r = float(filterrad)
847         if r <= 0:
848             raise ValueError("The filter radius must be a positive number")
849         self._filterrad = r
850         self.stale = True
851 
852     def get_filterrad(self):
853         """Return the filterrad setting."""
854         return self._filterrad

</code><intended_behavior>This class provides additional context to the issue.</intended_behavior>, <file>lib/matplotlib/image.py</file>
<class>_ImageBase</class>
<method>None</method>
<code>
230 class _ImageBase(martist.Artist, cm.ScalarMappable):
231     """
232     Base class for images.
233 
234     interpolation and cmap default to their rc settings
235 
236     cmap is a colors.Colormap instance
237     norm is a colors.Normalize instance to map luminance to 0-1
238 
239     extent is data axes (left, right, bottom, top) for making image plots
240     registered with data plots.  Default is to label the pixel
241     centers with the zero-based row and column indices.
242 
243     Additional kwargs are matplotlib.artist properties
244     """
245     zorder = 0
246 
247     def __init__(self, ax,
248                  cmap=None,
249                  norm=None,
250                  interpolation=None,
251                  origin=None,
252                  filternorm=True,
253                  filterrad=4.0,
254                  resample=False,
255                  *,
256                  interpolation_stage=None,
257                  **kwargs
258                  ):
259         martist.Artist.__init__(self)
260         cm.ScalarMappable.__init__(self, norm, cmap)
261         if origin is None:
262             origin = mpl.rcParams['image.origin']
263         _api.check_in_list(["upper", "lower"], origin=origin)
264         self.origin = origin
265         self.set_filternorm(filternorm)
266         self.set_filterrad(filterrad)
267         self.set_interpolation(interpolation)
268         self.set_interpolation_stage(interpolation_stage)
269         self.set_resample(resample)
270         self.axes = ax
271 
272         self._imcache = None
273 
274         self._internal_update(kwargs)
275 
276     def __str__(self):
277         try:
278             size = self.get_size()
279             return f"{type(self).__name__}(size={size!r})"
280         except RuntimeError:
281             return type(self).__name__
282 
283     def __getstate__(self):
284         # Save some space on the pickle by not saving the cache.
285         return {**super().__getstate__(), "_imcache": None}
286 
287     def get_size(self):
288         """Return the size of the image as tuple (numrows, numcols)."""
289         if self._A is None:
290             raise RuntimeError('You must first set the image array')
291 
292         return self._A.shape[:2]
293 
294     def set_alpha(self, alpha):
295         """
296         Set the alpha value used for blending - not supported on all backends.
297 
298         Parameters
299         ----------
300         alpha : float or 2D array-like or None
301         """
302         martist.Artist._set_alpha_for_array(self, alpha)
303         if np.ndim(alpha) not in (0, 2):
304             raise TypeError('alpha must be a float, two-dimensional '
305                             'array, or None')
306         self._imcache = None
307 
308     def _get_scalar_alpha(self):
309         """
310         Get a scalar alpha value to be applied to the artist as a whole.
311 
312         If the alpha value is a matrix, the method returns 1.0 because pixels
313         have individual alpha values (see `~._ImageBase._make_image` for
314         details). If the alpha value is a scalar, the method returns said value
315         to be applied to the artist as a whole because pixels do not have
316         individual alpha values.
317         """
318         return 1.0 if self._alpha is None or np.ndim(self._alpha) > 0 \
319             else self._alpha
320 
321     def changed(self):
322         """
323         Call this whenever the mappable is changed so observers can update.
324         """
325         self._imcache = None
326         cm.ScalarMappable.changed(self)
327 
328     def _make_image(self, A, in_bbox, out_bbox, clip_bbox, magnification=1.0,
329                     unsampled=False, round_to_pixel_border=True):
330         """
331         Normalize, rescale, and colormap the image *A* from the given *in_bbox*
332         (in data space), to the given *out_bbox* (in pixel space) clipped to
333         the given *clip_bbox* (also in pixel space), and magnified by the
334         *magnification* factor.
335 
336         *A* may be a greyscale image (M, N) with a dtype of `~numpy.float32`,
337         `~numpy.float64`, `~numpy.float128`, `~numpy.uint16` or `~numpy.uint8`,
338         or an (M, N, 4) RGBA image with a dtype of `~numpy.float32`,
339         `~numpy.float64`, `~numpy.float128`, or `~numpy.uint8`.
340 
341         If *unsampled* is True, the image will not be scaled, but an
342         appropriate affine transformation will be returned instead.
343 
344         If *round_to_pixel_border* is True, the output image size will be
345         rounded to the nearest pixel boundary.  This makes the images align
346         correctly with the axes.  It should not be used if exact scaling is
347         needed, such as for `FigureImage`.
348 
349         Returns
350         -------
351         image : (M, N, 4) `numpy.uint8` array
352             The RGBA image, resampled unless *unsampled* is True.
353         x, y : float
354             The upper left corner where the image should be drawn, in pixel
355             space.
356         trans : `~matplotlib.transforms.Affine2D`
357             The affine transformation from image to pixel space.
358         """
359         if A is None:
360             raise RuntimeError('You must first set the image '
361                                'array or the image attribute')
362         if A.size == 0:
363             raise RuntimeError("_make_image must get a non-empty image. "
364                                "Your Artist's draw method must filter before "
365                                "this method is called.")
366 
367         clipped_bbox = Bbox.intersection(out_bbox, clip_bbox)
368 
369         if clipped_bbox is None:
370             return None, 0, 0, None
371 
372         out_width_base = clipped_bbox.width * magnification
373         out_height_base = clipped_bbox.height * magnification
374 
375         if out_width_base == 0 or out_height_base == 0:
376             return None, 0, 0, None
377 
378         if self.origin == 'upper':
379             # Flip the input image using a transform.  This avoids the
380             # problem with flipping the array, which results in a copy
381             # when it is converted to contiguous in the C wrapper
382             t0 = Affine2D().translate(0, -A.shape[0]).scale(1, -1)
383         else:
384             t0 = IdentityTransform()
385 
386         t0 += (
387             Affine2D()
388             .scale(
389                 in_bbox.width / A.shape[1],
390                 in_bbox.height / A.shape[0])
391             .translate(in_bbox.x0, in_bbox.y0)
392             + self.get_transform())
393 
394         t = (t0
395              + (Affine2D()
396                 .translate(-clipped_bbox.x0, -clipped_bbox.y0)
397                 .scale(magnification)))
398 
399         # So that the image is aligned with the edge of the axes, we want to
400         # round up the output width to the next integer.  This also means
401         # scaling the transform slightly to account for the extra subpixel.
402         if (t.is_affine and round_to_pixel_border and
403                 (out_width_base % 1.0 != 0.0 or out_height_base % 1.0 != 0.0)):
404             out_width = math.ceil(out_width_base)
405             out_height = math.ceil(out_height_base)
406             extra_width = (out_width - out_width_base) / out_width_base
407             extra_height = (out_height - out_height_base) / out_height_base
408             t += Affine2D().scale(1.0 + extra_width, 1.0 + extra_height)
409         else:
410             out_width = int(out_width_base)
411             out_height = int(out_height_base)
412         out_shape = (out_height, out_width)
413 
414         if not unsampled:
415             if not (A.ndim == 2 or A.ndim == 3 and A.shape[-1] in (3, 4)):
416                 raise ValueError(f"Invalid shape {A.shape} for image data")
417             if A.ndim == 2 and self._interpolation_stage != 'rgba':
418                 # if we are a 2D array, then we are running through the
419                 # norm + colormap transformation.  However, in general the
420                 # input data is not going to match the size on the screen so we
421                 # have to resample to the correct number of pixels
422 
423                 # TODO slice input array first
424                 a_min = A.min()
425                 a_max = A.max()
426                 if a_min is np.ma.masked:  # All masked; values don't matter.
427                     a_min, a_max = np.int32(0), np.int32(1)
428                 if A.dtype.kind == 'f':  # Float dtype: scale to same dtype.
429                     scaled_dtype = np.dtype(
430                         np.float64 if A.dtype.itemsize > 4 else np.float32)
431                     if scaled_dtype.itemsize < A.dtype.itemsize:
432                         _api.warn_external(f"Casting input data from {A.dtype}"
433                                            f" to {scaled_dtype} for imshow.")
434                 else:  # Int dtype, likely.
435                     # Scale to appropriately sized float: use float32 if the
436                     # dynamic range is small, to limit the memory footprint.
437                     da = a_max.astype(np.float64) - a_min.astype(np.float64)
438                     scaled_dtype = np.float64 if da > 1e8 else np.float32
439 
440                 # Scale the input data to [.1, .9].  The Agg interpolators clip
441                 # to [0, 1] internally, and we use a smaller input scale to
442                 # identify the interpolated points that need to be flagged as
443                 # over/under.  This may introduce numeric instabilities in very
444                 # broadly scaled data.
445 
446                 # Always copy, and don't allow array subtypes.
447                 A_scaled = np.array(A, dtype=scaled_dtype)
448                 # Clip scaled data around norm if necessary.  This is necessary
449                 # for big numbers at the edge of float64's ability to represent
450                 # changes.  Applying a norm first would be good, but ruins the
451                 # interpolation of over numbers.
452                 self.norm.autoscale_None(A)
453                 dv = np.float64(self.norm.vmax) - np.float64(self.norm.vmin)
454                 vmid = np.float64(self.norm.vmin) + dv / 2
455                 fact = 1e7 if scaled_dtype == np.float64 else 1e4
456                 newmin = vmid - dv * fact
457                 if newmin < a_min:
458                     newmin = None
459                 else:
460                     a_min = np.float64(newmin)
461                 newmax = vmid + dv * fact
462                 if newmax > a_max:
463                     newmax = None
464                 else:
465                     a_max = np.float64(newmax)
466                 if newmax is not None or newmin is not None:
467                     np.clip(A_scaled, newmin, newmax, out=A_scaled)
468 
469                 # Rescale the raw data to [offset, 1-offset] so that the
470                 # resampling code will run cleanly.  Using dyadic numbers here
471                 # could reduce the error, but would not fully eliminate it and
472                 # breaks a number of tests (due to the slightly different
473                 # error bouncing some pixels across a boundary in the (very
474                 # quantized) colormapping step).
475                 offset = .1
476                 frac = .8
477                 # Run vmin/vmax through the same rescaling as the raw data;
478                 # otherwise, data values close or equal to the boundaries can
479                 # end up on the wrong side due to floating point error.
480                 vmin, vmax = self.norm.vmin, self.norm.vmax
481                 if vmin is np.ma.masked:
482                     vmin, vmax = a_min, a_max
483                 vrange = np.array([vmin, vmax], dtype=scaled_dtype)
484 
485                 A_scaled -= a_min
486                 vrange -= a_min
487                 # .item() handles a_min/a_max being ndarray subclasses.
488                 a_min = a_min.astype(scaled_dtype).item()
489                 a_max = a_max.astype(scaled_dtype).item()
490 
491                 if a_min != a_max:
492                     A_scaled /= ((a_max - a_min) / frac)
493                     vrange /= ((a_max - a_min) / frac)
494                 A_scaled += offset
495                 vrange += offset
496                 # resample the input data to the correct resolution and shape
497                 A_resampled = _resample(self, A_scaled, out_shape, t)
498                 del A_scaled  # Make sure we don't use A_scaled anymore!
499                 # Un-scale the resampled data to approximately the original
500                 # range. Things that interpolated to outside the original range
501                 # will still be outside, but possibly clipped in the case of
502                 # higher order interpolation + drastically changing data.
503                 A_resampled -= offset
504                 vrange -= offset
505                 if a_min != a_max:
506                     A_resampled *= ((a_max - a_min) / frac)
507                     vrange *= ((a_max - a_min) / frac)
508                 A_resampled += a_min
509                 vrange += a_min
510                 # if using NoNorm, cast back to the original datatype
511                 if isinstance(self.norm, mcolors.NoNorm):
512                     A_resampled = A_resampled.astype(A.dtype)
513 
514                 mask = (np.where(A.mask, np.float32(np.nan), np.float32(1))
515                         if A.mask.shape == A.shape  # nontrivial mask
516                         else np.ones_like(A, np.float32))
517                 # we always have to interpolate the mask to account for
518                 # non-affine transformations
519                 out_alpha = _resample(self, mask, out_shape, t, resample=True)
520                 del mask  # Make sure we don't use mask anymore!
521                 # Agg updates out_alpha in place.  If the pixel has no image
522                 # data it will not be updated (and still be 0 as we initialized
523                 # it), if input data that would go into that output pixel than
524                 # it will be `nan`, if all the input data for a pixel is good
525                 # it will be 1, and if there is _some_ good data in that output
526                 # pixel it will be between [0, 1] (such as a rotated image).
527                 out_mask = np.isnan(out_alpha)
528                 out_alpha[out_mask] = 1
529                 # Apply the pixel-by-pixel alpha values if present
530                 alpha = self.get_alpha()
531                 if alpha is not None and np.ndim(alpha) > 0:
532                     out_alpha *= _resample(self, alpha, out_shape,
533                                            t, resample=True)
534                 # mask and run through the norm
535                 resampled_masked = np.ma.masked_array(A_resampled, out_mask)
536                 # we have re-set the vmin/vmax to account for small errors
537                 # that may have moved input values in/out of range
538                 s_vmin, s_vmax = vrange
539                 if isinstance(self.norm, mcolors.LogNorm) and s_vmin <= 0:
540                     # Don't give 0 or negative values to LogNorm
541                     s_vmin = np.finfo(scaled_dtype).eps
542                 # Block the norm from sending an update signal during the
543                 # temporary vmin/vmax change
544                 with self.norm.callbacks.blocked(), \
545                      cbook._setattr_cm(self.norm, vmin=s_vmin, vmax=s_vmax):
546                     output = self.norm(resampled_masked)
547             else:
548                 if A.ndim == 2:  # _interpolation_stage == 'rgba'
549                     self.norm.autoscale_None(A)
550                     A = self.to_rgba(A)
551                 if A.shape[2] == 3:
552                     A = _rgb_to_rgba(A)
553                 alpha = self._get_scalar_alpha()
554                 output_alpha = _resample(  # resample alpha channel
555                     self, A[..., 3], out_shape, t, alpha=alpha)
556                 output = _resample(  # resample rgb channels
557                     self, _rgb_to_rgba(A[..., :3]), out_shape, t, alpha=alpha)
558                 output[..., 3] = output_alpha  # recombine rgb and alpha
559 
560             # output is now either a 2D array of normed (int or float) data
561             # or an RGBA array of re-sampled input
562             output = self.to_rgba(output, bytes=True, norm=False)
563             # output is now a correctly sized RGBA array of uint8
564 
565             # Apply alpha *after* if the input was greyscale without a mask
566             if A.ndim == 2:
567                 alpha = self._get_scalar_alpha()
568                 alpha_channel = output[:, :, 3]
569                 alpha_channel[:] = (  # Assignment will cast to uint8.
570                     alpha_channel.astype(np.float32) * out_alpha * alpha)
571 
572         else:
573             if self._imcache is None:
574                 self._imcache = self.to_rgba(A, bytes=True, norm=(A.ndim == 2))
575             output = self._imcache
576 
577             # Subset the input image to only the part that will be displayed.
578             subset = TransformedBbox(clip_bbox, t0.inverted()).frozen()
579             output = output[
580                 int(max(subset.ymin, 0)):
581                 int(min(subset.ymax + 1, output.shape[0])),
582                 int(max(subset.xmin, 0)):
583                 int(min(subset.xmax + 1, output.shape[1]))]
584 
585             t = Affine2D().translate(
586                 int(max(subset.xmin, 0)), int(max(subset.ymin, 0))) + t
587 
588         return output, clipped_bbox.x0, clipped_bbox.y0, t
589 
590     def make_image(self, renderer, magnification=1.0, unsampled=False):
591         """
592         Normalize, rescale, and colormap this image's data for rendering using
593         *renderer*, with the given *magnification*.
594 
595         If *unsampled* is True, the image will not be scaled, but an
596         appropriate affine transformation will be returned instead.
597 
598         Returns
599         -------
600         image : (M, N, 4) `numpy.uint8` array
601             The RGBA image, resampled unless *unsampled* is True.
602         x, y : float
603             The upper left corner where the image should be drawn, in pixel
604             space.
605         trans : `~matplotlib.transforms.Affine2D`
606             The affine transformation from image to pixel space.
607         """
608         raise NotImplementedError('The make_image method must be overridden')
609 
610     def _check_unsampled_image(self):
611         """
612         Return whether the image is better to be drawn unsampled.
613 
614         The derived class needs to override it.
615         """
616         return False
617 
618     @martist.allow_rasterization
619     def draw(self, renderer, *args, **kwargs):
620         # if not visible, declare victory and return
621         if not self.get_visible():
622             self.stale = False
623             return
624         # for empty images, there is nothing to draw!
625         if self.get_array().size == 0:
626             self.stale = False
627             return
628         # actually render the image.
629         gc = renderer.new_gc()
630         self._set_gc_clip(gc)
631         gc.set_alpha(self._get_scalar_alpha())
632         gc.set_url(self.get_url())
633         gc.set_gid(self.get_gid())
634         if (renderer.option_scale_image()  # Renderer supports transform kwarg.
635                 and self._check_unsampled_image()
636                 and self.get_transform().is_affine):
637             im, l, b, trans = self.make_image(renderer, unsampled=True)
638             if im is not None:
639                 trans = Affine2D().scale(im.shape[1], im.shape[0]) + trans
640                 renderer.draw_image(gc, l, b, im, trans)
641         else:
642             im, l, b, trans = self.make_image(
643                 renderer, renderer.get_image_magnification())
644             if im is not None:
645                 renderer.draw_image(gc, l, b, im)
646         gc.restore()
647         self.stale = False
648 
649     def contains(self, mouseevent):
650         """Test whether the mouse event occurred within the image."""
651         inside, info = self._default_contains(mouseevent)
652         if inside is not None:
653             return inside, info
654         # 1) This doesn't work for figimage; but figimage also needs a fix
655         #    below (as the check cannot use x/ydata and extents).
656         # 2) As long as the check below uses x/ydata, we need to test axes
657         #    identity instead of `self.axes.contains(event)` because even if
658         #    axes overlap, x/ydata is only valid for event.inaxes anyways.
659         if self.axes is not mouseevent.inaxes:
660             return False, {}
661         # TODO: make sure this is consistent with patch and patch
662         # collection on nonlinear transformed coordinates.
663         # TODO: consider returning image coordinates (shouldn't
664         # be too difficult given that the image is rectilinear
665         trans = self.get_transform().inverted()
666         x, y = trans.transform([mouseevent.x, mouseevent.y])
667         xmin, xmax, ymin, ymax = self.get_extent()
668         if xmin > xmax:
669             xmin, xmax = xmax, xmin
670         if ymin > ymax:
671             ymin, ymax = ymax, ymin
672 
673         if x is not None and y is not None:
674             inside = (xmin <= x <= xmax) and (ymin <= y <= ymax)
675         else:
676             inside = False
677 
678         return inside, {}
679 
680     def write_png(self, fname):
681         """Write the image to png file *fname*."""
682         im = self.to_rgba(self._A[::-1] if self.origin == 'lower' else self._A,
683                           bytes=True, norm=True)
684         PIL.Image.fromarray(im).save(fname, format="png")
685 
686     def set_data(self, A):
687         """
688         Set the image array.
689 
690         Note that this function does *not* update the normalization used.
691 
692         Parameters
693         ----------
694         A : array-like or `PIL.Image.Image`
695         """
696         if isinstance(A, PIL.Image.Image):
697             A = pil_to_array(A)  # Needed e.g. to apply png palette.
698         self._A = cbook.safe_masked_invalid(A, copy=True)
699 
700         if (self._A.dtype != np.uint8 and
701                 not np.can_cast(self._A.dtype, float, "same_kind")):
702             raise TypeError(f"Image data of dtype {self._A.dtype} cannot be "
703                             "converted to float")
704 
705         if self._A.ndim == 3 and self._A.shape[-1] == 1:
706             # If just one dimension assume scalar and apply colormap
707             self._A = self._A[:, :, 0]
708 
709         if not (self._A.ndim == 2
710                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):
711             raise TypeError(f"Invalid shape {self._A.shape} for image data")
712 
713         if self._A.ndim == 3:
714             # If the input data has values outside the valid range (after
715             # normalisation), we issue a warning and then clip X to the bounds
716             # - otherwise casting wraps extreme values, hiding outliers and
717             # making reliable interpretation impossible.
718             high = 255 if np.issubdtype(self._A.dtype, np.integer) else 1
719             if self._A.min() < 0 or high < self._A.max():
720                 _log.warning(
721                     'Clipping input data to the valid range for imshow with '
722                     'RGB data ([0..1] for floats or [0..255] for integers).'
723                 )
724                 self._A = np.clip(self._A, 0, high)
725             # Cast unsupported integer types to uint8
726             if self._A.dtype != np.uint8 and np.issubdtype(self._A.dtype,
727                                                            np.integer):
728                 self._A = self._A.astype(np.uint8)
729 
730         self._imcache = None
731         self.stale = True
732 
733     def set_array(self, A):
734         """
735         Retained for backwards compatibility - use set_data instead.
736 
737         Parameters
738         ----------
739         A : array-like
740         """
741         # This also needs to be here to override the inherited
742         # cm.ScalarMappable.set_array method so it is not invoked by mistake.
743         self.set_data(A)
744 
745     def get_interpolation(self):
746         """
747         Return the interpolation method the image uses when resizing.
748 
749         One of 'antialiased', 'nearest', 'bilinear', 'bicubic', 'spline16',
750         'spline36', 'hanning', 'hamming', 'hermite', 'kaiser', 'quadric',
751         'catrom', 'gaussian', 'bessel', 'mitchell', 'sinc', 'lanczos',
752         or 'none'.
753         """
754         return self._interpolation
755 
756     def set_interpolation(self, s):
757         """
758         Set the interpolation method the image uses when resizing.
759 
760         If None, use :rc:`image.interpolation`. If 'none', the image is
761         shown as is without interpolating. 'none' is only supported in
762         agg, ps and pdf backends and will fall back to 'nearest' mode
763         for other backends.
764 
765         Parameters
766         ----------
767         s : {'antialiased', 'nearest', 'bilinear', 'bicubic', 'spline16', \
768 'spline36', 'hanning', 'hamming', 'hermite', 'kaiser', 'quadric', 'catrom', \
769 'gaussian', 'bessel', 'mitchell', 'sinc', 'lanczos', 'none'} or None
770         """
771         if s is None:
772             s = mpl.rcParams['image.interpolation']
773         s = s.lower()
774         _api.check_in_list(_interpd_, interpolation=s)
775         self._interpolation = s
776         self.stale = True
777 
778     def set_interpolation_stage(self, s):
779         """
780         Set when interpolation happens during the transform to RGBA.
781 
782         Parameters
783         ----------
784         s : {'data', 'rgba'} or None
785             Whether to apply up/downsampling interpolation in data or RGBA
786             space.
787         """
788         if s is None:
789             s = "data"  # placeholder for maybe having rcParam
790         _api.check_in_list(['data', 'rgba'], s=s)
791         self._interpolation_stage = s
792         self.stale = True
793 
794     def can_composite(self):
795         """Return whether the image can be composited with its neighbors."""
796         trans = self.get_transform()
797         return (
798             self._interpolation != 'none' and
799             trans.is_affine and
800             trans.is_separable)
801 
802     def set_resample(self, v):
803         """
804         Set whether image resampling is used.
805 
806         Parameters
807         ----------
808         v : bool or None
809             If None, use :rc:`image.resample`.
810         """
811         if v is None:
812             v = mpl.rcParams['image.resample']
813         self._resample = v
814         self.stale = True
815 
816     def get_resample(self):
817         """Return whether image resampling is used."""
818         return self._resample
819 
820     def set_filternorm(self, filternorm):
821         """
822         Set whether the resize filter normalizes the weights.
823 
824         See help for `~.Axes.imshow`.
825 
826         Parameters
827         ----------
828         filternorm : bool
829         """
830         self._filternorm = bool(filternorm)
831         self.stale = True
832 
833     def get_filternorm(self):
834         """Return whether the resize filter normalizes the weights."""
835         return self._filternorm
836 
837     def set_filterrad(self, filterrad):
838         """
839         Set the resize filter radius only applicable to some
840         interpolation schemes -- see help for imshow
841 
842         Parameters
843         ----------
844         filterrad : positive float
845         """
846         r = float(filterrad)
847         if r <= 0:
848             raise ValueError("The filter radius must be a positive number")
849         self._filterrad = r
850         self.stale = True
851 
852     def get_filterrad(self):
853         """Return the filterrad setting."""
854         return self._filterrad

</code><intended_behavior>Implement a new method, get_shape, that accurately provides the dimensions of the image, potentially including depth for color images. This method should leverage the image's internal representation (likely stored in self._A) to return a tuple reflecting the imageâ€™s width, height, and, if applicable, color channel count. This addresses the enhancement proposal directly by introducing a method with a numpy-consistent naming convention and functionality. It improves the API consistency with numpy and better communicates the capabilities of the AxesImage and related classes to the library users.</intended_behavior>]
2025-10-15 07:36:24.104 | INFO     | Overall retry 0 succeeded; ending workflow
2025-10-15 07:36:24.104 | INFO     | Search-only: skipping patch selection
2025-10-15 07:36:24.188 | INFO     | Task matplotlib__matplotlib-25425 completed successfully.
2025-10-15 07:36:24.189 | INFO     | No patch generated. You can try running ACR again.
