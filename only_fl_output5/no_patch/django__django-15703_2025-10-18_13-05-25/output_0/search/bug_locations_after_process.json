[
    {
        "rel_file_path": "django/db/models/options.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__4.2/django/db/models/options.py",
        "start": 1,
        "end": 988,
        "class_name": null,
        "method_name": null,
        "code": "1 import bisect\n2 import copy\n3 import inspect\n4 from collections import defaultdict\n5 \n6 from django.apps import apps\n7 from django.conf import settings\n8 from django.core.exceptions import FieldDoesNotExist, ImproperlyConfigured\n9 from django.db import connections\n10 from django.db.models import AutoField, Manager, OrderWrt, UniqueConstraint\n11 from django.db.models.query_utils import PathInfo\n12 from django.utils.datastructures import ImmutableList, OrderedSet\n13 from django.utils.functional import cached_property\n14 from django.utils.module_loading import import_string\n15 from django.utils.text import camel_case_to_spaces, format_lazy\n16 from django.utils.translation import override\n17 \n18 PROXY_PARENTS = object()\n19 \n20 EMPTY_RELATION_TREE = ()\n21 \n22 IMMUTABLE_WARNING = (\n23     \"The return type of '%s' should never be mutated. If you want to manipulate this \"\n24     \"list for your own use, make a copy first.\"\n25 )\n26 \n27 DEFAULT_NAMES = (\n28     \"verbose_name\",\n29     \"verbose_name_plural\",\n30     \"db_table\",\n31     \"ordering\",\n32     \"unique_together\",\n33     \"permissions\",\n34     \"get_latest_by\",\n35     \"order_with_respect_to\",\n36     \"app_label\",\n37     \"db_tablespace\",\n38     \"abstract\",\n39     \"managed\",\n40     \"proxy\",\n41     \"swappable\",\n42     \"auto_created\",\n43     \"index_together\",\n44     \"apps\",\n45     \"default_permissions\",\n46     \"select_on_save\",\n47     \"default_related_name\",\n48     \"required_db_features\",\n49     \"required_db_vendor\",\n50     \"base_manager_name\",\n51     \"default_manager_name\",\n52     \"indexes\",\n53     \"constraints\",\n54 )\n55 \n56 \n57 def normalize_together(option_together):\n58     \"\"\"\n59     option_together can be either a tuple of tuples, or a single\n60     tuple of two strings. Normalize it to a tuple of tuples, so that\n61     calling code can uniformly expect that.\n62     \"\"\"\n63     try:\n64         if not option_together:\n65             return ()\n66         if not isinstance(option_together, (tuple, list)):\n67             raise TypeError\n68         first_element = option_together[0]\n69         if not isinstance(first_element, (tuple, list)):\n70             option_together = (option_together,)\n71         # Normalize everything to tuples\n72         return tuple(tuple(ot) for ot in option_together)\n73     except TypeError:\n74         # If the value of option_together isn't valid, return it\n75         # verbatim; this will be picked up by the check framework later.\n76         return option_together\n77 \n78 \n79 def make_immutable_fields_list(name, data):\n80     return ImmutableList(data, warning=IMMUTABLE_WARNING % name)\n81 \n82 \n83 class Options:\n84     FORWARD_PROPERTIES = {\n85         \"fields\",\n86         \"many_to_many\",\n87         \"concrete_fields\",\n88         \"local_concrete_fields\",\n89         \"_forward_fields_map\",\n90         \"managers\",\n91         \"managers_map\",\n92         \"base_manager\",\n93         \"default_manager\",\n94     }\n95     REVERSE_PROPERTIES = {\"related_objects\", \"fields_map\", \"_relation_tree\"}\n96 \n97     default_apps = apps\n98 \n99     def __init__(self, meta, app_label=None):\n100         self._get_fields_cache = {}\n101         self.local_fields = []\n102         self.local_many_to_many = []\n103         self.private_fields = []\n104         self.local_managers = []\n105         self.base_manager_name = None\n106         self.default_manager_name = None\n107         self.model_name = None\n108         self.verbose_name = None\n109         self.verbose_name_plural = None\n110         self.db_table = \"\"\n111         self.ordering = []\n112         self._ordering_clash = False\n113         self.indexes = []\n114         self.constraints = []\n115         self.unique_together = []\n116         self.index_together = []\n117         self.select_on_save = False\n118         self.default_permissions = (\"add\", \"change\", \"delete\", \"view\")\n119         self.permissions = []\n120         self.object_name = None\n121         self.app_label = app_label\n122         self.get_latest_by = None\n123         self.order_with_respect_to = None\n124         self.db_tablespace = settings.DEFAULT_TABLESPACE\n125         self.required_db_features = []\n126         self.required_db_vendor = None\n127         self.meta = meta\n128         self.pk = None\n129         self.auto_field = None\n130         self.abstract = False\n131         self.managed = True\n132         self.proxy = False\n133         # For any class that is a proxy (including automatically created\n134         # classes for deferred object loading), proxy_for_model tells us\n135         # which class this model is proxying. Note that proxy_for_model\n136         # can create a chain of proxy models. For non-proxy models, the\n137         # variable is always None.\n138         self.proxy_for_model = None\n139         # For any non-abstract class, the concrete class is the model\n140         # in the end of the proxy_for_model chain. In particular, for\n141         # concrete models, the concrete_model is always the class itself.\n142         self.concrete_model = None\n143         self.swappable = None\n144         self.parents = {}\n145         self.auto_created = False\n146 \n147         # List of all lookups defined in ForeignKey 'limit_choices_to' options\n148         # from *other* models. Needed for some admin checks. Internal use only.\n149         self.related_fkey_lookups = []\n150 \n151         # A custom app registry to use, if you're making a separate model set.\n152         self.apps = self.default_apps\n153 \n154         self.default_related_name = None\n155 \n156     @property\n157     def label(self):\n158         return \"%s.%s\" % (self.app_label, self.object_name)\n159 \n160     @property\n161     def label_lower(self):\n162         return \"%s.%s\" % (self.app_label, self.model_name)\n163 \n164     @property\n165     def app_config(self):\n166         # Don't go through get_app_config to avoid triggering imports.\n167         return self.apps.app_configs.get(self.app_label)\n168 \n169     def contribute_to_class(self, cls, name):\n170         from django.db import connection\n171         from django.db.backends.utils import truncate_name\n172 \n173         cls._meta = self\n174         self.model = cls\n175         # First, construct the default values for these options.\n176         self.object_name = cls.__name__\n177         self.model_name = self.object_name.lower()\n178         self.verbose_name = camel_case_to_spaces(self.object_name)\n179 \n180         # Store the original user-defined values for each option,\n181         # for use when serializing the model definition\n182         self.original_attrs = {}\n183 \n184         # Next, apply any overridden values from 'class Meta'.\n185         if self.meta:\n186             meta_attrs = self.meta.__dict__.copy()\n187             for name in self.meta.__dict__:\n188                 # Ignore any private attributes that Django doesn't care about.\n189                 # NOTE: We can't modify a dictionary's contents while looping\n190                 # over it, so we loop over the *original* dictionary instead.\n191                 if name.startswith(\"_\"):\n192                     del meta_attrs[name]\n193             for attr_name in DEFAULT_NAMES:\n194                 if attr_name in meta_attrs:\n195                     setattr(self, attr_name, meta_attrs.pop(attr_name))\n196                     self.original_attrs[attr_name] = getattr(self, attr_name)\n197                 elif hasattr(self.meta, attr_name):\n198                     setattr(self, attr_name, getattr(self.meta, attr_name))\n199                     self.original_attrs[attr_name] = getattr(self, attr_name)\n200 \n201             self.unique_together = normalize_together(self.unique_together)\n202             self.index_together = normalize_together(self.index_together)\n203             # App label/class name interpolation for names of constraints and\n204             # indexes.\n205             if not getattr(cls._meta, \"abstract\", False):\n206                 for attr_name in {\"constraints\", \"indexes\"}:\n207                     objs = getattr(self, attr_name, [])\n208                     setattr(self, attr_name, self._format_names_with_class(cls, objs))\n209 \n210             # verbose_name_plural is a special case because it uses a 's'\n211             # by default.\n212             if self.verbose_name_plural is None:\n213                 self.verbose_name_plural = format_lazy(\"{}s\", self.verbose_name)\n214 \n215             # order_with_respect_and ordering are mutually exclusive.\n216             self._ordering_clash = bool(self.ordering and self.order_with_respect_to)\n217 \n218             # Any leftover attributes must be invalid.\n219             if meta_attrs != {}:\n220                 raise TypeError(\n221                     \"'class Meta' got invalid attribute(s): %s\" % \",\".join(meta_attrs)\n222                 )\n223         else:\n224             self.verbose_name_plural = format_lazy(\"{}s\", self.verbose_name)\n225         del self.meta\n226 \n227         # If the db_table wasn't provided, use the app_label + model_name.\n228         if not self.db_table:\n229             self.db_table = \"%s_%s\" % (self.app_label, self.model_name)\n230             self.db_table = truncate_name(\n231                 self.db_table, connection.ops.max_name_length()\n232             )\n233 \n234     def _format_names_with_class(self, cls, objs):\n235         \"\"\"App label/class name interpolation for object names.\"\"\"\n236         new_objs = []\n237         for obj in objs:\n238             obj = obj.clone()\n239             obj.name = obj.name % {\n240                 \"app_label\": cls._meta.app_label.lower(),\n241                 \"class\": cls.__name__.lower(),\n242             }\n243             new_objs.append(obj)\n244         return new_objs\n245 \n246     def _get_default_pk_class(self):\n247         pk_class_path = getattr(\n248             self.app_config,\n249             \"default_auto_field\",\n250             settings.DEFAULT_AUTO_FIELD,\n251         )\n252         if self.app_config and self.app_config._is_default_auto_field_overridden:\n253             app_config_class = type(self.app_config)\n254             source = (\n255                 f\"{app_config_class.__module__}.\"\n256                 f\"{app_config_class.__qualname__}.default_auto_field\"\n257             )\n258         else:\n259             source = \"DEFAULT_AUTO_FIELD\"\n260         if not pk_class_path:\n261             raise ImproperlyConfigured(f\"{source} must not be empty.\")\n262         try:\n263             pk_class = import_string(pk_class_path)\n264         except ImportError as e:\n265             msg = (\n266                 f\"{source} refers to the module '{pk_class_path}' that could \"\n267                 f\"not be imported.\"\n268             )\n269             raise ImproperlyConfigured(msg) from e\n270         if not issubclass(pk_class, AutoField):\n271             raise ValueError(\n272                 f\"Primary key '{pk_class_path}' referred by {source} must \"\n273                 f\"subclass AutoField.\"\n274             )\n275         return pk_class\n276 \n277     def _prepare(self, model):\n278         if self.order_with_respect_to:\n279             # The app registry will not be ready at this point, so we cannot\n280             # use get_field().\n281             query = self.order_with_respect_to\n282             try:\n283                 self.order_with_respect_to = next(\n284                     f\n285                     for f in self._get_fields(reverse=False)\n286                     if f.name == query or f.attname == query\n287                 )\n288             except StopIteration:\n289                 raise FieldDoesNotExist(\n290                     \"%s has no field named '%s'\" % (self.object_name, query)\n291                 )\n292 \n293             self.ordering = (\"_order\",)\n294             if not any(\n295                 isinstance(field, OrderWrt) for field in model._meta.local_fields\n296             ):\n297                 model.add_to_class(\"_order\", OrderWrt())\n298         else:\n299             self.order_with_respect_to = None\n300 \n301         if self.pk is None:\n302             if self.parents:\n303                 # Promote the first parent link in lieu of adding yet another\n304                 # field.\n305                 field = next(iter(self.parents.values()))\n306                 # Look for a local field with the same name as the\n307                 # first parent link. If a local field has already been\n308                 # created, use it instead of promoting the parent\n309                 already_created = [\n310                     fld for fld in self.local_fields if fld.name == field.name\n311                 ]\n312                 if already_created:\n313                     field = already_created[0]\n314                 field.primary_key = True\n315                 self.setup_pk(field)\n316             else:\n317                 pk_class = self._get_default_pk_class()\n318                 auto = pk_class(verbose_name=\"ID\", primary_key=True, auto_created=True)\n319                 model.add_to_class(\"id\", auto)\n320 \n321     def add_manager(self, manager):\n322         self.local_managers.append(manager)\n323         self._expire_cache()\n324 \n325     def add_field(self, field, private=False):\n326         # Insert the given field in the order in which it was created, using\n327         # the \"creation_counter\" attribute of the field.\n328         # Move many-to-many related fields from self.fields into\n329         # self.many_to_many.\n330         if private:\n331             self.private_fields.append(field)\n332         elif field.is_relation and field.many_to_many:\n333             bisect.insort(self.local_many_to_many, field)\n334         else:\n335             bisect.insort(self.local_fields, field)\n336             self.setup_pk(field)\n337 \n338         # If the field being added is a relation to another known field,\n339         # expire the cache on this field and the forward cache on the field\n340         # being referenced, because there will be new relationships in the\n341         # cache. Otherwise, expire the cache of references *to* this field.\n342         # The mechanism for getting at the related model is slightly odd -\n343         # ideally, we'd just ask for field.related_model. However, related_model\n344         # is a cached property, and all the models haven't been loaded yet, so\n345         # we need to make sure we don't cache a string reference.\n346         if (\n347             field.is_relation\n348             and hasattr(field.remote_field, \"model\")\n349             and field.remote_field.model\n350         ):\n351             try:\n352                 field.remote_field.model._meta._expire_cache(forward=False)\n353             except AttributeError:\n354                 pass\n355             self._expire_cache()\n356         else:\n357             self._expire_cache(reverse=False)\n358 \n359     def setup_pk(self, field):\n360         if not self.pk and field.primary_key:\n361             self.pk = field\n362             field.serialize = False\n363 \n364     def setup_proxy(self, target):\n365         \"\"\"\n366         Do the internal setup so that the current model is a proxy for\n367         \"target\".\n368         \"\"\"\n369         self.pk = target._meta.pk\n370         self.proxy_for_model = target\n371         self.db_table = target._meta.db_table\n372 \n373     def __repr__(self):\n374         return \"<Options for %s>\" % self.object_name\n375 \n376     def __str__(self):\n377         return self.label_lower\n378 \n379     def can_migrate(self, connection):\n380         \"\"\"\n381         Return True if the model can/should be migrated on the `connection`.\n382         `connection` can be either a real connection or a connection alias.\n383         \"\"\"\n384         if self.proxy or self.swapped or not self.managed:\n385             return False\n386         if isinstance(connection, str):\n387             connection = connections[connection]\n388         if self.required_db_vendor:\n389             return self.required_db_vendor == connection.vendor\n390         if self.required_db_features:\n391             return all(\n392                 getattr(connection.features, feat, False)\n393                 for feat in self.required_db_features\n394             )\n395         return True\n396 \n397     @property\n398     def verbose_name_raw(self):\n399         \"\"\"Return the untranslated verbose name.\"\"\"\n400         with override(None):\n401             return str(self.verbose_name)\n402 \n403     @property\n404     def swapped(self):\n405         \"\"\"\n406         Has this model been swapped out for another? If so, return the model\n407         name of the replacement; otherwise, return None.\n408 \n409         For historical reasons, model name lookups using get_model() are\n410         case insensitive, so we make sure we are case insensitive here.\n411         \"\"\"\n412         if self.swappable:\n413             swapped_for = getattr(settings, self.swappable, None)\n414             if swapped_for:\n415                 try:\n416                     swapped_label, swapped_object = swapped_for.split(\".\")\n417                 except ValueError:\n418                     # setting not in the format app_label.model_name\n419                     # raising ImproperlyConfigured here causes problems with\n420                     # test cleanup code - instead it is raised in get_user_model\n421                     # or as part of validation.\n422                     return swapped_for\n423 \n424                 if (\n425                     \"%s.%s\" % (swapped_label, swapped_object.lower())\n426                     != self.label_lower\n427                 ):\n428                     return swapped_for\n429         return None\n430 \n431     @cached_property\n432     def managers(self):\n433         managers = []\n434         seen_managers = set()\n435         bases = (b for b in self.model.mro() if hasattr(b, \"_meta\"))\n436         for depth, base in enumerate(bases):\n437             for manager in base._meta.local_managers:\n438                 if manager.name in seen_managers:\n439                     continue\n440 \n441                 manager = copy.copy(manager)\n442                 manager.model = self.model\n443                 seen_managers.add(manager.name)\n444                 managers.append((depth, manager.creation_counter, manager))\n445 \n446         return make_immutable_fields_list(\n447             \"managers\",\n448             (m[2] for m in sorted(managers)),\n449         )\n450 \n451     @cached_property\n452     def managers_map(self):\n453         return {manager.name: manager for manager in self.managers}\n454 \n455     @cached_property\n456     def base_manager(self):\n457         base_manager_name = self.base_manager_name\n458         if not base_manager_name:\n459             # Get the first parent's base_manager_name if there's one.\n460             for parent in self.model.mro()[1:]:\n461                 if hasattr(parent, \"_meta\"):\n462                     if parent._base_manager.name != \"_base_manager\":\n463                         base_manager_name = parent._base_manager.name\n464                     break\n465 \n466         if base_manager_name:\n467             try:\n468                 return self.managers_map[base_manager_name]\n469             except KeyError:\n470                 raise ValueError(\n471                     \"%s has no manager named %r\"\n472                     % (\n473                         self.object_name,\n474                         base_manager_name,\n475                     )\n476                 )\n477 \n478         manager = Manager()\n479         manager.name = \"_base_manager\"\n480         manager.model = self.model\n481         manager.auto_created = True\n482         return manager\n483 \n484     @cached_property\n485     def default_manager(self):\n486         default_manager_name = self.default_manager_name\n487         if not default_manager_name and not self.local_managers:\n488             # Get the first parent's default_manager_name if there's one.\n489             for parent in self.model.mro()[1:]:\n490                 if hasattr(parent, \"_meta\"):\n491                     default_manager_name = parent._meta.default_manager_name\n492                     break\n493 \n494         if default_manager_name:\n495             try:\n496                 return self.managers_map[default_manager_name]\n497             except KeyError:\n498                 raise ValueError(\n499                     \"%s has no manager named %r\"\n500                     % (\n501                         self.object_name,\n502                         default_manager_name,\n503                     )\n504                 )\n505 \n506         if self.managers:\n507             return self.managers[0]\n508 \n509     @cached_property\n510     def fields(self):\n511         \"\"\"\n512         Return a list of all forward fields on the model and its parents,\n513         excluding ManyToManyFields.\n514 \n515         Private API intended only to be used by Django itself; get_fields()\n516         combined with filtering of field properties is the public API for\n517         obtaining this field list.\n518         \"\"\"\n519         # For legacy reasons, the fields property should only contain forward\n520         # fields that are not private or with a m2m cardinality. Therefore we\n521         # pass these three filters as filters to the generator.\n522         # The third lambda is a longwinded way of checking f.related_model - we don't\n523         # use that property directly because related_model is a cached property,\n524         # and all the models may not have been loaded yet; we don't want to cache\n525         # the string reference to the related_model.\n526         def is_not_an_m2m_field(f):\n527             return not (f.is_relation and f.many_to_many)\n528 \n529         def is_not_a_generic_relation(f):\n530             return not (f.is_relation and f.one_to_many)\n531 \n532         def is_not_a_generic_foreign_key(f):\n533             return not (\n534                 f.is_relation\n535                 and f.many_to_one\n536                 and not (hasattr(f.remote_field, \"model\") and f.remote_field.model)\n537             )\n538 \n539         return make_immutable_fields_list(\n540             \"fields\",\n541             (\n542                 f\n543                 for f in self._get_fields(reverse=False)\n544                 if is_not_an_m2m_field(f)\n545                 and is_not_a_generic_relation(f)\n546                 and is_not_a_generic_foreign_key(f)\n547             ),\n548         )\n549 \n550     @cached_property\n551     def concrete_fields(self):\n552         \"\"\"\n553         Return a list of all concrete fields on the model and its parents.\n554 \n555         Private API intended only to be used by Django itself; get_fields()\n556         combined with filtering of field properties is the public API for\n557         obtaining this field list.\n558         \"\"\"\n559         return make_immutable_fields_list(\n560             \"concrete_fields\", (f for f in self.fields if f.concrete)\n561         )\n562 \n563     @cached_property\n564     def local_concrete_fields(self):\n565         \"\"\"\n566         Return a list of all concrete fields on the model.\n567 \n568         Private API intended only to be used by Django itself; get_fields()\n569         combined with filtering of field properties is the public API for\n570         obtaining this field list.\n571         \"\"\"\n572         return make_immutable_fields_list(\n573             \"local_concrete_fields\", (f for f in self.local_fields if f.concrete)\n574         )\n575 \n576     @cached_property\n577     def many_to_many(self):\n578         \"\"\"\n579         Return a list of all many to many fields on the model and its parents.\n580 \n581         Private API intended only to be used by Django itself; get_fields()\n582         combined with filtering of field properties is the public API for\n583         obtaining this list.\n584         \"\"\"\n585         return make_immutable_fields_list(\n586             \"many_to_many\",\n587             (\n588                 f\n589                 for f in self._get_fields(reverse=False)\n590                 if f.is_relation and f.many_to_many\n591             ),\n592         )\n593 \n594     @cached_property\n595     def related_objects(self):\n596         \"\"\"\n597         Return all related objects pointing to the current model. The related\n598         objects can come from a one-to-one, one-to-many, or many-to-many field\n599         relation type.\n600 \n601         Private API intended only to be used by Django itself; get_fields()\n602         combined with filtering of field properties is the public API for\n603         obtaining this field list.\n604         \"\"\"\n605         all_related_fields = self._get_fields(\n606             forward=False, reverse=True, include_hidden=True\n607         )\n608         return make_immutable_fields_list(\n609             \"related_objects\",\n610             (\n611                 obj\n612                 for obj in all_related_fields\n613                 if not obj.hidden or obj.field.many_to_many\n614             ),\n615         )\n616 \n617     @cached_property\n618     def _forward_fields_map(self):\n619         res = {}\n620         fields = self._get_fields(reverse=False)\n621         for field in fields:\n622             res[field.name] = field\n623             # Due to the way Django's internals work, get_field() should also\n624             # be able to fetch a field by attname. In the case of a concrete\n625             # field with relation, includes the *_id name too\n626             try:\n627                 res[field.attname] = field\n628             except AttributeError:\n629                 pass\n630         return res\n631 \n632     @cached_property\n633     def fields_map(self):\n634         res = {}\n635         fields = self._get_fields(forward=False, include_hidden=True)\n636         for field in fields:\n637             res[field.name] = field\n638             # Due to the way Django's internals work, get_field() should also\n639             # be able to fetch a field by attname. In the case of a concrete\n640             # field with relation, includes the *_id name too\n641             try:\n642                 res[field.attname] = field\n643             except AttributeError:\n644                 pass\n645         return res\n646 \n647     def get_field(self, field_name):\n648         \"\"\"\n649         Return a field instance given the name of a forward or reverse field.\n650         \"\"\"\n651         try:\n652             # In order to avoid premature loading of the relation tree\n653             # (expensive) we prefer checking if the field is a forward field.\n654             return self._forward_fields_map[field_name]\n655         except KeyError:\n656             # If the app registry is not ready, reverse fields are\n657             # unavailable, therefore we throw a FieldDoesNotExist exception.\n658             if not self.apps.models_ready:\n659                 raise FieldDoesNotExist(\n660                     \"%s has no field named '%s'. The app cache isn't ready yet, \"\n661                     \"so if this is an auto-created related field, it won't \"\n662                     \"be available yet.\" % (self.object_name, field_name)\n663                 )\n664 \n665         try:\n666             # Retrieve field instance by name from cached or just-computed\n667             # field map.\n668             return self.fields_map[field_name]\n669         except KeyError:\n670             raise FieldDoesNotExist(\n671                 \"%s has no field named '%s'\" % (self.object_name, field_name)\n672             )\n673 \n674     def get_base_chain(self, model):\n675         \"\"\"\n676         Return a list of parent classes leading to `model` (ordered from\n677         closest to most distant ancestor). This has to handle the case where\n678         `model` is a grandparent or even more distant relation.\n679         \"\"\"\n680         if not self.parents:\n681             return []\n682         if model in self.parents:\n683             return [model]\n684         for parent in self.parents:\n685             res = parent._meta.get_base_chain(model)\n686             if res:\n687                 res.insert(0, parent)\n688                 return res\n689         return []\n690 \n691     def get_parent_list(self):\n692         \"\"\"\n693         Return all the ancestors of this model as a list ordered by MRO.\n694         Useful for determining if something is an ancestor, regardless of lineage.\n695         \"\"\"\n696         result = OrderedSet(self.parents)\n697         for parent in self.parents:\n698             for ancestor in parent._meta.get_parent_list():\n699                 result.add(ancestor)\n700         return list(result)\n701 \n702     def get_ancestor_link(self, ancestor):\n703         \"\"\"\n704         Return the field on the current model which points to the given\n705         \"ancestor\". This is possible an indirect link (a pointer to a parent\n706         model, which points, eventually, to the ancestor). Used when\n707         constructing table joins for model inheritance.\n708 \n709         Return None if the model isn't an ancestor of this one.\n710         \"\"\"\n711         if ancestor in self.parents:\n712             return self.parents[ancestor]\n713         for parent in self.parents:\n714             # Tries to get a link field from the immediate parent\n715             parent_link = parent._meta.get_ancestor_link(ancestor)\n716             if parent_link:\n717                 # In case of a proxied model, the first link\n718                 # of the chain to the ancestor is that parent\n719                 # links\n720                 return self.parents[parent] or parent_link\n721 \n722     def get_path_to_parent(self, parent):\n723         \"\"\"\n724         Return a list of PathInfos containing the path from the current\n725         model to the parent model, or an empty list if parent is not a\n726         parent of the current model.\n727         \"\"\"\n728         if self.model is parent:\n729             return []\n730         # Skip the chain of proxy to the concrete proxied model.\n731         proxied_model = self.concrete_model\n732         path = []\n733         opts = self\n734         for int_model in self.get_base_chain(parent):\n735             if int_model is proxied_model:\n736                 opts = int_model._meta\n737             else:\n738                 final_field = opts.parents[int_model]\n739                 targets = (final_field.remote_field.get_related_field(),)\n740                 opts = int_model._meta\n741                 path.append(\n742                     PathInfo(\n743                         from_opts=final_field.model._meta,\n744                         to_opts=opts,\n745                         target_fields=targets,\n746                         join_field=final_field,\n747                         m2m=False,\n748                         direct=True,\n749                         filtered_relation=None,\n750                     )\n751                 )\n752         return path\n753 \n754     def get_path_from_parent(self, parent):\n755         \"\"\"\n756         Return a list of PathInfos containing the path from the parent\n757         model to the current model, or an empty list if parent is not a\n758         parent of the current model.\n759         \"\"\"\n760         if self.model is parent:\n761             return []\n762         model = self.concrete_model\n763         # Get a reversed base chain including both the current and parent\n764         # models.\n765         chain = model._meta.get_base_chain(parent)\n766         chain.reverse()\n767         chain.append(model)\n768         # Construct a list of the PathInfos between models in chain.\n769         path = []\n770         for i, ancestor in enumerate(chain[:-1]):\n771             child = chain[i + 1]\n772             link = child._meta.get_ancestor_link(ancestor)\n773             path.extend(link.reverse_path_infos)\n774         return path\n775 \n776     def _populate_directed_relation_graph(self):\n777         \"\"\"\n778         This method is used by each model to find its reverse objects. As this\n779         method is very expensive and is accessed frequently (it looks up every\n780         field in a model, in every app), it is computed on first access and then\n781         is set as a property on every model.\n782         \"\"\"\n783         related_objects_graph = defaultdict(list)\n784 \n785         all_models = self.apps.get_models(include_auto_created=True)\n786         for model in all_models:\n787             opts = model._meta\n788             # Abstract model's fields are copied to child models, hence we will\n789             # see the fields from the child models.\n790             if opts.abstract:\n791                 continue\n792             fields_with_relations = (\n793                 f\n794                 for f in opts._get_fields(reverse=False, include_parents=False)\n795                 if f.is_relation and f.related_model is not None\n796             )\n797             for f in fields_with_relations:\n798                 if not isinstance(f.remote_field.model, str):\n799                     remote_label = f.remote_field.model._meta.concrete_model._meta.label\n800                     related_objects_graph[remote_label].append(f)\n801 \n802         for model in all_models:\n803             # Set the relation_tree using the internal __dict__. In this way\n804             # we avoid calling the cached property. In attribute lookup,\n805             # __dict__ takes precedence over a data descriptor (such as\n806             # @cached_property). This means that the _meta._relation_tree is\n807             # only called if related_objects is not in __dict__.\n808             related_objects = related_objects_graph[\n809                 model._meta.concrete_model._meta.label\n810             ]\n811             model._meta.__dict__[\"_relation_tree\"] = related_objects\n812         # It seems it is possible that self is not in all_models, so guard\n813         # against that with default for get().\n814         return self.__dict__.get(\"_relation_tree\", EMPTY_RELATION_TREE)\n815 \n816     @cached_property\n817     def _relation_tree(self):\n818         return self._populate_directed_relation_graph()\n819 \n820     def _expire_cache(self, forward=True, reverse=True):\n821         # This method is usually called by apps.cache_clear(), when the\n822         # registry is finalized, or when a new field is added.\n823         if forward:\n824             for cache_key in self.FORWARD_PROPERTIES:\n825                 if cache_key in self.__dict__:\n826                     delattr(self, cache_key)\n827         if reverse and not self.abstract:\n828             for cache_key in self.REVERSE_PROPERTIES:\n829                 if cache_key in self.__dict__:\n830                     delattr(self, cache_key)\n831         self._get_fields_cache = {}\n832 \n833     def get_fields(self, include_parents=True, include_hidden=False):\n834         \"\"\"\n835         Return a list of fields associated to the model. By default, include\n836         forward and reverse fields, fields derived from inheritance, but not\n837         hidden fields. The returned fields can be changed using the parameters:\n838 \n839         - include_parents: include fields derived from inheritance\n840         - include_hidden:  include fields that have a related_name that\n841                            starts with a \"+\"\n842         \"\"\"\n843         if include_parents is False:\n844             include_parents = PROXY_PARENTS\n845         return self._get_fields(\n846             include_parents=include_parents, include_hidden=include_hidden\n847         )\n848 \n849     def _get_fields(\n850         self,\n851         forward=True,\n852         reverse=True,\n853         include_parents=True,\n854         include_hidden=False,\n855         seen_models=None,\n856     ):\n857         \"\"\"\n858         Internal helper function to return fields of the model.\n859         * If forward=True, then fields defined on this model are returned.\n860         * If reverse=True, then relations pointing to this model are returned.\n861         * If include_hidden=True, then fields with is_hidden=True are returned.\n862         * The include_parents argument toggles if fields from parent models\n863           should be included. It has three values: True, False, and\n864           PROXY_PARENTS. When set to PROXY_PARENTS, the call will return all\n865           fields defined for the current model or any of its parents in the\n866           parent chain to the model's concrete model.\n867         \"\"\"\n868         if include_parents not in (True, False, PROXY_PARENTS):\n869             raise TypeError(\n870                 \"Invalid argument for include_parents: %s\" % (include_parents,)\n871             )\n872         # This helper function is used to allow recursion in ``get_fields()``\n873         # implementation and to provide a fast way for Django's internals to\n874         # access specific subsets of fields.\n875 \n876         # We must keep track of which models we have already seen. Otherwise we\n877         # could include the same field multiple times from different models.\n878         topmost_call = seen_models is None\n879         if topmost_call:\n880             seen_models = set()\n881         seen_models.add(self.model)\n882 \n883         # Creates a cache key composed of all arguments\n884         cache_key = (forward, reverse, include_parents, include_hidden, topmost_call)\n885 \n886         try:\n887             # In order to avoid list manipulation. Always return a shallow copy\n888             # of the results.\n889             return self._get_fields_cache[cache_key]\n890         except KeyError:\n891             pass\n892 \n893         fields = []\n894         # Recursively call _get_fields() on each parent, with the same\n895         # options provided in this call.\n896         if include_parents is not False:\n897             for parent in self.parents:\n898                 # In diamond inheritance it is possible that we see the same\n899                 # model from two different routes. In that case, avoid adding\n900                 # fields from the same parent again.\n901                 if parent in seen_models:\n902                     continue\n903                 if (\n904                     parent._meta.concrete_model != self.concrete_model\n905                     and include_parents == PROXY_PARENTS\n906                 ):\n907                     continue\n908                 for obj in parent._meta._get_fields(\n909                     forward=forward,\n910                     reverse=reverse,\n911                     include_parents=include_parents,\n912                     include_hidden=include_hidden,\n913                     seen_models=seen_models,\n914                 ):\n915                     if (\n916                         not getattr(obj, \"parent_link\", False)\n917                         or obj.model == self.concrete_model\n918                     ):\n919                         fields.append(obj)\n920         if reverse and not self.proxy:\n921             # Tree is computed once and cached until the app cache is expired.\n922             # It is composed of a list of fields pointing to the current model\n923             # from other models.\n924             all_fields = self._relation_tree\n925             for field in all_fields:\n926                 # If hidden fields should be included or the relation is not\n927                 # intentionally hidden, add to the fields dict.\n928                 if include_hidden or not field.remote_field.hidden:\n929                     fields.append(field.remote_field)\n930 \n931         if forward:\n932             fields += self.local_fields\n933             fields += self.local_many_to_many\n934             # Private fields are recopied to each child model, and they get a\n935             # different model as field.model in each child. Hence we have to\n936             # add the private fields separately from the topmost call. If we\n937             # did this recursively similar to local_fields, we would get field\n938             # instances with field.model != self.model.\n939             if topmost_call:\n940                 fields += self.private_fields\n941 \n942         # In order to avoid list manipulation. Always\n943         # return a shallow copy of the results\n944         fields = make_immutable_fields_list(\"get_fields()\", fields)\n945 \n946         # Store result into cache for later access\n947         self._get_fields_cache[cache_key] = fields\n948         return fields\n949 \n950     @cached_property\n951     def total_unique_constraints(self):\n952         \"\"\"\n953         Return a list of total unique constraints. Useful for determining set\n954         of fields guaranteed to be unique for all rows.\n955         \"\"\"\n956         return [\n957             constraint\n958             for constraint in self.constraints\n959             if (\n960                 isinstance(constraint, UniqueConstraint)\n961                 and constraint.condition is None\n962                 and not constraint.contains_expressions\n963             )\n964         ]\n965 \n966     @cached_property\n967     def _property_names(self):\n968         \"\"\"Return a set of the names of the properties defined on the model.\"\"\"\n969         names = []\n970         for name in dir(self.model):\n971             attr = inspect.getattr_static(self.model, name)\n972             if isinstance(attr, property):\n973                 names.append(name)\n974         return frozenset(names)\n975 \n976     @cached_property\n977     def db_returning_fields(self):\n978         \"\"\"\n979         Private API intended only to be used by Django itself.\n980         Fields to be returned after a database insert.\n981         \"\"\"\n982         return [\n983             field\n984             for field in self._get_fields(\n985                 forward=True, reverse=False, include_parents=PROXY_PARENTS\n986             )\n987             if getattr(field, \"db_returning\", False)\n988         ]\n",
        "intended_behavior": "This file likely contains the core logic for handling model metadata, including index definitions. The intended behavior here would be to update the handling of the Meta options to either warn or fully deprecate the use of index_together in favor of utilizing indexes with the Index class for future model migrations. An additional method or an update to an existing method should guide or automatically convert index_together definitions to indexes using Index where direct translation is possible."
    },
    {
        "rel_file_path": "django/db/models/base.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__4.2/django/db/models/base.py",
        "start": 1,
        "end": 2500,
        "class_name": null,
        "method_name": null,
        "code": "1 import copy\n2 import inspect\n3 import warnings\n4 from functools import partialmethod\n5 from itertools import chain\n6 \n7 import django\n8 from django.apps import apps\n9 from django.conf import settings\n10 from django.core import checks\n11 from django.core.exceptions import (\n12     NON_FIELD_ERRORS,\n13     FieldDoesNotExist,\n14     FieldError,\n15     MultipleObjectsReturned,\n16     ObjectDoesNotExist,\n17     ValidationError,\n18 )\n19 from django.db import (\n20     DJANGO_VERSION_PICKLE_KEY,\n21     DatabaseError,\n22     connection,\n23     connections,\n24     router,\n25     transaction,\n26 )\n27 from django.db.models import NOT_PROVIDED, ExpressionWrapper, IntegerField, Max, Value\n28 from django.db.models.constants import LOOKUP_SEP\n29 from django.db.models.constraints import CheckConstraint, UniqueConstraint\n30 from django.db.models.deletion import CASCADE, Collector\n31 from django.db.models.expressions import RawSQL\n32 from django.db.models.fields.related import (\n33     ForeignObjectRel,\n34     OneToOneField,\n35     lazy_related_operation,\n36     resolve_relation,\n37 )\n38 from django.db.models.functions import Coalesce\n39 from django.db.models.manager import Manager\n40 from django.db.models.options import Options\n41 from django.db.models.query import F, Q\n42 from django.db.models.signals import (\n43     class_prepared,\n44     post_init,\n45     post_save,\n46     pre_init,\n47     pre_save,\n48 )\n49 from django.db.models.utils import make_model_tuple\n50 from django.utils.encoding import force_str\n51 from django.utils.hashable import make_hashable\n52 from django.utils.text import capfirst, get_text_list\n53 from django.utils.translation import gettext_lazy as _\n54 \n55 \n56 class Deferred:\n57     def __repr__(self):\n58         return \"<Deferred field>\"\n59 \n60     def __str__(self):\n61         return \"<Deferred field>\"\n62 \n63 \n64 DEFERRED = Deferred()\n65 \n66 \n67 def subclass_exception(name, bases, module, attached_to):\n68     \"\"\"\n69     Create exception subclass. Used by ModelBase below.\n70 \n71     The exception is created in a way that allows it to be pickled, assuming\n72     that the returned exception class will be added as an attribute to the\n73     'attached_to' class.\n74     \"\"\"\n75     return type(\n76         name,\n77         bases,\n78         {\n79             \"__module__\": module,\n80             \"__qualname__\": \"%s.%s\" % (attached_to.__qualname__, name),\n81         },\n82     )\n83 \n84 \n85 def _has_contribute_to_class(value):\n86     # Only call contribute_to_class() if it's bound.\n87     return not inspect.isclass(value) and hasattr(value, \"contribute_to_class\")\n88 \n89 \n90 class ModelBase(type):\n91     \"\"\"Metaclass for all models.\"\"\"\n92 \n93     def __new__(cls, name, bases, attrs, **kwargs):\n94         super_new = super().__new__\n95 \n96         # Also ensure initialization is only performed for subclasses of Model\n97         # (excluding Model class itself).\n98         parents = [b for b in bases if isinstance(b, ModelBase)]\n99         if not parents:\n100             return super_new(cls, name, bases, attrs)\n101 \n102         # Create the class.\n103         module = attrs.pop(\"__module__\")\n104         new_attrs = {\"__module__\": module}\n105         classcell = attrs.pop(\"__classcell__\", None)\n106         if classcell is not None:\n107             new_attrs[\"__classcell__\"] = classcell\n108         attr_meta = attrs.pop(\"Meta\", None)\n109         # Pass all attrs without a (Django-specific) contribute_to_class()\n110         # method to type.__new__() so that they're properly initialized\n111         # (i.e. __set_name__()).\n112         contributable_attrs = {}\n113         for obj_name, obj in attrs.items():\n114             if _has_contribute_to_class(obj):\n115                 contributable_attrs[obj_name] = obj\n116             else:\n117                 new_attrs[obj_name] = obj\n118         new_class = super_new(cls, name, bases, new_attrs, **kwargs)\n119 \n120         abstract = getattr(attr_meta, \"abstract\", False)\n121         meta = attr_meta or getattr(new_class, \"Meta\", None)\n122         base_meta = getattr(new_class, \"_meta\", None)\n123 \n124         app_label = None\n125 \n126         # Look for an application configuration to attach the model to.\n127         app_config = apps.get_containing_app_config(module)\n128 \n129         if getattr(meta, \"app_label\", None) is None:\n130             if app_config is None:\n131                 if not abstract:\n132                     raise RuntimeError(\n133                         \"Model class %s.%s doesn't declare an explicit \"\n134                         \"app_label and isn't in an application in \"\n135                         \"INSTALLED_APPS.\" % (module, name)\n136                     )\n137 \n138             else:\n139                 app_label = app_config.label\n140 \n141         new_class.add_to_class(\"_meta\", Options(meta, app_label))\n142         if not abstract:\n143             new_class.add_to_class(\n144                 \"DoesNotExist\",\n145                 subclass_exception(\n146                     \"DoesNotExist\",\n147                     tuple(\n148                         x.DoesNotExist\n149                         for x in parents\n150                         if hasattr(x, \"_meta\") and not x._meta.abstract\n151                     )\n152                     or (ObjectDoesNotExist,),\n153                     module,\n154                     attached_to=new_class,\n155                 ),\n156             )\n157             new_class.add_to_class(\n158                 \"MultipleObjectsReturned\",\n159                 subclass_exception(\n160                     \"MultipleObjectsReturned\",\n161                     tuple(\n162                         x.MultipleObjectsReturned\n163                         for x in parents\n164                         if hasattr(x, \"_meta\") and not x._meta.abstract\n165                     )\n166                     or (MultipleObjectsReturned,),\n167                     module,\n168                     attached_to=new_class,\n169                 ),\n170             )\n171             if base_meta and not base_meta.abstract:\n172                 # Non-abstract child classes inherit some attributes from their\n173                 # non-abstract parent (unless an ABC comes before it in the\n174                 # method resolution order).\n175                 if not hasattr(meta, \"ordering\"):\n176                     new_class._meta.ordering = base_meta.ordering\n177                 if not hasattr(meta, \"get_latest_by\"):\n178                     new_class._meta.get_latest_by = base_meta.get_latest_by\n179 \n180         is_proxy = new_class._meta.proxy\n181 \n182         # If the model is a proxy, ensure that the base class\n183         # hasn't been swapped out.\n184         if is_proxy and base_meta and base_meta.swapped:\n185             raise TypeError(\n186                 \"%s cannot proxy the swapped model '%s'.\" % (name, base_meta.swapped)\n187             )\n188 \n189         # Add remaining attributes (those with a contribute_to_class() method)\n190         # to the class.\n191         for obj_name, obj in contributable_attrs.items():\n192             new_class.add_to_class(obj_name, obj)\n193 \n194         # All the fields of any type declared on this model\n195         new_fields = chain(\n196             new_class._meta.local_fields,\n197             new_class._meta.local_many_to_many,\n198             new_class._meta.private_fields,\n199         )\n200         field_names = {f.name for f in new_fields}\n201 \n202         # Basic setup for proxy models.\n203         if is_proxy:\n204             base = None\n205             for parent in [kls for kls in parents if hasattr(kls, \"_meta\")]:\n206                 if parent._meta.abstract:\n207                     if parent._meta.fields:\n208                         raise TypeError(\n209                             \"Abstract base class containing model fields not \"\n210                             \"permitted for proxy model '%s'.\" % name\n211                         )\n212                     else:\n213                         continue\n214                 if base is None:\n215                     base = parent\n216                 elif parent._meta.concrete_model is not base._meta.concrete_model:\n217                     raise TypeError(\n218                         \"Proxy model '%s' has more than one non-abstract model base \"\n219                         \"class.\" % name\n220                     )\n221             if base is None:\n222                 raise TypeError(\n223                     \"Proxy model '%s' has no non-abstract model base class.\" % name\n224                 )\n225             new_class._meta.setup_proxy(base)\n226             new_class._meta.concrete_model = base._meta.concrete_model\n227         else:\n228             new_class._meta.concrete_model = new_class\n229 \n230         # Collect the parent links for multi-table inheritance.\n231         parent_links = {}\n232         for base in reversed([new_class] + parents):\n233             # Conceptually equivalent to `if base is Model`.\n234             if not hasattr(base, \"_meta\"):\n235                 continue\n236             # Skip concrete parent classes.\n237             if base != new_class and not base._meta.abstract:\n238                 continue\n239             # Locate OneToOneField instances.\n240             for field in base._meta.local_fields:\n241                 if isinstance(field, OneToOneField) and field.remote_field.parent_link:\n242                     related = resolve_relation(new_class, field.remote_field.model)\n243                     parent_links[make_model_tuple(related)] = field\n244 \n245         # Track fields inherited from base models.\n246         inherited_attributes = set()\n247         # Do the appropriate setup for any model parents.\n248         for base in new_class.mro():\n249             if base not in parents or not hasattr(base, \"_meta\"):\n250                 # Things without _meta aren't functional models, so they're\n251                 # uninteresting parents.\n252                 inherited_attributes.update(base.__dict__)\n253                 continue\n254 \n255             parent_fields = base._meta.local_fields + base._meta.local_many_to_many\n256             if not base._meta.abstract:\n257                 # Check for clashes between locally declared fields and those\n258                 # on the base classes.\n259                 for field in parent_fields:\n260                     if field.name in field_names:\n261                         raise FieldError(\n262                             \"Local field %r in class %r clashes with field of \"\n263                             \"the same name from base class %r.\"\n264                             % (\n265                                 field.name,\n266                                 name,\n267                                 base.__name__,\n268                             )\n269                         )\n270                     else:\n271                         inherited_attributes.add(field.name)\n272 \n273                 # Concrete classes...\n274                 base = base._meta.concrete_model\n275                 base_key = make_model_tuple(base)\n276                 if base_key in parent_links:\n277                     field = parent_links[base_key]\n278                 elif not is_proxy:\n279                     attr_name = \"%s_ptr\" % base._meta.model_name\n280                     field = OneToOneField(\n281                         base,\n282                         on_delete=CASCADE,\n283                         name=attr_name,\n284                         auto_created=True,\n285                         parent_link=True,\n286                     )\n287 \n288                     if attr_name in field_names:\n289                         raise FieldError(\n290                             \"Auto-generated field '%s' in class %r for \"\n291                             \"parent_link to base class %r clashes with \"\n292                             \"declared field of the same name.\"\n293                             % (\n294                                 attr_name,\n295                                 name,\n296                                 base.__name__,\n297                             )\n298                         )\n299 \n300                     # Only add the ptr field if it's not already present;\n301                     # e.g. migrations will already have it specified\n302                     if not hasattr(new_class, attr_name):\n303                         new_class.add_to_class(attr_name, field)\n304                 else:\n305                     field = None\n306                 new_class._meta.parents[base] = field\n307             else:\n308                 base_parents = base._meta.parents.copy()\n309 \n310                 # Add fields from abstract base class if it wasn't overridden.\n311                 for field in parent_fields:\n312                     if (\n313                         field.name not in field_names\n314                         and field.name not in new_class.__dict__\n315                         and field.name not in inherited_attributes\n316                     ):\n317                         new_field = copy.deepcopy(field)\n318                         new_class.add_to_class(field.name, new_field)\n319                         # Replace parent links defined on this base by the new\n320                         # field. It will be appropriately resolved if required.\n321                         if field.one_to_one:\n322                             for parent, parent_link in base_parents.items():\n323                                 if field == parent_link:\n324                                     base_parents[parent] = new_field\n325 \n326                 # Pass any non-abstract parent classes onto child.\n327                 new_class._meta.parents.update(base_parents)\n328 \n329             # Inherit private fields (like GenericForeignKey) from the parent\n330             # class\n331             for field in base._meta.private_fields:\n332                 if field.name in field_names:\n333                     if not base._meta.abstract:\n334                         raise FieldError(\n335                             \"Local field %r in class %r clashes with field of \"\n336                             \"the same name from base class %r.\"\n337                             % (\n338                                 field.name,\n339                                 name,\n340                                 base.__name__,\n341                             )\n342                         )\n343                 else:\n344                     field = copy.deepcopy(field)\n345                     if not base._meta.abstract:\n346                         field.mti_inherited = True\n347                     new_class.add_to_class(field.name, field)\n348 \n349         # Copy indexes so that index names are unique when models extend an\n350         # abstract model.\n351         new_class._meta.indexes = [\n352             copy.deepcopy(idx) for idx in new_class._meta.indexes\n353         ]\n354 \n355         if abstract:\n356             # Abstract base models can't be instantiated and don't appear in\n357             # the list of models for an app. We do the final setup for them a\n358             # little differently from normal models.\n359             attr_meta.abstract = False\n360             new_class.Meta = attr_meta\n361             return new_class\n362 \n363         new_class._prepare()\n364         new_class._meta.apps.register_model(new_class._meta.app_label, new_class)\n365         return new_class\n366 \n367     def add_to_class(cls, name, value):\n368         if _has_contribute_to_class(value):\n369             value.contribute_to_class(cls, name)\n370         else:\n371             setattr(cls, name, value)\n372 \n373     def _prepare(cls):\n374         \"\"\"Create some methods once self._meta has been populated.\"\"\"\n375         opts = cls._meta\n376         opts._prepare(cls)\n377 \n378         if opts.order_with_respect_to:\n379             cls.get_next_in_order = partialmethod(\n380                 cls._get_next_or_previous_in_order, is_next=True\n381             )\n382             cls.get_previous_in_order = partialmethod(\n383                 cls._get_next_or_previous_in_order, is_next=False\n384             )\n385 \n386             # Defer creating accessors on the foreign class until it has been\n387             # created and registered. If remote_field is None, we're ordering\n388             # with respect to a GenericForeignKey and don't know what the\n389             # foreign class is - we'll add those accessors later in\n390             # contribute_to_class().\n391             if opts.order_with_respect_to.remote_field:\n392                 wrt = opts.order_with_respect_to\n393                 remote = wrt.remote_field.model\n394                 lazy_related_operation(make_foreign_order_accessors, cls, remote)\n395 \n396         # Give the class a docstring -- its definition.\n397         if cls.__doc__ is None:\n398             cls.__doc__ = \"%s(%s)\" % (\n399                 cls.__name__,\n400                 \", \".join(f.name for f in opts.fields),\n401             )\n402 \n403         get_absolute_url_override = settings.ABSOLUTE_URL_OVERRIDES.get(\n404             opts.label_lower\n405         )\n406         if get_absolute_url_override:\n407             setattr(cls, \"get_absolute_url\", get_absolute_url_override)\n408 \n409         if not opts.managers:\n410             if any(f.name == \"objects\" for f in opts.fields):\n411                 raise ValueError(\n412                     \"Model %s must specify a custom Manager, because it has a \"\n413                     \"field named 'objects'.\" % cls.__name__\n414                 )\n415             manager = Manager()\n416             manager.auto_created = True\n417             cls.add_to_class(\"objects\", manager)\n418 \n419         # Set the name of _meta.indexes. This can't be done in\n420         # Options.contribute_to_class() because fields haven't been added to\n421         # the model at that point.\n422         for index in cls._meta.indexes:\n423             if not index.name:\n424                 index.set_name_with_model(cls)\n425 \n426         class_prepared.send(sender=cls)\n427 \n428     @property\n429     def _base_manager(cls):\n430         return cls._meta.base_manager\n431 \n432     @property\n433     def _default_manager(cls):\n434         return cls._meta.default_manager\n435 \n436 \n437 class ModelStateCacheDescriptor:\n438     \"\"\"\n439     Upon first access, replace itself with an empty dictionary on the instance.\n440     \"\"\"\n441 \n442     def __set_name__(self, owner, name):\n443         self.attribute_name = name\n444 \n445     def __get__(self, instance, cls=None):\n446         if instance is None:\n447             return self\n448         res = instance.__dict__[self.attribute_name] = {}\n449         return res\n450 \n451 \n452 class ModelState:\n453     \"\"\"Store model instance state.\"\"\"\n454 \n455     db = None\n456     # If true, uniqueness validation checks will consider this a new, unsaved\n457     # object. Necessary for correct validation of new instances of objects with\n458     # explicit (non-auto) PKs. This impacts validation only; it has no effect\n459     # on the actual save.\n460     adding = True\n461     fields_cache = ModelStateCacheDescriptor()\n462     related_managers_cache = ModelStateCacheDescriptor()\n463 \n464     def __getstate__(self):\n465         state = self.__dict__.copy()\n466         if \"fields_cache\" in state:\n467             state[\"fields_cache\"] = self.fields_cache.copy()\n468         # Manager instances stored in related_managers_cache won't necessarily\n469         # be deserializable if they were dynamically created via an inner\n470         # scope, e.g. create_forward_many_to_many_manager() and\n471         # create_generic_related_manager().\n472         if \"related_managers_cache\" in state:\n473             state[\"related_managers_cache\"] = {}\n474         return state\n475 \n476 \n477 class Model(metaclass=ModelBase):\n478     def __init__(self, *args, **kwargs):\n479         # Alias some things as locals to avoid repeat global lookups\n480         cls = self.__class__\n481         opts = self._meta\n482         _setattr = setattr\n483         _DEFERRED = DEFERRED\n484         if opts.abstract:\n485             raise TypeError(\"Abstract models cannot be instantiated.\")\n486 \n487         pre_init.send(sender=cls, args=args, kwargs=kwargs)\n488 \n489         # Set up the storage for instance state\n490         self._state = ModelState()\n491 \n492         # There is a rather weird disparity here; if kwargs, it's set, then args\n493         # overrides it. It should be one or the other; don't duplicate the work\n494         # The reason for the kwargs check is that standard iterator passes in by\n495         # args, and instantiation for iteration is 33% faster.\n496         if len(args) > len(opts.concrete_fields):\n497             # Daft, but matches old exception sans the err msg.\n498             raise IndexError(\"Number of args exceeds number of fields\")\n499 \n500         if not kwargs:\n501             fields_iter = iter(opts.concrete_fields)\n502             # The ordering of the zip calls matter - zip throws StopIteration\n503             # when an iter throws it. So if the first iter throws it, the second\n504             # is *not* consumed. We rely on this, so don't change the order\n505             # without changing the logic.\n506             for val, field in zip(args, fields_iter):\n507                 if val is _DEFERRED:\n508                     continue\n509                 _setattr(self, field.attname, val)\n510         else:\n511             # Slower, kwargs-ready version.\n512             fields_iter = iter(opts.fields)\n513             for val, field in zip(args, fields_iter):\n514                 if val is _DEFERRED:\n515                     continue\n516                 _setattr(self, field.attname, val)\n517                 if kwargs.pop(field.name, NOT_PROVIDED) is not NOT_PROVIDED:\n518                     raise TypeError(\n519                         f\"{cls.__qualname__}() got both positional and \"\n520                         f\"keyword arguments for field '{field.name}'.\"\n521                     )\n522 \n523         # Now we're left with the unprocessed fields that *must* come from\n524         # keywords, or default.\n525 \n526         for field in fields_iter:\n527             is_related_object = False\n528             # Virtual field\n529             if field.attname not in kwargs and field.column is None:\n530                 continue\n531             if kwargs:\n532                 if isinstance(field.remote_field, ForeignObjectRel):\n533                     try:\n534                         # Assume object instance was passed in.\n535                         rel_obj = kwargs.pop(field.name)\n536                         is_related_object = True\n537                     except KeyError:\n538                         try:\n539                             # Object instance wasn't passed in -- must be an ID.\n540                             val = kwargs.pop(field.attname)\n541                         except KeyError:\n542                             val = field.get_default()\n543                 else:\n544                     try:\n545                         val = kwargs.pop(field.attname)\n546                     except KeyError:\n547                         # This is done with an exception rather than the\n548                         # default argument on pop because we don't want\n549                         # get_default() to be evaluated, and then not used.\n550                         # Refs #12057.\n551                         val = field.get_default()\n552             else:\n553                 val = field.get_default()\n554 \n555             if is_related_object:\n556                 # If we are passed a related instance, set it using the\n557                 # field.name instead of field.attname (e.g. \"user\" instead of\n558                 # \"user_id\") so that the object gets properly cached (and type\n559                 # checked) by the RelatedObjectDescriptor.\n560                 if rel_obj is not _DEFERRED:\n561                     _setattr(self, field.name, rel_obj)\n562             else:\n563                 if val is not _DEFERRED:\n564                     _setattr(self, field.attname, val)\n565 \n566         if kwargs:\n567             property_names = opts._property_names\n568             unexpected = ()\n569             for prop, value in kwargs.items():\n570                 # Any remaining kwargs must correspond to properties or virtual\n571                 # fields.\n572                 if prop in property_names:\n573                     if value is not _DEFERRED:\n574                         _setattr(self, prop, value)\n575                 else:\n576                     try:\n577                         opts.get_field(prop)\n578                     except FieldDoesNotExist:\n579                         unexpected += (prop,)\n580                     else:\n581                         if value is not _DEFERRED:\n582                             _setattr(self, prop, value)\n583             if unexpected:\n584                 unexpected_names = \", \".join(repr(n) for n in unexpected)\n585                 raise TypeError(\n586                     f\"{cls.__name__}() got unexpected keyword arguments: \"\n587                     f\"{unexpected_names}\"\n588                 )\n589         super().__init__()\n590         post_init.send(sender=cls, instance=self)\n591 \n592     @classmethod\n593     def from_db(cls, db, field_names, values):\n594         if len(values) != len(cls._meta.concrete_fields):\n595             values_iter = iter(values)\n596             values = [\n597                 next(values_iter) if f.attname in field_names else DEFERRED\n598                 for f in cls._meta.concrete_fields\n599             ]\n600         new = cls(*values)\n601         new._state.adding = False\n602         new._state.db = db\n603         return new\n604 \n605     def __repr__(self):\n606         return \"<%s: %s>\" % (self.__class__.__name__, self)\n607 \n608     def __str__(self):\n609         return \"%s object (%s)\" % (self.__class__.__name__, self.pk)\n610 \n611     def __eq__(self, other):\n612         if not isinstance(other, Model):\n613             return NotImplemented\n614         if self._meta.concrete_model != other._meta.concrete_model:\n615             return False\n616         my_pk = self.pk\n617         if my_pk is None:\n618             return self is other\n619         return my_pk == other.pk\n620 \n621     def __hash__(self):\n622         if self.pk is None:\n623             raise TypeError(\"Model instances without primary key value are unhashable\")\n624         return hash(self.pk)\n625 \n626     def __reduce__(self):\n627         data = self.__getstate__()\n628         data[DJANGO_VERSION_PICKLE_KEY] = django.__version__\n629         class_id = self._meta.app_label, self._meta.object_name\n630         return model_unpickle, (class_id,), data\n631 \n632     def __getstate__(self):\n633         \"\"\"Hook to allow choosing the attributes to pickle.\"\"\"\n634         state = self.__dict__.copy()\n635         state[\"_state\"] = copy.copy(state[\"_state\"])\n636         # memoryview cannot be pickled, so cast it to bytes and store\n637         # separately.\n638         _memoryview_attrs = []\n639         for attr, value in state.items():\n640             if isinstance(value, memoryview):\n641                 _memoryview_attrs.append((attr, bytes(value)))\n642         if _memoryview_attrs:\n643             state[\"_memoryview_attrs\"] = _memoryview_attrs\n644             for attr, value in _memoryview_attrs:\n645                 state.pop(attr)\n646         return state\n647 \n648     def __setstate__(self, state):\n649         pickled_version = state.get(DJANGO_VERSION_PICKLE_KEY)\n650         if pickled_version:\n651             if pickled_version != django.__version__:\n652                 warnings.warn(\n653                     \"Pickled model instance's Django version %s does not \"\n654                     \"match the current version %s.\"\n655                     % (pickled_version, django.__version__),\n656                     RuntimeWarning,\n657                     stacklevel=2,\n658                 )\n659         else:\n660             warnings.warn(\n661                 \"Pickled model instance's Django version is not specified.\",\n662                 RuntimeWarning,\n663                 stacklevel=2,\n664             )\n665         if \"_memoryview_attrs\" in state:\n666             for attr, value in state.pop(\"_memoryview_attrs\"):\n667                 state[attr] = memoryview(value)\n668         self.__dict__.update(state)\n669 \n670     def _get_pk_val(self, meta=None):\n671         meta = meta or self._meta\n672         return getattr(self, meta.pk.attname)\n673 \n674     def _set_pk_val(self, value):\n675         for parent_link in self._meta.parents.values():\n676             if parent_link and parent_link != self._meta.pk:\n677                 setattr(self, parent_link.target_field.attname, value)\n678         return setattr(self, self._meta.pk.attname, value)\n679 \n680     pk = property(_get_pk_val, _set_pk_val)\n681 \n682     def get_deferred_fields(self):\n683         \"\"\"\n684         Return a set containing names of deferred fields for this instance.\n685         \"\"\"\n686         return {\n687             f.attname\n688             for f in self._meta.concrete_fields\n689             if f.attname not in self.__dict__\n690         }\n691 \n692     def refresh_from_db(self, using=None, fields=None):\n693         \"\"\"\n694         Reload field values from the database.\n695 \n696         By default, the reloading happens from the database this instance was\n697         loaded from, or by the read router if this instance wasn't loaded from\n698         any database. The using parameter will override the default.\n699 \n700         Fields can be used to specify which fields to reload. The fields\n701         should be an iterable of field attnames. If fields is None, then\n702         all non-deferred fields are reloaded.\n703 \n704         When accessing deferred fields of an instance, the deferred loading\n705         of the field will call this method.\n706         \"\"\"\n707         if fields is None:\n708             self._prefetched_objects_cache = {}\n709         else:\n710             prefetched_objects_cache = getattr(self, \"_prefetched_objects_cache\", ())\n711             for field in fields:\n712                 if field in prefetched_objects_cache:\n713                     del prefetched_objects_cache[field]\n714                     fields.remove(field)\n715             if not fields:\n716                 return\n717             if any(LOOKUP_SEP in f for f in fields):\n718                 raise ValueError(\n719                     'Found \"%s\" in fields argument. Relations and transforms '\n720                     \"are not allowed in fields.\" % LOOKUP_SEP\n721                 )\n722 \n723         hints = {\"instance\": self}\n724         db_instance_qs = self.__class__._base_manager.db_manager(\n725             using, hints=hints\n726         ).filter(pk=self.pk)\n727 \n728         # Use provided fields, if not set then reload all non-deferred fields.\n729         deferred_fields = self.get_deferred_fields()\n730         if fields is not None:\n731             fields = list(fields)\n732             db_instance_qs = db_instance_qs.only(*fields)\n733         elif deferred_fields:\n734             fields = [\n735                 f.attname\n736                 for f in self._meta.concrete_fields\n737                 if f.attname not in deferred_fields\n738             ]\n739             db_instance_qs = db_instance_qs.only(*fields)\n740 \n741         db_instance = db_instance_qs.get()\n742         non_loaded_fields = db_instance.get_deferred_fields()\n743         for field in self._meta.concrete_fields:\n744             if field.attname in non_loaded_fields:\n745                 # This field wasn't refreshed - skip ahead.\n746                 continue\n747             setattr(self, field.attname, getattr(db_instance, field.attname))\n748             # Clear cached foreign keys.\n749             if field.is_relation and field.is_cached(self):\n750                 field.delete_cached_value(self)\n751 \n752         # Clear cached relations.\n753         for field in self._meta.related_objects:\n754             if field.is_cached(self):\n755                 field.delete_cached_value(self)\n756 \n757         self._state.db = db_instance._state.db\n758 \n759     def serializable_value(self, field_name):\n760         \"\"\"\n761         Return the value of the field name for this instance. If the field is\n762         a foreign key, return the id value instead of the object. If there's\n763         no Field object with this name on the model, return the model\n764         attribute's value.\n765 \n766         Used to serialize a field's value (in the serializer, or form output,\n767         for example). Normally, you would just access the attribute directly\n768         and not use this method.\n769         \"\"\"\n770         try:\n771             field = self._meta.get_field(field_name)\n772         except FieldDoesNotExist:\n773             return getattr(self, field_name)\n774         return getattr(self, field.attname)\n775 \n776     def save(\n777         self, force_insert=False, force_update=False, using=None, update_fields=None\n778     ):\n779         \"\"\"\n780         Save the current instance. Override this in a subclass if you want to\n781         control the saving process.\n782 \n783         The 'force_insert' and 'force_update' parameters can be used to insist\n784         that the \"save\" must be an SQL insert or update (or equivalent for\n785         non-SQL backends), respectively. Normally, they should not be set.\n786         \"\"\"\n787         self._prepare_related_fields_for_save(operation_name=\"save\")\n788 \n789         using = using or router.db_for_write(self.__class__, instance=self)\n790         if force_insert and (force_update or update_fields):\n791             raise ValueError(\"Cannot force both insert and updating in model saving.\")\n792 \n793         deferred_fields = self.get_deferred_fields()\n794         if update_fields is not None:\n795             # If update_fields is empty, skip the save. We do also check for\n796             # no-op saves later on for inheritance cases. This bailout is\n797             # still needed for skipping signal sending.\n798             if not update_fields:\n799                 return\n800 \n801             update_fields = frozenset(update_fields)\n802             field_names = set()\n803 \n804             for field in self._meta.concrete_fields:\n805                 if not field.primary_key:\n806                     field_names.add(field.name)\n807 \n808                     if field.name != field.attname:\n809                         field_names.add(field.attname)\n810 \n811             non_model_fields = update_fields.difference(field_names)\n812 \n813             if non_model_fields:\n814                 raise ValueError(\n815                     \"The following fields do not exist in this model, are m2m \"\n816                     \"fields, or are non-concrete fields: %s\"\n817                     % \", \".join(non_model_fields)\n818                 )\n819 \n820         # If saving to the same database, and this model is deferred, then\n821         # automatically do an \"update_fields\" save on the loaded fields.\n822         elif not force_insert and deferred_fields and using == self._state.db:\n823             field_names = set()\n824             for field in self._meta.concrete_fields:\n825                 if not field.primary_key and not hasattr(field, \"through\"):\n826                     field_names.add(field.attname)\n827             loaded_fields = field_names.difference(deferred_fields)\n828             if loaded_fields:\n829                 update_fields = frozenset(loaded_fields)\n830 \n831         self.save_base(\n832             using=using,\n833             force_insert=force_insert,\n834             force_update=force_update,\n835             update_fields=update_fields,\n836         )\n837 \n838     save.alters_data = True\n839 \n840     def save_base(\n841         self,\n842         raw=False,\n843         force_insert=False,\n844         force_update=False,\n845         using=None,\n846         update_fields=None,\n847     ):\n848         \"\"\"\n849         Handle the parts of saving which should be done only once per save,\n850         yet need to be done in raw saves, too. This includes some sanity\n851         checks and signal sending.\n852 \n853         The 'raw' argument is telling save_base not to save any parent\n854         models and not to do any changes to the values before save. This\n855         is used by fixture loading.\n856         \"\"\"\n857         using = using or router.db_for_write(self.__class__, instance=self)\n858         assert not (force_insert and (force_update or update_fields))\n859         assert update_fields is None or update_fields\n860         cls = origin = self.__class__\n861         # Skip proxies, but keep the origin as the proxy model.\n862         if cls._meta.proxy:\n863             cls = cls._meta.concrete_model\n864         meta = cls._meta\n865         if not meta.auto_created:\n866             pre_save.send(\n867                 sender=origin,\n868                 instance=self,\n869                 raw=raw,\n870                 using=using,\n871                 update_fields=update_fields,\n872             )\n873         # A transaction isn't needed if one query is issued.\n874         if meta.parents:\n875             context_manager = transaction.atomic(using=using, savepoint=False)\n876         else:\n877             context_manager = transaction.mark_for_rollback_on_error(using=using)\n878         with context_manager:\n879             parent_inserted = False\n880             if not raw:\n881                 parent_inserted = self._save_parents(cls, using, update_fields)\n882             updated = self._save_table(\n883                 raw,\n884                 cls,\n885                 force_insert or parent_inserted,\n886                 force_update,\n887                 using,\n888                 update_fields,\n889             )\n890         # Store the database on which the object was saved\n891         self._state.db = using\n892         # Once saved, this is no longer a to-be-added instance.\n893         self._state.adding = False\n894 \n895         # Signal that the save is complete\n896         if not meta.auto_created:\n897             post_save.send(\n898                 sender=origin,\n899                 instance=self,\n900                 created=(not updated),\n901                 update_fields=update_fields,\n902                 raw=raw,\n903                 using=using,\n904             )\n905 \n906     save_base.alters_data = True\n907 \n908     def _save_parents(self, cls, using, update_fields):\n909         \"\"\"Save all the parents of cls using values from self.\"\"\"\n910         meta = cls._meta\n911         inserted = False\n912         for parent, field in meta.parents.items():\n913             # Make sure the link fields are synced between parent and self.\n914             if (\n915                 field\n916                 and getattr(self, parent._meta.pk.attname) is None\n917                 and getattr(self, field.attname) is not None\n918             ):\n919                 setattr(self, parent._meta.pk.attname, getattr(self, field.attname))\n920             parent_inserted = self._save_parents(\n921                 cls=parent, using=using, update_fields=update_fields\n922             )\n923             updated = self._save_table(\n924                 cls=parent,\n925                 using=using,\n926                 update_fields=update_fields,\n927                 force_insert=parent_inserted,\n928             )\n929             if not updated:\n930                 inserted = True\n931             # Set the parent's PK value to self.\n932             if field:\n933                 setattr(self, field.attname, self._get_pk_val(parent._meta))\n934                 # Since we didn't have an instance of the parent handy set\n935                 # attname directly, bypassing the descriptor. Invalidate\n936                 # the related object cache, in case it's been accidentally\n937                 # populated. A fresh instance will be re-built from the\n938                 # database if necessary.\n939                 if field.is_cached(self):\n940                     field.delete_cached_value(self)\n941         return inserted\n942 \n943     def _save_table(\n944         self,\n945         raw=False,\n946         cls=None,\n947         force_insert=False,\n948         force_update=False,\n949         using=None,\n950         update_fields=None,\n951     ):\n952         \"\"\"\n953         Do the heavy-lifting involved in saving. Update or insert the data\n954         for a single table.\n955         \"\"\"\n956         meta = cls._meta\n957         non_pks = [f for f in meta.local_concrete_fields if not f.primary_key]\n958 \n959         if update_fields:\n960             non_pks = [\n961                 f\n962                 for f in non_pks\n963                 if f.name in update_fields or f.attname in update_fields\n964             ]\n965 \n966         pk_val = self._get_pk_val(meta)\n967         if pk_val is None:\n968             pk_val = meta.pk.get_pk_value_on_save(self)\n969             setattr(self, meta.pk.attname, pk_val)\n970         pk_set = pk_val is not None\n971         if not pk_set and (force_update or update_fields):\n972             raise ValueError(\"Cannot force an update in save() with no primary key.\")\n973         updated = False\n974         # Skip an UPDATE when adding an instance and primary key has a default.\n975         if (\n976             not raw\n977             and not force_insert\n978             and self._state.adding\n979             and meta.pk.default\n980             and meta.pk.default is not NOT_PROVIDED\n981         ):\n982             force_insert = True\n983         # If possible, try an UPDATE. If that doesn't update anything, do an INSERT.\n984         if pk_set and not force_insert:\n985             base_qs = cls._base_manager.using(using)\n986             values = [\n987                 (\n988                     f,\n989                     None,\n990                     (getattr(self, f.attname) if raw else f.pre_save(self, False)),\n991                 )\n992                 for f in non_pks\n993             ]\n994             forced_update = update_fields or force_update\n995             updated = self._do_update(\n996                 base_qs, using, pk_val, values, update_fields, forced_update\n997             )\n998             if force_update and not updated:\n999                 raise DatabaseError(\"Forced update did not affect any rows.\")\n1000             if update_fields and not updated:\n1001                 raise DatabaseError(\"Save with update_fields did not affect any rows.\")\n1002         if not updated:\n1003             if meta.order_with_respect_to:\n1004                 # If this is a model with an order_with_respect_to\n1005                 # autopopulate the _order field\n1006                 field = meta.order_with_respect_to\n1007                 filter_args = field.get_filter_kwargs_for_object(self)\n1008                 self._order = (\n1009                     cls._base_manager.using(using)\n1010                     .filter(**filter_args)\n1011                     .aggregate(\n1012                         _order__max=Coalesce(\n1013                             ExpressionWrapper(\n1014                                 Max(\"_order\") + Value(1), output_field=IntegerField()\n1015                             ),\n1016                             Value(0),\n1017                         ),\n1018                     )[\"_order__max\"]\n1019                 )\n1020             fields = meta.local_concrete_fields\n1021             if not pk_set:\n1022                 fields = [f for f in fields if f is not meta.auto_field]\n1023 \n1024             returning_fields = meta.db_returning_fields\n1025             results = self._do_insert(\n1026                 cls._base_manager, using, fields, returning_fields, raw\n1027             )\n1028             if results:\n1029                 for value, field in zip(results[0], returning_fields):\n1030                     setattr(self, field.attname, value)\n1031         return updated\n1032 \n1033     def _do_update(self, base_qs, using, pk_val, values, update_fields, forced_update):\n1034         \"\"\"\n1035         Try to update the model. Return True if the model was updated (if an\n1036         update query was done and a matching row was found in the DB).\n1037         \"\"\"\n1038         filtered = base_qs.filter(pk=pk_val)\n1039         if not values:\n1040             # We can end up here when saving a model in inheritance chain where\n1041             # update_fields doesn't target any field in current model. In that\n1042             # case we just say the update succeeded. Another case ending up here\n1043             # is a model with just PK - in that case check that the PK still\n1044             # exists.\n1045             return update_fields is not None or filtered.exists()\n1046         if self._meta.select_on_save and not forced_update:\n1047             return (\n1048                 filtered.exists()\n1049                 and\n1050                 # It may happen that the object is deleted from the DB right after\n1051                 # this check, causing the subsequent UPDATE to return zero matching\n1052                 # rows. The same result can occur in some rare cases when the\n1053                 # database returns zero despite the UPDATE being executed\n1054                 # successfully (a row is matched and updated). In order to\n1055                 # distinguish these two cases, the object's existence in the\n1056                 # database is again checked for if the UPDATE query returns 0.\n1057                 (filtered._update(values) > 0 or filtered.exists())\n1058             )\n1059         return filtered._update(values) > 0\n1060 \n1061     def _do_insert(self, manager, using, fields, returning_fields, raw):\n1062         \"\"\"\n1063         Do an INSERT. If returning_fields is defined then this method should\n1064         return the newly created data for the model.\n1065         \"\"\"\n1066         return manager._insert(\n1067             [self],\n1068             fields=fields,\n1069             returning_fields=returning_fields,\n1070             using=using,\n1071             raw=raw,\n1072         )\n1073 \n1074     def _prepare_related_fields_for_save(self, operation_name, fields=None):\n1075         # Ensure that a model instance without a PK hasn't been assigned to\n1076         # a ForeignKey, GenericForeignKey or OneToOneField on this model. If\n1077         # the field is nullable, allowing the save would result in silent data\n1078         # loss.\n1079         for field in self._meta.concrete_fields:\n1080             if fields and field not in fields:\n1081                 continue\n1082             # If the related field isn't cached, then an instance hasn't been\n1083             # assigned and there's no need to worry about this check.\n1084             if field.is_relation and field.is_cached(self):\n1085                 obj = getattr(self, field.name, None)\n1086                 if not obj:\n1087                     continue\n1088                 # A pk may have been assigned manually to a model instance not\n1089                 # saved to the database (or auto-generated in a case like\n1090                 # UUIDField), but we allow the save to proceed and rely on the\n1091                 # database to raise an IntegrityError if applicable. If\n1092                 # constraints aren't supported by the database, there's the\n1093                 # unavoidable risk of data corruption.\n1094                 if obj.pk is None:\n1095                     # Remove the object from a related instance cache.\n1096                     if not field.remote_field.multiple:\n1097                         field.remote_field.delete_cached_value(obj)\n1098                     raise ValueError(\n1099                         \"%s() prohibited to prevent data loss due to unsaved \"\n1100                         \"related object '%s'.\" % (operation_name, field.name)\n1101                     )\n1102                 elif getattr(self, field.attname) in field.empty_values:\n1103                     # Set related object if it has been saved after an\n1104                     # assignment.\n1105                     setattr(self, field.name, obj)\n1106                 # If the relationship's pk/to_field was changed, clear the\n1107                 # cached relationship.\n1108                 if getattr(obj, field.target_field.attname) != getattr(\n1109                     self, field.attname\n1110                 ):\n1111                     field.delete_cached_value(self)\n1112         # GenericForeignKeys are private.\n1113         for field in self._meta.private_fields:\n1114             if fields and field not in fields:\n1115                 continue\n1116             if (\n1117                 field.is_relation\n1118                 and field.is_cached(self)\n1119                 and hasattr(field, \"fk_field\")\n1120             ):\n1121                 obj = field.get_cached_value(self, default=None)\n1122                 if obj and obj.pk is None:\n1123                     raise ValueError(\n1124                         f\"{operation_name}() prohibited to prevent data loss due to \"\n1125                         f\"unsaved related object '{field.name}'.\"\n1126                     )\n1127 \n1128     def delete(self, using=None, keep_parents=False):\n1129         if self.pk is None:\n1130             raise ValueError(\n1131                 \"%s object can't be deleted because its %s attribute is set \"\n1132                 \"to None.\" % (self._meta.object_name, self._meta.pk.attname)\n1133             )\n1134         using = using or router.db_for_write(self.__class__, instance=self)\n1135         collector = Collector(using=using, origin=self)\n1136         collector.collect([self], keep_parents=keep_parents)\n1137         return collector.delete()\n1138 \n1139     delete.alters_data = True\n1140 \n1141     def _get_FIELD_display(self, field):\n1142         value = getattr(self, field.attname)\n1143         choices_dict = dict(make_hashable(field.flatchoices))\n1144         # force_str() to coerce lazy strings.\n1145         return force_str(\n1146             choices_dict.get(make_hashable(value), value), strings_only=True\n1147         )\n1148 \n1149     def _get_next_or_previous_by_FIELD(self, field, is_next, **kwargs):\n1150         if not self.pk:\n1151             raise ValueError(\"get_next/get_previous cannot be used on unsaved objects.\")\n1152         op = \"gt\" if is_next else \"lt\"\n1153         order = \"\" if is_next else \"-\"\n1154         param = getattr(self, field.attname)\n1155         q = Q((field.name, param), (f\"pk__{op}\", self.pk), _connector=Q.AND)\n1156         q = Q(q, (f\"{field.name}__{op}\", param), _connector=Q.OR)\n1157         qs = (\n1158             self.__class__._default_manager.using(self._state.db)\n1159             .filter(**kwargs)\n1160             .filter(q)\n1161             .order_by(\"%s%s\" % (order, field.name), \"%spk\" % order)\n1162         )\n1163         try:\n1164             return qs[0]\n1165         except IndexError:\n1166             raise self.DoesNotExist(\n1167                 \"%s matching query does not exist.\" % self.__class__._meta.object_name\n1168             )\n1169 \n1170     def _get_next_or_previous_in_order(self, is_next):\n1171         cachename = \"__%s_order_cache\" % is_next\n1172         if not hasattr(self, cachename):\n1173             op = \"gt\" if is_next else \"lt\"\n1174             order = \"_order\" if is_next else \"-_order\"\n1175             order_field = self._meta.order_with_respect_to\n1176             filter_args = order_field.get_filter_kwargs_for_object(self)\n1177             obj = (\n1178                 self.__class__._default_manager.filter(**filter_args)\n1179                 .filter(\n1180                     **{\n1181                         \"_order__%s\"\n1182                         % op: self.__class__._default_manager.values(\"_order\").filter(\n1183                             **{self._meta.pk.name: self.pk}\n1184                         )\n1185                     }\n1186                 )\n1187                 .order_by(order)[:1]\n1188                 .get()\n1189             )\n1190             setattr(self, cachename, obj)\n1191         return getattr(self, cachename)\n1192 \n1193     def _get_field_value_map(self, meta, exclude=None):\n1194         if exclude is None:\n1195             exclude = set()\n1196         meta = meta or self._meta\n1197         return {\n1198             field.name: Value(getattr(self, field.attname), field)\n1199             for field in meta.local_concrete_fields\n1200             if field.name not in exclude\n1201         }\n1202 \n1203     def prepare_database_save(self, field):\n1204         if self.pk is None:\n1205             raise ValueError(\n1206                 \"Unsaved model instance %r cannot be used in an ORM query.\" % self\n1207             )\n1208         return getattr(self, field.remote_field.get_related_field().attname)\n1209 \n1210     def clean(self):\n1211         \"\"\"\n1212         Hook for doing any extra model-wide validation after clean() has been\n1213         called on every field by self.clean_fields. Any ValidationError raised\n1214         by this method will not be associated with a particular field; it will\n1215         have a special-case association with the field defined by NON_FIELD_ERRORS.\n1216         \"\"\"\n1217         pass\n1218 \n1219     def validate_unique(self, exclude=None):\n1220         \"\"\"\n1221         Check unique constraints on the model and raise ValidationError if any\n1222         failed.\n1223         \"\"\"\n1224         unique_checks, date_checks = self._get_unique_checks(exclude=exclude)\n1225 \n1226         errors = self._perform_unique_checks(unique_checks)\n1227         date_errors = self._perform_date_checks(date_checks)\n1228 \n1229         for k, v in date_errors.items():\n1230             errors.setdefault(k, []).extend(v)\n1231 \n1232         if errors:\n1233             raise ValidationError(errors)\n1234 \n1235     def _get_unique_checks(self, exclude=None, include_meta_constraints=False):\n1236         \"\"\"\n1237         Return a list of checks to perform. Since validate_unique() could be\n1238         called from a ModelForm, some fields may have been excluded; we can't\n1239         perform a unique check on a model that is missing fields involved\n1240         in that check. Fields that did not validate should also be excluded,\n1241         but they need to be passed in via the exclude argument.\n1242         \"\"\"\n1243         if exclude is None:\n1244             exclude = set()\n1245         unique_checks = []\n1246 \n1247         unique_togethers = [(self.__class__, self._meta.unique_together)]\n1248         constraints = []\n1249         if include_meta_constraints:\n1250             constraints = [(self.__class__, self._meta.total_unique_constraints)]\n1251         for parent_class in self._meta.get_parent_list():\n1252             if parent_class._meta.unique_together:\n1253                 unique_togethers.append(\n1254                     (parent_class, parent_class._meta.unique_together)\n1255                 )\n1256             if include_meta_constraints and parent_class._meta.total_unique_constraints:\n1257                 constraints.append(\n1258                     (parent_class, parent_class._meta.total_unique_constraints)\n1259                 )\n1260 \n1261         for model_class, unique_together in unique_togethers:\n1262             for check in unique_together:\n1263                 if not any(name in exclude for name in check):\n1264                     # Add the check if the field isn't excluded.\n1265                     unique_checks.append((model_class, tuple(check)))\n1266 \n1267         if include_meta_constraints:\n1268             for model_class, model_constraints in constraints:\n1269                 for constraint in model_constraints:\n1270                     if not any(name in exclude for name in constraint.fields):\n1271                         unique_checks.append((model_class, constraint.fields))\n1272 \n1273         # These are checks for the unique_for_<date/year/month>.\n1274         date_checks = []\n1275 \n1276         # Gather a list of checks for fields declared as unique and add them to\n1277         # the list of checks.\n1278 \n1279         fields_with_class = [(self.__class__, self._meta.local_fields)]\n1280         for parent_class in self._meta.get_parent_list():\n1281             fields_with_class.append((parent_class, parent_class._meta.local_fields))\n1282 \n1283         for model_class, fields in fields_with_class:\n1284             for f in fields:\n1285                 name = f.name\n1286                 if name in exclude:\n1287                     continue\n1288                 if f.unique:\n1289                     unique_checks.append((model_class, (name,)))\n1290                 if f.unique_for_date and f.unique_for_date not in exclude:\n1291                     date_checks.append((model_class, \"date\", name, f.unique_for_date))\n1292                 if f.unique_for_year and f.unique_for_year not in exclude:\n1293                     date_checks.append((model_class, \"year\", name, f.unique_for_year))\n1294                 if f.unique_for_month and f.unique_for_month not in exclude:\n1295                     date_checks.append((model_class, \"month\", name, f.unique_for_month))\n1296         return unique_checks, date_checks\n1297 \n1298     def _perform_unique_checks(self, unique_checks):\n1299         errors = {}\n1300 \n1301         for model_class, unique_check in unique_checks:\n1302             # Try to look up an existing object with the same values as this\n1303             # object's values for all the unique field.\n1304 \n1305             lookup_kwargs = {}\n1306             for field_name in unique_check:\n1307                 f = self._meta.get_field(field_name)\n1308                 lookup_value = getattr(self, f.attname)\n1309                 # TODO: Handle multiple backends with different feature flags.\n1310                 if lookup_value is None or (\n1311                     lookup_value == \"\"\n1312                     and connection.features.interprets_empty_strings_as_nulls\n1313                 ):\n1314                     # no value, skip the lookup\n1315                     continue\n1316                 if f.primary_key and not self._state.adding:\n1317                     # no need to check for unique primary key when editing\n1318                     continue\n1319                 lookup_kwargs[str(field_name)] = lookup_value\n1320 \n1321             # some fields were skipped, no reason to do the check\n1322             if len(unique_check) != len(lookup_kwargs):\n1323                 continue\n1324 \n1325             qs = model_class._default_manager.filter(**lookup_kwargs)\n1326 \n1327             # Exclude the current object from the query if we are editing an\n1328             # instance (as opposed to creating a new one)\n1329             # Note that we need to use the pk as defined by model_class, not\n1330             # self.pk. These can be different fields because model inheritance\n1331             # allows single model to have effectively multiple primary keys.\n1332             # Refs #17615.\n1333             model_class_pk = self._get_pk_val(model_class._meta)\n1334             if not self._state.adding and model_class_pk is not None:\n1335                 qs = qs.exclude(pk=model_class_pk)\n1336             if qs.exists():\n1337                 if len(unique_check) == 1:\n1338                     key = unique_check[0]\n1339                 else:\n1340                     key = NON_FIELD_ERRORS\n1341                 errors.setdefault(key, []).append(\n1342                     self.unique_error_message(model_class, unique_check)\n1343                 )\n1344 \n1345         return errors\n1346 \n1347     def _perform_date_checks(self, date_checks):\n1348         errors = {}\n1349         for model_class, lookup_type, field, unique_for in date_checks:\n1350             lookup_kwargs = {}\n1351             # there's a ticket to add a date lookup, we can remove this special\n1352             # case if that makes it's way in\n1353             date = getattr(self, unique_for)\n1354             if date is None:\n1355                 continue\n1356             if lookup_type == \"date\":\n1357                 lookup_kwargs[\"%s__day\" % unique_for] = date.day\n1358                 lookup_kwargs[\"%s__month\" % unique_for] = date.month\n1359                 lookup_kwargs[\"%s__year\" % unique_for] = date.year\n1360             else:\n1361                 lookup_kwargs[\"%s__%s\" % (unique_for, lookup_type)] = getattr(\n1362                     date, lookup_type\n1363                 )\n1364             lookup_kwargs[field] = getattr(self, field)\n1365 \n1366             qs = model_class._default_manager.filter(**lookup_kwargs)\n1367             # Exclude the current object from the query if we are editing an\n1368             # instance (as opposed to creating a new one)\n1369             if not self._state.adding and self.pk is not None:\n1370                 qs = qs.exclude(pk=self.pk)\n1371 \n1372             if qs.exists():\n1373                 errors.setdefault(field, []).append(\n1374                     self.date_error_message(lookup_type, field, unique_for)\n1375                 )\n1376         return errors\n1377 \n1378     def date_error_message(self, lookup_type, field_name, unique_for):\n1379         opts = self._meta\n1380         field = opts.get_field(field_name)\n1381         return ValidationError(\n1382             message=field.error_messages[\"unique_for_date\"],\n1383             code=\"unique_for_date\",\n1384             params={\n1385                 \"model\": self,\n1386                 \"model_name\": capfirst(opts.verbose_name),\n1387                 \"lookup_type\": lookup_type,\n1388                 \"field\": field_name,\n1389                 \"field_label\": capfirst(field.verbose_name),\n1390                 \"date_field\": unique_for,\n1391                 \"date_field_label\": capfirst(opts.get_field(unique_for).verbose_name),\n1392             },\n1393         )\n1394 \n1395     def unique_error_message(self, model_class, unique_check):\n1396         opts = model_class._meta\n1397 \n1398         params = {\n1399             \"model\": self,\n1400             \"model_class\": model_class,\n1401             \"model_name\": capfirst(opts.verbose_name),\n1402             \"unique_check\": unique_check,\n1403         }\n1404 \n1405         # A unique field\n1406         if len(unique_check) == 1:\n1407             field = opts.get_field(unique_check[0])\n1408             params[\"field_label\"] = capfirst(field.verbose_name)\n1409             return ValidationError(\n1410                 message=field.error_messages[\"unique\"],\n1411                 code=\"unique\",\n1412                 params=params,\n1413             )\n1414 \n1415         # unique_together\n1416         else:\n1417             field_labels = [\n1418                 capfirst(opts.get_field(f).verbose_name) for f in unique_check\n1419             ]\n1420             params[\"field_labels\"] = get_text_list(field_labels, _(\"and\"))\n1421             return ValidationError(\n1422                 message=_(\"%(model_name)s with this %(field_labels)s already exists.\"),\n1423                 code=\"unique_together\",\n1424                 params=params,\n1425             )\n1426 \n1427     def get_constraints(self):\n1428         constraints = [(self.__class__, self._meta.constraints)]\n1429         for parent_class in self._meta.get_parent_list():\n1430             if parent_class._meta.constraints:\n1431                 constraints.append((parent_class, parent_class._meta.constraints))\n1432         return constraints\n1433 \n1434     def validate_constraints(self, exclude=None):\n1435         constraints = self.get_constraints()\n1436         using = router.db_for_write(self.__class__, instance=self)\n1437 \n1438         errors = {}\n1439         for model_class, model_constraints in constraints:\n1440             for constraint in model_constraints:\n1441                 try:\n1442                     constraint.validate(model_class, self, exclude=exclude, using=using)\n1443                 except ValidationError as e:\n1444                     if e.code == \"unique\" and len(constraint.fields) == 1:\n1445                         errors.setdefault(constraint.fields[0], []).append(e)\n1446                     else:\n1447                         errors = e.update_error_dict(errors)\n1448         if errors:\n1449             raise ValidationError(errors)\n1450 \n1451     def full_clean(self, exclude=None, validate_unique=True, validate_constraints=True):\n1452         \"\"\"\n1453         Call clean_fields(), clean(), validate_unique(), and\n1454         validate_constraints() on the model. Raise a ValidationError for any\n1455         errors that occur.\n1456         \"\"\"\n1457         errors = {}\n1458         if exclude is None:\n1459             exclude = set()\n1460         else:\n1461             exclude = set(exclude)\n1462 \n1463         try:\n1464             self.clean_fields(exclude=exclude)\n1465         except ValidationError as e:\n1466             errors = e.update_error_dict(errors)\n1467 \n1468         # Form.clean() is run even if other validation fails, so do the\n1469         # same with Model.clean() for consistency.\n1470         try:\n1471             self.clean()\n1472         except ValidationError as e:\n1473             errors = e.update_error_dict(errors)\n1474 \n1475         # Run unique checks, but only for fields that passed validation.\n1476         if validate_unique:\n1477             for name in errors:\n1478                 if name != NON_FIELD_ERRORS and name not in exclude:\n1479                     exclude.add(name)\n1480             try:\n1481                 self.validate_unique(exclude=exclude)\n1482             except ValidationError as e:\n1483                 errors = e.update_error_dict(errors)\n1484 \n1485         # Run constraints checks, but only for fields that passed validation.\n1486         if validate_constraints:\n1487             for name in errors:\n1488                 if name != NON_FIELD_ERRORS and name not in exclude:\n1489                     exclude.add(name)\n1490             try:\n1491                 self.validate_constraints(exclude=exclude)\n1492             except ValidationError as e:\n1493                 errors = e.update_error_dict(errors)\n1494 \n1495         if errors:\n1496             raise ValidationError(errors)\n1497 \n1498     def clean_fields(self, exclude=None):\n1499         \"\"\"\n1500         Clean all fields and raise a ValidationError containing a dict\n1501         of all validation errors if any occur.\n1502         \"\"\"\n1503         if exclude is None:\n1504             exclude = set()\n1505 \n1506         errors = {}\n1507         for f in self._meta.fields:\n1508             if f.name in exclude:\n1509                 continue\n1510             # Skip validation for empty fields with blank=True. The developer\n1511             # is responsible for making sure they have a valid value.\n1512             raw_value = getattr(self, f.attname)\n1513             if f.blank and raw_value in f.empty_values:\n1514                 continue\n1515             try:\n1516                 setattr(self, f.attname, f.clean(raw_value, self))\n1517             except ValidationError as e:\n1518                 errors[f.name] = e.error_list\n1519 \n1520         if errors:\n1521             raise ValidationError(errors)\n1522 \n1523     @classmethod\n1524     def check(cls, **kwargs):\n1525         errors = [\n1526             *cls._check_swappable(),\n1527             *cls._check_model(),\n1528             *cls._check_managers(**kwargs),\n1529         ]\n1530         if not cls._meta.swapped:\n1531             databases = kwargs.get(\"databases\") or []\n1532             errors += [\n1533                 *cls._check_fields(**kwargs),\n1534                 *cls._check_m2m_through_same_relationship(),\n1535                 *cls._check_long_column_names(databases),\n1536             ]\n1537             clash_errors = (\n1538                 *cls._check_id_field(),\n1539                 *cls._check_field_name_clashes(),\n1540                 *cls._check_model_name_db_lookup_clashes(),\n1541                 *cls._check_property_name_related_field_accessor_clashes(),\n1542                 *cls._check_single_primary_key(),\n1543             )\n1544             errors.extend(clash_errors)\n1545             # If there are field name clashes, hide consequent column name\n1546             # clashes.\n1547             if not clash_errors:\n1548                 errors.extend(cls._check_column_name_clashes())\n1549             errors += [\n1550                 *cls._check_index_together(),\n1551                 *cls._check_unique_together(),\n1552                 *cls._check_indexes(databases),\n1553                 *cls._check_ordering(),\n1554                 *cls._check_constraints(databases),\n1555                 *cls._check_default_pk(),\n1556             ]\n1557 \n1558         return errors\n1559 \n1560     @classmethod\n1561     def _check_default_pk(cls):\n1562         if (\n1563             not cls._meta.abstract\n1564             and cls._meta.pk.auto_created\n1565             and\n1566             # Inherited PKs are checked in parents models.\n1567             not (\n1568                 isinstance(cls._meta.pk, OneToOneField)\n1569                 and cls._meta.pk.remote_field.parent_link\n1570             )\n1571             and not settings.is_overridden(\"DEFAULT_AUTO_FIELD\")\n1572             and cls._meta.app_config\n1573             and not cls._meta.app_config._is_default_auto_field_overridden\n1574         ):\n1575             return [\n1576                 checks.Warning(\n1577                     f\"Auto-created primary key used when not defining a \"\n1578                     f\"primary key type, by default \"\n1579                     f\"'{settings.DEFAULT_AUTO_FIELD}'.\",\n1580                     hint=(\n1581                         f\"Configure the DEFAULT_AUTO_FIELD setting or the \"\n1582                         f\"{cls._meta.app_config.__class__.__qualname__}.\"\n1583                         f\"default_auto_field attribute to point to a subclass \"\n1584                         f\"of AutoField, e.g. 'django.db.models.BigAutoField'.\"\n1585                     ),\n1586                     obj=cls,\n1587                     id=\"models.W042\",\n1588                 ),\n1589             ]\n1590         return []\n1591 \n1592     @classmethod\n1593     def _check_swappable(cls):\n1594         \"\"\"Check if the swapped model exists.\"\"\"\n1595         errors = []\n1596         if cls._meta.swapped:\n1597             try:\n1598                 apps.get_model(cls._meta.swapped)\n1599             except ValueError:\n1600                 errors.append(\n1601                     checks.Error(\n1602                         \"'%s' is not of the form 'app_label.app_name'.\"\n1603                         % cls._meta.swappable,\n1604                         id=\"models.E001\",\n1605                     )\n1606                 )\n1607             except LookupError:\n1608                 app_label, model_name = cls._meta.swapped.split(\".\")\n1609                 errors.append(\n1610                     checks.Error(\n1611                         \"'%s' references '%s.%s', which has not been \"\n1612                         \"installed, or is abstract.\"\n1613                         % (cls._meta.swappable, app_label, model_name),\n1614                         id=\"models.E002\",\n1615                     )\n1616                 )\n1617         return errors\n1618 \n1619     @classmethod\n1620     def _check_model(cls):\n1621         errors = []\n1622         if cls._meta.proxy:\n1623             if cls._meta.local_fields or cls._meta.local_many_to_many:\n1624                 errors.append(\n1625                     checks.Error(\n1626                         \"Proxy model '%s' contains model fields.\" % cls.__name__,\n1627                         id=\"models.E017\",\n1628                     )\n1629                 )\n1630         return errors\n1631 \n1632     @classmethod\n1633     def _check_managers(cls, **kwargs):\n1634         \"\"\"Perform all manager checks.\"\"\"\n1635         errors = []\n1636         for manager in cls._meta.managers:\n1637             errors.extend(manager.check(**kwargs))\n1638         return errors\n1639 \n1640     @classmethod\n1641     def _check_fields(cls, **kwargs):\n1642         \"\"\"Perform all field checks.\"\"\"\n1643         errors = []\n1644         for field in cls._meta.local_fields:\n1645             errors.extend(field.check(**kwargs))\n1646         for field in cls._meta.local_many_to_many:\n1647             errors.extend(field.check(from_model=cls, **kwargs))\n1648         return errors\n1649 \n1650     @classmethod\n1651     def _check_m2m_through_same_relationship(cls):\n1652         \"\"\"Check if no relationship model is used by more than one m2m field.\"\"\"\n1653 \n1654         errors = []\n1655         seen_intermediary_signatures = []\n1656 \n1657         fields = cls._meta.local_many_to_many\n1658 \n1659         # Skip when the target model wasn't found.\n1660         fields = (f for f in fields if isinstance(f.remote_field.model, ModelBase))\n1661 \n1662         # Skip when the relationship model wasn't found.\n1663         fields = (f for f in fields if isinstance(f.remote_field.through, ModelBase))\n1664 \n1665         for f in fields:\n1666             signature = (\n1667                 f.remote_field.model,\n1668                 cls,\n1669                 f.remote_field.through,\n1670                 f.remote_field.through_fields,\n1671             )\n1672             if signature in seen_intermediary_signatures:\n1673                 errors.append(\n1674                     checks.Error(\n1675                         \"The model has two identical many-to-many relations \"\n1676                         \"through the intermediate model '%s'.\"\n1677                         % f.remote_field.through._meta.label,\n1678                         obj=cls,\n1679                         id=\"models.E003\",\n1680                     )\n1681                 )\n1682             else:\n1683                 seen_intermediary_signatures.append(signature)\n1684         return errors\n1685 \n1686     @classmethod\n1687     def _check_id_field(cls):\n1688         \"\"\"Check if `id` field is a primary key.\"\"\"\n1689         fields = [\n1690             f for f in cls._meta.local_fields if f.name == \"id\" and f != cls._meta.pk\n1691         ]\n1692         # fields is empty or consists of the invalid \"id\" field\n1693         if fields and not fields[0].primary_key and cls._meta.pk.name == \"id\":\n1694             return [\n1695                 checks.Error(\n1696                     \"'id' can only be used as a field name if the field also \"\n1697                     \"sets 'primary_key=True'.\",\n1698                     obj=cls,\n1699                     id=\"models.E004\",\n1700                 )\n1701             ]\n1702         else:\n1703             return []\n1704 \n1705     @classmethod\n1706     def _check_field_name_clashes(cls):\n1707         \"\"\"Forbid field shadowing in multi-table inheritance.\"\"\"\n1708         errors = []\n1709         used_fields = {}  # name or attname -> field\n1710 \n1711         # Check that multi-inheritance doesn't cause field name shadowing.\n1712         for parent in cls._meta.get_parent_list():\n1713             for f in parent._meta.local_fields:\n1714                 clash = used_fields.get(f.name) or used_fields.get(f.attname) or None\n1715                 if clash:\n1716                     errors.append(\n1717                         checks.Error(\n1718                             \"The field '%s' from parent model \"\n1719                             \"'%s' clashes with the field '%s' \"\n1720                             \"from parent model '%s'.\"\n1721                             % (clash.name, clash.model._meta, f.name, f.model._meta),\n1722                             obj=cls,\n1723                             id=\"models.E005\",\n1724                         )\n1725                     )\n1726                 used_fields[f.name] = f\n1727                 used_fields[f.attname] = f\n1728 \n1729         # Check that fields defined in the model don't clash with fields from\n1730         # parents, including auto-generated fields like multi-table inheritance\n1731         # child accessors.\n1732         for parent in cls._meta.get_parent_list():\n1733             for f in parent._meta.get_fields():\n1734                 if f not in used_fields:\n1735                     used_fields[f.name] = f\n1736 \n1737         for f in cls._meta.local_fields:\n1738             clash = used_fields.get(f.name) or used_fields.get(f.attname) or None\n1739             # Note that we may detect clash between user-defined non-unique\n1740             # field \"id\" and automatically added unique field \"id\", both\n1741             # defined at the same model. This special case is considered in\n1742             # _check_id_field and here we ignore it.\n1743             id_conflict = (\n1744                 f.name == \"id\" and clash and clash.name == \"id\" and clash.model == cls\n1745             )\n1746             if clash and not id_conflict:\n1747                 errors.append(\n1748                     checks.Error(\n1749                         \"The field '%s' clashes with the field '%s' \"\n1750                         \"from model '%s'.\" % (f.name, clash.name, clash.model._meta),\n1751                         obj=f,\n1752                         id=\"models.E006\",\n1753                     )\n1754                 )\n1755             used_fields[f.name] = f\n1756             used_fields[f.attname] = f\n1757 \n1758         return errors\n1759 \n1760     @classmethod\n1761     def _check_column_name_clashes(cls):\n1762         # Store a list of column names which have already been used by other fields.\n1763         used_column_names = []\n1764         errors = []\n1765 \n1766         for f in cls._meta.local_fields:\n1767             _, column_name = f.get_attname_column()\n1768 \n1769             # Ensure the column name is not already in use.\n1770             if column_name and column_name in used_column_names:\n1771                 errors.append(\n1772                     checks.Error(\n1773                         \"Field '%s' has column name '%s' that is used by \"\n1774                         \"another field.\" % (f.name, column_name),\n1775                         hint=\"Specify a 'db_column' for the field.\",\n1776                         obj=cls,\n1777                         id=\"models.E007\",\n1778                     )\n1779                 )\n1780             else:\n1781                 used_column_names.append(column_name)\n1782 \n1783         return errors\n1784 \n1785     @classmethod\n1786     def _check_model_name_db_lookup_clashes(cls):\n1787         errors = []\n1788         model_name = cls.__name__\n1789         if model_name.startswith(\"_\") or model_name.endswith(\"_\"):\n1790             errors.append(\n1791                 checks.Error(\n1792                     \"The model name '%s' cannot start or end with an underscore \"\n1793                     \"as it collides with the query lookup syntax.\" % model_name,\n1794                     obj=cls,\n1795                     id=\"models.E023\",\n1796                 )\n1797             )\n1798         elif LOOKUP_SEP in model_name:\n1799             errors.append(\n1800                 checks.Error(\n1801                     \"The model name '%s' cannot contain double underscores as \"\n1802                     \"it collides with the query lookup syntax.\" % model_name,\n1803                     obj=cls,\n1804                     id=\"models.E024\",\n1805                 )\n1806             )\n1807         return errors\n1808 \n1809     @classmethod\n1810     def _check_property_name_related_field_accessor_clashes(cls):\n1811         errors = []\n1812         property_names = cls._meta._property_names\n1813         related_field_accessors = (\n1814             f.get_attname()\n1815             for f in cls._meta._get_fields(reverse=False)\n1816             if f.is_relation and f.related_model is not None\n1817         )\n1818         for accessor in related_field_accessors:\n1819             if accessor in property_names:\n1820                 errors.append(\n1821                     checks.Error(\n1822                         \"The property '%s' clashes with a related field \"\n1823                         \"accessor.\" % accessor,\n1824                         obj=cls,\n1825                         id=\"models.E025\",\n1826                     )\n1827                 )\n1828         return errors\n1829 \n1830     @classmethod\n1831     def _check_single_primary_key(cls):\n1832         errors = []\n1833         if sum(1 for f in cls._meta.local_fields if f.primary_key) > 1:\n1834             errors.append(\n1835                 checks.Error(\n1836                     \"The model cannot have more than one field with \"\n1837                     \"'primary_key=True'.\",\n1838                     obj=cls,\n1839                     id=\"models.E026\",\n1840                 )\n1841             )\n1842         return errors\n1843 \n1844     @classmethod\n1845     def _check_index_together(cls):\n1846         \"\"\"Check the value of \"index_together\" option.\"\"\"\n1847         if not isinstance(cls._meta.index_together, (tuple, list)):\n1848             return [\n1849                 checks.Error(\n1850                     \"'index_together' must be a list or tuple.\",\n1851                     obj=cls,\n1852                     id=\"models.E008\",\n1853                 )\n1854             ]\n1855 \n1856         elif any(\n1857             not isinstance(fields, (tuple, list)) for fields in cls._meta.index_together\n1858         ):\n1859             return [\n1860                 checks.Error(\n1861                     \"All 'index_together' elements must be lists or tuples.\",\n1862                     obj=cls,\n1863                     id=\"models.E009\",\n1864                 )\n1865             ]\n1866 \n1867         else:\n1868             errors = []\n1869             for fields in cls._meta.index_together:\n1870                 errors.extend(cls._check_local_fields(fields, \"index_together\"))\n1871             return errors\n1872 \n1873     @classmethod\n1874     def _check_unique_together(cls):\n1875         \"\"\"Check the value of \"unique_together\" option.\"\"\"\n1876         if not isinstance(cls._meta.unique_together, (tuple, list)):\n1877             return [\n1878                 checks.Error(\n1879                     \"'unique_together' must be a list or tuple.\",\n1880                     obj=cls,\n1881                     id=\"models.E010\",\n1882                 )\n1883             ]\n1884 \n1885         elif any(\n1886             not isinstance(fields, (tuple, list))\n1887             for fields in cls._meta.unique_together\n1888         ):\n1889             return [\n1890                 checks.Error(\n1891                     \"All 'unique_together' elements must be lists or tuples.\",\n1892                     obj=cls,\n1893                     id=\"models.E011\",\n1894                 )\n1895             ]\n1896 \n1897         else:\n1898             errors = []\n1899             for fields in cls._meta.unique_together:\n1900                 errors.extend(cls._check_local_fields(fields, \"unique_together\"))\n1901             return errors\n1902 \n1903     @classmethod\n1904     def _check_indexes(cls, databases):\n1905         \"\"\"Check fields, names, and conditions of indexes.\"\"\"\n1906         errors = []\n1907         references = set()\n1908         for index in cls._meta.indexes:\n1909             # Index name can't start with an underscore or a number, restricted\n1910             # for cross-database compatibility with Oracle.\n1911             if index.name[0] == \"_\" or index.name[0].isdigit():\n1912                 errors.append(\n1913                     checks.Error(\n1914                         \"The index name '%s' cannot start with an underscore \"\n1915                         \"or a number.\" % index.name,\n1916                         obj=cls,\n1917                         id=\"models.E033\",\n1918                     ),\n1919                 )\n1920             if len(index.name) > index.max_name_length:\n1921                 errors.append(\n1922                     checks.Error(\n1923                         \"The index name '%s' cannot be longer than %d \"\n1924                         \"characters.\" % (index.name, index.max_name_length),\n1925                         obj=cls,\n1926                         id=\"models.E034\",\n1927                     ),\n1928                 )\n1929             if index.contains_expressions:\n1930                 for expression in index.expressions:\n1931                     references.update(\n1932                         ref[0] for ref in cls._get_expr_references(expression)\n1933                     )\n1934         for db in databases:\n1935             if not router.allow_migrate_model(db, cls):\n1936                 continue\n1937             connection = connections[db]\n1938             if not (\n1939                 connection.features.supports_partial_indexes\n1940                 or \"supports_partial_indexes\" in cls._meta.required_db_features\n1941             ) and any(index.condition is not None for index in cls._meta.indexes):\n1942                 errors.append(\n1943                     checks.Warning(\n1944                         \"%s does not support indexes with conditions.\"\n1945                         % connection.display_name,\n1946                         hint=(\n1947                             \"Conditions will be ignored. Silence this warning \"\n1948                             \"if you don't care about it.\"\n1949                         ),\n1950                         obj=cls,\n1951                         id=\"models.W037\",\n1952                     )\n1953                 )\n1954             if not (\n1955                 connection.features.supports_covering_indexes\n1956                 or \"supports_covering_indexes\" in cls._meta.required_db_features\n1957             ) and any(index.include for index in cls._meta.indexes):\n1958                 errors.append(\n1959                     checks.Warning(\n1960                         \"%s does not support indexes with non-key columns.\"\n1961                         % connection.display_name,\n1962                         hint=(\n1963                             \"Non-key columns will be ignored. Silence this \"\n1964                             \"warning if you don't care about it.\"\n1965                         ),\n1966                         obj=cls,\n1967                         id=\"models.W040\",\n1968                     )\n1969                 )\n1970             if not (\n1971                 connection.features.supports_expression_indexes\n1972                 or \"supports_expression_indexes\" in cls._meta.required_db_features\n1973             ) and any(index.contains_expressions for index in cls._meta.indexes):\n1974                 errors.append(\n1975                     checks.Warning(\n1976                         \"%s does not support indexes on expressions.\"\n1977                         % connection.display_name,\n1978                         hint=(\n1979                             \"An index won't be created. Silence this warning \"\n1980                             \"if you don't care about it.\"\n1981                         ),\n1982                         obj=cls,\n1983                         id=\"models.W043\",\n1984                     )\n1985                 )\n1986         fields = [\n1987             field for index in cls._meta.indexes for field, _ in index.fields_orders\n1988         ]\n1989         fields += [include for index in cls._meta.indexes for include in index.include]\n1990         fields += references\n1991         errors.extend(cls._check_local_fields(fields, \"indexes\"))\n1992         return errors\n1993 \n1994     @classmethod\n1995     def _check_local_fields(cls, fields, option):\n1996         from django.db import models\n1997 \n1998         # In order to avoid hitting the relation tree prematurely, we use our\n1999         # own fields_map instead of using get_field()\n2000         forward_fields_map = {}\n2001         for field in cls._meta._get_fields(reverse=False):\n2002             forward_fields_map[field.name] = field\n2003             if hasattr(field, \"attname\"):\n2004                 forward_fields_map[field.attname] = field\n2005 \n2006         errors = []\n2007         for field_name in fields:\n2008             try:\n2009                 field = forward_fields_map[field_name]\n2010             except KeyError:\n2011                 errors.append(\n2012                     checks.Error(\n2013                         \"'%s' refers to the nonexistent field '%s'.\"\n2014                         % (\n2015                             option,\n2016                             field_name,\n2017                         ),\n2018                         obj=cls,\n2019                         id=\"models.E012\",\n2020                     )\n2021                 )\n2022             else:\n2023                 if isinstance(field.remote_field, models.ManyToManyRel):\n2024                     errors.append(\n2025                         checks.Error(\n2026                             \"'%s' refers to a ManyToManyField '%s', but \"\n2027                             \"ManyToManyFields are not permitted in '%s'.\"\n2028                             % (\n2029                                 option,\n2030                                 field_name,\n2031                                 option,\n2032                             ),\n2033                             obj=cls,\n2034                             id=\"models.E013\",\n2035                         )\n2036                     )\n2037                 elif field not in cls._meta.local_fields:\n2038                     errors.append(\n2039                         checks.Error(\n2040                             \"'%s' refers to field '%s' which is not local to model \"\n2041                             \"'%s'.\" % (option, field_name, cls._meta.object_name),\n2042                             hint=\"This issue may be caused by multi-table inheritance.\",\n2043                             obj=cls,\n2044                             id=\"models.E016\",\n2045                         )\n2046                     )\n2047         return errors\n2048 \n2049     @classmethod\n2050     def _check_ordering(cls):\n2051         \"\"\"\n2052         Check \"ordering\" option -- is it a list of strings and do all fields\n2053         exist?\n2054         \"\"\"\n2055         if cls._meta._ordering_clash:\n2056             return [\n2057                 checks.Error(\n2058                     \"'ordering' and 'order_with_respect_to' cannot be used together.\",\n2059                     obj=cls,\n2060                     id=\"models.E021\",\n2061                 ),\n2062             ]\n2063 \n2064         if cls._meta.order_with_respect_to or not cls._meta.ordering:\n2065             return []\n2066 \n2067         if not isinstance(cls._meta.ordering, (list, tuple)):\n2068             return [\n2069                 checks.Error(\n2070                     \"'ordering' must be a tuple or list (even if you want to order by \"\n2071                     \"only one field).\",\n2072                     obj=cls,\n2073                     id=\"models.E014\",\n2074                 )\n2075             ]\n2076 \n2077         errors = []\n2078         fields = cls._meta.ordering\n2079 \n2080         # Skip expressions and '?' fields.\n2081         fields = (f for f in fields if isinstance(f, str) and f != \"?\")\n2082 \n2083         # Convert \"-field\" to \"field\".\n2084         fields = ((f[1:] if f.startswith(\"-\") else f) for f in fields)\n2085 \n2086         # Separate related fields and non-related fields.\n2087         _fields = []\n2088         related_fields = []\n2089         for f in fields:\n2090             if LOOKUP_SEP in f:\n2091                 related_fields.append(f)\n2092             else:\n2093                 _fields.append(f)\n2094         fields = _fields\n2095 \n2096         # Check related fields.\n2097         for field in related_fields:\n2098             _cls = cls\n2099             fld = None\n2100             for part in field.split(LOOKUP_SEP):\n2101                 try:\n2102                     # pk is an alias that won't be found by opts.get_field.\n2103                     if part == \"pk\":\n2104                         fld = _cls._meta.pk\n2105                     else:\n2106                         fld = _cls._meta.get_field(part)\n2107                     if fld.is_relation:\n2108                         _cls = fld.path_infos[-1].to_opts.model\n2109                     else:\n2110                         _cls = None\n2111                 except (FieldDoesNotExist, AttributeError):\n2112                     if fld is None or (\n2113                         fld.get_transform(part) is None and fld.get_lookup(part) is None\n2114                     ):\n2115                         errors.append(\n2116                             checks.Error(\n2117                                 \"'ordering' refers to the nonexistent field, \"\n2118                                 \"related field, or lookup '%s'.\" % field,\n2119                                 obj=cls,\n2120                                 id=\"models.E015\",\n2121                             )\n2122                         )\n2123 \n2124         # Skip ordering on pk. This is always a valid order_by field\n2125         # but is an alias and therefore won't be found by opts.get_field.\n2126         fields = {f for f in fields if f != \"pk\"}\n2127 \n2128         # Check for invalid or nonexistent fields in ordering.\n2129         invalid_fields = []\n2130 \n2131         # Any field name that is not present in field_names does not exist.\n2132         # Also, ordering by m2m fields is not allowed.\n2133         opts = cls._meta\n2134         valid_fields = set(\n2135             chain.from_iterable(\n2136                 (f.name, f.attname)\n2137                 if not (f.auto_created and not f.concrete)\n2138                 else (f.field.related_query_name(),)\n2139                 for f in chain(opts.fields, opts.related_objects)\n2140             )\n2141         )\n2142 \n2143         invalid_fields.extend(fields - valid_fields)\n2144 \n2145         for invalid_field in invalid_fields:\n2146             errors.append(\n2147                 checks.Error(\n2148                     \"'ordering' refers to the nonexistent field, related \"\n2149                     \"field, or lookup '%s'.\" % invalid_field,\n2150                     obj=cls,\n2151                     id=\"models.E015\",\n2152                 )\n2153             )\n2154         return errors\n2155 \n2156     @classmethod\n2157     def _check_long_column_names(cls, databases):\n2158         \"\"\"\n2159         Check that any auto-generated column names are shorter than the limits\n2160         for each database in which the model will be created.\n2161         \"\"\"\n2162         if not databases:\n2163             return []\n2164         errors = []\n2165         allowed_len = None\n2166         db_alias = None\n2167 \n2168         # Find the minimum max allowed length among all specified db_aliases.\n2169         for db in databases:\n2170             # skip databases where the model won't be created\n2171             if not router.allow_migrate_model(db, cls):\n2172                 continue\n2173             connection = connections[db]\n2174             max_name_length = connection.ops.max_name_length()\n2175             if max_name_length is None or connection.features.truncates_names:\n2176                 continue\n2177             else:\n2178                 if allowed_len is None:\n2179                     allowed_len = max_name_length\n2180                     db_alias = db\n2181                 elif max_name_length < allowed_len:\n2182                     allowed_len = max_name_length\n2183                     db_alias = db\n2184 \n2185         if allowed_len is None:\n2186             return errors\n2187 \n2188         for f in cls._meta.local_fields:\n2189             _, column_name = f.get_attname_column()\n2190 \n2191             # Check if auto-generated name for the field is too long\n2192             # for the database.\n2193             if (\n2194                 f.db_column is None\n2195                 and column_name is not None\n2196                 and len(column_name) > allowed_len\n2197             ):\n2198                 errors.append(\n2199                     checks.Error(\n2200                         'Autogenerated column name too long for field \"%s\". '\n2201                         'Maximum length is \"%s\" for database \"%s\".'\n2202                         % (column_name, allowed_len, db_alias),\n2203                         hint=\"Set the column name manually using 'db_column'.\",\n2204                         obj=cls,\n2205                         id=\"models.E018\",\n2206                     )\n2207                 )\n2208 \n2209         for f in cls._meta.local_many_to_many:\n2210             # Skip nonexistent models.\n2211             if isinstance(f.remote_field.through, str):\n2212                 continue\n2213 \n2214             # Check if auto-generated name for the M2M field is too long\n2215             # for the database.\n2216             for m2m in f.remote_field.through._meta.local_fields:\n2217                 _, rel_name = m2m.get_attname_column()\n2218                 if (\n2219                     m2m.db_column is None\n2220                     and rel_name is not None\n2221                     and len(rel_name) > allowed_len\n2222                 ):\n2223                     errors.append(\n2224                         checks.Error(\n2225                             \"Autogenerated column name too long for M2M field \"\n2226                             '\"%s\". Maximum length is \"%s\" for database \"%s\".'\n2227                             % (rel_name, allowed_len, db_alias),\n2228                             hint=(\n2229                                 \"Use 'through' to create a separate model for \"\n2230                                 \"M2M and then set column_name using 'db_column'.\"\n2231                             ),\n2232                             obj=cls,\n2233                             id=\"models.E019\",\n2234                         )\n2235                     )\n2236 \n2237         return errors\n2238 \n2239     @classmethod\n2240     def _get_expr_references(cls, expr):\n2241         if isinstance(expr, Q):\n2242             for child in expr.children:\n2243                 if isinstance(child, tuple):\n2244                     lookup, value = child\n2245                     yield tuple(lookup.split(LOOKUP_SEP))\n2246                     yield from cls._get_expr_references(value)\n2247                 else:\n2248                     yield from cls._get_expr_references(child)\n2249         elif isinstance(expr, F):\n2250             yield tuple(expr.name.split(LOOKUP_SEP))\n2251         elif hasattr(expr, \"get_source_expressions\"):\n2252             for src_expr in expr.get_source_expressions():\n2253                 yield from cls._get_expr_references(src_expr)\n2254 \n2255     @classmethod\n2256     def _check_constraints(cls, databases):\n2257         errors = []\n2258         for db in databases:\n2259             if not router.allow_migrate_model(db, cls):\n2260                 continue\n2261             connection = connections[db]\n2262             if not (\n2263                 connection.features.supports_table_check_constraints\n2264                 or \"supports_table_check_constraints\" in cls._meta.required_db_features\n2265             ) and any(\n2266                 isinstance(constraint, CheckConstraint)\n2267                 for constraint in cls._meta.constraints\n2268             ):\n2269                 errors.append(\n2270                     checks.Warning(\n2271                         \"%s does not support check constraints.\"\n2272                         % connection.display_name,\n2273                         hint=(\n2274                             \"A constraint won't be created. Silence this \"\n2275                             \"warning if you don't care about it.\"\n2276                         ),\n2277                         obj=cls,\n2278                         id=\"models.W027\",\n2279                     )\n2280                 )\n2281             if not (\n2282                 connection.features.supports_partial_indexes\n2283                 or \"supports_partial_indexes\" in cls._meta.required_db_features\n2284             ) and any(\n2285                 isinstance(constraint, UniqueConstraint)\n2286                 and constraint.condition is not None\n2287                 for constraint in cls._meta.constraints\n2288             ):\n2289                 errors.append(\n2290                     checks.Warning(\n2291                         \"%s does not support unique constraints with \"\n2292                         \"conditions.\" % connection.display_name,\n2293                         hint=(\n2294                             \"A constraint won't be created. Silence this \"\n2295                             \"warning if you don't care about it.\"\n2296                         ),\n2297                         obj=cls,\n2298                         id=\"models.W036\",\n2299                     )\n2300                 )\n2301             if not (\n2302                 connection.features.supports_deferrable_unique_constraints\n2303                 or \"supports_deferrable_unique_constraints\"\n2304                 in cls._meta.required_db_features\n2305             ) and any(\n2306                 isinstance(constraint, UniqueConstraint)\n2307                 and constraint.deferrable is not None\n2308                 for constraint in cls._meta.constraints\n2309             ):\n2310                 errors.append(\n2311                     checks.Warning(\n2312                         \"%s does not support deferrable unique constraints.\"\n2313                         % connection.display_name,\n2314                         hint=(\n2315                             \"A constraint won't be created. Silence this \"\n2316                             \"warning if you don't care about it.\"\n2317                         ),\n2318                         obj=cls,\n2319                         id=\"models.W038\",\n2320                     )\n2321                 )\n2322             if not (\n2323                 connection.features.supports_covering_indexes\n2324                 or \"supports_covering_indexes\" in cls._meta.required_db_features\n2325             ) and any(\n2326                 isinstance(constraint, UniqueConstraint) and constraint.include\n2327                 for constraint in cls._meta.constraints\n2328             ):\n2329                 errors.append(\n2330                     checks.Warning(\n2331                         \"%s does not support unique constraints with non-key \"\n2332                         \"columns.\" % connection.display_name,\n2333                         hint=(\n2334                             \"A constraint won't be created. Silence this \"\n2335                             \"warning if you don't care about it.\"\n2336                         ),\n2337                         obj=cls,\n2338                         id=\"models.W039\",\n2339                     )\n2340                 )\n2341             if not (\n2342                 connection.features.supports_expression_indexes\n2343                 or \"supports_expression_indexes\" in cls._meta.required_db_features\n2344             ) and any(\n2345                 isinstance(constraint, UniqueConstraint)\n2346                 and constraint.contains_expressions\n2347                 for constraint in cls._meta.constraints\n2348             ):\n2349                 errors.append(\n2350                     checks.Warning(\n2351                         \"%s does not support unique constraints on \"\n2352                         \"expressions.\" % connection.display_name,\n2353                         hint=(\n2354                             \"A constraint won't be created. Silence this \"\n2355                             \"warning if you don't care about it.\"\n2356                         ),\n2357                         obj=cls,\n2358                         id=\"models.W044\",\n2359                     )\n2360                 )\n2361             fields = set(\n2362                 chain.from_iterable(\n2363                     (*constraint.fields, *constraint.include)\n2364                     for constraint in cls._meta.constraints\n2365                     if isinstance(constraint, UniqueConstraint)\n2366                 )\n2367             )\n2368             references = set()\n2369             for constraint in cls._meta.constraints:\n2370                 if isinstance(constraint, UniqueConstraint):\n2371                     if (\n2372                         connection.features.supports_partial_indexes\n2373                         or \"supports_partial_indexes\"\n2374                         not in cls._meta.required_db_features\n2375                     ) and isinstance(constraint.condition, Q):\n2376                         references.update(\n2377                             cls._get_expr_references(constraint.condition)\n2378                         )\n2379                     if (\n2380                         connection.features.supports_expression_indexes\n2381                         or \"supports_expression_indexes\"\n2382                         not in cls._meta.required_db_features\n2383                     ) and constraint.contains_expressions:\n2384                         for expression in constraint.expressions:\n2385                             references.update(cls._get_expr_references(expression))\n2386                 elif isinstance(constraint, CheckConstraint):\n2387                     if (\n2388                         connection.features.supports_table_check_constraints\n2389                         or \"supports_table_check_constraints\"\n2390                         not in cls._meta.required_db_features\n2391                     ):\n2392                         if isinstance(constraint.check, Q):\n2393                             references.update(\n2394                                 cls._get_expr_references(constraint.check)\n2395                             )\n2396                         if any(\n2397                             isinstance(expr, RawSQL)\n2398                             for expr in constraint.check.flatten()\n2399                         ):\n2400                             errors.append(\n2401                                 checks.Warning(\n2402                                     f\"Check constraint {constraint.name!r} contains \"\n2403                                     f\"RawSQL() expression and won't be validated \"\n2404                                     f\"during the model full_clean().\",\n2405                                     hint=(\n2406                                         \"Silence this warning if you don't care about \"\n2407                                         \"it.\"\n2408                                     ),\n2409                                     obj=cls,\n2410                                     id=\"models.W045\",\n2411                                 ),\n2412                             )\n2413             for field_name, *lookups in references:\n2414                 # pk is an alias that won't be found by opts.get_field.\n2415                 if field_name != \"pk\":\n2416                     fields.add(field_name)\n2417                 if not lookups:\n2418                     # If it has no lookups it cannot result in a JOIN.\n2419                     continue\n2420                 try:\n2421                     if field_name == \"pk\":\n2422                         field = cls._meta.pk\n2423                     else:\n2424                         field = cls._meta.get_field(field_name)\n2425                     if not field.is_relation or field.many_to_many or field.one_to_many:\n2426                         continue\n2427                 except FieldDoesNotExist:\n2428                     continue\n2429                 # JOIN must happen at the first lookup.\n2430                 first_lookup = lookups[0]\n2431                 if (\n2432                     hasattr(field, \"get_transform\")\n2433                     and hasattr(field, \"get_lookup\")\n2434                     and field.get_transform(first_lookup) is None\n2435                     and field.get_lookup(first_lookup) is None\n2436                 ):\n2437                     errors.append(\n2438                         checks.Error(\n2439                             \"'constraints' refers to the joined field '%s'.\"\n2440                             % LOOKUP_SEP.join([field_name] + lookups),\n2441                             obj=cls,\n2442                             id=\"models.E041\",\n2443                         )\n2444                     )\n2445             errors.extend(cls._check_local_fields(fields, \"constraints\"))\n2446         return errors\n2447 \n2448 \n2449 ############################################\n2450 # HELPER FUNCTIONS (CURRIED MODEL METHODS) #\n2451 ############################################\n2452 \n2453 # ORDERING METHODS #########################\n2454 \n2455 \n2456 def method_set_order(self, ordered_obj, id_list, using=None):\n2457     order_wrt = ordered_obj._meta.order_with_respect_to\n2458     filter_args = order_wrt.get_forward_related_filter(self)\n2459     ordered_obj.objects.db_manager(using).filter(**filter_args).bulk_update(\n2460         [ordered_obj(pk=pk, _order=order) for order, pk in enumerate(id_list)],\n2461         [\"_order\"],\n2462     )\n2463 \n2464 \n2465 def method_get_order(self, ordered_obj):\n2466     order_wrt = ordered_obj._meta.order_with_respect_to\n2467     filter_args = order_wrt.get_forward_related_filter(self)\n2468     pk_name = ordered_obj._meta.pk.name\n2469     return ordered_obj.objects.filter(**filter_args).values_list(pk_name, flat=True)\n2470 \n2471 \n2472 def make_foreign_order_accessors(model, related_model):\n2473     setattr(\n2474         related_model,\n2475         \"get_%s_order\" % model.__name__.lower(),\n2476         partialmethod(method_get_order, model),\n2477     )\n2478     setattr(\n2479         related_model,\n2480         \"set_%s_order\" % model.__name__.lower(),\n2481         partialmethod(method_set_order, model),\n2482     )\n2483 \n2484 \n2485 ########\n2486 # MISC #\n2487 ########\n2488 \n2489 \n2490 def model_unpickle(model_id):\n2491     \"\"\"Used to unpickle Model subclasses with deferred fields.\"\"\"\n2492     if isinstance(model_id, tuple):\n2493         model = apps.get_model(*model_id)\n2494     else:\n2495         # Backwards compat - the model was cached directly in earlier versions.\n2496         model = model_id\n2497     return model.__new__(model)\n2498 \n2499 \n2500 model_unpickle.__safe_for_unpickle__ = True\n",
        "intended_behavior": "Since this file is crucial for defining models, the intended behavior would involve ensuring that any model definition using index_together is flagged or automatically converted to use indexes. This could involve either runtime warnings during model initialization or enhancements to the model validation checks that guide developers to use indexes."
    },
    {
        "rel_file_path": "django/db/migrations/autodetector.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__4.2/django/db/migrations/autodetector.py",
        "start": 1,
        "end": 1730,
        "class_name": null,
        "method_name": null,
        "code": "1 import functools\n2 import re\n3 from collections import defaultdict\n4 from itertools import chain\n5 \n6 from django.conf import settings\n7 from django.db import models\n8 from django.db.migrations import operations\n9 from django.db.migrations.migration import Migration\n10 from django.db.migrations.operations.models import AlterModelOptions\n11 from django.db.migrations.optimizer import MigrationOptimizer\n12 from django.db.migrations.questioner import MigrationQuestioner\n13 from django.db.migrations.utils import (\n14     COMPILED_REGEX_TYPE,\n15     RegexObject,\n16     resolve_relation,\n17 )\n18 from django.utils.topological_sort import stable_topological_sort\n19 \n20 \n21 class MigrationAutodetector:\n22     \"\"\"\n23     Take a pair of ProjectStates and compare them to see what the first would\n24     need doing to make it match the second (the second usually being the\n25     project's current state).\n26 \n27     Note that this naturally operates on entire projects at a time,\n28     as it's likely that changes interact (for example, you can't\n29     add a ForeignKey without having a migration to add the table it\n30     depends on first). A user interface may offer single-app usage\n31     if it wishes, with the caveat that it may not always be possible.\n32     \"\"\"\n33 \n34     def __init__(self, from_state, to_state, questioner=None):\n35         self.from_state = from_state\n36         self.to_state = to_state\n37         self.questioner = questioner or MigrationQuestioner()\n38         self.existing_apps = {app for app, model in from_state.models}\n39 \n40     def changes(self, graph, trim_to_apps=None, convert_apps=None, migration_name=None):\n41         \"\"\"\n42         Main entry point to produce a list of applicable changes.\n43         Take a graph to base names on and an optional set of apps\n44         to try and restrict to (restriction is not guaranteed)\n45         \"\"\"\n46         changes = self._detect_changes(convert_apps, graph)\n47         changes = self.arrange_for_graph(changes, graph, migration_name)\n48         if trim_to_apps:\n49             changes = self._trim_to_apps(changes, trim_to_apps)\n50         return changes\n51 \n52     def deep_deconstruct(self, obj):\n53         \"\"\"\n54         Recursive deconstruction for a field and its arguments.\n55         Used for full comparison for rename/alter; sometimes a single-level\n56         deconstruction will not compare correctly.\n57         \"\"\"\n58         if isinstance(obj, list):\n59             return [self.deep_deconstruct(value) for value in obj]\n60         elif isinstance(obj, tuple):\n61             return tuple(self.deep_deconstruct(value) for value in obj)\n62         elif isinstance(obj, dict):\n63             return {key: self.deep_deconstruct(value) for key, value in obj.items()}\n64         elif isinstance(obj, functools.partial):\n65             return (\n66                 obj.func,\n67                 self.deep_deconstruct(obj.args),\n68                 self.deep_deconstruct(obj.keywords),\n69             )\n70         elif isinstance(obj, COMPILED_REGEX_TYPE):\n71             return RegexObject(obj)\n72         elif isinstance(obj, type):\n73             # If this is a type that implements 'deconstruct' as an instance method,\n74             # avoid treating this as being deconstructible itself - see #22951\n75             return obj\n76         elif hasattr(obj, \"deconstruct\"):\n77             deconstructed = obj.deconstruct()\n78             if isinstance(obj, models.Field):\n79                 # we have a field which also returns a name\n80                 deconstructed = deconstructed[1:]\n81             path, args, kwargs = deconstructed\n82             return (\n83                 path,\n84                 [self.deep_deconstruct(value) for value in args],\n85                 {key: self.deep_deconstruct(value) for key, value in kwargs.items()},\n86             )\n87         else:\n88             return obj\n89 \n90     def only_relation_agnostic_fields(self, fields):\n91         \"\"\"\n92         Return a definition of the fields that ignores field names and\n93         what related fields actually relate to. Used for detecting renames (as\n94         the related fields change during renames).\n95         \"\"\"\n96         fields_def = []\n97         for name, field in sorted(fields.items()):\n98             deconstruction = self.deep_deconstruct(field)\n99             if field.remote_field and field.remote_field.model:\n100                 deconstruction[2].pop(\"to\", None)\n101             fields_def.append(deconstruction)\n102         return fields_def\n103 \n104     def _detect_changes(self, convert_apps=None, graph=None):\n105         \"\"\"\n106         Return a dict of migration plans which will achieve the\n107         change from from_state to to_state. The dict has app labels\n108         as keys and a list of migrations as values.\n109 \n110         The resulting migrations aren't specially named, but the names\n111         do matter for dependencies inside the set.\n112 \n113         convert_apps is the list of apps to convert to use migrations\n114         (i.e. to make initial migrations for, in the usual case)\n115 \n116         graph is an optional argument that, if provided, can help improve\n117         dependency generation and avoid potential circular dependencies.\n118         \"\"\"\n119         # The first phase is generating all the operations for each app\n120         # and gathering them into a big per-app list.\n121         # Then go through that list, order it, and split into migrations to\n122         # resolve dependencies caused by M2Ms and FKs.\n123         self.generated_operations = {}\n124         self.altered_indexes = {}\n125         self.altered_constraints = {}\n126         self.renamed_fields = {}\n127 \n128         # Prepare some old/new state and model lists, separating\n129         # proxy models and ignoring unmigrated apps.\n130         self.old_model_keys = set()\n131         self.old_proxy_keys = set()\n132         self.old_unmanaged_keys = set()\n133         self.new_model_keys = set()\n134         self.new_proxy_keys = set()\n135         self.new_unmanaged_keys = set()\n136         for (app_label, model_name), model_state in self.from_state.models.items():\n137             if not model_state.options.get(\"managed\", True):\n138                 self.old_unmanaged_keys.add((app_label, model_name))\n139             elif app_label not in self.from_state.real_apps:\n140                 if model_state.options.get(\"proxy\"):\n141                     self.old_proxy_keys.add((app_label, model_name))\n142                 else:\n143                     self.old_model_keys.add((app_label, model_name))\n144 \n145         for (app_label, model_name), model_state in self.to_state.models.items():\n146             if not model_state.options.get(\"managed\", True):\n147                 self.new_unmanaged_keys.add((app_label, model_name))\n148             elif app_label not in self.from_state.real_apps or (\n149                 convert_apps and app_label in convert_apps\n150             ):\n151                 if model_state.options.get(\"proxy\"):\n152                     self.new_proxy_keys.add((app_label, model_name))\n153                 else:\n154                     self.new_model_keys.add((app_label, model_name))\n155 \n156         self.from_state.resolve_fields_and_relations()\n157         self.to_state.resolve_fields_and_relations()\n158 \n159         # Renames have to come first\n160         self.generate_renamed_models()\n161 \n162         # Prepare lists of fields and generate through model map\n163         self._prepare_field_lists()\n164         self._generate_through_model_map()\n165 \n166         # Generate non-rename model operations\n167         self.generate_deleted_models()\n168         self.generate_created_models()\n169         self.generate_deleted_proxies()\n170         self.generate_created_proxies()\n171         self.generate_altered_options()\n172         self.generate_altered_managers()\n173 \n174         # Create the renamed fields and store them in self.renamed_fields.\n175         # They are used by create_altered_indexes(), generate_altered_fields(),\n176         # generate_removed_altered_index/unique_together(), and\n177         # generate_altered_index/unique_together().\n178         self.create_renamed_fields()\n179         # Create the altered indexes and store them in self.altered_indexes.\n180         # This avoids the same computation in generate_removed_indexes()\n181         # and generate_added_indexes().\n182         self.create_altered_indexes()\n183         self.create_altered_constraints()\n184         # Generate index removal operations before field is removed\n185         self.generate_removed_constraints()\n186         self.generate_removed_indexes()\n187         # Generate field renaming operations.\n188         self.generate_renamed_fields()\n189         self.generate_renamed_indexes()\n190         # Generate removal of foo together.\n191         self.generate_removed_altered_unique_together()\n192         self.generate_removed_altered_index_together()\n193         # Generate field operations.\n194         self.generate_removed_fields()\n195         self.generate_added_fields()\n196         self.generate_altered_fields()\n197         self.generate_altered_order_with_respect_to()\n198         self.generate_altered_unique_together()\n199         self.generate_altered_index_together()\n200         self.generate_added_indexes()\n201         self.generate_added_constraints()\n202         self.generate_altered_db_table()\n203 \n204         self._sort_migrations()\n205         self._build_migration_list(graph)\n206         self._optimize_migrations()\n207 \n208         return self.migrations\n209 \n210     def _prepare_field_lists(self):\n211         \"\"\"\n212         Prepare field lists and a list of the fields that used through models\n213         in the old state so dependencies can be made from the through model\n214         deletion to the field that uses it.\n215         \"\"\"\n216         self.kept_model_keys = self.old_model_keys & self.new_model_keys\n217         self.kept_proxy_keys = self.old_proxy_keys & self.new_proxy_keys\n218         self.kept_unmanaged_keys = self.old_unmanaged_keys & self.new_unmanaged_keys\n219         self.through_users = {}\n220         self.old_field_keys = {\n221             (app_label, model_name, field_name)\n222             for app_label, model_name in self.kept_model_keys\n223             for field_name in self.from_state.models[\n224                 app_label, self.renamed_models.get((app_label, model_name), model_name)\n225             ].fields\n226         }\n227         self.new_field_keys = {\n228             (app_label, model_name, field_name)\n229             for app_label, model_name in self.kept_model_keys\n230             for field_name in self.to_state.models[app_label, model_name].fields\n231         }\n232 \n233     def _generate_through_model_map(self):\n234         \"\"\"Through model map generation.\"\"\"\n235         for app_label, model_name in sorted(self.old_model_keys):\n236             old_model_name = self.renamed_models.get(\n237                 (app_label, model_name), model_name\n238             )\n239             old_model_state = self.from_state.models[app_label, old_model_name]\n240             for field_name, field in old_model_state.fields.items():\n241                 if hasattr(field, \"remote_field\") and getattr(\n242                     field.remote_field, \"through\", None\n243                 ):\n244                     through_key = resolve_relation(\n245                         field.remote_field.through, app_label, model_name\n246                     )\n247                     self.through_users[through_key] = (\n248                         app_label,\n249                         old_model_name,\n250                         field_name,\n251                     )\n252 \n253     @staticmethod\n254     def _resolve_dependency(dependency):\n255         \"\"\"\n256         Return the resolved dependency and a boolean denoting whether or not\n257         it was swappable.\n258         \"\"\"\n259         if dependency[0] != \"__setting__\":\n260             return dependency, False\n261         resolved_app_label, resolved_object_name = getattr(\n262             settings, dependency[1]\n263         ).split(\".\")\n264         return (resolved_app_label, resolved_object_name.lower()) + dependency[2:], True\n265 \n266     def _build_migration_list(self, graph=None):\n267         \"\"\"\n268         Chop the lists of operations up into migrations with dependencies on\n269         each other. Do this by going through an app's list of operations until\n270         one is found that has an outgoing dependency that isn't in another\n271         app's migration yet (hasn't been chopped off its list). Then chop off\n272         the operations before it into a migration and move onto the next app.\n273         If the loops completes without doing anything, there's a circular\n274         dependency (which _should_ be impossible as the operations are\n275         all split at this point so they can't depend and be depended on).\n276         \"\"\"\n277         self.migrations = {}\n278         num_ops = sum(len(x) for x in self.generated_operations.values())\n279         chop_mode = False\n280         while num_ops:\n281             # On every iteration, we step through all the apps and see if there\n282             # is a completed set of operations.\n283             # If we find that a subset of the operations are complete we can\n284             # try to chop it off from the rest and continue, but we only\n285             # do this if we've already been through the list once before\n286             # without any chopping and nothing has changed.\n287             for app_label in sorted(self.generated_operations):\n288                 chopped = []\n289                 dependencies = set()\n290                 for operation in list(self.generated_operations[app_label]):\n291                     deps_satisfied = True\n292                     operation_dependencies = set()\n293                     for dep in operation._auto_deps:\n294                         # Temporarily resolve the swappable dependency to\n295                         # prevent circular references. While keeping the\n296                         # dependency checks on the resolved model, add the\n297                         # swappable dependencies.\n298                         original_dep = dep\n299                         dep, is_swappable_dep = self._resolve_dependency(dep)\n300                         if dep[0] != app_label:\n301                             # External app dependency. See if it's not yet\n302                             # satisfied.\n303                             for other_operation in self.generated_operations.get(\n304                                 dep[0], []\n305                             ):\n306                                 if self.check_dependency(other_operation, dep):\n307                                     deps_satisfied = False\n308                                     break\n309                             if not deps_satisfied:\n310                                 break\n311                             else:\n312                                 if is_swappable_dep:\n313                                     operation_dependencies.add(\n314                                         (original_dep[0], original_dep[1])\n315                                     )\n316                                 elif dep[0] in self.migrations:\n317                                     operation_dependencies.add(\n318                                         (dep[0], self.migrations[dep[0]][-1].name)\n319                                     )\n320                                 else:\n321                                     # If we can't find the other app, we add a\n322                                     # first/last dependency, but only if we've\n323                                     # already been through once and checked\n324                                     # everything.\n325                                     if chop_mode:\n326                                         # If the app already exists, we add a\n327                                         # dependency on the last migration, as\n328                                         # we don't know which migration\n329                                         # contains the target field. If it's\n330                                         # not yet migrated or has no\n331                                         # migrations, we use __first__.\n332                                         if graph and graph.leaf_nodes(dep[0]):\n333                                             operation_dependencies.add(\n334                                                 graph.leaf_nodes(dep[0])[0]\n335                                             )\n336                                         else:\n337                                             operation_dependencies.add(\n338                                                 (dep[0], \"__first__\")\n339                                             )\n340                                     else:\n341                                         deps_satisfied = False\n342                     if deps_satisfied:\n343                         chopped.append(operation)\n344                         dependencies.update(operation_dependencies)\n345                         del self.generated_operations[app_label][0]\n346                     else:\n347                         break\n348                 # Make a migration! Well, only if there's stuff to put in it\n349                 if dependencies or chopped:\n350                     if not self.generated_operations[app_label] or chop_mode:\n351                         subclass = type(\n352                             \"Migration\",\n353                             (Migration,),\n354                             {\"operations\": [], \"dependencies\": []},\n355                         )\n356                         instance = subclass(\n357                             \"auto_%i\" % (len(self.migrations.get(app_label, [])) + 1),\n358                             app_label,\n359                         )\n360                         instance.dependencies = list(dependencies)\n361                         instance.operations = chopped\n362                         instance.initial = app_label not in self.existing_apps\n363                         self.migrations.setdefault(app_label, []).append(instance)\n364                         chop_mode = False\n365                     else:\n366                         self.generated_operations[app_label] = (\n367                             chopped + self.generated_operations[app_label]\n368                         )\n369             new_num_ops = sum(len(x) for x in self.generated_operations.values())\n370             if new_num_ops == num_ops:\n371                 if not chop_mode:\n372                     chop_mode = True\n373                 else:\n374                     raise ValueError(\n375                         \"Cannot resolve operation dependencies: %r\"\n376                         % self.generated_operations\n377                     )\n378             num_ops = new_num_ops\n379 \n380     def _sort_migrations(self):\n381         \"\"\"\n382         Reorder to make things possible. Reordering may be needed so FKs work\n383         nicely inside the same app.\n384         \"\"\"\n385         for app_label, ops in sorted(self.generated_operations.items()):\n386             # construct a dependency graph for intra-app dependencies\n387             dependency_graph = {op: set() for op in ops}\n388             for op in ops:\n389                 for dep in op._auto_deps:\n390                     # Resolve intra-app dependencies to handle circular\n391                     # references involving a swappable model.\n392                     dep = self._resolve_dependency(dep)[0]\n393                     if dep[0] == app_label:\n394                         for op2 in ops:\n395                             if self.check_dependency(op2, dep):\n396                                 dependency_graph[op].add(op2)\n397 \n398             # we use a stable sort for deterministic tests & general behavior\n399             self.generated_operations[app_label] = stable_topological_sort(\n400                 ops, dependency_graph\n401             )\n402 \n403     def _optimize_migrations(self):\n404         # Add in internal dependencies among the migrations\n405         for app_label, migrations in self.migrations.items():\n406             for m1, m2 in zip(migrations, migrations[1:]):\n407                 m2.dependencies.append((app_label, m1.name))\n408 \n409         # De-dupe dependencies\n410         for migrations in self.migrations.values():\n411             for migration in migrations:\n412                 migration.dependencies = list(set(migration.dependencies))\n413 \n414         # Optimize migrations\n415         for app_label, migrations in self.migrations.items():\n416             for migration in migrations:\n417                 migration.operations = MigrationOptimizer().optimize(\n418                     migration.operations, app_label\n419                 )\n420 \n421     def check_dependency(self, operation, dependency):\n422         \"\"\"\n423         Return True if the given operation depends on the given dependency,\n424         False otherwise.\n425         \"\"\"\n426         # Created model\n427         if dependency[2] is None and dependency[3] is True:\n428             return (\n429                 isinstance(operation, operations.CreateModel)\n430                 and operation.name_lower == dependency[1].lower()\n431             )\n432         # Created field\n433         elif dependency[2] is not None and dependency[3] is True:\n434             return (\n435                 isinstance(operation, operations.CreateModel)\n436                 and operation.name_lower == dependency[1].lower()\n437                 and any(dependency[2] == x for x, y in operation.fields)\n438             ) or (\n439                 isinstance(operation, operations.AddField)\n440                 and operation.model_name_lower == dependency[1].lower()\n441                 and operation.name_lower == dependency[2].lower()\n442             )\n443         # Removed field\n444         elif dependency[2] is not None and dependency[3] is False:\n445             return (\n446                 isinstance(operation, operations.RemoveField)\n447                 and operation.model_name_lower == dependency[1].lower()\n448                 and operation.name_lower == dependency[2].lower()\n449             )\n450         # Removed model\n451         elif dependency[2] is None and dependency[3] is False:\n452             return (\n453                 isinstance(operation, operations.DeleteModel)\n454                 and operation.name_lower == dependency[1].lower()\n455             )\n456         # Field being altered\n457         elif dependency[2] is not None and dependency[3] == \"alter\":\n458             return (\n459                 isinstance(operation, operations.AlterField)\n460                 and operation.model_name_lower == dependency[1].lower()\n461                 and operation.name_lower == dependency[2].lower()\n462             )\n463         # order_with_respect_to being unset for a field\n464         elif dependency[2] is not None and dependency[3] == \"order_wrt_unset\":\n465             return (\n466                 isinstance(operation, operations.AlterOrderWithRespectTo)\n467                 and operation.name_lower == dependency[1].lower()\n468                 and (operation.order_with_respect_to or \"\").lower()\n469                 != dependency[2].lower()\n470             )\n471         # Field is removed and part of an index/unique_together\n472         elif dependency[2] is not None and dependency[3] == \"foo_together_change\":\n473             return (\n474                 isinstance(\n475                     operation,\n476                     (operations.AlterUniqueTogether, operations.AlterIndexTogether),\n477                 )\n478                 and operation.name_lower == dependency[1].lower()\n479             )\n480         # Unknown dependency. Raise an error.\n481         else:\n482             raise ValueError(\"Can't handle dependency %r\" % (dependency,))\n483 \n484     def add_operation(self, app_label, operation, dependencies=None, beginning=False):\n485         # Dependencies are\n486         # (app_label, model_name, field_name, create/delete as True/False)\n487         operation._auto_deps = dependencies or []\n488         if beginning:\n489             self.generated_operations.setdefault(app_label, []).insert(0, operation)\n490         else:\n491             self.generated_operations.setdefault(app_label, []).append(operation)\n492 \n493     def swappable_first_key(self, item):\n494         \"\"\"\n495         Place potential swappable models first in lists of created models (only\n496         real way to solve #22783).\n497         \"\"\"\n498         try:\n499             model_state = self.to_state.models[item]\n500             base_names = {\n501                 base if isinstance(base, str) else base.__name__\n502                 for base in model_state.bases\n503             }\n504             string_version = \"%s.%s\" % (item[0], item[1])\n505             if (\n506                 model_state.options.get(\"swappable\")\n507                 or \"AbstractUser\" in base_names\n508                 or \"AbstractBaseUser\" in base_names\n509                 or settings.AUTH_USER_MODEL.lower() == string_version.lower()\n510             ):\n511                 return (\"___\" + item[0], \"___\" + item[1])\n512         except LookupError:\n513             pass\n514         return item\n515 \n516     def generate_renamed_models(self):\n517         \"\"\"\n518         Find any renamed models, generate the operations for them, and remove\n519         the old entry from the model lists. Must be run before other\n520         model-level generation.\n521         \"\"\"\n522         self.renamed_models = {}\n523         self.renamed_models_rel = {}\n524         added_models = self.new_model_keys - self.old_model_keys\n525         for app_label, model_name in sorted(added_models):\n526             model_state = self.to_state.models[app_label, model_name]\n527             model_fields_def = self.only_relation_agnostic_fields(model_state.fields)\n528 \n529             removed_models = self.old_model_keys - self.new_model_keys\n530             for rem_app_label, rem_model_name in removed_models:\n531                 if rem_app_label == app_label:\n532                     rem_model_state = self.from_state.models[\n533                         rem_app_label, rem_model_name\n534                     ]\n535                     rem_model_fields_def = self.only_relation_agnostic_fields(\n536                         rem_model_state.fields\n537                     )\n538                     if model_fields_def == rem_model_fields_def:\n539                         if self.questioner.ask_rename_model(\n540                             rem_model_state, model_state\n541                         ):\n542                             dependencies = []\n543                             fields = list(model_state.fields.values()) + [\n544                                 field.remote_field\n545                                 for relations in self.to_state.relations[\n546                                     app_label, model_name\n547                                 ].values()\n548                                 for field in relations.values()\n549                             ]\n550                             for field in fields:\n551                                 if field.is_relation:\n552                                     dependencies.extend(\n553                                         self._get_dependencies_for_foreign_key(\n554                                             app_label,\n555                                             model_name,\n556                                             field,\n557                                             self.to_state,\n558                                         )\n559                                     )\n560                             self.add_operation(\n561                                 app_label,\n562                                 operations.RenameModel(\n563                                     old_name=rem_model_state.name,\n564                                     new_name=model_state.name,\n565                                 ),\n566                                 dependencies=dependencies,\n567                             )\n568                             self.renamed_models[app_label, model_name] = rem_model_name\n569                             renamed_models_rel_key = \"%s.%s\" % (\n570                                 rem_model_state.app_label,\n571                                 rem_model_state.name_lower,\n572                             )\n573                             self.renamed_models_rel[\n574                                 renamed_models_rel_key\n575                             ] = \"%s.%s\" % (\n576                                 model_state.app_label,\n577                                 model_state.name_lower,\n578                             )\n579                             self.old_model_keys.remove((rem_app_label, rem_model_name))\n580                             self.old_model_keys.add((app_label, model_name))\n581                             break\n582 \n583     def generate_created_models(self):\n584         \"\"\"\n585         Find all new models (both managed and unmanaged) and make create\n586         operations for them as well as separate operations to create any\n587         foreign key or M2M relationships (these are optimized later, if\n588         possible).\n589 \n590         Defer any model options that refer to collections of fields that might\n591         be deferred (e.g. unique_together, index_together).\n592         \"\"\"\n593         old_keys = self.old_model_keys | self.old_unmanaged_keys\n594         added_models = self.new_model_keys - old_keys\n595         added_unmanaged_models = self.new_unmanaged_keys - old_keys\n596         all_added_models = chain(\n597             sorted(added_models, key=self.swappable_first_key, reverse=True),\n598             sorted(added_unmanaged_models, key=self.swappable_first_key, reverse=True),\n599         )\n600         for app_label, model_name in all_added_models:\n601             model_state = self.to_state.models[app_label, model_name]\n602             # Gather related fields\n603             related_fields = {}\n604             primary_key_rel = None\n605             for field_name, field in model_state.fields.items():\n606                 if field.remote_field:\n607                     if field.remote_field.model:\n608                         if field.primary_key:\n609                             primary_key_rel = field.remote_field.model\n610                         elif not field.remote_field.parent_link:\n611                             related_fields[field_name] = field\n612                     if getattr(field.remote_field, \"through\", None):\n613                         related_fields[field_name] = field\n614 \n615             # Are there indexes/unique|index_together to defer?\n616             indexes = model_state.options.pop(\"indexes\")\n617             constraints = model_state.options.pop(\"constraints\")\n618             unique_together = model_state.options.pop(\"unique_together\", None)\n619             index_together = model_state.options.pop(\"index_together\", None)\n620             order_with_respect_to = model_state.options.pop(\n621                 \"order_with_respect_to\", None\n622             )\n623             # Depend on the deletion of any possible proxy version of us\n624             dependencies = [\n625                 (app_label, model_name, None, False),\n626             ]\n627             # Depend on all bases\n628             for base in model_state.bases:\n629                 if isinstance(base, str) and \".\" in base:\n630                     base_app_label, base_name = base.split(\".\", 1)\n631                     dependencies.append((base_app_label, base_name, None, True))\n632                     # Depend on the removal of base fields if the new model has\n633                     # a field with the same name.\n634                     old_base_model_state = self.from_state.models.get(\n635                         (base_app_label, base_name)\n636                     )\n637                     new_base_model_state = self.to_state.models.get(\n638                         (base_app_label, base_name)\n639                     )\n640                     if old_base_model_state and new_base_model_state:\n641                         removed_base_fields = (\n642                             set(old_base_model_state.fields)\n643                             .difference(\n644                                 new_base_model_state.fields,\n645                             )\n646                             .intersection(model_state.fields)\n647                         )\n648                         for removed_base_field in removed_base_fields:\n649                             dependencies.append(\n650                                 (base_app_label, base_name, removed_base_field, False)\n651                             )\n652             # Depend on the other end of the primary key if it's a relation\n653             if primary_key_rel:\n654                 dependencies.append(\n655                     resolve_relation(\n656                         primary_key_rel,\n657                         app_label,\n658                         model_name,\n659                     )\n660                     + (None, True)\n661                 )\n662             # Generate creation operation\n663             self.add_operation(\n664                 app_label,\n665                 operations.CreateModel(\n666                     name=model_state.name,\n667                     fields=[\n668                         d\n669                         for d in model_state.fields.items()\n670                         if d[0] not in related_fields\n671                     ],\n672                     options=model_state.options,\n673                     bases=model_state.bases,\n674                     managers=model_state.managers,\n675                 ),\n676                 dependencies=dependencies,\n677                 beginning=True,\n678             )\n679 \n680             # Don't add operations which modify the database for unmanaged models\n681             if not model_state.options.get(\"managed\", True):\n682                 continue\n683 \n684             # Generate operations for each related field\n685             for name, field in sorted(related_fields.items()):\n686                 dependencies = self._get_dependencies_for_foreign_key(\n687                     app_label,\n688                     model_name,\n689                     field,\n690                     self.to_state,\n691                 )\n692                 # Depend on our own model being created\n693                 dependencies.append((app_label, model_name, None, True))\n694                 # Make operation\n695                 self.add_operation(\n696                     app_label,\n697                     operations.AddField(\n698                         model_name=model_name,\n699                         name=name,\n700                         field=field,\n701                     ),\n702                     dependencies=list(set(dependencies)),\n703                 )\n704             # Generate other opns\n705             if order_with_respect_to:\n706                 self.add_operation(\n707                     app_label,\n708                     operations.AlterOrderWithRespectTo(\n709                         name=model_name,\n710                         order_with_respect_to=order_with_respect_to,\n711                     ),\n712                     dependencies=[\n713                         (app_label, model_name, order_with_respect_to, True),\n714                         (app_label, model_name, None, True),\n715                     ],\n716                 )\n717             related_dependencies = [\n718                 (app_label, model_name, name, True) for name in sorted(related_fields)\n719             ]\n720             related_dependencies.append((app_label, model_name, None, True))\n721             for index in indexes:\n722                 self.add_operation(\n723                     app_label,\n724                     operations.AddIndex(\n725                         model_name=model_name,\n726                         index=index,\n727                     ),\n728                     dependencies=related_dependencies,\n729                 )\n730             for constraint in constraints:\n731                 self.add_operation(\n732                     app_label,\n733                     operations.AddConstraint(\n734                         model_name=model_name,\n735                         constraint=constraint,\n736                     ),\n737                     dependencies=related_dependencies,\n738                 )\n739             if unique_together:\n740                 self.add_operation(\n741                     app_label,\n742                     operations.AlterUniqueTogether(\n743                         name=model_name,\n744                         unique_together=unique_together,\n745                     ),\n746                     dependencies=related_dependencies,\n747                 )\n748             if index_together:\n749                 self.add_operation(\n750                     app_label,\n751                     operations.AlterIndexTogether(\n752                         name=model_name,\n753                         index_together=index_together,\n754                     ),\n755                     dependencies=related_dependencies,\n756                 )\n757             # Fix relationships if the model changed from a proxy model to a\n758             # concrete model.\n759             relations = self.to_state.relations\n760             if (app_label, model_name) in self.old_proxy_keys:\n761                 for related_model_key, related_fields in relations[\n762                     app_label, model_name\n763                 ].items():\n764                     related_model_state = self.to_state.models[related_model_key]\n765                     for related_field_name, related_field in related_fields.items():\n766                         self.add_operation(\n767                             related_model_state.app_label,\n768                             operations.AlterField(\n769                                 model_name=related_model_state.name,\n770                                 name=related_field_name,\n771                                 field=related_field,\n772                             ),\n773                             dependencies=[(app_label, model_name, None, True)],\n774                         )\n775 \n776     def generate_created_proxies(self):\n777         \"\"\"\n778         Make CreateModel statements for proxy models. Use the same statements\n779         as that way there's less code duplication, but for proxy models it's\n780         safe to skip all the pointless field stuff and chuck out an operation.\n781         \"\"\"\n782         added = self.new_proxy_keys - self.old_proxy_keys\n783         for app_label, model_name in sorted(added):\n784             model_state = self.to_state.models[app_label, model_name]\n785             assert model_state.options.get(\"proxy\")\n786             # Depend on the deletion of any possible non-proxy version of us\n787             dependencies = [\n788                 (app_label, model_name, None, False),\n789             ]\n790             # Depend on all bases\n791             for base in model_state.bases:\n792                 if isinstance(base, str) and \".\" in base:\n793                     base_app_label, base_name = base.split(\".\", 1)\n794                     dependencies.append((base_app_label, base_name, None, True))\n795             # Generate creation operation\n796             self.add_operation(\n797                 app_label,\n798                 operations.CreateModel(\n799                     name=model_state.name,\n800                     fields=[],\n801                     options=model_state.options,\n802                     bases=model_state.bases,\n803                     managers=model_state.managers,\n804                 ),\n805                 # Depend on the deletion of any possible non-proxy version of us\n806                 dependencies=dependencies,\n807             )\n808 \n809     def generate_deleted_models(self):\n810         \"\"\"\n811         Find all deleted models (managed and unmanaged) and make delete\n812         operations for them as well as separate operations to delete any\n813         foreign key or M2M relationships (these are optimized later, if\n814         possible).\n815 \n816         Also bring forward removal of any model options that refer to\n817         collections of fields - the inverse of generate_created_models().\n818         \"\"\"\n819         new_keys = self.new_model_keys | self.new_unmanaged_keys\n820         deleted_models = self.old_model_keys - new_keys\n821         deleted_unmanaged_models = self.old_unmanaged_keys - new_keys\n822         all_deleted_models = chain(\n823             sorted(deleted_models), sorted(deleted_unmanaged_models)\n824         )\n825         for app_label, model_name in all_deleted_models:\n826             model_state = self.from_state.models[app_label, model_name]\n827             # Gather related fields\n828             related_fields = {}\n829             for field_name, field in model_state.fields.items():\n830                 if field.remote_field:\n831                     if field.remote_field.model:\n832                         related_fields[field_name] = field\n833                     if getattr(field.remote_field, \"through\", None):\n834                         related_fields[field_name] = field\n835             # Generate option removal first\n836             unique_together = model_state.options.pop(\"unique_together\", None)\n837             index_together = model_state.options.pop(\"index_together\", None)\n838             if unique_together:\n839                 self.add_operation(\n840                     app_label,\n841                     operations.AlterUniqueTogether(\n842                         name=model_name,\n843                         unique_together=None,\n844                     ),\n845                 )\n846             if index_together:\n847                 self.add_operation(\n848                     app_label,\n849                     operations.AlterIndexTogether(\n850                         name=model_name,\n851                         index_together=None,\n852                     ),\n853                 )\n854             # Then remove each related field\n855             for name in sorted(related_fields):\n856                 self.add_operation(\n857                     app_label,\n858                     operations.RemoveField(\n859                         model_name=model_name,\n860                         name=name,\n861                     ),\n862                 )\n863             # Finally, remove the model.\n864             # This depends on both the removal/alteration of all incoming fields\n865             # and the removal of all its own related fields, and if it's\n866             # a through model the field that references it.\n867             dependencies = []\n868             relations = self.from_state.relations\n869             for (\n870                 related_object_app_label,\n871                 object_name,\n872             ), relation_related_fields in relations[app_label, model_name].items():\n873                 for field_name, field in relation_related_fields.items():\n874                     dependencies.append(\n875                         (related_object_app_label, object_name, field_name, False),\n876                     )\n877                     if not field.many_to_many:\n878                         dependencies.append(\n879                             (\n880                                 related_object_app_label,\n881                                 object_name,\n882                                 field_name,\n883                                 \"alter\",\n884                             ),\n885                         )\n886 \n887             for name in sorted(related_fields):\n888                 dependencies.append((app_label, model_name, name, False))\n889             # We're referenced in another field's through=\n890             through_user = self.through_users.get((app_label, model_state.name_lower))\n891             if through_user:\n892                 dependencies.append(\n893                     (through_user[0], through_user[1], through_user[2], False)\n894                 )\n895             # Finally, make the operation, deduping any dependencies\n896             self.add_operation(\n897                 app_label,\n898                 operations.DeleteModel(\n899                     name=model_state.name,\n900                 ),\n901                 dependencies=list(set(dependencies)),\n902             )\n903 \n904     def generate_deleted_proxies(self):\n905         \"\"\"Make DeleteModel options for proxy models.\"\"\"\n906         deleted = self.old_proxy_keys - self.new_proxy_keys\n907         for app_label, model_name in sorted(deleted):\n908             model_state = self.from_state.models[app_label, model_name]\n909             assert model_state.options.get(\"proxy\")\n910             self.add_operation(\n911                 app_label,\n912                 operations.DeleteModel(\n913                     name=model_state.name,\n914                 ),\n915             )\n916 \n917     def create_renamed_fields(self):\n918         \"\"\"Work out renamed fields.\"\"\"\n919         self.renamed_operations = []\n920         old_field_keys = self.old_field_keys.copy()\n921         for app_label, model_name, field_name in sorted(\n922             self.new_field_keys - old_field_keys\n923         ):\n924             old_model_name = self.renamed_models.get(\n925                 (app_label, model_name), model_name\n926             )\n927             old_model_state = self.from_state.models[app_label, old_model_name]\n928             new_model_state = self.to_state.models[app_label, model_name]\n929             field = new_model_state.get_field(field_name)\n930             # Scan to see if this is actually a rename!\n931             field_dec = self.deep_deconstruct(field)\n932             for rem_app_label, rem_model_name, rem_field_name in sorted(\n933                 old_field_keys - self.new_field_keys\n934             ):\n935                 if rem_app_label == app_label and rem_model_name == model_name:\n936                     old_field = old_model_state.get_field(rem_field_name)\n937                     old_field_dec = self.deep_deconstruct(old_field)\n938                     if (\n939                         field.remote_field\n940                         and field.remote_field.model\n941                         and \"to\" in old_field_dec[2]\n942                     ):\n943                         old_rel_to = old_field_dec[2][\"to\"]\n944                         if old_rel_to in self.renamed_models_rel:\n945                             old_field_dec[2][\"to\"] = self.renamed_models_rel[old_rel_to]\n946                     old_field.set_attributes_from_name(rem_field_name)\n947                     old_db_column = old_field.get_attname_column()[1]\n948                     if old_field_dec == field_dec or (\n949                         # Was the field renamed and db_column equal to the\n950                         # old field's column added?\n951                         old_field_dec[0:2] == field_dec[0:2]\n952                         and dict(old_field_dec[2], db_column=old_db_column)\n953                         == field_dec[2]\n954                     ):\n955                         if self.questioner.ask_rename(\n956                             model_name, rem_field_name, field_name, field\n957                         ):\n958                             self.renamed_operations.append(\n959                                 (\n960                                     rem_app_label,\n961                                     rem_model_name,\n962                                     old_field.db_column,\n963                                     rem_field_name,\n964                                     app_label,\n965                                     model_name,\n966                                     field,\n967                                     field_name,\n968                                 )\n969                             )\n970                             old_field_keys.remove(\n971                                 (rem_app_label, rem_model_name, rem_field_name)\n972                             )\n973                             old_field_keys.add((app_label, model_name, field_name))\n974                             self.renamed_fields[\n975                                 app_label, model_name, field_name\n976                             ] = rem_field_name\n977                             break\n978 \n979     def generate_renamed_fields(self):\n980         \"\"\"Generate RenameField operations.\"\"\"\n981         for (\n982             rem_app_label,\n983             rem_model_name,\n984             rem_db_column,\n985             rem_field_name,\n986             app_label,\n987             model_name,\n988             field,\n989             field_name,\n990         ) in self.renamed_operations:\n991             # A db_column mismatch requires a prior noop AlterField for the\n992             # subsequent RenameField to be a noop on attempts at preserving the\n993             # old name.\n994             if rem_db_column != field.db_column:\n995                 altered_field = field.clone()\n996                 altered_field.name = rem_field_name\n997                 self.add_operation(\n998                     app_label,\n999                     operations.AlterField(\n1000                         model_name=model_name,\n1001                         name=rem_field_name,\n1002                         field=altered_field,\n1003                     ),\n1004                 )\n1005             self.add_operation(\n1006                 app_label,\n1007                 operations.RenameField(\n1008                     model_name=model_name,\n1009                     old_name=rem_field_name,\n1010                     new_name=field_name,\n1011                 ),\n1012             )\n1013             self.old_field_keys.remove((rem_app_label, rem_model_name, rem_field_name))\n1014             self.old_field_keys.add((app_label, model_name, field_name))\n1015 \n1016     def generate_added_fields(self):\n1017         \"\"\"Make AddField operations.\"\"\"\n1018         for app_label, model_name, field_name in sorted(\n1019             self.new_field_keys - self.old_field_keys\n1020         ):\n1021             self._generate_added_field(app_label, model_name, field_name)\n1022 \n1023     def _generate_added_field(self, app_label, model_name, field_name):\n1024         field = self.to_state.models[app_label, model_name].get_field(field_name)\n1025         # Adding a field always depends at least on its removal.\n1026         dependencies = [(app_label, model_name, field_name, False)]\n1027         # Fields that are foreignkeys/m2ms depend on stuff.\n1028         if field.remote_field and field.remote_field.model:\n1029             dependencies.extend(\n1030                 self._get_dependencies_for_foreign_key(\n1031                     app_label,\n1032                     model_name,\n1033                     field,\n1034                     self.to_state,\n1035                 )\n1036             )\n1037         # You can't just add NOT NULL fields with no default or fields\n1038         # which don't allow empty strings as default.\n1039         time_fields = (models.DateField, models.DateTimeField, models.TimeField)\n1040         preserve_default = (\n1041             field.null\n1042             or field.has_default()\n1043             or field.many_to_many\n1044             or (field.blank and field.empty_strings_allowed)\n1045             or (isinstance(field, time_fields) and field.auto_now)\n1046         )\n1047         if not preserve_default:\n1048             field = field.clone()\n1049             if isinstance(field, time_fields) and field.auto_now_add:\n1050                 field.default = self.questioner.ask_auto_now_add_addition(\n1051                     field_name, model_name\n1052                 )\n1053             else:\n1054                 field.default = self.questioner.ask_not_null_addition(\n1055                     field_name, model_name\n1056                 )\n1057         if (\n1058             field.unique\n1059             and field.default is not models.NOT_PROVIDED\n1060             and callable(field.default)\n1061         ):\n1062             self.questioner.ask_unique_callable_default_addition(field_name, model_name)\n1063         self.add_operation(\n1064             app_label,\n1065             operations.AddField(\n1066                 model_name=model_name,\n1067                 name=field_name,\n1068                 field=field,\n1069                 preserve_default=preserve_default,\n1070             ),\n1071             dependencies=dependencies,\n1072         )\n1073 \n1074     def generate_removed_fields(self):\n1075         \"\"\"Make RemoveField operations.\"\"\"\n1076         for app_label, model_name, field_name in sorted(\n1077             self.old_field_keys - self.new_field_keys\n1078         ):\n1079             self._generate_removed_field(app_label, model_name, field_name)\n1080 \n1081     def _generate_removed_field(self, app_label, model_name, field_name):\n1082         self.add_operation(\n1083             app_label,\n1084             operations.RemoveField(\n1085                 model_name=model_name,\n1086                 name=field_name,\n1087             ),\n1088             # We might need to depend on the removal of an\n1089             # order_with_respect_to or index/unique_together operation;\n1090             # this is safely ignored if there isn't one\n1091             dependencies=[\n1092                 (app_label, model_name, field_name, \"order_wrt_unset\"),\n1093                 (app_label, model_name, field_name, \"foo_together_change\"),\n1094             ],\n1095         )\n1096 \n1097     def generate_altered_fields(self):\n1098         \"\"\"\n1099         Make AlterField operations, or possibly RemovedField/AddField if alter\n1100         isn't possible.\n1101         \"\"\"\n1102         for app_label, model_name, field_name in sorted(\n1103             self.old_field_keys & self.new_field_keys\n1104         ):\n1105             # Did the field change?\n1106             old_model_name = self.renamed_models.get(\n1107                 (app_label, model_name), model_name\n1108             )\n1109             old_field_name = self.renamed_fields.get(\n1110                 (app_label, model_name, field_name), field_name\n1111             )\n1112             old_field = self.from_state.models[app_label, old_model_name].get_field(\n1113                 old_field_name\n1114             )\n1115             new_field = self.to_state.models[app_label, model_name].get_field(\n1116                 field_name\n1117             )\n1118             dependencies = []\n1119             # Implement any model renames on relations; these are handled by RenameModel\n1120             # so we need to exclude them from the comparison\n1121             if hasattr(new_field, \"remote_field\") and getattr(\n1122                 new_field.remote_field, \"model\", None\n1123             ):\n1124                 rename_key = resolve_relation(\n1125                     new_field.remote_field.model, app_label, model_name\n1126                 )\n1127                 if rename_key in self.renamed_models:\n1128                     new_field.remote_field.model = old_field.remote_field.model\n1129                 # Handle ForeignKey which can only have a single to_field.\n1130                 remote_field_name = getattr(new_field.remote_field, \"field_name\", None)\n1131                 if remote_field_name:\n1132                     to_field_rename_key = rename_key + (remote_field_name,)\n1133                     if to_field_rename_key in self.renamed_fields:\n1134                         # Repoint both model and field name because to_field\n1135                         # inclusion in ForeignKey.deconstruct() is based on\n1136                         # both.\n1137                         new_field.remote_field.model = old_field.remote_field.model\n1138                         new_field.remote_field.field_name = (\n1139                             old_field.remote_field.field_name\n1140                         )\n1141                 # Handle ForeignObjects which can have multiple from_fields/to_fields.\n1142                 from_fields = getattr(new_field, \"from_fields\", None)\n1143                 if from_fields:\n1144                     from_rename_key = (app_label, model_name)\n1145                     new_field.from_fields = tuple(\n1146                         [\n1147                             self.renamed_fields.get(\n1148                                 from_rename_key + (from_field,), from_field\n1149                             )\n1150                             for from_field in from_fields\n1151                         ]\n1152                     )\n1153                     new_field.to_fields = tuple(\n1154                         [\n1155                             self.renamed_fields.get(rename_key + (to_field,), to_field)\n1156                             for to_field in new_field.to_fields\n1157                         ]\n1158                     )\n1159                 dependencies.extend(\n1160                     self._get_dependencies_for_foreign_key(\n1161                         app_label,\n1162                         model_name,\n1163                         new_field,\n1164                         self.to_state,\n1165                     )\n1166                 )\n1167             if hasattr(new_field, \"remote_field\") and getattr(\n1168                 new_field.remote_field, \"through\", None\n1169             ):\n1170                 rename_key = resolve_relation(\n1171                     new_field.remote_field.through, app_label, model_name\n1172                 )\n1173                 if rename_key in self.renamed_models:\n1174                     new_field.remote_field.through = old_field.remote_field.through\n1175             old_field_dec = self.deep_deconstruct(old_field)\n1176             new_field_dec = self.deep_deconstruct(new_field)\n1177             # If the field was confirmed to be renamed it means that only\n1178             # db_column was allowed to change which generate_renamed_fields()\n1179             # already accounts for by adding an AlterField operation.\n1180             if old_field_dec != new_field_dec and old_field_name == field_name:\n1181                 both_m2m = old_field.many_to_many and new_field.many_to_many\n1182                 neither_m2m = not old_field.many_to_many and not new_field.many_to_many\n1183                 if both_m2m or neither_m2m:\n1184                     # Either both fields are m2m or neither is\n1185                     preserve_default = True\n1186                     if (\n1187                         old_field.null\n1188                         and not new_field.null\n1189                         and not new_field.has_default()\n1190                         and not new_field.many_to_many\n1191                     ):\n1192                         field = new_field.clone()\n1193                         new_default = self.questioner.ask_not_null_alteration(\n1194                             field_name, model_name\n1195                         )\n1196                         if new_default is not models.NOT_PROVIDED:\n1197                             field.default = new_default\n1198                             preserve_default = False\n1199                     else:\n1200                         field = new_field\n1201                     self.add_operation(\n1202                         app_label,\n1203                         operations.AlterField(\n1204                             model_name=model_name,\n1205                             name=field_name,\n1206                             field=field,\n1207                             preserve_default=preserve_default,\n1208                         ),\n1209                         dependencies=dependencies,\n1210                     )\n1211                 else:\n1212                     # We cannot alter between m2m and concrete fields\n1213                     self._generate_removed_field(app_label, model_name, field_name)\n1214                     self._generate_added_field(app_label, model_name, field_name)\n1215 \n1216     def create_altered_indexes(self):\n1217         option_name = operations.AddIndex.option_name\n1218         self.renamed_index_together_values = defaultdict(list)\n1219 \n1220         for app_label, model_name in sorted(self.kept_model_keys):\n1221             old_model_name = self.renamed_models.get(\n1222                 (app_label, model_name), model_name\n1223             )\n1224             old_model_state = self.from_state.models[app_label, old_model_name]\n1225             new_model_state = self.to_state.models[app_label, model_name]\n1226 \n1227             old_indexes = old_model_state.options[option_name]\n1228             new_indexes = new_model_state.options[option_name]\n1229             added_indexes = [idx for idx in new_indexes if idx not in old_indexes]\n1230             removed_indexes = [idx for idx in old_indexes if idx not in new_indexes]\n1231             renamed_indexes = []\n1232             # Find renamed indexes.\n1233             remove_from_added = []\n1234             remove_from_removed = []\n1235             for new_index in added_indexes:\n1236                 new_index_dec = new_index.deconstruct()\n1237                 new_index_name = new_index_dec[2].pop(\"name\")\n1238                 for old_index in removed_indexes:\n1239                     old_index_dec = old_index.deconstruct()\n1240                     old_index_name = old_index_dec[2].pop(\"name\")\n1241                     # Indexes are the same except for the names.\n1242                     if (\n1243                         new_index_dec == old_index_dec\n1244                         and new_index_name != old_index_name\n1245                     ):\n1246                         renamed_indexes.append((old_index_name, new_index_name, None))\n1247                         remove_from_added.append(new_index)\n1248                         remove_from_removed.append(old_index)\n1249             # Find index_together changed to indexes.\n1250             for (\n1251                 old_value,\n1252                 new_value,\n1253                 index_together_app_label,\n1254                 index_together_model_name,\n1255                 dependencies,\n1256             ) in self._get_altered_foo_together_operations(\n1257                 operations.AlterIndexTogether.option_name\n1258             ):\n1259                 if (\n1260                     app_label != index_together_app_label\n1261                     or model_name != index_together_model_name\n1262                 ):\n1263                     continue\n1264                 removed_values = old_value.difference(new_value)\n1265                 for removed_index_together in removed_values:\n1266                     renamed_index_together_indexes = []\n1267                     for new_index in added_indexes:\n1268                         _, args, kwargs = new_index.deconstruct()\n1269                         # Ensure only 'fields' are defined in the Index.\n1270                         if (\n1271                             not args\n1272                             and new_index.fields == list(removed_index_together)\n1273                             and set(kwargs) == {\"name\", \"fields\"}\n1274                         ):\n1275                             renamed_index_together_indexes.append(new_index)\n1276 \n1277                     if len(renamed_index_together_indexes) == 1:\n1278                         renamed_index = renamed_index_together_indexes[0]\n1279                         remove_from_added.append(renamed_index)\n1280                         renamed_indexes.append(\n1281                             (None, renamed_index.name, removed_index_together)\n1282                         )\n1283                         self.renamed_index_together_values[\n1284                             index_together_app_label, index_together_model_name\n1285                         ].append(removed_index_together)\n1286             # Remove renamed indexes from the lists of added and removed\n1287             # indexes.\n1288             added_indexes = [\n1289                 idx for idx in added_indexes if idx not in remove_from_added\n1290             ]\n1291             removed_indexes = [\n1292                 idx for idx in removed_indexes if idx not in remove_from_removed\n1293             ]\n1294 \n1295             self.altered_indexes.update(\n1296                 {\n1297                     (app_label, model_name): {\n1298                         \"added_indexes\": added_indexes,\n1299                         \"removed_indexes\": removed_indexes,\n1300                         \"renamed_indexes\": renamed_indexes,\n1301                     }\n1302                 }\n1303             )\n1304 \n1305     def generate_added_indexes(self):\n1306         for (app_label, model_name), alt_indexes in self.altered_indexes.items():\n1307             for index in alt_indexes[\"added_indexes\"]:\n1308                 self.add_operation(\n1309                     app_label,\n1310                     operations.AddIndex(\n1311                         model_name=model_name,\n1312                         index=index,\n1313                     ),\n1314                 )\n1315 \n1316     def generate_removed_indexes(self):\n1317         for (app_label, model_name), alt_indexes in self.altered_indexes.items():\n1318             for index in alt_indexes[\"removed_indexes\"]:\n1319                 self.add_operation(\n1320                     app_label,\n1321                     operations.RemoveIndex(\n1322                         model_name=model_name,\n1323                         name=index.name,\n1324                     ),\n1325                 )\n1326 \n1327     def generate_renamed_indexes(self):\n1328         for (app_label, model_name), alt_indexes in self.altered_indexes.items():\n1329             for old_index_name, new_index_name, old_fields in alt_indexes[\n1330                 \"renamed_indexes\"\n1331             ]:\n1332                 self.add_operation(\n1333                     app_label,\n1334                     operations.RenameIndex(\n1335                         model_name=model_name,\n1336                         new_name=new_index_name,\n1337                         old_name=old_index_name,\n1338                         old_fields=old_fields,\n1339                     ),\n1340                 )\n1341 \n1342     def create_altered_constraints(self):\n1343         option_name = operations.AddConstraint.option_name\n1344         for app_label, model_name in sorted(self.kept_model_keys):\n1345             old_model_name = self.renamed_models.get(\n1346                 (app_label, model_name), model_name\n1347             )\n1348             old_model_state = self.from_state.models[app_label, old_model_name]\n1349             new_model_state = self.to_state.models[app_label, model_name]\n1350 \n1351             old_constraints = old_model_state.options[option_name]\n1352             new_constraints = new_model_state.options[option_name]\n1353             add_constraints = [c for c in new_constraints if c not in old_constraints]\n1354             rem_constraints = [c for c in old_constraints if c not in new_constraints]\n1355 \n1356             self.altered_constraints.update(\n1357                 {\n1358                     (app_label, model_name): {\n1359                         \"added_constraints\": add_constraints,\n1360                         \"removed_constraints\": rem_constraints,\n1361                     }\n1362                 }\n1363             )\n1364 \n1365     def generate_added_constraints(self):\n1366         for (\n1367             app_label,\n1368             model_name,\n1369         ), alt_constraints in self.altered_constraints.items():\n1370             for constraint in alt_constraints[\"added_constraints\"]:\n1371                 self.add_operation(\n1372                     app_label,\n1373                     operations.AddConstraint(\n1374                         model_name=model_name,\n1375                         constraint=constraint,\n1376                     ),\n1377                 )\n1378 \n1379     def generate_removed_constraints(self):\n1380         for (\n1381             app_label,\n1382             model_name,\n1383         ), alt_constraints in self.altered_constraints.items():\n1384             for constraint in alt_constraints[\"removed_constraints\"]:\n1385                 self.add_operation(\n1386                     app_label,\n1387                     operations.RemoveConstraint(\n1388                         model_name=model_name,\n1389                         name=constraint.name,\n1390                     ),\n1391                 )\n1392 \n1393     @staticmethod\n1394     def _get_dependencies_for_foreign_key(app_label, model_name, field, project_state):\n1395         remote_field_model = None\n1396         if hasattr(field.remote_field, \"model\"):\n1397             remote_field_model = field.remote_field.model\n1398         else:\n1399             relations = project_state.relations[app_label, model_name]\n1400             for (remote_app_label, remote_model_name), fields in relations.items():\n1401                 if any(\n1402                     field == related_field.remote_field\n1403                     for related_field in fields.values()\n1404                 ):\n1405                     remote_field_model = f\"{remote_app_label}.{remote_model_name}\"\n1406                     break\n1407         # Account for FKs to swappable models\n1408         swappable_setting = getattr(field, \"swappable_setting\", None)\n1409         if swappable_setting is not None:\n1410             dep_app_label = \"__setting__\"\n1411             dep_object_name = swappable_setting\n1412         else:\n1413             dep_app_label, dep_object_name = resolve_relation(\n1414                 remote_field_model,\n1415                 app_label,\n1416                 model_name,\n1417             )\n1418         dependencies = [(dep_app_label, dep_object_name, None, True)]\n1419         if getattr(field.remote_field, \"through\", None):\n1420             through_app_label, through_object_name = resolve_relation(\n1421                 remote_field_model,\n1422                 app_label,\n1423                 model_name,\n1424             )\n1425             dependencies.append((through_app_label, through_object_name, None, True))\n1426         return dependencies\n1427 \n1428     def _get_altered_foo_together_operations(self, option_name):\n1429         for app_label, model_name in sorted(self.kept_model_keys):\n1430             old_model_name = self.renamed_models.get(\n1431                 (app_label, model_name), model_name\n1432             )\n1433             old_model_state = self.from_state.models[app_label, old_model_name]\n1434             new_model_state = self.to_state.models[app_label, model_name]\n1435 \n1436             # We run the old version through the field renames to account for those\n1437             old_value = old_model_state.options.get(option_name)\n1438             old_value = (\n1439                 {\n1440                     tuple(\n1441                         self.renamed_fields.get((app_label, model_name, n), n)\n1442                         for n in unique\n1443                     )\n1444                     for unique in old_value\n1445                 }\n1446                 if old_value\n1447                 else set()\n1448             )\n1449 \n1450             new_value = new_model_state.options.get(option_name)\n1451             new_value = set(new_value) if new_value else set()\n1452 \n1453             if old_value != new_value:\n1454                 dependencies = []\n1455                 for foo_togethers in new_value:\n1456                     for field_name in foo_togethers:\n1457                         field = new_model_state.get_field(field_name)\n1458                         if field.remote_field and field.remote_field.model:\n1459                             dependencies.extend(\n1460                                 self._get_dependencies_for_foreign_key(\n1461                                     app_label,\n1462                                     model_name,\n1463                                     field,\n1464                                     self.to_state,\n1465                                 )\n1466                             )\n1467                 yield (\n1468                     old_value,\n1469                     new_value,\n1470                     app_label,\n1471                     model_name,\n1472                     dependencies,\n1473                 )\n1474 \n1475     def _generate_removed_altered_foo_together(self, operation):\n1476         for (\n1477             old_value,\n1478             new_value,\n1479             app_label,\n1480             model_name,\n1481             dependencies,\n1482         ) in self._get_altered_foo_together_operations(operation.option_name):\n1483             if operation == operations.AlterIndexTogether:\n1484                 old_value = {\n1485                     value\n1486                     for value in old_value\n1487                     if value\n1488                     not in self.renamed_index_together_values[app_label, model_name]\n1489                 }\n1490             removal_value = new_value.intersection(old_value)\n1491             if removal_value or old_value:\n1492                 self.add_operation(\n1493                     app_label,\n1494                     operation(\n1495                         name=model_name, **{operation.option_name: removal_value}\n1496                     ),\n1497                     dependencies=dependencies,\n1498                 )\n1499 \n1500     def generate_removed_altered_unique_together(self):\n1501         self._generate_removed_altered_foo_together(operations.AlterUniqueTogether)\n1502 \n1503     def generate_removed_altered_index_together(self):\n1504         self._generate_removed_altered_foo_together(operations.AlterIndexTogether)\n1505 \n1506     def _generate_altered_foo_together(self, operation):\n1507         for (\n1508             old_value,\n1509             new_value,\n1510             app_label,\n1511             model_name,\n1512             dependencies,\n1513         ) in self._get_altered_foo_together_operations(operation.option_name):\n1514             removal_value = new_value.intersection(old_value)\n1515             if new_value != removal_value:\n1516                 self.add_operation(\n1517                     app_label,\n1518                     operation(name=model_name, **{operation.option_name: new_value}),\n1519                     dependencies=dependencies,\n1520                 )\n1521 \n1522     def generate_altered_unique_together(self):\n1523         self._generate_altered_foo_together(operations.AlterUniqueTogether)\n1524 \n1525     def generate_altered_index_together(self):\n1526         self._generate_altered_foo_together(operations.AlterIndexTogether)\n1527 \n1528     def generate_altered_db_table(self):\n1529         models_to_check = self.kept_model_keys.union(\n1530             self.kept_proxy_keys, self.kept_unmanaged_keys\n1531         )\n1532         for app_label, model_name in sorted(models_to_check):\n1533             old_model_name = self.renamed_models.get(\n1534                 (app_label, model_name), model_name\n1535             )\n1536             old_model_state = self.from_state.models[app_label, old_model_name]\n1537             new_model_state = self.to_state.models[app_label, model_name]\n1538             old_db_table_name = old_model_state.options.get(\"db_table\")\n1539             new_db_table_name = new_model_state.options.get(\"db_table\")\n1540             if old_db_table_name != new_db_table_name:\n1541                 self.add_operation(\n1542                     app_label,\n1543                     operations.AlterModelTable(\n1544                         name=model_name,\n1545                         table=new_db_table_name,\n1546                     ),\n1547                 )\n1548 \n1549     def generate_altered_options(self):\n1550         \"\"\"\n1551         Work out if any non-schema-affecting options have changed and make an\n1552         operation to represent them in state changes (in case Python code in\n1553         migrations needs them).\n1554         \"\"\"\n1555         models_to_check = self.kept_model_keys.union(\n1556             self.kept_proxy_keys,\n1557             self.kept_unmanaged_keys,\n1558             # unmanaged converted to managed\n1559             self.old_unmanaged_keys & self.new_model_keys,\n1560             # managed converted to unmanaged\n1561             self.old_model_keys & self.new_unmanaged_keys,\n1562         )\n1563 \n1564         for app_label, model_name in sorted(models_to_check):\n1565             old_model_name = self.renamed_models.get(\n1566                 (app_label, model_name), model_name\n1567             )\n1568             old_model_state = self.from_state.models[app_label, old_model_name]\n1569             new_model_state = self.to_state.models[app_label, model_name]\n1570             old_options = {\n1571                 key: value\n1572                 for key, value in old_model_state.options.items()\n1573                 if key in AlterModelOptions.ALTER_OPTION_KEYS\n1574             }\n1575             new_options = {\n1576                 key: value\n1577                 for key, value in new_model_state.options.items()\n1578                 if key in AlterModelOptions.ALTER_OPTION_KEYS\n1579             }\n1580             if old_options != new_options:\n1581                 self.add_operation(\n1582                     app_label,\n1583                     operations.AlterModelOptions(\n1584                         name=model_name,\n1585                         options=new_options,\n1586                     ),\n1587                 )\n1588 \n1589     def generate_altered_order_with_respect_to(self):\n1590         for app_label, model_name in sorted(self.kept_model_keys):\n1591             old_model_name = self.renamed_models.get(\n1592                 (app_label, model_name), model_name\n1593             )\n1594             old_model_state = self.from_state.models[app_label, old_model_name]\n1595             new_model_state = self.to_state.models[app_label, model_name]\n1596             if old_model_state.options.get(\n1597                 \"order_with_respect_to\"\n1598             ) != new_model_state.options.get(\"order_with_respect_to\"):\n1599                 # Make sure it comes second if we're adding\n1600                 # (removal dependency is part of RemoveField)\n1601                 dependencies = []\n1602                 if new_model_state.options.get(\"order_with_respect_to\"):\n1603                     dependencies.append(\n1604                         (\n1605                             app_label,\n1606                             model_name,\n1607                             new_model_state.options[\"order_with_respect_to\"],\n1608                             True,\n1609                         )\n1610                     )\n1611                 # Actually generate the operation\n1612                 self.add_operation(\n1613                     app_label,\n1614                     operations.AlterOrderWithRespectTo(\n1615                         name=model_name,\n1616                         order_with_respect_to=new_model_state.options.get(\n1617                             \"order_with_respect_to\"\n1618                         ),\n1619                     ),\n1620                     dependencies=dependencies,\n1621                 )\n1622 \n1623     def generate_altered_managers(self):\n1624         for app_label, model_name in sorted(self.kept_model_keys):\n1625             old_model_name = self.renamed_models.get(\n1626                 (app_label, model_name), model_name\n1627             )\n1628             old_model_state = self.from_state.models[app_label, old_model_name]\n1629             new_model_state = self.to_state.models[app_label, model_name]\n1630             if old_model_state.managers != new_model_state.managers:\n1631                 self.add_operation(\n1632                     app_label,\n1633                     operations.AlterModelManagers(\n1634                         name=model_name,\n1635                         managers=new_model_state.managers,\n1636                     ),\n1637                 )\n1638 \n1639     def arrange_for_graph(self, changes, graph, migration_name=None):\n1640         \"\"\"\n1641         Take a result from changes() and a MigrationGraph, and fix the names\n1642         and dependencies of the changes so they extend the graph from the leaf\n1643         nodes for each app.\n1644         \"\"\"\n1645         leaves = graph.leaf_nodes()\n1646         name_map = {}\n1647         for app_label, migrations in list(changes.items()):\n1648             if not migrations:\n1649                 continue\n1650             # Find the app label's current leaf node\n1651             app_leaf = None\n1652             for leaf in leaves:\n1653                 if leaf[0] == app_label:\n1654                     app_leaf = leaf\n1655                     break\n1656             # Do they want an initial migration for this app?\n1657             if app_leaf is None and not self.questioner.ask_initial(app_label):\n1658                 # They don't.\n1659                 for migration in migrations:\n1660                     name_map[(app_label, migration.name)] = (app_label, \"__first__\")\n1661                 del changes[app_label]\n1662                 continue\n1663             # Work out the next number in the sequence\n1664             if app_leaf is None:\n1665                 next_number = 1\n1666             else:\n1667                 next_number = (self.parse_number(app_leaf[1]) or 0) + 1\n1668             # Name each migration\n1669             for i, migration in enumerate(migrations):\n1670                 if i == 0 and app_leaf:\n1671                     migration.dependencies.append(app_leaf)\n1672                 new_name_parts = [\"%04i\" % next_number]\n1673                 if migration_name:\n1674                     new_name_parts.append(migration_name)\n1675                 elif i == 0 and not app_leaf:\n1676                     new_name_parts.append(\"initial\")\n1677                 else:\n1678                     new_name_parts.append(migration.suggest_name()[:100])\n1679                 new_name = \"_\".join(new_name_parts)\n1680                 name_map[(app_label, migration.name)] = (app_label, new_name)\n1681                 next_number += 1\n1682                 migration.name = new_name\n1683         # Now fix dependencies\n1684         for migrations in changes.values():\n1685             for migration in migrations:\n1686                 migration.dependencies = [\n1687                     name_map.get(d, d) for d in migration.dependencies\n1688                 ]\n1689         return changes\n1690 \n1691     def _trim_to_apps(self, changes, app_labels):\n1692         \"\"\"\n1693         Take changes from arrange_for_graph() and set of app labels, and return\n1694         a modified set of changes which trims out as many migrations that are\n1695         not in app_labels as possible. Note that some other migrations may\n1696         still be present as they may be required dependencies.\n1697         \"\"\"\n1698         # Gather other app dependencies in a first pass\n1699         app_dependencies = {}\n1700         for app_label, migrations in changes.items():\n1701             for migration in migrations:\n1702                 for dep_app_label, name in migration.dependencies:\n1703                     app_dependencies.setdefault(app_label, set()).add(dep_app_label)\n1704         required_apps = set(app_labels)\n1705         # Keep resolving till there's no change\n1706         old_required_apps = None\n1707         while old_required_apps != required_apps:\n1708             old_required_apps = set(required_apps)\n1709             required_apps.update(\n1710                 *[app_dependencies.get(app_label, ()) for app_label in required_apps]\n1711             )\n1712         # Remove all migrations that aren't needed\n1713         for app_label in list(changes):\n1714             if app_label not in required_apps:\n1715                 del changes[app_label]\n1716         return changes\n1717 \n1718     @classmethod\n1719     def parse_number(cls, name):\n1720         \"\"\"\n1721         Given a migration name, try to extract a number from the beginning of\n1722         it. For a squashed migration such as '0001_squashed_0004\u2026', return the\n1723         second number. If no number is found, return None.\n1724         \"\"\"\n1725         if squashed_match := re.search(r\".*_squashed_(\\d+)\", name):\n1726             return int(squashed_match[1])\n1727         match = re.match(r\"^\\d+\", name)\n1728         if match:\n1729             return int(match[0])\n1730         return None\n",
        "intended_behavior": "The automatic migration generation is a critical part of how Django handles changes in model definitions. This file's intended behavior should be updated to generate AddIndex or RemoveIndex operations instead of operations that rely on index_together. This would help in phasing out index_together usage in migrations and steering developers towards the indexes approach."
    }
]