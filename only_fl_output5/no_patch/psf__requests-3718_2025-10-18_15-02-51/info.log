2025-10-18 15:02:51.387 | INFO     | Starting overall retry 0 with model gpt-4-0125-preview
2025-10-18 15:02:53.976 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=886, output_tokens=12, cost=0.009220
2025-10-18 15:02:53.977 | INFO     | Test agent decides that the issue statement does not contain reproduction steps; skipping reproducer tracing
2025-10-18 15:02:53.982 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-18 15:03:00.724 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=1152, output_tokens=247, cost=0.018930
2025-10-18 15:03:00.731 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-18 15:03:05.635 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=601, output_tokens=113, cost=0.009400
2025-10-18 15:03:05.637 | DEBUG    | Extracted a valid json.
2025-10-18 15:03:05.637 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_method_in_class(\"run\", \"InvalidLinkBear\")",
        "search_method_in_class(\"find_links_in_file\", \"InvalidLinkBear\")",
        "search_method_in_class(\"get_status_code\", \"InvalidLinkBear\")",
        "search_code(\"requests.head\")",
        "search_code(\"requests.api.head\")",
        "search_code_in_file(\"self.raw.read(chunk_size)\", \"C:/Python34/lib/site-packages/requests/models.py\")"
    ],
    "bug_locations": []
}
2025-10-18 15:03:05.655 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-18 15:03:05.656 | DEBUG    | <Agent search> Analyzing search results.
2025-10-18 15:03:20.319 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=1685, output_tokens=646, cost=0.036230
2025-10-18 15:03:20.333 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-18 15:03:31.023 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=2547, output_tokens=470, cost=0.039570
2025-10-18 15:03:31.032 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-18 15:03:39.426 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=824, output_tokens=374, cost=0.019460
2025-10-18 15:03:39.427 | DEBUG    | Extracted a valid json.
2025-10-18 15:03:39.427 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_class_in_file('InvalidLinkBear', 'file that contains the `InvalidLinkBear` class')",
        "search_method_in_class('get_status_code', 'InvalidLinkBear')"
    ],
    "bug_locations": [
        {
            "file": "Likely in a file that contains the `InvalidLinkBear` class",
            "class": "InvalidLinkBear",
            "method": "get_status_code",
            "intended_behavior": "This method aims to send an HTTP request to a given URL and return the status code of the response. To resolve the issue, the method should ensure that the response object is not `None` before attempting to access the `read` attribute or any other attributes/methods on it. A possible solution is to add a check to confirm the response object is not `None` after the request is made and before accessing its properties. If a `None` response is encountered, it should gracefully handle the error or retry the request, depending on the specific requirements of the project."
        },
        {
            "file": "Any utility file handling HTTP requests made by bears",
            "class": "",
            "method": "",
            "intended_behavior": "Considering the issue might not solely reside in a specific method but could also be due to how HTTP response errors are globally handled (or not handled) within the project, an improvement could be implemented in the form of enhanced error handling for HTTP requests across the project. Specifically, there should be standardized error handling that checks the validity of the response object and handles cases where requests fail, return `None`, or are unable to read the expected data. This improvement would ensure that any network call made by the `coala` bears would be robust against network errors and inconsistencies in response data."
        }
    ]
}
2025-10-18 15:03:39.435 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-18 15:03:39.436 | DEBUG    | <Agent search> Analyzing search results.
2025-10-18 15:03:52.015 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=3200, output_tokens=603, cost=0.050090
2025-10-18 15:03:52.070 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-18 15:04:02.516 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=4019, output_tokens=477, cost=0.054500
2025-10-18 15:04:02.530 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-18 15:04:08.590 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=831, output_tokens=240, cost=0.015510
2025-10-18 15:04:08.591 | DEBUG    | Extracted a valid json.
2025-10-18 15:04:08.591 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [],
    "bug_locations": [
        {
            "file": "Likely within a utility file used by `InvalidLinkBear` for performing HTTP requests, or directly within the method where HTTP requests are made",
            "class": "InvalidLinkBear or a related utility class for HTTP requests",
            "method": "The method that performs HTTP `HEAD` requests, potentially named `get_status_code` or similar",
            "intended_behavior": "To prevent the `AttributeError: 'NoneType' object has no attribute 'read'` from occurring, the method that performs the HTTP requests should: Ensure that the HTTP request is executed within a try-except block to catch potential exceptions that may occur during the request, such as connection errors or timeouts. Validate the response object before attempting to access its attributes, including `read`. If the response is `None` or the request fails, appropriate error handling should be conducted, such as logging the error and possibly retrying the request or exiting gracefully. Update the documentation of the method to clearly state its behavior in scenarios where the request fails or when the response is `None`."
        }
    ]
}
2025-10-18 15:04:08.595 | DEBUG    | Failed to retrieve code from all bug locations. Asking search agent to re-generate response.
2025-10-18 15:04:08.596 | DEBUG    | <Agent search> Downstream could not consume our last response. Will retry.
2025-10-18 15:04:08.596 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-18 15:04:17.284 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=4530, output_tokens=310, cost=0.054600
2025-10-18 15:04:17.291 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-18 15:04:21.194 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=664, output_tokens=77, cost=0.008950
2025-10-18 15:04:21.195 | DEBUG    | Extracted a valid json.
2025-10-18 15:04:21.196 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [],
    "bug_locations": [
        {
            "file": "",
            "class": "InvalidLinkBear",
            "method": "",
            "intended_behavior": "HTTP response objects handling, especially when responses are None or when network requests fail, should include proper error handling and checking before accessing methods or properties like read."
        }
    ]
}
2025-10-18 15:04:21.198 | DEBUG    | Failed to retrieve code from all bug locations. Asking search agent to re-generate response.
2025-10-18 15:04:21.199 | DEBUG    | <Agent search> Downstream could not consume our last response. Will retry.
2025-10-18 15:04:21.199 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-18 15:04:33.714 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=4874, output_tokens=413, cost=0.061130
2025-10-18 15:04:33.721 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-18 15:04:35.848 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=767, output_tokens=14, cost=0.008090
2025-10-18 15:04:35.849 | DEBUG    | Both API_calls and bug_locations are empty. Will retry.
2025-10-18 15:04:35.849 | DEBUG    | Trying to convert API calls/bug locations into json. Try 2 of 5.
2025-10-18 15:04:37.797 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=767, output_tokens=14, cost=0.008090
2025-10-18 15:04:37.798 | DEBUG    | Both API_calls and bug_locations are empty. Will retry.
2025-10-18 15:04:37.798 | DEBUG    | Trying to convert API calls/bug locations into json. Try 3 of 5.
2025-10-18 15:04:39.805 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=767, output_tokens=14, cost=0.008090
2025-10-18 15:04:39.806 | DEBUG    | Both API_calls and bug_locations are empty. Will retry.
2025-10-18 15:04:39.806 | DEBUG    | Trying to convert API calls/bug locations into json. Try 4 of 5.
2025-10-18 15:04:40.802 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=767, output_tokens=14, cost=0.008090
2025-10-18 15:04:40.803 | DEBUG    | Both API_calls and bug_locations are empty. Will retry.
2025-10-18 15:04:40.803 | DEBUG    | Trying to convert API calls/bug locations into json. Try 5 of 5.
2025-10-18 15:04:42.919 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=767, output_tokens=14, cost=0.008090
2025-10-18 15:04:42.920 | DEBUG    | Both API_calls and bug_locations are empty. Will retry.
2025-10-18 15:04:42.920 | DEBUG    | Agent proxy return the following json: None
2025-10-18 15:04:42.920 | DEBUG    | Could not extract API calls from agent search response, asking search agent to re-generate response.
2025-10-18 15:04:42.921 | DEBUG    | <Agent search> Downstream could not consume our last response. Will retry.
2025-10-18 15:04:42.921 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-18 15:04:56.790 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=5314, output_tokens=609, cost=0.071410
2025-10-18 15:04:56.804 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-18 15:05:00.311 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=963, output_tokens=78, cost=0.011970
2025-10-18 15:05:00.313 | DEBUG    | Extracted a valid json.
2025-10-18 15:05:00.313 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_class(\"InvalidLinkBear\")",
        "search_code(\"requests\")",
        "search_method_in_class(\"get_status_code\", \"InvalidLinkBear\")",
        "search_code(\"AttributeError\")",
        "search_code(\"NoneType\")",
        "search_code(\"requests.head\")"
    ],
    "bug_locations": []
}
2025-10-18 15:05:00.375 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-18 15:05:00.376 | DEBUG    | <Agent search> Analyzing search results.
2025-10-18 15:05:15.003 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=6865, output_tokens=611, cost=0.086980
2025-10-18 15:05:15.014 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-18 15:05:28.819 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=7692, output_tokens=594, cost=0.094740
2025-10-18 15:05:28.830 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-18 15:05:32.151 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=948, output_tokens=120, cost=0.013080
2025-10-18 15:05:32.152 | DEBUG    | Extracted a valid json.
2025-10-18 15:05:32.153 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [],
    "bug_locations":[
        {
            "file": "requests/sessions.py",
            "class": "",
            "method": "",
            "intended_behavior": "Ensure that every HTTP response is checked for 'None' before attempting to access its content or any methods."
        },
        {
            "file": "requests/adapters.py",
            "class": "",
            "method": "",
            "intended_behavior": "Ensure that every HTTP response is checked for 'None' before attempting to access its content or any methods."
        }
    ]
}
2025-10-18 15:05:32.158 | DEBUG    | Bug location extracted successfully: [<file>requests/sessions.py</file>
<class>None</class>
<method>None</method>
<code>
1 # -*- coding: utf-8 -*-
2 
3 """
4 requests.session
5 ~~~~~~~~~~~~~~~~
6 
7 This module provides a Session object to manage and persist settings across
8 requests (cookies, auth, proxies).
9 """
10 import os
11 from collections import Mapping
12 from datetime import datetime
13 
14 from .auth import _basic_auth_str
15 from .compat import cookielib, OrderedDict, urljoin, urlparse
16 from .cookies import (
17     cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar, merge_cookies)
18 from .models import Request, PreparedRequest, DEFAULT_REDIRECT_LIMIT
19 from .hooks import default_hooks, dispatch_hook
20 from ._internal_utils import to_native_string
21 from .utils import to_key_val_list, default_headers
22 from .exceptions import (
23     TooManyRedirects, InvalidSchema, ChunkedEncodingError, ContentDecodingError)
24 from .packages.urllib3._collections import RecentlyUsedContainer
25 from .structures import CaseInsensitiveDict
26 
27 from .adapters import HTTPAdapter
28 
29 from .utils import (
30     requote_uri, get_environ_proxies, get_netrc_auth, should_bypass_proxies,
31     get_auth_from_url, rewind_body
32 )
33 
34 from .status_codes import codes
35 
36 # formerly defined here, reexposed here for backward compatibility
37 from .models import REDIRECT_STATI
38 
39 REDIRECT_CACHE_SIZE = 1000
40 
41 
42 def merge_setting(request_setting, session_setting, dict_class=OrderedDict):
43     """Determines appropriate setting for a given request, taking into account
44     the explicit setting on that request, and the setting in the session. If a
45     setting is a dictionary, they will be merged together using `dict_class`
46     """
47 
48     if session_setting is None:
49         return request_setting
50 
51     if request_setting is None:
52         return session_setting
53 
54     # Bypass if not a dictionary (e.g. verify)
55     if not (
56             isinstance(session_setting, Mapping) and
57             isinstance(request_setting, Mapping)
58     ):
59         return request_setting
60 
61     merged_setting = dict_class(to_key_val_list(session_setting))
62     merged_setting.update(to_key_val_list(request_setting))
63 
64     # Remove keys that are set to None. Extract keys first to avoid altering
65     # the dictionary during iteration.
66     none_keys = [k for (k, v) in merged_setting.items() if v is None]
67     for key in none_keys:
68         del merged_setting[key]
69 
70     return merged_setting
71 
72 
73 def merge_hooks(request_hooks, session_hooks, dict_class=OrderedDict):
74     """Properly merges both requests and session hooks.
75 
76     This is necessary because when request_hooks == {'response': []}, the
77     merge breaks Session hooks entirely.
78     """
79     if session_hooks is None or session_hooks.get('response') == []:
80         return request_hooks
81 
82     if request_hooks is None or request_hooks.get('response') == []:
83         return session_hooks
84 
85     return merge_setting(request_hooks, session_hooks, dict_class)
86 
87 
88 class SessionRedirectMixin(object):
89     def resolve_redirects(self, resp, req, stream=False, timeout=None,
90                           verify=True, cert=None, proxies=None, **adapter_kwargs):
91         """Receives a Response. Returns a generator of Responses."""
92 
93         i = 0
94         hist = [] # keep track of history
95 
96         while resp.is_redirect:
97             prepared_request = req.copy()
98 
99             if i > 0:
100                 # Update history and keep track of redirects.
101                 hist.append(resp)
102                 new_hist = list(hist)
103                 resp.history = new_hist
104 
105             try:
106                 resp.content  # Consume socket so it can be released
107             except (ChunkedEncodingError, ContentDecodingError, RuntimeError):
108                 resp.raw.read(decode_content=False)
109 
110             if i >= self.max_redirects:
111                 raise TooManyRedirects('Exceeded %s redirects.' % self.max_redirects, response=resp)
112 
113             # Release the connection back into the pool.
114             resp.close()
115 
116             url = resp.headers['location']
117 
118             # Handle redirection without scheme (see: RFC 1808 Section 4)
119             if url.startswith('//'):
120                 parsed_rurl = urlparse(resp.url)
121                 url = '%s:%s' % (parsed_rurl.scheme, url)
122 
123             # The scheme should be lower case...
124             parsed = urlparse(url)
125             url = parsed.geturl()
126 
127             # Facilitate relative 'location' headers, as allowed by RFC 7231.
128             # (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')
129             # Compliant with RFC3986, we percent encode the url.
130             if not parsed.netloc:
131                 url = urljoin(resp.url, requote_uri(url))
132             else:
133                 url = requote_uri(url)
134 
135             prepared_request.url = to_native_string(url)
136             # Cache the url, unless it redirects to itself.
137             if resp.is_permanent_redirect and req.url != prepared_request.url:
138                 self.redirect_cache[req.url] = prepared_request.url
139 
140             self.rebuild_method(prepared_request, resp)
141 
142             # https://github.com/kennethreitz/requests/issues/1084
143             if resp.status_code not in (codes.temporary_redirect, codes.permanent_redirect):
144                 # https://github.com/kennethreitz/requests/issues/3490
145                 purged_headers = ('Content-Length', 'Content-Type', 'Transfer-Encoding')
146                 for header in purged_headers:
147                     prepared_request.headers.pop(header, None)
148                 prepared_request.body = None
149 
150             headers = prepared_request.headers
151             try:
152                 del headers['Cookie']
153             except KeyError:
154                 pass
155 
156             # Extract any cookies sent on the response to the cookiejar
157             # in the new request. Because we've mutated our copied prepared
158             # request, use the old one that we haven't yet touched.
159             extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)
160             merge_cookies(prepared_request._cookies, self.cookies)
161             prepared_request.prepare_cookies(prepared_request._cookies)
162 
163             # Rebuild auth and proxy information.
164             proxies = self.rebuild_proxies(prepared_request, proxies)
165             self.rebuild_auth(prepared_request, resp)
166 
167             # A failed tell() sets `_body_position` to `object()`. This non-None
168             # value ensures `rewindable` will be True, allowing us to raise an
169             # UnrewindableBodyError, instead of hanging the connection.
170             rewindable = (
171                 prepared_request._body_position is not None and
172                 ('Content-Length' in headers or 'Transfer-Encoding' in headers)
173             )
174 
175             # Attempt to rewind consumed file-like object.
176             if rewindable:
177                 rewind_body(prepared_request)
178 
179             # Override the original request.
180             req = prepared_request
181 
182             resp = self.send(
183                 req,
184                 stream=stream,
185                 timeout=timeout,
186                 verify=verify,
187                 cert=cert,
188                 proxies=proxies,
189                 allow_redirects=False,
190                 **adapter_kwargs
191             )
192 
193             extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)
194 
195             i += 1
196             yield resp
197 
198     def rebuild_auth(self, prepared_request, response):
199         """When being redirected we may want to strip authentication from the
200         request to avoid leaking credentials. This method intelligently removes
201         and reapplies authentication where possible to avoid credential loss.
202         """
203         headers = prepared_request.headers
204         url = prepared_request.url
205 
206         if 'Authorization' in headers:
207             # If we get redirected to a new host, we should strip out any
208             # authentication headers.
209             original_parsed = urlparse(response.request.url)
210             redirect_parsed = urlparse(url)
211 
212             if (original_parsed.hostname != redirect_parsed.hostname):
213                 del headers['Authorization']
214 
215         # .netrc might have more auth for us on our new host.
216         new_auth = get_netrc_auth(url) if self.trust_env else None
217         if new_auth is not None:
218             prepared_request.prepare_auth(new_auth)
219 
220         return
221 
222     def rebuild_proxies(self, prepared_request, proxies):
223         """This method re-evaluates the proxy configuration by considering the
224         environment variables. If we are redirected to a URL covered by
225         NO_PROXY, we strip the proxy configuration. Otherwise, we set missing
226         proxy keys for this URL (in case they were stripped by a previous
227         redirect).
228 
229         This method also replaces the Proxy-Authorization header where
230         necessary.
231 
232         :rtype: dict
233         """
234         headers = prepared_request.headers
235         url = prepared_request.url
236         scheme = urlparse(url).scheme
237         new_proxies = proxies.copy() if proxies is not None else {}
238 
239         if self.trust_env and not should_bypass_proxies(url):
240             environ_proxies = get_environ_proxies(url)
241 
242             proxy = environ_proxies.get(scheme, environ_proxies.get('all'))
243 
244             if proxy:
245                 new_proxies.setdefault(scheme, proxy)
246 
247         if 'Proxy-Authorization' in headers:
248             del headers['Proxy-Authorization']
249 
250         try:
251             username, password = get_auth_from_url(new_proxies[scheme])
252         except KeyError:
253             username, password = None, None
254 
255         if username and password:
256             headers['Proxy-Authorization'] = _basic_auth_str(username, password)
257 
258         return new_proxies
259 
260     def rebuild_method(self, prepared_request, response):
261         """When being redirected we may want to change the method of the request
262         based on certain specs or browser behavior.
263         """
264         method = prepared_request.method
265 
266         # http://tools.ietf.org/html/rfc7231#section-6.4.4
267         if response.status_code == codes.see_other and method != 'HEAD':
268             method = 'GET'
269 
270         # Do what the browsers do, despite standards...
271         # First, turn 302s into GETs.
272         if response.status_code == codes.found and method != 'HEAD':
273             method = 'GET'
274 
275         # Second, if a POST is responded to with a 301, turn it into a GET.
276         # This bizarre behaviour is explained in Issue 1704.
277         if response.status_code == codes.moved and method == 'POST':
278             method = 'GET'
279 
280         prepared_request.method = method
281 
282 
283 class Session(SessionRedirectMixin):
284     """A Requests session.
285 
286     Provides cookie persistence, connection-pooling, and configuration.
287 
288     Basic Usage::
289 
290       >>> import requests
291       >>> s = requests.Session()
292       >>> s.get('http://httpbin.org/get')
293       <Response [200]>
294 
295     Or as a context manager::
296 
297       >>> with requests.Session() as s:
298       >>>     s.get('http://httpbin.org/get')
299       <Response [200]>
300     """
301 
302     __attrs__ = [
303         'headers', 'cookies', 'auth', 'proxies', 'hooks', 'params', 'verify',
304         'cert', 'prefetch', 'adapters', 'stream', 'trust_env',
305         'max_redirects',
306     ]
307 
308     def __init__(self):
309 
310         #: A case-insensitive dictionary of headers to be sent on each
311         #: :class:`Request <Request>` sent from this
312         #: :class:`Session <Session>`.
313         self.headers = default_headers()
314 
315         #: Default Authentication tuple or object to attach to
316         #: :class:`Request <Request>`.
317         self.auth = None
318 
319         #: Dictionary mapping protocol or protocol and host to the URL of the proxy
320         #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to
321         #: be used on each :class:`Request <Request>`.
322         self.proxies = {}
323 
324         #: Event-handling hooks.
325         self.hooks = default_hooks()
326 
327         #: Dictionary of querystring data to attach to each
328         #: :class:`Request <Request>`. The dictionary values may be lists for
329         #: representing multivalued query parameters.
330         self.params = {}
331 
332         #: Stream response content default.
333         self.stream = False
334 
335         #: SSL Verification default.
336         self.verify = True
337 
338         #: SSL client certificate default.
339         self.cert = None
340 
341         #: Maximum number of redirects allowed. If the request exceeds this
342         #: limit, a :class:`TooManyRedirects` exception is raised.
343         #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is
344         #: 30.
345         self.max_redirects = DEFAULT_REDIRECT_LIMIT
346 
347         #: Trust environment settings for proxy configuration, default
348         #: authentication and similar.
349         self.trust_env = True
350 
351         #: A CookieJar containing all currently outstanding cookies set on this
352         #: session. By default it is a
353         #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but
354         #: may be any other ``cookielib.CookieJar`` compatible object.
355         self.cookies = cookiejar_from_dict({})
356 
357         # Default connection adapters.
358         self.adapters = OrderedDict()
359         self.mount('https://', HTTPAdapter())
360         self.mount('http://', HTTPAdapter())
361 
362         # Only store 1000 redirects to prevent using infinite memory
363         self.redirect_cache = RecentlyUsedContainer(REDIRECT_CACHE_SIZE)
364 
365     def __enter__(self):
366         return self
367 
368     def __exit__(self, *args):
369         self.close()
370 
371     def prepare_request(self, request):
372         """Constructs a :class:`PreparedRequest <PreparedRequest>` for
373         transmission and returns it. The :class:`PreparedRequest` has settings
374         merged from the :class:`Request <Request>` instance and those of the
375         :class:`Session`.
376 
377         :param request: :class:`Request` instance to prepare with this
378             session's settings.
379         :rtype: requests.PreparedRequest
380         """
381         cookies = request.cookies or {}
382 
383         # Bootstrap CookieJar.
384         if not isinstance(cookies, cookielib.CookieJar):
385             cookies = cookiejar_from_dict(cookies)
386 
387         # Merge with session cookies
388         merged_cookies = merge_cookies(
389             merge_cookies(RequestsCookieJar(), self.cookies), cookies)
390 
391         # Set environment's basic authentication if not explicitly set.
392         auth = request.auth
393         if self.trust_env and not auth and not self.auth:
394             auth = get_netrc_auth(request.url)
395 
396         p = PreparedRequest()
397         p.prepare(
398             method=request.method.upper(),
399             url=request.url,
400             files=request.files,
401             data=request.data,
402             json=request.json,
403             headers=merge_setting(request.headers, self.headers, dict_class=CaseInsensitiveDict),
404             params=merge_setting(request.params, self.params),
405             auth=merge_setting(auth, self.auth),
406             cookies=merged_cookies,
407             hooks=merge_hooks(request.hooks, self.hooks),
408         )
409         return p
410 
411     def request(self, method, url,
412         params=None,
413         data=None,
414         headers=None,
415         cookies=None,
416         files=None,
417         auth=None,
418         timeout=None,
419         allow_redirects=True,
420         proxies=None,
421         hooks=None,
422         stream=None,
423         verify=None,
424         cert=None,
425         json=None):
426         """Constructs a :class:`Request <Request>`, prepares it and sends it.
427         Returns :class:`Response <Response>` object.
428 
429         :param method: method for the new :class:`Request` object.
430         :param url: URL for the new :class:`Request` object.
431         :param params: (optional) Dictionary or bytes to be sent in the query
432             string for the :class:`Request`.
433         :param data: (optional) Dictionary, bytes, or file-like object to send
434             in the body of the :class:`Request`.
435         :param json: (optional) json to send in the body of the
436             :class:`Request`.
437         :param headers: (optional) Dictionary of HTTP Headers to send with the
438             :class:`Request`.
439         :param cookies: (optional) Dict or CookieJar object to send with the
440             :class:`Request`.
441         :param files: (optional) Dictionary of ``'filename': file-like-objects``
442             for multipart encoding upload.
443         :param auth: (optional) Auth tuple or callable to enable
444             Basic/Digest/Custom HTTP Auth.
445         :param timeout: (optional) How long to wait for the server to send
446             data before giving up, as a float, or a :ref:`(connect timeout,
447             read timeout) <timeouts>` tuple.
448         :type timeout: float or tuple
449         :param allow_redirects: (optional) Set to True by default.
450         :type allow_redirects: bool
451         :param proxies: (optional) Dictionary mapping protocol or protocol and
452             hostname to the URL of the proxy.
453         :param stream: (optional) whether to immediately download the response
454             content. Defaults to ``False``.
455         :param verify: (optional) whether the SSL cert will be verified.
456             A CA_BUNDLE path can also be provided. Defaults to ``True``.
457         :param cert: (optional) if String, path to ssl client cert file (.pem).
458             If Tuple, ('cert', 'key') pair.
459         :rtype: requests.Response
460         """
461         # Create the Request.
462         req = Request(
463             method = method.upper(),
464             url = url,
465             headers = headers,
466             files = files,
467             data = data or {},
468             json = json,
469             params = params or {},
470             auth = auth,
471             cookies = cookies,
472             hooks = hooks,
473         )
474         prep = self.prepare_request(req)
475 
476         proxies = proxies or {}
477 
478         settings = self.merge_environment_settings(
479             prep.url, proxies, stream, verify, cert
480         )
481 
482         # Send the request.
483         send_kwargs = {
484             'timeout': timeout,
485             'allow_redirects': allow_redirects,
486         }
487         send_kwargs.update(settings)
488         resp = self.send(prep, **send_kwargs)
489 
490         return resp
491 
492     def get(self, url, **kwargs):
493         """Sends a GET request. Returns :class:`Response` object.
494 
495         :param url: URL for the new :class:`Request` object.
496         :param \*\*kwargs: Optional arguments that ``request`` takes.
497         :rtype: requests.Response
498         """
499 
500         kwargs.setdefault('allow_redirects', True)
501         return self.request('GET', url, **kwargs)
502 
503     def options(self, url, **kwargs):
504         """Sends a OPTIONS request. Returns :class:`Response` object.
505 
506         :param url: URL for the new :class:`Request` object.
507         :param \*\*kwargs: Optional arguments that ``request`` takes.
508         :rtype: requests.Response
509         """
510 
511         kwargs.setdefault('allow_redirects', True)
512         return self.request('OPTIONS', url, **kwargs)
513 
514     def head(self, url, **kwargs):
515         """Sends a HEAD request. Returns :class:`Response` object.
516 
517         :param url: URL for the new :class:`Request` object.
518         :param \*\*kwargs: Optional arguments that ``request`` takes.
519         :rtype: requests.Response
520         """
521 
522         kwargs.setdefault('allow_redirects', False)
523         return self.request('HEAD', url, **kwargs)
524 
525     def post(self, url, data=None, json=None, **kwargs):
526         """Sends a POST request. Returns :class:`Response` object.
527 
528         :param url: URL for the new :class:`Request` object.
529         :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
530         :param json: (optional) json to send in the body of the :class:`Request`.
531         :param \*\*kwargs: Optional arguments that ``request`` takes.
532         :rtype: requests.Response
533         """
534 
535         return self.request('POST', url, data=data, json=json, **kwargs)
536 
537     def put(self, url, data=None, **kwargs):
538         """Sends a PUT request. Returns :class:`Response` object.
539 
540         :param url: URL for the new :class:`Request` object.
541         :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
542         :param \*\*kwargs: Optional arguments that ``request`` takes.
543         :rtype: requests.Response
544         """
545 
546         return self.request('PUT', url, data=data, **kwargs)
547 
548     def patch(self, url, data=None, **kwargs):
549         """Sends a PATCH request. Returns :class:`Response` object.
550 
551         :param url: URL for the new :class:`Request` object.
552         :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
553         :param \*\*kwargs: Optional arguments that ``request`` takes.
554         :rtype: requests.Response
555         """
556 
557         return self.request('PATCH', url,  data=data, **kwargs)
558 
559     def delete(self, url, **kwargs):
560         """Sends a DELETE request. Returns :class:`Response` object.
561 
562         :param url: URL for the new :class:`Request` object.
563         :param \*\*kwargs: Optional arguments that ``request`` takes.
564         :rtype: requests.Response
565         """
566 
567         return self.request('DELETE', url, **kwargs)
568 
569     def send(self, request, **kwargs):
570         """
571         Send a given PreparedRequest.
572 
573         :rtype: requests.Response
574         """
575         # Set defaults that the hooks can utilize to ensure they always have
576         # the correct parameters to reproduce the previous request.
577         kwargs.setdefault('stream', self.stream)
578         kwargs.setdefault('verify', self.verify)
579         kwargs.setdefault('cert', self.cert)
580         kwargs.setdefault('proxies', self.proxies)
581 
582         # It's possible that users might accidentally send a Request object.
583         # Guard against that specific failure case.
584         if isinstance(request, Request):
585             raise ValueError('You can only send PreparedRequests.')
586 
587         # Set up variables needed for resolve_redirects and dispatching of hooks
588         allow_redirects = kwargs.pop('allow_redirects', True)
589         stream = kwargs.get('stream')
590         hooks = request.hooks
591 
592         # Resolve URL in redirect cache, if available.
593         if allow_redirects:
594             checked_urls = set()
595             while request.url in self.redirect_cache:
596                 checked_urls.add(request.url)
597                 new_url = self.redirect_cache.get(request.url)
598                 if new_url in checked_urls:
599                     break
600                 request.url = new_url
601 
602         # Get the appropriate adapter to use
603         adapter = self.get_adapter(url=request.url)
604 
605         # Start time (approximately) of the request
606         start = datetime.utcnow()
607 
608         # Send the request
609         r = adapter.send(request, **kwargs)
610 
611         # Total elapsed time of the request (approximately)
612         r.elapsed = datetime.utcnow() - start
613 
614         # Response manipulation hooks
615         r = dispatch_hook('response', hooks, r, **kwargs)
616 
617         # Persist cookies
618         if r.history:
619 
620             # If the hooks create history then we want those cookies too
621             for resp in r.history:
622                 extract_cookies_to_jar(self.cookies, resp.request, resp.raw)
623 
624         extract_cookies_to_jar(self.cookies, request, r.raw)
625 
626         # Redirect resolving generator.
627         gen = self.resolve_redirects(r, request, **kwargs)
628 
629         # Resolve redirects if allowed.
630         history = [resp for resp in gen] if allow_redirects else []
631 
632         # Shuffle things around if there's history.
633         if history:
634             # Insert the first (original) request at the start
635             history.insert(0, r)
636             # Get the last request made
637             r = history.pop()
638             r.history = history
639 
640         if not stream:
641             r.content
642 
643         return r
644 
645     def merge_environment_settings(self, url, proxies, stream, verify, cert):
646         """
647         Check the environment and merge it with some settings.
648 
649         :rtype: dict
650         """
651         # Gather clues from the surrounding environment.
652         if self.trust_env:
653             # Set environment's proxies.
654             env_proxies = get_environ_proxies(url) or {}
655             for (k, v) in env_proxies.items():
656                 proxies.setdefault(k, v)
657 
658             # Look for requests environment configuration and be compatible
659             # with cURL.
660             if verify is True or verify is None:
661                 verify = (os.environ.get('REQUESTS_CA_BUNDLE') or
662                           os.environ.get('CURL_CA_BUNDLE'))
663 
664         # Merge all the kwargs.
665         proxies = merge_setting(proxies, self.proxies)
666         stream = merge_setting(stream, self.stream)
667         verify = merge_setting(verify, self.verify)
668         cert = merge_setting(cert, self.cert)
669 
670         return {'verify': verify, 'proxies': proxies, 'stream': stream,
671                 'cert': cert}
672 
673     def get_adapter(self, url):
674         """
675         Returns the appropriate connection adapter for the given URL.
676 
677         :rtype: requests.adapters.BaseAdapter
678         """
679         for (prefix, adapter) in self.adapters.items():
680 
681             if url.lower().startswith(prefix):
682                 return adapter
683 
684         # Nothing matches :-/
685         raise InvalidSchema("No connection adapters were found for '%s'" % url)
686 
687     def close(self):
688         """Closes all adapters and as such the session"""
689         for v in self.adapters.values():
690             v.close()
691 
692     def mount(self, prefix, adapter):
693         """Registers a connection adapter to a prefix.
694 
695         Adapters are sorted in descending order by key length.
696         """
697         self.adapters[prefix] = adapter
698         keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]
699 
700         for key in keys_to_move:
701             self.adapters[key] = self.adapters.pop(key)
702 
703     def __getstate__(self):
704         state = dict((attr, getattr(self, attr, None)) for attr in self.__attrs__)
705         state['redirect_cache'] = dict(self.redirect_cache)
706         return state
707 
708     def __setstate__(self, state):
709         redirect_cache = state.pop('redirect_cache', {})
710         for attr, value in state.items():
711             setattr(self, attr, value)
712 
713         self.redirect_cache = RecentlyUsedContainer(REDIRECT_CACHE_SIZE)
714         for redirect, to in redirect_cache.items():
715             self.redirect_cache[redirect] = to
716 
717 
718 def session():
719     """
720     Returns a :class:`Session` for context-management.
721 
722     :rtype: Session
723     """
724 
725     return Session()

</code><intended_behavior>Ensure that every HTTP response is checked for 'None' before attempting to access its content or any methods.</intended_behavior>, <file>requests/adapters.py</file>
<class>None</class>
<method>None</method>
<code>
1 # -*- coding: utf-8 -*-
2 
3 """
4 requests.adapters
5 ~~~~~~~~~~~~~~~~~
6 
7 This module contains the transport adapters that Requests uses to define
8 and maintain connections.
9 """
10 
11 import os.path
12 import socket
13 
14 from .models import Response
15 from .packages.urllib3.poolmanager import PoolManager, proxy_from_url
16 from .packages.urllib3.response import HTTPResponse
17 from .packages.urllib3.util import Timeout as TimeoutSauce
18 from .packages.urllib3.util.retry import Retry
19 from .compat import urlparse, basestring
20 from .utils import (DEFAULT_CA_BUNDLE_PATH, get_encoding_from_headers,
21                     prepend_scheme_if_needed, get_auth_from_url, urldefragauth,
22                     select_proxy, to_native_string)
23 from .structures import CaseInsensitiveDict
24 from .packages.urllib3.exceptions import ClosedPoolError
25 from .packages.urllib3.exceptions import ConnectTimeoutError
26 from .packages.urllib3.exceptions import HTTPError as _HTTPError
27 from .packages.urllib3.exceptions import MaxRetryError
28 from .packages.urllib3.exceptions import NewConnectionError
29 from .packages.urllib3.exceptions import ProxyError as _ProxyError
30 from .packages.urllib3.exceptions import ProtocolError
31 from .packages.urllib3.exceptions import ReadTimeoutError
32 from .packages.urllib3.exceptions import SSLError as _SSLError
33 from .packages.urllib3.exceptions import ResponseError
34 from .cookies import extract_cookies_to_jar
35 from .exceptions import (ConnectionError, ConnectTimeout, ReadTimeout, SSLError,
36                          ProxyError, RetryError, InvalidSchema)
37 from .auth import _basic_auth_str
38 
39 try:
40     from .packages.urllib3.contrib.socks import SOCKSProxyManager
41 except ImportError:
42     def SOCKSProxyManager(*args, **kwargs):
43         raise InvalidSchema("Missing dependencies for SOCKS support.")
44 
45 DEFAULT_POOLBLOCK = False
46 DEFAULT_POOLSIZE = 10
47 DEFAULT_RETRIES = 0
48 DEFAULT_POOL_TIMEOUT = None
49 
50 
51 class BaseAdapter(object):
52     """The Base Transport Adapter"""
53 
54     def __init__(self):
55         super(BaseAdapter, self).__init__()
56 
57     def send(self, request, stream=False, timeout=None, verify=True,
58              cert=None, proxies=None):
59         """Sends PreparedRequest object. Returns Response object.
60 
61         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
62         :param stream: (optional) Whether to stream the request content.
63         :param timeout: (optional) How long to wait for the server to send
64             data before giving up, as a float, or a :ref:`(connect timeout,
65             read timeout) <timeouts>` tuple.
66         :type timeout: float or tuple
67         :param verify: (optional) Whether to verify SSL certificates.
68         :param cert: (optional) Any user-provided SSL certificate to be trusted.
69         :param proxies: (optional) The proxies dictionary to apply to the request.
70         """
71         raise NotImplementedError
72 
73     def close(self):
74         """Cleans up adapter specific items."""
75         raise NotImplementedError
76 
77 
78 class HTTPAdapter(BaseAdapter):
79     """The built-in HTTP Adapter for urllib3.
80 
81     Provides a general-case interface for Requests sessions to contact HTTP and
82     HTTPS urls by implementing the Transport Adapter interface. This class will
83     usually be created by the :class:`Session <Session>` class under the
84     covers.
85 
86     :param pool_connections: The number of urllib3 connection pools to cache.
87     :param pool_maxsize: The maximum number of connections to save in the pool.
88     :param max_retries: The maximum number of retries each connection
89         should attempt. Note, this applies only to failed DNS lookups, socket
90         connections and connection timeouts, never to requests where data has
91         made it to the server. By default, Requests does not retry failed
92         connections. If you need granular control over the conditions under
93         which we retry a request, import urllib3's ``Retry`` class and pass
94         that instead.
95     :param pool_block: Whether the connection pool should block for connections.
96 
97     Usage::
98 
99       >>> import requests
100       >>> s = requests.Session()
101       >>> a = requests.adapters.HTTPAdapter(max_retries=3)
102       >>> s.mount('http://', a)
103     """
104     __attrs__ = ['max_retries', 'config', '_pool_connections', '_pool_maxsize',
105                  '_pool_block']
106 
107     def __init__(self, pool_connections=DEFAULT_POOLSIZE,
108                  pool_maxsize=DEFAULT_POOLSIZE, max_retries=DEFAULT_RETRIES,
109                  pool_block=DEFAULT_POOLBLOCK):
110         if max_retries == DEFAULT_RETRIES:
111             self.max_retries = Retry(0, read=False)
112         else:
113             self.max_retries = Retry.from_int(max_retries)
114         self.config = {}
115         self.proxy_manager = {}
116 
117         super(HTTPAdapter, self).__init__()
118 
119         self._pool_connections = pool_connections
120         self._pool_maxsize = pool_maxsize
121         self._pool_block = pool_block
122 
123         self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)
124 
125     def __getstate__(self):
126         return dict((attr, getattr(self, attr, None)) for attr in
127                     self.__attrs__)
128 
129     def __setstate__(self, state):
130         # Can't handle by adding 'proxy_manager' to self.__attrs__ because
131         # self.poolmanager uses a lambda function, which isn't pickleable.
132         self.proxy_manager = {}
133         self.config = {}
134 
135         for attr, value in state.items():
136             setattr(self, attr, value)
137 
138         self.init_poolmanager(self._pool_connections, self._pool_maxsize,
139                               block=self._pool_block)
140 
141     def init_poolmanager(self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs):
142         """Initializes a urllib3 PoolManager.
143 
144         This method should not be called from user code, and is only
145         exposed for use when subclassing the
146         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
147 
148         :param connections: The number of urllib3 connection pools to cache.
149         :param maxsize: The maximum number of connections to save in the pool.
150         :param block: Block when no free connections are available.
151         :param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.
152         """
153         # save these values for pickling
154         self._pool_connections = connections
155         self._pool_maxsize = maxsize
156         self._pool_block = block
157 
158         self.poolmanager = PoolManager(num_pools=connections, maxsize=maxsize,
159                                        block=block, strict=True, **pool_kwargs)
160 
161     def proxy_manager_for(self, proxy, **proxy_kwargs):
162         """Return urllib3 ProxyManager for the given proxy.
163 
164         This method should not be called from user code, and is only
165         exposed for use when subclassing the
166         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
167 
168         :param proxy: The proxy to return a urllib3 ProxyManager for.
169         :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.
170         :returns: ProxyManager
171         :rtype: requests.packages.urllib3.ProxyManager
172         """
173         if proxy in self.proxy_manager:
174             manager = self.proxy_manager[proxy]
175         elif proxy.lower().startswith('socks'):
176             username, password = get_auth_from_url(proxy)
177             manager = self.proxy_manager[proxy] = SOCKSProxyManager(
178                 proxy,
179                 username=username,
180                 password=password,
181                 num_pools=self._pool_connections,
182                 maxsize=self._pool_maxsize,
183                 block=self._pool_block,
184                 **proxy_kwargs
185             )
186         else:
187             proxy_headers = self.proxy_headers(proxy)
188             manager = self.proxy_manager[proxy] = proxy_from_url(
189                 proxy,
190                 proxy_headers=proxy_headers,
191                 num_pools=self._pool_connections,
192                 maxsize=self._pool_maxsize,
193                 block=self._pool_block,
194                 **proxy_kwargs)
195 
196         return manager
197 
198     def cert_verify(self, conn, url, verify, cert):
199         """Verify a SSL certificate. This method should not be called from user
200         code, and is only exposed for use when subclassing the
201         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
202 
203         :param conn: The urllib3 connection object associated with the cert.
204         :param url: The requested URL.
205         :param verify: Whether we should actually verify the certificate.
206         :param cert: The SSL certificate to verify.
207         """
208         if url.lower().startswith('https') and verify:
209 
210             cert_loc = None
211 
212             # Allow self-specified cert location.
213             if verify is not True:
214                 cert_loc = verify
215 
216             if not cert_loc:
217                 cert_loc = DEFAULT_CA_BUNDLE_PATH
218 
219             if not cert_loc:
220                 raise Exception("Could not find a suitable SSL CA certificate bundle.")
221 
222             conn.cert_reqs = 'CERT_REQUIRED'
223 
224             if not os.path.isdir(cert_loc):
225                 conn.ca_certs = cert_loc
226             else:
227                 conn.ca_cert_dir = cert_loc
228         else:
229             conn.cert_reqs = 'CERT_NONE'
230             conn.ca_certs = None
231             conn.ca_cert_dir = None
232 
233         if cert:
234             if not isinstance(cert, basestring):
235                 conn.cert_file = cert[0]
236                 conn.key_file = cert[1]
237             else:
238                 conn.cert_file = cert
239 
240     def build_response(self, req, resp):
241         """Builds a :class:`Response <requests.Response>` object from a urllib3
242         response. This should not be called from user code, and is only exposed
243         for use when subclassing the
244         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`
245 
246         :param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.
247         :param resp: The urllib3 response object.
248         :rtype: requests.Response
249         """
250         response = Response()
251 
252         # Fallback to None if there's no status_code, for whatever reason.
253         response.status_code = getattr(resp, 'status', None)
254 
255         # Make headers case-insensitive.
256         response.headers = CaseInsensitiveDict(getattr(resp, 'headers', {}))
257 
258         # Set encoding.
259         response.encoding = get_encoding_from_headers(response.headers)
260         response.raw = resp
261         response.reason = response.raw.reason
262 
263         if isinstance(req.url, bytes):
264             response.url = req.url.decode('utf-8')
265         else:
266             response.url = req.url
267 
268         # Add new cookies from the server.
269         extract_cookies_to_jar(response.cookies, req, resp)
270 
271         # Give the Response some context.
272         response.request = req
273         response.connection = self
274 
275         return response
276 
277     def get_connection(self, url, proxies=None):
278         """Returns a urllib3 connection for the given URL. This should not be
279         called from user code, and is only exposed for use when subclassing the
280         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
281 
282         :param url: The URL to connect to.
283         :param proxies: (optional) A Requests-style dictionary of proxies used on this request.
284         :rtype: requests.packages.urllib3.ConnectionPool
285         """
286         proxy = select_proxy(url, proxies)
287 
288         if proxy:
289             proxy = prepend_scheme_if_needed(proxy, 'http')
290             proxy_manager = self.proxy_manager_for(proxy)
291             conn = proxy_manager.connection_from_url(url)
292         else:
293             # Only scheme should be lower case
294             parsed = urlparse(url)
295             url = parsed.geturl()
296             conn = self.poolmanager.connection_from_url(url)
297 
298         return conn
299 
300     def close(self):
301         """Disposes of any internal state.
302 
303         Currently, this closes the PoolManager and any active ProxyManager,
304         which closes any pooled connections.
305         """
306         self.poolmanager.clear()
307         for proxy in self.proxy_manager.values():
308             proxy.clear()
309 
310     def request_url(self, request, proxies):
311         """Obtain the url to use when making the final request.
312 
313         If the message is being sent through a HTTP proxy, the full URL has to
314         be used. Otherwise, we should only use the path portion of the URL.
315 
316         This should not be called from user code, and is only exposed for use
317         when subclassing the
318         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
319 
320         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
321         :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.
322         :rtype: str
323         """
324         proxy = select_proxy(request.url, proxies)
325         scheme = urlparse(request.url).scheme
326 
327         is_proxied_http_request = (proxy and scheme != 'https')
328         using_socks_proxy = False
329         if proxy:
330             proxy_scheme = urlparse(proxy).scheme.lower()
331             using_socks_proxy = proxy_scheme.startswith('socks')
332 
333         url = request.path_url
334         if is_proxied_http_request and not using_socks_proxy:
335             url = urldefragauth(request.url)
336 
337         return url
338 
339     def add_headers(self, request, **kwargs):
340         """Add any headers needed by the connection. As of v2.0 this does
341         nothing by default, but is left for overriding by users that subclass
342         the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
343 
344         This should not be called from user code, and is only exposed for use
345         when subclassing the
346         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
347 
348         :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.
349         :param kwargs: The keyword arguments from the call to send().
350         """
351         pass
352 
353     def proxy_headers(self, proxy):
354         """Returns a dictionary of the headers to add to any request sent
355         through a proxy. This works with urllib3 magic to ensure that they are
356         correctly sent to the proxy, rather than in a tunnelled request if
357         CONNECT is being used.
358 
359         This should not be called from user code, and is only exposed for use
360         when subclassing the
361         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
362 
363         :param proxies: The url of the proxy being used for this request.
364         :rtype: dict
365         """
366         headers = {}
367         username, password = get_auth_from_url(proxy)
368 
369         if username:
370             headers['Proxy-Authorization'] = _basic_auth_str(username,
371                                                              password)
372 
373         return headers
374 
375     def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
376         """Sends PreparedRequest object. Returns Response object.
377 
378         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
379         :param stream: (optional) Whether to stream the request content.
380         :param timeout: (optional) How long to wait for the server to send
381             data before giving up, as a float, or a :ref:`(connect timeout,
382             read timeout) <timeouts>` tuple.
383         :type timeout: float or tuple
384         :param verify: (optional) Whether to verify SSL certificates.
385         :param cert: (optional) Any user-provided SSL certificate to be trusted.
386         :param proxies: (optional) The proxies dictionary to apply to the request.
387         :rtype: requests.Response
388         """
389 
390         conn = self.get_connection(request.url, proxies)
391 
392         self.cert_verify(conn, request.url, verify, cert)
393         url = self.request_url(request, proxies)
394         self.add_headers(request)
395 
396         chunked = not (request.body is None or 'Content-Length' in request.headers)
397 
398         if isinstance(timeout, tuple):
399             try:
400                 connect, read = timeout
401                 timeout = TimeoutSauce(connect=connect, read=read)
402             except ValueError as e:
403                 # this may raise a string formatting error.
404                 err = ("Invalid timeout {0}. Pass a (connect, read) "
405                        "timeout tuple, or a single float to set "
406                        "both timeouts to the same value".format(timeout))
407                 raise ValueError(err)
408         else:
409             timeout = TimeoutSauce(connect=timeout, read=timeout)
410 
411         try:
412             if not chunked:
413                 resp = conn.urlopen(
414                     method=request.method,
415                     url=url,
416                     body=request.body,
417                     headers=request.headers,
418                     redirect=False,
419                     assert_same_host=False,
420                     preload_content=False,
421                     decode_content=False,
422                     retries=self.max_retries,
423                     timeout=timeout
424                 )
425 
426             # Send the request.
427             else:
428                 if hasattr(conn, 'proxy_pool'):
429                     conn = conn.proxy_pool
430 
431                 low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)
432 
433                 try:
434                     low_conn.putrequest(request.method,
435                                         url,
436                                         skip_accept_encoding=True)
437 
438                     for header, value in request.headers.items():
439                         low_conn.putheader(header, value)
440 
441                     low_conn.endheaders()
442 
443                     for i in request.body:
444                         low_conn.send(hex(len(i))[2:].encode('utf-8'))
445                         low_conn.send(b'\r\n')
446                         low_conn.send(i)
447                         low_conn.send(b'\r\n')
448                     low_conn.send(b'0\r\n\r\n')
449 
450                     # Receive the response from the server
451                     try:
452                         # For Python 2.7+ versions, use buffering of HTTP
453                         # responses
454                         r = low_conn.getresponse(buffering=True)
455                     except TypeError:
456                         # For compatibility with Python 2.6 versions and back
457                         r = low_conn.getresponse()
458 
459                     resp = HTTPResponse.from_httplib(
460                         r,
461                         pool=conn,
462                         connection=low_conn,
463                         preload_content=False,
464                         decode_content=False
465                     )
466                 except:
467                     # If we hit any problems here, clean up the connection.
468                     # Then, reraise so that we can handle the actual exception.
469                     low_conn.close()
470                     raise
471 
472         except (ProtocolError, socket.error) as err:
473             raise ConnectionError(err, request=request)
474 
475         except MaxRetryError as e:
476             if isinstance(e.reason, ConnectTimeoutError):
477                 # TODO: Remove this in 3.0.0: see #2811
478                 if not isinstance(e.reason, NewConnectionError):
479                     raise ConnectTimeout(e, request=request)
480 
481             if isinstance(e.reason, ResponseError):
482                 raise RetryError(e, request=request)
483 
484             if isinstance(e.reason, _ProxyError):
485                 raise ProxyError(e, request=request)
486 
487             raise ConnectionError(e, request=request)
488 
489         except ClosedPoolError as e:
490             raise ConnectionError(e, request=request)
491 
492         except _ProxyError as e:
493             raise ProxyError(e)
494 
495         except (_SSLError, _HTTPError) as e:
496             if isinstance(e, _SSLError):
497                 raise SSLError(e, request=request)
498             elif isinstance(e, ReadTimeoutError):
499                 raise ReadTimeout(e, request=request)
500             else:
501                 raise
502 
503         return self.build_response(request, resp)

</code><intended_behavior>Ensure that every HTTP response is checked for 'None' before attempting to access its content or any methods.</intended_behavior>]
2025-10-18 15:05:32.158 | INFO     | Search completed. Bug locations: [<file>requests/sessions.py</file>
<class>None</class>
<method>None</method>
<code>
1 # -*- coding: utf-8 -*-
2 
3 """
4 requests.session
5 ~~~~~~~~~~~~~~~~
6 
7 This module provides a Session object to manage and persist settings across
8 requests (cookies, auth, proxies).
9 """
10 import os
11 from collections import Mapping
12 from datetime import datetime
13 
14 from .auth import _basic_auth_str
15 from .compat import cookielib, OrderedDict, urljoin, urlparse
16 from .cookies import (
17     cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar, merge_cookies)
18 from .models import Request, PreparedRequest, DEFAULT_REDIRECT_LIMIT
19 from .hooks import default_hooks, dispatch_hook
20 from ._internal_utils import to_native_string
21 from .utils import to_key_val_list, default_headers
22 from .exceptions import (
23     TooManyRedirects, InvalidSchema, ChunkedEncodingError, ContentDecodingError)
24 from .packages.urllib3._collections import RecentlyUsedContainer
25 from .structures import CaseInsensitiveDict
26 
27 from .adapters import HTTPAdapter
28 
29 from .utils import (
30     requote_uri, get_environ_proxies, get_netrc_auth, should_bypass_proxies,
31     get_auth_from_url, rewind_body
32 )
33 
34 from .status_codes import codes
35 
36 # formerly defined here, reexposed here for backward compatibility
37 from .models import REDIRECT_STATI
38 
39 REDIRECT_CACHE_SIZE = 1000
40 
41 
42 def merge_setting(request_setting, session_setting, dict_class=OrderedDict):
43     """Determines appropriate setting for a given request, taking into account
44     the explicit setting on that request, and the setting in the session. If a
45     setting is a dictionary, they will be merged together using `dict_class`
46     """
47 
48     if session_setting is None:
49         return request_setting
50 
51     if request_setting is None:
52         return session_setting
53 
54     # Bypass if not a dictionary (e.g. verify)
55     if not (
56             isinstance(session_setting, Mapping) and
57             isinstance(request_setting, Mapping)
58     ):
59         return request_setting
60 
61     merged_setting = dict_class(to_key_val_list(session_setting))
62     merged_setting.update(to_key_val_list(request_setting))
63 
64     # Remove keys that are set to None. Extract keys first to avoid altering
65     # the dictionary during iteration.
66     none_keys = [k for (k, v) in merged_setting.items() if v is None]
67     for key in none_keys:
68         del merged_setting[key]
69 
70     return merged_setting
71 
72 
73 def merge_hooks(request_hooks, session_hooks, dict_class=OrderedDict):
74     """Properly merges both requests and session hooks.
75 
76     This is necessary because when request_hooks == {'response': []}, the
77     merge breaks Session hooks entirely.
78     """
79     if session_hooks is None or session_hooks.get('response') == []:
80         return request_hooks
81 
82     if request_hooks is None or request_hooks.get('response') == []:
83         return session_hooks
84 
85     return merge_setting(request_hooks, session_hooks, dict_class)
86 
87 
88 class SessionRedirectMixin(object):
89     def resolve_redirects(self, resp, req, stream=False, timeout=None,
90                           verify=True, cert=None, proxies=None, **adapter_kwargs):
91         """Receives a Response. Returns a generator of Responses."""
92 
93         i = 0
94         hist = [] # keep track of history
95 
96         while resp.is_redirect:
97             prepared_request = req.copy()
98 
99             if i > 0:
100                 # Update history and keep track of redirects.
101                 hist.append(resp)
102                 new_hist = list(hist)
103                 resp.history = new_hist
104 
105             try:
106                 resp.content  # Consume socket so it can be released
107             except (ChunkedEncodingError, ContentDecodingError, RuntimeError):
108                 resp.raw.read(decode_content=False)
109 
110             if i >= self.max_redirects:
111                 raise TooManyRedirects('Exceeded %s redirects.' % self.max_redirects, response=resp)
112 
113             # Release the connection back into the pool.
114             resp.close()
115 
116             url = resp.headers['location']
117 
118             # Handle redirection without scheme (see: RFC 1808 Section 4)
119             if url.startswith('//'):
120                 parsed_rurl = urlparse(resp.url)
121                 url = '%s:%s' % (parsed_rurl.scheme, url)
122 
123             # The scheme should be lower case...
124             parsed = urlparse(url)
125             url = parsed.geturl()
126 
127             # Facilitate relative 'location' headers, as allowed by RFC 7231.
128             # (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')
129             # Compliant with RFC3986, we percent encode the url.
130             if not parsed.netloc:
131                 url = urljoin(resp.url, requote_uri(url))
132             else:
133                 url = requote_uri(url)
134 
135             prepared_request.url = to_native_string(url)
136             # Cache the url, unless it redirects to itself.
137             if resp.is_permanent_redirect and req.url != prepared_request.url:
138                 self.redirect_cache[req.url] = prepared_request.url
139 
140             self.rebuild_method(prepared_request, resp)
141 
142             # https://github.com/kennethreitz/requests/issues/1084
143             if resp.status_code not in (codes.temporary_redirect, codes.permanent_redirect):
144                 # https://github.com/kennethreitz/requests/issues/3490
145                 purged_headers = ('Content-Length', 'Content-Type', 'Transfer-Encoding')
146                 for header in purged_headers:
147                     prepared_request.headers.pop(header, None)
148                 prepared_request.body = None
149 
150             headers = prepared_request.headers
151             try:
152                 del headers['Cookie']
153             except KeyError:
154                 pass
155 
156             # Extract any cookies sent on the response to the cookiejar
157             # in the new request. Because we've mutated our copied prepared
158             # request, use the old one that we haven't yet touched.
159             extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)
160             merge_cookies(prepared_request._cookies, self.cookies)
161             prepared_request.prepare_cookies(prepared_request._cookies)
162 
163             # Rebuild auth and proxy information.
164             proxies = self.rebuild_proxies(prepared_request, proxies)
165             self.rebuild_auth(prepared_request, resp)
166 
167             # A failed tell() sets `_body_position` to `object()`. This non-None
168             # value ensures `rewindable` will be True, allowing us to raise an
169             # UnrewindableBodyError, instead of hanging the connection.
170             rewindable = (
171                 prepared_request._body_position is not None and
172                 ('Content-Length' in headers or 'Transfer-Encoding' in headers)
173             )
174 
175             # Attempt to rewind consumed file-like object.
176             if rewindable:
177                 rewind_body(prepared_request)
178 
179             # Override the original request.
180             req = prepared_request
181 
182             resp = self.send(
183                 req,
184                 stream=stream,
185                 timeout=timeout,
186                 verify=verify,
187                 cert=cert,
188                 proxies=proxies,
189                 allow_redirects=False,
190                 **adapter_kwargs
191             )
192 
193             extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)
194 
195             i += 1
196             yield resp
197 
198     def rebuild_auth(self, prepared_request, response):
199         """When being redirected we may want to strip authentication from the
200         request to avoid leaking credentials. This method intelligently removes
201         and reapplies authentication where possible to avoid credential loss.
202         """
203         headers = prepared_request.headers
204         url = prepared_request.url
205 
206         if 'Authorization' in headers:
207             # If we get redirected to a new host, we should strip out any
208             # authentication headers.
209             original_parsed = urlparse(response.request.url)
210             redirect_parsed = urlparse(url)
211 
212             if (original_parsed.hostname != redirect_parsed.hostname):
213                 del headers['Authorization']
214 
215         # .netrc might have more auth for us on our new host.
216         new_auth = get_netrc_auth(url) if self.trust_env else None
217         if new_auth is not None:
218             prepared_request.prepare_auth(new_auth)
219 
220         return
221 
222     def rebuild_proxies(self, prepared_request, proxies):
223         """This method re-evaluates the proxy configuration by considering the
224         environment variables. If we are redirected to a URL covered by
225         NO_PROXY, we strip the proxy configuration. Otherwise, we set missing
226         proxy keys for this URL (in case they were stripped by a previous
227         redirect).
228 
229         This method also replaces the Proxy-Authorization header where
230         necessary.
231 
232         :rtype: dict
233         """
234         headers = prepared_request.headers
235         url = prepared_request.url
236         scheme = urlparse(url).scheme
237         new_proxies = proxies.copy() if proxies is not None else {}
238 
239         if self.trust_env and not should_bypass_proxies(url):
240             environ_proxies = get_environ_proxies(url)
241 
242             proxy = environ_proxies.get(scheme, environ_proxies.get('all'))
243 
244             if proxy:
245                 new_proxies.setdefault(scheme, proxy)
246 
247         if 'Proxy-Authorization' in headers:
248             del headers['Proxy-Authorization']
249 
250         try:
251             username, password = get_auth_from_url(new_proxies[scheme])
252         except KeyError:
253             username, password = None, None
254 
255         if username and password:
256             headers['Proxy-Authorization'] = _basic_auth_str(username, password)
257 
258         return new_proxies
259 
260     def rebuild_method(self, prepared_request, response):
261         """When being redirected we may want to change the method of the request
262         based on certain specs or browser behavior.
263         """
264         method = prepared_request.method
265 
266         # http://tools.ietf.org/html/rfc7231#section-6.4.4
267         if response.status_code == codes.see_other and method != 'HEAD':
268             method = 'GET'
269 
270         # Do what the browsers do, despite standards...
271         # First, turn 302s into GETs.
272         if response.status_code == codes.found and method != 'HEAD':
273             method = 'GET'
274 
275         # Second, if a POST is responded to with a 301, turn it into a GET.
276         # This bizarre behaviour is explained in Issue 1704.
277         if response.status_code == codes.moved and method == 'POST':
278             method = 'GET'
279 
280         prepared_request.method = method
281 
282 
283 class Session(SessionRedirectMixin):
284     """A Requests session.
285 
286     Provides cookie persistence, connection-pooling, and configuration.
287 
288     Basic Usage::
289 
290       >>> import requests
291       >>> s = requests.Session()
292       >>> s.get('http://httpbin.org/get')
293       <Response [200]>
294 
295     Or as a context manager::
296 
297       >>> with requests.Session() as s:
298       >>>     s.get('http://httpbin.org/get')
299       <Response [200]>
300     """
301 
302     __attrs__ = [
303         'headers', 'cookies', 'auth', 'proxies', 'hooks', 'params', 'verify',
304         'cert', 'prefetch', 'adapters', 'stream', 'trust_env',
305         'max_redirects',
306     ]
307 
308     def __init__(self):
309 
310         #: A case-insensitive dictionary of headers to be sent on each
311         #: :class:`Request <Request>` sent from this
312         #: :class:`Session <Session>`.
313         self.headers = default_headers()
314 
315         #: Default Authentication tuple or object to attach to
316         #: :class:`Request <Request>`.
317         self.auth = None
318 
319         #: Dictionary mapping protocol or protocol and host to the URL of the proxy
320         #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to
321         #: be used on each :class:`Request <Request>`.
322         self.proxies = {}
323 
324         #: Event-handling hooks.
325         self.hooks = default_hooks()
326 
327         #: Dictionary of querystring data to attach to each
328         #: :class:`Request <Request>`. The dictionary values may be lists for
329         #: representing multivalued query parameters.
330         self.params = {}
331 
332         #: Stream response content default.
333         self.stream = False
334 
335         #: SSL Verification default.
336         self.verify = True
337 
338         #: SSL client certificate default.
339         self.cert = None
340 
341         #: Maximum number of redirects allowed. If the request exceeds this
342         #: limit, a :class:`TooManyRedirects` exception is raised.
343         #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is
344         #: 30.
345         self.max_redirects = DEFAULT_REDIRECT_LIMIT
346 
347         #: Trust environment settings for proxy configuration, default
348         #: authentication and similar.
349         self.trust_env = True
350 
351         #: A CookieJar containing all currently outstanding cookies set on this
352         #: session. By default it is a
353         #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but
354         #: may be any other ``cookielib.CookieJar`` compatible object.
355         self.cookies = cookiejar_from_dict({})
356 
357         # Default connection adapters.
358         self.adapters = OrderedDict()
359         self.mount('https://', HTTPAdapter())
360         self.mount('http://', HTTPAdapter())
361 
362         # Only store 1000 redirects to prevent using infinite memory
363         self.redirect_cache = RecentlyUsedContainer(REDIRECT_CACHE_SIZE)
364 
365     def __enter__(self):
366         return self
367 
368     def __exit__(self, *args):
369         self.close()
370 
371     def prepare_request(self, request):
372         """Constructs a :class:`PreparedRequest <PreparedRequest>` for
373         transmission and returns it. The :class:`PreparedRequest` has settings
374         merged from the :class:`Request <Request>` instance and those of the
375         :class:`Session`.
376 
377         :param request: :class:`Request` instance to prepare with this
378             session's settings.
379         :rtype: requests.PreparedRequest
380         """
381         cookies = request.cookies or {}
382 
383         # Bootstrap CookieJar.
384         if not isinstance(cookies, cookielib.CookieJar):
385             cookies = cookiejar_from_dict(cookies)
386 
387         # Merge with session cookies
388         merged_cookies = merge_cookies(
389             merge_cookies(RequestsCookieJar(), self.cookies), cookies)
390 
391         # Set environment's basic authentication if not explicitly set.
392         auth = request.auth
393         if self.trust_env and not auth and not self.auth:
394             auth = get_netrc_auth(request.url)
395 
396         p = PreparedRequest()
397         p.prepare(
398             method=request.method.upper(),
399             url=request.url,
400             files=request.files,
401             data=request.data,
402             json=request.json,
403             headers=merge_setting(request.headers, self.headers, dict_class=CaseInsensitiveDict),
404             params=merge_setting(request.params, self.params),
405             auth=merge_setting(auth, self.auth),
406             cookies=merged_cookies,
407             hooks=merge_hooks(request.hooks, self.hooks),
408         )
409         return p
410 
411     def request(self, method, url,
412         params=None,
413         data=None,
414         headers=None,
415         cookies=None,
416         files=None,
417         auth=None,
418         timeout=None,
419         allow_redirects=True,
420         proxies=None,
421         hooks=None,
422         stream=None,
423         verify=None,
424         cert=None,
425         json=None):
426         """Constructs a :class:`Request <Request>`, prepares it and sends it.
427         Returns :class:`Response <Response>` object.
428 
429         :param method: method for the new :class:`Request` object.
430         :param url: URL for the new :class:`Request` object.
431         :param params: (optional) Dictionary or bytes to be sent in the query
432             string for the :class:`Request`.
433         :param data: (optional) Dictionary, bytes, or file-like object to send
434             in the body of the :class:`Request`.
435         :param json: (optional) json to send in the body of the
436             :class:`Request`.
437         :param headers: (optional) Dictionary of HTTP Headers to send with the
438             :class:`Request`.
439         :param cookies: (optional) Dict or CookieJar object to send with the
440             :class:`Request`.
441         :param files: (optional) Dictionary of ``'filename': file-like-objects``
442             for multipart encoding upload.
443         :param auth: (optional) Auth tuple or callable to enable
444             Basic/Digest/Custom HTTP Auth.
445         :param timeout: (optional) How long to wait for the server to send
446             data before giving up, as a float, or a :ref:`(connect timeout,
447             read timeout) <timeouts>` tuple.
448         :type timeout: float or tuple
449         :param allow_redirects: (optional) Set to True by default.
450         :type allow_redirects: bool
451         :param proxies: (optional) Dictionary mapping protocol or protocol and
452             hostname to the URL of the proxy.
453         :param stream: (optional) whether to immediately download the response
454             content. Defaults to ``False``.
455         :param verify: (optional) whether the SSL cert will be verified.
456             A CA_BUNDLE path can also be provided. Defaults to ``True``.
457         :param cert: (optional) if String, path to ssl client cert file (.pem).
458             If Tuple, ('cert', 'key') pair.
459         :rtype: requests.Response
460         """
461         # Create the Request.
462         req = Request(
463             method = method.upper(),
464             url = url,
465             headers = headers,
466             files = files,
467             data = data or {},
468             json = json,
469             params = params or {},
470             auth = auth,
471             cookies = cookies,
472             hooks = hooks,
473         )
474         prep = self.prepare_request(req)
475 
476         proxies = proxies or {}
477 
478         settings = self.merge_environment_settings(
479             prep.url, proxies, stream, verify, cert
480         )
481 
482         # Send the request.
483         send_kwargs = {
484             'timeout': timeout,
485             'allow_redirects': allow_redirects,
486         }
487         send_kwargs.update(settings)
488         resp = self.send(prep, **send_kwargs)
489 
490         return resp
491 
492     def get(self, url, **kwargs):
493         """Sends a GET request. Returns :class:`Response` object.
494 
495         :param url: URL for the new :class:`Request` object.
496         :param \*\*kwargs: Optional arguments that ``request`` takes.
497         :rtype: requests.Response
498         """
499 
500         kwargs.setdefault('allow_redirects', True)
501         return self.request('GET', url, **kwargs)
502 
503     def options(self, url, **kwargs):
504         """Sends a OPTIONS request. Returns :class:`Response` object.
505 
506         :param url: URL for the new :class:`Request` object.
507         :param \*\*kwargs: Optional arguments that ``request`` takes.
508         :rtype: requests.Response
509         """
510 
511         kwargs.setdefault('allow_redirects', True)
512         return self.request('OPTIONS', url, **kwargs)
513 
514     def head(self, url, **kwargs):
515         """Sends a HEAD request. Returns :class:`Response` object.
516 
517         :param url: URL for the new :class:`Request` object.
518         :param \*\*kwargs: Optional arguments that ``request`` takes.
519         :rtype: requests.Response
520         """
521 
522         kwargs.setdefault('allow_redirects', False)
523         return self.request('HEAD', url, **kwargs)
524 
525     def post(self, url, data=None, json=None, **kwargs):
526         """Sends a POST request. Returns :class:`Response` object.
527 
528         :param url: URL for the new :class:`Request` object.
529         :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
530         :param json: (optional) json to send in the body of the :class:`Request`.
531         :param \*\*kwargs: Optional arguments that ``request`` takes.
532         :rtype: requests.Response
533         """
534 
535         return self.request('POST', url, data=data, json=json, **kwargs)
536 
537     def put(self, url, data=None, **kwargs):
538         """Sends a PUT request. Returns :class:`Response` object.
539 
540         :param url: URL for the new :class:`Request` object.
541         :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
542         :param \*\*kwargs: Optional arguments that ``request`` takes.
543         :rtype: requests.Response
544         """
545 
546         return self.request('PUT', url, data=data, **kwargs)
547 
548     def patch(self, url, data=None, **kwargs):
549         """Sends a PATCH request. Returns :class:`Response` object.
550 
551         :param url: URL for the new :class:`Request` object.
552         :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.
553         :param \*\*kwargs: Optional arguments that ``request`` takes.
554         :rtype: requests.Response
555         """
556 
557         return self.request('PATCH', url,  data=data, **kwargs)
558 
559     def delete(self, url, **kwargs):
560         """Sends a DELETE request. Returns :class:`Response` object.
561 
562         :param url: URL for the new :class:`Request` object.
563         :param \*\*kwargs: Optional arguments that ``request`` takes.
564         :rtype: requests.Response
565         """
566 
567         return self.request('DELETE', url, **kwargs)
568 
569     def send(self, request, **kwargs):
570         """
571         Send a given PreparedRequest.
572 
573         :rtype: requests.Response
574         """
575         # Set defaults that the hooks can utilize to ensure they always have
576         # the correct parameters to reproduce the previous request.
577         kwargs.setdefault('stream', self.stream)
578         kwargs.setdefault('verify', self.verify)
579         kwargs.setdefault('cert', self.cert)
580         kwargs.setdefault('proxies', self.proxies)
581 
582         # It's possible that users might accidentally send a Request object.
583         # Guard against that specific failure case.
584         if isinstance(request, Request):
585             raise ValueError('You can only send PreparedRequests.')
586 
587         # Set up variables needed for resolve_redirects and dispatching of hooks
588         allow_redirects = kwargs.pop('allow_redirects', True)
589         stream = kwargs.get('stream')
590         hooks = request.hooks
591 
592         # Resolve URL in redirect cache, if available.
593         if allow_redirects:
594             checked_urls = set()
595             while request.url in self.redirect_cache:
596                 checked_urls.add(request.url)
597                 new_url = self.redirect_cache.get(request.url)
598                 if new_url in checked_urls:
599                     break
600                 request.url = new_url
601 
602         # Get the appropriate adapter to use
603         adapter = self.get_adapter(url=request.url)
604 
605         # Start time (approximately) of the request
606         start = datetime.utcnow()
607 
608         # Send the request
609         r = adapter.send(request, **kwargs)
610 
611         # Total elapsed time of the request (approximately)
612         r.elapsed = datetime.utcnow() - start
613 
614         # Response manipulation hooks
615         r = dispatch_hook('response', hooks, r, **kwargs)
616 
617         # Persist cookies
618         if r.history:
619 
620             # If the hooks create history then we want those cookies too
621             for resp in r.history:
622                 extract_cookies_to_jar(self.cookies, resp.request, resp.raw)
623 
624         extract_cookies_to_jar(self.cookies, request, r.raw)
625 
626         # Redirect resolving generator.
627         gen = self.resolve_redirects(r, request, **kwargs)
628 
629         # Resolve redirects if allowed.
630         history = [resp for resp in gen] if allow_redirects else []
631 
632         # Shuffle things around if there's history.
633         if history:
634             # Insert the first (original) request at the start
635             history.insert(0, r)
636             # Get the last request made
637             r = history.pop()
638             r.history = history
639 
640         if not stream:
641             r.content
642 
643         return r
644 
645     def merge_environment_settings(self, url, proxies, stream, verify, cert):
646         """
647         Check the environment and merge it with some settings.
648 
649         :rtype: dict
650         """
651         # Gather clues from the surrounding environment.
652         if self.trust_env:
653             # Set environment's proxies.
654             env_proxies = get_environ_proxies(url) or {}
655             for (k, v) in env_proxies.items():
656                 proxies.setdefault(k, v)
657 
658             # Look for requests environment configuration and be compatible
659             # with cURL.
660             if verify is True or verify is None:
661                 verify = (os.environ.get('REQUESTS_CA_BUNDLE') or
662                           os.environ.get('CURL_CA_BUNDLE'))
663 
664         # Merge all the kwargs.
665         proxies = merge_setting(proxies, self.proxies)
666         stream = merge_setting(stream, self.stream)
667         verify = merge_setting(verify, self.verify)
668         cert = merge_setting(cert, self.cert)
669 
670         return {'verify': verify, 'proxies': proxies, 'stream': stream,
671                 'cert': cert}
672 
673     def get_adapter(self, url):
674         """
675         Returns the appropriate connection adapter for the given URL.
676 
677         :rtype: requests.adapters.BaseAdapter
678         """
679         for (prefix, adapter) in self.adapters.items():
680 
681             if url.lower().startswith(prefix):
682                 return adapter
683 
684         # Nothing matches :-/
685         raise InvalidSchema("No connection adapters were found for '%s'" % url)
686 
687     def close(self):
688         """Closes all adapters and as such the session"""
689         for v in self.adapters.values():
690             v.close()
691 
692     def mount(self, prefix, adapter):
693         """Registers a connection adapter to a prefix.
694 
695         Adapters are sorted in descending order by key length.
696         """
697         self.adapters[prefix] = adapter
698         keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]
699 
700         for key in keys_to_move:
701             self.adapters[key] = self.adapters.pop(key)
702 
703     def __getstate__(self):
704         state = dict((attr, getattr(self, attr, None)) for attr in self.__attrs__)
705         state['redirect_cache'] = dict(self.redirect_cache)
706         return state
707 
708     def __setstate__(self, state):
709         redirect_cache = state.pop('redirect_cache', {})
710         for attr, value in state.items():
711             setattr(self, attr, value)
712 
713         self.redirect_cache = RecentlyUsedContainer(REDIRECT_CACHE_SIZE)
714         for redirect, to in redirect_cache.items():
715             self.redirect_cache[redirect] = to
716 
717 
718 def session():
719     """
720     Returns a :class:`Session` for context-management.
721 
722     :rtype: Session
723     """
724 
725     return Session()

</code><intended_behavior>Ensure that every HTTP response is checked for 'None' before attempting to access its content or any methods.</intended_behavior>, <file>requests/adapters.py</file>
<class>None</class>
<method>None</method>
<code>
1 # -*- coding: utf-8 -*-
2 
3 """
4 requests.adapters
5 ~~~~~~~~~~~~~~~~~
6 
7 This module contains the transport adapters that Requests uses to define
8 and maintain connections.
9 """
10 
11 import os.path
12 import socket
13 
14 from .models import Response
15 from .packages.urllib3.poolmanager import PoolManager, proxy_from_url
16 from .packages.urllib3.response import HTTPResponse
17 from .packages.urllib3.util import Timeout as TimeoutSauce
18 from .packages.urllib3.util.retry import Retry
19 from .compat import urlparse, basestring
20 from .utils import (DEFAULT_CA_BUNDLE_PATH, get_encoding_from_headers,
21                     prepend_scheme_if_needed, get_auth_from_url, urldefragauth,
22                     select_proxy, to_native_string)
23 from .structures import CaseInsensitiveDict
24 from .packages.urllib3.exceptions import ClosedPoolError
25 from .packages.urllib3.exceptions import ConnectTimeoutError
26 from .packages.urllib3.exceptions import HTTPError as _HTTPError
27 from .packages.urllib3.exceptions import MaxRetryError
28 from .packages.urllib3.exceptions import NewConnectionError
29 from .packages.urllib3.exceptions import ProxyError as _ProxyError
30 from .packages.urllib3.exceptions import ProtocolError
31 from .packages.urllib3.exceptions import ReadTimeoutError
32 from .packages.urllib3.exceptions import SSLError as _SSLError
33 from .packages.urllib3.exceptions import ResponseError
34 from .cookies import extract_cookies_to_jar
35 from .exceptions import (ConnectionError, ConnectTimeout, ReadTimeout, SSLError,
36                          ProxyError, RetryError, InvalidSchema)
37 from .auth import _basic_auth_str
38 
39 try:
40     from .packages.urllib3.contrib.socks import SOCKSProxyManager
41 except ImportError:
42     def SOCKSProxyManager(*args, **kwargs):
43         raise InvalidSchema("Missing dependencies for SOCKS support.")
44 
45 DEFAULT_POOLBLOCK = False
46 DEFAULT_POOLSIZE = 10
47 DEFAULT_RETRIES = 0
48 DEFAULT_POOL_TIMEOUT = None
49 
50 
51 class BaseAdapter(object):
52     """The Base Transport Adapter"""
53 
54     def __init__(self):
55         super(BaseAdapter, self).__init__()
56 
57     def send(self, request, stream=False, timeout=None, verify=True,
58              cert=None, proxies=None):
59         """Sends PreparedRequest object. Returns Response object.
60 
61         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
62         :param stream: (optional) Whether to stream the request content.
63         :param timeout: (optional) How long to wait for the server to send
64             data before giving up, as a float, or a :ref:`(connect timeout,
65             read timeout) <timeouts>` tuple.
66         :type timeout: float or tuple
67         :param verify: (optional) Whether to verify SSL certificates.
68         :param cert: (optional) Any user-provided SSL certificate to be trusted.
69         :param proxies: (optional) The proxies dictionary to apply to the request.
70         """
71         raise NotImplementedError
72 
73     def close(self):
74         """Cleans up adapter specific items."""
75         raise NotImplementedError
76 
77 
78 class HTTPAdapter(BaseAdapter):
79     """The built-in HTTP Adapter for urllib3.
80 
81     Provides a general-case interface for Requests sessions to contact HTTP and
82     HTTPS urls by implementing the Transport Adapter interface. This class will
83     usually be created by the :class:`Session <Session>` class under the
84     covers.
85 
86     :param pool_connections: The number of urllib3 connection pools to cache.
87     :param pool_maxsize: The maximum number of connections to save in the pool.
88     :param max_retries: The maximum number of retries each connection
89         should attempt. Note, this applies only to failed DNS lookups, socket
90         connections and connection timeouts, never to requests where data has
91         made it to the server. By default, Requests does not retry failed
92         connections. If you need granular control over the conditions under
93         which we retry a request, import urllib3's ``Retry`` class and pass
94         that instead.
95     :param pool_block: Whether the connection pool should block for connections.
96 
97     Usage::
98 
99       >>> import requests
100       >>> s = requests.Session()
101       >>> a = requests.adapters.HTTPAdapter(max_retries=3)
102       >>> s.mount('http://', a)
103     """
104     __attrs__ = ['max_retries', 'config', '_pool_connections', '_pool_maxsize',
105                  '_pool_block']
106 
107     def __init__(self, pool_connections=DEFAULT_POOLSIZE,
108                  pool_maxsize=DEFAULT_POOLSIZE, max_retries=DEFAULT_RETRIES,
109                  pool_block=DEFAULT_POOLBLOCK):
110         if max_retries == DEFAULT_RETRIES:
111             self.max_retries = Retry(0, read=False)
112         else:
113             self.max_retries = Retry.from_int(max_retries)
114         self.config = {}
115         self.proxy_manager = {}
116 
117         super(HTTPAdapter, self).__init__()
118 
119         self._pool_connections = pool_connections
120         self._pool_maxsize = pool_maxsize
121         self._pool_block = pool_block
122 
123         self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)
124 
125     def __getstate__(self):
126         return dict((attr, getattr(self, attr, None)) for attr in
127                     self.__attrs__)
128 
129     def __setstate__(self, state):
130         # Can't handle by adding 'proxy_manager' to self.__attrs__ because
131         # self.poolmanager uses a lambda function, which isn't pickleable.
132         self.proxy_manager = {}
133         self.config = {}
134 
135         for attr, value in state.items():
136             setattr(self, attr, value)
137 
138         self.init_poolmanager(self._pool_connections, self._pool_maxsize,
139                               block=self._pool_block)
140 
141     def init_poolmanager(self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs):
142         """Initializes a urllib3 PoolManager.
143 
144         This method should not be called from user code, and is only
145         exposed for use when subclassing the
146         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
147 
148         :param connections: The number of urllib3 connection pools to cache.
149         :param maxsize: The maximum number of connections to save in the pool.
150         :param block: Block when no free connections are available.
151         :param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.
152         """
153         # save these values for pickling
154         self._pool_connections = connections
155         self._pool_maxsize = maxsize
156         self._pool_block = block
157 
158         self.poolmanager = PoolManager(num_pools=connections, maxsize=maxsize,
159                                        block=block, strict=True, **pool_kwargs)
160 
161     def proxy_manager_for(self, proxy, **proxy_kwargs):
162         """Return urllib3 ProxyManager for the given proxy.
163 
164         This method should not be called from user code, and is only
165         exposed for use when subclassing the
166         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
167 
168         :param proxy: The proxy to return a urllib3 ProxyManager for.
169         :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.
170         :returns: ProxyManager
171         :rtype: requests.packages.urllib3.ProxyManager
172         """
173         if proxy in self.proxy_manager:
174             manager = self.proxy_manager[proxy]
175         elif proxy.lower().startswith('socks'):
176             username, password = get_auth_from_url(proxy)
177             manager = self.proxy_manager[proxy] = SOCKSProxyManager(
178                 proxy,
179                 username=username,
180                 password=password,
181                 num_pools=self._pool_connections,
182                 maxsize=self._pool_maxsize,
183                 block=self._pool_block,
184                 **proxy_kwargs
185             )
186         else:
187             proxy_headers = self.proxy_headers(proxy)
188             manager = self.proxy_manager[proxy] = proxy_from_url(
189                 proxy,
190                 proxy_headers=proxy_headers,
191                 num_pools=self._pool_connections,
192                 maxsize=self._pool_maxsize,
193                 block=self._pool_block,
194                 **proxy_kwargs)
195 
196         return manager
197 
198     def cert_verify(self, conn, url, verify, cert):
199         """Verify a SSL certificate. This method should not be called from user
200         code, and is only exposed for use when subclassing the
201         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
202 
203         :param conn: The urllib3 connection object associated with the cert.
204         :param url: The requested URL.
205         :param verify: Whether we should actually verify the certificate.
206         :param cert: The SSL certificate to verify.
207         """
208         if url.lower().startswith('https') and verify:
209 
210             cert_loc = None
211 
212             # Allow self-specified cert location.
213             if verify is not True:
214                 cert_loc = verify
215 
216             if not cert_loc:
217                 cert_loc = DEFAULT_CA_BUNDLE_PATH
218 
219             if not cert_loc:
220                 raise Exception("Could not find a suitable SSL CA certificate bundle.")
221 
222             conn.cert_reqs = 'CERT_REQUIRED'
223 
224             if not os.path.isdir(cert_loc):
225                 conn.ca_certs = cert_loc
226             else:
227                 conn.ca_cert_dir = cert_loc
228         else:
229             conn.cert_reqs = 'CERT_NONE'
230             conn.ca_certs = None
231             conn.ca_cert_dir = None
232 
233         if cert:
234             if not isinstance(cert, basestring):
235                 conn.cert_file = cert[0]
236                 conn.key_file = cert[1]
237             else:
238                 conn.cert_file = cert
239 
240     def build_response(self, req, resp):
241         """Builds a :class:`Response <requests.Response>` object from a urllib3
242         response. This should not be called from user code, and is only exposed
243         for use when subclassing the
244         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`
245 
246         :param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.
247         :param resp: The urllib3 response object.
248         :rtype: requests.Response
249         """
250         response = Response()
251 
252         # Fallback to None if there's no status_code, for whatever reason.
253         response.status_code = getattr(resp, 'status', None)
254 
255         # Make headers case-insensitive.
256         response.headers = CaseInsensitiveDict(getattr(resp, 'headers', {}))
257 
258         # Set encoding.
259         response.encoding = get_encoding_from_headers(response.headers)
260         response.raw = resp
261         response.reason = response.raw.reason
262 
263         if isinstance(req.url, bytes):
264             response.url = req.url.decode('utf-8')
265         else:
266             response.url = req.url
267 
268         # Add new cookies from the server.
269         extract_cookies_to_jar(response.cookies, req, resp)
270 
271         # Give the Response some context.
272         response.request = req
273         response.connection = self
274 
275         return response
276 
277     def get_connection(self, url, proxies=None):
278         """Returns a urllib3 connection for the given URL. This should not be
279         called from user code, and is only exposed for use when subclassing the
280         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
281 
282         :param url: The URL to connect to.
283         :param proxies: (optional) A Requests-style dictionary of proxies used on this request.
284         :rtype: requests.packages.urllib3.ConnectionPool
285         """
286         proxy = select_proxy(url, proxies)
287 
288         if proxy:
289             proxy = prepend_scheme_if_needed(proxy, 'http')
290             proxy_manager = self.proxy_manager_for(proxy)
291             conn = proxy_manager.connection_from_url(url)
292         else:
293             # Only scheme should be lower case
294             parsed = urlparse(url)
295             url = parsed.geturl()
296             conn = self.poolmanager.connection_from_url(url)
297 
298         return conn
299 
300     def close(self):
301         """Disposes of any internal state.
302 
303         Currently, this closes the PoolManager and any active ProxyManager,
304         which closes any pooled connections.
305         """
306         self.poolmanager.clear()
307         for proxy in self.proxy_manager.values():
308             proxy.clear()
309 
310     def request_url(self, request, proxies):
311         """Obtain the url to use when making the final request.
312 
313         If the message is being sent through a HTTP proxy, the full URL has to
314         be used. Otherwise, we should only use the path portion of the URL.
315 
316         This should not be called from user code, and is only exposed for use
317         when subclassing the
318         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
319 
320         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
321         :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.
322         :rtype: str
323         """
324         proxy = select_proxy(request.url, proxies)
325         scheme = urlparse(request.url).scheme
326 
327         is_proxied_http_request = (proxy and scheme != 'https')
328         using_socks_proxy = False
329         if proxy:
330             proxy_scheme = urlparse(proxy).scheme.lower()
331             using_socks_proxy = proxy_scheme.startswith('socks')
332 
333         url = request.path_url
334         if is_proxied_http_request and not using_socks_proxy:
335             url = urldefragauth(request.url)
336 
337         return url
338 
339     def add_headers(self, request, **kwargs):
340         """Add any headers needed by the connection. As of v2.0 this does
341         nothing by default, but is left for overriding by users that subclass
342         the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
343 
344         This should not be called from user code, and is only exposed for use
345         when subclassing the
346         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
347 
348         :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.
349         :param kwargs: The keyword arguments from the call to send().
350         """
351         pass
352 
353     def proxy_headers(self, proxy):
354         """Returns a dictionary of the headers to add to any request sent
355         through a proxy. This works with urllib3 magic to ensure that they are
356         correctly sent to the proxy, rather than in a tunnelled request if
357         CONNECT is being used.
358 
359         This should not be called from user code, and is only exposed for use
360         when subclassing the
361         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.
362 
363         :param proxies: The url of the proxy being used for this request.
364         :rtype: dict
365         """
366         headers = {}
367         username, password = get_auth_from_url(proxy)
368 
369         if username:
370             headers['Proxy-Authorization'] = _basic_auth_str(username,
371                                                              password)
372 
373         return headers
374 
375     def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
376         """Sends PreparedRequest object. Returns Response object.
377 
378         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
379         :param stream: (optional) Whether to stream the request content.
380         :param timeout: (optional) How long to wait for the server to send
381             data before giving up, as a float, or a :ref:`(connect timeout,
382             read timeout) <timeouts>` tuple.
383         :type timeout: float or tuple
384         :param verify: (optional) Whether to verify SSL certificates.
385         :param cert: (optional) Any user-provided SSL certificate to be trusted.
386         :param proxies: (optional) The proxies dictionary to apply to the request.
387         :rtype: requests.Response
388         """
389 
390         conn = self.get_connection(request.url, proxies)
391 
392         self.cert_verify(conn, request.url, verify, cert)
393         url = self.request_url(request, proxies)
394         self.add_headers(request)
395 
396         chunked = not (request.body is None or 'Content-Length' in request.headers)
397 
398         if isinstance(timeout, tuple):
399             try:
400                 connect, read = timeout
401                 timeout = TimeoutSauce(connect=connect, read=read)
402             except ValueError as e:
403                 # this may raise a string formatting error.
404                 err = ("Invalid timeout {0}. Pass a (connect, read) "
405                        "timeout tuple, or a single float to set "
406                        "both timeouts to the same value".format(timeout))
407                 raise ValueError(err)
408         else:
409             timeout = TimeoutSauce(connect=timeout, read=timeout)
410 
411         try:
412             if not chunked:
413                 resp = conn.urlopen(
414                     method=request.method,
415                     url=url,
416                     body=request.body,
417                     headers=request.headers,
418                     redirect=False,
419                     assert_same_host=False,
420                     preload_content=False,
421                     decode_content=False,
422                     retries=self.max_retries,
423                     timeout=timeout
424                 )
425 
426             # Send the request.
427             else:
428                 if hasattr(conn, 'proxy_pool'):
429                     conn = conn.proxy_pool
430 
431                 low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)
432 
433                 try:
434                     low_conn.putrequest(request.method,
435                                         url,
436                                         skip_accept_encoding=True)
437 
438                     for header, value in request.headers.items():
439                         low_conn.putheader(header, value)
440 
441                     low_conn.endheaders()
442 
443                     for i in request.body:
444                         low_conn.send(hex(len(i))[2:].encode('utf-8'))
445                         low_conn.send(b'\r\n')
446                         low_conn.send(i)
447                         low_conn.send(b'\r\n')
448                     low_conn.send(b'0\r\n\r\n')
449 
450                     # Receive the response from the server
451                     try:
452                         # For Python 2.7+ versions, use buffering of HTTP
453                         # responses
454                         r = low_conn.getresponse(buffering=True)
455                     except TypeError:
456                         # For compatibility with Python 2.6 versions and back
457                         r = low_conn.getresponse()
458 
459                     resp = HTTPResponse.from_httplib(
460                         r,
461                         pool=conn,
462                         connection=low_conn,
463                         preload_content=False,
464                         decode_content=False
465                     )
466                 except:
467                     # If we hit any problems here, clean up the connection.
468                     # Then, reraise so that we can handle the actual exception.
469                     low_conn.close()
470                     raise
471 
472         except (ProtocolError, socket.error) as err:
473             raise ConnectionError(err, request=request)
474 
475         except MaxRetryError as e:
476             if isinstance(e.reason, ConnectTimeoutError):
477                 # TODO: Remove this in 3.0.0: see #2811
478                 if not isinstance(e.reason, NewConnectionError):
479                     raise ConnectTimeout(e, request=request)
480 
481             if isinstance(e.reason, ResponseError):
482                 raise RetryError(e, request=request)
483 
484             if isinstance(e.reason, _ProxyError):
485                 raise ProxyError(e, request=request)
486 
487             raise ConnectionError(e, request=request)
488 
489         except ClosedPoolError as e:
490             raise ConnectionError(e, request=request)
491 
492         except _ProxyError as e:
493             raise ProxyError(e)
494 
495         except (_SSLError, _HTTPError) as e:
496             if isinstance(e, _SSLError):
497                 raise SSLError(e, request=request)
498             elif isinstance(e, ReadTimeoutError):
499                 raise ReadTimeout(e, request=request)
500             else:
501                 raise
502 
503         return self.build_response(request, resp)

</code><intended_behavior>Ensure that every HTTP response is checked for 'None' before attempting to access its content or any methods.</intended_behavior>]
2025-10-18 15:05:32.158 | INFO     | Overall retry 0 succeeded; ending workflow
2025-10-18 15:05:32.158 | INFO     | Search-only: skipping patch selection
2025-10-18 15:05:32.221 | INFO     | Task psf__requests-3718 completed successfully.
2025-10-18 15:05:32.222 | INFO     | No patch generated. You can try running ACR again.
