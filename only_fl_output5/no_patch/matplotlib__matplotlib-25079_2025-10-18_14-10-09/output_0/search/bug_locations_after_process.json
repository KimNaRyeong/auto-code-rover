[
    {
        "rel_file_path": "lib/matplotlib/colors.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/matplotlib__matplotlib/setup_matplotlib__matplotlib__3.6/lib/matplotlib/colors.py",
        "start": 1,
        "end": 2659,
        "class_name": null,
        "method_name": null,
        "code": "1 \"\"\"\n2 A module for converting numbers or color arguments to *RGB* or *RGBA*.\n3 \n4 *RGB* and *RGBA* are sequences of, respectively, 3 or 4 floats in the\n5 range 0-1.\n6 \n7 This module includes functions and classes for color specification conversions,\n8 and for mapping numbers to colors in a 1-D array of colors called a colormap.\n9 \n10 Mapping data onto colors using a colormap typically involves two steps: a data\n11 array is first mapped onto the range 0-1 using a subclass of `Normalize`,\n12 then this number is mapped to a color using a subclass of `Colormap`.  Two\n13 subclasses of `Colormap` provided here:  `LinearSegmentedColormap`, which uses\n14 piecewise-linear interpolation to define colormaps, and `ListedColormap`, which\n15 makes a colormap from a list of colors.\n16 \n17 .. seealso::\n18 \n19   :doc:`/tutorials/colors/colormap-manipulation` for examples of how to\n20   make colormaps and\n21 \n22   :doc:`/tutorials/colors/colormaps` for a list of built-in colormaps.\n23 \n24   :doc:`/tutorials/colors/colormapnorms` for more details about data\n25   normalization\n26 \n27   More colormaps are available at palettable_.\n28 \n29 The module also provides functions for checking whether an object can be\n30 interpreted as a color (`is_color_like`), for converting such an object\n31 to an RGBA tuple (`to_rgba`) or to an HTML-like hex string in the\n32 \"#rrggbb\" format (`to_hex`), and a sequence of colors to an (n, 4)\n33 RGBA array (`to_rgba_array`).  Caching is used for efficiency.\n34 \n35 Colors that Matplotlib recognizes are listed at\n36 :doc:`/tutorials/colors/colors`.\n37 \n38 .. _palettable: https://jiffyclub.github.io/palettable/\n39 .. _xkcd color survey: https://xkcd.com/color/rgb/\n40 \"\"\"\n41 \n42 import base64\n43 from collections.abc import Sized, Sequence, Mapping\n44 import functools\n45 import importlib\n46 import inspect\n47 import io\n48 import itertools\n49 from numbers import Number\n50 import re\n51 from PIL import Image\n52 from PIL.PngImagePlugin import PngInfo\n53 \n54 import matplotlib as mpl\n55 import numpy as np\n56 from matplotlib import _api, _cm, cbook, scale\n57 from ._color_data import BASE_COLORS, TABLEAU_COLORS, CSS4_COLORS, XKCD_COLORS\n58 \n59 \n60 class _ColorMapping(dict):\n61     def __init__(self, mapping):\n62         super().__init__(mapping)\n63         self.cache = {}\n64 \n65     def __setitem__(self, key, value):\n66         super().__setitem__(key, value)\n67         self.cache.clear()\n68 \n69     def __delitem__(self, key):\n70         super().__delitem__(key)\n71         self.cache.clear()\n72 \n73 \n74 _colors_full_map = {}\n75 # Set by reverse priority order.\n76 _colors_full_map.update(XKCD_COLORS)\n77 _colors_full_map.update({k.replace('grey', 'gray'): v\n78                          for k, v in XKCD_COLORS.items()\n79                          if 'grey' in k})\n80 _colors_full_map.update(CSS4_COLORS)\n81 _colors_full_map.update(TABLEAU_COLORS)\n82 _colors_full_map.update({k.replace('gray', 'grey'): v\n83                          for k, v in TABLEAU_COLORS.items()\n84                          if 'gray' in k})\n85 _colors_full_map.update(BASE_COLORS)\n86 _colors_full_map = _ColorMapping(_colors_full_map)\n87 \n88 _REPR_PNG_SIZE = (512, 64)\n89 \n90 \n91 def get_named_colors_mapping():\n92     \"\"\"Return the global mapping of names to named colors.\"\"\"\n93     return _colors_full_map\n94 \n95 \n96 class ColorSequenceRegistry(Mapping):\n97     r\"\"\"\n98     Container for sequences of colors that are known to Matplotlib by name.\n99 \n100     The universal registry instance is `matplotlib.color_sequences`. There\n101     should be no need for users to instantiate `.ColorSequenceRegistry`\n102     themselves.\n103 \n104     Read access uses a dict-like interface mapping names to lists of colors::\n105 \n106         import matplotlib as mpl\n107         cmap = mpl.color_sequences['tab10']\n108 \n109     The returned lists are copies, so that their modification does not change\n110     the global definition of the color sequence.\n111 \n112     Additional color sequences can be added via\n113     `.ColorSequenceRegistry.register`::\n114 \n115         mpl.color_sequences.register('rgb', ['r', 'g', 'b'])\n116     \"\"\"\n117 \n118     _BUILTIN_COLOR_SEQUENCES = {\n119         'tab10': _cm._tab10_data,\n120         'tab20': _cm._tab20_data,\n121         'tab20b': _cm._tab20b_data,\n122         'tab20c': _cm._tab20c_data,\n123         'Pastel1': _cm._Pastel1_data,\n124         'Pastel2': _cm._Pastel2_data,\n125         'Paired': _cm._Paired_data,\n126         'Accent': _cm._Accent_data,\n127         'Dark2': _cm._Dark2_data,\n128         'Set1': _cm._Set1_data,\n129         'Set2': _cm._Set1_data,\n130         'Set3': _cm._Set1_data,\n131     }\n132 \n133     def __init__(self):\n134         self._color_sequences = {**self._BUILTIN_COLOR_SEQUENCES}\n135 \n136     def __getitem__(self, item):\n137         try:\n138             return list(self._color_sequences[item])\n139         except KeyError:\n140             raise KeyError(f\"{item!r} is not a known color sequence name\")\n141 \n142     def __iter__(self):\n143         return iter(self._color_sequences)\n144 \n145     def __len__(self):\n146         return len(self._color_sequences)\n147 \n148     def __str__(self):\n149         return ('ColorSequenceRegistry; available colormaps:\\n' +\n150                 ', '.join(f\"'{name}'\" for name in self))\n151 \n152     def register(self, name, color_list):\n153         \"\"\"\n154         Register a new color sequence.\n155 \n156         The color sequence registry stores a copy of the given *color_list*, so\n157         that future changes to the original list do not affect the registered\n158         color sequence. Think of this as the registry taking a snapshot\n159         of *color_list* at registration.\n160 \n161         Parameters\n162         ----------\n163         name : str\n164             The name for the color sequence.\n165 \n166         color_list : list of colors\n167             An iterable returning valid Matplotlib colors when iterating over.\n168             Note however that the returned color sequence will always be a\n169             list regardless of the input type.\n170 \n171         \"\"\"\n172         if name in self._BUILTIN_COLOR_SEQUENCES:\n173             raise ValueError(f\"{name!r} is a reserved name for a builtin \"\n174                              \"color sequence\")\n175 \n176         color_list = list(color_list)  # force copy and coerce type to list\n177         for color in color_list:\n178             try:\n179                 to_rgba(color)\n180             except ValueError:\n181                 raise ValueError(\n182                     f\"{color!r} is not a valid color specification\")\n183 \n184         self._color_sequences[name] = color_list\n185 \n186     def unregister(self, name):\n187         \"\"\"\n188         Remove a sequence from the registry.\n189 \n190         You cannot remove built-in color sequences.\n191 \n192         If the name is not registered, returns with no error.\n193         \"\"\"\n194         if name in self._BUILTIN_COLOR_SEQUENCES:\n195             raise ValueError(\n196                 f\"Cannot unregister builtin color sequence {name!r}\")\n197         self._color_sequences.pop(name, None)\n198 \n199 \n200 _color_sequences = ColorSequenceRegistry()\n201 \n202 \n203 def _sanitize_extrema(ex):\n204     if ex is None:\n205         return ex\n206     try:\n207         ret = ex.item()\n208     except AttributeError:\n209         ret = float(ex)\n210     return ret\n211 \n212 \n213 def _is_nth_color(c):\n214     \"\"\"Return whether *c* can be interpreted as an item in the color cycle.\"\"\"\n215     return isinstance(c, str) and re.match(r\"\\AC[0-9]+\\Z\", c)\n216 \n217 \n218 def is_color_like(c):\n219     \"\"\"Return whether *c* can be interpreted as an RGB(A) color.\"\"\"\n220     # Special-case nth color syntax because it cannot be parsed during setup.\n221     if _is_nth_color(c):\n222         return True\n223     try:\n224         to_rgba(c)\n225     except ValueError:\n226         return False\n227     else:\n228         return True\n229 \n230 \n231 def _has_alpha_channel(c):\n232     \"\"\"Return whether *c* is a color with an alpha channel.\"\"\"\n233     # 4-element sequences are interpreted as r, g, b, a\n234     return not isinstance(c, str) and len(c) == 4\n235 \n236 \n237 def _check_color_like(**kwargs):\n238     \"\"\"\n239     For each *key, value* pair in *kwargs*, check that *value* is color-like.\n240     \"\"\"\n241     for k, v in kwargs.items():\n242         if not is_color_like(v):\n243             raise ValueError(f\"{v!r} is not a valid value for {k}\")\n244 \n245 \n246 def same_color(c1, c2):\n247     \"\"\"\n248     Return whether the colors *c1* and *c2* are the same.\n249 \n250     *c1*, *c2* can be single colors or lists/arrays of colors.\n251     \"\"\"\n252     c1 = to_rgba_array(c1)\n253     c2 = to_rgba_array(c2)\n254     n1 = max(c1.shape[0], 1)  # 'none' results in shape (0, 4), but is 1-elem\n255     n2 = max(c2.shape[0], 1)  # 'none' results in shape (0, 4), but is 1-elem\n256 \n257     if n1 != n2:\n258         raise ValueError('Different number of elements passed.')\n259     # The following shape test is needed to correctly handle comparisons with\n260     # 'none', which results in a shape (0, 4) array and thus cannot be tested\n261     # via value comparison.\n262     return c1.shape == c2.shape and (c1 == c2).all()\n263 \n264 \n265 def to_rgba(c, alpha=None):\n266     \"\"\"\n267     Convert *c* to an RGBA color.\n268 \n269     Parameters\n270     ----------\n271     c : Matplotlib color or ``np.ma.masked``\n272 \n273     alpha : float, optional\n274         If *alpha* is given, force the alpha value of the returned RGBA tuple\n275         to *alpha*.\n276 \n277         If None, the alpha value from *c* is used. If *c* does not have an\n278         alpha channel, then alpha defaults to 1.\n279 \n280         *alpha* is ignored for the color value ``\"none\"`` (case-insensitive),\n281         which always maps to ``(0, 0, 0, 0)``.\n282 \n283     Returns\n284     -------\n285     tuple\n286         Tuple of floats ``(r, g, b, a)``, where each channel (red, green, blue,\n287         alpha) can assume values between 0 and 1.\n288     \"\"\"\n289     # Special-case nth color syntax because it should not be cached.\n290     if _is_nth_color(c):\n291         prop_cycler = mpl.rcParams['axes.prop_cycle']\n292         colors = prop_cycler.by_key().get('color', ['k'])\n293         c = colors[int(c[1:]) % len(colors)]\n294     try:\n295         rgba = _colors_full_map.cache[c, alpha]\n296     except (KeyError, TypeError):  # Not in cache, or unhashable.\n297         rgba = None\n298     if rgba is None:  # Suppress exception chaining of cache lookup failure.\n299         rgba = _to_rgba_no_colorcycle(c, alpha)\n300         try:\n301             _colors_full_map.cache[c, alpha] = rgba\n302         except TypeError:\n303             pass\n304     return rgba\n305 \n306 \n307 def _to_rgba_no_colorcycle(c, alpha=None):\n308     \"\"\"\n309     Convert *c* to an RGBA color, with no support for color-cycle syntax.\n310 \n311     If *alpha* is given, force the alpha value of the returned RGBA tuple\n312     to *alpha*. Otherwise, the alpha value from *c* is used, if it has alpha\n313     information, or defaults to 1.\n314 \n315     *alpha* is ignored for the color value ``\"none\"`` (case-insensitive),\n316     which always maps to ``(0, 0, 0, 0)``.\n317     \"\"\"\n318     orig_c = c\n319     if c is np.ma.masked:\n320         return (0., 0., 0., 0.)\n321     if isinstance(c, str):\n322         if c.lower() == \"none\":\n323             return (0., 0., 0., 0.)\n324         # Named color.\n325         try:\n326             # This may turn c into a non-string, so we check again below.\n327             c = _colors_full_map[c]\n328         except KeyError:\n329             if len(orig_c) != 1:\n330                 try:\n331                     c = _colors_full_map[c.lower()]\n332                 except KeyError:\n333                     pass\n334     if isinstance(c, str):\n335         # hex color in #rrggbb format.\n336         match = re.match(r\"\\A#[a-fA-F0-9]{6}\\Z\", c)\n337         if match:\n338             return (tuple(int(n, 16) / 255\n339                           for n in [c[1:3], c[3:5], c[5:7]])\n340                     + (alpha if alpha is not None else 1.,))\n341         # hex color in #rgb format, shorthand for #rrggbb.\n342         match = re.match(r\"\\A#[a-fA-F0-9]{3}\\Z\", c)\n343         if match:\n344             return (tuple(int(n, 16) / 255\n345                           for n in [c[1]*2, c[2]*2, c[3]*2])\n346                     + (alpha if alpha is not None else 1.,))\n347         # hex color with alpha in #rrggbbaa format.\n348         match = re.match(r\"\\A#[a-fA-F0-9]{8}\\Z\", c)\n349         if match:\n350             color = [int(n, 16) / 255\n351                      for n in [c[1:3], c[3:5], c[5:7], c[7:9]]]\n352             if alpha is not None:\n353                 color[-1] = alpha\n354             return tuple(color)\n355         # hex color with alpha in #rgba format, shorthand for #rrggbbaa.\n356         match = re.match(r\"\\A#[a-fA-F0-9]{4}\\Z\", c)\n357         if match:\n358             color = [int(n, 16) / 255\n359                      for n in [c[1]*2, c[2]*2, c[3]*2, c[4]*2]]\n360             if alpha is not None:\n361                 color[-1] = alpha\n362             return tuple(color)\n363         # string gray.\n364         try:\n365             c = float(c)\n366         except ValueError:\n367             pass\n368         else:\n369             if not (0 <= c <= 1):\n370                 raise ValueError(\n371                     f\"Invalid string grayscale value {orig_c!r}. \"\n372                     f\"Value must be within 0-1 range\")\n373             return c, c, c, alpha if alpha is not None else 1.\n374         raise ValueError(f\"Invalid RGBA argument: {orig_c!r}\")\n375     # turn 2-D array into 1-D array\n376     if isinstance(c, np.ndarray):\n377         if c.ndim == 2 and c.shape[0] == 1:\n378             c = c.reshape(-1)\n379     # tuple color.\n380     if not np.iterable(c):\n381         raise ValueError(f\"Invalid RGBA argument: {orig_c!r}\")\n382     if len(c) not in [3, 4]:\n383         raise ValueError(\"RGBA sequence should have length 3 or 4\")\n384     if not all(isinstance(x, Number) for x in c):\n385         # Checks that don't work: `map(float, ...)`, `np.array(..., float)` and\n386         # `np.array(...).astype(float)` would all convert \"0.5\" to 0.5.\n387         raise ValueError(f\"Invalid RGBA argument: {orig_c!r}\")\n388     # Return a tuple to prevent the cached value from being modified.\n389     c = tuple(map(float, c))\n390     if len(c) == 3 and alpha is None:\n391         alpha = 1\n392     if alpha is not None:\n393         c = c[:3] + (alpha,)\n394     if any(elem < 0 or elem > 1 for elem in c):\n395         raise ValueError(\"RGBA values should be within 0-1 range\")\n396     return c\n397 \n398 \n399 def to_rgba_array(c, alpha=None):\n400     \"\"\"\n401     Convert *c* to a (n, 4) array of RGBA colors.\n402 \n403     Parameters\n404     ----------\n405     c : Matplotlib color or array of colors\n406         If *c* is a masked array, an `~numpy.ndarray` is returned with a\n407         (0, 0, 0, 0) row for each masked value or row in *c*.\n408 \n409     alpha : float or sequence of floats, optional\n410         If *alpha* is given, force the alpha value of the returned RGBA tuple\n411         to *alpha*.\n412 \n413         If None, the alpha value from *c* is used. If *c* does not have an\n414         alpha channel, then alpha defaults to 1.\n415 \n416         *alpha* is ignored for the color value ``\"none\"`` (case-insensitive),\n417         which always maps to ``(0, 0, 0, 0)``.\n418 \n419         If *alpha* is a sequence and *c* is a single color, *c* will be\n420         repeated to match the length of *alpha*.\n421 \n422     Returns\n423     -------\n424     array\n425         (n, 4) array of RGBA colors,  where each channel (red, green, blue,\n426         alpha) can assume values between 0 and 1.\n427     \"\"\"\n428     # Special-case inputs that are already arrays, for performance.  (If the\n429     # array has the wrong kind or shape, raise the error during one-at-a-time\n430     # conversion.)\n431     if np.iterable(alpha):\n432         alpha = np.asarray(alpha).ravel()\n433     if (isinstance(c, np.ndarray) and c.dtype.kind in \"if\"\n434             and c.ndim == 2 and c.shape[1] in [3, 4]):\n435         mask = c.mask.any(axis=1) if np.ma.is_masked(c) else None\n436         c = np.ma.getdata(c)\n437         if np.iterable(alpha):\n438             if c.shape[0] == 1 and alpha.shape[0] > 1:\n439                 c = np.tile(c, (alpha.shape[0], 1))\n440             elif c.shape[0] != alpha.shape[0]:\n441                 raise ValueError(\"The number of colors must match the number\"\n442                                  \" of alpha values if there are more than one\"\n443                                  \" of each.\")\n444         if c.shape[1] == 3:\n445             result = np.column_stack([c, np.zeros(len(c))])\n446             result[:, -1] = alpha if alpha is not None else 1.\n447         elif c.shape[1] == 4:\n448             result = c.copy()\n449             if alpha is not None:\n450                 result[:, -1] = alpha\n451         if mask is not None:\n452             result[mask] = 0\n453         if np.any((result < 0) | (result > 1)):\n454             raise ValueError(\"RGBA values should be within 0-1 range\")\n455         return result\n456     # Handle single values.\n457     # Note that this occurs *after* handling inputs that are already arrays, as\n458     # `to_rgba(c, alpha)` (below) is expensive for such inputs, due to the need\n459     # to format the array in the ValueError message(!).\n460     if cbook._str_lower_equal(c, \"none\"):\n461         return np.zeros((0, 4), float)\n462     try:\n463         if np.iterable(alpha):\n464             return np.array([to_rgba(c, a) for a in alpha], float)\n465         else:\n466             return np.array([to_rgba(c, alpha)], float)\n467     except (ValueError, TypeError):\n468         pass\n469 \n470     if isinstance(c, str):\n471         raise ValueError(f\"{c!r} is not a valid color value.\")\n472 \n473     if len(c) == 0:\n474         return np.zeros((0, 4), float)\n475 \n476     # Quick path if the whole sequence can be directly converted to a numpy\n477     # array in one shot.\n478     if isinstance(c, Sequence):\n479         lens = {len(cc) if isinstance(cc, (list, tuple)) else -1 for cc in c}\n480         if lens == {3}:\n481             rgba = np.column_stack([c, np.ones(len(c))])\n482         elif lens == {4}:\n483             rgba = np.array(c)\n484         else:\n485             rgba = np.array([to_rgba(cc) for cc in c])\n486     else:\n487         rgba = np.array([to_rgba(cc) for cc in c])\n488 \n489     if alpha is not None:\n490         rgba[:, 3] = alpha\n491     return rgba\n492 \n493 \n494 def to_rgb(c):\n495     \"\"\"Convert *c* to an RGB color, silently dropping the alpha channel.\"\"\"\n496     return to_rgba(c)[:3]\n497 \n498 \n499 def to_hex(c, keep_alpha=False):\n500     \"\"\"\n501     Convert *c* to a hex color.\n502 \n503     Parameters\n504     ----------\n505     c : :doc:`color </tutorials/colors/colors>` or `numpy.ma.masked`\n506 \n507     keep_alpha : bool, default: False\n508       If False, use the ``#rrggbb`` format, otherwise use ``#rrggbbaa``.\n509 \n510     Returns\n511     -------\n512     str\n513       ``#rrggbb`` or ``#rrggbbaa`` hex color string\n514     \"\"\"\n515     c = to_rgba(c)\n516     if not keep_alpha:\n517         c = c[:3]\n518     return \"#\" + \"\".join(format(round(val * 255), \"02x\") for val in c)\n519 \n520 \n521 ### Backwards-compatible color-conversion API\n522 \n523 \n524 cnames = CSS4_COLORS\n525 hexColorPattern = re.compile(r\"\\A#[a-fA-F0-9]{6}\\Z\")\n526 rgb2hex = to_hex\n527 hex2color = to_rgb\n528 \n529 \n530 class ColorConverter:\n531     \"\"\"\n532     A class only kept for backwards compatibility.\n533 \n534     Its functionality is entirely provided by module-level functions.\n535     \"\"\"\n536     colors = _colors_full_map\n537     cache = _colors_full_map.cache\n538     to_rgb = staticmethod(to_rgb)\n539     to_rgba = staticmethod(to_rgba)\n540     to_rgba_array = staticmethod(to_rgba_array)\n541 \n542 \n543 colorConverter = ColorConverter()\n544 \n545 \n546 ### End of backwards-compatible color-conversion API\n547 \n548 \n549 def _create_lookup_table(N, data, gamma=1.0):\n550     r\"\"\"\n551     Create an *N* -element 1D lookup table.\n552 \n553     This assumes a mapping :math:`f : [0, 1] \\rightarrow [0, 1]`. The returned\n554     data is an array of N values :math:`y = f(x)` where x is sampled from\n555     [0, 1].\n556 \n557     By default (*gamma* = 1) x is equidistantly sampled from [0, 1]. The\n558     *gamma* correction factor :math:`\\gamma` distorts this equidistant\n559     sampling by :math:`x \\rightarrow x^\\gamma`.\n560 \n561     Parameters\n562     ----------\n563     N : int\n564         The number of elements of the created lookup table; at least 1.\n565 \n566     data : (M, 3) array-like or callable\n567         Defines the mapping :math:`f`.\n568 \n569         If a (M, 3) array-like, the rows define values (x, y0, y1).  The x\n570         values must start with x=0, end with x=1, and all x values be in\n571         increasing order.\n572 \n573         A value between :math:`x_i` and :math:`x_{i+1}` is mapped to the range\n574         :math:`y^1_{i-1} \\ldots y^0_i` by linear interpolation.\n575 \n576         For the simple case of a y-continuous mapping, y0 and y1 are identical.\n577 \n578         The two values of y are to allow for discontinuous mapping functions.\n579         E.g. a sawtooth with a period of 0.2 and an amplitude of 1 would be::\n580 \n581             [(0, 1, 0), (0.2, 1, 0), (0.4, 1, 0), ..., [(1, 1, 0)]\n582 \n583         In the special case of ``N == 1``, by convention the returned value\n584         is y0 for x == 1.\n585 \n586         If *data* is a callable, it must accept and return numpy arrays::\n587 \n588            data(x : ndarray) -> ndarray\n589 \n590         and map values between 0 - 1 to 0 - 1.\n591 \n592     gamma : float\n593         Gamma correction factor for input distribution x of the mapping.\n594 \n595         See also https://en.wikipedia.org/wiki/Gamma_correction.\n596 \n597     Returns\n598     -------\n599     array\n600         The lookup table where ``lut[x * (N-1)]`` gives the closest value\n601         for values of x between 0 and 1.\n602 \n603     Notes\n604     -----\n605     This function is internally used for `.LinearSegmentedColormap`.\n606     \"\"\"\n607 \n608     if callable(data):\n609         xind = np.linspace(0, 1, N) ** gamma\n610         lut = np.clip(np.array(data(xind), dtype=float), 0, 1)\n611         return lut\n612 \n613     try:\n614         adata = np.array(data)\n615     except Exception as err:\n616         raise TypeError(\"data must be convertible to an array\") from err\n617     _api.check_shape((None, 3), data=adata)\n618 \n619     x = adata[:, 0]\n620     y0 = adata[:, 1]\n621     y1 = adata[:, 2]\n622 \n623     if x[0] != 0. or x[-1] != 1.0:\n624         raise ValueError(\n625             \"data mapping points must start with x=0 and end with x=1\")\n626     if (np.diff(x) < 0).any():\n627         raise ValueError(\"data mapping points must have x in increasing order\")\n628     # begin generation of lookup table\n629     if N == 1:\n630         # convention: use the y = f(x=1) value for a 1-element lookup table\n631         lut = np.array(y0[-1])\n632     else:\n633         x = x * (N - 1)\n634         xind = (N - 1) * np.linspace(0, 1, N) ** gamma\n635         ind = np.searchsorted(x, xind)[1:-1]\n636 \n637         distance = (xind[1:-1] - x[ind - 1]) / (x[ind] - x[ind - 1])\n638         lut = np.concatenate([\n639             [y1[0]],\n640             distance * (y0[ind] - y1[ind - 1]) + y1[ind - 1],\n641             [y0[-1]],\n642         ])\n643     # ensure that the lut is confined to values between 0 and 1 by clipping it\n644     return np.clip(lut, 0.0, 1.0)\n645 \n646 \n647 class Colormap:\n648     \"\"\"\n649     Baseclass for all scalar to RGBA mappings.\n650 \n651     Typically, Colormap instances are used to convert data values (floats)\n652     from the interval ``[0, 1]`` to the RGBA color that the respective\n653     Colormap represents. For scaling of data into the ``[0, 1]`` interval see\n654     `matplotlib.colors.Normalize`. Subclasses of `matplotlib.cm.ScalarMappable`\n655     make heavy use of this ``data -> normalize -> map-to-color`` processing\n656     chain.\n657     \"\"\"\n658 \n659     def __init__(self, name, N=256):\n660         \"\"\"\n661         Parameters\n662         ----------\n663         name : str\n664             The name of the colormap.\n665         N : int\n666             The number of RGB quantization levels.\n667         \"\"\"\n668         self.name = name\n669         self.N = int(N)  # ensure that N is always int\n670         self._rgba_bad = (0.0, 0.0, 0.0, 0.0)  # If bad, don't paint anything.\n671         self._rgba_under = None\n672         self._rgba_over = None\n673         self._i_under = self.N\n674         self._i_over = self.N + 1\n675         self._i_bad = self.N + 2\n676         self._isinit = False\n677         #: When this colormap exists on a scalar mappable and colorbar_extend\n678         #: is not False, colorbar creation will pick up ``colorbar_extend`` as\n679         #: the default value for the ``extend`` keyword in the\n680         #: `matplotlib.colorbar.Colorbar` constructor.\n681         self.colorbar_extend = False\n682 \n683     def __call__(self, X, alpha=None, bytes=False):\n684         \"\"\"\n685         Parameters\n686         ----------\n687         X : float or int, `~numpy.ndarray` or scalar\n688             The data value(s) to convert to RGBA.\n689             For floats, *X* should be in the interval ``[0.0, 1.0]`` to\n690             return the RGBA values ``X*100`` percent along the Colormap line.\n691             For integers, *X* should be in the interval ``[0, Colormap.N)`` to\n692             return RGBA values *indexed* from the Colormap with index ``X``.\n693         alpha : float or array-like or None\n694             Alpha must be a scalar between 0 and 1, a sequence of such\n695             floats with shape matching X, or None.\n696         bytes : bool\n697             If False (default), the returned RGBA values will be floats in the\n698             interval ``[0, 1]`` otherwise they will be uint8s in the interval\n699             ``[0, 255]``.\n700 \n701         Returns\n702         -------\n703         Tuple of RGBA values if X is scalar, otherwise an array of\n704         RGBA values with a shape of ``X.shape + (4, )``.\n705         \"\"\"\n706         if not self._isinit:\n707             self._init()\n708 \n709         xa = np.array(X, copy=True)\n710         if not xa.dtype.isnative:\n711             xa = xa.byteswap().newbyteorder()  # Native byteorder is faster.\n712         if xa.dtype.kind == \"f\":\n713             xa *= self.N\n714             # xa == 1 (== N after multiplication) is not out of range.\n715             xa[xa == self.N] = self.N - 1\n716         # Pre-compute the masks before casting to int (which can truncate\n717         # negative values to zero or wrap large floats to negative ints).\n718         mask_under = xa < 0\n719         mask_over = xa >= self.N\n720         # If input was masked, get the bad mask from it; else mask out nans.\n721         mask_bad = X.mask if np.ma.is_masked(X) else np.isnan(xa)\n722         with np.errstate(invalid=\"ignore\"):\n723             # We need this cast for unsigned ints as well as floats\n724             xa = xa.astype(int)\n725         xa[mask_under] = self._i_under\n726         xa[mask_over] = self._i_over\n727         xa[mask_bad] = self._i_bad\n728 \n729         lut = self._lut\n730         if bytes:\n731             lut = (lut * 255).astype(np.uint8)\n732 \n733         rgba = lut.take(xa, axis=0, mode='clip')\n734 \n735         if alpha is not None:\n736             alpha = np.clip(alpha, 0, 1)\n737             if bytes:\n738                 alpha *= 255  # Will be cast to uint8 upon assignment.\n739             if alpha.shape not in [(), xa.shape]:\n740                 raise ValueError(\n741                     f\"alpha is array-like but its shape {alpha.shape} does \"\n742                     f\"not match that of X {xa.shape}\")\n743             rgba[..., -1] = alpha\n744             # If the \"bad\" color is all zeros, then ignore alpha input.\n745             if (lut[-1] == 0).all():\n746                 rgba[mask_bad] = (0, 0, 0, 0)\n747 \n748         if not np.iterable(X):\n749             rgba = tuple(rgba)\n750         return rgba\n751 \n752     def __copy__(self):\n753         cls = self.__class__\n754         cmapobject = cls.__new__(cls)\n755         cmapobject.__dict__.update(self.__dict__)\n756         if self._isinit:\n757             cmapobject._lut = np.copy(self._lut)\n758         return cmapobject\n759 \n760     def __eq__(self, other):\n761         if (not isinstance(other, Colormap) or self.name != other.name or\n762                 self.colorbar_extend != other.colorbar_extend):\n763             return False\n764         # To compare lookup tables the Colormaps have to be initialized\n765         if not self._isinit:\n766             self._init()\n767         if not other._isinit:\n768             other._init()\n769         return np.array_equal(self._lut, other._lut)\n770 \n771     def get_bad(self):\n772         \"\"\"Get the color for masked values.\"\"\"\n773         if not self._isinit:\n774             self._init()\n775         return np.array(self._lut[self._i_bad])\n776 \n777     def set_bad(self, color='k', alpha=None):\n778         \"\"\"Set the color for masked values.\"\"\"\n779         self._rgba_bad = to_rgba(color, alpha)\n780         if self._isinit:\n781             self._set_extremes()\n782 \n783     def get_under(self):\n784         \"\"\"Get the color for low out-of-range values.\"\"\"\n785         if not self._isinit:\n786             self._init()\n787         return np.array(self._lut[self._i_under])\n788 \n789     def set_under(self, color='k', alpha=None):\n790         \"\"\"Set the color for low out-of-range values.\"\"\"\n791         self._rgba_under = to_rgba(color, alpha)\n792         if self._isinit:\n793             self._set_extremes()\n794 \n795     def get_over(self):\n796         \"\"\"Get the color for high out-of-range values.\"\"\"\n797         if not self._isinit:\n798             self._init()\n799         return np.array(self._lut[self._i_over])\n800 \n801     def set_over(self, color='k', alpha=None):\n802         \"\"\"Set the color for high out-of-range values.\"\"\"\n803         self._rgba_over = to_rgba(color, alpha)\n804         if self._isinit:\n805             self._set_extremes()\n806 \n807     def set_extremes(self, *, bad=None, under=None, over=None):\n808         \"\"\"\n809         Set the colors for masked (*bad*) values and, when ``norm.clip =\n810         False``, low (*under*) and high (*over*) out-of-range values.\n811         \"\"\"\n812         if bad is not None:\n813             self.set_bad(bad)\n814         if under is not None:\n815             self.set_under(under)\n816         if over is not None:\n817             self.set_over(over)\n818 \n819     def with_extremes(self, *, bad=None, under=None, over=None):\n820         \"\"\"\n821         Return a copy of the colormap, for which the colors for masked (*bad*)\n822         values and, when ``norm.clip = False``, low (*under*) and high (*over*)\n823         out-of-range values, have been set accordingly.\n824         \"\"\"\n825         new_cm = self.copy()\n826         new_cm.set_extremes(bad=bad, under=under, over=over)\n827         return new_cm\n828 \n829     def _set_extremes(self):\n830         if self._rgba_under:\n831             self._lut[self._i_under] = self._rgba_under\n832         else:\n833             self._lut[self._i_under] = self._lut[0]\n834         if self._rgba_over:\n835             self._lut[self._i_over] = self._rgba_over\n836         else:\n837             self._lut[self._i_over] = self._lut[self.N - 1]\n838         self._lut[self._i_bad] = self._rgba_bad\n839 \n840     def _init(self):\n841         \"\"\"Generate the lookup table, ``self._lut``.\"\"\"\n842         raise NotImplementedError(\"Abstract class only\")\n843 \n844     def is_gray(self):\n845         \"\"\"Return whether the colormap is grayscale.\"\"\"\n846         if not self._isinit:\n847             self._init()\n848         return (np.all(self._lut[:, 0] == self._lut[:, 1]) and\n849                 np.all(self._lut[:, 0] == self._lut[:, 2]))\n850 \n851     def resampled(self, lutsize):\n852         \"\"\"Return a new colormap with *lutsize* entries.\"\"\"\n853         if hasattr(self, '_resample'):\n854             _api.warn_external(\n855                 \"The ability to resample a color map is now public API \"\n856                 f\"However the class {type(self)} still only implements \"\n857                 \"the previous private _resample method.  Please update \"\n858                 \"your class.\"\n859             )\n860             return self._resample(lutsize)\n861 \n862         raise NotImplementedError()\n863 \n864     def reversed(self, name=None):\n865         \"\"\"\n866         Return a reversed instance of the Colormap.\n867 \n868         .. note:: This function is not implemented for the base class.\n869 \n870         Parameters\n871         ----------\n872         name : str, optional\n873             The name for the reversed colormap. If None, the\n874             name is set to ``self.name + \"_r\"``.\n875 \n876         See Also\n877         --------\n878         LinearSegmentedColormap.reversed\n879         ListedColormap.reversed\n880         \"\"\"\n881         raise NotImplementedError()\n882 \n883     def _repr_png_(self):\n884         \"\"\"Generate a PNG representation of the Colormap.\"\"\"\n885         X = np.tile(np.linspace(0, 1, _REPR_PNG_SIZE[0]),\n886                     (_REPR_PNG_SIZE[1], 1))\n887         pixels = self(X, bytes=True)\n888         png_bytes = io.BytesIO()\n889         title = self.name + ' colormap'\n890         author = f'Matplotlib v{mpl.__version__}, https://matplotlib.org'\n891         pnginfo = PngInfo()\n892         pnginfo.add_text('Title', title)\n893         pnginfo.add_text('Description', title)\n894         pnginfo.add_text('Author', author)\n895         pnginfo.add_text('Software', author)\n896         Image.fromarray(pixels).save(png_bytes, format='png', pnginfo=pnginfo)\n897         return png_bytes.getvalue()\n898 \n899     def _repr_html_(self):\n900         \"\"\"Generate an HTML representation of the Colormap.\"\"\"\n901         png_bytes = self._repr_png_()\n902         png_base64 = base64.b64encode(png_bytes).decode('ascii')\n903         def color_block(color):\n904             hex_color = to_hex(color, keep_alpha=True)\n905             return (f'<div title=\"{hex_color}\" '\n906                     'style=\"display: inline-block; '\n907                     'width: 1em; height: 1em; '\n908                     'margin: 0; '\n909                     'vertical-align: middle; '\n910                     'border: 1px solid #555; '\n911                     f'background-color: {hex_color};\"></div>')\n912 \n913         return ('<div style=\"vertical-align: middle;\">'\n914                 f'<strong>{self.name}</strong> '\n915                 '</div>'\n916                 '<div class=\"cmap\"><img '\n917                 f'alt=\"{self.name} colormap\" '\n918                 f'title=\"{self.name}\" '\n919                 'style=\"border: 1px solid #555;\" '\n920                 f'src=\"data:image/png;base64,{png_base64}\"></div>'\n921                 '<div style=\"vertical-align: middle; '\n922                 f'max-width: {_REPR_PNG_SIZE[0]+2}px; '\n923                 'display: flex; justify-content: space-between;\">'\n924                 '<div style=\"float: left;\">'\n925                 f'{color_block(self.get_under())} under'\n926                 '</div>'\n927                 '<div style=\"margin: 0 auto; display: inline-block;\">'\n928                 f'bad {color_block(self.get_bad())}'\n929                 '</div>'\n930                 '<div style=\"float: right;\">'\n931                 f'over {color_block(self.get_over())}'\n932                 '</div>')\n933 \n934     def copy(self):\n935         \"\"\"Return a copy of the colormap.\"\"\"\n936         return self.__copy__()\n937 \n938 \n939 class LinearSegmentedColormap(Colormap):\n940     \"\"\"\n941     Colormap objects based on lookup tables using linear segments.\n942 \n943     The lookup table is generated using linear interpolation for each\n944     primary color, with the 0-1 domain divided into any number of\n945     segments.\n946     \"\"\"\n947 \n948     def __init__(self, name, segmentdata, N=256, gamma=1.0):\n949         \"\"\"\n950         Create colormap from linear mapping segments\n951 \n952         segmentdata argument is a dictionary with a red, green and blue\n953         entries. Each entry should be a list of *x*, *y0*, *y1* tuples,\n954         forming rows in a table. Entries for alpha are optional.\n955 \n956         Example: suppose you want red to increase from 0 to 1 over\n957         the bottom half, green to do the same over the middle half,\n958         and blue over the top half.  Then you would use::\n959 \n960             cdict = {'red':   [(0.0,  0.0, 0.0),\n961                                (0.5,  1.0, 1.0),\n962                                (1.0,  1.0, 1.0)],\n963 \n964                      'green': [(0.0,  0.0, 0.0),\n965                                (0.25, 0.0, 0.0),\n966                                (0.75, 1.0, 1.0),\n967                                (1.0,  1.0, 1.0)],\n968 \n969                      'blue':  [(0.0,  0.0, 0.0),\n970                                (0.5,  0.0, 0.0),\n971                                (1.0,  1.0, 1.0)]}\n972 \n973         Each row in the table for a given color is a sequence of\n974         *x*, *y0*, *y1* tuples.  In each sequence, *x* must increase\n975         monotonically from 0 to 1.  For any input value *z* falling\n976         between *x[i]* and *x[i+1]*, the output value of a given color\n977         will be linearly interpolated between *y1[i]* and *y0[i+1]*::\n978 \n979             row i:   x  y0  y1\n980                            /\n981                           /\n982             row i+1: x  y0  y1\n983 \n984         Hence y0 in the first row and y1 in the last row are never used.\n985 \n986         See Also\n987         --------\n988         LinearSegmentedColormap.from_list\n989             Static method; factory function for generating a smoothly-varying\n990             LinearSegmentedColormap.\n991         \"\"\"\n992         # True only if all colors in map are identical; needed for contouring.\n993         self.monochrome = False\n994         super().__init__(name, N)\n995         self._segmentdata = segmentdata\n996         self._gamma = gamma\n997 \n998     def _init(self):\n999         self._lut = np.ones((self.N + 3, 4), float)\n1000         self._lut[:-3, 0] = _create_lookup_table(\n1001             self.N, self._segmentdata['red'], self._gamma)\n1002         self._lut[:-3, 1] = _create_lookup_table(\n1003             self.N, self._segmentdata['green'], self._gamma)\n1004         self._lut[:-3, 2] = _create_lookup_table(\n1005             self.N, self._segmentdata['blue'], self._gamma)\n1006         if 'alpha' in self._segmentdata:\n1007             self._lut[:-3, 3] = _create_lookup_table(\n1008                 self.N, self._segmentdata['alpha'], 1)\n1009         self._isinit = True\n1010         self._set_extremes()\n1011 \n1012     def set_gamma(self, gamma):\n1013         \"\"\"Set a new gamma value and regenerate colormap.\"\"\"\n1014         self._gamma = gamma\n1015         self._init()\n1016 \n1017     @staticmethod\n1018     def from_list(name, colors, N=256, gamma=1.0):\n1019         \"\"\"\n1020         Create a `LinearSegmentedColormap` from a list of colors.\n1021 \n1022         Parameters\n1023         ----------\n1024         name : str\n1025             The name of the colormap.\n1026         colors : array-like of colors or array-like of (value, color)\n1027             If only colors are given, they are equidistantly mapped from the\n1028             range :math:`[0, 1]`; i.e. 0 maps to ``colors[0]`` and 1 maps to\n1029             ``colors[-1]``.\n1030             If (value, color) pairs are given, the mapping is from *value*\n1031             to *color*. This can be used to divide the range unevenly.\n1032         N : int\n1033             The number of RGB quantization levels.\n1034         gamma : float\n1035         \"\"\"\n1036         if not np.iterable(colors):\n1037             raise ValueError('colors must be iterable')\n1038 \n1039         if (isinstance(colors[0], Sized) and len(colors[0]) == 2\n1040                 and not isinstance(colors[0], str)):\n1041             # List of value, color pairs\n1042             vals, colors = zip(*colors)\n1043         else:\n1044             vals = np.linspace(0, 1, len(colors))\n1045 \n1046         r, g, b, a = to_rgba_array(colors).T\n1047         cdict = {\n1048             \"red\": np.column_stack([vals, r, r]),\n1049             \"green\": np.column_stack([vals, g, g]),\n1050             \"blue\": np.column_stack([vals, b, b]),\n1051             \"alpha\": np.column_stack([vals, a, a]),\n1052         }\n1053 \n1054         return LinearSegmentedColormap(name, cdict, N, gamma)\n1055 \n1056     def resampled(self, lutsize):\n1057         \"\"\"Return a new colormap with *lutsize* entries.\"\"\"\n1058         new_cmap = LinearSegmentedColormap(self.name, self._segmentdata,\n1059                                            lutsize)\n1060         new_cmap._rgba_over = self._rgba_over\n1061         new_cmap._rgba_under = self._rgba_under\n1062         new_cmap._rgba_bad = self._rgba_bad\n1063         return new_cmap\n1064 \n1065     # Helper ensuring picklability of the reversed cmap.\n1066     @staticmethod\n1067     def _reverser(func, x):\n1068         return func(1 - x)\n1069 \n1070     def reversed(self, name=None):\n1071         \"\"\"\n1072         Return a reversed instance of the Colormap.\n1073 \n1074         Parameters\n1075         ----------\n1076         name : str, optional\n1077             The name for the reversed colormap. If None, the\n1078             name is set to ``self.name + \"_r\"``.\n1079 \n1080         Returns\n1081         -------\n1082         LinearSegmentedColormap\n1083             The reversed colormap.\n1084         \"\"\"\n1085         if name is None:\n1086             name = self.name + \"_r\"\n1087 \n1088         # Using a partial object keeps the cmap picklable.\n1089         data_r = {key: (functools.partial(self._reverser, data)\n1090                         if callable(data) else\n1091                         [(1.0 - x, y1, y0) for x, y0, y1 in reversed(data)])\n1092                   for key, data in self._segmentdata.items()}\n1093 \n1094         new_cmap = LinearSegmentedColormap(name, data_r, self.N, self._gamma)\n1095         # Reverse the over/under values too\n1096         new_cmap._rgba_over = self._rgba_under\n1097         new_cmap._rgba_under = self._rgba_over\n1098         new_cmap._rgba_bad = self._rgba_bad\n1099         return new_cmap\n1100 \n1101 \n1102 class ListedColormap(Colormap):\n1103     \"\"\"\n1104     Colormap object generated from a list of colors.\n1105 \n1106     This may be most useful when indexing directly into a colormap,\n1107     but it can also be used to generate special colormaps for ordinary\n1108     mapping.\n1109 \n1110     Parameters\n1111     ----------\n1112     colors : list, array\n1113         List of Matplotlib color specifications, or an equivalent Nx3 or Nx4\n1114         floating point array (*N* RGB or RGBA values).\n1115     name : str, optional\n1116         String to identify the colormap.\n1117     N : int, optional\n1118         Number of entries in the map. The default is *None*, in which case\n1119         there is one colormap entry for each element in the list of colors.\n1120         If ::\n1121 \n1122             N < len(colors)\n1123 \n1124         the list will be truncated at *N*. If ::\n1125 \n1126             N > len(colors)\n1127 \n1128         the list will be extended by repetition.\n1129     \"\"\"\n1130     def __init__(self, colors, name='from_list', N=None):\n1131         self.monochrome = False  # Are all colors identical? (for contour.py)\n1132         if N is None:\n1133             self.colors = colors\n1134             N = len(colors)\n1135         else:\n1136             if isinstance(colors, str):\n1137                 self.colors = [colors] * N\n1138                 self.monochrome = True\n1139             elif np.iterable(colors):\n1140                 if len(colors) == 1:\n1141                     self.monochrome = True\n1142                 self.colors = list(\n1143                     itertools.islice(itertools.cycle(colors), N))\n1144             else:\n1145                 try:\n1146                     gray = float(colors)\n1147                 except TypeError:\n1148                     pass\n1149                 else:\n1150                     self.colors = [gray] * N\n1151                 self.monochrome = True\n1152         super().__init__(name, N)\n1153 \n1154     def _init(self):\n1155         self._lut = np.zeros((self.N + 3, 4), float)\n1156         self._lut[:-3] = to_rgba_array(self.colors)\n1157         self._isinit = True\n1158         self._set_extremes()\n1159 \n1160     def resampled(self, lutsize):\n1161         \"\"\"Return a new colormap with *lutsize* entries.\"\"\"\n1162         colors = self(np.linspace(0, 1, lutsize))\n1163         new_cmap = ListedColormap(colors, name=self.name)\n1164         # Keep the over/under values too\n1165         new_cmap._rgba_over = self._rgba_over\n1166         new_cmap._rgba_under = self._rgba_under\n1167         new_cmap._rgba_bad = self._rgba_bad\n1168         return new_cmap\n1169 \n1170     def reversed(self, name=None):\n1171         \"\"\"\n1172         Return a reversed instance of the Colormap.\n1173 \n1174         Parameters\n1175         ----------\n1176         name : str, optional\n1177             The name for the reversed colormap. If None, the\n1178             name is set to ``self.name + \"_r\"``.\n1179 \n1180         Returns\n1181         -------\n1182         ListedColormap\n1183             A reversed instance of the colormap.\n1184         \"\"\"\n1185         if name is None:\n1186             name = self.name + \"_r\"\n1187 \n1188         colors_r = list(reversed(self.colors))\n1189         new_cmap = ListedColormap(colors_r, name=name, N=self.N)\n1190         # Reverse the over/under values too\n1191         new_cmap._rgba_over = self._rgba_under\n1192         new_cmap._rgba_under = self._rgba_over\n1193         new_cmap._rgba_bad = self._rgba_bad\n1194         return new_cmap\n1195 \n1196 \n1197 class Normalize:\n1198     \"\"\"\n1199     A class which, when called, linearly normalizes data into the\n1200     ``[0.0, 1.0]`` interval.\n1201     \"\"\"\n1202 \n1203     def __init__(self, vmin=None, vmax=None, clip=False):\n1204         \"\"\"\n1205         Parameters\n1206         ----------\n1207         vmin, vmax : float or None\n1208             If *vmin* and/or *vmax* is not given, they are initialized from the\n1209             minimum and maximum value, respectively, of the first input\n1210             processed; i.e., ``__call__(A)`` calls ``autoscale_None(A)``.\n1211 \n1212         clip : bool, default: False\n1213             If ``True`` values falling outside the range ``[vmin, vmax]``,\n1214             are mapped to 0 or 1, whichever is closer, and masked values are\n1215             set to 1.  If ``False`` masked values remain masked.\n1216 \n1217             Clipping silently defeats the purpose of setting the over, under,\n1218             and masked colors in a colormap, so it is likely to lead to\n1219             surprises; therefore the default is ``clip=False``.\n1220 \n1221         Notes\n1222         -----\n1223         Returns 0 if ``vmin == vmax``.\n1224         \"\"\"\n1225         self._vmin = _sanitize_extrema(vmin)\n1226         self._vmax = _sanitize_extrema(vmax)\n1227         self._clip = clip\n1228         self._scale = None\n1229         self.callbacks = cbook.CallbackRegistry(signals=[\"changed\"])\n1230 \n1231     @property\n1232     def vmin(self):\n1233         return self._vmin\n1234 \n1235     @vmin.setter\n1236     def vmin(self, value):\n1237         value = _sanitize_extrema(value)\n1238         if value != self._vmin:\n1239             self._vmin = value\n1240             self._changed()\n1241 \n1242     @property\n1243     def vmax(self):\n1244         return self._vmax\n1245 \n1246     @vmax.setter\n1247     def vmax(self, value):\n1248         value = _sanitize_extrema(value)\n1249         if value != self._vmax:\n1250             self._vmax = value\n1251             self._changed()\n1252 \n1253     @property\n1254     def clip(self):\n1255         return self._clip\n1256 \n1257     @clip.setter\n1258     def clip(self, value):\n1259         if value != self._clip:\n1260             self._clip = value\n1261             self._changed()\n1262 \n1263     def _changed(self):\n1264         \"\"\"\n1265         Call this whenever the norm is changed to notify all the\n1266         callback listeners to the 'changed' signal.\n1267         \"\"\"\n1268         self.callbacks.process('changed')\n1269 \n1270     @staticmethod\n1271     def process_value(value):\n1272         \"\"\"\n1273         Homogenize the input *value* for easy and efficient normalization.\n1274 \n1275         *value* can be a scalar or sequence.\n1276 \n1277         Returns\n1278         -------\n1279         result : masked array\n1280             Masked array with the same shape as *value*.\n1281         is_scalar : bool\n1282             Whether *value* is a scalar.\n1283 \n1284         Notes\n1285         -----\n1286         Float dtypes are preserved; integer types with two bytes or smaller are\n1287         converted to np.float32, and larger types are converted to np.float64.\n1288         Preserving float32 when possible, and using in-place operations,\n1289         greatly improves speed for large arrays.\n1290         \"\"\"\n1291         is_scalar = not np.iterable(value)\n1292         if is_scalar:\n1293             value = [value]\n1294         dtype = np.min_scalar_type(value)\n1295         if np.issubdtype(dtype, np.integer) or dtype.type is np.bool_:\n1296             # bool_/int8/int16 -> float32; int32/int64 -> float64\n1297             dtype = np.promote_types(dtype, np.float32)\n1298         # ensure data passed in as an ndarray subclass are interpreted as\n1299         # an ndarray. See issue #6622.\n1300         mask = np.ma.getmask(value)\n1301         data = np.asarray(value)\n1302         result = np.ma.array(data, mask=mask, dtype=dtype, copy=True)\n1303         return result, is_scalar\n1304 \n1305     def __call__(self, value, clip=None):\n1306         \"\"\"\n1307         Normalize *value* data in the ``[vmin, vmax]`` interval into the\n1308         ``[0.0, 1.0]`` interval and return it.\n1309 \n1310         Parameters\n1311         ----------\n1312         value\n1313             Data to normalize.\n1314         clip : bool\n1315             If ``None``, defaults to ``self.clip`` (which defaults to\n1316             ``False``).\n1317 \n1318         Notes\n1319         -----\n1320         If not already initialized, ``self.vmin`` and ``self.vmax`` are\n1321         initialized using ``self.autoscale_None(value)``.\n1322         \"\"\"\n1323         if clip is None:\n1324             clip = self.clip\n1325 \n1326         result, is_scalar = self.process_value(value)\n1327 \n1328         if self.vmin is None or self.vmax is None:\n1329             self.autoscale_None(result)\n1330         # Convert at least to float, without losing precision.\n1331         (vmin,), _ = self.process_value(self.vmin)\n1332         (vmax,), _ = self.process_value(self.vmax)\n1333         if vmin == vmax:\n1334             result.fill(0)  # Or should it be all masked?  Or 0.5?\n1335         elif vmin > vmax:\n1336             raise ValueError(\"minvalue must be less than or equal to maxvalue\")\n1337         else:\n1338             if clip:\n1339                 mask = np.ma.getmask(result)\n1340                 result = np.ma.array(np.clip(result.filled(vmax), vmin, vmax),\n1341                                      mask=mask)\n1342             # ma division is very slow; we can take a shortcut\n1343             resdat = result.data\n1344             resdat -= vmin\n1345             resdat /= (vmax - vmin)\n1346             result = np.ma.array(resdat, mask=result.mask, copy=False)\n1347         if is_scalar:\n1348             result = result[0]\n1349         return result\n1350 \n1351     def inverse(self, value):\n1352         if not self.scaled():\n1353             raise ValueError(\"Not invertible until both vmin and vmax are set\")\n1354         (vmin,), _ = self.process_value(self.vmin)\n1355         (vmax,), _ = self.process_value(self.vmax)\n1356 \n1357         if np.iterable(value):\n1358             val = np.ma.asarray(value)\n1359             return vmin + val * (vmax - vmin)\n1360         else:\n1361             return vmin + value * (vmax - vmin)\n1362 \n1363     def autoscale(self, A):\n1364         \"\"\"Set *vmin*, *vmax* to min, max of *A*.\"\"\"\n1365         self.vmin = self.vmax = None\n1366         self.autoscale_None(A)\n1367 \n1368     def autoscale_None(self, A):\n1369         \"\"\"If vmin or vmax are not set, use the min/max of *A* to set them.\"\"\"\n1370         A = np.asanyarray(A)\n1371         if self.vmin is None and A.size:\n1372             self.vmin = A.min()\n1373         if self.vmax is None and A.size:\n1374             self.vmax = A.max()\n1375 \n1376     def scaled(self):\n1377         \"\"\"Return whether vmin and vmax are set.\"\"\"\n1378         return self.vmin is not None and self.vmax is not None\n1379 \n1380 \n1381 class TwoSlopeNorm(Normalize):\n1382     def __init__(self, vcenter, vmin=None, vmax=None):\n1383         \"\"\"\n1384         Normalize data with a set center.\n1385 \n1386         Useful when mapping data with an unequal rates of change around a\n1387         conceptual center, e.g., data that range from -2 to 4, with 0 as\n1388         the midpoint.\n1389 \n1390         Parameters\n1391         ----------\n1392         vcenter : float\n1393             The data value that defines ``0.5`` in the normalization.\n1394         vmin : float, optional\n1395             The data value that defines ``0.0`` in the normalization.\n1396             Defaults to the min value of the dataset.\n1397         vmax : float, optional\n1398             The data value that defines ``1.0`` in the normalization.\n1399             Defaults to the max value of the dataset.\n1400 \n1401         Examples\n1402         --------\n1403         This maps data value -4000 to 0., 0 to 0.5, and +10000 to 1.0; data\n1404         between is linearly interpolated::\n1405 \n1406             >>> import matplotlib.colors as mcolors\n1407             >>> offset = mcolors.TwoSlopeNorm(vmin=-4000.,\n1408                                               vcenter=0., vmax=10000)\n1409             >>> data = [-4000., -2000., 0., 2500., 5000., 7500., 10000.]\n1410             >>> offset(data)\n1411             array([0., 0.25, 0.5, 0.625, 0.75, 0.875, 1.0])\n1412         \"\"\"\n1413 \n1414         super().__init__(vmin=vmin, vmax=vmax)\n1415         self._vcenter = vcenter\n1416         if vcenter is not None and vmax is not None and vcenter >= vmax:\n1417             raise ValueError('vmin, vcenter, and vmax must be in '\n1418                              'ascending order')\n1419         if vcenter is not None and vmin is not None and vcenter <= vmin:\n1420             raise ValueError('vmin, vcenter, and vmax must be in '\n1421                              'ascending order')\n1422 \n1423     @property\n1424     def vcenter(self):\n1425         return self._vcenter\n1426 \n1427     @vcenter.setter\n1428     def vcenter(self, value):\n1429         if value != self._vcenter:\n1430             self._vcenter = value\n1431             self._changed()\n1432 \n1433     def autoscale_None(self, A):\n1434         \"\"\"\n1435         Get vmin and vmax.\n1436 \n1437         If vcenter isn't in the range [vmin, vmax], either vmin or vmax\n1438         is expanded so that vcenter lies in the middle of the modified range\n1439         [vmin, vmax].\n1440         \"\"\"\n1441         super().autoscale_None(A)\n1442         if self.vmin >= self.vcenter:\n1443             self.vmin = self.vcenter - (self.vmax - self.vcenter)\n1444         if self.vmax <= self.vcenter:\n1445             self.vmax = self.vcenter + (self.vcenter - self.vmin)\n1446 \n1447     def __call__(self, value, clip=None):\n1448         \"\"\"\n1449         Map value to the interval [0, 1]. The clip argument is unused.\n1450         \"\"\"\n1451         result, is_scalar = self.process_value(value)\n1452         self.autoscale_None(result)  # sets self.vmin, self.vmax if None\n1453 \n1454         if not self.vmin <= self.vcenter <= self.vmax:\n1455             raise ValueError(\"vmin, vcenter, vmax must increase monotonically\")\n1456         # note that we must extrapolate for tick locators:\n1457         result = np.ma.masked_array(\n1458             np.interp(result, [self.vmin, self.vcenter, self.vmax],\n1459                       [0, 0.5, 1], left=-np.inf, right=np.inf),\n1460             mask=np.ma.getmask(result))\n1461         if is_scalar:\n1462             result = np.atleast_1d(result)[0]\n1463         return result\n1464 \n1465     def inverse(self, value):\n1466         if not self.scaled():\n1467             raise ValueError(\"Not invertible until both vmin and vmax are set\")\n1468         (vmin,), _ = self.process_value(self.vmin)\n1469         (vmax,), _ = self.process_value(self.vmax)\n1470         (vcenter,), _ = self.process_value(self.vcenter)\n1471         result = np.interp(value, [0, 0.5, 1], [vmin, vcenter, vmax],\n1472                            left=-np.inf, right=np.inf)\n1473         return result\n1474 \n1475 \n1476 class CenteredNorm(Normalize):\n1477     def __init__(self, vcenter=0, halfrange=None, clip=False):\n1478         \"\"\"\n1479         Normalize symmetrical data around a center (0 by default).\n1480 \n1481         Unlike `TwoSlopeNorm`, `CenteredNorm` applies an equal rate of change\n1482         around the center.\n1483 \n1484         Useful when mapping symmetrical data around a conceptual center\n1485         e.g., data that range from -2 to 4, with 0 as the midpoint, and\n1486         with equal rates of change around that midpoint.\n1487 \n1488         Parameters\n1489         ----------\n1490         vcenter : float, default: 0\n1491             The data value that defines ``0.5`` in the normalization.\n1492         halfrange : float, optional\n1493             The range of data values that defines a range of ``0.5`` in the\n1494             normalization, so that *vcenter* - *halfrange* is ``0.0`` and\n1495             *vcenter* + *halfrange* is ``1.0`` in the normalization.\n1496             Defaults to the largest absolute difference to *vcenter* for\n1497             the values in the dataset.\n1498 \n1499         Examples\n1500         --------\n1501         This maps data values -2 to 0.25, 0 to 0.5, and 4 to 1.0\n1502         (assuming equal rates of change above and below 0.0):\n1503 \n1504             >>> import matplotlib.colors as mcolors\n1505             >>> norm = mcolors.CenteredNorm(halfrange=4.0)\n1506             >>> data = [-2., 0., 4.]\n1507             >>> norm(data)\n1508             array([0.25, 0.5 , 1.  ])\n1509         \"\"\"\n1510         super().__init__(vmin=None, vmax=None, clip=clip)\n1511         self._vcenter = vcenter\n1512         # calling the halfrange setter to set vmin and vmax\n1513         self.halfrange = halfrange\n1514 \n1515     def autoscale(self, A):\n1516         \"\"\"\n1517         Set *halfrange* to ``max(abs(A-vcenter))``, then set *vmin* and *vmax*.\n1518         \"\"\"\n1519         A = np.asanyarray(A)\n1520         self.halfrange = max(self._vcenter-A.min(),\n1521                              A.max()-self._vcenter)\n1522 \n1523     def autoscale_None(self, A):\n1524         \"\"\"Set *vmin* and *vmax*.\"\"\"\n1525         A = np.asanyarray(A)\n1526         if self.halfrange is None and A.size:\n1527             self.autoscale(A)\n1528 \n1529     @property\n1530     def vmin(self):\n1531         return self._vmin\n1532 \n1533     @vmin.setter\n1534     def vmin(self, value):\n1535         value = _sanitize_extrema(value)\n1536         if value != self._vmin:\n1537             self._vmin = value\n1538             self._vmax = 2*self.vcenter - value\n1539             self._changed()\n1540 \n1541     @property\n1542     def vmax(self):\n1543         return self._vmax\n1544 \n1545     @vmax.setter\n1546     def vmax(self, value):\n1547         value = _sanitize_extrema(value)\n1548         if value != self._vmax:\n1549             self._vmax = value\n1550             self._vmin = 2*self.vcenter - value\n1551             self._changed()\n1552 \n1553     @property\n1554     def vcenter(self):\n1555         return self._vcenter\n1556 \n1557     @vcenter.setter\n1558     def vcenter(self, vcenter):\n1559         if vcenter != self._vcenter:\n1560             self._vcenter = vcenter\n1561             # Trigger an update of the vmin/vmax values through the setter\n1562             self.halfrange = self.halfrange\n1563             self._changed()\n1564 \n1565     @property\n1566     def halfrange(self):\n1567         if self.vmin is None or self.vmax is None:\n1568             return None\n1569         return (self.vmax - self.vmin) / 2\n1570 \n1571     @halfrange.setter\n1572     def halfrange(self, halfrange):\n1573         if halfrange is None:\n1574             self.vmin = None\n1575             self.vmax = None\n1576         else:\n1577             self.vmin = self.vcenter - abs(halfrange)\n1578             self.vmax = self.vcenter + abs(halfrange)\n1579 \n1580 \n1581 def make_norm_from_scale(scale_cls, base_norm_cls=None, *, init=None):\n1582     \"\"\"\n1583     Decorator for building a `.Normalize` subclass from a `~.scale.ScaleBase`\n1584     subclass.\n1585 \n1586     After ::\n1587 \n1588         @make_norm_from_scale(scale_cls)\n1589         class norm_cls(Normalize):\n1590             ...\n1591 \n1592     *norm_cls* is filled with methods so that normalization computations are\n1593     forwarded to *scale_cls* (i.e., *scale_cls* is the scale that would be used\n1594     for the colorbar of a mappable normalized with *norm_cls*).\n1595 \n1596     If *init* is not passed, then the constructor signature of *norm_cls*\n1597     will be ``norm_cls(vmin=None, vmax=None, clip=False)``; these three\n1598     parameters will be forwarded to the base class (``Normalize.__init__``),\n1599     and a *scale_cls* object will be initialized with no arguments (other than\n1600     a dummy axis).\n1601 \n1602     If the *scale_cls* constructor takes additional parameters, then *init*\n1603     should be passed to `make_norm_from_scale`.  It is a callable which is\n1604     *only* used for its signature.  First, this signature will become the\n1605     signature of *norm_cls*.  Second, the *norm_cls* constructor will bind the\n1606     parameters passed to it using this signature, extract the bound *vmin*,\n1607     *vmax*, and *clip* values, pass those to ``Normalize.__init__``, and\n1608     forward the remaining bound values (including any defaults defined by the\n1609     signature) to the *scale_cls* constructor.\n1610     \"\"\"\n1611 \n1612     if base_norm_cls is None:\n1613         return functools.partial(make_norm_from_scale, scale_cls, init=init)\n1614 \n1615     if isinstance(scale_cls, functools.partial):\n1616         scale_args = scale_cls.args\n1617         scale_kwargs_items = tuple(scale_cls.keywords.items())\n1618         scale_cls = scale_cls.func\n1619     else:\n1620         scale_args = scale_kwargs_items = ()\n1621 \n1622     if init is None:\n1623         def init(vmin=None, vmax=None, clip=False): pass\n1624 \n1625     return _make_norm_from_scale(\n1626         scale_cls, scale_args, scale_kwargs_items,\n1627         base_norm_cls, inspect.signature(init))\n1628 \n1629 \n1630 @functools.cache\n1631 def _make_norm_from_scale(\n1632     scale_cls, scale_args, scale_kwargs_items,\n1633     base_norm_cls, bound_init_signature,\n1634 ):\n1635     \"\"\"\n1636     Helper for `make_norm_from_scale`.\n1637 \n1638     This function is split out to enable caching (in particular so that\n1639     different unpickles reuse the same class).  In order to do so,\n1640 \n1641     - ``functools.partial`` *scale_cls* is expanded into ``func, args, kwargs``\n1642       to allow memoizing returned norms (partial instances always compare\n1643       unequal, but we can check identity based on ``func, args, kwargs``;\n1644     - *init* is replaced by *init_signature*, as signatures are picklable,\n1645       unlike to arbitrary lambdas.\n1646     \"\"\"\n1647 \n1648     class Norm(base_norm_cls):\n1649         def __reduce__(self):\n1650             cls = type(self)\n1651             # If the class is toplevel-accessible, it is possible to directly\n1652             # pickle it \"by name\".  This is required to support norm classes\n1653             # defined at a module's toplevel, as the inner base_norm_cls is\n1654             # otherwise unpicklable (as it gets shadowed by the generated norm\n1655             # class).  If either import or attribute access fails, fall back to\n1656             # the general path.\n1657             try:\n1658                 if cls is getattr(importlib.import_module(cls.__module__),\n1659                                   cls.__qualname__):\n1660                     return (_create_empty_object_of_class, (cls,), vars(self))\n1661             except (ImportError, AttributeError):\n1662                 pass\n1663             return (_picklable_norm_constructor,\n1664                     (scale_cls, scale_args, scale_kwargs_items,\n1665                      base_norm_cls, bound_init_signature),\n1666                     vars(self))\n1667 \n1668         def __init__(self, *args, **kwargs):\n1669             ba = bound_init_signature.bind(*args, **kwargs)\n1670             ba.apply_defaults()\n1671             super().__init__(\n1672                 **{k: ba.arguments.pop(k) for k in [\"vmin\", \"vmax\", \"clip\"]})\n1673             self._scale = functools.partial(\n1674                 scale_cls, *scale_args, **dict(scale_kwargs_items))(\n1675                     axis=None, **ba.arguments)\n1676             self._trf = self._scale.get_transform()\n1677 \n1678         __init__.__signature__ = bound_init_signature.replace(parameters=[\n1679             inspect.Parameter(\"self\", inspect.Parameter.POSITIONAL_OR_KEYWORD),\n1680             *bound_init_signature.parameters.values()])\n1681 \n1682         def __call__(self, value, clip=None):\n1683             value, is_scalar = self.process_value(value)\n1684             if self.vmin is None or self.vmax is None:\n1685                 self.autoscale_None(value)\n1686             if self.vmin > self.vmax:\n1687                 raise ValueError(\"vmin must be less or equal to vmax\")\n1688             if self.vmin == self.vmax:\n1689                 return np.full_like(value, 0)\n1690             if clip is None:\n1691                 clip = self.clip\n1692             if clip:\n1693                 value = np.clip(value, self.vmin, self.vmax)\n1694             t_value = self._trf.transform(value).reshape(np.shape(value))\n1695             t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n1696             if not np.isfinite([t_vmin, t_vmax]).all():\n1697                 raise ValueError(\"Invalid vmin or vmax\")\n1698             t_value -= t_vmin\n1699             t_value /= (t_vmax - t_vmin)\n1700             t_value = np.ma.masked_invalid(t_value, copy=False)\n1701             return t_value[0] if is_scalar else t_value\n1702 \n1703         def inverse(self, value):\n1704             if not self.scaled():\n1705                 raise ValueError(\"Not invertible until scaled\")\n1706             if self.vmin > self.vmax:\n1707                 raise ValueError(\"vmin must be less or equal to vmax\")\n1708             t_vmin, t_vmax = self._trf.transform([self.vmin, self.vmax])\n1709             if not np.isfinite([t_vmin, t_vmax]).all():\n1710                 raise ValueError(\"Invalid vmin or vmax\")\n1711             value, is_scalar = self.process_value(value)\n1712             rescaled = value * (t_vmax - t_vmin)\n1713             rescaled += t_vmin\n1714             value = (self._trf\n1715                      .inverted()\n1716                      .transform(rescaled)\n1717                      .reshape(np.shape(value)))\n1718             return value[0] if is_scalar else value\n1719 \n1720         def autoscale_None(self, A):\n1721             # i.e. A[np.isfinite(...)], but also for non-array A's\n1722             in_trf_domain = np.extract(np.isfinite(self._trf.transform(A)), A)\n1723             if in_trf_domain.size == 0:\n1724                 in_trf_domain = np.ma.masked\n1725             return super().autoscale_None(in_trf_domain)\n1726 \n1727     if base_norm_cls is Normalize:\n1728         Norm.__name__ = f\"{scale_cls.__name__}Norm\"\n1729         Norm.__qualname__ = f\"{scale_cls.__qualname__}Norm\"\n1730     else:\n1731         Norm.__name__ = base_norm_cls.__name__\n1732         Norm.__qualname__ = base_norm_cls.__qualname__\n1733     Norm.__module__ = base_norm_cls.__module__\n1734     Norm.__doc__ = base_norm_cls.__doc__\n1735 \n1736     return Norm\n1737 \n1738 \n1739 def _create_empty_object_of_class(cls):\n1740     return cls.__new__(cls)\n1741 \n1742 \n1743 def _picklable_norm_constructor(*args):\n1744     return _create_empty_object_of_class(_make_norm_from_scale(*args))\n1745 \n1746 \n1747 @make_norm_from_scale(\n1748     scale.FuncScale,\n1749     init=lambda functions, vmin=None, vmax=None, clip=False: None)\n1750 class FuncNorm(Normalize):\n1751     \"\"\"\n1752     Arbitrary normalization using functions for the forward and inverse.\n1753 \n1754     Parameters\n1755     ----------\n1756     functions : (callable, callable)\n1757         two-tuple of the forward and inverse functions for the normalization.\n1758         The forward function must be monotonic.\n1759 \n1760         Both functions must have the signature ::\n1761 \n1762            def forward(values: array-like) -> array-like\n1763 \n1764     vmin, vmax : float or None\n1765         If *vmin* and/or *vmax* is not given, they are initialized from the\n1766         minimum and maximum value, respectively, of the first input\n1767         processed; i.e., ``__call__(A)`` calls ``autoscale_None(A)``.\n1768 \n1769     clip : bool, default: False\n1770         If ``True`` values falling outside the range ``[vmin, vmax]``,\n1771         are mapped to 0 or 1, whichever is closer, and masked values are\n1772         set to 1.  If ``False`` masked values remain masked.\n1773 \n1774         Clipping silently defeats the purpose of setting the over, under,\n1775         and masked colors in a colormap, so it is likely to lead to\n1776         surprises; therefore the default is ``clip=False``.\n1777     \"\"\"\n1778 \n1779 \n1780 LogNorm = make_norm_from_scale(\n1781     functools.partial(scale.LogScale, nonpositive=\"mask\"))(Normalize)\n1782 LogNorm.__name__ = LogNorm.__qualname__ = \"LogNorm\"\n1783 LogNorm.__doc__ = \"Normalize a given value to the 0-1 range on a log scale.\"\n1784 \n1785 \n1786 @make_norm_from_scale(\n1787     scale.SymmetricalLogScale,\n1788     init=lambda linthresh, linscale=1., vmin=None, vmax=None, clip=False, *,\n1789                 base=10: None)\n1790 class SymLogNorm(Normalize):\n1791     \"\"\"\n1792     The symmetrical logarithmic scale is logarithmic in both the\n1793     positive and negative directions from the origin.\n1794 \n1795     Since the values close to zero tend toward infinity, there is a\n1796     need to have a range around zero that is linear.  The parameter\n1797     *linthresh* allows the user to specify the size of this range\n1798     (-*linthresh*, *linthresh*).\n1799 \n1800     Parameters\n1801     ----------\n1802     linthresh : float\n1803         The range within which the plot is linear (to avoid having the plot\n1804         go to infinity around zero).\n1805     linscale : float, default: 1\n1806         This allows the linear range (-*linthresh* to *linthresh*) to be\n1807         stretched relative to the logarithmic range. Its value is the\n1808         number of decades to use for each half of the linear range. For\n1809         example, when *linscale* == 1.0 (the default), the space used for\n1810         the positive and negative halves of the linear range will be equal\n1811         to one decade in the logarithmic range.\n1812     base : float, default: 10\n1813     \"\"\"\n1814 \n1815     @property\n1816     def linthresh(self):\n1817         return self._scale.linthresh\n1818 \n1819     @linthresh.setter\n1820     def linthresh(self, value):\n1821         self._scale.linthresh = value\n1822 \n1823 \n1824 @make_norm_from_scale(\n1825     scale.AsinhScale,\n1826     init=lambda linear_width=1, vmin=None, vmax=None, clip=False: None)\n1827 class AsinhNorm(Normalize):\n1828     \"\"\"\n1829     The inverse hyperbolic sine scale is approximately linear near\n1830     the origin, but becomes logarithmic for larger positive\n1831     or negative values. Unlike the `SymLogNorm`, the transition between\n1832     these linear and logarithmic regions is smooth, which may reduce\n1833     the risk of visual artifacts.\n1834 \n1835     .. note::\n1836 \n1837        This API is provisional and may be revised in the future\n1838        based on early user feedback.\n1839 \n1840     Parameters\n1841     ----------\n1842     linear_width : float, default: 1\n1843         The effective width of the linear region, beyond which\n1844         the transformation becomes asymptotically logarithmic\n1845     \"\"\"\n1846 \n1847     @property\n1848     def linear_width(self):\n1849         return self._scale.linear_width\n1850 \n1851     @linear_width.setter\n1852     def linear_width(self, value):\n1853         self._scale.linear_width = value\n1854 \n1855 \n1856 class PowerNorm(Normalize):\n1857     \"\"\"\n1858     Linearly map a given value to the 0-1 range and then apply\n1859     a power-law normalization over that range.\n1860     \"\"\"\n1861     def __init__(self, gamma, vmin=None, vmax=None, clip=False):\n1862         super().__init__(vmin, vmax, clip)\n1863         self.gamma = gamma\n1864 \n1865     def __call__(self, value, clip=None):\n1866         if clip is None:\n1867             clip = self.clip\n1868 \n1869         result, is_scalar = self.process_value(value)\n1870 \n1871         self.autoscale_None(result)\n1872         gamma = self.gamma\n1873         vmin, vmax = self.vmin, self.vmax\n1874         if vmin > vmax:\n1875             raise ValueError(\"minvalue must be less than or equal to maxvalue\")\n1876         elif vmin == vmax:\n1877             result.fill(0)\n1878         else:\n1879             if clip:\n1880                 mask = np.ma.getmask(result)\n1881                 result = np.ma.array(np.clip(result.filled(vmax), vmin, vmax),\n1882                                      mask=mask)\n1883             resdat = result.data\n1884             resdat -= vmin\n1885             resdat[resdat < 0] = 0\n1886             np.power(resdat, gamma, resdat)\n1887             resdat /= (vmax - vmin) ** gamma\n1888 \n1889             result = np.ma.array(resdat, mask=result.mask, copy=False)\n1890         if is_scalar:\n1891             result = result[0]\n1892         return result\n1893 \n1894     def inverse(self, value):\n1895         if not self.scaled():\n1896             raise ValueError(\"Not invertible until scaled\")\n1897         gamma = self.gamma\n1898         vmin, vmax = self.vmin, self.vmax\n1899 \n1900         if np.iterable(value):\n1901             val = np.ma.asarray(value)\n1902             return np.ma.power(val, 1. / gamma) * (vmax - vmin) + vmin\n1903         else:\n1904             return pow(value, 1. / gamma) * (vmax - vmin) + vmin\n1905 \n1906 \n1907 class BoundaryNorm(Normalize):\n1908     \"\"\"\n1909     Generate a colormap index based on discrete intervals.\n1910 \n1911     Unlike `Normalize` or `LogNorm`, `BoundaryNorm` maps values to integers\n1912     instead of to the interval 0-1.\n1913     \"\"\"\n1914 \n1915     # Mapping to the 0-1 interval could have been done via piece-wise linear\n1916     # interpolation, but using integers seems simpler, and reduces the number\n1917     # of conversions back and forth between int and float.\n1918 \n1919     def __init__(self, boundaries, ncolors, clip=False, *, extend='neither'):\n1920         \"\"\"\n1921         Parameters\n1922         ----------\n1923         boundaries : array-like\n1924             Monotonically increasing sequence of at least 2 bin edges:  data\n1925             falling in the n-th bin will be mapped to the n-th color.\n1926 \n1927         ncolors : int\n1928             Number of colors in the colormap to be used.\n1929 \n1930         clip : bool, optional\n1931             If clip is ``True``, out of range values are mapped to 0 if they\n1932             are below ``boundaries[0]`` or mapped to ``ncolors - 1`` if they\n1933             are above ``boundaries[-1]``.\n1934 \n1935             If clip is ``False``, out of range values are mapped to -1 if\n1936             they are below ``boundaries[0]`` or mapped to *ncolors* if they are\n1937             above ``boundaries[-1]``. These are then converted to valid indices\n1938             by `Colormap.__call__`.\n1939 \n1940         extend : {'neither', 'both', 'min', 'max'}, default: 'neither'\n1941             Extend the number of bins to include one or both of the\n1942             regions beyond the boundaries.  For example, if ``extend``\n1943             is 'min', then the color to which the region between the first\n1944             pair of boundaries is mapped will be distinct from the first\n1945             color in the colormap, and by default a\n1946             `~matplotlib.colorbar.Colorbar` will be drawn with\n1947             the triangle extension on the left or lower end.\n1948 \n1949         Notes\n1950         -----\n1951         If there are fewer bins (including extensions) than colors, then the\n1952         color index is chosen by linearly interpolating the ``[0, nbins - 1]``\n1953         range onto the ``[0, ncolors - 1]`` range, effectively skipping some\n1954         colors in the middle of the colormap.\n1955         \"\"\"\n1956         if clip and extend != 'neither':\n1957             raise ValueError(\"'clip=True' is not compatible with 'extend'\")\n1958         super().__init__(vmin=boundaries[0], vmax=boundaries[-1], clip=clip)\n1959         self.boundaries = np.asarray(boundaries)\n1960         self.N = len(self.boundaries)\n1961         if self.N < 2:\n1962             raise ValueError(\"You must provide at least 2 boundaries \"\n1963                              f\"(1 region) but you passed in {boundaries!r}\")\n1964         self.Ncmap = ncolors\n1965         self.extend = extend\n1966 \n1967         self._scale = None  # don't use the default scale.\n1968 \n1969         self._n_regions = self.N - 1  # number of colors needed\n1970         self._offset = 0\n1971         if extend in ('min', 'both'):\n1972             self._n_regions += 1\n1973             self._offset = 1\n1974         if extend in ('max', 'both'):\n1975             self._n_regions += 1\n1976         if self._n_regions > self.Ncmap:\n1977             raise ValueError(f\"There are {self._n_regions} color bins \"\n1978                              \"including extensions, but ncolors = \"\n1979                              f\"{ncolors}; ncolors must equal or exceed the \"\n1980                              \"number of bins\")\n1981 \n1982     def __call__(self, value, clip=None):\n1983         \"\"\"\n1984         This method behaves similarly to `.Normalize.__call__`, except that it\n1985         returns integers or arrays of int16.\n1986         \"\"\"\n1987         if clip is None:\n1988             clip = self.clip\n1989 \n1990         xx, is_scalar = self.process_value(value)\n1991         mask = np.ma.getmaskarray(xx)\n1992         # Fill masked values a value above the upper boundary\n1993         xx = np.atleast_1d(xx.filled(self.vmax + 1))\n1994         if clip:\n1995             np.clip(xx, self.vmin, self.vmax, out=xx)\n1996             max_col = self.Ncmap - 1\n1997         else:\n1998             max_col = self.Ncmap\n1999         # this gives us the bins in the lookup table in the range\n2000         # [0, _n_regions - 1]  (the offset is set in the init)\n2001         iret = np.digitize(xx, self.boundaries) - 1 + self._offset\n2002         # if we have more colors than regions, stretch the region\n2003         # index computed above to full range of the color bins.  This\n2004         # will make use of the full range (but skip some of the colors\n2005         # in the middle) such that the first region is mapped to the\n2006         # first color and the last region is mapped to the last color.\n2007         if self.Ncmap > self._n_regions:\n2008             if self._n_regions == 1:\n2009                 # special case the 1 region case, pick the middle color\n2010                 iret[iret == 0] = (self.Ncmap - 1) // 2\n2011             else:\n2012                 # otherwise linearly remap the values from the region index\n2013                 # to the color index spaces\n2014                 iret = (self.Ncmap - 1) / (self._n_regions - 1) * iret\n2015         # cast to 16bit integers in all cases\n2016         iret = iret.astype(np.int16)\n2017         iret[xx < self.vmin] = -1\n2018         iret[xx >= self.vmax] = max_col\n2019         ret = np.ma.array(iret, mask=mask)\n2020         if is_scalar:\n2021             ret = int(ret[0])  # assume python scalar\n2022         return ret\n2023 \n2024     def inverse(self, value):\n2025         \"\"\"\n2026         Raises\n2027         ------\n2028         ValueError\n2029             BoundaryNorm is not invertible, so calling this method will always\n2030             raise an error\n2031         \"\"\"\n2032         raise ValueError(\"BoundaryNorm is not invertible\")\n2033 \n2034 \n2035 class NoNorm(Normalize):\n2036     \"\"\"\n2037     Dummy replacement for `Normalize`, for the case where we want to use\n2038     indices directly in a `~matplotlib.cm.ScalarMappable`.\n2039     \"\"\"\n2040     def __call__(self, value, clip=None):\n2041         return value\n2042 \n2043     def inverse(self, value):\n2044         return value\n2045 \n2046 \n2047 def rgb_to_hsv(arr):\n2048     \"\"\"\n2049     Convert float RGB values (in the range [0, 1]), in a numpy array to HSV\n2050     values.\n2051 \n2052     Parameters\n2053     ----------\n2054     arr : (..., 3) array-like\n2055        All values must be in the range [0, 1]\n2056 \n2057     Returns\n2058     -------\n2059     (..., 3) `~numpy.ndarray`\n2060        Colors converted to HSV values in range [0, 1]\n2061     \"\"\"\n2062     arr = np.asarray(arr)\n2063 \n2064     # check length of the last dimension, should be _some_ sort of rgb\n2065     if arr.shape[-1] != 3:\n2066         raise ValueError(\"Last dimension of input array must be 3; \"\n2067                          f\"shape {arr.shape} was found.\")\n2068 \n2069     in_shape = arr.shape\n2070     arr = np.array(\n2071         arr, copy=False,\n2072         dtype=np.promote_types(arr.dtype, np.float32),  # Don't work on ints.\n2073         ndmin=2,  # In case input was 1D.\n2074     )\n2075     out = np.zeros_like(arr)\n2076     arr_max = arr.max(-1)\n2077     ipos = arr_max > 0\n2078     delta = arr.ptp(-1)\n2079     s = np.zeros_like(delta)\n2080     s[ipos] = delta[ipos] / arr_max[ipos]\n2081     ipos = delta > 0\n2082     # red is max\n2083     idx = (arr[..., 0] == arr_max) & ipos\n2084     out[idx, 0] = (arr[idx, 1] - arr[idx, 2]) / delta[idx]\n2085     # green is max\n2086     idx = (arr[..., 1] == arr_max) & ipos\n2087     out[idx, 0] = 2. + (arr[idx, 2] - arr[idx, 0]) / delta[idx]\n2088     # blue is max\n2089     idx = (arr[..., 2] == arr_max) & ipos\n2090     out[idx, 0] = 4. + (arr[idx, 0] - arr[idx, 1]) / delta[idx]\n2091 \n2092     out[..., 0] = (out[..., 0] / 6.0) % 1.0\n2093     out[..., 1] = s\n2094     out[..., 2] = arr_max\n2095 \n2096     return out.reshape(in_shape)\n2097 \n2098 \n2099 def hsv_to_rgb(hsv):\n2100     \"\"\"\n2101     Convert HSV values to RGB.\n2102 \n2103     Parameters\n2104     ----------\n2105     hsv : (..., 3) array-like\n2106        All values assumed to be in range [0, 1]\n2107 \n2108     Returns\n2109     -------\n2110     (..., 3) `~numpy.ndarray`\n2111        Colors converted to RGB values in range [0, 1]\n2112     \"\"\"\n2113     hsv = np.asarray(hsv)\n2114 \n2115     # check length of the last dimension, should be _some_ sort of rgb\n2116     if hsv.shape[-1] != 3:\n2117         raise ValueError(\"Last dimension of input array must be 3; \"\n2118                          f\"shape {hsv.shape} was found.\")\n2119 \n2120     in_shape = hsv.shape\n2121     hsv = np.array(\n2122         hsv, copy=False,\n2123         dtype=np.promote_types(hsv.dtype, np.float32),  # Don't work on ints.\n2124         ndmin=2,  # In case input was 1D.\n2125     )\n2126 \n2127     h = hsv[..., 0]\n2128     s = hsv[..., 1]\n2129     v = hsv[..., 2]\n2130 \n2131     r = np.empty_like(h)\n2132     g = np.empty_like(h)\n2133     b = np.empty_like(h)\n2134 \n2135     i = (h * 6.0).astype(int)\n2136     f = (h * 6.0) - i\n2137     p = v * (1.0 - s)\n2138     q = v * (1.0 - s * f)\n2139     t = v * (1.0 - s * (1.0 - f))\n2140 \n2141     idx = i % 6 == 0\n2142     r[idx] = v[idx]\n2143     g[idx] = t[idx]\n2144     b[idx] = p[idx]\n2145 \n2146     idx = i == 1\n2147     r[idx] = q[idx]\n2148     g[idx] = v[idx]\n2149     b[idx] = p[idx]\n2150 \n2151     idx = i == 2\n2152     r[idx] = p[idx]\n2153     g[idx] = v[idx]\n2154     b[idx] = t[idx]\n2155 \n2156     idx = i == 3\n2157     r[idx] = p[idx]\n2158     g[idx] = q[idx]\n2159     b[idx] = v[idx]\n2160 \n2161     idx = i == 4\n2162     r[idx] = t[idx]\n2163     g[idx] = p[idx]\n2164     b[idx] = v[idx]\n2165 \n2166     idx = i == 5\n2167     r[idx] = v[idx]\n2168     g[idx] = p[idx]\n2169     b[idx] = q[idx]\n2170 \n2171     idx = s == 0\n2172     r[idx] = v[idx]\n2173     g[idx] = v[idx]\n2174     b[idx] = v[idx]\n2175 \n2176     rgb = np.stack([r, g, b], axis=-1)\n2177 \n2178     return rgb.reshape(in_shape)\n2179 \n2180 \n2181 def _vector_magnitude(arr):\n2182     # things that don't work here:\n2183     #  * np.linalg.norm: drops mask from ma.array\n2184     #  * np.sum: drops mask from ma.array unless entire vector is masked\n2185     sum_sq = 0\n2186     for i in range(arr.shape[-1]):\n2187         sum_sq += arr[..., i, np.newaxis] ** 2\n2188     return np.sqrt(sum_sq)\n2189 \n2190 \n2191 class LightSource:\n2192     \"\"\"\n2193     Create a light source coming from the specified azimuth and elevation.\n2194     Angles are in degrees, with the azimuth measured\n2195     clockwise from north and elevation up from the zero plane of the surface.\n2196 \n2197     `shade` is used to produce \"shaded\" RGB values for a data array.\n2198     `shade_rgb` can be used to combine an RGB image with an elevation map.\n2199     `hillshade` produces an illumination map of a surface.\n2200     \"\"\"\n2201 \n2202     def __init__(self, azdeg=315, altdeg=45, hsv_min_val=0, hsv_max_val=1,\n2203                  hsv_min_sat=1, hsv_max_sat=0):\n2204         \"\"\"\n2205         Specify the azimuth (measured clockwise from south) and altitude\n2206         (measured up from the plane of the surface) of the light source\n2207         in degrees.\n2208 \n2209         Parameters\n2210         ----------\n2211         azdeg : float, default: 315 degrees (from the northwest)\n2212             The azimuth (0-360, degrees clockwise from North) of the light\n2213             source.\n2214         altdeg : float, default: 45 degrees\n2215             The altitude (0-90, degrees up from horizontal) of the light\n2216             source.\n2217 \n2218         Notes\n2219         -----\n2220         For backwards compatibility, the parameters *hsv_min_val*,\n2221         *hsv_max_val*, *hsv_min_sat*, and *hsv_max_sat* may be supplied at\n2222         initialization as well.  However, these parameters will only be used if\n2223         \"blend_mode='hsv'\" is passed into `shade` or `shade_rgb`.\n2224         See the documentation for `blend_hsv` for more details.\n2225         \"\"\"\n2226         self.azdeg = azdeg\n2227         self.altdeg = altdeg\n2228         self.hsv_min_val = hsv_min_val\n2229         self.hsv_max_val = hsv_max_val\n2230         self.hsv_min_sat = hsv_min_sat\n2231         self.hsv_max_sat = hsv_max_sat\n2232 \n2233     @property\n2234     def direction(self):\n2235         \"\"\"The unit vector direction towards the light source.\"\"\"\n2236         # Azimuth is in degrees clockwise from North. Convert to radians\n2237         # counterclockwise from East (mathematical notation).\n2238         az = np.radians(90 - self.azdeg)\n2239         alt = np.radians(self.altdeg)\n2240         return np.array([\n2241             np.cos(az) * np.cos(alt),\n2242             np.sin(az) * np.cos(alt),\n2243             np.sin(alt)\n2244         ])\n2245 \n2246     def hillshade(self, elevation, vert_exag=1, dx=1, dy=1, fraction=1.):\n2247         \"\"\"\n2248         Calculate the illumination intensity for a surface using the defined\n2249         azimuth and elevation for the light source.\n2250 \n2251         This computes the normal vectors for the surface, and then passes them\n2252         on to `shade_normals`\n2253 \n2254         Parameters\n2255         ----------\n2256         elevation : 2D array-like\n2257             The height values used to generate an illumination map\n2258         vert_exag : number, optional\n2259             The amount to exaggerate the elevation values by when calculating\n2260             illumination. This can be used either to correct for differences in\n2261             units between the x-y coordinate system and the elevation\n2262             coordinate system (e.g. decimal degrees vs. meters) or to\n2263             exaggerate or de-emphasize topographic effects.\n2264         dx : number, optional\n2265             The x-spacing (columns) of the input *elevation* grid.\n2266         dy : number, optional\n2267             The y-spacing (rows) of the input *elevation* grid.\n2268         fraction : number, optional\n2269             Increases or decreases the contrast of the hillshade.  Values\n2270             greater than one will cause intermediate values to move closer to\n2271             full illumination or shadow (and clipping any values that move\n2272             beyond 0 or 1). Note that this is not visually or mathematically\n2273             the same as vertical exaggeration.\n2274 \n2275         Returns\n2276         -------\n2277         `~numpy.ndarray`\n2278             A 2D array of illumination values between 0-1, where 0 is\n2279             completely in shadow and 1 is completely illuminated.\n2280         \"\"\"\n2281 \n2282         # Because most image and raster GIS data has the first row in the array\n2283         # as the \"top\" of the image, dy is implicitly negative.  This is\n2284         # consistent to what `imshow` assumes, as well.\n2285         dy = -dy\n2286 \n2287         # compute the normal vectors from the partial derivatives\n2288         e_dy, e_dx = np.gradient(vert_exag * elevation, dy, dx)\n2289 \n2290         # .view is to keep subclasses\n2291         normal = np.empty(elevation.shape + (3,)).view(type(elevation))\n2292         normal[..., 0] = -e_dx\n2293         normal[..., 1] = -e_dy\n2294         normal[..., 2] = 1\n2295         normal /= _vector_magnitude(normal)\n2296 \n2297         return self.shade_normals(normal, fraction)\n2298 \n2299     def shade_normals(self, normals, fraction=1.):\n2300         \"\"\"\n2301         Calculate the illumination intensity for the normal vectors of a\n2302         surface using the defined azimuth and elevation for the light source.\n2303 \n2304         Imagine an artificial sun placed at infinity in some azimuth and\n2305         elevation position illuminating our surface. The parts of the surface\n2306         that slope toward the sun should brighten while those sides facing away\n2307         should become darker.\n2308 \n2309         Parameters\n2310         ----------\n2311         fraction : number, optional\n2312             Increases or decreases the contrast of the hillshade.  Values\n2313             greater than one will cause intermediate values to move closer to\n2314             full illumination or shadow (and clipping any values that move\n2315             beyond 0 or 1). Note that this is not visually or mathematically\n2316             the same as vertical exaggeration.\n2317 \n2318         Returns\n2319         -------\n2320         `~numpy.ndarray`\n2321             A 2D array of illumination values between 0-1, where 0 is\n2322             completely in shadow and 1 is completely illuminated.\n2323         \"\"\"\n2324 \n2325         intensity = normals.dot(self.direction)\n2326 \n2327         # Apply contrast stretch\n2328         imin, imax = intensity.min(), intensity.max()\n2329         intensity *= fraction\n2330 \n2331         # Rescale to 0-1, keeping range before contrast stretch\n2332         # If constant slope, keep relative scaling (i.e. flat should be 0.5,\n2333         # fully occluded 0, etc.)\n2334         if (imax - imin) > 1e-6:\n2335             # Strictly speaking, this is incorrect. Negative values should be\n2336             # clipped to 0 because they're fully occluded. However, rescaling\n2337             # in this manner is consistent with the previous implementation and\n2338             # visually appears better than a \"hard\" clip.\n2339             intensity -= imin\n2340             intensity /= (imax - imin)\n2341         intensity = np.clip(intensity, 0, 1)\n2342 \n2343         return intensity\n2344 \n2345     def shade(self, data, cmap, norm=None, blend_mode='overlay', vmin=None,\n2346               vmax=None, vert_exag=1, dx=1, dy=1, fraction=1, **kwargs):\n2347         \"\"\"\n2348         Combine colormapped data values with an illumination intensity map\n2349         (a.k.a.  \"hillshade\") of the values.\n2350 \n2351         Parameters\n2352         ----------\n2353         data : 2D array-like\n2354             The height values used to generate a shaded map.\n2355         cmap : `~matplotlib.colors.Colormap`\n2356             The colormap used to color the *data* array. Note that this must be\n2357             a `~matplotlib.colors.Colormap` instance.  For example, rather than\n2358             passing in ``cmap='gist_earth'``, use\n2359             ``cmap=plt.get_cmap('gist_earth')`` instead.\n2360         norm : `~matplotlib.colors.Normalize` instance, optional\n2361             The normalization used to scale values before colormapping. If\n2362             None, the input will be linearly scaled between its min and max.\n2363         blend_mode : {'hsv', 'overlay', 'soft'} or callable, optional\n2364             The type of blending used to combine the colormapped data\n2365             values with the illumination intensity.  Default is\n2366             \"overlay\".  Note that for most topographic surfaces,\n2367             \"overlay\" or \"soft\" appear more visually realistic. If a\n2368             user-defined function is supplied, it is expected to\n2369             combine an MxNx3 RGB array of floats (ranging 0 to 1) with\n2370             an MxNx1 hillshade array (also 0 to 1).  (Call signature\n2371             ``func(rgb, illum, **kwargs)``) Additional kwargs supplied\n2372             to this function will be passed on to the *blend_mode*\n2373             function.\n2374         vmin : float or None, optional\n2375             The minimum value used in colormapping *data*. If *None* the\n2376             minimum value in *data* is used. If *norm* is specified, then this\n2377             argument will be ignored.\n2378         vmax : float or None, optional\n2379             The maximum value used in colormapping *data*. If *None* the\n2380             maximum value in *data* is used. If *norm* is specified, then this\n2381             argument will be ignored.\n2382         vert_exag : number, optional\n2383             The amount to exaggerate the elevation values by when calculating\n2384             illumination. This can be used either to correct for differences in\n2385             units between the x-y coordinate system and the elevation\n2386             coordinate system (e.g. decimal degrees vs. meters) or to\n2387             exaggerate or de-emphasize topography.\n2388         dx : number, optional\n2389             The x-spacing (columns) of the input *elevation* grid.\n2390         dy : number, optional\n2391             The y-spacing (rows) of the input *elevation* grid.\n2392         fraction : number, optional\n2393             Increases or decreases the contrast of the hillshade.  Values\n2394             greater than one will cause intermediate values to move closer to\n2395             full illumination or shadow (and clipping any values that move\n2396             beyond 0 or 1). Note that this is not visually or mathematically\n2397             the same as vertical exaggeration.\n2398         Additional kwargs are passed on to the *blend_mode* function.\n2399 \n2400         Returns\n2401         -------\n2402         `~numpy.ndarray`\n2403             An MxNx4 array of floats ranging between 0-1.\n2404         \"\"\"\n2405         if vmin is None:\n2406             vmin = data.min()\n2407         if vmax is None:\n2408             vmax = data.max()\n2409         if norm is None:\n2410             norm = Normalize(vmin=vmin, vmax=vmax)\n2411 \n2412         rgb0 = cmap(norm(data))\n2413         rgb1 = self.shade_rgb(rgb0, elevation=data, blend_mode=blend_mode,\n2414                               vert_exag=vert_exag, dx=dx, dy=dy,\n2415                               fraction=fraction, **kwargs)\n2416         # Don't overwrite the alpha channel, if present.\n2417         rgb0[..., :3] = rgb1[..., :3]\n2418         return rgb0\n2419 \n2420     def shade_rgb(self, rgb, elevation, fraction=1., blend_mode='hsv',\n2421                   vert_exag=1, dx=1, dy=1, **kwargs):\n2422         \"\"\"\n2423         Use this light source to adjust the colors of the *rgb* input array to\n2424         give the impression of a shaded relief map with the given *elevation*.\n2425 \n2426         Parameters\n2427         ----------\n2428         rgb : array-like\n2429             An (M, N, 3) RGB array, assumed to be in the range of 0 to 1.\n2430         elevation : array-like\n2431             An (M, N) array of the height values used to generate a shaded map.\n2432         fraction : number\n2433             Increases or decreases the contrast of the hillshade.  Values\n2434             greater than one will cause intermediate values to move closer to\n2435             full illumination or shadow (and clipping any values that move\n2436             beyond 0 or 1). Note that this is not visually or mathematically\n2437             the same as vertical exaggeration.\n2438         blend_mode : {'hsv', 'overlay', 'soft'} or callable, optional\n2439             The type of blending used to combine the colormapped data values\n2440             with the illumination intensity.  For backwards compatibility, this\n2441             defaults to \"hsv\". Note that for most topographic surfaces,\n2442             \"overlay\" or \"soft\" appear more visually realistic. If a\n2443             user-defined function is supplied, it is expected to combine an\n2444             MxNx3 RGB array of floats (ranging 0 to 1) with an MxNx1 hillshade\n2445             array (also 0 to 1).  (Call signature\n2446             ``func(rgb, illum, **kwargs)``)\n2447             Additional kwargs supplied to this function will be passed on to\n2448             the *blend_mode* function.\n2449         vert_exag : number, optional\n2450             The amount to exaggerate the elevation values by when calculating\n2451             illumination. This can be used either to correct for differences in\n2452             units between the x-y coordinate system and the elevation\n2453             coordinate system (e.g. decimal degrees vs. meters) or to\n2454             exaggerate or de-emphasize topography.\n2455         dx : number, optional\n2456             The x-spacing (columns) of the input *elevation* grid.\n2457         dy : number, optional\n2458             The y-spacing (rows) of the input *elevation* grid.\n2459         Additional kwargs are passed on to the *blend_mode* function.\n2460 \n2461         Returns\n2462         -------\n2463         `~numpy.ndarray`\n2464             An (m, n, 3) array of floats ranging between 0-1.\n2465         \"\"\"\n2466         # Calculate the \"hillshade\" intensity.\n2467         intensity = self.hillshade(elevation, vert_exag, dx, dy, fraction)\n2468         intensity = intensity[..., np.newaxis]\n2469 \n2470         # Blend the hillshade and rgb data using the specified mode\n2471         lookup = {\n2472                 'hsv': self.blend_hsv,\n2473                 'soft': self.blend_soft_light,\n2474                 'overlay': self.blend_overlay,\n2475                 }\n2476         if blend_mode in lookup:\n2477             blend = lookup[blend_mode](rgb, intensity, **kwargs)\n2478         else:\n2479             try:\n2480                 blend = blend_mode(rgb, intensity, **kwargs)\n2481             except TypeError as err:\n2482                 raise ValueError('\"blend_mode\" must be callable or one of '\n2483                                  f'{lookup.keys}') from err\n2484 \n2485         # Only apply result where hillshade intensity isn't masked\n2486         if np.ma.is_masked(intensity):\n2487             mask = intensity.mask[..., 0]\n2488             for i in range(3):\n2489                 blend[..., i][mask] = rgb[..., i][mask]\n2490 \n2491         return blend\n2492 \n2493     def blend_hsv(self, rgb, intensity, hsv_max_sat=None, hsv_max_val=None,\n2494                   hsv_min_val=None, hsv_min_sat=None):\n2495         \"\"\"\n2496         Take the input data array, convert to HSV values in the given colormap,\n2497         then adjust those color values to give the impression of a shaded\n2498         relief map with a specified light source.  RGBA values are returned,\n2499         which can then be used to plot the shaded image with imshow.\n2500 \n2501         The color of the resulting image will be darkened by moving the (s, v)\n2502         values (in HSV colorspace) toward (hsv_min_sat, hsv_min_val) in the\n2503         shaded regions, or lightened by sliding (s, v) toward (hsv_max_sat,\n2504         hsv_max_val) in regions that are illuminated.  The default extremes are\n2505         chose so that completely shaded points are nearly black (s = 1, v = 0)\n2506         and completely illuminated points are nearly white (s = 0, v = 1).\n2507 \n2508         Parameters\n2509         ----------\n2510         rgb : `~numpy.ndarray`\n2511             An MxNx3 RGB array of floats ranging from 0 to 1 (color image).\n2512         intensity : `~numpy.ndarray`\n2513             An MxNx1 array of floats ranging from 0 to 1 (grayscale image).\n2514         hsv_max_sat : number, default: 1\n2515             The maximum saturation value that the *intensity* map can shift the\n2516             output image to.\n2517         hsv_min_sat : number, optional\n2518             The minimum saturation value that the *intensity* map can shift the\n2519             output image to. Defaults to 0.\n2520         hsv_max_val : number, optional\n2521             The maximum value (\"v\" in \"hsv\") that the *intensity* map can shift\n2522             the output image to. Defaults to 1.\n2523         hsv_min_val : number, optional\n2524             The minimum value (\"v\" in \"hsv\") that the *intensity* map can shift\n2525             the output image to. Defaults to 0.\n2526 \n2527         Returns\n2528         -------\n2529         `~numpy.ndarray`\n2530             An MxNx3 RGB array representing the combined images.\n2531         \"\"\"\n2532         # Backward compatibility...\n2533         if hsv_max_sat is None:\n2534             hsv_max_sat = self.hsv_max_sat\n2535         if hsv_max_val is None:\n2536             hsv_max_val = self.hsv_max_val\n2537         if hsv_min_sat is None:\n2538             hsv_min_sat = self.hsv_min_sat\n2539         if hsv_min_val is None:\n2540             hsv_min_val = self.hsv_min_val\n2541 \n2542         # Expects a 2D intensity array scaled between -1 to 1...\n2543         intensity = intensity[..., 0]\n2544         intensity = 2 * intensity - 1\n2545 \n2546         # Convert to rgb, then rgb to hsv\n2547         hsv = rgb_to_hsv(rgb[:, :, 0:3])\n2548         hue, sat, val = np.moveaxis(hsv, -1, 0)\n2549 \n2550         # Modify hsv values (in place) to simulate illumination.\n2551         # putmask(A, mask, B) <=> A[mask] = B[mask]\n2552         np.putmask(sat, (np.abs(sat) > 1.e-10) & (intensity > 0),\n2553                    (1 - intensity) * sat + intensity * hsv_max_sat)\n2554         np.putmask(sat, (np.abs(sat) > 1.e-10) & (intensity < 0),\n2555                    (1 + intensity) * sat - intensity * hsv_min_sat)\n2556         np.putmask(val, intensity > 0,\n2557                    (1 - intensity) * val + intensity * hsv_max_val)\n2558         np.putmask(val, intensity < 0,\n2559                    (1 + intensity) * val - intensity * hsv_min_val)\n2560         np.clip(hsv[:, :, 1:], 0, 1, out=hsv[:, :, 1:])\n2561 \n2562         # Convert modified hsv back to rgb.\n2563         return hsv_to_rgb(hsv)\n2564 \n2565     def blend_soft_light(self, rgb, intensity):\n2566         \"\"\"\n2567         Combine an RGB image with an intensity map using \"soft light\" blending,\n2568         using the \"pegtop\" formula.\n2569 \n2570         Parameters\n2571         ----------\n2572         rgb : `~numpy.ndarray`\n2573             An MxNx3 RGB array of floats ranging from 0 to 1 (color image).\n2574         intensity : `~numpy.ndarray`\n2575             An MxNx1 array of floats ranging from 0 to 1 (grayscale image).\n2576 \n2577         Returns\n2578         -------\n2579         `~numpy.ndarray`\n2580             An MxNx3 RGB array representing the combined images.\n2581         \"\"\"\n2582         return 2 * intensity * rgb + (1 - 2 * intensity) * rgb**2\n2583 \n2584     def blend_overlay(self, rgb, intensity):\n2585         \"\"\"\n2586         Combine an RGB image with an intensity map using \"overlay\" blending.\n2587 \n2588         Parameters\n2589         ----------\n2590         rgb : `~numpy.ndarray`\n2591             An MxNx3 RGB array of floats ranging from 0 to 1 (color image).\n2592         intensity : `~numpy.ndarray`\n2593             An MxNx1 array of floats ranging from 0 to 1 (grayscale image).\n2594 \n2595         Returns\n2596         -------\n2597         ndarray\n2598             An MxNx3 RGB array representing the combined images.\n2599         \"\"\"\n2600         low = 2 * intensity * rgb\n2601         high = 1 - 2 * (1 - intensity) * (1 - rgb)\n2602         return np.where(rgb <= 0.5, low, high)\n2603 \n2604 \n2605 def from_levels_and_colors(levels, colors, extend='neither'):\n2606     \"\"\"\n2607     A helper routine to generate a cmap and a norm instance which\n2608     behave similar to contourf's levels and colors arguments.\n2609 \n2610     Parameters\n2611     ----------\n2612     levels : sequence of numbers\n2613         The quantization levels used to construct the `BoundaryNorm`.\n2614         Value ``v`` is quantized to level ``i`` if ``lev[i] <= v < lev[i+1]``.\n2615     colors : sequence of colors\n2616         The fill color to use for each level. If *extend* is \"neither\" there\n2617         must be ``n_level - 1`` colors. For an *extend* of \"min\" or \"max\" add\n2618         one extra color, and for an *extend* of \"both\" add two colors.\n2619     extend : {'neither', 'min', 'max', 'both'}, optional\n2620         The behaviour when a value falls out of range of the given levels.\n2621         See `~.Axes.contourf` for details.\n2622 \n2623     Returns\n2624     -------\n2625     cmap : `~matplotlib.colors.Normalize`\n2626     norm : `~matplotlib.colors.Colormap`\n2627     \"\"\"\n2628     slice_map = {\n2629         'both': slice(1, -1),\n2630         'min': slice(1, None),\n2631         'max': slice(0, -1),\n2632         'neither': slice(0, None),\n2633     }\n2634     _api.check_in_list(slice_map, extend=extend)\n2635     color_slice = slice_map[extend]\n2636 \n2637     n_data_colors = len(levels) - 1\n2638     n_expected = n_data_colors + color_slice.start - (color_slice.stop or 0)\n2639     if len(colors) != n_expected:\n2640         raise ValueError(\n2641             f'With extend == {extend!r} and {len(levels)} levels, '\n2642             f'expected {n_expected} colors, but got {len(colors)}')\n2643 \n2644     cmap = ListedColormap(colors[color_slice], N=n_data_colors)\n2645 \n2646     if extend in ['min', 'both']:\n2647         cmap.set_under(colors[0])\n2648     else:\n2649         cmap.set_under('none')\n2650 \n2651     if extend in ['max', 'both']:\n2652         cmap.set_over(colors[-1])\n2653     else:\n2654         cmap.set_over('none')\n2655 \n2656     cmap.colorbar_extend = extend\n2657 \n2658     norm = BoundaryNorm(levels, ncolors=n_data_colors)\n2659     return cmap, norm\n",
        "intended_behavior": "When a normalization class's `__call__`, `autoscale`, or `autoscale_None` methods are invoked after a norm change, they should validate `vmin` and `vmax` taking into account the specific requirements of the new norm. For `LogNorm`, they should ensure `vmin` and `vmax` are positive and not equal to zero. Exception handling around these values should be robust enough to manage dynamic norm updates, especially in interactive settings or after initial plot creation."
    },
    {
        "rel_file_path": "lib/matplotlib/figure.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/matplotlib__matplotlib/setup_matplotlib__matplotlib__3.6/lib/matplotlib/figure.py",
        "start": 1178,
        "end": 1278,
        "class_name": null,
        "method_name": "colorbar",
        "code": "1178     def colorbar(\n1179             self, mappable, cax=None, ax=None, use_gridspec=True, **kwargs):\n1180         \"\"\"\n1181         Add a colorbar to a plot.\n1182 \n1183         Parameters\n1184         ----------\n1185         mappable\n1186             The `matplotlib.cm.ScalarMappable` (i.e., `.AxesImage`,\n1187             `.ContourSet`, etc.) described by this colorbar.  This argument is\n1188             mandatory for the `.Figure.colorbar` method but optional for the\n1189             `.pyplot.colorbar` function, which sets the default to the current\n1190             image.\n1191 \n1192             Note that one can create a `.ScalarMappable` \"on-the-fly\" to\n1193             generate colorbars not attached to a previously drawn artist, e.g.\n1194             ::\n1195 \n1196                 fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), ax=ax)\n1197 \n1198         cax : `~matplotlib.axes.Axes`, optional\n1199             Axes into which the colorbar will be drawn.\n1200 \n1201         ax : `~.axes.Axes` or iterable or `numpy.ndarray` of Axes, optional\n1202             One or more parent axes from which space for a new colorbar axes\n1203             will be stolen, if *cax* is None.  This has no effect if *cax* is\n1204             set.\n1205 \n1206         use_gridspec : bool, optional\n1207             If *cax* is ``None``, a new *cax* is created as an instance of\n1208             Axes.  If *ax* is positioned with a subplotspec and *use_gridspec*\n1209             is ``True``, then *cax* is also positioned with a subplotspec.\n1210 \n1211         Returns\n1212         -------\n1213         colorbar : `~matplotlib.colorbar.Colorbar`\n1214 \n1215         Other Parameters\n1216         ----------------\n1217         %(_make_axes_kw_doc)s\n1218         %(_colormap_kw_doc)s\n1219 \n1220         Notes\n1221         -----\n1222         If *mappable* is a `~.contour.ContourSet`, its *extend* kwarg is\n1223         included automatically.\n1224 \n1225         The *shrink* kwarg provides a simple way to scale the colorbar with\n1226         respect to the axes. Note that if *cax* is specified, it determines the\n1227         size of the colorbar, and *shrink* and *aspect* are ignored.\n1228 \n1229         For more precise control, you can manually specify the positions of the\n1230         axes objects in which the mappable and the colorbar are drawn.  In this\n1231         case, do not use any of the axes properties kwargs.\n1232 \n1233         It is known that some vector graphics viewers (svg and pdf) render\n1234         white gaps between segments of the colorbar.  This is due to bugs in\n1235         the viewers, not Matplotlib.  As a workaround, the colorbar can be\n1236         rendered with overlapping segments::\n1237 \n1238             cbar = colorbar()\n1239             cbar.solids.set_edgecolor(\"face\")\n1240             draw()\n1241 \n1242         However, this has negative consequences in other circumstances, e.g.\n1243         with semi-transparent images (alpha < 1) and colorbar extensions;\n1244         therefore, this workaround is not used by default (see issue #1188).\n1245         \"\"\"\n1246 \n1247         if ax is None:\n1248             ax = getattr(mappable, \"axes\", None)\n1249 \n1250         if (self.get_layout_engine() is not None and\n1251                 not self.get_layout_engine().colorbar_gridspec):\n1252             use_gridspec = False\n1253         if cax is None:\n1254             current_ax = self.gca()\n1255             if ax is None:\n1256                 _api.warn_deprecated(\"3.6\", message=(\n1257                     'Unable to determine Axes to steal space for Colorbar. '\n1258                     'Using gca(), but will raise in the future. '\n1259                     'Either provide the *cax* argument to use as the Axes for '\n1260                     'the Colorbar, provide the *ax* argument to steal space '\n1261                     'from it, or add *mappable* to an Axes.'))\n1262                 ax = current_ax\n1263             if (use_gridspec\n1264                     and isinstance(ax, mpl.axes._base._AxesBase)\n1265                     and ax.get_subplotspec()):\n1266                 cax, kwargs = cbar.make_axes_gridspec(ax, **kwargs)\n1267             else:\n1268                 cax, kwargs = cbar.make_axes(ax, **kwargs)\n1269             # make_axes calls add_{axes,subplot} which changes gca; undo that.\n1270             self.sca(current_ax)\n1271             cax.grid(visible=False, which='both', axis='both')\n1272 \n1273         NON_COLORBAR_KEYS = [  # remove kws that cannot be passed to Colorbar\n1274             'fraction', 'pad', 'shrink', 'aspect', 'anchor', 'panchor']\n1275         cb = cbar.Colorbar(cax, mappable, **{\n1276             k: v for k, v in kwargs.items() if k not in NON_COLORBAR_KEYS})\n1277         self.stale = True\n1278         return cb\n",
        "intended_behavior": "Upon updating the normalization of an existing plot that already has a colorbar, the `colorbar` method should check if the associated mappable's norm has been updated (e.g., to `LogNorm` from another norm) and perform necessary updates to ensure the colorbar reflects the new scale correctly. This includes recalculating the colorbar's ticks and label positions if necessary, based on the new norm's scale, without triggering errors related to `vmin` and `vmax` values."
    },
    {
        "rel_file_path": "lib/matplotlib/figure.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/matplotlib__matplotlib/setup_matplotlib__matplotlib__3.6/lib/matplotlib/figure.py",
        "start": 1178,
        "end": 1278,
        "class_name": "FigureBase",
        "method_name": "colorbar",
        "code": "1178     def colorbar(\n1179             self, mappable, cax=None, ax=None, use_gridspec=True, **kwargs):\n1180         \"\"\"\n1181         Add a colorbar to a plot.\n1182 \n1183         Parameters\n1184         ----------\n1185         mappable\n1186             The `matplotlib.cm.ScalarMappable` (i.e., `.AxesImage`,\n1187             `.ContourSet`, etc.) described by this colorbar.  This argument is\n1188             mandatory for the `.Figure.colorbar` method but optional for the\n1189             `.pyplot.colorbar` function, which sets the default to the current\n1190             image.\n1191 \n1192             Note that one can create a `.ScalarMappable` \"on-the-fly\" to\n1193             generate colorbars not attached to a previously drawn artist, e.g.\n1194             ::\n1195 \n1196                 fig.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap), ax=ax)\n1197 \n1198         cax : `~matplotlib.axes.Axes`, optional\n1199             Axes into which the colorbar will be drawn.\n1200 \n1201         ax : `~.axes.Axes` or iterable or `numpy.ndarray` of Axes, optional\n1202             One or more parent axes from which space for a new colorbar axes\n1203             will be stolen, if *cax* is None.  This has no effect if *cax* is\n1204             set.\n1205 \n1206         use_gridspec : bool, optional\n1207             If *cax* is ``None``, a new *cax* is created as an instance of\n1208             Axes.  If *ax* is positioned with a subplotspec and *use_gridspec*\n1209             is ``True``, then *cax* is also positioned with a subplotspec.\n1210 \n1211         Returns\n1212         -------\n1213         colorbar : `~matplotlib.colorbar.Colorbar`\n1214 \n1215         Other Parameters\n1216         ----------------\n1217         %(_make_axes_kw_doc)s\n1218         %(_colormap_kw_doc)s\n1219 \n1220         Notes\n1221         -----\n1222         If *mappable* is a `~.contour.ContourSet`, its *extend* kwarg is\n1223         included automatically.\n1224 \n1225         The *shrink* kwarg provides a simple way to scale the colorbar with\n1226         respect to the axes. Note that if *cax* is specified, it determines the\n1227         size of the colorbar, and *shrink* and *aspect* are ignored.\n1228 \n1229         For more precise control, you can manually specify the positions of the\n1230         axes objects in which the mappable and the colorbar are drawn.  In this\n1231         case, do not use any of the axes properties kwargs.\n1232 \n1233         It is known that some vector graphics viewers (svg and pdf) render\n1234         white gaps between segments of the colorbar.  This is due to bugs in\n1235         the viewers, not Matplotlib.  As a workaround, the colorbar can be\n1236         rendered with overlapping segments::\n1237 \n1238             cbar = colorbar()\n1239             cbar.solids.set_edgecolor(\"face\")\n1240             draw()\n1241 \n1242         However, this has negative consequences in other circumstances, e.g.\n1243         with semi-transparent images (alpha < 1) and colorbar extensions;\n1244         therefore, this workaround is not used by default (see issue #1188).\n1245         \"\"\"\n1246 \n1247         if ax is None:\n1248             ax = getattr(mappable, \"axes\", None)\n1249 \n1250         if (self.get_layout_engine() is not None and\n1251                 not self.get_layout_engine().colorbar_gridspec):\n1252             use_gridspec = False\n1253         if cax is None:\n1254             current_ax = self.gca()\n1255             if ax is None:\n1256                 _api.warn_deprecated(\"3.6\", message=(\n1257                     'Unable to determine Axes to steal space for Colorbar. '\n1258                     'Using gca(), but will raise in the future. '\n1259                     'Either provide the *cax* argument to use as the Axes for '\n1260                     'the Colorbar, provide the *ax* argument to steal space '\n1261                     'from it, or add *mappable* to an Axes.'))\n1262                 ax = current_ax\n1263             if (use_gridspec\n1264                     and isinstance(ax, mpl.axes._base._AxesBase)\n1265                     and ax.get_subplotspec()):\n1266                 cax, kwargs = cbar.make_axes_gridspec(ax, **kwargs)\n1267             else:\n1268                 cax, kwargs = cbar.make_axes(ax, **kwargs)\n1269             # make_axes calls add_{axes,subplot} which changes gca; undo that.\n1270             self.sca(current_ax)\n1271             cax.grid(visible=False, which='both', axis='both')\n1272 \n1273         NON_COLORBAR_KEYS = [  # remove kws that cannot be passed to Colorbar\n1274             'fraction', 'pad', 'shrink', 'aspect', 'anchor', 'panchor']\n1275         cb = cbar.Colorbar(cax, mappable, **{\n1276             k: v for k, v in kwargs.items() if k not in NON_COLORBAR_KEYS})\n1277         self.stale = True\n1278         return cb\n",
        "intended_behavior": "Upon updating the normalization of an existing plot that already has a colorbar, the `colorbar` method should check if the associated mappable's norm has been updated (e.g., to `LogNorm` from another norm) and perform necessary updates to ensure the colorbar reflects the new scale correctly. This includes recalculating the colorbar's ticks and label positions if necessary, based on the new norm's scale, without triggering errors related to `vmin` and `vmax` values."
    }
]