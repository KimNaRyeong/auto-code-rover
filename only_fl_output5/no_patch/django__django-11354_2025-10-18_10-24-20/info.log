2025-10-18 10:24:20.504 | INFO     | Starting overall retry 0 with model gpt-4-0125-preview
2025-10-18 10:24:24.180 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=581, output_tokens=12, cost=0.006170
2025-10-18 10:24:36.971 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=761, output_tokens=584, cost=0.025130
2025-10-18 10:24:38.305 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-18 10:24:45.997 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=857, output_tokens=356, cost=0.019250
2025-10-18 10:24:46.005 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-18 10:24:48.897 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=710, output_tokens=59, cost=0.008870
2025-10-18 10:24:48.898 | DEBUG    | Extracted a valid json.
2025-10-18 10:24:48.898 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_class(\"Query\")",
        "search_class(\"RawSQL\")",
        "search_method_in_class(\"get_aggregation\", \"Query\")",
        "search_code(\"inner_query.default_cols\")"
    ],
    "bug_locations": []
}
2025-10-18 10:24:48.990 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-18 10:24:48.990 | DEBUG    | <Agent search> Analyzing search results.
2025-10-18 10:25:03.727 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=4017, output_tokens=659, cost=0.059940
2025-10-18 10:25:03.740 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-18 10:25:10.072 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=4892, output_tokens=273, cost=0.057110
2025-10-18 10:25:10.078 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-18 10:25:17.691 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=627, output_tokens=289, cost=0.014940
2025-10-18 10:25:17.692 | DEBUG    | Extracted a valid json.
2025-10-18 10:25:17.693 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [],
    "bug_locations": [
        {
            "file": "django/db/models/sql/query.py",
            "class": "Query",
            "method": "get_aggregation",
            "intended_behavior": "The `get_aggregation` method should be updated to ensure it correctly maintains the necessary INNER JOINs when handling queries that involve fields from parent models due to model inheritance. This involves refining the logic that determines when to set `inner_query.default_cols` to `False` and how `inner_query.group_by` is adjusted. Particularly, the modification should:\n\n- Add a condition to check if the annotation involves fields from an inherited model. If so, the method should preserve the `default_cols` as `True` or ensure the necessary JOINs are explicitly included in the `group_by`.\n- Ensure that INNER JOINs necessary for accessing inherited model fields are not dropped even when `default_cols` is set to `False`. This may involve more nuanced handling or additional checks around the conditions that currently lead to setting `inner_query.default_cols` to `False`.\n\nThe objective is to preserve all existing functionalities while ensuring that count operations on annotated querysets referencing inherited model fields do not result in errors due to missing columns. This might require a more sophisticated analysis of the queryset's structure to understand when JOINs are necessary for correct count aggregation."
        }
    ]
}
2025-10-18 10:25:17.712 | DEBUG    | Bug location extracted successfully: [<file>django/db/models/sql/query.py</file>
<class>Query</class>
<method>get_aggregation</method>
<code>
410     def get_aggregation(self, using, added_aggregate_names):
411         """
412         Return the dictionary with the values of the existing aggregations.
413         """
414         if not self.annotation_select:
415             return {}
416         has_limit = self.low_mark != 0 or self.high_mark is not None
417         existing_annotations = [
418             annotation for alias, annotation
419             in self.annotations.items()
420             if alias not in added_aggregate_names
421         ]
422         # Decide if we need to use a subquery.
423         #
424         # Existing annotations would cause incorrect results as get_aggregation()
425         # must produce just one result and thus must not use GROUP BY. But we
426         # aren't smart enough to remove the existing annotations from the
427         # query, so those would force us to use GROUP BY.
428         #
429         # If the query has limit or distinct, or uses set operations, then
430         # those operations must be done in a subquery so that the query
431         # aggregates on the limit and/or distinct results instead of applying
432         # the distinct and limit after the aggregation.
433         if (isinstance(self.group_by, tuple) or has_limit or existing_annotations or
434                 self.distinct or self.combinator):
435             from django.db.models.sql.subqueries import AggregateQuery
436             outer_query = AggregateQuery(self.model)
437             inner_query = self.clone()
438             inner_query.select_for_update = False
439             inner_query.select_related = False
440             inner_query.set_annotation_mask(self.annotation_select)
441             if not has_limit and not self.distinct_fields:
442                 # Queries with distinct_fields need ordering and when a limit
443                 # is applied we must take the slice from the ordered query.
444                 # Otherwise no need for ordering.
445                 inner_query.clear_ordering(True)
446             if not inner_query.distinct:
447                 # If the inner query uses default select and it has some
448                 # aggregate annotations, then we must make sure the inner
449                 # query is grouped by the main model's primary key. However,
450                 # clearing the select clause can alter results if distinct is
451                 # used.
452                 has_existing_aggregate_annotations = any(
453                     annotation for annotation in existing_annotations
454                     if getattr(annotation, 'contains_aggregate', True)
455                 )
456                 if inner_query.default_cols and has_existing_aggregate_annotations:
457                     inner_query.group_by = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)
458                 inner_query.default_cols = False
459 
460             relabels = {t: 'subquery' for t in inner_query.alias_map}
461             relabels[None] = 'subquery'
462             # Remove any aggregates marked for reduction from the subquery
463             # and move them to the outer AggregateQuery.
464             col_cnt = 0
465             for alias, expression in list(inner_query.annotation_select.items()):
466                 annotation_select_mask = inner_query.annotation_select_mask
467                 if expression.is_summary:
468                     expression, col_cnt = inner_query.rewrite_cols(expression, col_cnt)
469                     outer_query.annotations[alias] = expression.relabeled_clone(relabels)
470                     del inner_query.annotations[alias]
471                     annotation_select_mask.remove(alias)
472                 # Make sure the annotation_select wont use cached results.
473                 inner_query.set_annotation_mask(inner_query.annotation_select_mask)
474             if inner_query.select == () and not inner_query.default_cols and not inner_query.annotation_select_mask:
475                 # In case of Model.objects[0:3].count(), there would be no
476                 # field selected in the inner query, yet we must use a subquery.
477                 # So, make sure at least one field is selected.
478                 inner_query.select = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)
479             try:
480                 outer_query.add_subquery(inner_query, using)
481             except EmptyResultSet:
482                 return {
483                     alias: None
484                     for alias in outer_query.annotation_select
485                 }
486         else:
487             outer_query = self
488             self.select = ()
489             self.default_cols = False
490             self.extra = {}
491 
492         outer_query.clear_ordering(True)
493         outer_query.clear_limits()
494         outer_query.select_for_update = False
495         outer_query.select_related = False
496         compiler = outer_query.get_compiler(using)
497         result = compiler.execute_sql(SINGLE)
498         if result is None:
499             result = [None] * len(outer_query.annotation_select)
500 
501         converters = compiler.get_converters(outer_query.annotation_select.values())
502         result = next(compiler.apply_converters((result,), converters))
503 
504         return dict(zip(outer_query.annotation_select, result))

</code><intended_behavior>The `get_aggregation` method should be updated to ensure it correctly maintains the necessary INNER JOINs when handling queries that involve fields from parent models due to model inheritance. This involves refining the logic that determines when to set `inner_query.default_cols` to `False` and how `inner_query.group_by` is adjusted. Particularly, the modification should:

- Add a condition to check if the annotation involves fields from an inherited model. If so, the method should preserve the `default_cols` as `True` or ensure the necessary JOINs are explicitly included in the `group_by`.
- Ensure that INNER JOINs necessary for accessing inherited model fields are not dropped even when `default_cols` is set to `False`. This may involve more nuanced handling or additional checks around the conditions that currently lead to setting `inner_query.default_cols` to `False`.

The objective is to preserve all existing functionalities while ensuring that count operations on annotated querysets referencing inherited model fields do not result in errors due to missing columns. This might require a more sophisticated analysis of the queryset's structure to understand when JOINs are necessary for correct count aggregation.</intended_behavior>, <file>django/db/models/sql/query.py</file>
<class>Query</class>
<method>None</method>
<code>
145 class Query(BaseExpression):
146     """A single SQL query."""
147 
148     alias_prefix = 'T'
149     subq_aliases = frozenset([alias_prefix])
150 
151     compiler = 'SQLCompiler'
152 
153     def __init__(self, model, where=WhereNode):
154         self.model = model
155         self.alias_refcount = {}
156         # alias_map is the most important data structure regarding joins.
157         # It's used for recording which joins exist in the query and what
158         # types they are. The key is the alias of the joined table (possibly
159         # the table name) and the value is a Join-like object (see
160         # sql.datastructures.Join for more information).
161         self.alias_map = {}
162         # Sometimes the query contains references to aliases in outer queries (as
163         # a result of split_exclude). Correct alias quoting needs to know these
164         # aliases too.
165         self.external_aliases = set()
166         self.table_map = {}     # Maps table names to list of aliases.
167         self.default_cols = True
168         self.default_ordering = True
169         self.standard_ordering = True
170         self.used_aliases = set()
171         self.filter_is_sticky = False
172         self.subquery = False
173 
174         # SQL-related attributes
175         # Select and related select clauses are expressions to use in the
176         # SELECT clause of the query.
177         # The select is used for cases where we want to set up the select
178         # clause to contain other than default fields (values(), subqueries...)
179         # Note that annotations go to annotations dictionary.
180         self.select = ()
181         self.where = where()
182         self.where_class = where
183         # The group_by attribute can have one of the following forms:
184         #  - None: no group by at all in the query
185         #  - A tuple of expressions: group by (at least) those expressions.
186         #    String refs are also allowed for now.
187         #  - True: group by all select fields of the model
188         # See compiler.get_group_by() for details.
189         self.group_by = None
190         self.order_by = ()
191         self.low_mark, self.high_mark = 0, None  # Used for offset/limit
192         self.distinct = False
193         self.distinct_fields = ()
194         self.select_for_update = False
195         self.select_for_update_nowait = False
196         self.select_for_update_skip_locked = False
197         self.select_for_update_of = ()
198 
199         self.select_related = False
200         # Arbitrary limit for select_related to prevents infinite recursion.
201         self.max_depth = 5
202 
203         # Holds the selects defined by a call to values() or values_list()
204         # excluding annotation_select and extra_select.
205         self.values_select = ()
206 
207         # SQL annotation-related attributes
208         self.annotations = {}  # Maps alias -> Annotation Expression
209         self.annotation_select_mask = None
210         self._annotation_select_cache = None
211 
212         # Set combination attributes
213         self.combinator = None
214         self.combinator_all = False
215         self.combined_queries = ()
216 
217         # These are for extensions. The contents are more or less appended
218         # verbatim to the appropriate clause.
219         self.extra = {}  # Maps col_alias -> (col_sql, params).
220         self.extra_select_mask = None
221         self._extra_select_cache = None
222 
223         self.extra_tables = ()
224         self.extra_order_by = ()
225 
226         # A tuple that is a set of model field names and either True, if these
227         # are the fields to defer, or False if these are the only fields to
228         # load.
229         self.deferred_loading = (frozenset(), True)
230 
231         self._filtered_relations = {}
232 
233         self.explain_query = False
234         self.explain_format = None
235         self.explain_options = {}
236 
237     @property
238     def output_field(self):
239         if len(self.select) == 1:
240             return self.select[0].field
241         elif len(self.annotation_select) == 1:
242             return next(iter(self.annotation_select.values())).output_field
243 
244     @property
245     def has_select_fields(self):
246         return bool(self.select or self.annotation_select_mask or self.extra_select_mask)
247 
248     @cached_property
249     def base_table(self):
250         for alias in self.alias_map:
251             return alias
252 
253     def __str__(self):
254         """
255         Return the query as a string of SQL with the parameter values
256         substituted in (use sql_with_params() to see the unsubstituted string).
257 
258         Parameter values won't necessarily be quoted correctly, since that is
259         done by the database interface at execution time.
260         """
261         sql, params = self.sql_with_params()
262         return sql % params
263 
264     def sql_with_params(self):
265         """
266         Return the query as an SQL string and the parameters that will be
267         substituted into the query.
268         """
269         return self.get_compiler(DEFAULT_DB_ALIAS).as_sql()
270 
271     def __deepcopy__(self, memo):
272         """Limit the amount of work when a Query is deepcopied."""
273         result = self.clone()
274         memo[id(self)] = result
275         return result
276 
277     def get_compiler(self, using=None, connection=None):
278         if using is None and connection is None:
279             raise ValueError("Need either using or connection")
280         if using:
281             connection = connections[using]
282         return connection.ops.compiler(self.compiler)(self, connection, using)
283 
284     def get_meta(self):
285         """
286         Return the Options instance (the model._meta) from which to start
287         processing. Normally, this is self.model._meta, but it can be changed
288         by subclasses.
289         """
290         return self.model._meta
291 
292     def clone(self):
293         """
294         Return a copy of the current Query. A lightweight alternative to
295         to deepcopy().
296         """
297         obj = Empty()
298         obj.__class__ = self.__class__
299         # Copy references to everything.
300         obj.__dict__ = self.__dict__.copy()
301         # Clone attributes that can't use shallow copy.
302         obj.alias_refcount = self.alias_refcount.copy()
303         obj.alias_map = self.alias_map.copy()
304         obj.external_aliases = self.external_aliases.copy()
305         obj.table_map = self.table_map.copy()
306         obj.where = self.where.clone()
307         obj.annotations = self.annotations.copy()
308         if self.annotation_select_mask is None:
309             obj.annotation_select_mask = None
310         else:
311             obj.annotation_select_mask = self.annotation_select_mask.copy()
312         # _annotation_select_cache cannot be copied, as doing so breaks the
313         # (necessary) state in which both annotations and
314         # _annotation_select_cache point to the same underlying objects.
315         # It will get re-populated in the cloned queryset the next time it's
316         # used.
317         obj._annotation_select_cache = None
318         obj.extra = self.extra.copy()
319         if self.extra_select_mask is None:
320             obj.extra_select_mask = None
321         else:
322             obj.extra_select_mask = self.extra_select_mask.copy()
323         if self._extra_select_cache is None:
324             obj._extra_select_cache = None
325         else:
326             obj._extra_select_cache = self._extra_select_cache.copy()
327         if 'subq_aliases' in self.__dict__:
328             obj.subq_aliases = self.subq_aliases.copy()
329         obj.used_aliases = self.used_aliases.copy()
330         obj._filtered_relations = self._filtered_relations.copy()
331         # Clear the cached_property
332         try:
333             del obj.base_table
334         except AttributeError:
335             pass
336         return obj
337 
338     def chain(self, klass=None):
339         """
340         Return a copy of the current Query that's ready for another operation.
341         The klass argument changes the type of the Query, e.g. UpdateQuery.
342         """
343         obj = self.clone()
344         if klass and obj.__class__ != klass:
345             obj.__class__ = klass
346         if not obj.filter_is_sticky:
347             obj.used_aliases = set()
348         obj.filter_is_sticky = False
349         if hasattr(obj, '_setup_query'):
350             obj._setup_query()
351         return obj
352 
353     def relabeled_clone(self, change_map):
354         clone = self.clone()
355         clone.change_aliases(change_map)
356         return clone
357 
358     def rewrite_cols(self, annotation, col_cnt):
359         # We must make sure the inner query has the referred columns in it.
360         # If we are aggregating over an annotation, then Django uses Ref()
361         # instances to note this. However, if we are annotating over a column
362         # of a related model, then it might be that column isn't part of the
363         # SELECT clause of the inner query, and we must manually make sure
364         # the column is selected. An example case is:
365         #    .aggregate(Sum('author__awards'))
366         # Resolving this expression results in a join to author, but there
367         # is no guarantee the awards column of author is in the select clause
368         # of the query. Thus we must manually add the column to the inner
369         # query.
370         orig_exprs = annotation.get_source_expressions()
371         new_exprs = []
372         for expr in orig_exprs:
373             # FIXME: These conditions are fairly arbitrary. Identify a better
374             # method of having expressions decide which code path they should
375             # take.
376             if isinstance(expr, Ref):
377                 # Its already a Ref to subquery (see resolve_ref() for
378                 # details)
379                 new_exprs.append(expr)
380             elif isinstance(expr, (WhereNode, Lookup)):
381                 # Decompose the subexpressions further. The code here is
382                 # copied from the else clause, but this condition must appear
383                 # before the contains_aggregate/is_summary condition below.
384                 new_expr, col_cnt = self.rewrite_cols(expr, col_cnt)
385                 new_exprs.append(new_expr)
386             else:
387                 # Reuse aliases of expressions already selected in subquery.
388                 for col_alias, selected_annotation in self.annotation_select.items():
389                     if selected_annotation == expr:
390                         new_expr = Ref(col_alias, expr)
391                         break
392                 else:
393                     # An expression that is not selected the subquery.
394                     if isinstance(expr, Col) or (expr.contains_aggregate and not expr.is_summary):
395                         # Reference column or another aggregate. Select it
396                         # under a non-conflicting alias.
397                         col_cnt += 1
398                         col_alias = '__col%d' % col_cnt
399                         self.annotations[col_alias] = expr
400                         self.append_annotation_mask([col_alias])
401                         new_expr = Ref(col_alias, expr)
402                     else:
403                         # Some other expression not referencing database values
404                         # directly. Its subexpression might contain Cols.
405                         new_expr, col_cnt = self.rewrite_cols(expr, col_cnt)
406                 new_exprs.append(new_expr)
407         annotation.set_source_expressions(new_exprs)
408         return annotation, col_cnt
409 
410     def get_aggregation(self, using, added_aggregate_names):
411         """
412         Return the dictionary with the values of the existing aggregations.
413         """
414         if not self.annotation_select:
415             return {}
416         has_limit = self.low_mark != 0 or self.high_mark is not None
417         existing_annotations = [
418             annotation for alias, annotation
419             in self.annotations.items()
420             if alias not in added_aggregate_names
421         ]
422         # Decide if we need to use a subquery.
423         #
424         # Existing annotations would cause incorrect results as get_aggregation()
425         # must produce just one result and thus must not use GROUP BY. But we
426         # aren't smart enough to remove the existing annotations from the
427         # query, so those would force us to use GROUP BY.
428         #
429         # If the query has limit or distinct, or uses set operations, then
430         # those operations must be done in a subquery so that the query
431         # aggregates on the limit and/or distinct results instead of applying
432         # the distinct and limit after the aggregation.
433         if (isinstance(self.group_by, tuple) or has_limit or existing_annotations or
434                 self.distinct or self.combinator):
435             from django.db.models.sql.subqueries import AggregateQuery
436             outer_query = AggregateQuery(self.model)
437             inner_query = self.clone()
438             inner_query.select_for_update = False
439             inner_query.select_related = False
440             inner_query.set_annotation_mask(self.annotation_select)
441             if not has_limit and not self.distinct_fields:
442                 # Queries with distinct_fields need ordering and when a limit
443                 # is applied we must take the slice from the ordered query.
444                 # Otherwise no need for ordering.
445                 inner_query.clear_ordering(True)
446             if not inner_query.distinct:
447                 # If the inner query uses default select and it has some
448                 # aggregate annotations, then we must make sure the inner
449                 # query is grouped by the main model's primary key. However,
450                 # clearing the select clause can alter results if distinct is
451                 # used.
452                 has_existing_aggregate_annotations = any(
453                     annotation for annotation in existing_annotations
454                     if getattr(annotation, 'contains_aggregate', True)
455                 )
456                 if inner_query.default_cols and has_existing_aggregate_annotations:
457                     inner_query.group_by = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)
458                 inner_query.default_cols = False
459 
460             relabels = {t: 'subquery' for t in inner_query.alias_map}
461             relabels[None] = 'subquery'
462             # Remove any aggregates marked for reduction from the subquery
463             # and move them to the outer AggregateQuery.
464             col_cnt = 0
465             for alias, expression in list(inner_query.annotation_select.items()):
466                 annotation_select_mask = inner_query.annotation_select_mask
467                 if expression.is_summary:
468                     expression, col_cnt = inner_query.rewrite_cols(expression, col_cnt)
469                     outer_query.annotations[alias] = expression.relabeled_clone(relabels)
470                     del inner_query.annotations[alias]
471                     annotation_select_mask.remove(alias)
472                 # Make sure the annotation_select wont use cached results.
473                 inner_query.set_annotation_mask(inner_query.annotation_select_mask)
474             if inner_query.select == () and not inner_query.default_cols and not inner_query.annotation_select_mask:
475                 # In case of Model.objects[0:3].count(), there would be no
476                 # field selected in the inner query, yet we must use a subquery.
477                 # So, make sure at least one field is selected.
478                 inner_query.select = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)
479             try:
480                 outer_query.add_subquery(inner_query, using)
481             except EmptyResultSet:
482                 return {
483                     alias: None
484                     for alias in outer_query.annotation_select
485                 }
486         else:
487             outer_query = self
488             self.select = ()
489             self.default_cols = False
490             self.extra = {}
491 
492         outer_query.clear_ordering(True)
493         outer_query.clear_limits()
494         outer_query.select_for_update = False
495         outer_query.select_related = False
496         compiler = outer_query.get_compiler(using)
497         result = compiler.execute_sql(SINGLE)
498         if result is None:
499             result = [None] * len(outer_query.annotation_select)
500 
501         converters = compiler.get_converters(outer_query.annotation_select.values())
502         result = next(compiler.apply_converters((result,), converters))
503 
504         return dict(zip(outer_query.annotation_select, result))
505 
506     def get_count(self, using):
507         """
508         Perform a COUNT() query using the current filter constraints.
509         """
510         obj = self.clone()
511         obj.add_annotation(Count('*'), alias='__count', is_summary=True)
512         number = obj.get_aggregation(using, ['__count'])['__count']
513         if number is None:
514             number = 0
515         return number
516 
517     def has_filters(self):
518         return self.where
519 
520     def has_results(self, using):
521         q = self.clone()
522         if not q.distinct:
523             if q.group_by is True:
524                 q.add_fields((f.attname for f in self.model._meta.concrete_fields), False)
525                 q.set_group_by()
526             q.clear_select_clause()
527         q.clear_ordering(True)
528         q.set_limits(high=1)
529         compiler = q.get_compiler(using=using)
530         return compiler.has_results()
531 
532     def explain(self, using, format=None, **options):
533         q = self.clone()
534         q.explain_query = True
535         q.explain_format = format
536         q.explain_options = options
537         compiler = q.get_compiler(using=using)
538         return '\n'.join(compiler.explain_query())
539 
540     def combine(self, rhs, connector):
541         """
542         Merge the 'rhs' query into the current one (with any 'rhs' effects
543         being applied *after* (that is, "to the right of") anything in the
544         current query. 'rhs' is not modified during a call to this function.
545 
546         The 'connector' parameter describes how to connect filters from the
547         'rhs' query.
548         """
549         assert self.model == rhs.model, \
550             "Cannot combine queries on two different base models."
551         assert self.can_filter(), \
552             "Cannot combine queries once a slice has been taken."
553         assert self.distinct == rhs.distinct, \
554             "Cannot combine a unique query with a non-unique query."
555         assert self.distinct_fields == rhs.distinct_fields, \
556             "Cannot combine queries with different distinct fields."
557 
558         # Work out how to relabel the rhs aliases, if necessary.
559         change_map = {}
560         conjunction = (connector == AND)
561 
562         # Determine which existing joins can be reused. When combining the
563         # query with AND we must recreate all joins for m2m filters. When
564         # combining with OR we can reuse joins. The reason is that in AND
565         # case a single row can't fulfill a condition like:
566         #     revrel__col=1 & revrel__col=2
567         # But, there might be two different related rows matching this
568         # condition. In OR case a single True is enough, so single row is
569         # enough, too.
570         #
571         # Note that we will be creating duplicate joins for non-m2m joins in
572         # the AND case. The results will be correct but this creates too many
573         # joins. This is something that could be fixed later on.
574         reuse = set() if conjunction else set(self.alias_map)
575         # Base table must be present in the query - this is the same
576         # table on both sides.
577         self.get_initial_alias()
578         joinpromoter = JoinPromoter(connector, 2, False)
579         joinpromoter.add_votes(
580             j for j in self.alias_map if self.alias_map[j].join_type == INNER)
581         rhs_votes = set()
582         # Now, add the joins from rhs query into the new query (skipping base
583         # table).
584         rhs_tables = list(rhs.alias_map)[1:]
585         for alias in rhs_tables:
586             join = rhs.alias_map[alias]
587             # If the left side of the join was already relabeled, use the
588             # updated alias.
589             join = join.relabeled_clone(change_map)
590             new_alias = self.join(join, reuse=reuse)
591             if join.join_type == INNER:
592                 rhs_votes.add(new_alias)
593             # We can't reuse the same join again in the query. If we have two
594             # distinct joins for the same connection in rhs query, then the
595             # combined query must have two joins, too.
596             reuse.discard(new_alias)
597             if alias != new_alias:
598                 change_map[alias] = new_alias
599             if not rhs.alias_refcount[alias]:
600                 # The alias was unused in the rhs query. Unref it so that it
601                 # will be unused in the new query, too. We have to add and
602                 # unref the alias so that join promotion has information of
603                 # the join type for the unused alias.
604                 self.unref_alias(new_alias)
605         joinpromoter.add_votes(rhs_votes)
606         joinpromoter.update_join_types(self)
607 
608         # Now relabel a copy of the rhs where-clause and add it to the current
609         # one.
610         w = rhs.where.clone()
611         w.relabel_aliases(change_map)
612         self.where.add(w, connector)
613 
614         # Selection columns and extra extensions are those provided by 'rhs'.
615         if rhs.select:
616             self.set_select([col.relabeled_clone(change_map) for col in rhs.select])
617         else:
618             self.select = ()
619 
620         if connector == OR:
621             # It would be nice to be able to handle this, but the queries don't
622             # really make sense (or return consistent value sets). Not worth
623             # the extra complexity when you can write a real query instead.
624             if self.extra and rhs.extra:
625                 raise ValueError("When merging querysets using 'or', you cannot have extra(select=...) on both sides.")
626         self.extra.update(rhs.extra)
627         extra_select_mask = set()
628         if self.extra_select_mask is not None:
629             extra_select_mask.update(self.extra_select_mask)
630         if rhs.extra_select_mask is not None:
631             extra_select_mask.update(rhs.extra_select_mask)
632         if extra_select_mask:
633             self.set_extra_mask(extra_select_mask)
634         self.extra_tables += rhs.extra_tables
635 
636         # Ordering uses the 'rhs' ordering, unless it has none, in which case
637         # the current ordering is used.
638         self.order_by = rhs.order_by or self.order_by
639         self.extra_order_by = rhs.extra_order_by or self.extra_order_by
640 
641     def deferred_to_data(self, target, callback):
642         """
643         Convert the self.deferred_loading data structure to an alternate data
644         structure, describing the field that *will* be loaded. This is used to
645         compute the columns to select from the database and also by the
646         QuerySet class to work out which fields are being initialized on each
647         model. Models that have all their fields included aren't mentioned in
648         the result, only those that have field restrictions in place.
649 
650         The "target" parameter is the instance that is populated (in place).
651         The "callback" is a function that is called whenever a (model, field)
652         pair need to be added to "target". It accepts three parameters:
653         "target", and the model and list of fields being added for that model.
654         """
655         field_names, defer = self.deferred_loading
656         if not field_names:
657             return
658         orig_opts = self.get_meta()
659         seen = {}
660         must_include = {orig_opts.concrete_model: {orig_opts.pk}}
661         for field_name in field_names:
662             parts = field_name.split(LOOKUP_SEP)
663             cur_model = self.model._meta.concrete_model
664             opts = orig_opts
665             for name in parts[:-1]:
666                 old_model = cur_model
667                 if name in self._filtered_relations:
668                     name = self._filtered_relations[name].relation_name
669                 source = opts.get_field(name)
670                 if is_reverse_o2o(source):
671                     cur_model = source.related_model
672                 else:
673                     cur_model = source.remote_field.model
674                 opts = cur_model._meta
675                 # Even if we're "just passing through" this model, we must add
676                 # both the current model's pk and the related reference field
677                 # (if it's not a reverse relation) to the things we select.
678                 if not is_reverse_o2o(source):
679                     must_include[old_model].add(source)
680                 add_to_dict(must_include, cur_model, opts.pk)
681             field = opts.get_field(parts[-1])
682             is_reverse_object = field.auto_created and not field.concrete
683             model = field.related_model if is_reverse_object else field.model
684             model = model._meta.concrete_model
685             if model == opts.model:
686                 model = cur_model
687             if not is_reverse_o2o(field):
688                 add_to_dict(seen, model, field)
689 
690         if defer:
691             # We need to load all fields for each model, except those that
692             # appear in "seen" (for all models that appear in "seen"). The only
693             # slight complexity here is handling fields that exist on parent
694             # models.
695             workset = {}
696             for model, values in seen.items():
697                 for field in model._meta.local_fields:
698                     if field not in values:
699                         m = field.model._meta.concrete_model
700                         add_to_dict(workset, m, field)
701             for model, values in must_include.items():
702                 # If we haven't included a model in workset, we don't add the
703                 # corresponding must_include fields for that model, since an
704                 # empty set means "include all fields". That's why there's no
705                 # "else" branch here.
706                 if model in workset:
707                     workset[model].update(values)
708             for model, values in workset.items():
709                 callback(target, model, values)
710         else:
711             for model, values in must_include.items():
712                 if model in seen:
713                     seen[model].update(values)
714                 else:
715                     # As we've passed through this model, but not explicitly
716                     # included any fields, we have to make sure it's mentioned
717                     # so that only the "must include" fields are pulled in.
718                     seen[model] = values
719             # Now ensure that every model in the inheritance chain is mentioned
720             # in the parent list. Again, it must be mentioned to ensure that
721             # only "must include" fields are pulled in.
722             for model in orig_opts.get_parent_list():
723                 seen.setdefault(model, set())
724             for model, values in seen.items():
725                 callback(target, model, values)
726 
727     def table_alias(self, table_name, create=False, filtered_relation=None):
728         """
729         Return a table alias for the given table_name and whether this is a
730         new alias or not.
731 
732         If 'create' is true, a new alias is always created. Otherwise, the
733         most recently created alias for the table (if one exists) is reused.
734         """
735         alias_list = self.table_map.get(table_name)
736         if not create and alias_list:
737             alias = alias_list[0]
738             self.alias_refcount[alias] += 1
739             return alias, False
740 
741         # Create a new alias for this table.
742         if alias_list:
743             alias = '%s%d' % (self.alias_prefix, len(self.alias_map) + 1)
744             alias_list.append(alias)
745         else:
746             # The first occurrence of a table uses the table name directly.
747             alias = filtered_relation.alias if filtered_relation is not None else table_name
748             self.table_map[table_name] = [alias]
749         self.alias_refcount[alias] = 1
750         return alias, True
751 
752     def ref_alias(self, alias):
753         """Increases the reference count for this alias."""
754         self.alias_refcount[alias] += 1
755 
756     def unref_alias(self, alias, amount=1):
757         """Decreases the reference count for this alias."""
758         self.alias_refcount[alias] -= amount
759 
760     def promote_joins(self, aliases):
761         """
762         Promote recursively the join type of given aliases and its children to
763         an outer join. If 'unconditional' is False, only promote the join if
764         it is nullable or the parent join is an outer join.
765 
766         The children promotion is done to avoid join chains that contain a LOUTER
767         b INNER c. So, if we have currently a INNER b INNER c and a->b is promoted,
768         then we must also promote b->c automatically, or otherwise the promotion
769         of a->b doesn't actually change anything in the query results.
770         """
771         aliases = list(aliases)
772         while aliases:
773             alias = aliases.pop(0)
774             if self.alias_map[alias].join_type is None:
775                 # This is the base table (first FROM entry) - this table
776                 # isn't really joined at all in the query, so we should not
777                 # alter its join type.
778                 continue
779             # Only the first alias (skipped above) should have None join_type
780             assert self.alias_map[alias].join_type is not None
781             parent_alias = self.alias_map[alias].parent_alias
782             parent_louter = parent_alias and self.alias_map[parent_alias].join_type == LOUTER
783             already_louter = self.alias_map[alias].join_type == LOUTER
784             if ((self.alias_map[alias].nullable or parent_louter) and
785                     not already_louter):
786                 self.alias_map[alias] = self.alias_map[alias].promote()
787                 # Join type of 'alias' changed, so re-examine all aliases that
788                 # refer to this one.
789                 aliases.extend(
790                     join for join in self.alias_map
791                     if self.alias_map[join].parent_alias == alias and join not in aliases
792                 )
793 
794     def demote_joins(self, aliases):
795         """
796         Change join type from LOUTER to INNER for all joins in aliases.
797 
798         Similarly to promote_joins(), this method must ensure no join chains
799         containing first an outer, then an inner join are generated. If we
800         are demoting b->c join in chain a LOUTER b LOUTER c then we must
801         demote a->b automatically, or otherwise the demotion of b->c doesn't
802         actually change anything in the query results. .
803         """
804         aliases = list(aliases)
805         while aliases:
806             alias = aliases.pop(0)
807             if self.alias_map[alias].join_type == LOUTER:
808                 self.alias_map[alias] = self.alias_map[alias].demote()
809                 parent_alias = self.alias_map[alias].parent_alias
810                 if self.alias_map[parent_alias].join_type == INNER:
811                     aliases.append(parent_alias)
812 
813     def reset_refcounts(self, to_counts):
814         """
815         Reset reference counts for aliases so that they match the value passed
816         in `to_counts`.
817         """
818         for alias, cur_refcount in self.alias_refcount.copy().items():
819             unref_amount = cur_refcount - to_counts.get(alias, 0)
820             self.unref_alias(alias, unref_amount)
821 
822     def change_aliases(self, change_map):
823         """
824         Change the aliases in change_map (which maps old-alias -> new-alias),
825         relabelling any references to them in select columns and the where
826         clause.
827         """
828         assert set(change_map).isdisjoint(change_map.values())
829 
830         # 1. Update references in "select" (normal columns plus aliases),
831         # "group by" and "where".
832         self.where.relabel_aliases(change_map)
833         if isinstance(self.group_by, tuple):
834             self.group_by = tuple([col.relabeled_clone(change_map) for col in self.group_by])
835         self.select = tuple([col.relabeled_clone(change_map) for col in self.select])
836         self.annotations = self.annotations and {
837             key: col.relabeled_clone(change_map) for key, col in self.annotations.items()
838         }
839 
840         # 2. Rename the alias in the internal table/alias datastructures.
841         for old_alias, new_alias in change_map.items():
842             if old_alias not in self.alias_map:
843                 continue
844             alias_data = self.alias_map[old_alias].relabeled_clone(change_map)
845             self.alias_map[new_alias] = alias_data
846             self.alias_refcount[new_alias] = self.alias_refcount[old_alias]
847             del self.alias_refcount[old_alias]
848             del self.alias_map[old_alias]
849 
850             table_aliases = self.table_map[alias_data.table_name]
851             for pos, alias in enumerate(table_aliases):
852                 if alias == old_alias:
853                     table_aliases[pos] = new_alias
854                     break
855         self.external_aliases = {change_map.get(alias, alias)
856                                  for alias in self.external_aliases}
857 
858     def bump_prefix(self, outer_query):
859         """
860         Change the alias prefix to the next letter in the alphabet in a way
861         that the outer query's aliases and this query's aliases will not
862         conflict. Even tables that previously had no alias will get an alias
863         after this call.
864         """
865         def prefix_gen():
866             """
867             Generate a sequence of characters in alphabetical order:
868                 -> 'A', 'B', 'C', ...
869 
870             When the alphabet is finished, the sequence will continue with the
871             Cartesian product:
872                 -> 'AA', 'AB', 'AC', ...
873             """
874             alphabet = ascii_uppercase
875             prefix = chr(ord(self.alias_prefix) + 1)
876             yield prefix
877             for n in count(1):
878                 seq = alphabet[alphabet.index(prefix):] if prefix else alphabet
879                 for s in product(seq, repeat=n):
880                     yield ''.join(s)
881                 prefix = None
882 
883         if self.alias_prefix != outer_query.alias_prefix:
884             # No clashes between self and outer query should be possible.
885             return
886 
887         # Explicitly avoid infinite loop. The constant divider is based on how
888         # much depth recursive subquery references add to the stack. This value
889         # might need to be adjusted when adding or removing function calls from
890         # the code path in charge of performing these operations.
891         local_recursion_limit = sys.getrecursionlimit() // 16
892         for pos, prefix in enumerate(prefix_gen()):
893             if prefix not in self.subq_aliases:
894                 self.alias_prefix = prefix
895                 break
896             if pos > local_recursion_limit:
897                 raise RecursionError(
898                     'Maximum recursion depth exceeded: too many subqueries.'
899                 )
900         self.subq_aliases = self.subq_aliases.union([self.alias_prefix])
901         outer_query.subq_aliases = outer_query.subq_aliases.union(self.subq_aliases)
902         self.change_aliases({
903             alias: '%s%d' % (self.alias_prefix, pos)
904             for pos, alias in enumerate(self.alias_map)
905         })
906 
907     def get_initial_alias(self):
908         """
909         Return the first alias for this query, after increasing its reference
910         count.
911         """
912         if self.alias_map:
913             alias = self.base_table
914             self.ref_alias(alias)
915         else:
916             alias = self.join(BaseTable(self.get_meta().db_table, None))
917         return alias
918 
919     def count_active_tables(self):
920         """
921         Return the number of tables in this query with a non-zero reference
922         count. After execution, the reference counts are zeroed, so tables
923         added in compiler will not be seen by this method.
924         """
925         return len([1 for count in self.alias_refcount.values() if count])
926 
927     def join(self, join, reuse=None, reuse_with_filtered_relation=False):
928         """
929         Return an alias for the 'join', either reusing an existing alias for
930         that join or creating a new one. 'join' is either a
931         sql.datastructures.BaseTable or Join.
932 
933         The 'reuse' parameter can be either None which means all joins are
934         reusable, or it can be a set containing the aliases that can be reused.
935 
936         The 'reuse_with_filtered_relation' parameter is used when computing
937         FilteredRelation instances.
938 
939         A join is always created as LOUTER if the lhs alias is LOUTER to make
940         sure chains like t1 LOUTER t2 INNER t3 aren't generated. All new
941         joins are created as LOUTER if the join is nullable.
942         """
943         if reuse_with_filtered_relation and reuse:
944             reuse_aliases = [
945                 a for a, j in self.alias_map.items()
946                 if a in reuse and j.equals(join, with_filtered_relation=False)
947             ]
948         else:
949             reuse_aliases = [
950                 a for a, j in self.alias_map.items()
951                 if (reuse is None or a in reuse) and j == join
952             ]
953         if reuse_aliases:
954             if join.table_alias in reuse_aliases:
955                 reuse_alias = join.table_alias
956             else:
957                 # Reuse the most recent alias of the joined table
958                 # (a many-to-many relation may be joined multiple times).
959                 reuse_alias = reuse_aliases[-1]
960             self.ref_alias(reuse_alias)
961             return reuse_alias
962 
963         # No reuse is possible, so we need a new alias.
964         alias, _ = self.table_alias(join.table_name, create=True, filtered_relation=join.filtered_relation)
965         if join.join_type:
966             if self.alias_map[join.parent_alias].join_type == LOUTER or join.nullable:
967                 join_type = LOUTER
968             else:
969                 join_type = INNER
970             join.join_type = join_type
971         join.table_alias = alias
972         self.alias_map[alias] = join
973         return alias
974 
975     def join_parent_model(self, opts, model, alias, seen):
976         """
977         Make sure the given 'model' is joined in the query. If 'model' isn't
978         a parent of 'opts' or if it is None this method is a no-op.
979 
980         The 'alias' is the root alias for starting the join, 'seen' is a dict
981         of model -> alias of existing joins. It must also contain a mapping
982         of None -> some alias. This will be returned in the no-op case.
983         """
984         if model in seen:
985             return seen[model]
986         chain = opts.get_base_chain(model)
987         if not chain:
988             return alias
989         curr_opts = opts
990         for int_model in chain:
991             if int_model in seen:
992                 curr_opts = int_model._meta
993                 alias = seen[int_model]
994                 continue
995             # Proxy model have elements in base chain
996             # with no parents, assign the new options
997             # object and skip to the next base in that
998             # case
999             if not curr_opts.parents[int_model]:
1000                 curr_opts = int_model._meta
1001                 continue
1002             link_field = curr_opts.get_ancestor_link(int_model)
1003             join_info = self.setup_joins([link_field.name], curr_opts, alias)
1004             curr_opts = int_model._meta
1005             alias = seen[int_model] = join_info.joins[-1]
1006         return alias or seen[None]
1007 
1008     def add_annotation(self, annotation, alias, is_summary=False):
1009         """Add a single annotation expression to the Query."""
1010         annotation = annotation.resolve_expression(self, allow_joins=True, reuse=None,
1011                                                    summarize=is_summary)
1012         self.append_annotation_mask([alias])
1013         self.annotations[alias] = annotation
1014 
1015     def resolve_expression(self, query, *args, **kwargs):
1016         clone = self.clone()
1017         # Subqueries need to use a different set of aliases than the outer query.
1018         clone.bump_prefix(query)
1019         clone.subquery = True
1020         # It's safe to drop ordering if the queryset isn't using slicing,
1021         # distinct(*fields) or select_for_update().
1022         if (self.low_mark == 0 and self.high_mark is None and
1023                 not self.distinct_fields and
1024                 not self.select_for_update):
1025             clone.clear_ordering(True)
1026         clone.where.resolve_expression(query, *args, **kwargs)
1027         for key, value in clone.annotations.items():
1028             resolved = value.resolve_expression(query, *args, **kwargs)
1029             if hasattr(resolved, 'external_aliases'):
1030                 resolved.external_aliases.update(clone.alias_map)
1031             clone.annotations[key] = resolved
1032         # Outer query's aliases are considered external.
1033         clone.external_aliases.update(
1034             alias for alias, table in query.alias_map.items()
1035             if (
1036                 isinstance(table, Join) and table.join_field.related_model._meta.db_table != alias
1037             ) or (
1038                 isinstance(table, BaseTable) and table.table_name != table.table_alias
1039             )
1040         )
1041         return clone
1042 
1043     def as_sql(self, compiler, connection):
1044         sql, params = self.get_compiler(connection=connection).as_sql()
1045         if self.subquery:
1046             sql = '(%s)' % sql
1047         return sql, params
1048 
1049     def resolve_lookup_value(self, value, can_reuse, allow_joins, simple_col):
1050         if hasattr(value, 'resolve_expression'):
1051             kwargs = {'reuse': can_reuse, 'allow_joins': allow_joins}
1052             if isinstance(value, F):
1053                 kwargs['simple_col'] = simple_col
1054             value = value.resolve_expression(self, **kwargs)
1055         elif isinstance(value, (list, tuple)):
1056             # The items of the iterable may be expressions and therefore need
1057             # to be resolved independently.
1058             for sub_value in value:
1059                 if hasattr(sub_value, 'resolve_expression'):
1060                     if isinstance(sub_value, F):
1061                         sub_value.resolve_expression(
1062                             self, reuse=can_reuse, allow_joins=allow_joins,
1063                             simple_col=simple_col,
1064                         )
1065                     else:
1066                         sub_value.resolve_expression(self, reuse=can_reuse, allow_joins=allow_joins)
1067         return value
1068 
1069     def solve_lookup_type(self, lookup):
1070         """
1071         Solve the lookup type from the lookup (e.g.: 'foobar__id__icontains').
1072         """
1073         lookup_splitted = lookup.split(LOOKUP_SEP)
1074         if self.annotations:
1075             expression, expression_lookups = refs_expression(lookup_splitted, self.annotations)
1076             if expression:
1077                 return expression_lookups, (), expression
1078         _, field, _, lookup_parts = self.names_to_path(lookup_splitted, self.get_meta())
1079         field_parts = lookup_splitted[0:len(lookup_splitted) - len(lookup_parts)]
1080         if len(lookup_parts) > 1 and not field_parts:
1081             raise FieldError(
1082                 'Invalid lookup "%s" for model %s".' %
1083                 (lookup, self.get_meta().model.__name__)
1084             )
1085         return lookup_parts, field_parts, False
1086 
1087     def check_query_object_type(self, value, opts, field):
1088         """
1089         Check whether the object passed while querying is of the correct type.
1090         If not, raise a ValueError specifying the wrong object.
1091         """
1092         if hasattr(value, '_meta'):
1093             if not check_rel_lookup_compatibility(value._meta.model, opts, field):
1094                 raise ValueError(
1095                     'Cannot query "%s": Must be "%s" instance.' %
1096                     (value, opts.object_name))
1097 
1098     def check_related_objects(self, field, value, opts):
1099         """Check the type of object passed to query relations."""
1100         if field.is_relation:
1101             # Check that the field and the queryset use the same model in a
1102             # query like .filter(author=Author.objects.all()). For example, the
1103             # opts would be Author's (from the author field) and value.model
1104             # would be Author.objects.all() queryset's .model (Author also).
1105             # The field is the related field on the lhs side.
1106             if (isinstance(value, Query) and not value.has_select_fields and
1107                     not check_rel_lookup_compatibility(value.model, opts, field)):
1108                 raise ValueError(
1109                     'Cannot use QuerySet for "%s": Use a QuerySet for "%s".' %
1110                     (value.model._meta.object_name, opts.object_name)
1111                 )
1112             elif hasattr(value, '_meta'):
1113                 self.check_query_object_type(value, opts, field)
1114             elif hasattr(value, '__iter__'):
1115                 for v in value:
1116                     self.check_query_object_type(v, opts, field)
1117 
1118     def build_lookup(self, lookups, lhs, rhs):
1119         """
1120         Try to extract transforms and lookup from given lhs.
1121 
1122         The lhs value is something that works like SQLExpression.
1123         The rhs value is what the lookup is going to compare against.
1124         The lookups is a list of names to extract using get_lookup()
1125         and get_transform().
1126         """
1127         # __exact is the default lookup if one isn't given.
1128         *transforms, lookup_name = lookups or ['exact']
1129         for name in transforms:
1130             lhs = self.try_transform(lhs, name)
1131         # First try get_lookup() so that the lookup takes precedence if the lhs
1132         # supports both transform and lookup for the name.
1133         lookup_class = lhs.get_lookup(lookup_name)
1134         if not lookup_class:
1135             if lhs.field.is_relation:
1136                 raise FieldError('Related Field got invalid lookup: {}'.format(lookup_name))
1137             # A lookup wasn't found. Try to interpret the name as a transform
1138             # and do an Exact lookup against it.
1139             lhs = self.try_transform(lhs, lookup_name)
1140             lookup_name = 'exact'
1141             lookup_class = lhs.get_lookup(lookup_name)
1142             if not lookup_class:
1143                 return
1144 
1145         lookup = lookup_class(lhs, rhs)
1146         # Interpret '__exact=None' as the sql 'is NULL'; otherwise, reject all
1147         # uses of None as a query value unless the lookup supports it.
1148         if lookup.rhs is None and not lookup.can_use_none_as_rhs:
1149             if lookup_name not in ('exact', 'iexact'):
1150                 raise ValueError("Cannot use None as a query value")
1151             return lhs.get_lookup('isnull')(lhs, True)
1152 
1153         # For Oracle '' is equivalent to null. The check must be done at this
1154         # stage because join promotion can't be done in the compiler. Using
1155         # DEFAULT_DB_ALIAS isn't nice but it's the best that can be done here.
1156         # A similar thing is done in is_nullable(), too.
1157         if (connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls and
1158                 lookup_name == 'exact' and lookup.rhs == ''):
1159             return lhs.get_lookup('isnull')(lhs, True)
1160 
1161         return lookup
1162 
1163     def try_transform(self, lhs, name):
1164         """
1165         Helper method for build_lookup(). Try to fetch and initialize
1166         a transform for name parameter from lhs.
1167         """
1168         transform_class = lhs.get_transform(name)
1169         if transform_class:
1170             return transform_class(lhs)
1171         else:
1172             output_field = lhs.output_field.__class__
1173             suggested_lookups = difflib.get_close_matches(name, output_field.get_lookups())
1174             if suggested_lookups:
1175                 suggestion = ', perhaps you meant %s?' % ' or '.join(suggested_lookups)
1176             else:
1177                 suggestion = '.'
1178             raise FieldError(
1179                 "Unsupported lookup '%s' for %s or join on the field not "
1180                 "permitted%s" % (name, output_field.__name__, suggestion)
1181             )
1182 
1183     def build_filter(self, filter_expr, branch_negated=False, current_negated=False,
1184                      can_reuse=None, allow_joins=True, split_subq=True,
1185                      reuse_with_filtered_relation=False, simple_col=False):
1186         """
1187         Build a WhereNode for a single filter clause but don't add it
1188         to this Query. Query.add_q() will then add this filter to the where
1189         Node.
1190 
1191         The 'branch_negated' tells us if the current branch contains any
1192         negations. This will be used to determine if subqueries are needed.
1193 
1194         The 'current_negated' is used to determine if the current filter is
1195         negated or not and this will be used to determine if IS NULL filtering
1196         is needed.
1197 
1198         The difference between current_negated and branch_negated is that
1199         branch_negated is set on first negation, but current_negated is
1200         flipped for each negation.
1201 
1202         Note that add_filter will not do any negating itself, that is done
1203         upper in the code by add_q().
1204 
1205         The 'can_reuse' is a set of reusable joins for multijoins.
1206 
1207         If 'reuse_with_filtered_relation' is True, then only joins in can_reuse
1208         will be reused.
1209 
1210         The method will create a filter clause that can be added to the current
1211         query. However, if the filter isn't added to the query then the caller
1212         is responsible for unreffing the joins used.
1213         """
1214         if isinstance(filter_expr, dict):
1215             raise FieldError("Cannot parse keyword query as dict")
1216         arg, value = filter_expr
1217         if not arg:
1218             raise FieldError("Cannot parse keyword query %r" % arg)
1219         lookups, parts, reffed_expression = self.solve_lookup_type(arg)
1220 
1221         if not getattr(reffed_expression, 'filterable', True):
1222             raise NotSupportedError(
1223                 reffed_expression.__class__.__name__ + ' is disallowed in '
1224                 'the filter clause.'
1225             )
1226 
1227         if not allow_joins and len(parts) > 1:
1228             raise FieldError("Joined field references are not permitted in this query")
1229 
1230         pre_joins = self.alias_refcount.copy()
1231         value = self.resolve_lookup_value(value, can_reuse, allow_joins, simple_col)
1232         used_joins = {k for k, v in self.alias_refcount.items() if v > pre_joins.get(k, 0)}
1233 
1234         clause = self.where_class()
1235         if reffed_expression:
1236             condition = self.build_lookup(lookups, reffed_expression, value)
1237             clause.add(condition, AND)
1238             return clause, []
1239 
1240         opts = self.get_meta()
1241         alias = self.get_initial_alias()
1242         allow_many = not branch_negated or not split_subq
1243 
1244         try:
1245             join_info = self.setup_joins(
1246                 parts, opts, alias, can_reuse=can_reuse, allow_many=allow_many,
1247                 reuse_with_filtered_relation=reuse_with_filtered_relation,
1248             )
1249 
1250             # Prevent iterator from being consumed by check_related_objects()
1251             if isinstance(value, Iterator):
1252                 value = list(value)
1253             self.check_related_objects(join_info.final_field, value, join_info.opts)
1254 
1255             # split_exclude() needs to know which joins were generated for the
1256             # lookup parts
1257             self._lookup_joins = join_info.joins
1258         except MultiJoin as e:
1259             return self.split_exclude(filter_expr, can_reuse, e.names_with_path)
1260 
1261         # Update used_joins before trimming since they are reused to determine
1262         # which joins could be later promoted to INNER.
1263         used_joins.update(join_info.joins)
1264         targets, alias, join_list = self.trim_joins(join_info.targets, join_info.joins, join_info.path)
1265         if can_reuse is not None:
1266             can_reuse.update(join_list)
1267 
1268         if join_info.final_field.is_relation:
1269             # No support for transforms for relational fields
1270             num_lookups = len(lookups)
1271             if num_lookups > 1:
1272                 raise FieldError('Related Field got invalid lookup: {}'.format(lookups[0]))
1273             if len(targets) == 1:
1274                 col = _get_col(targets[0], join_info.final_field, alias, simple_col)
1275             else:
1276                 col = MultiColSource(alias, targets, join_info.targets, join_info.final_field)
1277         else:
1278             col = _get_col(targets[0], join_info.final_field, alias, simple_col)
1279 
1280         condition = self.build_lookup(lookups, col, value)
1281         lookup_type = condition.lookup_name
1282         clause.add(condition, AND)
1283 
1284         require_outer = lookup_type == 'isnull' and condition.rhs is True and not current_negated
1285         if current_negated and (lookup_type != 'isnull' or condition.rhs is False) and condition.rhs is not None:
1286             require_outer = True
1287             if (lookup_type != 'isnull' and (
1288                     self.is_nullable(targets[0]) or
1289                     self.alias_map[join_list[-1]].join_type == LOUTER)):
1290                 # The condition added here will be SQL like this:
1291                 # NOT (col IS NOT NULL), where the first NOT is added in
1292                 # upper layers of code. The reason for addition is that if col
1293                 # is null, then col != someval will result in SQL "unknown"
1294                 # which isn't the same as in Python. The Python None handling
1295                 # is wanted, and it can be gotten by
1296                 # (col IS NULL OR col != someval)
1297                 #   <=>
1298                 # NOT (col IS NOT NULL AND col = someval).
1299                 lookup_class = targets[0].get_lookup('isnull')
1300                 col = _get_col(targets[0], join_info.targets[0], alias, simple_col)
1301                 clause.add(lookup_class(col, False), AND)
1302         return clause, used_joins if not require_outer else ()
1303 
1304     def add_filter(self, filter_clause):
1305         self.add_q(Q(**{filter_clause[0]: filter_clause[1]}))
1306 
1307     def add_q(self, q_object):
1308         """
1309         A preprocessor for the internal _add_q(). Responsible for doing final
1310         join promotion.
1311         """
1312         # For join promotion this case is doing an AND for the added q_object
1313         # and existing conditions. So, any existing inner join forces the join
1314         # type to remain inner. Existing outer joins can however be demoted.
1315         # (Consider case where rel_a is LOUTER and rel_a__col=1 is added - if
1316         # rel_a doesn't produce any rows, then the whole condition must fail.
1317         # So, demotion is OK.
1318         existing_inner = {a for a in self.alias_map if self.alias_map[a].join_type == INNER}
1319         clause, _ = self._add_q(q_object, self.used_aliases)
1320         if clause:
1321             self.where.add(clause, AND)
1322         self.demote_joins(existing_inner)
1323 
1324     def build_where(self, q_object):
1325         return self._add_q(q_object, used_aliases=set(), allow_joins=False, simple_col=True)[0]
1326 
1327     def _add_q(self, q_object, used_aliases, branch_negated=False,
1328                current_negated=False, allow_joins=True, split_subq=True,
1329                simple_col=False):
1330         """Add a Q-object to the current filter."""
1331         connector = q_object.connector
1332         current_negated = current_negated ^ q_object.negated
1333         branch_negated = branch_negated or q_object.negated
1334         target_clause = self.where_class(connector=connector,
1335                                          negated=q_object.negated)
1336         joinpromoter = JoinPromoter(q_object.connector, len(q_object.children), current_negated)
1337         for child in q_object.children:
1338             if isinstance(child, Node):
1339                 child_clause, needed_inner = self._add_q(
1340                     child, used_aliases, branch_negated,
1341                     current_negated, allow_joins, split_subq, simple_col)
1342                 joinpromoter.add_votes(needed_inner)
1343             else:
1344                 child_clause, needed_inner = self.build_filter(
1345                     child, can_reuse=used_aliases, branch_negated=branch_negated,
1346                     current_negated=current_negated, allow_joins=allow_joins,
1347                     split_subq=split_subq, simple_col=simple_col,
1348                 )
1349                 joinpromoter.add_votes(needed_inner)
1350             if child_clause:
1351                 target_clause.add(child_clause, connector)
1352         needed_inner = joinpromoter.update_join_types(self)
1353         return target_clause, needed_inner
1354 
1355     def build_filtered_relation_q(self, q_object, reuse, branch_negated=False, current_negated=False):
1356         """Add a FilteredRelation object to the current filter."""
1357         connector = q_object.connector
1358         current_negated ^= q_object.negated
1359         branch_negated = branch_negated or q_object.negated
1360         target_clause = self.where_class(connector=connector, negated=q_object.negated)
1361         for child in q_object.children:
1362             if isinstance(child, Node):
1363                 child_clause = self.build_filtered_relation_q(
1364                     child, reuse=reuse, branch_negated=branch_negated,
1365                     current_negated=current_negated,
1366                 )
1367             else:
1368                 child_clause, _ = self.build_filter(
1369                     child, can_reuse=reuse, branch_negated=branch_negated,
1370                     current_negated=current_negated,
1371                     allow_joins=True, split_subq=False,
1372                     reuse_with_filtered_relation=True,
1373                 )
1374             target_clause.add(child_clause, connector)
1375         return target_clause
1376 
1377     def add_filtered_relation(self, filtered_relation, alias):
1378         filtered_relation.alias = alias
1379         lookups = dict(get_children_from_q(filtered_relation.condition))
1380         for lookup in chain((filtered_relation.relation_name,), lookups):
1381             lookup_parts, field_parts, _ = self.solve_lookup_type(lookup)
1382             shift = 2 if not lookup_parts else 1
1383             if len(field_parts) > (shift + len(lookup_parts)):
1384                 raise ValueError(
1385                     "FilteredRelation's condition doesn't support nested "
1386                     "relations (got %r)." % lookup
1387                 )
1388         self._filtered_relations[filtered_relation.alias] = filtered_relation
1389 
1390     def names_to_path(self, names, opts, allow_many=True, fail_on_missing=False):
1391         """
1392         Walk the list of names and turns them into PathInfo tuples. A single
1393         name in 'names' can generate multiple PathInfos (m2m, for example).
1394 
1395         'names' is the path of names to travel, 'opts' is the model Options we
1396         start the name resolving from, 'allow_many' is as for setup_joins().
1397         If fail_on_missing is set to True, then a name that can't be resolved
1398         will generate a FieldError.
1399 
1400         Return a list of PathInfo tuples. In addition return the final field
1401         (the last used join field) and target (which is a field guaranteed to
1402         contain the same value as the final field). Finally, return those names
1403         that weren't found (which are likely transforms and the final lookup).
1404         """
1405         path, names_with_path = [], []
1406         for pos, name in enumerate(names):
1407             cur_names_with_path = (name, [])
1408             if name == 'pk':
1409                 name = opts.pk.name
1410 
1411             field = None
1412             filtered_relation = None
1413             try:
1414                 field = opts.get_field(name)
1415             except FieldDoesNotExist:
1416                 if name in self.annotation_select:
1417                     field = self.annotation_select[name].output_field
1418                 elif name in self._filtered_relations and pos == 0:
1419                     filtered_relation = self._filtered_relations[name]
1420                     field = opts.get_field(filtered_relation.relation_name)
1421             if field is not None:
1422                 # Fields that contain one-to-many relations with a generic
1423                 # model (like a GenericForeignKey) cannot generate reverse
1424                 # relations and therefore cannot be used for reverse querying.
1425                 if field.is_relation and not field.related_model:
1426                     raise FieldError(
1427                         "Field %r does not generate an automatic reverse "
1428                         "relation and therefore cannot be used for reverse "
1429                         "querying. If it is a GenericForeignKey, consider "
1430                         "adding a GenericRelation." % name
1431                     )
1432                 try:
1433                     model = field.model._meta.concrete_model
1434                 except AttributeError:
1435                     # QuerySet.annotate() may introduce fields that aren't
1436                     # attached to a model.
1437                     model = None
1438             else:
1439                 # We didn't find the current field, so move position back
1440                 # one step.
1441                 pos -= 1
1442                 if pos == -1 or fail_on_missing:
1443                     available = sorted([
1444                         *get_field_names_from_opts(opts),
1445                         *self.annotation_select,
1446                         *self._filtered_relations,
1447                     ])
1448                     raise FieldError("Cannot resolve keyword '%s' into field. "
1449                                      "Choices are: %s" % (name, ", ".join(available)))
1450                 break
1451             # Check if we need any joins for concrete inheritance cases (the
1452             # field lives in parent, but we are currently in one of its
1453             # children)
1454             if model is not opts.model:
1455                 path_to_parent = opts.get_path_to_parent(model)
1456                 if path_to_parent:
1457                     path.extend(path_to_parent)
1458                     cur_names_with_path[1].extend(path_to_parent)
1459                     opts = path_to_parent[-1].to_opts
1460             if hasattr(field, 'get_path_info'):
1461                 pathinfos = field.get_path_info(filtered_relation)
1462                 if not allow_many:
1463                     for inner_pos, p in enumerate(pathinfos):
1464                         if p.m2m:
1465                             cur_names_with_path[1].extend(pathinfos[0:inner_pos + 1])
1466                             names_with_path.append(cur_names_with_path)
1467                             raise MultiJoin(pos + 1, names_with_path)
1468                 last = pathinfos[-1]
1469                 path.extend(pathinfos)
1470                 final_field = last.join_field
1471                 opts = last.to_opts
1472                 targets = last.target_fields
1473                 cur_names_with_path[1].extend(pathinfos)
1474                 names_with_path.append(cur_names_with_path)
1475             else:
1476                 # Local non-relational field.
1477                 final_field = field
1478                 targets = (field,)
1479                 if fail_on_missing and pos + 1 != len(names):
1480                     raise FieldError(
1481                         "Cannot resolve keyword %r into field. Join on '%s'"
1482                         " not permitted." % (names[pos + 1], name))
1483                 break
1484         return path, final_field, targets, names[pos + 1:]
1485 
1486     def setup_joins(self, names, opts, alias, can_reuse=None, allow_many=True,
1487                     reuse_with_filtered_relation=False):
1488         """
1489         Compute the necessary table joins for the passage through the fields
1490         given in 'names'. 'opts' is the Options class for the current model
1491         (which gives the table we are starting from), 'alias' is the alias for
1492         the table to start the joining from.
1493 
1494         The 'can_reuse' defines the reverse foreign key joins we can reuse. It
1495         can be None in which case all joins are reusable or a set of aliases
1496         that can be reused. Note that non-reverse foreign keys are always
1497         reusable when using setup_joins().
1498 
1499         The 'reuse_with_filtered_relation' can be used to force 'can_reuse'
1500         parameter and force the relation on the given connections.
1501 
1502         If 'allow_many' is False, then any reverse foreign key seen will
1503         generate a MultiJoin exception.
1504 
1505         Return the final field involved in the joins, the target field (used
1506         for any 'where' constraint), the final 'opts' value, the joins, the
1507         field path traveled to generate the joins, and a transform function
1508         that takes a field and alias and is equivalent to `field.get_col(alias)`
1509         in the simple case but wraps field transforms if they were included in
1510         names.
1511 
1512         The target field is the field containing the concrete value. Final
1513         field can be something different, for example foreign key pointing to
1514         that value. Final field is needed for example in some value
1515         conversions (convert 'obj' in fk__id=obj to pk val using the foreign
1516         key field for example).
1517         """
1518         joins = [alias]
1519         # The transform can't be applied yet, as joins must be trimmed later.
1520         # To avoid making every caller of this method look up transforms
1521         # directly, compute transforms here and create a partial that converts
1522         # fields to the appropriate wrapped version.
1523 
1524         def final_transformer(field, alias):
1525             return field.get_col(alias)
1526 
1527         # Try resolving all the names as fields first. If there's an error,
1528         # treat trailing names as lookups until a field can be resolved.
1529         last_field_exception = None
1530         for pivot in range(len(names), 0, -1):
1531             try:
1532                 path, final_field, targets, rest = self.names_to_path(
1533                     names[:pivot], opts, allow_many, fail_on_missing=True,
1534                 )
1535             except FieldError as exc:
1536                 if pivot == 1:
1537                     # The first item cannot be a lookup, so it's safe
1538                     # to raise the field error here.
1539                     raise
1540                 else:
1541                     last_field_exception = exc
1542             else:
1543                 # The transforms are the remaining items that couldn't be
1544                 # resolved into fields.
1545                 transforms = names[pivot:]
1546                 break
1547         for name in transforms:
1548             def transform(field, alias, *, name, previous):
1549                 try:
1550                     wrapped = previous(field, alias)
1551                     return self.try_transform(wrapped, name)
1552                 except FieldError:
1553                     # FieldError is raised if the transform doesn't exist.
1554                     if isinstance(final_field, Field) and last_field_exception:
1555                         raise last_field_exception
1556                     else:
1557                         raise
1558             final_transformer = functools.partial(transform, name=name, previous=final_transformer)
1559         # Then, add the path to the query's joins. Note that we can't trim
1560         # joins at this stage - we will need the information about join type
1561         # of the trimmed joins.
1562         for join in path:
1563             if join.filtered_relation:
1564                 filtered_relation = join.filtered_relation.clone()
1565                 table_alias = filtered_relation.alias
1566             else:
1567                 filtered_relation = None
1568                 table_alias = None
1569             opts = join.to_opts
1570             if join.direct:
1571                 nullable = self.is_nullable(join.join_field)
1572             else:
1573                 nullable = True
1574             connection = Join(
1575                 opts.db_table, alias, table_alias, INNER, join.join_field,
1576                 nullable, filtered_relation=filtered_relation,
1577             )
1578             reuse = can_reuse if join.m2m or reuse_with_filtered_relation else None
1579             alias = self.join(
1580                 connection, reuse=reuse,
1581                 reuse_with_filtered_relation=reuse_with_filtered_relation,
1582             )
1583             joins.append(alias)
1584             if filtered_relation:
1585                 filtered_relation.path = joins[:]
1586         return JoinInfo(final_field, targets, opts, joins, path, final_transformer)
1587 
1588     def trim_joins(self, targets, joins, path):
1589         """
1590         The 'target' parameter is the final field being joined to, 'joins'
1591         is the full list of join aliases. The 'path' contain the PathInfos
1592         used to create the joins.
1593 
1594         Return the final target field and table alias and the new active
1595         joins.
1596 
1597         Always trim any direct join if the target column is already in the
1598         previous table. Can't trim reverse joins as it's unknown if there's
1599         anything on the other side of the join.
1600         """
1601         joins = joins[:]
1602         for pos, info in enumerate(reversed(path)):
1603             if len(joins) == 1 or not info.direct:
1604                 break
1605             if info.filtered_relation:
1606                 break
1607             join_targets = {t.column for t in info.join_field.foreign_related_fields}
1608             cur_targets = {t.column for t in targets}
1609             if not cur_targets.issubset(join_targets):
1610                 break
1611             targets_dict = {r[1].column: r[0] for r in info.join_field.related_fields if r[1].column in cur_targets}
1612             targets = tuple(targets_dict[t.column] for t in targets)
1613             self.unref_alias(joins.pop())
1614         return targets, joins[-1], joins
1615 
1616     @classmethod
1617     def _gen_col_aliases(cls, exprs):
1618         for expr in exprs:
1619             if isinstance(expr, Col):
1620                 yield expr.alias
1621             else:
1622                 yield from cls._gen_col_aliases(expr.get_source_expressions())
1623 
1624     def resolve_ref(self, name, allow_joins=True, reuse=None, summarize=False, simple_col=False):
1625         if not allow_joins and LOOKUP_SEP in name:
1626             raise FieldError("Joined field references are not permitted in this query")
1627         annotation = self.annotations.get(name)
1628         if annotation is not None:
1629             if not allow_joins:
1630                 for alias in self._gen_col_aliases([annotation]):
1631                     if isinstance(self.alias_map[alias], Join):
1632                         raise FieldError(
1633                             'Joined field references are not permitted in '
1634                             'this query'
1635                         )
1636             if summarize:
1637                 # Summarize currently means we are doing an aggregate() query
1638                 # which is executed as a wrapped subquery if any of the
1639                 # aggregate() elements reference an existing annotation. In
1640                 # that case we need to return a Ref to the subquery's annotation.
1641                 return Ref(name, self.annotation_select[name])
1642             else:
1643                 return annotation
1644         else:
1645             field_list = name.split(LOOKUP_SEP)
1646             join_info = self.setup_joins(field_list, self.get_meta(), self.get_initial_alias(), can_reuse=reuse)
1647             targets, final_alias, join_list = self.trim_joins(join_info.targets, join_info.joins, join_info.path)
1648             if not allow_joins and len(join_list) > 1:
1649                 raise FieldError('Joined field references are not permitted in this query')
1650             if len(targets) > 1:
1651                 raise FieldError("Referencing multicolumn fields with F() objects "
1652                                  "isn't supported")
1653             # Verify that the last lookup in name is a field or a transform:
1654             # transform_function() raises FieldError if not.
1655             join_info.transform_function(targets[0], final_alias)
1656             if reuse is not None:
1657                 reuse.update(join_list)
1658             col = _get_col(targets[0], join_info.targets[0], join_list[-1], simple_col)
1659             return col
1660 
1661     def split_exclude(self, filter_expr, can_reuse, names_with_path):
1662         """
1663         When doing an exclude against any kind of N-to-many relation, we need
1664         to use a subquery. This method constructs the nested query, given the
1665         original exclude filter (filter_expr) and the portion up to the first
1666         N-to-many relation field.
1667 
1668         For example, if the origin filter is ~Q(child__name='foo'), filter_expr
1669         is ('child__name', 'foo') and can_reuse is a set of joins usable for
1670         filters in the original query.
1671 
1672         We will turn this into equivalent of:
1673             WHERE NOT (pk IN (SELECT parent_id FROM thetable
1674                               WHERE name = 'foo' AND parent_id IS NOT NULL))
1675 
1676         It might be worth it to consider using WHERE NOT EXISTS as that has
1677         saner null handling, and is easier for the backend's optimizer to
1678         handle.
1679         """
1680         filter_lhs, filter_rhs = filter_expr
1681         if isinstance(filter_rhs, F):
1682             filter_expr = (filter_lhs, OuterRef(filter_rhs.name))
1683         # Generate the inner query.
1684         query = Query(self.model)
1685         query._filtered_relations = self._filtered_relations
1686         query.add_filter(filter_expr)
1687         query.clear_ordering(True)
1688         # Try to have as simple as possible subquery -> trim leading joins from
1689         # the subquery.
1690         trimmed_prefix, contains_louter = query.trim_start(names_with_path)
1691 
1692         # Add extra check to make sure the selected field will not be null
1693         # since we are adding an IN <subquery> clause. This prevents the
1694         # database from tripping over IN (...,NULL,...) selects and returning
1695         # nothing
1696         col = query.select[0]
1697         select_field = col.target
1698         alias = col.alias
1699         if self.is_nullable(select_field):
1700             lookup_class = select_field.get_lookup('isnull')
1701             lookup = lookup_class(select_field.get_col(alias), False)
1702             query.where.add(lookup, AND)
1703         if alias in can_reuse:
1704             pk = select_field.model._meta.pk
1705             # Need to add a restriction so that outer query's filters are in effect for
1706             # the subquery, too.
1707             query.bump_prefix(self)
1708             lookup_class = select_field.get_lookup('exact')
1709             # Note that the query.select[0].alias is different from alias
1710             # due to bump_prefix above.
1711             lookup = lookup_class(pk.get_col(query.select[0].alias),
1712                                   pk.get_col(alias))
1713             query.where.add(lookup, AND)
1714             query.external_aliases.add(alias)
1715 
1716         condition, needed_inner = self.build_filter(
1717             ('%s__in' % trimmed_prefix, query),
1718             current_negated=True, branch_negated=True, can_reuse=can_reuse)
1719         if contains_louter:
1720             or_null_condition, _ = self.build_filter(
1721                 ('%s__isnull' % trimmed_prefix, True),
1722                 current_negated=True, branch_negated=True, can_reuse=can_reuse)
1723             condition.add(or_null_condition, OR)
1724             # Note that the end result will be:
1725             # (outercol NOT IN innerq AND outercol IS NOT NULL) OR outercol IS NULL.
1726             # This might look crazy but due to how IN works, this seems to be
1727             # correct. If the IS NOT NULL check is removed then outercol NOT
1728             # IN will return UNKNOWN. If the IS NULL check is removed, then if
1729             # outercol IS NULL we will not match the row.
1730         return condition, needed_inner
1731 
1732     def set_empty(self):
1733         self.where.add(NothingNode(), AND)
1734 
1735     def is_empty(self):
1736         return any(isinstance(c, NothingNode) for c in self.where.children)
1737 
1738     def set_limits(self, low=None, high=None):
1739         """
1740         Adjust the limits on the rows retrieved. Use low/high to set these,
1741         as it makes it more Pythonic to read and write. When the SQL query is
1742         created, convert them to the appropriate offset and limit values.
1743 
1744         Apply any limits passed in here to the existing constraints. Add low
1745         to the current low value and clamp both to any existing high value.
1746         """
1747         if high is not None:
1748             if self.high_mark is not None:
1749                 self.high_mark = min(self.high_mark, self.low_mark + high)
1750             else:
1751                 self.high_mark = self.low_mark + high
1752         if low is not None:
1753             if self.high_mark is not None:
1754                 self.low_mark = min(self.high_mark, self.low_mark + low)
1755             else:
1756                 self.low_mark = self.low_mark + low
1757 
1758         if self.low_mark == self.high_mark:
1759             self.set_empty()
1760 
1761     def clear_limits(self):
1762         """Clear any existing limits."""
1763         self.low_mark, self.high_mark = 0, None
1764 
1765     def has_limit_one(self):
1766         return self.high_mark is not None and (self.high_mark - self.low_mark) == 1
1767 
1768     def can_filter(self):
1769         """
1770         Return True if adding filters to this instance is still possible.
1771 
1772         Typically, this means no limits or offsets have been put on the results.
1773         """
1774         return not self.low_mark and self.high_mark is None
1775 
1776     def clear_select_clause(self):
1777         """Remove all fields from SELECT clause."""
1778         self.select = ()
1779         self.default_cols = False
1780         self.select_related = False
1781         self.set_extra_mask(())
1782         self.set_annotation_mask(())
1783 
1784     def clear_select_fields(self):
1785         """
1786         Clear the list of fields to select (but not extra_select columns).
1787         Some queryset types completely replace any existing list of select
1788         columns.
1789         """
1790         self.select = ()
1791         self.values_select = ()
1792 
1793     def add_select_col(self, col):
1794         self.select += col,
1795         self.values_select += col.output_field.name,
1796 
1797     def set_select(self, cols):
1798         self.default_cols = False
1799         self.select = tuple(cols)
1800 
1801     def add_distinct_fields(self, *field_names):
1802         """
1803         Add and resolve the given fields to the query's "distinct on" clause.
1804         """
1805         self.distinct_fields = field_names
1806         self.distinct = True
1807 
1808     def add_fields(self, field_names, allow_m2m=True):
1809         """
1810         Add the given (model) fields to the select set. Add the field names in
1811         the order specified.
1812         """
1813         alias = self.get_initial_alias()
1814         opts = self.get_meta()
1815 
1816         try:
1817             cols = []
1818             for name in field_names:
1819                 # Join promotion note - we must not remove any rows here, so
1820                 # if there is no existing joins, use outer join.
1821                 join_info = self.setup_joins(name.split(LOOKUP_SEP), opts, alias, allow_many=allow_m2m)
1822                 targets, final_alias, joins = self.trim_joins(
1823                     join_info.targets,
1824                     join_info.joins,
1825                     join_info.path,
1826                 )
1827                 for target in targets:
1828                     cols.append(join_info.transform_function(target, final_alias))
1829             if cols:
1830                 self.set_select(cols)
1831         except MultiJoin:
1832             raise FieldError("Invalid field name: '%s'" % name)
1833         except FieldError:
1834             if LOOKUP_SEP in name:
1835                 # For lookups spanning over relationships, show the error
1836                 # from the model on which the lookup failed.
1837                 raise
1838             else:
1839                 names = sorted([
1840                     *get_field_names_from_opts(opts), *self.extra,
1841                     *self.annotation_select, *self._filtered_relations
1842                 ])
1843                 raise FieldError("Cannot resolve keyword %r into field. "
1844                                  "Choices are: %s" % (name, ", ".join(names)))
1845 
1846     def add_ordering(self, *ordering):
1847         """
1848         Add items from the 'ordering' sequence to the query's "order by"
1849         clause. These items are either field names (not column names) --
1850         possibly with a direction prefix ('-' or '?') -- or OrderBy
1851         expressions.
1852 
1853         If 'ordering' is empty, clear all ordering from the query.
1854         """
1855         errors = []
1856         for item in ordering:
1857             if not hasattr(item, 'resolve_expression') and not ORDER_PATTERN.match(item):
1858                 errors.append(item)
1859             if getattr(item, 'contains_aggregate', False):
1860                 raise FieldError(
1861                     'Using an aggregate in order_by() without also including '
1862                     'it in annotate() is not allowed: %s' % item
1863                 )
1864         if errors:
1865             raise FieldError('Invalid order_by arguments: %s' % errors)
1866         if ordering:
1867             self.order_by += ordering
1868         else:
1869             self.default_ordering = False
1870 
1871     def clear_ordering(self, force_empty):
1872         """
1873         Remove any ordering settings. If 'force_empty' is True, there will be
1874         no ordering in the resulting query (not even the model's default).
1875         """
1876         self.order_by = ()
1877         self.extra_order_by = ()
1878         if force_empty:
1879             self.default_ordering = False
1880 
1881     def set_group_by(self):
1882         """
1883         Expand the GROUP BY clause required by the query.
1884 
1885         This will usually be the set of all non-aggregate fields in the
1886         return data. If the database backend supports grouping by the
1887         primary key, and the query would be equivalent, the optimization
1888         will be made automatically.
1889         """
1890         group_by = list(self.select)
1891         if self.annotation_select:
1892             for alias, annotation in self.annotation_select.items():
1893                 try:
1894                     inspect.getcallargs(annotation.get_group_by_cols, alias=alias)
1895                 except TypeError:
1896                     annotation_class = annotation.__class__
1897                     msg = (
1898                         '`alias=None` must be added to the signature of '
1899                         '%s.%s.get_group_by_cols().'
1900                     ) % (annotation_class.__module__, annotation_class.__qualname__)
1901                     warnings.warn(msg, category=RemovedInDjango40Warning)
1902                     group_by_cols = annotation.get_group_by_cols()
1903                 else:
1904                     group_by_cols = annotation.get_group_by_cols(alias=alias)
1905                 group_by.extend(group_by_cols)
1906         self.group_by = tuple(group_by)
1907 
1908     def add_select_related(self, fields):
1909         """
1910         Set up the select_related data structure so that we only select
1911         certain related models (as opposed to all models, when
1912         self.select_related=True).
1913         """
1914         if isinstance(self.select_related, bool):
1915             field_dict = {}
1916         else:
1917             field_dict = self.select_related
1918         for field in fields:
1919             d = field_dict
1920             for part in field.split(LOOKUP_SEP):
1921                 d = d.setdefault(part, {})
1922         self.select_related = field_dict
1923 
1924     def add_extra(self, select, select_params, where, params, tables, order_by):
1925         """
1926         Add data to the various extra_* attributes for user-created additions
1927         to the query.
1928         """
1929         if select:
1930             # We need to pair any placeholder markers in the 'select'
1931             # dictionary with their parameters in 'select_params' so that
1932             # subsequent updates to the select dictionary also adjust the
1933             # parameters appropriately.
1934             select_pairs = {}
1935             if select_params:
1936                 param_iter = iter(select_params)
1937             else:
1938                 param_iter = iter([])
1939             for name, entry in select.items():
1940                 entry = str(entry)
1941                 entry_params = []
1942                 pos = entry.find("%s")
1943                 while pos != -1:
1944                     if pos == 0 or entry[pos - 1] != '%':
1945                         entry_params.append(next(param_iter))
1946                     pos = entry.find("%s", pos + 2)
1947                 select_pairs[name] = (entry, entry_params)
1948             self.extra.update(select_pairs)
1949         if where or params:
1950             self.where.add(ExtraWhere(where, params), AND)
1951         if tables:
1952             self.extra_tables += tuple(tables)
1953         if order_by:
1954             self.extra_order_by = order_by
1955 
1956     def clear_deferred_loading(self):
1957         """Remove any fields from the deferred loading set."""
1958         self.deferred_loading = (frozenset(), True)
1959 
1960     def add_deferred_loading(self, field_names):
1961         """
1962         Add the given list of model field names to the set of fields to
1963         exclude from loading from the database when automatic column selection
1964         is done. Add the new field names to any existing field names that
1965         are deferred (or removed from any existing field names that are marked
1966         as the only ones for immediate loading).
1967         """
1968         # Fields on related models are stored in the literal double-underscore
1969         # format, so that we can use a set datastructure. We do the foo__bar
1970         # splitting and handling when computing the SQL column names (as part of
1971         # get_columns()).
1972         existing, defer = self.deferred_loading
1973         if defer:
1974             # Add to existing deferred names.
1975             self.deferred_loading = existing.union(field_names), True
1976         else:
1977             # Remove names from the set of any existing "immediate load" names.
1978             self.deferred_loading = existing.difference(field_names), False
1979 
1980     def add_immediate_loading(self, field_names):
1981         """
1982         Add the given list of model field names to the set of fields to
1983         retrieve when the SQL is executed ("immediate loading" fields). The
1984         field names replace any existing immediate loading field names. If
1985         there are field names already specified for deferred loading, remove
1986         those names from the new field_names before storing the new names
1987         for immediate loading. (That is, immediate loading overrides any
1988         existing immediate values, but respects existing deferrals.)
1989         """
1990         existing, defer = self.deferred_loading
1991         field_names = set(field_names)
1992         if 'pk' in field_names:
1993             field_names.remove('pk')
1994             field_names.add(self.get_meta().pk.name)
1995 
1996         if defer:
1997             # Remove any existing deferred names from the current set before
1998             # setting the new names.
1999             self.deferred_loading = field_names.difference(existing), False
2000         else:
2001             # Replace any existing "immediate load" field names.
2002             self.deferred_loading = frozenset(field_names), False
2003 
2004     def get_loaded_field_names(self):
2005         """
2006         If any fields are marked to be deferred, return a dictionary mapping
2007         models to a set of names in those fields that will be loaded. If a
2008         model is not in the returned dictionary, none of its fields are
2009         deferred.
2010 
2011         If no fields are marked for deferral, return an empty dictionary.
2012         """
2013         # We cache this because we call this function multiple times
2014         # (compiler.fill_related_selections, query.iterator)
2015         try:
2016             return self._loaded_field_names_cache
2017         except AttributeError:
2018             collection = {}
2019             self.deferred_to_data(collection, self.get_loaded_field_names_cb)
2020             self._loaded_field_names_cache = collection
2021             return collection
2022 
2023     def get_loaded_field_names_cb(self, target, model, fields):
2024         """Callback used by get_deferred_field_names()."""
2025         target[model] = {f.attname for f in fields}
2026 
2027     def set_annotation_mask(self, names):
2028         """Set the mask of annotations that will be returned by the SELECT."""
2029         if names is None:
2030             self.annotation_select_mask = None
2031         else:
2032             self.annotation_select_mask = set(names)
2033         self._annotation_select_cache = None
2034 
2035     def append_annotation_mask(self, names):
2036         if self.annotation_select_mask is not None:
2037             self.set_annotation_mask(self.annotation_select_mask.union(names))
2038 
2039     def set_extra_mask(self, names):
2040         """
2041         Set the mask of extra select items that will be returned by SELECT.
2042         Don't remove them from the Query since they might be used later.
2043         """
2044         if names is None:
2045             self.extra_select_mask = None
2046         else:
2047             self.extra_select_mask = set(names)
2048         self._extra_select_cache = None
2049 
2050     def set_values(self, fields):
2051         self.select_related = False
2052         self.clear_deferred_loading()
2053         self.clear_select_fields()
2054 
2055         if self.group_by is True:
2056             self.add_fields((f.attname for f in self.model._meta.concrete_fields), False)
2057             self.set_group_by()
2058             self.clear_select_fields()
2059 
2060         if fields:
2061             field_names = []
2062             extra_names = []
2063             annotation_names = []
2064             if not self.extra and not self.annotations:
2065                 # Shortcut - if there are no extra or annotations, then
2066                 # the values() clause must be just field names.
2067                 field_names = list(fields)
2068             else:
2069                 self.default_cols = False
2070                 for f in fields:
2071                     if f in self.extra_select:
2072                         extra_names.append(f)
2073                     elif f in self.annotation_select:
2074                         annotation_names.append(f)
2075                     else:
2076                         field_names.append(f)
2077             self.set_extra_mask(extra_names)
2078             self.set_annotation_mask(annotation_names)
2079         else:
2080             field_names = [f.attname for f in self.model._meta.concrete_fields]
2081 
2082         self.values_select = tuple(field_names)
2083         self.add_fields(field_names, True)
2084 
2085     @property
2086     def annotation_select(self):
2087         """
2088         Return the dictionary of aggregate columns that are not masked and
2089         should be used in the SELECT clause. Cache this result for performance.
2090         """
2091         if self._annotation_select_cache is not None:
2092             return self._annotation_select_cache
2093         elif not self.annotations:
2094             return {}
2095         elif self.annotation_select_mask is not None:
2096             self._annotation_select_cache = {
2097                 k: v for k, v in self.annotations.items()
2098                 if k in self.annotation_select_mask
2099             }
2100             return self._annotation_select_cache
2101         else:
2102             return self.annotations
2103 
2104     @property
2105     def extra_select(self):
2106         if self._extra_select_cache is not None:
2107             return self._extra_select_cache
2108         if not self.extra:
2109             return {}
2110         elif self.extra_select_mask is not None:
2111             self._extra_select_cache = {
2112                 k: v for k, v in self.extra.items()
2113                 if k in self.extra_select_mask
2114             }
2115             return self._extra_select_cache
2116         else:
2117             return self.extra
2118 
2119     def trim_start(self, names_with_path):
2120         """
2121         Trim joins from the start of the join path. The candidates for trim
2122         are the PathInfos in names_with_path structure that are m2m joins.
2123 
2124         Also set the select column so the start matches the join.
2125 
2126         This method is meant to be used for generating the subquery joins &
2127         cols in split_exclude().
2128 
2129         Return a lookup usable for doing outerq.filter(lookup=self) and a
2130         boolean indicating if the joins in the prefix contain a LEFT OUTER join.
2131         _"""
2132         all_paths = []
2133         for _, paths in names_with_path:
2134             all_paths.extend(paths)
2135         contains_louter = False
2136         # Trim and operate only on tables that were generated for
2137         # the lookup part of the query. That is, avoid trimming
2138         # joins generated for F() expressions.
2139         lookup_tables = [
2140             t for t in self.alias_map
2141             if t in self._lookup_joins or t == self.base_table
2142         ]
2143         for trimmed_paths, path in enumerate(all_paths):
2144             if path.m2m:
2145                 break
2146             if self.alias_map[lookup_tables[trimmed_paths + 1]].join_type == LOUTER:
2147                 contains_louter = True
2148             alias = lookup_tables[trimmed_paths]
2149             self.unref_alias(alias)
2150         # The path.join_field is a Rel, lets get the other side's field
2151         join_field = path.join_field.field
2152         # Build the filter prefix.
2153         paths_in_prefix = trimmed_paths
2154         trimmed_prefix = []
2155         for name, path in names_with_path:
2156             if paths_in_prefix - len(path) < 0:
2157                 break
2158             trimmed_prefix.append(name)
2159             paths_in_prefix -= len(path)
2160         trimmed_prefix.append(
2161             join_field.foreign_related_fields[0].name)
2162         trimmed_prefix = LOOKUP_SEP.join(trimmed_prefix)
2163         # Lets still see if we can trim the first join from the inner query
2164         # (that is, self). We can't do this for:
2165         # - LEFT JOINs because we would miss those rows that have nothing on
2166         #   the outer side,
2167         # - INNER JOINs from filtered relations because we would miss their
2168         #   filters.
2169         first_join = self.alias_map[lookup_tables[trimmed_paths + 1]]
2170         if first_join.join_type != LOUTER and not first_join.filtered_relation:
2171             select_fields = [r[0] for r in join_field.related_fields]
2172             select_alias = lookup_tables[trimmed_paths + 1]
2173             self.unref_alias(lookup_tables[trimmed_paths])
2174             extra_restriction = join_field.get_extra_restriction(
2175                 self.where_class, None, lookup_tables[trimmed_paths + 1])
2176             if extra_restriction:
2177                 self.where.add(extra_restriction, AND)
2178         else:
2179             # TODO: It might be possible to trim more joins from the start of the
2180             # inner query if it happens to have a longer join chain containing the
2181             # values in select_fields. Lets punt this one for now.
2182             select_fields = [r[1] for r in join_field.related_fields]
2183             select_alias = lookup_tables[trimmed_paths]
2184         # The found starting point is likely a Join instead of a BaseTable reference.
2185         # But the first entry in the query's FROM clause must not be a JOIN.
2186         for table in self.alias_map:
2187             if self.alias_refcount[table] > 0:
2188                 self.alias_map[table] = BaseTable(self.alias_map[table].table_name, table)
2189                 break
2190         self.set_select([f.get_col(select_alias) for f in select_fields])
2191         return trimmed_prefix, contains_louter
2192 
2193     def is_nullable(self, field):
2194         """
2195         Check if the given field should be treated as nullable.
2196 
2197         Some backends treat '' as null and Django treats such fields as
2198         nullable for those backends. In such situations field.null can be
2199         False even if we should treat the field as nullable.
2200         """
2201         # We need to use DEFAULT_DB_ALIAS here, as QuerySet does not have
2202         # (nor should it have) knowledge of which connection is going to be
2203         # used. The proper fix would be to defer all decisions where
2204         # is_nullable() is needed to the compiler stage, but that is not easy
2205         # to do currently.
2206         return (
2207             connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls and
2208             field.empty_strings_allowed
2209         ) or field.null

</code><intended_behavior>This class provides additional context to the issue.</intended_behavior>]
2025-10-18 10:25:17.712 | INFO     | Search completed. Bug locations: [<file>django/db/models/sql/query.py</file>
<class>Query</class>
<method>get_aggregation</method>
<code>
410     def get_aggregation(self, using, added_aggregate_names):
411         """
412         Return the dictionary with the values of the existing aggregations.
413         """
414         if not self.annotation_select:
415             return {}
416         has_limit = self.low_mark != 0 or self.high_mark is not None
417         existing_annotations = [
418             annotation for alias, annotation
419             in self.annotations.items()
420             if alias not in added_aggregate_names
421         ]
422         # Decide if we need to use a subquery.
423         #
424         # Existing annotations would cause incorrect results as get_aggregation()
425         # must produce just one result and thus must not use GROUP BY. But we
426         # aren't smart enough to remove the existing annotations from the
427         # query, so those would force us to use GROUP BY.
428         #
429         # If the query has limit or distinct, or uses set operations, then
430         # those operations must be done in a subquery so that the query
431         # aggregates on the limit and/or distinct results instead of applying
432         # the distinct and limit after the aggregation.
433         if (isinstance(self.group_by, tuple) or has_limit or existing_annotations or
434                 self.distinct or self.combinator):
435             from django.db.models.sql.subqueries import AggregateQuery
436             outer_query = AggregateQuery(self.model)
437             inner_query = self.clone()
438             inner_query.select_for_update = False
439             inner_query.select_related = False
440             inner_query.set_annotation_mask(self.annotation_select)
441             if not has_limit and not self.distinct_fields:
442                 # Queries with distinct_fields need ordering and when a limit
443                 # is applied we must take the slice from the ordered query.
444                 # Otherwise no need for ordering.
445                 inner_query.clear_ordering(True)
446             if not inner_query.distinct:
447                 # If the inner query uses default select and it has some
448                 # aggregate annotations, then we must make sure the inner
449                 # query is grouped by the main model's primary key. However,
450                 # clearing the select clause can alter results if distinct is
451                 # used.
452                 has_existing_aggregate_annotations = any(
453                     annotation for annotation in existing_annotations
454                     if getattr(annotation, 'contains_aggregate', True)
455                 )
456                 if inner_query.default_cols and has_existing_aggregate_annotations:
457                     inner_query.group_by = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)
458                 inner_query.default_cols = False
459 
460             relabels = {t: 'subquery' for t in inner_query.alias_map}
461             relabels[None] = 'subquery'
462             # Remove any aggregates marked for reduction from the subquery
463             # and move them to the outer AggregateQuery.
464             col_cnt = 0
465             for alias, expression in list(inner_query.annotation_select.items()):
466                 annotation_select_mask = inner_query.annotation_select_mask
467                 if expression.is_summary:
468                     expression, col_cnt = inner_query.rewrite_cols(expression, col_cnt)
469                     outer_query.annotations[alias] = expression.relabeled_clone(relabels)
470                     del inner_query.annotations[alias]
471                     annotation_select_mask.remove(alias)
472                 # Make sure the annotation_select wont use cached results.
473                 inner_query.set_annotation_mask(inner_query.annotation_select_mask)
474             if inner_query.select == () and not inner_query.default_cols and not inner_query.annotation_select_mask:
475                 # In case of Model.objects[0:3].count(), there would be no
476                 # field selected in the inner query, yet we must use a subquery.
477                 # So, make sure at least one field is selected.
478                 inner_query.select = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)
479             try:
480                 outer_query.add_subquery(inner_query, using)
481             except EmptyResultSet:
482                 return {
483                     alias: None
484                     for alias in outer_query.annotation_select
485                 }
486         else:
487             outer_query = self
488             self.select = ()
489             self.default_cols = False
490             self.extra = {}
491 
492         outer_query.clear_ordering(True)
493         outer_query.clear_limits()
494         outer_query.select_for_update = False
495         outer_query.select_related = False
496         compiler = outer_query.get_compiler(using)
497         result = compiler.execute_sql(SINGLE)
498         if result is None:
499             result = [None] * len(outer_query.annotation_select)
500 
501         converters = compiler.get_converters(outer_query.annotation_select.values())
502         result = next(compiler.apply_converters((result,), converters))
503 
504         return dict(zip(outer_query.annotation_select, result))

</code><intended_behavior>The `get_aggregation` method should be updated to ensure it correctly maintains the necessary INNER JOINs when handling queries that involve fields from parent models due to model inheritance. This involves refining the logic that determines when to set `inner_query.default_cols` to `False` and how `inner_query.group_by` is adjusted. Particularly, the modification should:

- Add a condition to check if the annotation involves fields from an inherited model. If so, the method should preserve the `default_cols` as `True` or ensure the necessary JOINs are explicitly included in the `group_by`.
- Ensure that INNER JOINs necessary for accessing inherited model fields are not dropped even when `default_cols` is set to `False`. This may involve more nuanced handling or additional checks around the conditions that currently lead to setting `inner_query.default_cols` to `False`.

The objective is to preserve all existing functionalities while ensuring that count operations on annotated querysets referencing inherited model fields do not result in errors due to missing columns. This might require a more sophisticated analysis of the queryset's structure to understand when JOINs are necessary for correct count aggregation.</intended_behavior>, <file>django/db/models/sql/query.py</file>
<class>Query</class>
<method>None</method>
<code>
145 class Query(BaseExpression):
146     """A single SQL query."""
147 
148     alias_prefix = 'T'
149     subq_aliases = frozenset([alias_prefix])
150 
151     compiler = 'SQLCompiler'
152 
153     def __init__(self, model, where=WhereNode):
154         self.model = model
155         self.alias_refcount = {}
156         # alias_map is the most important data structure regarding joins.
157         # It's used for recording which joins exist in the query and what
158         # types they are. The key is the alias of the joined table (possibly
159         # the table name) and the value is a Join-like object (see
160         # sql.datastructures.Join for more information).
161         self.alias_map = {}
162         # Sometimes the query contains references to aliases in outer queries (as
163         # a result of split_exclude). Correct alias quoting needs to know these
164         # aliases too.
165         self.external_aliases = set()
166         self.table_map = {}     # Maps table names to list of aliases.
167         self.default_cols = True
168         self.default_ordering = True
169         self.standard_ordering = True
170         self.used_aliases = set()
171         self.filter_is_sticky = False
172         self.subquery = False
173 
174         # SQL-related attributes
175         # Select and related select clauses are expressions to use in the
176         # SELECT clause of the query.
177         # The select is used for cases where we want to set up the select
178         # clause to contain other than default fields (values(), subqueries...)
179         # Note that annotations go to annotations dictionary.
180         self.select = ()
181         self.where = where()
182         self.where_class = where
183         # The group_by attribute can have one of the following forms:
184         #  - None: no group by at all in the query
185         #  - A tuple of expressions: group by (at least) those expressions.
186         #    String refs are also allowed for now.
187         #  - True: group by all select fields of the model
188         # See compiler.get_group_by() for details.
189         self.group_by = None
190         self.order_by = ()
191         self.low_mark, self.high_mark = 0, None  # Used for offset/limit
192         self.distinct = False
193         self.distinct_fields = ()
194         self.select_for_update = False
195         self.select_for_update_nowait = False
196         self.select_for_update_skip_locked = False
197         self.select_for_update_of = ()
198 
199         self.select_related = False
200         # Arbitrary limit for select_related to prevents infinite recursion.
201         self.max_depth = 5
202 
203         # Holds the selects defined by a call to values() or values_list()
204         # excluding annotation_select and extra_select.
205         self.values_select = ()
206 
207         # SQL annotation-related attributes
208         self.annotations = {}  # Maps alias -> Annotation Expression
209         self.annotation_select_mask = None
210         self._annotation_select_cache = None
211 
212         # Set combination attributes
213         self.combinator = None
214         self.combinator_all = False
215         self.combined_queries = ()
216 
217         # These are for extensions. The contents are more or less appended
218         # verbatim to the appropriate clause.
219         self.extra = {}  # Maps col_alias -> (col_sql, params).
220         self.extra_select_mask = None
221         self._extra_select_cache = None
222 
223         self.extra_tables = ()
224         self.extra_order_by = ()
225 
226         # A tuple that is a set of model field names and either True, if these
227         # are the fields to defer, or False if these are the only fields to
228         # load.
229         self.deferred_loading = (frozenset(), True)
230 
231         self._filtered_relations = {}
232 
233         self.explain_query = False
234         self.explain_format = None
235         self.explain_options = {}
236 
237     @property
238     def output_field(self):
239         if len(self.select) == 1:
240             return self.select[0].field
241         elif len(self.annotation_select) == 1:
242             return next(iter(self.annotation_select.values())).output_field
243 
244     @property
245     def has_select_fields(self):
246         return bool(self.select or self.annotation_select_mask or self.extra_select_mask)
247 
248     @cached_property
249     def base_table(self):
250         for alias in self.alias_map:
251             return alias
252 
253     def __str__(self):
254         """
255         Return the query as a string of SQL with the parameter values
256         substituted in (use sql_with_params() to see the unsubstituted string).
257 
258         Parameter values won't necessarily be quoted correctly, since that is
259         done by the database interface at execution time.
260         """
261         sql, params = self.sql_with_params()
262         return sql % params
263 
264     def sql_with_params(self):
265         """
266         Return the query as an SQL string and the parameters that will be
267         substituted into the query.
268         """
269         return self.get_compiler(DEFAULT_DB_ALIAS).as_sql()
270 
271     def __deepcopy__(self, memo):
272         """Limit the amount of work when a Query is deepcopied."""
273         result = self.clone()
274         memo[id(self)] = result
275         return result
276 
277     def get_compiler(self, using=None, connection=None):
278         if using is None and connection is None:
279             raise ValueError("Need either using or connection")
280         if using:
281             connection = connections[using]
282         return connection.ops.compiler(self.compiler)(self, connection, using)
283 
284     def get_meta(self):
285         """
286         Return the Options instance (the model._meta) from which to start
287         processing. Normally, this is self.model._meta, but it can be changed
288         by subclasses.
289         """
290         return self.model._meta
291 
292     def clone(self):
293         """
294         Return a copy of the current Query. A lightweight alternative to
295         to deepcopy().
296         """
297         obj = Empty()
298         obj.__class__ = self.__class__
299         # Copy references to everything.
300         obj.__dict__ = self.__dict__.copy()
301         # Clone attributes that can't use shallow copy.
302         obj.alias_refcount = self.alias_refcount.copy()
303         obj.alias_map = self.alias_map.copy()
304         obj.external_aliases = self.external_aliases.copy()
305         obj.table_map = self.table_map.copy()
306         obj.where = self.where.clone()
307         obj.annotations = self.annotations.copy()
308         if self.annotation_select_mask is None:
309             obj.annotation_select_mask = None
310         else:
311             obj.annotation_select_mask = self.annotation_select_mask.copy()
312         # _annotation_select_cache cannot be copied, as doing so breaks the
313         # (necessary) state in which both annotations and
314         # _annotation_select_cache point to the same underlying objects.
315         # It will get re-populated in the cloned queryset the next time it's
316         # used.
317         obj._annotation_select_cache = None
318         obj.extra = self.extra.copy()
319         if self.extra_select_mask is None:
320             obj.extra_select_mask = None
321         else:
322             obj.extra_select_mask = self.extra_select_mask.copy()
323         if self._extra_select_cache is None:
324             obj._extra_select_cache = None
325         else:
326             obj._extra_select_cache = self._extra_select_cache.copy()
327         if 'subq_aliases' in self.__dict__:
328             obj.subq_aliases = self.subq_aliases.copy()
329         obj.used_aliases = self.used_aliases.copy()
330         obj._filtered_relations = self._filtered_relations.copy()
331         # Clear the cached_property
332         try:
333             del obj.base_table
334         except AttributeError:
335             pass
336         return obj
337 
338     def chain(self, klass=None):
339         """
340         Return a copy of the current Query that's ready for another operation.
341         The klass argument changes the type of the Query, e.g. UpdateQuery.
342         """
343         obj = self.clone()
344         if klass and obj.__class__ != klass:
345             obj.__class__ = klass
346         if not obj.filter_is_sticky:
347             obj.used_aliases = set()
348         obj.filter_is_sticky = False
349         if hasattr(obj, '_setup_query'):
350             obj._setup_query()
351         return obj
352 
353     def relabeled_clone(self, change_map):
354         clone = self.clone()
355         clone.change_aliases(change_map)
356         return clone
357 
358     def rewrite_cols(self, annotation, col_cnt):
359         # We must make sure the inner query has the referred columns in it.
360         # If we are aggregating over an annotation, then Django uses Ref()
361         # instances to note this. However, if we are annotating over a column
362         # of a related model, then it might be that column isn't part of the
363         # SELECT clause of the inner query, and we must manually make sure
364         # the column is selected. An example case is:
365         #    .aggregate(Sum('author__awards'))
366         # Resolving this expression results in a join to author, but there
367         # is no guarantee the awards column of author is in the select clause
368         # of the query. Thus we must manually add the column to the inner
369         # query.
370         orig_exprs = annotation.get_source_expressions()
371         new_exprs = []
372         for expr in orig_exprs:
373             # FIXME: These conditions are fairly arbitrary. Identify a better
374             # method of having expressions decide which code path they should
375             # take.
376             if isinstance(expr, Ref):
377                 # Its already a Ref to subquery (see resolve_ref() for
378                 # details)
379                 new_exprs.append(expr)
380             elif isinstance(expr, (WhereNode, Lookup)):
381                 # Decompose the subexpressions further. The code here is
382                 # copied from the else clause, but this condition must appear
383                 # before the contains_aggregate/is_summary condition below.
384                 new_expr, col_cnt = self.rewrite_cols(expr, col_cnt)
385                 new_exprs.append(new_expr)
386             else:
387                 # Reuse aliases of expressions already selected in subquery.
388                 for col_alias, selected_annotation in self.annotation_select.items():
389                     if selected_annotation == expr:
390                         new_expr = Ref(col_alias, expr)
391                         break
392                 else:
393                     # An expression that is not selected the subquery.
394                     if isinstance(expr, Col) or (expr.contains_aggregate and not expr.is_summary):
395                         # Reference column or another aggregate. Select it
396                         # under a non-conflicting alias.
397                         col_cnt += 1
398                         col_alias = '__col%d' % col_cnt
399                         self.annotations[col_alias] = expr
400                         self.append_annotation_mask([col_alias])
401                         new_expr = Ref(col_alias, expr)
402                     else:
403                         # Some other expression not referencing database values
404                         # directly. Its subexpression might contain Cols.
405                         new_expr, col_cnt = self.rewrite_cols(expr, col_cnt)
406                 new_exprs.append(new_expr)
407         annotation.set_source_expressions(new_exprs)
408         return annotation, col_cnt
409 
410     def get_aggregation(self, using, added_aggregate_names):
411         """
412         Return the dictionary with the values of the existing aggregations.
413         """
414         if not self.annotation_select:
415             return {}
416         has_limit = self.low_mark != 0 or self.high_mark is not None
417         existing_annotations = [
418             annotation for alias, annotation
419             in self.annotations.items()
420             if alias not in added_aggregate_names
421         ]
422         # Decide if we need to use a subquery.
423         #
424         # Existing annotations would cause incorrect results as get_aggregation()
425         # must produce just one result and thus must not use GROUP BY. But we
426         # aren't smart enough to remove the existing annotations from the
427         # query, so those would force us to use GROUP BY.
428         #
429         # If the query has limit or distinct, or uses set operations, then
430         # those operations must be done in a subquery so that the query
431         # aggregates on the limit and/or distinct results instead of applying
432         # the distinct and limit after the aggregation.
433         if (isinstance(self.group_by, tuple) or has_limit or existing_annotations or
434                 self.distinct or self.combinator):
435             from django.db.models.sql.subqueries import AggregateQuery
436             outer_query = AggregateQuery(self.model)
437             inner_query = self.clone()
438             inner_query.select_for_update = False
439             inner_query.select_related = False
440             inner_query.set_annotation_mask(self.annotation_select)
441             if not has_limit and not self.distinct_fields:
442                 # Queries with distinct_fields need ordering and when a limit
443                 # is applied we must take the slice from the ordered query.
444                 # Otherwise no need for ordering.
445                 inner_query.clear_ordering(True)
446             if not inner_query.distinct:
447                 # If the inner query uses default select and it has some
448                 # aggregate annotations, then we must make sure the inner
449                 # query is grouped by the main model's primary key. However,
450                 # clearing the select clause can alter results if distinct is
451                 # used.
452                 has_existing_aggregate_annotations = any(
453                     annotation for annotation in existing_annotations
454                     if getattr(annotation, 'contains_aggregate', True)
455                 )
456                 if inner_query.default_cols and has_existing_aggregate_annotations:
457                     inner_query.group_by = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)
458                 inner_query.default_cols = False
459 
460             relabels = {t: 'subquery' for t in inner_query.alias_map}
461             relabels[None] = 'subquery'
462             # Remove any aggregates marked for reduction from the subquery
463             # and move them to the outer AggregateQuery.
464             col_cnt = 0
465             for alias, expression in list(inner_query.annotation_select.items()):
466                 annotation_select_mask = inner_query.annotation_select_mask
467                 if expression.is_summary:
468                     expression, col_cnt = inner_query.rewrite_cols(expression, col_cnt)
469                     outer_query.annotations[alias] = expression.relabeled_clone(relabels)
470                     del inner_query.annotations[alias]
471                     annotation_select_mask.remove(alias)
472                 # Make sure the annotation_select wont use cached results.
473                 inner_query.set_annotation_mask(inner_query.annotation_select_mask)
474             if inner_query.select == () and not inner_query.default_cols and not inner_query.annotation_select_mask:
475                 # In case of Model.objects[0:3].count(), there would be no
476                 # field selected in the inner query, yet we must use a subquery.
477                 # So, make sure at least one field is selected.
478                 inner_query.select = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)
479             try:
480                 outer_query.add_subquery(inner_query, using)
481             except EmptyResultSet:
482                 return {
483                     alias: None
484                     for alias in outer_query.annotation_select
485                 }
486         else:
487             outer_query = self
488             self.select = ()
489             self.default_cols = False
490             self.extra = {}
491 
492         outer_query.clear_ordering(True)
493         outer_query.clear_limits()
494         outer_query.select_for_update = False
495         outer_query.select_related = False
496         compiler = outer_query.get_compiler(using)
497         result = compiler.execute_sql(SINGLE)
498         if result is None:
499             result = [None] * len(outer_query.annotation_select)
500 
501         converters = compiler.get_converters(outer_query.annotation_select.values())
502         result = next(compiler.apply_converters((result,), converters))
503 
504         return dict(zip(outer_query.annotation_select, result))
505 
506     def get_count(self, using):
507         """
508         Perform a COUNT() query using the current filter constraints.
509         """
510         obj = self.clone()
511         obj.add_annotation(Count('*'), alias='__count', is_summary=True)
512         number = obj.get_aggregation(using, ['__count'])['__count']
513         if number is None:
514             number = 0
515         return number
516 
517     def has_filters(self):
518         return self.where
519 
520     def has_results(self, using):
521         q = self.clone()
522         if not q.distinct:
523             if q.group_by is True:
524                 q.add_fields((f.attname for f in self.model._meta.concrete_fields), False)
525                 q.set_group_by()
526             q.clear_select_clause()
527         q.clear_ordering(True)
528         q.set_limits(high=1)
529         compiler = q.get_compiler(using=using)
530         return compiler.has_results()
531 
532     def explain(self, using, format=None, **options):
533         q = self.clone()
534         q.explain_query = True
535         q.explain_format = format
536         q.explain_options = options
537         compiler = q.get_compiler(using=using)
538         return '\n'.join(compiler.explain_query())
539 
540     def combine(self, rhs, connector):
541         """
542         Merge the 'rhs' query into the current one (with any 'rhs' effects
543         being applied *after* (that is, "to the right of") anything in the
544         current query. 'rhs' is not modified during a call to this function.
545 
546         The 'connector' parameter describes how to connect filters from the
547         'rhs' query.
548         """
549         assert self.model == rhs.model, \
550             "Cannot combine queries on two different base models."
551         assert self.can_filter(), \
552             "Cannot combine queries once a slice has been taken."
553         assert self.distinct == rhs.distinct, \
554             "Cannot combine a unique query with a non-unique query."
555         assert self.distinct_fields == rhs.distinct_fields, \
556             "Cannot combine queries with different distinct fields."
557 
558         # Work out how to relabel the rhs aliases, if necessary.
559         change_map = {}
560         conjunction = (connector == AND)
561 
562         # Determine which existing joins can be reused. When combining the
563         # query with AND we must recreate all joins for m2m filters. When
564         # combining with OR we can reuse joins. The reason is that in AND
565         # case a single row can't fulfill a condition like:
566         #     revrel__col=1 & revrel__col=2
567         # But, there might be two different related rows matching this
568         # condition. In OR case a single True is enough, so single row is
569         # enough, too.
570         #
571         # Note that we will be creating duplicate joins for non-m2m joins in
572         # the AND case. The results will be correct but this creates too many
573         # joins. This is something that could be fixed later on.
574         reuse = set() if conjunction else set(self.alias_map)
575         # Base table must be present in the query - this is the same
576         # table on both sides.
577         self.get_initial_alias()
578         joinpromoter = JoinPromoter(connector, 2, False)
579         joinpromoter.add_votes(
580             j for j in self.alias_map if self.alias_map[j].join_type == INNER)
581         rhs_votes = set()
582         # Now, add the joins from rhs query into the new query (skipping base
583         # table).
584         rhs_tables = list(rhs.alias_map)[1:]
585         for alias in rhs_tables:
586             join = rhs.alias_map[alias]
587             # If the left side of the join was already relabeled, use the
588             # updated alias.
589             join = join.relabeled_clone(change_map)
590             new_alias = self.join(join, reuse=reuse)
591             if join.join_type == INNER:
592                 rhs_votes.add(new_alias)
593             # We can't reuse the same join again in the query. If we have two
594             # distinct joins for the same connection in rhs query, then the
595             # combined query must have two joins, too.
596             reuse.discard(new_alias)
597             if alias != new_alias:
598                 change_map[alias] = new_alias
599             if not rhs.alias_refcount[alias]:
600                 # The alias was unused in the rhs query. Unref it so that it
601                 # will be unused in the new query, too. We have to add and
602                 # unref the alias so that join promotion has information of
603                 # the join type for the unused alias.
604                 self.unref_alias(new_alias)
605         joinpromoter.add_votes(rhs_votes)
606         joinpromoter.update_join_types(self)
607 
608         # Now relabel a copy of the rhs where-clause and add it to the current
609         # one.
610         w = rhs.where.clone()
611         w.relabel_aliases(change_map)
612         self.where.add(w, connector)
613 
614         # Selection columns and extra extensions are those provided by 'rhs'.
615         if rhs.select:
616             self.set_select([col.relabeled_clone(change_map) for col in rhs.select])
617         else:
618             self.select = ()
619 
620         if connector == OR:
621             # It would be nice to be able to handle this, but the queries don't
622             # really make sense (or return consistent value sets). Not worth
623             # the extra complexity when you can write a real query instead.
624             if self.extra and rhs.extra:
625                 raise ValueError("When merging querysets using 'or', you cannot have extra(select=...) on both sides.")
626         self.extra.update(rhs.extra)
627         extra_select_mask = set()
628         if self.extra_select_mask is not None:
629             extra_select_mask.update(self.extra_select_mask)
630         if rhs.extra_select_mask is not None:
631             extra_select_mask.update(rhs.extra_select_mask)
632         if extra_select_mask:
633             self.set_extra_mask(extra_select_mask)
634         self.extra_tables += rhs.extra_tables
635 
636         # Ordering uses the 'rhs' ordering, unless it has none, in which case
637         # the current ordering is used.
638         self.order_by = rhs.order_by or self.order_by
639         self.extra_order_by = rhs.extra_order_by or self.extra_order_by
640 
641     def deferred_to_data(self, target, callback):
642         """
643         Convert the self.deferred_loading data structure to an alternate data
644         structure, describing the field that *will* be loaded. This is used to
645         compute the columns to select from the database and also by the
646         QuerySet class to work out which fields are being initialized on each
647         model. Models that have all their fields included aren't mentioned in
648         the result, only those that have field restrictions in place.
649 
650         The "target" parameter is the instance that is populated (in place).
651         The "callback" is a function that is called whenever a (model, field)
652         pair need to be added to "target". It accepts three parameters:
653         "target", and the model and list of fields being added for that model.
654         """
655         field_names, defer = self.deferred_loading
656         if not field_names:
657             return
658         orig_opts = self.get_meta()
659         seen = {}
660         must_include = {orig_opts.concrete_model: {orig_opts.pk}}
661         for field_name in field_names:
662             parts = field_name.split(LOOKUP_SEP)
663             cur_model = self.model._meta.concrete_model
664             opts = orig_opts
665             for name in parts[:-1]:
666                 old_model = cur_model
667                 if name in self._filtered_relations:
668                     name = self._filtered_relations[name].relation_name
669                 source = opts.get_field(name)
670                 if is_reverse_o2o(source):
671                     cur_model = source.related_model
672                 else:
673                     cur_model = source.remote_field.model
674                 opts = cur_model._meta
675                 # Even if we're "just passing through" this model, we must add
676                 # both the current model's pk and the related reference field
677                 # (if it's not a reverse relation) to the things we select.
678                 if not is_reverse_o2o(source):
679                     must_include[old_model].add(source)
680                 add_to_dict(must_include, cur_model, opts.pk)
681             field = opts.get_field(parts[-1])
682             is_reverse_object = field.auto_created and not field.concrete
683             model = field.related_model if is_reverse_object else field.model
684             model = model._meta.concrete_model
685             if model == opts.model:
686                 model = cur_model
687             if not is_reverse_o2o(field):
688                 add_to_dict(seen, model, field)
689 
690         if defer:
691             # We need to load all fields for each model, except those that
692             # appear in "seen" (for all models that appear in "seen"). The only
693             # slight complexity here is handling fields that exist on parent
694             # models.
695             workset = {}
696             for model, values in seen.items():
697                 for field in model._meta.local_fields:
698                     if field not in values:
699                         m = field.model._meta.concrete_model
700                         add_to_dict(workset, m, field)
701             for model, values in must_include.items():
702                 # If we haven't included a model in workset, we don't add the
703                 # corresponding must_include fields for that model, since an
704                 # empty set means "include all fields". That's why there's no
705                 # "else" branch here.
706                 if model in workset:
707                     workset[model].update(values)
708             for model, values in workset.items():
709                 callback(target, model, values)
710         else:
711             for model, values in must_include.items():
712                 if model in seen:
713                     seen[model].update(values)
714                 else:
715                     # As we've passed through this model, but not explicitly
716                     # included any fields, we have to make sure it's mentioned
717                     # so that only the "must include" fields are pulled in.
718                     seen[model] = values
719             # Now ensure that every model in the inheritance chain is mentioned
720             # in the parent list. Again, it must be mentioned to ensure that
721             # only "must include" fields are pulled in.
722             for model in orig_opts.get_parent_list():
723                 seen.setdefault(model, set())
724             for model, values in seen.items():
725                 callback(target, model, values)
726 
727     def table_alias(self, table_name, create=False, filtered_relation=None):
728         """
729         Return a table alias for the given table_name and whether this is a
730         new alias or not.
731 
732         If 'create' is true, a new alias is always created. Otherwise, the
733         most recently created alias for the table (if one exists) is reused.
734         """
735         alias_list = self.table_map.get(table_name)
736         if not create and alias_list:
737             alias = alias_list[0]
738             self.alias_refcount[alias] += 1
739             return alias, False
740 
741         # Create a new alias for this table.
742         if alias_list:
743             alias = '%s%d' % (self.alias_prefix, len(self.alias_map) + 1)
744             alias_list.append(alias)
745         else:
746             # The first occurrence of a table uses the table name directly.
747             alias = filtered_relation.alias if filtered_relation is not None else table_name
748             self.table_map[table_name] = [alias]
749         self.alias_refcount[alias] = 1
750         return alias, True
751 
752     def ref_alias(self, alias):
753         """Increases the reference count for this alias."""
754         self.alias_refcount[alias] += 1
755 
756     def unref_alias(self, alias, amount=1):
757         """Decreases the reference count for this alias."""
758         self.alias_refcount[alias] -= amount
759 
760     def promote_joins(self, aliases):
761         """
762         Promote recursively the join type of given aliases and its children to
763         an outer join. If 'unconditional' is False, only promote the join if
764         it is nullable or the parent join is an outer join.
765 
766         The children promotion is done to avoid join chains that contain a LOUTER
767         b INNER c. So, if we have currently a INNER b INNER c and a->b is promoted,
768         then we must also promote b->c automatically, or otherwise the promotion
769         of a->b doesn't actually change anything in the query results.
770         """
771         aliases = list(aliases)
772         while aliases:
773             alias = aliases.pop(0)
774             if self.alias_map[alias].join_type is None:
775                 # This is the base table (first FROM entry) - this table
776                 # isn't really joined at all in the query, so we should not
777                 # alter its join type.
778                 continue
779             # Only the first alias (skipped above) should have None join_type
780             assert self.alias_map[alias].join_type is not None
781             parent_alias = self.alias_map[alias].parent_alias
782             parent_louter = parent_alias and self.alias_map[parent_alias].join_type == LOUTER
783             already_louter = self.alias_map[alias].join_type == LOUTER
784             if ((self.alias_map[alias].nullable or parent_louter) and
785                     not already_louter):
786                 self.alias_map[alias] = self.alias_map[alias].promote()
787                 # Join type of 'alias' changed, so re-examine all aliases that
788                 # refer to this one.
789                 aliases.extend(
790                     join for join in self.alias_map
791                     if self.alias_map[join].parent_alias == alias and join not in aliases
792                 )
793 
794     def demote_joins(self, aliases):
795         """
796         Change join type from LOUTER to INNER for all joins in aliases.
797 
798         Similarly to promote_joins(), this method must ensure no join chains
799         containing first an outer, then an inner join are generated. If we
800         are demoting b->c join in chain a LOUTER b LOUTER c then we must
801         demote a->b automatically, or otherwise the demotion of b->c doesn't
802         actually change anything in the query results. .
803         """
804         aliases = list(aliases)
805         while aliases:
806             alias = aliases.pop(0)
807             if self.alias_map[alias].join_type == LOUTER:
808                 self.alias_map[alias] = self.alias_map[alias].demote()
809                 parent_alias = self.alias_map[alias].parent_alias
810                 if self.alias_map[parent_alias].join_type == INNER:
811                     aliases.append(parent_alias)
812 
813     def reset_refcounts(self, to_counts):
814         """
815         Reset reference counts for aliases so that they match the value passed
816         in `to_counts`.
817         """
818         for alias, cur_refcount in self.alias_refcount.copy().items():
819             unref_amount = cur_refcount - to_counts.get(alias, 0)
820             self.unref_alias(alias, unref_amount)
821 
822     def change_aliases(self, change_map):
823         """
824         Change the aliases in change_map (which maps old-alias -> new-alias),
825         relabelling any references to them in select columns and the where
826         clause.
827         """
828         assert set(change_map).isdisjoint(change_map.values())
829 
830         # 1. Update references in "select" (normal columns plus aliases),
831         # "group by" and "where".
832         self.where.relabel_aliases(change_map)
833         if isinstance(self.group_by, tuple):
834             self.group_by = tuple([col.relabeled_clone(change_map) for col in self.group_by])
835         self.select = tuple([col.relabeled_clone(change_map) for col in self.select])
836         self.annotations = self.annotations and {
837             key: col.relabeled_clone(change_map) for key, col in self.annotations.items()
838         }
839 
840         # 2. Rename the alias in the internal table/alias datastructures.
841         for old_alias, new_alias in change_map.items():
842             if old_alias not in self.alias_map:
843                 continue
844             alias_data = self.alias_map[old_alias].relabeled_clone(change_map)
845             self.alias_map[new_alias] = alias_data
846             self.alias_refcount[new_alias] = self.alias_refcount[old_alias]
847             del self.alias_refcount[old_alias]
848             del self.alias_map[old_alias]
849 
850             table_aliases = self.table_map[alias_data.table_name]
851             for pos, alias in enumerate(table_aliases):
852                 if alias == old_alias:
853                     table_aliases[pos] = new_alias
854                     break
855         self.external_aliases = {change_map.get(alias, alias)
856                                  for alias in self.external_aliases}
857 
858     def bump_prefix(self, outer_query):
859         """
860         Change the alias prefix to the next letter in the alphabet in a way
861         that the outer query's aliases and this query's aliases will not
862         conflict. Even tables that previously had no alias will get an alias
863         after this call.
864         """
865         def prefix_gen():
866             """
867             Generate a sequence of characters in alphabetical order:
868                 -> 'A', 'B', 'C', ...
869 
870             When the alphabet is finished, the sequence will continue with the
871             Cartesian product:
872                 -> 'AA', 'AB', 'AC', ...
873             """
874             alphabet = ascii_uppercase
875             prefix = chr(ord(self.alias_prefix) + 1)
876             yield prefix
877             for n in count(1):
878                 seq = alphabet[alphabet.index(prefix):] if prefix else alphabet
879                 for s in product(seq, repeat=n):
880                     yield ''.join(s)
881                 prefix = None
882 
883         if self.alias_prefix != outer_query.alias_prefix:
884             # No clashes between self and outer query should be possible.
885             return
886 
887         # Explicitly avoid infinite loop. The constant divider is based on how
888         # much depth recursive subquery references add to the stack. This value
889         # might need to be adjusted when adding or removing function calls from
890         # the code path in charge of performing these operations.
891         local_recursion_limit = sys.getrecursionlimit() // 16
892         for pos, prefix in enumerate(prefix_gen()):
893             if prefix not in self.subq_aliases:
894                 self.alias_prefix = prefix
895                 break
896             if pos > local_recursion_limit:
897                 raise RecursionError(
898                     'Maximum recursion depth exceeded: too many subqueries.'
899                 )
900         self.subq_aliases = self.subq_aliases.union([self.alias_prefix])
901         outer_query.subq_aliases = outer_query.subq_aliases.union(self.subq_aliases)
902         self.change_aliases({
903             alias: '%s%d' % (self.alias_prefix, pos)
904             for pos, alias in enumerate(self.alias_map)
905         })
906 
907     def get_initial_alias(self):
908         """
909         Return the first alias for this query, after increasing its reference
910         count.
911         """
912         if self.alias_map:
913             alias = self.base_table
914             self.ref_alias(alias)
915         else:
916             alias = self.join(BaseTable(self.get_meta().db_table, None))
917         return alias
918 
919     def count_active_tables(self):
920         """
921         Return the number of tables in this query with a non-zero reference
922         count. After execution, the reference counts are zeroed, so tables
923         added in compiler will not be seen by this method.
924         """
925         return len([1 for count in self.alias_refcount.values() if count])
926 
927     def join(self, join, reuse=None, reuse_with_filtered_relation=False):
928         """
929         Return an alias for the 'join', either reusing an existing alias for
930         that join or creating a new one. 'join' is either a
931         sql.datastructures.BaseTable or Join.
932 
933         The 'reuse' parameter can be either None which means all joins are
934         reusable, or it can be a set containing the aliases that can be reused.
935 
936         The 'reuse_with_filtered_relation' parameter is used when computing
937         FilteredRelation instances.
938 
939         A join is always created as LOUTER if the lhs alias is LOUTER to make
940         sure chains like t1 LOUTER t2 INNER t3 aren't generated. All new
941         joins are created as LOUTER if the join is nullable.
942         """
943         if reuse_with_filtered_relation and reuse:
944             reuse_aliases = [
945                 a for a, j in self.alias_map.items()
946                 if a in reuse and j.equals(join, with_filtered_relation=False)
947             ]
948         else:
949             reuse_aliases = [
950                 a for a, j in self.alias_map.items()
951                 if (reuse is None or a in reuse) and j == join
952             ]
953         if reuse_aliases:
954             if join.table_alias in reuse_aliases:
955                 reuse_alias = join.table_alias
956             else:
957                 # Reuse the most recent alias of the joined table
958                 # (a many-to-many relation may be joined multiple times).
959                 reuse_alias = reuse_aliases[-1]
960             self.ref_alias(reuse_alias)
961             return reuse_alias
962 
963         # No reuse is possible, so we need a new alias.
964         alias, _ = self.table_alias(join.table_name, create=True, filtered_relation=join.filtered_relation)
965         if join.join_type:
966             if self.alias_map[join.parent_alias].join_type == LOUTER or join.nullable:
967                 join_type = LOUTER
968             else:
969                 join_type = INNER
970             join.join_type = join_type
971         join.table_alias = alias
972         self.alias_map[alias] = join
973         return alias
974 
975     def join_parent_model(self, opts, model, alias, seen):
976         """
977         Make sure the given 'model' is joined in the query. If 'model' isn't
978         a parent of 'opts' or if it is None this method is a no-op.
979 
980         The 'alias' is the root alias for starting the join, 'seen' is a dict
981         of model -> alias of existing joins. It must also contain a mapping
982         of None -> some alias. This will be returned in the no-op case.
983         """
984         if model in seen:
985             return seen[model]
986         chain = opts.get_base_chain(model)
987         if not chain:
988             return alias
989         curr_opts = opts
990         for int_model in chain:
991             if int_model in seen:
992                 curr_opts = int_model._meta
993                 alias = seen[int_model]
994                 continue
995             # Proxy model have elements in base chain
996             # with no parents, assign the new options
997             # object and skip to the next base in that
998             # case
999             if not curr_opts.parents[int_model]:
1000                 curr_opts = int_model._meta
1001                 continue
1002             link_field = curr_opts.get_ancestor_link(int_model)
1003             join_info = self.setup_joins([link_field.name], curr_opts, alias)
1004             curr_opts = int_model._meta
1005             alias = seen[int_model] = join_info.joins[-1]
1006         return alias or seen[None]
1007 
1008     def add_annotation(self, annotation, alias, is_summary=False):
1009         """Add a single annotation expression to the Query."""
1010         annotation = annotation.resolve_expression(self, allow_joins=True, reuse=None,
1011                                                    summarize=is_summary)
1012         self.append_annotation_mask([alias])
1013         self.annotations[alias] = annotation
1014 
1015     def resolve_expression(self, query, *args, **kwargs):
1016         clone = self.clone()
1017         # Subqueries need to use a different set of aliases than the outer query.
1018         clone.bump_prefix(query)
1019         clone.subquery = True
1020         # It's safe to drop ordering if the queryset isn't using slicing,
1021         # distinct(*fields) or select_for_update().
1022         if (self.low_mark == 0 and self.high_mark is None and
1023                 not self.distinct_fields and
1024                 not self.select_for_update):
1025             clone.clear_ordering(True)
1026         clone.where.resolve_expression(query, *args, **kwargs)
1027         for key, value in clone.annotations.items():
1028             resolved = value.resolve_expression(query, *args, **kwargs)
1029             if hasattr(resolved, 'external_aliases'):
1030                 resolved.external_aliases.update(clone.alias_map)
1031             clone.annotations[key] = resolved
1032         # Outer query's aliases are considered external.
1033         clone.external_aliases.update(
1034             alias for alias, table in query.alias_map.items()
1035             if (
1036                 isinstance(table, Join) and table.join_field.related_model._meta.db_table != alias
1037             ) or (
1038                 isinstance(table, BaseTable) and table.table_name != table.table_alias
1039             )
1040         )
1041         return clone
1042 
1043     def as_sql(self, compiler, connection):
1044         sql, params = self.get_compiler(connection=connection).as_sql()
1045         if self.subquery:
1046             sql = '(%s)' % sql
1047         return sql, params
1048 
1049     def resolve_lookup_value(self, value, can_reuse, allow_joins, simple_col):
1050         if hasattr(value, 'resolve_expression'):
1051             kwargs = {'reuse': can_reuse, 'allow_joins': allow_joins}
1052             if isinstance(value, F):
1053                 kwargs['simple_col'] = simple_col
1054             value = value.resolve_expression(self, **kwargs)
1055         elif isinstance(value, (list, tuple)):
1056             # The items of the iterable may be expressions and therefore need
1057             # to be resolved independently.
1058             for sub_value in value:
1059                 if hasattr(sub_value, 'resolve_expression'):
1060                     if isinstance(sub_value, F):
1061                         sub_value.resolve_expression(
1062                             self, reuse=can_reuse, allow_joins=allow_joins,
1063                             simple_col=simple_col,
1064                         )
1065                     else:
1066                         sub_value.resolve_expression(self, reuse=can_reuse, allow_joins=allow_joins)
1067         return value
1068 
1069     def solve_lookup_type(self, lookup):
1070         """
1071         Solve the lookup type from the lookup (e.g.: 'foobar__id__icontains').
1072         """
1073         lookup_splitted = lookup.split(LOOKUP_SEP)
1074         if self.annotations:
1075             expression, expression_lookups = refs_expression(lookup_splitted, self.annotations)
1076             if expression:
1077                 return expression_lookups, (), expression
1078         _, field, _, lookup_parts = self.names_to_path(lookup_splitted, self.get_meta())
1079         field_parts = lookup_splitted[0:len(lookup_splitted) - len(lookup_parts)]
1080         if len(lookup_parts) > 1 and not field_parts:
1081             raise FieldError(
1082                 'Invalid lookup "%s" for model %s".' %
1083                 (lookup, self.get_meta().model.__name__)
1084             )
1085         return lookup_parts, field_parts, False
1086 
1087     def check_query_object_type(self, value, opts, field):
1088         """
1089         Check whether the object passed while querying is of the correct type.
1090         If not, raise a ValueError specifying the wrong object.
1091         """
1092         if hasattr(value, '_meta'):
1093             if not check_rel_lookup_compatibility(value._meta.model, opts, field):
1094                 raise ValueError(
1095                     'Cannot query "%s": Must be "%s" instance.' %
1096                     (value, opts.object_name))
1097 
1098     def check_related_objects(self, field, value, opts):
1099         """Check the type of object passed to query relations."""
1100         if field.is_relation:
1101             # Check that the field and the queryset use the same model in a
1102             # query like .filter(author=Author.objects.all()). For example, the
1103             # opts would be Author's (from the author field) and value.model
1104             # would be Author.objects.all() queryset's .model (Author also).
1105             # The field is the related field on the lhs side.
1106             if (isinstance(value, Query) and not value.has_select_fields and
1107                     not check_rel_lookup_compatibility(value.model, opts, field)):
1108                 raise ValueError(
1109                     'Cannot use QuerySet for "%s": Use a QuerySet for "%s".' %
1110                     (value.model._meta.object_name, opts.object_name)
1111                 )
1112             elif hasattr(value, '_meta'):
1113                 self.check_query_object_type(value, opts, field)
1114             elif hasattr(value, '__iter__'):
1115                 for v in value:
1116                     self.check_query_object_type(v, opts, field)
1117 
1118     def build_lookup(self, lookups, lhs, rhs):
1119         """
1120         Try to extract transforms and lookup from given lhs.
1121 
1122         The lhs value is something that works like SQLExpression.
1123         The rhs value is what the lookup is going to compare against.
1124         The lookups is a list of names to extract using get_lookup()
1125         and get_transform().
1126         """
1127         # __exact is the default lookup if one isn't given.
1128         *transforms, lookup_name = lookups or ['exact']
1129         for name in transforms:
1130             lhs = self.try_transform(lhs, name)
1131         # First try get_lookup() so that the lookup takes precedence if the lhs
1132         # supports both transform and lookup for the name.
1133         lookup_class = lhs.get_lookup(lookup_name)
1134         if not lookup_class:
1135             if lhs.field.is_relation:
1136                 raise FieldError('Related Field got invalid lookup: {}'.format(lookup_name))
1137             # A lookup wasn't found. Try to interpret the name as a transform
1138             # and do an Exact lookup against it.
1139             lhs = self.try_transform(lhs, lookup_name)
1140             lookup_name = 'exact'
1141             lookup_class = lhs.get_lookup(lookup_name)
1142             if not lookup_class:
1143                 return
1144 
1145         lookup = lookup_class(lhs, rhs)
1146         # Interpret '__exact=None' as the sql 'is NULL'; otherwise, reject all
1147         # uses of None as a query value unless the lookup supports it.
1148         if lookup.rhs is None and not lookup.can_use_none_as_rhs:
1149             if lookup_name not in ('exact', 'iexact'):
1150                 raise ValueError("Cannot use None as a query value")
1151             return lhs.get_lookup('isnull')(lhs, True)
1152 
1153         # For Oracle '' is equivalent to null. The check must be done at this
1154         # stage because join promotion can't be done in the compiler. Using
1155         # DEFAULT_DB_ALIAS isn't nice but it's the best that can be done here.
1156         # A similar thing is done in is_nullable(), too.
1157         if (connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls and
1158                 lookup_name == 'exact' and lookup.rhs == ''):
1159             return lhs.get_lookup('isnull')(lhs, True)
1160 
1161         return lookup
1162 
1163     def try_transform(self, lhs, name):
1164         """
1165         Helper method for build_lookup(). Try to fetch and initialize
1166         a transform for name parameter from lhs.
1167         """
1168         transform_class = lhs.get_transform(name)
1169         if transform_class:
1170             return transform_class(lhs)
1171         else:
1172             output_field = lhs.output_field.__class__
1173             suggested_lookups = difflib.get_close_matches(name, output_field.get_lookups())
1174             if suggested_lookups:
1175                 suggestion = ', perhaps you meant %s?' % ' or '.join(suggested_lookups)
1176             else:
1177                 suggestion = '.'
1178             raise FieldError(
1179                 "Unsupported lookup '%s' for %s or join on the field not "
1180                 "permitted%s" % (name, output_field.__name__, suggestion)
1181             )
1182 
1183     def build_filter(self, filter_expr, branch_negated=False, current_negated=False,
1184                      can_reuse=None, allow_joins=True, split_subq=True,
1185                      reuse_with_filtered_relation=False, simple_col=False):
1186         """
1187         Build a WhereNode for a single filter clause but don't add it
1188         to this Query. Query.add_q() will then add this filter to the where
1189         Node.
1190 
1191         The 'branch_negated' tells us if the current branch contains any
1192         negations. This will be used to determine if subqueries are needed.
1193 
1194         The 'current_negated' is used to determine if the current filter is
1195         negated or not and this will be used to determine if IS NULL filtering
1196         is needed.
1197 
1198         The difference between current_negated and branch_negated is that
1199         branch_negated is set on first negation, but current_negated is
1200         flipped for each negation.
1201 
1202         Note that add_filter will not do any negating itself, that is done
1203         upper in the code by add_q().
1204 
1205         The 'can_reuse' is a set of reusable joins for multijoins.
1206 
1207         If 'reuse_with_filtered_relation' is True, then only joins in can_reuse
1208         will be reused.
1209 
1210         The method will create a filter clause that can be added to the current
1211         query. However, if the filter isn't added to the query then the caller
1212         is responsible for unreffing the joins used.
1213         """
1214         if isinstance(filter_expr, dict):
1215             raise FieldError("Cannot parse keyword query as dict")
1216         arg, value = filter_expr
1217         if not arg:
1218             raise FieldError("Cannot parse keyword query %r" % arg)
1219         lookups, parts, reffed_expression = self.solve_lookup_type(arg)
1220 
1221         if not getattr(reffed_expression, 'filterable', True):
1222             raise NotSupportedError(
1223                 reffed_expression.__class__.__name__ + ' is disallowed in '
1224                 'the filter clause.'
1225             )
1226 
1227         if not allow_joins and len(parts) > 1:
1228             raise FieldError("Joined field references are not permitted in this query")
1229 
1230         pre_joins = self.alias_refcount.copy()
1231         value = self.resolve_lookup_value(value, can_reuse, allow_joins, simple_col)
1232         used_joins = {k for k, v in self.alias_refcount.items() if v > pre_joins.get(k, 0)}
1233 
1234         clause = self.where_class()
1235         if reffed_expression:
1236             condition = self.build_lookup(lookups, reffed_expression, value)
1237             clause.add(condition, AND)
1238             return clause, []
1239 
1240         opts = self.get_meta()
1241         alias = self.get_initial_alias()
1242         allow_many = not branch_negated or not split_subq
1243 
1244         try:
1245             join_info = self.setup_joins(
1246                 parts, opts, alias, can_reuse=can_reuse, allow_many=allow_many,
1247                 reuse_with_filtered_relation=reuse_with_filtered_relation,
1248             )
1249 
1250             # Prevent iterator from being consumed by check_related_objects()
1251             if isinstance(value, Iterator):
1252                 value = list(value)
1253             self.check_related_objects(join_info.final_field, value, join_info.opts)
1254 
1255             # split_exclude() needs to know which joins were generated for the
1256             # lookup parts
1257             self._lookup_joins = join_info.joins
1258         except MultiJoin as e:
1259             return self.split_exclude(filter_expr, can_reuse, e.names_with_path)
1260 
1261         # Update used_joins before trimming since they are reused to determine
1262         # which joins could be later promoted to INNER.
1263         used_joins.update(join_info.joins)
1264         targets, alias, join_list = self.trim_joins(join_info.targets, join_info.joins, join_info.path)
1265         if can_reuse is not None:
1266             can_reuse.update(join_list)
1267 
1268         if join_info.final_field.is_relation:
1269             # No support for transforms for relational fields
1270             num_lookups = len(lookups)
1271             if num_lookups > 1:
1272                 raise FieldError('Related Field got invalid lookup: {}'.format(lookups[0]))
1273             if len(targets) == 1:
1274                 col = _get_col(targets[0], join_info.final_field, alias, simple_col)
1275             else:
1276                 col = MultiColSource(alias, targets, join_info.targets, join_info.final_field)
1277         else:
1278             col = _get_col(targets[0], join_info.final_field, alias, simple_col)
1279 
1280         condition = self.build_lookup(lookups, col, value)
1281         lookup_type = condition.lookup_name
1282         clause.add(condition, AND)
1283 
1284         require_outer = lookup_type == 'isnull' and condition.rhs is True and not current_negated
1285         if current_negated and (lookup_type != 'isnull' or condition.rhs is False) and condition.rhs is not None:
1286             require_outer = True
1287             if (lookup_type != 'isnull' and (
1288                     self.is_nullable(targets[0]) or
1289                     self.alias_map[join_list[-1]].join_type == LOUTER)):
1290                 # The condition added here will be SQL like this:
1291                 # NOT (col IS NOT NULL), where the first NOT is added in
1292                 # upper layers of code. The reason for addition is that if col
1293                 # is null, then col != someval will result in SQL "unknown"
1294                 # which isn't the same as in Python. The Python None handling
1295                 # is wanted, and it can be gotten by
1296                 # (col IS NULL OR col != someval)
1297                 #   <=>
1298                 # NOT (col IS NOT NULL AND col = someval).
1299                 lookup_class = targets[0].get_lookup('isnull')
1300                 col = _get_col(targets[0], join_info.targets[0], alias, simple_col)
1301                 clause.add(lookup_class(col, False), AND)
1302         return clause, used_joins if not require_outer else ()
1303 
1304     def add_filter(self, filter_clause):
1305         self.add_q(Q(**{filter_clause[0]: filter_clause[1]}))
1306 
1307     def add_q(self, q_object):
1308         """
1309         A preprocessor for the internal _add_q(). Responsible for doing final
1310         join promotion.
1311         """
1312         # For join promotion this case is doing an AND for the added q_object
1313         # and existing conditions. So, any existing inner join forces the join
1314         # type to remain inner. Existing outer joins can however be demoted.
1315         # (Consider case where rel_a is LOUTER and rel_a__col=1 is added - if
1316         # rel_a doesn't produce any rows, then the whole condition must fail.
1317         # So, demotion is OK.
1318         existing_inner = {a for a in self.alias_map if self.alias_map[a].join_type == INNER}
1319         clause, _ = self._add_q(q_object, self.used_aliases)
1320         if clause:
1321             self.where.add(clause, AND)
1322         self.demote_joins(existing_inner)
1323 
1324     def build_where(self, q_object):
1325         return self._add_q(q_object, used_aliases=set(), allow_joins=False, simple_col=True)[0]
1326 
1327     def _add_q(self, q_object, used_aliases, branch_negated=False,
1328                current_negated=False, allow_joins=True, split_subq=True,
1329                simple_col=False):
1330         """Add a Q-object to the current filter."""
1331         connector = q_object.connector
1332         current_negated = current_negated ^ q_object.negated
1333         branch_negated = branch_negated or q_object.negated
1334         target_clause = self.where_class(connector=connector,
1335                                          negated=q_object.negated)
1336         joinpromoter = JoinPromoter(q_object.connector, len(q_object.children), current_negated)
1337         for child in q_object.children:
1338             if isinstance(child, Node):
1339                 child_clause, needed_inner = self._add_q(
1340                     child, used_aliases, branch_negated,
1341                     current_negated, allow_joins, split_subq, simple_col)
1342                 joinpromoter.add_votes(needed_inner)
1343             else:
1344                 child_clause, needed_inner = self.build_filter(
1345                     child, can_reuse=used_aliases, branch_negated=branch_negated,
1346                     current_negated=current_negated, allow_joins=allow_joins,
1347                     split_subq=split_subq, simple_col=simple_col,
1348                 )
1349                 joinpromoter.add_votes(needed_inner)
1350             if child_clause:
1351                 target_clause.add(child_clause, connector)
1352         needed_inner = joinpromoter.update_join_types(self)
1353         return target_clause, needed_inner
1354 
1355     def build_filtered_relation_q(self, q_object, reuse, branch_negated=False, current_negated=False):
1356         """Add a FilteredRelation object to the current filter."""
1357         connector = q_object.connector
1358         current_negated ^= q_object.negated
1359         branch_negated = branch_negated or q_object.negated
1360         target_clause = self.where_class(connector=connector, negated=q_object.negated)
1361         for child in q_object.children:
1362             if isinstance(child, Node):
1363                 child_clause = self.build_filtered_relation_q(
1364                     child, reuse=reuse, branch_negated=branch_negated,
1365                     current_negated=current_negated,
1366                 )
1367             else:
1368                 child_clause, _ = self.build_filter(
1369                     child, can_reuse=reuse, branch_negated=branch_negated,
1370                     current_negated=current_negated,
1371                     allow_joins=True, split_subq=False,
1372                     reuse_with_filtered_relation=True,
1373                 )
1374             target_clause.add(child_clause, connector)
1375         return target_clause
1376 
1377     def add_filtered_relation(self, filtered_relation, alias):
1378         filtered_relation.alias = alias
1379         lookups = dict(get_children_from_q(filtered_relation.condition))
1380         for lookup in chain((filtered_relation.relation_name,), lookups):
1381             lookup_parts, field_parts, _ = self.solve_lookup_type(lookup)
1382             shift = 2 if not lookup_parts else 1
1383             if len(field_parts) > (shift + len(lookup_parts)):
1384                 raise ValueError(
1385                     "FilteredRelation's condition doesn't support nested "
1386                     "relations (got %r)." % lookup
1387                 )
1388         self._filtered_relations[filtered_relation.alias] = filtered_relation
1389 
1390     def names_to_path(self, names, opts, allow_many=True, fail_on_missing=False):
1391         """
1392         Walk the list of names and turns them into PathInfo tuples. A single
1393         name in 'names' can generate multiple PathInfos (m2m, for example).
1394 
1395         'names' is the path of names to travel, 'opts' is the model Options we
1396         start the name resolving from, 'allow_many' is as for setup_joins().
1397         If fail_on_missing is set to True, then a name that can't be resolved
1398         will generate a FieldError.
1399 
1400         Return a list of PathInfo tuples. In addition return the final field
1401         (the last used join field) and target (which is a field guaranteed to
1402         contain the same value as the final field). Finally, return those names
1403         that weren't found (which are likely transforms and the final lookup).
1404         """
1405         path, names_with_path = [], []
1406         for pos, name in enumerate(names):
1407             cur_names_with_path = (name, [])
1408             if name == 'pk':
1409                 name = opts.pk.name
1410 
1411             field = None
1412             filtered_relation = None
1413             try:
1414                 field = opts.get_field(name)
1415             except FieldDoesNotExist:
1416                 if name in self.annotation_select:
1417                     field = self.annotation_select[name].output_field
1418                 elif name in self._filtered_relations and pos == 0:
1419                     filtered_relation = self._filtered_relations[name]
1420                     field = opts.get_field(filtered_relation.relation_name)
1421             if field is not None:
1422                 # Fields that contain one-to-many relations with a generic
1423                 # model (like a GenericForeignKey) cannot generate reverse
1424                 # relations and therefore cannot be used for reverse querying.
1425                 if field.is_relation and not field.related_model:
1426                     raise FieldError(
1427                         "Field %r does not generate an automatic reverse "
1428                         "relation and therefore cannot be used for reverse "
1429                         "querying. If it is a GenericForeignKey, consider "
1430                         "adding a GenericRelation." % name
1431                     )
1432                 try:
1433                     model = field.model._meta.concrete_model
1434                 except AttributeError:
1435                     # QuerySet.annotate() may introduce fields that aren't
1436                     # attached to a model.
1437                     model = None
1438             else:
1439                 # We didn't find the current field, so move position back
1440                 # one step.
1441                 pos -= 1
1442                 if pos == -1 or fail_on_missing:
1443                     available = sorted([
1444                         *get_field_names_from_opts(opts),
1445                         *self.annotation_select,
1446                         *self._filtered_relations,
1447                     ])
1448                     raise FieldError("Cannot resolve keyword '%s' into field. "
1449                                      "Choices are: %s" % (name, ", ".join(available)))
1450                 break
1451             # Check if we need any joins for concrete inheritance cases (the
1452             # field lives in parent, but we are currently in one of its
1453             # children)
1454             if model is not opts.model:
1455                 path_to_parent = opts.get_path_to_parent(model)
1456                 if path_to_parent:
1457                     path.extend(path_to_parent)
1458                     cur_names_with_path[1].extend(path_to_parent)
1459                     opts = path_to_parent[-1].to_opts
1460             if hasattr(field, 'get_path_info'):
1461                 pathinfos = field.get_path_info(filtered_relation)
1462                 if not allow_many:
1463                     for inner_pos, p in enumerate(pathinfos):
1464                         if p.m2m:
1465                             cur_names_with_path[1].extend(pathinfos[0:inner_pos + 1])
1466                             names_with_path.append(cur_names_with_path)
1467                             raise MultiJoin(pos + 1, names_with_path)
1468                 last = pathinfos[-1]
1469                 path.extend(pathinfos)
1470                 final_field = last.join_field
1471                 opts = last.to_opts
1472                 targets = last.target_fields
1473                 cur_names_with_path[1].extend(pathinfos)
1474                 names_with_path.append(cur_names_with_path)
1475             else:
1476                 # Local non-relational field.
1477                 final_field = field
1478                 targets = (field,)
1479                 if fail_on_missing and pos + 1 != len(names):
1480                     raise FieldError(
1481                         "Cannot resolve keyword %r into field. Join on '%s'"
1482                         " not permitted." % (names[pos + 1], name))
1483                 break
1484         return path, final_field, targets, names[pos + 1:]
1485 
1486     def setup_joins(self, names, opts, alias, can_reuse=None, allow_many=True,
1487                     reuse_with_filtered_relation=False):
1488         """
1489         Compute the necessary table joins for the passage through the fields
1490         given in 'names'. 'opts' is the Options class for the current model
1491         (which gives the table we are starting from), 'alias' is the alias for
1492         the table to start the joining from.
1493 
1494         The 'can_reuse' defines the reverse foreign key joins we can reuse. It
1495         can be None in which case all joins are reusable or a set of aliases
1496         that can be reused. Note that non-reverse foreign keys are always
1497         reusable when using setup_joins().
1498 
1499         The 'reuse_with_filtered_relation' can be used to force 'can_reuse'
1500         parameter and force the relation on the given connections.
1501 
1502         If 'allow_many' is False, then any reverse foreign key seen will
1503         generate a MultiJoin exception.
1504 
1505         Return the final field involved in the joins, the target field (used
1506         for any 'where' constraint), the final 'opts' value, the joins, the
1507         field path traveled to generate the joins, and a transform function
1508         that takes a field and alias and is equivalent to `field.get_col(alias)`
1509         in the simple case but wraps field transforms if they were included in
1510         names.
1511 
1512         The target field is the field containing the concrete value. Final
1513         field can be something different, for example foreign key pointing to
1514         that value. Final field is needed for example in some value
1515         conversions (convert 'obj' in fk__id=obj to pk val using the foreign
1516         key field for example).
1517         """
1518         joins = [alias]
1519         # The transform can't be applied yet, as joins must be trimmed later.
1520         # To avoid making every caller of this method look up transforms
1521         # directly, compute transforms here and create a partial that converts
1522         # fields to the appropriate wrapped version.
1523 
1524         def final_transformer(field, alias):
1525             return field.get_col(alias)
1526 
1527         # Try resolving all the names as fields first. If there's an error,
1528         # treat trailing names as lookups until a field can be resolved.
1529         last_field_exception = None
1530         for pivot in range(len(names), 0, -1):
1531             try:
1532                 path, final_field, targets, rest = self.names_to_path(
1533                     names[:pivot], opts, allow_many, fail_on_missing=True,
1534                 )
1535             except FieldError as exc:
1536                 if pivot == 1:
1537                     # The first item cannot be a lookup, so it's safe
1538                     # to raise the field error here.
1539                     raise
1540                 else:
1541                     last_field_exception = exc
1542             else:
1543                 # The transforms are the remaining items that couldn't be
1544                 # resolved into fields.
1545                 transforms = names[pivot:]
1546                 break
1547         for name in transforms:
1548             def transform(field, alias, *, name, previous):
1549                 try:
1550                     wrapped = previous(field, alias)
1551                     return self.try_transform(wrapped, name)
1552                 except FieldError:
1553                     # FieldError is raised if the transform doesn't exist.
1554                     if isinstance(final_field, Field) and last_field_exception:
1555                         raise last_field_exception
1556                     else:
1557                         raise
1558             final_transformer = functools.partial(transform, name=name, previous=final_transformer)
1559         # Then, add the path to the query's joins. Note that we can't trim
1560         # joins at this stage - we will need the information about join type
1561         # of the trimmed joins.
1562         for join in path:
1563             if join.filtered_relation:
1564                 filtered_relation = join.filtered_relation.clone()
1565                 table_alias = filtered_relation.alias
1566             else:
1567                 filtered_relation = None
1568                 table_alias = None
1569             opts = join.to_opts
1570             if join.direct:
1571                 nullable = self.is_nullable(join.join_field)
1572             else:
1573                 nullable = True
1574             connection = Join(
1575                 opts.db_table, alias, table_alias, INNER, join.join_field,
1576                 nullable, filtered_relation=filtered_relation,
1577             )
1578             reuse = can_reuse if join.m2m or reuse_with_filtered_relation else None
1579             alias = self.join(
1580                 connection, reuse=reuse,
1581                 reuse_with_filtered_relation=reuse_with_filtered_relation,
1582             )
1583             joins.append(alias)
1584             if filtered_relation:
1585                 filtered_relation.path = joins[:]
1586         return JoinInfo(final_field, targets, opts, joins, path, final_transformer)
1587 
1588     def trim_joins(self, targets, joins, path):
1589         """
1590         The 'target' parameter is the final field being joined to, 'joins'
1591         is the full list of join aliases. The 'path' contain the PathInfos
1592         used to create the joins.
1593 
1594         Return the final target field and table alias and the new active
1595         joins.
1596 
1597         Always trim any direct join if the target column is already in the
1598         previous table. Can't trim reverse joins as it's unknown if there's
1599         anything on the other side of the join.
1600         """
1601         joins = joins[:]
1602         for pos, info in enumerate(reversed(path)):
1603             if len(joins) == 1 or not info.direct:
1604                 break
1605             if info.filtered_relation:
1606                 break
1607             join_targets = {t.column for t in info.join_field.foreign_related_fields}
1608             cur_targets = {t.column for t in targets}
1609             if not cur_targets.issubset(join_targets):
1610                 break
1611             targets_dict = {r[1].column: r[0] for r in info.join_field.related_fields if r[1].column in cur_targets}
1612             targets = tuple(targets_dict[t.column] for t in targets)
1613             self.unref_alias(joins.pop())
1614         return targets, joins[-1], joins
1615 
1616     @classmethod
1617     def _gen_col_aliases(cls, exprs):
1618         for expr in exprs:
1619             if isinstance(expr, Col):
1620                 yield expr.alias
1621             else:
1622                 yield from cls._gen_col_aliases(expr.get_source_expressions())
1623 
1624     def resolve_ref(self, name, allow_joins=True, reuse=None, summarize=False, simple_col=False):
1625         if not allow_joins and LOOKUP_SEP in name:
1626             raise FieldError("Joined field references are not permitted in this query")
1627         annotation = self.annotations.get(name)
1628         if annotation is not None:
1629             if not allow_joins:
1630                 for alias in self._gen_col_aliases([annotation]):
1631                     if isinstance(self.alias_map[alias], Join):
1632                         raise FieldError(
1633                             'Joined field references are not permitted in '
1634                             'this query'
1635                         )
1636             if summarize:
1637                 # Summarize currently means we are doing an aggregate() query
1638                 # which is executed as a wrapped subquery if any of the
1639                 # aggregate() elements reference an existing annotation. In
1640                 # that case we need to return a Ref to the subquery's annotation.
1641                 return Ref(name, self.annotation_select[name])
1642             else:
1643                 return annotation
1644         else:
1645             field_list = name.split(LOOKUP_SEP)
1646             join_info = self.setup_joins(field_list, self.get_meta(), self.get_initial_alias(), can_reuse=reuse)
1647             targets, final_alias, join_list = self.trim_joins(join_info.targets, join_info.joins, join_info.path)
1648             if not allow_joins and len(join_list) > 1:
1649                 raise FieldError('Joined field references are not permitted in this query')
1650             if len(targets) > 1:
1651                 raise FieldError("Referencing multicolumn fields with F() objects "
1652                                  "isn't supported")
1653             # Verify that the last lookup in name is a field or a transform:
1654             # transform_function() raises FieldError if not.
1655             join_info.transform_function(targets[0], final_alias)
1656             if reuse is not None:
1657                 reuse.update(join_list)
1658             col = _get_col(targets[0], join_info.targets[0], join_list[-1], simple_col)
1659             return col
1660 
1661     def split_exclude(self, filter_expr, can_reuse, names_with_path):
1662         """
1663         When doing an exclude against any kind of N-to-many relation, we need
1664         to use a subquery. This method constructs the nested query, given the
1665         original exclude filter (filter_expr) and the portion up to the first
1666         N-to-many relation field.
1667 
1668         For example, if the origin filter is ~Q(child__name='foo'), filter_expr
1669         is ('child__name', 'foo') and can_reuse is a set of joins usable for
1670         filters in the original query.
1671 
1672         We will turn this into equivalent of:
1673             WHERE NOT (pk IN (SELECT parent_id FROM thetable
1674                               WHERE name = 'foo' AND parent_id IS NOT NULL))
1675 
1676         It might be worth it to consider using WHERE NOT EXISTS as that has
1677         saner null handling, and is easier for the backend's optimizer to
1678         handle.
1679         """
1680         filter_lhs, filter_rhs = filter_expr
1681         if isinstance(filter_rhs, F):
1682             filter_expr = (filter_lhs, OuterRef(filter_rhs.name))
1683         # Generate the inner query.
1684         query = Query(self.model)
1685         query._filtered_relations = self._filtered_relations
1686         query.add_filter(filter_expr)
1687         query.clear_ordering(True)
1688         # Try to have as simple as possible subquery -> trim leading joins from
1689         # the subquery.
1690         trimmed_prefix, contains_louter = query.trim_start(names_with_path)
1691 
1692         # Add extra check to make sure the selected field will not be null
1693         # since we are adding an IN <subquery> clause. This prevents the
1694         # database from tripping over IN (...,NULL,...) selects and returning
1695         # nothing
1696         col = query.select[0]
1697         select_field = col.target
1698         alias = col.alias
1699         if self.is_nullable(select_field):
1700             lookup_class = select_field.get_lookup('isnull')
1701             lookup = lookup_class(select_field.get_col(alias), False)
1702             query.where.add(lookup, AND)
1703         if alias in can_reuse:
1704             pk = select_field.model._meta.pk
1705             # Need to add a restriction so that outer query's filters are in effect for
1706             # the subquery, too.
1707             query.bump_prefix(self)
1708             lookup_class = select_field.get_lookup('exact')
1709             # Note that the query.select[0].alias is different from alias
1710             # due to bump_prefix above.
1711             lookup = lookup_class(pk.get_col(query.select[0].alias),
1712                                   pk.get_col(alias))
1713             query.where.add(lookup, AND)
1714             query.external_aliases.add(alias)
1715 
1716         condition, needed_inner = self.build_filter(
1717             ('%s__in' % trimmed_prefix, query),
1718             current_negated=True, branch_negated=True, can_reuse=can_reuse)
1719         if contains_louter:
1720             or_null_condition, _ = self.build_filter(
1721                 ('%s__isnull' % trimmed_prefix, True),
1722                 current_negated=True, branch_negated=True, can_reuse=can_reuse)
1723             condition.add(or_null_condition, OR)
1724             # Note that the end result will be:
1725             # (outercol NOT IN innerq AND outercol IS NOT NULL) OR outercol IS NULL.
1726             # This might look crazy but due to how IN works, this seems to be
1727             # correct. If the IS NOT NULL check is removed then outercol NOT
1728             # IN will return UNKNOWN. If the IS NULL check is removed, then if
1729             # outercol IS NULL we will not match the row.
1730         return condition, needed_inner
1731 
1732     def set_empty(self):
1733         self.where.add(NothingNode(), AND)
1734 
1735     def is_empty(self):
1736         return any(isinstance(c, NothingNode) for c in self.where.children)
1737 
1738     def set_limits(self, low=None, high=None):
1739         """
1740         Adjust the limits on the rows retrieved. Use low/high to set these,
1741         as it makes it more Pythonic to read and write. When the SQL query is
1742         created, convert them to the appropriate offset and limit values.
1743 
1744         Apply any limits passed in here to the existing constraints. Add low
1745         to the current low value and clamp both to any existing high value.
1746         """
1747         if high is not None:
1748             if self.high_mark is not None:
1749                 self.high_mark = min(self.high_mark, self.low_mark + high)
1750             else:
1751                 self.high_mark = self.low_mark + high
1752         if low is not None:
1753             if self.high_mark is not None:
1754                 self.low_mark = min(self.high_mark, self.low_mark + low)
1755             else:
1756                 self.low_mark = self.low_mark + low
1757 
1758         if self.low_mark == self.high_mark:
1759             self.set_empty()
1760 
1761     def clear_limits(self):
1762         """Clear any existing limits."""
1763         self.low_mark, self.high_mark = 0, None
1764 
1765     def has_limit_one(self):
1766         return self.high_mark is not None and (self.high_mark - self.low_mark) == 1
1767 
1768     def can_filter(self):
1769         """
1770         Return True if adding filters to this instance is still possible.
1771 
1772         Typically, this means no limits or offsets have been put on the results.
1773         """
1774         return not self.low_mark and self.high_mark is None
1775 
1776     def clear_select_clause(self):
1777         """Remove all fields from SELECT clause."""
1778         self.select = ()
1779         self.default_cols = False
1780         self.select_related = False
1781         self.set_extra_mask(())
1782         self.set_annotation_mask(())
1783 
1784     def clear_select_fields(self):
1785         """
1786         Clear the list of fields to select (but not extra_select columns).
1787         Some queryset types completely replace any existing list of select
1788         columns.
1789         """
1790         self.select = ()
1791         self.values_select = ()
1792 
1793     def add_select_col(self, col):
1794         self.select += col,
1795         self.values_select += col.output_field.name,
1796 
1797     def set_select(self, cols):
1798         self.default_cols = False
1799         self.select = tuple(cols)
1800 
1801     def add_distinct_fields(self, *field_names):
1802         """
1803         Add and resolve the given fields to the query's "distinct on" clause.
1804         """
1805         self.distinct_fields = field_names
1806         self.distinct = True
1807 
1808     def add_fields(self, field_names, allow_m2m=True):
1809         """
1810         Add the given (model) fields to the select set. Add the field names in
1811         the order specified.
1812         """
1813         alias = self.get_initial_alias()
1814         opts = self.get_meta()
1815 
1816         try:
1817             cols = []
1818             for name in field_names:
1819                 # Join promotion note - we must not remove any rows here, so
1820                 # if there is no existing joins, use outer join.
1821                 join_info = self.setup_joins(name.split(LOOKUP_SEP), opts, alias, allow_many=allow_m2m)
1822                 targets, final_alias, joins = self.trim_joins(
1823                     join_info.targets,
1824                     join_info.joins,
1825                     join_info.path,
1826                 )
1827                 for target in targets:
1828                     cols.append(join_info.transform_function(target, final_alias))
1829             if cols:
1830                 self.set_select(cols)
1831         except MultiJoin:
1832             raise FieldError("Invalid field name: '%s'" % name)
1833         except FieldError:
1834             if LOOKUP_SEP in name:
1835                 # For lookups spanning over relationships, show the error
1836                 # from the model on which the lookup failed.
1837                 raise
1838             else:
1839                 names = sorted([
1840                     *get_field_names_from_opts(opts), *self.extra,
1841                     *self.annotation_select, *self._filtered_relations
1842                 ])
1843                 raise FieldError("Cannot resolve keyword %r into field. "
1844                                  "Choices are: %s" % (name, ", ".join(names)))
1845 
1846     def add_ordering(self, *ordering):
1847         """
1848         Add items from the 'ordering' sequence to the query's "order by"
1849         clause. These items are either field names (not column names) --
1850         possibly with a direction prefix ('-' or '?') -- or OrderBy
1851         expressions.
1852 
1853         If 'ordering' is empty, clear all ordering from the query.
1854         """
1855         errors = []
1856         for item in ordering:
1857             if not hasattr(item, 'resolve_expression') and not ORDER_PATTERN.match(item):
1858                 errors.append(item)
1859             if getattr(item, 'contains_aggregate', False):
1860                 raise FieldError(
1861                     'Using an aggregate in order_by() without also including '
1862                     'it in annotate() is not allowed: %s' % item
1863                 )
1864         if errors:
1865             raise FieldError('Invalid order_by arguments: %s' % errors)
1866         if ordering:
1867             self.order_by += ordering
1868         else:
1869             self.default_ordering = False
1870 
1871     def clear_ordering(self, force_empty):
1872         """
1873         Remove any ordering settings. If 'force_empty' is True, there will be
1874         no ordering in the resulting query (not even the model's default).
1875         """
1876         self.order_by = ()
1877         self.extra_order_by = ()
1878         if force_empty:
1879             self.default_ordering = False
1880 
1881     def set_group_by(self):
1882         """
1883         Expand the GROUP BY clause required by the query.
1884 
1885         This will usually be the set of all non-aggregate fields in the
1886         return data. If the database backend supports grouping by the
1887         primary key, and the query would be equivalent, the optimization
1888         will be made automatically.
1889         """
1890         group_by = list(self.select)
1891         if self.annotation_select:
1892             for alias, annotation in self.annotation_select.items():
1893                 try:
1894                     inspect.getcallargs(annotation.get_group_by_cols, alias=alias)
1895                 except TypeError:
1896                     annotation_class = annotation.__class__
1897                     msg = (
1898                         '`alias=None` must be added to the signature of '
1899                         '%s.%s.get_group_by_cols().'
1900                     ) % (annotation_class.__module__, annotation_class.__qualname__)
1901                     warnings.warn(msg, category=RemovedInDjango40Warning)
1902                     group_by_cols = annotation.get_group_by_cols()
1903                 else:
1904                     group_by_cols = annotation.get_group_by_cols(alias=alias)
1905                 group_by.extend(group_by_cols)
1906         self.group_by = tuple(group_by)
1907 
1908     def add_select_related(self, fields):
1909         """
1910         Set up the select_related data structure so that we only select
1911         certain related models (as opposed to all models, when
1912         self.select_related=True).
1913         """
1914         if isinstance(self.select_related, bool):
1915             field_dict = {}
1916         else:
1917             field_dict = self.select_related
1918         for field in fields:
1919             d = field_dict
1920             for part in field.split(LOOKUP_SEP):
1921                 d = d.setdefault(part, {})
1922         self.select_related = field_dict
1923 
1924     def add_extra(self, select, select_params, where, params, tables, order_by):
1925         """
1926         Add data to the various extra_* attributes for user-created additions
1927         to the query.
1928         """
1929         if select:
1930             # We need to pair any placeholder markers in the 'select'
1931             # dictionary with their parameters in 'select_params' so that
1932             # subsequent updates to the select dictionary also adjust the
1933             # parameters appropriately.
1934             select_pairs = {}
1935             if select_params:
1936                 param_iter = iter(select_params)
1937             else:
1938                 param_iter = iter([])
1939             for name, entry in select.items():
1940                 entry = str(entry)
1941                 entry_params = []
1942                 pos = entry.find("%s")
1943                 while pos != -1:
1944                     if pos == 0 or entry[pos - 1] != '%':
1945                         entry_params.append(next(param_iter))
1946                     pos = entry.find("%s", pos + 2)
1947                 select_pairs[name] = (entry, entry_params)
1948             self.extra.update(select_pairs)
1949         if where or params:
1950             self.where.add(ExtraWhere(where, params), AND)
1951         if tables:
1952             self.extra_tables += tuple(tables)
1953         if order_by:
1954             self.extra_order_by = order_by
1955 
1956     def clear_deferred_loading(self):
1957         """Remove any fields from the deferred loading set."""
1958         self.deferred_loading = (frozenset(), True)
1959 
1960     def add_deferred_loading(self, field_names):
1961         """
1962         Add the given list of model field names to the set of fields to
1963         exclude from loading from the database when automatic column selection
1964         is done. Add the new field names to any existing field names that
1965         are deferred (or removed from any existing field names that are marked
1966         as the only ones for immediate loading).
1967         """
1968         # Fields on related models are stored in the literal double-underscore
1969         # format, so that we can use a set datastructure. We do the foo__bar
1970         # splitting and handling when computing the SQL column names (as part of
1971         # get_columns()).
1972         existing, defer = self.deferred_loading
1973         if defer:
1974             # Add to existing deferred names.
1975             self.deferred_loading = existing.union(field_names), True
1976         else:
1977             # Remove names from the set of any existing "immediate load" names.
1978             self.deferred_loading = existing.difference(field_names), False
1979 
1980     def add_immediate_loading(self, field_names):
1981         """
1982         Add the given list of model field names to the set of fields to
1983         retrieve when the SQL is executed ("immediate loading" fields). The
1984         field names replace any existing immediate loading field names. If
1985         there are field names already specified for deferred loading, remove
1986         those names from the new field_names before storing the new names
1987         for immediate loading. (That is, immediate loading overrides any
1988         existing immediate values, but respects existing deferrals.)
1989         """
1990         existing, defer = self.deferred_loading
1991         field_names = set(field_names)
1992         if 'pk' in field_names:
1993             field_names.remove('pk')
1994             field_names.add(self.get_meta().pk.name)
1995 
1996         if defer:
1997             # Remove any existing deferred names from the current set before
1998             # setting the new names.
1999             self.deferred_loading = field_names.difference(existing), False
2000         else:
2001             # Replace any existing "immediate load" field names.
2002             self.deferred_loading = frozenset(field_names), False
2003 
2004     def get_loaded_field_names(self):
2005         """
2006         If any fields are marked to be deferred, return a dictionary mapping
2007         models to a set of names in those fields that will be loaded. If a
2008         model is not in the returned dictionary, none of its fields are
2009         deferred.
2010 
2011         If no fields are marked for deferral, return an empty dictionary.
2012         """
2013         # We cache this because we call this function multiple times
2014         # (compiler.fill_related_selections, query.iterator)
2015         try:
2016             return self._loaded_field_names_cache
2017         except AttributeError:
2018             collection = {}
2019             self.deferred_to_data(collection, self.get_loaded_field_names_cb)
2020             self._loaded_field_names_cache = collection
2021             return collection
2022 
2023     def get_loaded_field_names_cb(self, target, model, fields):
2024         """Callback used by get_deferred_field_names()."""
2025         target[model] = {f.attname for f in fields}
2026 
2027     def set_annotation_mask(self, names):
2028         """Set the mask of annotations that will be returned by the SELECT."""
2029         if names is None:
2030             self.annotation_select_mask = None
2031         else:
2032             self.annotation_select_mask = set(names)
2033         self._annotation_select_cache = None
2034 
2035     def append_annotation_mask(self, names):
2036         if self.annotation_select_mask is not None:
2037             self.set_annotation_mask(self.annotation_select_mask.union(names))
2038 
2039     def set_extra_mask(self, names):
2040         """
2041         Set the mask of extra select items that will be returned by SELECT.
2042         Don't remove them from the Query since they might be used later.
2043         """
2044         if names is None:
2045             self.extra_select_mask = None
2046         else:
2047             self.extra_select_mask = set(names)
2048         self._extra_select_cache = None
2049 
2050     def set_values(self, fields):
2051         self.select_related = False
2052         self.clear_deferred_loading()
2053         self.clear_select_fields()
2054 
2055         if self.group_by is True:
2056             self.add_fields((f.attname for f in self.model._meta.concrete_fields), False)
2057             self.set_group_by()
2058             self.clear_select_fields()
2059 
2060         if fields:
2061             field_names = []
2062             extra_names = []
2063             annotation_names = []
2064             if not self.extra and not self.annotations:
2065                 # Shortcut - if there are no extra or annotations, then
2066                 # the values() clause must be just field names.
2067                 field_names = list(fields)
2068             else:
2069                 self.default_cols = False
2070                 for f in fields:
2071                     if f in self.extra_select:
2072                         extra_names.append(f)
2073                     elif f in self.annotation_select:
2074                         annotation_names.append(f)
2075                     else:
2076                         field_names.append(f)
2077             self.set_extra_mask(extra_names)
2078             self.set_annotation_mask(annotation_names)
2079         else:
2080             field_names = [f.attname for f in self.model._meta.concrete_fields]
2081 
2082         self.values_select = tuple(field_names)
2083         self.add_fields(field_names, True)
2084 
2085     @property
2086     def annotation_select(self):
2087         """
2088         Return the dictionary of aggregate columns that are not masked and
2089         should be used in the SELECT clause. Cache this result for performance.
2090         """
2091         if self._annotation_select_cache is not None:
2092             return self._annotation_select_cache
2093         elif not self.annotations:
2094             return {}
2095         elif self.annotation_select_mask is not None:
2096             self._annotation_select_cache = {
2097                 k: v for k, v in self.annotations.items()
2098                 if k in self.annotation_select_mask
2099             }
2100             return self._annotation_select_cache
2101         else:
2102             return self.annotations
2103 
2104     @property
2105     def extra_select(self):
2106         if self._extra_select_cache is not None:
2107             return self._extra_select_cache
2108         if not self.extra:
2109             return {}
2110         elif self.extra_select_mask is not None:
2111             self._extra_select_cache = {
2112                 k: v for k, v in self.extra.items()
2113                 if k in self.extra_select_mask
2114             }
2115             return self._extra_select_cache
2116         else:
2117             return self.extra
2118 
2119     def trim_start(self, names_with_path):
2120         """
2121         Trim joins from the start of the join path. The candidates for trim
2122         are the PathInfos in names_with_path structure that are m2m joins.
2123 
2124         Also set the select column so the start matches the join.
2125 
2126         This method is meant to be used for generating the subquery joins &
2127         cols in split_exclude().
2128 
2129         Return a lookup usable for doing outerq.filter(lookup=self) and a
2130         boolean indicating if the joins in the prefix contain a LEFT OUTER join.
2131         _"""
2132         all_paths = []
2133         for _, paths in names_with_path:
2134             all_paths.extend(paths)
2135         contains_louter = False
2136         # Trim and operate only on tables that were generated for
2137         # the lookup part of the query. That is, avoid trimming
2138         # joins generated for F() expressions.
2139         lookup_tables = [
2140             t for t in self.alias_map
2141             if t in self._lookup_joins or t == self.base_table
2142         ]
2143         for trimmed_paths, path in enumerate(all_paths):
2144             if path.m2m:
2145                 break
2146             if self.alias_map[lookup_tables[trimmed_paths + 1]].join_type == LOUTER:
2147                 contains_louter = True
2148             alias = lookup_tables[trimmed_paths]
2149             self.unref_alias(alias)
2150         # The path.join_field is a Rel, lets get the other side's field
2151         join_field = path.join_field.field
2152         # Build the filter prefix.
2153         paths_in_prefix = trimmed_paths
2154         trimmed_prefix = []
2155         for name, path in names_with_path:
2156             if paths_in_prefix - len(path) < 0:
2157                 break
2158             trimmed_prefix.append(name)
2159             paths_in_prefix -= len(path)
2160         trimmed_prefix.append(
2161             join_field.foreign_related_fields[0].name)
2162         trimmed_prefix = LOOKUP_SEP.join(trimmed_prefix)
2163         # Lets still see if we can trim the first join from the inner query
2164         # (that is, self). We can't do this for:
2165         # - LEFT JOINs because we would miss those rows that have nothing on
2166         #   the outer side,
2167         # - INNER JOINs from filtered relations because we would miss their
2168         #   filters.
2169         first_join = self.alias_map[lookup_tables[trimmed_paths + 1]]
2170         if first_join.join_type != LOUTER and not first_join.filtered_relation:
2171             select_fields = [r[0] for r in join_field.related_fields]
2172             select_alias = lookup_tables[trimmed_paths + 1]
2173             self.unref_alias(lookup_tables[trimmed_paths])
2174             extra_restriction = join_field.get_extra_restriction(
2175                 self.where_class, None, lookup_tables[trimmed_paths + 1])
2176             if extra_restriction:
2177                 self.where.add(extra_restriction, AND)
2178         else:
2179             # TODO: It might be possible to trim more joins from the start of the
2180             # inner query if it happens to have a longer join chain containing the
2181             # values in select_fields. Lets punt this one for now.
2182             select_fields = [r[1] for r in join_field.related_fields]
2183             select_alias = lookup_tables[trimmed_paths]
2184         # The found starting point is likely a Join instead of a BaseTable reference.
2185         # But the first entry in the query's FROM clause must not be a JOIN.
2186         for table in self.alias_map:
2187             if self.alias_refcount[table] > 0:
2188                 self.alias_map[table] = BaseTable(self.alias_map[table].table_name, table)
2189                 break
2190         self.set_select([f.get_col(select_alias) for f in select_fields])
2191         return trimmed_prefix, contains_louter
2192 
2193     def is_nullable(self, field):
2194         """
2195         Check if the given field should be treated as nullable.
2196 
2197         Some backends treat '' as null and Django treats such fields as
2198         nullable for those backends. In such situations field.null can be
2199         False even if we should treat the field as nullable.
2200         """
2201         # We need to use DEFAULT_DB_ALIAS here, as QuerySet does not have
2202         # (nor should it have) knowledge of which connection is going to be
2203         # used. The proper fix would be to defer all decisions where
2204         # is_nullable() is needed to the compiler stage, but that is not easy
2205         # to do currently.
2206         return (
2207             connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls and
2208             field.empty_strings_allowed
2209         ) or field.null

</code><intended_behavior>This class provides additional context to the issue.</intended_behavior>]
2025-10-18 10:25:17.713 | INFO     | Overall retry 0 succeeded; ending workflow
2025-10-18 10:25:17.713 | INFO     | Search-only: skipping patch selection
2025-10-18 10:25:17.908 | INFO     | Task django__django-11354 completed successfully.
2025-10-18 10:25:17.908 | INFO     | No patch generated. You can try running ACR again.
