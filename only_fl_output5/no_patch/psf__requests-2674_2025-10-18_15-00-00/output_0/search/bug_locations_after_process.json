[
    {
        "rel_file_path": "requests/adapters.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/psf__requests/setup_psf__requests__2.7/requests/adapters.py",
        "start": 1,
        "end": 435,
        "class_name": null,
        "method_name": null,
        "code": "1 # -*- coding: utf-8 -*-\n2 \n3 \"\"\"\n4 requests.adapters\n5 ~~~~~~~~~~~~~~~~~\n6 \n7 This module contains the transport adapters that Requests uses to define\n8 and maintain connections.\n9 \"\"\"\n10 \n11 import socket\n12 \n13 from .models import Response\n14 from .packages.urllib3.poolmanager import PoolManager, proxy_from_url\n15 from .packages.urllib3.response import HTTPResponse\n16 from .packages.urllib3.util import Timeout as TimeoutSauce\n17 from .packages.urllib3.util.retry import Retry\n18 from .compat import urlparse, basestring\n19 from .utils import (DEFAULT_CA_BUNDLE_PATH, get_encoding_from_headers,\n20                     prepend_scheme_if_needed, get_auth_from_url, urldefragauth)\n21 from .structures import CaseInsensitiveDict\n22 from .packages.urllib3.exceptions import ConnectTimeoutError\n23 from .packages.urllib3.exceptions import HTTPError as _HTTPError\n24 from .packages.urllib3.exceptions import MaxRetryError\n25 from .packages.urllib3.exceptions import ProxyError as _ProxyError\n26 from .packages.urllib3.exceptions import ProtocolError\n27 from .packages.urllib3.exceptions import ReadTimeoutError\n28 from .packages.urllib3.exceptions import SSLError as _SSLError\n29 from .packages.urllib3.exceptions import ResponseError\n30 from .cookies import extract_cookies_to_jar\n31 from .exceptions import (ConnectionError, ConnectTimeout, ReadTimeout, SSLError,\n32                          ProxyError, RetryError)\n33 from .auth import _basic_auth_str\n34 \n35 DEFAULT_POOLBLOCK = False\n36 DEFAULT_POOLSIZE = 10\n37 DEFAULT_RETRIES = 0\n38 DEFAULT_POOL_TIMEOUT = None\n39 \n40 \n41 class BaseAdapter(object):\n42     \"\"\"The Base Transport Adapter\"\"\"\n43 \n44     def __init__(self):\n45         super(BaseAdapter, self).__init__()\n46 \n47     def send(self):\n48         raise NotImplementedError\n49 \n50     def close(self):\n51         raise NotImplementedError\n52 \n53 \n54 class HTTPAdapter(BaseAdapter):\n55     \"\"\"The built-in HTTP Adapter for urllib3.\n56 \n57     Provides a general-case interface for Requests sessions to contact HTTP and\n58     HTTPS urls by implementing the Transport Adapter interface. This class will\n59     usually be created by the :class:`Session <Session>` class under the\n60     covers.\n61 \n62     :param pool_connections: The number of urllib3 connection pools to cache.\n63     :param pool_maxsize: The maximum number of connections to save in the pool.\n64     :param int max_retries: The maximum number of retries each connection\n65         should attempt. Note, this applies only to failed DNS lookups, socket\n66         connections and connection timeouts, never to requests where data has\n67         made it to the server. By default, Requests does not retry failed\n68         connections. If you need granular control over the conditions under\n69         which we retry a request, import urllib3's ``Retry`` class and pass\n70         that instead.\n71     :param pool_block: Whether the connection pool should block for connections.\n72 \n73     Usage::\n74 \n75       >>> import requests\n76       >>> s = requests.Session()\n77       >>> a = requests.adapters.HTTPAdapter(max_retries=3)\n78       >>> s.mount('http://', a)\n79     \"\"\"\n80     __attrs__ = ['max_retries', 'config', '_pool_connections', '_pool_maxsize',\n81                  '_pool_block']\n82 \n83     def __init__(self, pool_connections=DEFAULT_POOLSIZE,\n84                  pool_maxsize=DEFAULT_POOLSIZE, max_retries=DEFAULT_RETRIES,\n85                  pool_block=DEFAULT_POOLBLOCK):\n86         if max_retries == DEFAULT_RETRIES:\n87             self.max_retries = Retry(0, read=False)\n88         else:\n89             self.max_retries = Retry.from_int(max_retries)\n90         self.config = {}\n91         self.proxy_manager = {}\n92 \n93         super(HTTPAdapter, self).__init__()\n94 \n95         self._pool_connections = pool_connections\n96         self._pool_maxsize = pool_maxsize\n97         self._pool_block = pool_block\n98 \n99         self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)\n100 \n101     def __getstate__(self):\n102         return dict((attr, getattr(self, attr, None)) for attr in\n103                     self.__attrs__)\n104 \n105     def __setstate__(self, state):\n106         # Can't handle by adding 'proxy_manager' to self.__attrs__ because\n107         # because self.poolmanager uses a lambda function, which isn't pickleable.\n108         self.proxy_manager = {}\n109         self.config = {}\n110 \n111         for attr, value in state.items():\n112             setattr(self, attr, value)\n113 \n114         self.init_poolmanager(self._pool_connections, self._pool_maxsize,\n115                               block=self._pool_block)\n116 \n117     def init_poolmanager(self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs):\n118         \"\"\"Initializes a urllib3 PoolManager.\n119 \n120         This method should not be called from user code, and is only\n121         exposed for use when subclassing the\n122         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n123 \n124         :param connections: The number of urllib3 connection pools to cache.\n125         :param maxsize: The maximum number of connections to save in the pool.\n126         :param block: Block when no free connections are available.\n127         :param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.\n128         \"\"\"\n129         # save these values for pickling\n130         self._pool_connections = connections\n131         self._pool_maxsize = maxsize\n132         self._pool_block = block\n133 \n134         self.poolmanager = PoolManager(num_pools=connections, maxsize=maxsize,\n135                                        block=block, strict=True, **pool_kwargs)\n136 \n137     def proxy_manager_for(self, proxy, **proxy_kwargs):\n138         \"\"\"Return urllib3 ProxyManager for the given proxy.\n139 \n140         This method should not be called from user code, and is only\n141         exposed for use when subclassing the\n142         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n143 \n144         :param proxy: The proxy to return a urllib3 ProxyManager for.\n145         :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.\n146         :returns: ProxyManager\n147         \"\"\"\n148         if not proxy in self.proxy_manager:\n149             proxy_headers = self.proxy_headers(proxy)\n150             self.proxy_manager[proxy] = proxy_from_url(\n151                 proxy,\n152                 proxy_headers=proxy_headers,\n153                 num_pools=self._pool_connections,\n154                 maxsize=self._pool_maxsize,\n155                 block=self._pool_block,\n156                 **proxy_kwargs)\n157 \n158         return self.proxy_manager[proxy]\n159 \n160     def cert_verify(self, conn, url, verify, cert):\n161         \"\"\"Verify a SSL certificate. This method should not be called from user\n162         code, and is only exposed for use when subclassing the\n163         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n164 \n165         :param conn: The urllib3 connection object associated with the cert.\n166         :param url: The requested URL.\n167         :param verify: Whether we should actually verify the certificate.\n168         :param cert: The SSL certificate to verify.\n169         \"\"\"\n170         if url.lower().startswith('https') and verify:\n171 \n172             cert_loc = None\n173 \n174             # Allow self-specified cert location.\n175             if verify is not True:\n176                 cert_loc = verify\n177 \n178             if not cert_loc:\n179                 cert_loc = DEFAULT_CA_BUNDLE_PATH\n180 \n181             if not cert_loc:\n182                 raise Exception(\"Could not find a suitable SSL CA certificate bundle.\")\n183 \n184             conn.cert_reqs = 'CERT_REQUIRED'\n185             conn.ca_certs = cert_loc\n186         else:\n187             conn.cert_reqs = 'CERT_NONE'\n188             conn.ca_certs = None\n189 \n190         if cert:\n191             if not isinstance(cert, basestring):\n192                 conn.cert_file = cert[0]\n193                 conn.key_file = cert[1]\n194             else:\n195                 conn.cert_file = cert\n196 \n197     def build_response(self, req, resp):\n198         \"\"\"Builds a :class:`Response <requests.Response>` object from a urllib3\n199         response. This should not be called from user code, and is only exposed\n200         for use when subclassing the\n201         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`\n202 \n203         :param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.\n204         :param resp: The urllib3 response object.\n205         \"\"\"\n206         response = Response()\n207 \n208         # Fallback to None if there's no status_code, for whatever reason.\n209         response.status_code = getattr(resp, 'status', None)\n210 \n211         # Make headers case-insensitive.\n212         response.headers = CaseInsensitiveDict(getattr(resp, 'headers', {}))\n213 \n214         # Set encoding.\n215         response.encoding = get_encoding_from_headers(response.headers)\n216         response.raw = resp\n217         response.reason = response.raw.reason\n218 \n219         if isinstance(req.url, bytes):\n220             response.url = req.url.decode('utf-8')\n221         else:\n222             response.url = req.url\n223 \n224         # Add new cookies from the server.\n225         extract_cookies_to_jar(response.cookies, req, resp)\n226 \n227         # Give the Response some context.\n228         response.request = req\n229         response.connection = self\n230 \n231         return response\n232 \n233     def get_connection(self, url, proxies=None):\n234         \"\"\"Returns a urllib3 connection for the given URL. This should not be\n235         called from user code, and is only exposed for use when subclassing the\n236         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n237 \n238         :param url: The URL to connect to.\n239         :param proxies: (optional) A Requests-style dictionary of proxies used on this request.\n240         \"\"\"\n241         proxies = proxies or {}\n242         proxy = proxies.get(urlparse(url.lower()).scheme)\n243 \n244         if proxy:\n245             proxy = prepend_scheme_if_needed(proxy, 'http')\n246             proxy_manager = self.proxy_manager_for(proxy)\n247             conn = proxy_manager.connection_from_url(url)\n248         else:\n249             # Only scheme should be lower case\n250             parsed = urlparse(url)\n251             url = parsed.geturl()\n252             conn = self.poolmanager.connection_from_url(url)\n253 \n254         return conn\n255 \n256     def close(self):\n257         \"\"\"Disposes of any internal state.\n258 \n259         Currently, this just closes the PoolManager, which closes pooled\n260         connections.\n261         \"\"\"\n262         self.poolmanager.clear()\n263 \n264     def request_url(self, request, proxies):\n265         \"\"\"Obtain the url to use when making the final request.\n266 \n267         If the message is being sent through a HTTP proxy, the full URL has to\n268         be used. Otherwise, we should only use the path portion of the URL.\n269 \n270         This should not be called from user code, and is only exposed for use\n271         when subclassing the\n272         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n273 \n274         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n275         :param proxies: A dictionary of schemes to proxy URLs.\n276         \"\"\"\n277         proxies = proxies or {}\n278         scheme = urlparse(request.url).scheme\n279         proxy = proxies.get(scheme)\n280 \n281         if proxy and scheme != 'https':\n282             url = urldefragauth(request.url)\n283         else:\n284             url = request.path_url\n285 \n286         return url\n287 \n288     def add_headers(self, request, **kwargs):\n289         \"\"\"Add any headers needed by the connection. As of v2.0 this does\n290         nothing by default, but is left for overriding by users that subclass\n291         the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n292 \n293         This should not be called from user code, and is only exposed for use\n294         when subclassing the\n295         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n296 \n297         :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.\n298         :param kwargs: The keyword arguments from the call to send().\n299         \"\"\"\n300         pass\n301 \n302     def proxy_headers(self, proxy):\n303         \"\"\"Returns a dictionary of the headers to add to any request sent\n304         through a proxy. This works with urllib3 magic to ensure that they are\n305         correctly sent to the proxy, rather than in a tunnelled request if\n306         CONNECT is being used.\n307 \n308         This should not be called from user code, and is only exposed for use\n309         when subclassing the\n310         :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.\n311 \n312         :param proxies: The url of the proxy being used for this request.\n313         :param kwargs: Optional additional keyword arguments.\n314         \"\"\"\n315         headers = {}\n316         username, password = get_auth_from_url(proxy)\n317 \n318         if username and password:\n319             headers['Proxy-Authorization'] = _basic_auth_str(username,\n320                                                              password)\n321 \n322         return headers\n323 \n324     def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):\n325         \"\"\"Sends PreparedRequest object. Returns Response object.\n326 \n327         :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.\n328         :param stream: (optional) Whether to stream the request content.\n329         :param timeout: (optional) How long to wait for the server to send\n330             data before giving up, as a float, or a (`connect timeout, read\n331             timeout <user/advanced.html#timeouts>`_) tuple.\n332         :type timeout: float or tuple\n333         :param verify: (optional) Whether to verify SSL certificates.\n334         :param cert: (optional) Any user-provided SSL certificate to be trusted.\n335         :param proxies: (optional) The proxies dictionary to apply to the request.\n336         \"\"\"\n337 \n338         conn = self.get_connection(request.url, proxies)\n339 \n340         self.cert_verify(conn, request.url, verify, cert)\n341         url = self.request_url(request, proxies)\n342         self.add_headers(request)\n343 \n344         chunked = not (request.body is None or 'Content-Length' in request.headers)\n345 \n346         if isinstance(timeout, tuple):\n347             try:\n348                 connect, read = timeout\n349                 timeout = TimeoutSauce(connect=connect, read=read)\n350             except ValueError as e:\n351                 # this may raise a string formatting error.\n352                 err = (\"Invalid timeout {0}. Pass a (connect, read) \"\n353                        \"timeout tuple, or a single float to set \"\n354                        \"both timeouts to the same value\".format(timeout))\n355                 raise ValueError(err)\n356         else:\n357             timeout = TimeoutSauce(connect=timeout, read=timeout)\n358 \n359         try:\n360             if not chunked:\n361                 resp = conn.urlopen(\n362                     method=request.method,\n363                     url=url,\n364                     body=request.body,\n365                     headers=request.headers,\n366                     redirect=False,\n367                     assert_same_host=False,\n368                     preload_content=False,\n369                     decode_content=False,\n370                     retries=self.max_retries,\n371                     timeout=timeout\n372                 )\n373 \n374             # Send the request.\n375             else:\n376                 if hasattr(conn, 'proxy_pool'):\n377                     conn = conn.proxy_pool\n378 \n379                 low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)\n380 \n381                 try:\n382                     low_conn.putrequest(request.method,\n383                                         url,\n384                                         skip_accept_encoding=True)\n385 \n386                     for header, value in request.headers.items():\n387                         low_conn.putheader(header, value)\n388 \n389                     low_conn.endheaders()\n390 \n391                     for i in request.body:\n392                         low_conn.send(hex(len(i))[2:].encode('utf-8'))\n393                         low_conn.send(b'\\r\\n')\n394                         low_conn.send(i)\n395                         low_conn.send(b'\\r\\n')\n396                     low_conn.send(b'0\\r\\n\\r\\n')\n397 \n398                     r = low_conn.getresponse()\n399                     resp = HTTPResponse.from_httplib(\n400                         r,\n401                         pool=conn,\n402                         connection=low_conn,\n403                         preload_content=False,\n404                         decode_content=False\n405                     )\n406                 except:\n407                     # If we hit any problems here, clean up the connection.\n408                     # Then, reraise so that we can handle the actual exception.\n409                     low_conn.close()\n410                     raise\n411 \n412         except (ProtocolError, socket.error) as err:\n413             raise ConnectionError(err, request=request)\n414 \n415         except MaxRetryError as e:\n416             if isinstance(e.reason, ConnectTimeoutError):\n417                 raise ConnectTimeout(e, request=request)\n418 \n419             if isinstance(e.reason, ResponseError):\n420                 raise RetryError(e, request=request)\n421 \n422             raise ConnectionError(e, request=request)\n423 \n424         except _ProxyError as e:\n425             raise ProxyError(e)\n426 \n427         except (_SSLError, _HTTPError) as e:\n428             if isinstance(e, _SSLError):\n429                 raise SSLError(e, request=request)\n430             elif isinstance(e, ReadTimeoutError):\n431                 raise ReadTimeout(e, request=request)\n432             else:\n433                 raise\n434 \n435         return self.build_response(request, resp)\n",
        "intended_behavior": "This file is critical as it handles the lower-level requests to `urllib3` and is likely where `urllib3` exceptions are caught and either passed through or wrapped in `requests` exceptions. The intended behavior here should be to ensure that all exceptions from `urllib3`, specifically `DecodeError` and `TimeoutError`, are caught and re-raised as comparable `requests.exceptions`. For `DecodeError`, an appropriate `requests` exception might be a new exception that accurately describes the error (e.g., `ContentDecodeError`), reflecting an issue with decoding response content. For `TimeoutError`, since `requests` already defines timeout exceptions, it could be mapped to `requests.exceptions.ReadTimeout` or a new more specific timeout exception if the existing ones do not accurately capture the scenario (e.g., `ProxyTimeoutError` for proxy timeout issues). This would involve adding or modifying exception handling blocks where `urllib3` exceptions are currently caught."
    },
    {
        "rel_file_path": "requests/sessions.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/psf__requests/setup_psf__requests__2.7/requests/sessions.py",
        "start": 1,
        "end": 677,
        "class_name": null,
        "method_name": null,
        "code": "1 # -*- coding: utf-8 -*-\n2 \n3 \"\"\"\n4 requests.session\n5 ~~~~~~~~~~~~~~~~\n6 \n7 This module provides a Session object to manage and persist settings across\n8 requests (cookies, auth, proxies).\n9 \n10 \"\"\"\n11 import os\n12 from collections import Mapping\n13 from datetime import datetime\n14 \n15 from .auth import _basic_auth_str\n16 from .compat import cookielib, OrderedDict, urljoin, urlparse\n17 from .cookies import (\n18     cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar, merge_cookies)\n19 from .models import Request, PreparedRequest, DEFAULT_REDIRECT_LIMIT\n20 from .hooks import default_hooks, dispatch_hook\n21 from .utils import to_key_val_list, default_headers, to_native_string\n22 from .exceptions import (\n23     TooManyRedirects, InvalidSchema, ChunkedEncodingError, ContentDecodingError)\n24 from .packages.urllib3._collections import RecentlyUsedContainer\n25 from .structures import CaseInsensitiveDict\n26 \n27 from .adapters import HTTPAdapter\n28 \n29 from .utils import (\n30     requote_uri, get_environ_proxies, get_netrc_auth, should_bypass_proxies,\n31     get_auth_from_url\n32 )\n33 \n34 from .status_codes import codes\n35 \n36 # formerly defined here, reexposed here for backward compatibility\n37 from .models import REDIRECT_STATI\n38 \n39 REDIRECT_CACHE_SIZE = 1000\n40 \n41 \n42 def merge_setting(request_setting, session_setting, dict_class=OrderedDict):\n43     \"\"\"\n44     Determines appropriate setting for a given request, taking into account the\n45     explicit setting on that request, and the setting in the session. If a\n46     setting is a dictionary, they will be merged together using `dict_class`\n47     \"\"\"\n48 \n49     if session_setting is None:\n50         return request_setting\n51 \n52     if request_setting is None:\n53         return session_setting\n54 \n55     # Bypass if not a dictionary (e.g. verify)\n56     if not (\n57             isinstance(session_setting, Mapping) and\n58             isinstance(request_setting, Mapping)\n59     ):\n60         return request_setting\n61 \n62     merged_setting = dict_class(to_key_val_list(session_setting))\n63     merged_setting.update(to_key_val_list(request_setting))\n64 \n65     # Remove keys that are set to None.\n66     for (k, v) in request_setting.items():\n67         if v is None:\n68             del merged_setting[k]\n69 \n70     merged_setting = dict((k, v) for (k, v) in merged_setting.items() if v is not None)\n71 \n72     return merged_setting\n73 \n74 \n75 def merge_hooks(request_hooks, session_hooks, dict_class=OrderedDict):\n76     \"\"\"\n77     Properly merges both requests and session hooks.\n78 \n79     This is necessary because when request_hooks == {'response': []}, the\n80     merge breaks Session hooks entirely.\n81     \"\"\"\n82     if session_hooks is None or session_hooks.get('response') == []:\n83         return request_hooks\n84 \n85     if request_hooks is None or request_hooks.get('response') == []:\n86         return session_hooks\n87 \n88     return merge_setting(request_hooks, session_hooks, dict_class)\n89 \n90 \n91 class SessionRedirectMixin(object):\n92     def resolve_redirects(self, resp, req, stream=False, timeout=None,\n93                           verify=True, cert=None, proxies=None, **adapter_kwargs):\n94         \"\"\"Receives a Response. Returns a generator of Responses.\"\"\"\n95 \n96         i = 0\n97         hist = [] # keep track of history\n98 \n99         while resp.is_redirect:\n100             prepared_request = req.copy()\n101 \n102             if i > 0:\n103                 # Update history and keep track of redirects.\n104                 hist.append(resp)\n105                 new_hist = list(hist)\n106                 resp.history = new_hist\n107 \n108             try:\n109                 resp.content  # Consume socket so it can be released\n110             except (ChunkedEncodingError, ContentDecodingError, RuntimeError):\n111                 resp.raw.read(decode_content=False)\n112 \n113             if i >= self.max_redirects:\n114                 raise TooManyRedirects('Exceeded %s redirects.' % self.max_redirects)\n115 \n116             # Release the connection back into the pool.\n117             resp.close()\n118 \n119             url = resp.headers['location']\n120             method = req.method\n121 \n122             # Handle redirection without scheme (see: RFC 1808 Section 4)\n123             if url.startswith('//'):\n124                 parsed_rurl = urlparse(resp.url)\n125                 url = '%s:%s' % (parsed_rurl.scheme, url)\n126 \n127             # The scheme should be lower case...\n128             parsed = urlparse(url)\n129             url = parsed.geturl()\n130 \n131             # Facilitate relative 'location' headers, as allowed by RFC 7231.\n132             # (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')\n133             # Compliant with RFC3986, we percent encode the url.\n134             if not parsed.netloc:\n135                 url = urljoin(resp.url, requote_uri(url))\n136             else:\n137                 url = requote_uri(url)\n138 \n139             prepared_request.url = to_native_string(url)\n140             # Cache the url, unless it redirects to itself.\n141             if resp.is_permanent_redirect and req.url != prepared_request.url:\n142                 self.redirect_cache[req.url] = prepared_request.url\n143 \n144             # http://tools.ietf.org/html/rfc7231#section-6.4.4\n145             if (resp.status_code == codes.see_other and\n146                     method != 'HEAD'):\n147                 method = 'GET'\n148 \n149             # Do what the browsers do, despite standards...\n150             # First, turn 302s into GETs.\n151             if resp.status_code == codes.found and method != 'HEAD':\n152                 method = 'GET'\n153 \n154             # Second, if a POST is responded to with a 301, turn it into a GET.\n155             # This bizarre behaviour is explained in Issue 1704.\n156             if resp.status_code == codes.moved and method == 'POST':\n157                 method = 'GET'\n158 \n159             prepared_request.method = method\n160 \n161             # https://github.com/kennethreitz/requests/issues/1084\n162             if resp.status_code not in (codes.temporary_redirect, codes.permanent_redirect):\n163                 if 'Content-Length' in prepared_request.headers:\n164                     del prepared_request.headers['Content-Length']\n165 \n166                 prepared_request.body = None\n167 \n168             headers = prepared_request.headers\n169             try:\n170                 del headers['Cookie']\n171             except KeyError:\n172                 pass\n173 \n174             # Extract any cookies sent on the response to the cookiejar\n175             # in the new request. Because we've mutated our copied prepared\n176             # request, use the old one that we haven't yet touched.\n177             extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)\n178             prepared_request._cookies.update(self.cookies)\n179             prepared_request.prepare_cookies(prepared_request._cookies)\n180 \n181             # Rebuild auth and proxy information.\n182             proxies = self.rebuild_proxies(prepared_request, proxies)\n183             self.rebuild_auth(prepared_request, resp)\n184 \n185             # Override the original request.\n186             req = prepared_request\n187 \n188             resp = self.send(\n189                 req,\n190                 stream=stream,\n191                 timeout=timeout,\n192                 verify=verify,\n193                 cert=cert,\n194                 proxies=proxies,\n195                 allow_redirects=False,\n196                 **adapter_kwargs\n197             )\n198 \n199             extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)\n200 \n201             i += 1\n202             yield resp\n203 \n204     def rebuild_auth(self, prepared_request, response):\n205         \"\"\"\n206         When being redirected we may want to strip authentication from the\n207         request to avoid leaking credentials. This method intelligently removes\n208         and reapplies authentication where possible to avoid credential loss.\n209         \"\"\"\n210         headers = prepared_request.headers\n211         url = prepared_request.url\n212 \n213         if 'Authorization' in headers:\n214             # If we get redirected to a new host, we should strip out any\n215             #\u00a0authentication headers.\n216             original_parsed = urlparse(response.request.url)\n217             redirect_parsed = urlparse(url)\n218 \n219             if (original_parsed.hostname != redirect_parsed.hostname):\n220                 del headers['Authorization']\n221 \n222         # .netrc might have more auth for us on our new host.\n223         new_auth = get_netrc_auth(url) if self.trust_env else None\n224         if new_auth is not None:\n225             prepared_request.prepare_auth(new_auth)\n226 \n227         return\n228 \n229     def rebuild_proxies(self, prepared_request, proxies):\n230         \"\"\"\n231         This method re-evaluates the proxy configuration by considering the\n232         environment variables. If we are redirected to a URL covered by\n233         NO_PROXY, we strip the proxy configuration. Otherwise, we set missing\n234         proxy keys for this URL (in case they were stripped by a previous\n235         redirect).\n236 \n237         This method also replaces the Proxy-Authorization header where\n238         necessary.\n239         \"\"\"\n240         headers = prepared_request.headers\n241         url = prepared_request.url\n242         scheme = urlparse(url).scheme\n243         new_proxies = proxies.copy() if proxies is not None else {}\n244 \n245         if self.trust_env and not should_bypass_proxies(url):\n246             environ_proxies = get_environ_proxies(url)\n247 \n248             proxy = environ_proxies.get(scheme)\n249 \n250             if proxy:\n251                 new_proxies.setdefault(scheme, environ_proxies[scheme])\n252 \n253         if 'Proxy-Authorization' in headers:\n254             del headers['Proxy-Authorization']\n255 \n256         try:\n257             username, password = get_auth_from_url(new_proxies[scheme])\n258         except KeyError:\n259             username, password = None, None\n260 \n261         if username and password:\n262             headers['Proxy-Authorization'] = _basic_auth_str(username, password)\n263 \n264         return new_proxies\n265 \n266 \n267 class Session(SessionRedirectMixin):\n268     \"\"\"A Requests session.\n269 \n270     Provides cookie persistence, connection-pooling, and configuration.\n271 \n272     Basic Usage::\n273 \n274       >>> import requests\n275       >>> s = requests.Session()\n276       >>> s.get('http://httpbin.org/get')\n277       200\n278     \"\"\"\n279 \n280     __attrs__ = [\n281         'headers', 'cookies', 'auth', 'proxies', 'hooks', 'params', 'verify',\n282         'cert', 'prefetch', 'adapters', 'stream', 'trust_env',\n283         'max_redirects',\n284     ]\n285 \n286     def __init__(self):\n287 \n288         #: A case-insensitive dictionary of headers to be sent on each\n289         #: :class:`Request <Request>` sent from this\n290         #: :class:`Session <Session>`.\n291         self.headers = default_headers()\n292 \n293         #: Default Authentication tuple or object to attach to\n294         #: :class:`Request <Request>`.\n295         self.auth = None\n296 \n297         #: Dictionary mapping protocol to the URL of the proxy (e.g.\n298         #: {'http': 'foo.bar:3128'}) to be used on each\n299         #: :class:`Request <Request>`.\n300         self.proxies = {}\n301 \n302         #: Event-handling hooks.\n303         self.hooks = default_hooks()\n304 \n305         #: Dictionary of querystring data to attach to each\n306         #: :class:`Request <Request>`. The dictionary values may be lists for\n307         #: representing multivalued query parameters.\n308         self.params = {}\n309 \n310         #: Stream response content default.\n311         self.stream = False\n312 \n313         #: SSL Verification default.\n314         self.verify = True\n315 \n316         #: SSL certificate default.\n317         self.cert = None\n318 \n319         #: Maximum number of redirects allowed. If the request exceeds this\n320         #: limit, a :class:`TooManyRedirects` exception is raised.\n321         self.max_redirects = DEFAULT_REDIRECT_LIMIT\n322 \n323         #: Should we trust the environment?\n324         self.trust_env = True\n325 \n326         #: A CookieJar containing all currently outstanding cookies set on this\n327         #: session. By default it is a\n328         #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but\n329         #: may be any other ``cookielib.CookieJar`` compatible object.\n330         self.cookies = cookiejar_from_dict({})\n331 \n332         # Default connection adapters.\n333         self.adapters = OrderedDict()\n334         self.mount('https://', HTTPAdapter())\n335         self.mount('http://', HTTPAdapter())\n336 \n337         # Only store 1000 redirects to prevent using infinite memory\n338         self.redirect_cache = RecentlyUsedContainer(REDIRECT_CACHE_SIZE)\n339 \n340     def __enter__(self):\n341         return self\n342 \n343     def __exit__(self, *args):\n344         self.close()\n345 \n346     def prepare_request(self, request):\n347         \"\"\"Constructs a :class:`PreparedRequest <PreparedRequest>` for\n348         transmission and returns it. The :class:`PreparedRequest` has settings\n349         merged from the :class:`Request <Request>` instance and those of the\n350         :class:`Session`.\n351 \n352         :param request: :class:`Request` instance to prepare with this\n353             session's settings.\n354         \"\"\"\n355         cookies = request.cookies or {}\n356 \n357         # Bootstrap CookieJar.\n358         if not isinstance(cookies, cookielib.CookieJar):\n359             cookies = cookiejar_from_dict(cookies)\n360 \n361         # Merge with session cookies\n362         merged_cookies = merge_cookies(\n363             merge_cookies(RequestsCookieJar(), self.cookies), cookies)\n364 \n365 \n366         # Set environment's basic authentication if not explicitly set.\n367         auth = request.auth\n368         if self.trust_env and not auth and not self.auth:\n369             auth = get_netrc_auth(request.url)\n370 \n371         p = PreparedRequest()\n372         p.prepare(\n373             method=request.method.upper(),\n374             url=request.url,\n375             files=request.files,\n376             data=request.data,\n377             json=request.json,\n378             headers=merge_setting(request.headers, self.headers, dict_class=CaseInsensitiveDict),\n379             params=merge_setting(request.params, self.params),\n380             auth=merge_setting(auth, self.auth),\n381             cookies=merged_cookies,\n382             hooks=merge_hooks(request.hooks, self.hooks),\n383         )\n384         return p\n385 \n386     def request(self, method, url,\n387         params=None,\n388         data=None,\n389         headers=None,\n390         cookies=None,\n391         files=None,\n392         auth=None,\n393         timeout=None,\n394         allow_redirects=True,\n395         proxies=None,\n396         hooks=None,\n397         stream=None,\n398         verify=None,\n399         cert=None,\n400         json=None):\n401         \"\"\"Constructs a :class:`Request <Request>`, prepares it and sends it.\n402         Returns :class:`Response <Response>` object.\n403 \n404         :param method: method for the new :class:`Request` object.\n405         :param url: URL for the new :class:`Request` object.\n406         :param params: (optional) Dictionary or bytes to be sent in the query\n407             string for the :class:`Request`.\n408         :param data: (optional) Dictionary or bytes to send in the body of the\n409             :class:`Request`.\n410         :param json: (optional) json to send in the body of the\n411             :class:`Request`.\n412         :param headers: (optional) Dictionary of HTTP Headers to send with the\n413             :class:`Request`.\n414         :param cookies: (optional) Dict or CookieJar object to send with the\n415             :class:`Request`.\n416         :param files: (optional) Dictionary of ``'filename': file-like-objects``\n417             for multipart encoding upload.\n418         :param auth: (optional) Auth tuple or callable to enable\n419             Basic/Digest/Custom HTTP Auth.\n420         :param timeout: (optional) How long to wait for the server to send\n421             data before giving up, as a float, or a (`connect timeout, read\n422             timeout <user/advanced.html#timeouts>`_) tuple.\n423         :type timeout: float or tuple\n424         :param allow_redirects: (optional) Set to True by default.\n425         :type allow_redirects: bool\n426         :param proxies: (optional) Dictionary mapping protocol to the URL of\n427             the proxy.\n428         :param stream: (optional) whether to immediately download the response\n429             content. Defaults to ``False``.\n430         :param verify: (optional) if ``True``, the SSL cert will be verified.\n431             A CA_BUNDLE path can also be provided.\n432         :param cert: (optional) if String, path to ssl client cert file (.pem).\n433             If Tuple, ('cert', 'key') pair.\n434         \"\"\"\n435 \n436         method = to_native_string(method)\n437 \n438         # Create the Request.\n439         req = Request(\n440             method = method.upper(),\n441             url = url,\n442             headers = headers,\n443             files = files,\n444             data = data or {},\n445             json = json,\n446             params = params or {},\n447             auth = auth,\n448             cookies = cookies,\n449             hooks = hooks,\n450         )\n451         prep = self.prepare_request(req)\n452 \n453         proxies = proxies or {}\n454 \n455         settings = self.merge_environment_settings(\n456             prep.url, proxies, stream, verify, cert\n457         )\n458 \n459         # Send the request.\n460         send_kwargs = {\n461             'timeout': timeout,\n462             'allow_redirects': allow_redirects,\n463         }\n464         send_kwargs.update(settings)\n465         resp = self.send(prep, **send_kwargs)\n466 \n467         return resp\n468 \n469     def get(self, url, **kwargs):\n470         \"\"\"Sends a GET request. Returns :class:`Response` object.\n471 \n472         :param url: URL for the new :class:`Request` object.\n473         :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n474         \"\"\"\n475 \n476         kwargs.setdefault('allow_redirects', True)\n477         return self.request('GET', url, **kwargs)\n478 \n479     def options(self, url, **kwargs):\n480         \"\"\"Sends a OPTIONS request. Returns :class:`Response` object.\n481 \n482         :param url: URL for the new :class:`Request` object.\n483         :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n484         \"\"\"\n485 \n486         kwargs.setdefault('allow_redirects', True)\n487         return self.request('OPTIONS', url, **kwargs)\n488 \n489     def head(self, url, **kwargs):\n490         \"\"\"Sends a HEAD request. Returns :class:`Response` object.\n491 \n492         :param url: URL for the new :class:`Request` object.\n493         :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n494         \"\"\"\n495 \n496         kwargs.setdefault('allow_redirects', False)\n497         return self.request('HEAD', url, **kwargs)\n498 \n499     def post(self, url, data=None, json=None, **kwargs):\n500         \"\"\"Sends a POST request. Returns :class:`Response` object.\n501 \n502         :param url: URL for the new :class:`Request` object.\n503         :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.\n504         :param json: (optional) json to send in the body of the :class:`Request`.\n505         :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n506         \"\"\"\n507 \n508         return self.request('POST', url, data=data, json=json, **kwargs)\n509 \n510     def put(self, url, data=None, **kwargs):\n511         \"\"\"Sends a PUT request. Returns :class:`Response` object.\n512 \n513         :param url: URL for the new :class:`Request` object.\n514         :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.\n515         :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n516         \"\"\"\n517 \n518         return self.request('PUT', url, data=data, **kwargs)\n519 \n520     def patch(self, url, data=None, **kwargs):\n521         \"\"\"Sends a PATCH request. Returns :class:`Response` object.\n522 \n523         :param url: URL for the new :class:`Request` object.\n524         :param data: (optional) Dictionary, bytes, or file-like object to send in the body of the :class:`Request`.\n525         :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n526         \"\"\"\n527 \n528         return self.request('PATCH', url,  data=data, **kwargs)\n529 \n530     def delete(self, url, **kwargs):\n531         \"\"\"Sends a DELETE request. Returns :class:`Response` object.\n532 \n533         :param url: URL for the new :class:`Request` object.\n534         :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n535         \"\"\"\n536 \n537         return self.request('DELETE', url, **kwargs)\n538 \n539     def send(self, request, **kwargs):\n540         \"\"\"Send a given PreparedRequest.\"\"\"\n541         # Set defaults that the hooks can utilize to ensure they always have\n542         # the correct parameters to reproduce the previous request.\n543         kwargs.setdefault('stream', self.stream)\n544         kwargs.setdefault('verify', self.verify)\n545         kwargs.setdefault('cert', self.cert)\n546         kwargs.setdefault('proxies', self.proxies)\n547 \n548         # It's possible that users might accidentally send a Request object.\n549         # Guard against that specific failure case.\n550         if not isinstance(request, PreparedRequest):\n551             raise ValueError('You can only send PreparedRequests.')\n552 \n553         checked_urls = set()\n554         while request.url in self.redirect_cache:\n555             checked_urls.add(request.url)\n556             new_url = self.redirect_cache.get(request.url)\n557             if new_url in checked_urls:\n558                 break\n559             request.url = new_url\n560 \n561         # Set up variables needed for resolve_redirects and dispatching of hooks\n562         allow_redirects = kwargs.pop('allow_redirects', True)\n563         stream = kwargs.get('stream')\n564         hooks = request.hooks\n565 \n566         # Get the appropriate adapter to use\n567         adapter = self.get_adapter(url=request.url)\n568 \n569         # Start time (approximately) of the request\n570         start = datetime.utcnow()\n571 \n572         # Send the request\n573         r = adapter.send(request, **kwargs)\n574 \n575         # Total elapsed time of the request (approximately)\n576         r.elapsed = datetime.utcnow() - start\n577 \n578         # Response manipulation hooks\n579         r = dispatch_hook('response', hooks, r, **kwargs)\n580 \n581         # Persist cookies\n582         if r.history:\n583 \n584             # If the hooks create history then we want those cookies too\n585             for resp in r.history:\n586                 extract_cookies_to_jar(self.cookies, resp.request, resp.raw)\n587 \n588         extract_cookies_to_jar(self.cookies, request, r.raw)\n589 \n590         # Redirect resolving generator.\n591         gen = self.resolve_redirects(r, request, **kwargs)\n592 \n593         # Resolve redirects if allowed.\n594         history = [resp for resp in gen] if allow_redirects else []\n595 \n596         # Shuffle things around if there's history.\n597         if history:\n598             # Insert the first (original) request at the start\n599             history.insert(0, r)\n600             # Get the last request made\n601             r = history.pop()\n602             r.history = history\n603 \n604         if not stream:\n605             r.content\n606 \n607         return r\n608 \n609     def merge_environment_settings(self, url, proxies, stream, verify, cert):\n610         \"\"\"Check the environment and merge it with some settings.\"\"\"\n611         # Gather clues from the surrounding environment.\n612         if self.trust_env:\n613             # Set environment's proxies.\n614             env_proxies = get_environ_proxies(url) or {}\n615             for (k, v) in env_proxies.items():\n616                 proxies.setdefault(k, v)\n617 \n618             # Look for requests environment configuration and be compatible\n619             # with cURL.\n620             if verify is True or verify is None:\n621                 verify = (os.environ.get('REQUESTS_CA_BUNDLE') or\n622                           os.environ.get('CURL_CA_BUNDLE'))\n623 \n624         # Merge all the kwargs.\n625         proxies = merge_setting(proxies, self.proxies)\n626         stream = merge_setting(stream, self.stream)\n627         verify = merge_setting(verify, self.verify)\n628         cert = merge_setting(cert, self.cert)\n629 \n630         return {'verify': verify, 'proxies': proxies, 'stream': stream,\n631                 'cert': cert}\n632 \n633     def get_adapter(self, url):\n634         \"\"\"Returns the appropriate connnection adapter for the given URL.\"\"\"\n635         for (prefix, adapter) in self.adapters.items():\n636 \n637             if url.lower().startswith(prefix):\n638                 return adapter\n639 \n640         # Nothing matches :-/\n641         raise InvalidSchema(\"No connection adapters were found for '%s'\" % url)\n642 \n643     def close(self):\n644         \"\"\"Closes all adapters and as such the session\"\"\"\n645         for v in self.adapters.values():\n646             v.close()\n647 \n648     def mount(self, prefix, adapter):\n649         \"\"\"Registers a connection adapter to a prefix.\n650 \n651         Adapters are sorted in descending order by key length.\"\"\"\n652 \n653         self.adapters[prefix] = adapter\n654         keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]\n655 \n656         for key in keys_to_move:\n657             self.adapters[key] = self.adapters.pop(key)\n658 \n659     def __getstate__(self):\n660         state = dict((attr, getattr(self, attr, None)) for attr in self.__attrs__)\n661         state['redirect_cache'] = dict(self.redirect_cache)\n662         return state\n663 \n664     def __setstate__(self, state):\n665         redirect_cache = state.pop('redirect_cache', {})\n666         for attr, value in state.items():\n667             setattr(self, attr, value)\n668 \n669         self.redirect_cache = RecentlyUsedContainer(REDIRECT_CACHE_SIZE)\n670         for redirect, to in redirect_cache.items():\n671             self.redirect_cache[redirect] = to\n672 \n673 \n674 def session():\n675     \"\"\"Returns a :class:`Session` for context-management.\"\"\"\n676 \n677     return Session()\n",
        "intended_behavior": "Given that this file likely orchestrates higher-level session requests and might also handle exceptions thrown during such operations, ensuring that `DecodeError` and `TimeoutError` from `urllib3` are correctly caught and wrapped here as well is essential. If `adapters.py` is the primary location for direct `urllib3` interactions, then `sessions.py` would be a secondary layer that might still encounter these exceptions if they slip through the first layer of handling. The intended behavior would be similar to `adapters.py`: updating catch blocks to include `urllib3`'s `DecodeError` and `TimeoutError`, wrapping and re-raising them as `requests.exceptions`. This ensures that even if direct interactions with `urllib3` in `sessions.py` might throw these exceptions, they're still handled according to `requests`' design principles."
    }
]