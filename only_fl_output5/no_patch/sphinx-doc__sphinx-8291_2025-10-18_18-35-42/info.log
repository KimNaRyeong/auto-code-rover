2025-10-18 18:35:42.556 | INFO     | Starting overall retry 0 with model gpt-4-0125-preview
2025-10-18 18:35:45.739 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=501, output_tokens=12, cost=0.005370
2025-10-18 18:35:45.740 | INFO     | Test agent decides that the issue statement does not contain reproduction steps; skipping reproducer tracing
2025-10-18 18:35:45.744 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-18 18:35:53.300 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=809, output_tokens=361, cost=0.018920
2025-10-18 18:35:53.306 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-18 18:35:55.611 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=715, output_tokens=71, cost=0.009280
2025-10-18 18:35:55.613 | DEBUG    | Extracted a valid json.
2025-10-18 18:35:55.613 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_code_in_file(\"napoleon\", \"docs/conf.py\")",
        "search_code_in_file(\"autodoc\", \"docs/conf.py\")",
        "search_class_in_file(\"PheresBaseException\", \"src/pheres/exceptions.py\")"
    ],
    "bug_locations": []
}
2025-10-18 18:35:55.618 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-18 18:35:55.619 | DEBUG    | <Agent search> Analyzing search results.
2025-10-18 18:36:04.627 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=1375, output_tokens=441, cost=0.026980
2025-10-18 18:36:04.638 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-18 18:36:16.943 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=2032, output_tokens=567, cost=0.037330
2025-10-18 18:36:16.954 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-18 18:36:21.373 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=921, output_tokens=194, cost=0.015030
2025-10-18 18:36:21.375 | DEBUG    | Extracted a valid json.
2025-10-18 18:36:21.375 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [],
    "bug_locations": [
        {
            "file": "docs/conf.py",
            "class": "",
            "method": "",
            "intended_behavior": "Ensure Sphinx's conf.py is configured to automatically detect type hints in attributes when using napoleon and autodoc. This might involve adjusting settings like napoleon_use_ivar or introducing custom extensions or logic to merge attribute documentation with type hints from the source code to avoid duplicate entries."
        },
        {
            "file": "src/pheres/exceptions.py",
            "class": "",
            "method": "",
            "intended_behavior": "Classes should be annotated in a way that allows Sphinx to correctly parse and document attribute types from the source code without requiring redundant type specifications in the docstrings. This might involve implementing or adjusting docstring formats or adopting specific Sphinx extensions/tools that improve the integration of attrs, type hints, and Sphinx."
        }
    ]
}
2025-10-18 18:36:21.378 | DEBUG    | Failed to retrieve code from all bug locations. Asking search agent to re-generate response.
2025-10-18 18:36:21.379 | DEBUG    | <Agent search> Downstream could not consume our last response. Will retry.
2025-10-18 18:36:21.379 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-18 18:36:32.918 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=2633, output_tokens=516, cost=0.041810
2025-10-18 18:36:32.927 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-18 18:36:36.037 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=870, output_tokens=14, cost=0.009120
2025-10-18 18:36:36.038 | DEBUG    | Both API_calls and bug_locations are empty. Will retry.
2025-10-18 18:36:36.038 | DEBUG    | Trying to convert API calls/bug locations into json. Try 2 of 5.
2025-10-18 18:36:38.649 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=870, output_tokens=14, cost=0.009120
2025-10-18 18:36:38.650 | DEBUG    | Both API_calls and bug_locations are empty. Will retry.
2025-10-18 18:36:38.657 | DEBUG    | Trying to convert API calls/bug locations into json. Try 3 of 5.
2025-10-18 18:36:39.926 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=870, output_tokens=14, cost=0.009120
2025-10-18 18:36:39.927 | DEBUG    | Both API_calls and bug_locations are empty. Will retry.
2025-10-18 18:36:39.927 | DEBUG    | Trying to convert API calls/bug locations into json. Try 4 of 5.
2025-10-18 18:36:40.791 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=870, output_tokens=14, cost=0.009120
2025-10-18 18:36:40.792 | DEBUG    | Both API_calls and bug_locations are empty. Will retry.
2025-10-18 18:36:40.792 | DEBUG    | Trying to convert API calls/bug locations into json. Try 5 of 5.
2025-10-18 18:36:43.264 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=870, output_tokens=14, cost=0.009120
2025-10-18 18:36:43.265 | DEBUG    | Both API_calls and bug_locations are empty. Will retry.
2025-10-18 18:36:43.265 | DEBUG    | Agent proxy return the following json: None
2025-10-18 18:36:43.266 | DEBUG    | Could not extract API calls from agent search response, asking search agent to re-generate response.
2025-10-18 18:36:43.267 | DEBUG    | <Agent search> Downstream could not consume our last response. Will retry.
2025-10-18 18:36:43.267 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-18 18:36:55.439 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=3176, output_tokens=553, cost=0.048350
2025-10-18 18:36:55.449 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-18 18:36:56.290 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=907, output_tokens=14, cost=0.009490
2025-10-18 18:36:56.291 | DEBUG    | Both API_calls and bug_locations are empty. Will retry.
2025-10-18 18:36:56.291 | DEBUG    | Trying to convert API calls/bug locations into json. Try 2 of 5.
2025-10-18 18:36:57.256 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=907, output_tokens=14, cost=0.009490
2025-10-18 18:36:57.257 | DEBUG    | Both API_calls and bug_locations are empty. Will retry.
2025-10-18 18:36:57.257 | DEBUG    | Trying to convert API calls/bug locations into json. Try 3 of 5.
2025-10-18 18:36:58.057 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=907, output_tokens=14, cost=0.009490
2025-10-18 18:36:58.058 | DEBUG    | Both API_calls and bug_locations are empty. Will retry.
2025-10-18 18:36:58.058 | DEBUG    | Trying to convert API calls/bug locations into json. Try 4 of 5.
2025-10-18 18:37:00.025 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=907, output_tokens=14, cost=0.009490
2025-10-18 18:37:00.026 | DEBUG    | Both API_calls and bug_locations are empty. Will retry.
2025-10-18 18:37:00.026 | DEBUG    | Trying to convert API calls/bug locations into json. Try 5 of 5.
2025-10-18 18:37:00.871 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=907, output_tokens=14, cost=0.009490
2025-10-18 18:37:00.872 | DEBUG    | Both API_calls and bug_locations are empty. Will retry.
2025-10-18 18:37:00.872 | DEBUG    | Agent proxy return the following json: None
2025-10-18 18:37:00.872 | DEBUG    | Could not extract API calls from agent search response, asking search agent to re-generate response.
2025-10-18 18:37:00.873 | DEBUG    | <Agent search> Downstream could not consume our last response. Will retry.
2025-10-18 18:37:00.873 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-18 18:37:07.053 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=3756, output_tokens=271, cost=0.045690
2025-10-18 18:37:07.060 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-18 18:37:10.978 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=625, output_tokens=53, cost=0.007840
2025-10-18 18:37:10.980 | DEBUG    | Extracted a valid json.
2025-10-18 18:37:10.980 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_code(\"napoleon\")",
        "search_code(\"autodoc\")",
        "search_code(\"attr.s\")",
        "search_code(\"type hints\")"
    ],
    "bug_locations": []
}
2025-10-18 18:37:11.226 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-18 18:37:11.227 | DEBUG    | <Agent search> Analyzing search results.
2025-10-18 18:37:26.594 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=4881, output_tokens=691, cost=0.069540
2025-10-18 18:37:26.601 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-18 18:37:37.110 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=5788, output_tokens=471, cost=0.072010
2025-10-18 18:37:37.118 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-18 18:37:45.732 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=825, output_tokens=300, cost=0.017250
2025-10-18 18:37:45.733 | DEBUG    | Extracted a valid json.
2025-10-18 18:37:45.733 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [],
    "bug_locations": [
        {
            "file": "sphinx/ext/napoleon/docstring.py",
            "class": "",
            "method": "",
            "intended_behavior": "Modify or enhance the docstring parsing functionality to better integrate type hints from the source code into the attribute documentation generated from Google-style docstrings. This could involve checking for existing type hints and preventing the generation of duplicate attribute entries, one from the docstring and one from the type hint, thereby merging them into a single entry."
        },
        {
            "file": "sphinx/ext/autodoc/typehints.py",
            "class": "",
            "method": "",
            "intended_behavior": "Enhance the handling of type hints for attributes specifically, with logic to intelligently merge type information with attribute descriptions obtained from docstrings. This process should respect user configurations in `conf.py`, possibly adding new options that allow users to specify their preferred handling method (e.g., prefer docstring types, prefer type hints, merge both with docstring taking precedence, etc.)."
        },
        {
            "file": "doc/conf.py",
            "class": "",
            "method": "",
            "intended_behavior": "Introduce new configuration options that provide users with explicit control over how attribute documentation is generated in the presence of both docstrings and type hints. This can include settings to avoid duplication and control the merging behavior."
        }
    ]
}
2025-10-18 18:37:45.741 | DEBUG    | Bug location extracted successfully: [<file>sphinx/ext/napoleon/docstring.py</file>
<class>None</class>
<method>None</method>
<code>
1 """
2     sphinx.ext.napoleon.docstring
3     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
4 
5 
6     Classes for docstring parsing and formatting.
7 
8 
9     :copyright: Copyright 2007-2020 by the Sphinx team, see AUTHORS.
10     :license: BSD, see LICENSE for details.
11 """
12 
13 import collections
14 import inspect
15 import re
16 from functools import partial
17 from typing import Any, Callable, Dict, List, Tuple, Union
18 
19 from sphinx.application import Sphinx
20 from sphinx.config import Config as SphinxConfig
21 from sphinx.ext.napoleon.iterators import modify_iter
22 from sphinx.locale import _, __
23 from sphinx.util import logging
24 
25 if False:
26     # For type annotation
27     from typing import Type  # for python3.5.1
28 
29 
30 logger = logging.getLogger(__name__)
31 
32 _directive_regex = re.compile(r'\.\. \S+::')
33 _google_section_regex = re.compile(r'^(\s|\w)+:\s*$')
34 _google_typed_arg_regex = re.compile(r'(.+?)\(\s*(.*[^\s]+)\s*\)')
35 _numpy_section_regex = re.compile(r'^[=\-`:\'"~^_*+#<>]{2,}\s*$')
36 _single_colon_regex = re.compile(r'(?<!:):(?!:)')
37 _xref_or_code_regex = re.compile(
38     r'((?::(?:[a-zA-Z0-9]+[\-_+:.])*[a-zA-Z0-9]+:`.+?`)|'
39     r'(?:``.+?``))')
40 _xref_regex = re.compile(
41     r'(?:(?::(?:[a-zA-Z0-9]+[\-_+:.])*[a-zA-Z0-9]+:)?`.+?`)'
42 )
43 _bullet_list_regex = re.compile(r'^(\*|\+|\-)(\s+\S|\s*$)')
44 _enumerated_list_regex = re.compile(
45     r'^(?P<paren>\()?'
46     r'(\d+|#|[ivxlcdm]+|[IVXLCDM]+|[a-zA-Z])'
47     r'(?(paren)\)|\.)(\s+\S|\s*$)')
48 _token_regex = re.compile(
49     r"(,\sor\s|\sor\s|\sof\s|:\s|\sto\s|,\sand\s|\sand\s|,\s"
50     r"|[{]|[}]"
51     r'|"(?:\\"|[^"])*"'
52     r"|'(?:\\'|[^'])*')"
53 )
54 _default_regex = re.compile(
55     r"^default[^_0-9A-Za-z].*$",
56 )
57 _SINGLETONS = ("None", "True", "False", "Ellipsis")
58 
59 
60 class GoogleDocstring:
61     """Convert Google style docstrings to reStructuredText.
62 
63     Parameters
64     ----------
65     docstring : :obj:`str` or :obj:`list` of :obj:`str`
66         The docstring to parse, given either as a string or split into
67         individual lines.
68     config: :obj:`sphinx.ext.napoleon.Config` or :obj:`sphinx.config.Config`
69         The configuration settings to use. If not given, defaults to the
70         config object on `app`; or if `app` is not given defaults to the
71         a new :class:`sphinx.ext.napoleon.Config` object.
72 
73 
74     Other Parameters
75     ----------------
76     app : :class:`sphinx.application.Sphinx`, optional
77         Application object representing the Sphinx process.
78     what : :obj:`str`, optional
79         A string specifying the type of the object to which the docstring
80         belongs. Valid values: "module", "class", "exception", "function",
81         "method", "attribute".
82     name : :obj:`str`, optional
83         The fully qualified name of the object.
84     obj : module, class, exception, function, method, or attribute
85         The object to which the docstring belongs.
86     options : :class:`sphinx.ext.autodoc.Options`, optional
87         The options given to the directive: an object with attributes
88         inherited_members, undoc_members, show_inheritance and noindex that
89         are True if the flag option of same name was given to the auto
90         directive.
91 
92 
93     Example
94     -------
95     >>> from sphinx.ext.napoleon import Config
96     >>> config = Config(napoleon_use_param=True, napoleon_use_rtype=True)
97     >>> docstring = '''One line summary.
98     ...
99     ... Extended description.
100     ...
101     ... Args:
102     ...   arg1(int): Description of `arg1`
103     ...   arg2(str): Description of `arg2`
104     ... Returns:
105     ...   str: Description of return value.
106     ... '''
107     >>> print(GoogleDocstring(docstring, config))
108     One line summary.
109     <BLANKLINE>
110     Extended description.
111     <BLANKLINE>
112     :param arg1: Description of `arg1`
113     :type arg1: int
114     :param arg2: Description of `arg2`
115     :type arg2: str
116     <BLANKLINE>
117     :returns: Description of return value.
118     :rtype: str
119     <BLANKLINE>
120 
121     """
122 
123     _name_rgx = re.compile(r"^\s*((?::(?P<role>\S+):)?`(?P<name>~?[a-zA-Z0-9_.-]+)`|"
124                            r" (?P<name2>~?[a-zA-Z0-9_.-]+))\s*", re.X)
125 
126     def __init__(self, docstring: Union[str, List[str]], config: SphinxConfig = None,
127                  app: Sphinx = None, what: str = '', name: str = '',
128                  obj: Any = None, options: Any = None) -> None:
129         self._config = config
130         self._app = app
131 
132         if not self._config:
133             from sphinx.ext.napoleon import Config
134             self._config = self._app.config if self._app else Config()  # type: ignore
135 
136         if not what:
137             if inspect.isclass(obj):
138                 what = 'class'
139             elif inspect.ismodule(obj):
140                 what = 'module'
141             elif callable(obj):
142                 what = 'function'
143             else:
144                 what = 'object'
145 
146         self._what = what
147         self._name = name
148         self._obj = obj
149         self._opt = options
150         if isinstance(docstring, str):
151             lines = docstring.splitlines()
152         else:
153             lines = docstring
154         self._line_iter = modify_iter(lines, modifier=lambda s: s.rstrip())
155         self._parsed_lines = []  # type: List[str]
156         self._is_in_section = False
157         self._section_indent = 0
158         if not hasattr(self, '_directive_sections'):
159             self._directive_sections = []  # type: List[str]
160         if not hasattr(self, '_sections'):
161             self._sections = {
162                 'args': self._parse_parameters_section,
163                 'arguments': self._parse_parameters_section,
164                 'attention': partial(self._parse_admonition, 'attention'),
165                 'attributes': self._parse_attributes_section,
166                 'caution': partial(self._parse_admonition, 'caution'),
167                 'danger': partial(self._parse_admonition, 'danger'),
168                 'error': partial(self._parse_admonition, 'error'),
169                 'example': self._parse_examples_section,
170                 'examples': self._parse_examples_section,
171                 'hint': partial(self._parse_admonition, 'hint'),
172                 'important': partial(self._parse_admonition, 'important'),
173                 'keyword args': self._parse_keyword_arguments_section,
174                 'keyword arguments': self._parse_keyword_arguments_section,
175                 'methods': self._parse_methods_section,
176                 'note': partial(self._parse_admonition, 'note'),
177                 'notes': self._parse_notes_section,
178                 'other parameters': self._parse_other_parameters_section,
179                 'parameters': self._parse_parameters_section,
180                 'return': self._parse_returns_section,
181                 'returns': self._parse_returns_section,
182                 'raise': self._parse_raises_section,
183                 'raises': self._parse_raises_section,
184                 'references': self._parse_references_section,
185                 'see also': self._parse_see_also_section,
186                 'tip': partial(self._parse_admonition, 'tip'),
187                 'todo': partial(self._parse_admonition, 'todo'),
188                 'warning': partial(self._parse_admonition, 'warning'),
189                 'warnings': partial(self._parse_admonition, 'warning'),
190                 'warn': self._parse_warns_section,
191                 'warns': self._parse_warns_section,
192                 'yield': self._parse_yields_section,
193                 'yields': self._parse_yields_section,
194             }  # type: Dict[str, Callable]
195 
196         self._load_custom_sections()
197 
198         self._parse()
199 
200     def __str__(self) -> str:
201         """Return the parsed docstring in reStructuredText format.
202 
203         Returns
204         -------
205         unicode
206             Unicode version of the docstring.
207 
208         """
209         return '\n'.join(self.lines())
210 
211     def lines(self) -> List[str]:
212         """Return the parsed lines of the docstring in reStructuredText format.
213 
214         Returns
215         -------
216         list(str)
217             The lines of the docstring in a list.
218 
219         """
220         return self._parsed_lines
221 
222     def _consume_indented_block(self, indent: int = 1) -> List[str]:
223         lines = []
224         line = self._line_iter.peek()
225         while(not self._is_section_break() and
226               (not line or self._is_indented(line, indent))):
227             lines.append(next(self._line_iter))
228             line = self._line_iter.peek()
229         return lines
230 
231     def _consume_contiguous(self) -> List[str]:
232         lines = []
233         while (self._line_iter.has_next() and
234                self._line_iter.peek() and
235                not self._is_section_header()):
236             lines.append(next(self._line_iter))
237         return lines
238 
239     def _consume_empty(self) -> List[str]:
240         lines = []
241         line = self._line_iter.peek()
242         while self._line_iter.has_next() and not line:
243             lines.append(next(self._line_iter))
244             line = self._line_iter.peek()
245         return lines
246 
247     def _consume_field(self, parse_type: bool = True, prefer_type: bool = False
248                        ) -> Tuple[str, str, List[str]]:
249         line = next(self._line_iter)
250 
251         before, colon, after = self._partition_field_on_colon(line)
252         _name, _type, _desc = before, '', after
253 
254         if parse_type:
255             match = _google_typed_arg_regex.match(before)
256             if match:
257                 _name = match.group(1).strip()
258                 _type = match.group(2)
259 
260         _name = self._escape_args_and_kwargs(_name)
261 
262         if prefer_type and not _type:
263             _type, _name = _name, _type
264         indent = self._get_indent(line) + 1
265         _descs = [_desc] + self._dedent(self._consume_indented_block(indent))
266         _descs = self.__class__(_descs, self._config).lines()
267         return _name, _type, _descs
268 
269     def _consume_fields(self, parse_type: bool = True, prefer_type: bool = False,
270                         multiple: bool = False) -> List[Tuple[str, str, List[str]]]:
271         self._consume_empty()
272         fields = []
273         while not self._is_section_break():
274             _name, _type, _desc = self._consume_field(parse_type, prefer_type)
275             if multiple and _name:
276                 for name in _name.split(","):
277                     fields.append((name.strip(), _type, _desc))
278             elif _name or _type or _desc:
279                 fields.append((_name, _type, _desc,))
280         return fields
281 
282     def _consume_inline_attribute(self) -> Tuple[str, List[str]]:
283         line = next(self._line_iter)
284         _type, colon, _desc = self._partition_field_on_colon(line)
285         if not colon or not _desc:
286             _type, _desc = _desc, _type
287             _desc += colon
288         _descs = [_desc] + self._dedent(self._consume_to_end())
289         _descs = self.__class__(_descs, self._config).lines()
290         return _type, _descs
291 
292     def _consume_returns_section(self) -> List[Tuple[str, str, List[str]]]:
293         lines = self._dedent(self._consume_to_next_section())
294         if lines:
295             before, colon, after = self._partition_field_on_colon(lines[0])
296             _name, _type, _desc = '', '', lines
297 
298             if colon:
299                 if after:
300                     _desc = [after] + lines[1:]
301                 else:
302                     _desc = lines[1:]
303 
304                 _type = before
305 
306             _desc = self.__class__(_desc, self._config).lines()
307             return [(_name, _type, _desc,)]
308         else:
309             return []
310 
311     def _consume_usage_section(self) -> List[str]:
312         lines = self._dedent(self._consume_to_next_section())
313         return lines
314 
315     def _consume_section_header(self) -> str:
316         section = next(self._line_iter)
317         stripped_section = section.strip(':')
318         if stripped_section.lower() in self._sections:
319             section = stripped_section
320         return section
321 
322     def _consume_to_end(self) -> List[str]:
323         lines = []
324         while self._line_iter.has_next():
325             lines.append(next(self._line_iter))
326         return lines
327 
328     def _consume_to_next_section(self) -> List[str]:
329         self._consume_empty()
330         lines = []
331         while not self._is_section_break():
332             lines.append(next(self._line_iter))
333         return lines + self._consume_empty()
334 
335     def _dedent(self, lines: List[str], full: bool = False) -> List[str]:
336         if full:
337             return [line.lstrip() for line in lines]
338         else:
339             min_indent = self._get_min_indent(lines)
340             return [line[min_indent:] for line in lines]
341 
342     def _escape_args_and_kwargs(self, name: str) -> str:
343         if name.endswith('_') and getattr(self._config, 'strip_signature_backslash', False):
344             name = name[:-1] + r'\_'
345 
346         if name[:2] == '**':
347             return r'\*\*' + name[2:]
348         elif name[:1] == '*':
349             return r'\*' + name[1:]
350         else:
351             return name
352 
353     def _fix_field_desc(self, desc: List[str]) -> List[str]:
354         if self._is_list(desc):
355             desc = [''] + desc
356         elif desc[0].endswith('::'):
357             desc_block = desc[1:]
358             indent = self._get_indent(desc[0])
359             block_indent = self._get_initial_indent(desc_block)
360             if block_indent > indent:
361                 desc = [''] + desc
362             else:
363                 desc = ['', desc[0]] + self._indent(desc_block, 4)
364         return desc
365 
366     def _format_admonition(self, admonition: str, lines: List[str]) -> List[str]:
367         lines = self._strip_empty(lines)
368         if len(lines) == 1:
369             return ['.. %s:: %s' % (admonition, lines[0].strip()), '']
370         elif lines:
371             lines = self._indent(self._dedent(lines), 3)
372             return ['.. %s::' % admonition, ''] + lines + ['']
373         else:
374             return ['.. %s::' % admonition, '']
375 
376     def _format_block(self, prefix: str, lines: List[str], padding: str = None) -> List[str]:
377         if lines:
378             if padding is None:
379                 padding = ' ' * len(prefix)
380             result_lines = []
381             for i, line in enumerate(lines):
382                 if i == 0:
383                     result_lines.append((prefix + line).rstrip())
384                 elif line:
385                     result_lines.append(padding + line)
386                 else:
387                     result_lines.append('')
388             return result_lines
389         else:
390             return [prefix]
391 
392     def _format_docutils_params(self, fields: List[Tuple[str, str, List[str]]],
393                                 field_role: str = 'param', type_role: str = 'type'
394                                 ) -> List[str]:
395         lines = []
396         for _name, _type, _desc in fields:
397             _desc = self._strip_empty(_desc)
398             if any(_desc):
399                 _desc = self._fix_field_desc(_desc)
400                 field = ':%s %s: ' % (field_role, _name)
401                 lines.extend(self._format_block(field, _desc))
402             else:
403                 lines.append(':%s %s:' % (field_role, _name))
404 
405             if _type:
406                 lines.append(':%s %s: %s' % (type_role, _name, _type))
407         return lines + ['']
408 
409     def _format_field(self, _name: str, _type: str, _desc: List[str]) -> List[str]:
410         _desc = self._strip_empty(_desc)
411         has_desc = any(_desc)
412         separator = ' -- ' if has_desc else ''
413         if _name:
414             if _type:
415                 if '`' in _type:
416                     field = '**%s** (%s)%s' % (_name, _type, separator)
417                 else:
418                     field = '**%s** (*%s*)%s' % (_name, _type, separator)
419             else:
420                 field = '**%s**%s' % (_name, separator)
421         elif _type:
422             if '`' in _type:
423                 field = '%s%s' % (_type, separator)
424             else:
425                 field = '*%s*%s' % (_type, separator)
426         else:
427             field = ''
428 
429         if has_desc:
430             _desc = self._fix_field_desc(_desc)
431             if _desc[0]:
432                 return [field + _desc[0]] + _desc[1:]
433             else:
434                 return [field] + _desc
435         else:
436             return [field]
437 
438     def _format_fields(self, field_type: str, fields: List[Tuple[str, str, List[str]]]
439                        ) -> List[str]:
440         field_type = ':%s:' % field_type.strip()
441         padding = ' ' * len(field_type)
442         multi = len(fields) > 1
443         lines = []  # type: List[str]
444         for _name, _type, _desc in fields:
445             field = self._format_field(_name, _type, _desc)
446             if multi:
447                 if lines:
448                     lines.extend(self._format_block(padding + ' * ', field))
449                 else:
450                     lines.extend(self._format_block(field_type + ' * ', field))
451             else:
452                 lines.extend(self._format_block(field_type + ' ', field))
453         if lines and lines[-1]:
454             lines.append('')
455         return lines
456 
457     def _get_current_indent(self, peek_ahead: int = 0) -> int:
458         line = self._line_iter.peek(peek_ahead + 1)[peek_ahead]
459         while line != self._line_iter.sentinel:
460             if line:
461                 return self._get_indent(line)
462             peek_ahead += 1
463             line = self._line_iter.peek(peek_ahead + 1)[peek_ahead]
464         return 0
465 
466     def _get_indent(self, line: str) -> int:
467         for i, s in enumerate(line):
468             if not s.isspace():
469                 return i
470         return len(line)
471 
472     def _get_initial_indent(self, lines: List[str]) -> int:
473         for line in lines:
474             if line:
475                 return self._get_indent(line)
476         return 0
477 
478     def _get_min_indent(self, lines: List[str]) -> int:
479         min_indent = None
480         for line in lines:
481             if line:
482                 indent = self._get_indent(line)
483                 if min_indent is None:
484                     min_indent = indent
485                 elif indent < min_indent:
486                     min_indent = indent
487         return min_indent or 0
488 
489     def _indent(self, lines: List[str], n: int = 4) -> List[str]:
490         return [(' ' * n) + line for line in lines]
491 
492     def _is_indented(self, line: str, indent: int = 1) -> bool:
493         for i, s in enumerate(line):
494             if i >= indent:
495                 return True
496             elif not s.isspace():
497                 return False
498         return False
499 
500     def _is_list(self, lines: List[str]) -> bool:
501         if not lines:
502             return False
503         if _bullet_list_regex.match(lines[0]):
504             return True
505         if _enumerated_list_regex.match(lines[0]):
506             return True
507         if len(lines) < 2 or lines[0].endswith('::'):
508             return False
509         indent = self._get_indent(lines[0])
510         next_indent = indent
511         for line in lines[1:]:
512             if line:
513                 next_indent = self._get_indent(line)
514                 break
515         return next_indent > indent
516 
517     def _is_section_header(self) -> bool:
518         section = self._line_iter.peek().lower()
519         match = _google_section_regex.match(section)
520         if match and section.strip(':') in self._sections:
521             header_indent = self._get_indent(section)
522             section_indent = self._get_current_indent(peek_ahead=1)
523             return section_indent > header_indent
524         elif self._directive_sections:
525             if _directive_regex.match(section):
526                 for directive_section in self._directive_sections:
527                     if section.startswith(directive_section):
528                         return True
529         return False
530 
531     def _is_section_break(self) -> bool:
532         line = self._line_iter.peek()
533         return (not self._line_iter.has_next() or
534                 self._is_section_header() or
535                 (self._is_in_section and
536                     line and
537                     not self._is_indented(line, self._section_indent)))
538 
539     def _load_custom_sections(self) -> None:
540         if self._config.napoleon_custom_sections is not None:
541             for entry in self._config.napoleon_custom_sections:
542                 if isinstance(entry, str):
543                     # if entry is just a label, add to sections list,
544                     # using generic section logic.
545                     self._sections[entry.lower()] = self._parse_custom_generic_section
546                 else:
547                     # otherwise, assume entry is container;
548                     # [0] is new section, [1] is the section to alias.
549                     # in the case of key mismatch, just handle as generic section.
550                     self._sections[entry[0].lower()] = \
551                         self._sections.get(entry[1].lower(),
552                                            self._parse_custom_generic_section)
553 
554     def _parse(self) -> None:
555         self._parsed_lines = self._consume_empty()
556 
557         if self._name and self._what in ('attribute', 'data', 'property'):
558             # Implicit stop using StopIteration no longer allowed in
559             # Python 3.7; see PEP 479
560             res = []  # type: List[str]
561             try:
562                 res = self._parse_attribute_docstring()
563             except StopIteration:
564                 pass
565             self._parsed_lines.extend(res)
566             return
567 
568         while self._line_iter.has_next():
569             if self._is_section_header():
570                 try:
571                     section = self._consume_section_header()
572                     self._is_in_section = True
573                     self._section_indent = self._get_current_indent()
574                     if _directive_regex.match(section):
575                         lines = [section] + self._consume_to_next_section()
576                     else:
577                         lines = self._sections[section.lower()](section)
578                 finally:
579                     self._is_in_section = False
580                     self._section_indent = 0
581             else:
582                 if not self._parsed_lines:
583                     lines = self._consume_contiguous() + self._consume_empty()
584                 else:
585                     lines = self._consume_to_next_section()
586             self._parsed_lines.extend(lines)
587 
588     def _parse_admonition(self, admonition: str, section: str) -> List[str]:
589         # type (str, str) -> List[str]
590         lines = self._consume_to_next_section()
591         return self._format_admonition(admonition, lines)
592 
593     def _parse_attribute_docstring(self) -> List[str]:
594         _type, _desc = self._consume_inline_attribute()
595         lines = self._format_field('', '', _desc)
596         if _type:
597             lines.extend(['', ':type: %s' % _type])
598         return lines
599 
600     def _parse_attributes_section(self, section: str) -> List[str]:
601         lines = []
602         for _name, _type, _desc in self._consume_fields():
603             if self._config.napoleon_use_ivar:
604                 _name = self._qualify_name(_name, self._obj)
605                 field = ':ivar %s: ' % _name
606                 lines.extend(self._format_block(field, _desc))
607                 if _type:
608                     lines.append(':vartype %s: %s' % (_name, _type))
609             else:
610                 lines.append('.. attribute:: ' + _name)
611                 if self._opt and 'noindex' in self._opt:
612                     lines.append('   :noindex:')
613                 lines.append('')
614 
615                 fields = self._format_field('', '', _desc)
616                 lines.extend(self._indent(fields, 3))
617                 if _type:
618                     lines.append('')
619                     lines.extend(self._indent([':type: %s' % _type], 3))
620                 lines.append('')
621         if self._config.napoleon_use_ivar:
622             lines.append('')
623         return lines
624 
625     def _parse_examples_section(self, section: str) -> List[str]:
626         labels = {
627             'example': _('Example'),
628             'examples': _('Examples'),
629         }
630         use_admonition = self._config.napoleon_use_admonition_for_examples
631         label = labels.get(section.lower(), section)
632         return self._parse_generic_section(label, use_admonition)
633 
634     def _parse_custom_generic_section(self, section: str) -> List[str]:
635         # for now, no admonition for simple custom sections
636         return self._parse_generic_section(section, False)
637 
638     def _parse_usage_section(self, section: str) -> List[str]:
639         header = ['.. rubric:: Usage:', '']
640         block = ['.. code-block:: python', '']
641         lines = self._consume_usage_section()
642         lines = self._indent(lines, 3)
643         return header + block + lines + ['']
644 
645     def _parse_generic_section(self, section: str, use_admonition: bool) -> List[str]:
646         lines = self._strip_empty(self._consume_to_next_section())
647         lines = self._dedent(lines)
648         if use_admonition:
649             header = '.. admonition:: %s' % section
650             lines = self._indent(lines, 3)
651         else:
652             header = '.. rubric:: %s' % section
653         if lines:
654             return [header, ''] + lines + ['']
655         else:
656             return [header, '']
657 
658     def _parse_keyword_arguments_section(self, section: str) -> List[str]:
659         fields = self._consume_fields()
660         if self._config.napoleon_use_keyword:
661             return self._format_docutils_params(
662                 fields,
663                 field_role="keyword",
664                 type_role="kwtype")
665         else:
666             return self._format_fields(_('Keyword Arguments'), fields)
667 
668     def _parse_methods_section(self, section: str) -> List[str]:
669         lines = []  # type: List[str]
670         for _name, _type, _desc in self._consume_fields(parse_type=False):
671             lines.append('.. method:: %s' % _name)
672             if self._opt and 'noindex' in self._opt:
673                 lines.append('   :noindex:')
674             if _desc:
675                 lines.extend([''] + self._indent(_desc, 3))
676             lines.append('')
677         return lines
678 
679     def _parse_notes_section(self, section: str) -> List[str]:
680         use_admonition = self._config.napoleon_use_admonition_for_notes
681         return self._parse_generic_section(_('Notes'), use_admonition)
682 
683     def _parse_other_parameters_section(self, section: str) -> List[str]:
684         return self._format_fields(_('Other Parameters'), self._consume_fields())
685 
686     def _parse_parameters_section(self, section: str) -> List[str]:
687         if self._config.napoleon_use_param:
688             # Allow to declare multiple parameters at once (ex: x, y: int)
689             fields = self._consume_fields(multiple=True)
690             return self._format_docutils_params(fields)
691         else:
692             fields = self._consume_fields()
693             return self._format_fields(_('Parameters'), fields)
694 
695     def _parse_raises_section(self, section: str) -> List[str]:
696         fields = self._consume_fields(parse_type=False, prefer_type=True)
697         lines = []  # type: List[str]
698         for _name, _type, _desc in fields:
699             m = self._name_rgx.match(_type)
700             if m and m.group('name'):
701                 _type = m.group('name')
702             elif _xref_regex.match(_type):
703                 pos = _type.find('`')
704                 _type = _type[pos + 1:-1]
705             _type = ' ' + _type if _type else ''
706             _desc = self._strip_empty(_desc)
707             _descs = ' ' + '\n    '.join(_desc) if any(_desc) else ''
708             lines.append(':raises%s:%s' % (_type, _descs))
709         if lines:
710             lines.append('')
711         return lines
712 
713     def _parse_references_section(self, section: str) -> List[str]:
714         use_admonition = self._config.napoleon_use_admonition_for_references
715         return self._parse_generic_section(_('References'), use_admonition)
716 
717     def _parse_returns_section(self, section: str) -> List[str]:
718         fields = self._consume_returns_section()
719         multi = len(fields) > 1
720         if multi:
721             use_rtype = False
722         else:
723             use_rtype = self._config.napoleon_use_rtype
724 
725         lines = []  # type: List[str]
726         for _name, _type, _desc in fields:
727             if use_rtype:
728                 field = self._format_field(_name, '', _desc)
729             else:
730                 field = self._format_field(_name, _type, _desc)
731 
732             if multi:
733                 if lines:
734                     lines.extend(self._format_block('          * ', field))
735                 else:
736                     lines.extend(self._format_block(':returns: * ', field))
737             else:
738                 lines.extend(self._format_block(':returns: ', field))
739                 if _type and use_rtype:
740                     lines.extend([':rtype: %s' % _type, ''])
741         if lines and lines[-1]:
742             lines.append('')
743         return lines
744 
745     def _parse_see_also_section(self, section: str) -> List[str]:
746         return self._parse_admonition('seealso', section)
747 
748     def _parse_warns_section(self, section: str) -> List[str]:
749         return self._format_fields(_('Warns'), self._consume_fields())
750 
751     def _parse_yields_section(self, section: str) -> List[str]:
752         fields = self._consume_returns_section()
753         return self._format_fields(_('Yields'), fields)
754 
755     def _partition_field_on_colon(self, line: str) -> Tuple[str, str, str]:
756         before_colon = []
757         after_colon = []
758         colon = ''
759         found_colon = False
760         for i, source in enumerate(_xref_or_code_regex.split(line)):
761             if found_colon:
762                 after_colon.append(source)
763             else:
764                 m = _single_colon_regex.search(source)
765                 if (i % 2) == 0 and m:
766                     found_colon = True
767                     colon = source[m.start(): m.end()]
768                     before_colon.append(source[:m.start()])
769                     after_colon.append(source[m.end():])
770                 else:
771                     before_colon.append(source)
772 
773         return ("".join(before_colon).strip(),
774                 colon,
775                 "".join(after_colon).strip())
776 
777     def _qualify_name(self, attr_name: str, klass: "Type") -> str:
778         if klass and '.' not in attr_name:
779             if attr_name.startswith('~'):
780                 attr_name = attr_name[1:]
781             try:
782                 q = klass.__qualname__
783             except AttributeError:
784                 q = klass.__name__
785             return '~%s.%s' % (q, attr_name)
786         return attr_name
787 
788     def _strip_empty(self, lines: List[str]) -> List[str]:
789         if lines:
790             start = -1
791             for i, line in enumerate(lines):
792                 if line:
793                     start = i
794                     break
795             if start == -1:
796                 lines = []
797             end = -1
798             for i in reversed(range(len(lines))):
799                 line = lines[i]
800                 if line:
801                     end = i
802                     break
803             if start > 0 or end + 1 < len(lines):
804                 lines = lines[start:end + 1]
805         return lines
806 
807 
808 def _recombine_set_tokens(tokens: List[str]) -> List[str]:
809     token_queue = collections.deque(tokens)
810     keywords = ("optional", "default")
811 
812     def takewhile_set(tokens):
813         open_braces = 0
814         previous_token = None
815         while True:
816             try:
817                 token = tokens.popleft()
818             except IndexError:
819                 break
820 
821             if token == ", ":
822                 previous_token = token
823                 continue
824 
825             if not token.strip():
826                 continue
827 
828             if token in keywords:
829                 tokens.appendleft(token)
830                 if previous_token is not None:
831                     tokens.appendleft(previous_token)
832                 break
833 
834             if previous_token is not None:
835                 yield previous_token
836                 previous_token = None
837 
838             if token == "{":
839                 open_braces += 1
840             elif token == "}":
841                 open_braces -= 1
842 
843             yield token
844 
845             if open_braces == 0:
846                 break
847 
848     def combine_set(tokens):
849         while True:
850             try:
851                 token = tokens.popleft()
852             except IndexError:
853                 break
854 
855             if token == "{":
856                 tokens.appendleft("{")
857                 yield "".join(takewhile_set(tokens))
858             else:
859                 yield token
860 
861     return list(combine_set(token_queue))
862 
863 
864 def _tokenize_type_spec(spec: str) -> List[str]:
865     def postprocess(item):
866         if _default_regex.match(item):
867             default = item[:7]
868             # can't be separated by anything other than a single space
869             # for now
870             other = item[8:]
871 
872             return [default, " ", other]
873         else:
874             return [item]
875 
876     tokens = list(
877         item
878         for raw_token in _token_regex.split(spec)
879         for item in postprocess(raw_token)
880         if item
881     )
882     return tokens
883 
884 
885 def _token_type(token: str, location: str = None) -> str:
886     def is_numeric(token):
887         try:
888             # use complex to make sure every numeric value is detected as literal
889             complex(token)
890         except ValueError:
891             return False
892         else:
893             return True
894 
895     if token.startswith(" ") or token.endswith(" "):
896         type_ = "delimiter"
897     elif (
898             is_numeric(token) or
899             (token.startswith("{") and token.endswith("}")) or
900             (token.startswith('"') and token.endswith('"')) or
901             (token.startswith("'") and token.endswith("'"))
902     ):
903         type_ = "literal"
904     elif token.startswith("{"):
905         logger.warning(
906             __("invalid value set (missing closing brace): %s"),
907             token,
908             location=location,
909         )
910         type_ = "literal"
911     elif token.endswith("}"):
912         logger.warning(
913             __("invalid value set (missing opening brace): %s"),
914             token,
915             location=location,
916         )
917         type_ = "literal"
918     elif token.startswith("'") or token.startswith('"'):
919         logger.warning(
920             __("malformed string literal (missing closing quote): %s"),
921             token,
922             location=location,
923         )
924         type_ = "literal"
925     elif token.endswith("'") or token.endswith('"'):
926         logger.warning(
927             __("malformed string literal (missing opening quote): %s"),
928             token,
929             location=location,
930         )
931         type_ = "literal"
932     elif token in ("optional", "default"):
933         # default is not a official keyword (yet) but supported by the
934         # reference implementation (numpydoc) and widely used
935         type_ = "control"
936     elif _xref_regex.match(token):
937         type_ = "reference"
938     else:
939         type_ = "obj"
940 
941     return type_
942 
943 
944 def _convert_numpy_type_spec(_type: str, location: str = None, translations: dict = {}) -> str:
945     def convert_obj(obj, translations, default_translation):
946         translation = translations.get(obj, obj)
947 
948         # use :class: (the default) only if obj is not a standard singleton
949         if translation in _SINGLETONS and default_translation == ":class:`%s`":
950             default_translation = ":obj:`%s`"
951         elif translation == "..." and default_translation == ":class:`%s`":
952             # allow referencing the builtin ...
953             default_translation = ":obj:`%s <Ellipsis>`"
954 
955         if _xref_regex.match(translation) is None:
956             translation = default_translation % translation
957 
958         return translation
959 
960     tokens = _tokenize_type_spec(_type)
961     combined_tokens = _recombine_set_tokens(tokens)
962     types = [
963         (token, _token_type(token, location))
964         for token in combined_tokens
965     ]
966 
967     converters = {
968         "literal": lambda x: "``%s``" % x,
969         "obj": lambda x: convert_obj(x, translations, ":class:`%s`"),
970         "control": lambda x: "*%s*" % x,
971         "delimiter": lambda x: x,
972         "reference": lambda x: x,
973     }
974 
975     converted = "".join(converters.get(type_)(token) for token, type_ in types)
976 
977     return converted
978 
979 
980 class NumpyDocstring(GoogleDocstring):
981     """Convert NumPy style docstrings to reStructuredText.
982 
983     Parameters
984     ----------
985     docstring : :obj:`str` or :obj:`list` of :obj:`str`
986         The docstring to parse, given either as a string or split into
987         individual lines.
988     config: :obj:`sphinx.ext.napoleon.Config` or :obj:`sphinx.config.Config`
989         The configuration settings to use. If not given, defaults to the
990         config object on `app`; or if `app` is not given defaults to the
991         a new :class:`sphinx.ext.napoleon.Config` object.
992 
993 
994     Other Parameters
995     ----------------
996     app : :class:`sphinx.application.Sphinx`, optional
997         Application object representing the Sphinx process.
998     what : :obj:`str`, optional
999         A string specifying the type of the object to which the docstring
1000         belongs. Valid values: "module", "class", "exception", "function",
1001         "method", "attribute".
1002     name : :obj:`str`, optional
1003         The fully qualified name of the object.
1004     obj : module, class, exception, function, method, or attribute
1005         The object to which the docstring belongs.
1006     options : :class:`sphinx.ext.autodoc.Options`, optional
1007         The options given to the directive: an object with attributes
1008         inherited_members, undoc_members, show_inheritance and noindex that
1009         are True if the flag option of same name was given to the auto
1010         directive.
1011 
1012 
1013     Example
1014     -------
1015     >>> from sphinx.ext.napoleon import Config
1016     >>> config = Config(napoleon_use_param=True, napoleon_use_rtype=True)
1017     >>> docstring = '''One line summary.
1018     ...
1019     ... Extended description.
1020     ...
1021     ... Parameters
1022     ... ----------
1023     ... arg1 : int
1024     ...     Description of `arg1`
1025     ... arg2 : str
1026     ...     Description of `arg2`
1027     ... Returns
1028     ... -------
1029     ... str
1030     ...     Description of return value.
1031     ... '''
1032     >>> print(NumpyDocstring(docstring, config))
1033     One line summary.
1034     <BLANKLINE>
1035     Extended description.
1036     <BLANKLINE>
1037     :param arg1: Description of `arg1`
1038     :type arg1: int
1039     :param arg2: Description of `arg2`
1040     :type arg2: str
1041     <BLANKLINE>
1042     :returns: Description of return value.
1043     :rtype: str
1044     <BLANKLINE>
1045 
1046     Methods
1047     -------
1048     __str__()
1049         Return the parsed docstring in reStructuredText format.
1050 
1051         Returns
1052         -------
1053         str
1054             UTF-8 encoded version of the docstring.
1055 
1056     __unicode__()
1057         Return the parsed docstring in reStructuredText format.
1058 
1059         Returns
1060         -------
1061         unicode
1062             Unicode version of the docstring.
1063 
1064     lines()
1065         Return the parsed lines of the docstring in reStructuredText format.
1066 
1067         Returns
1068         -------
1069         list(str)
1070             The lines of the docstring in a list.
1071 
1072     """
1073     def __init__(self, docstring: Union[str, List[str]], config: SphinxConfig = None,
1074                  app: Sphinx = None, what: str = '', name: str = '',
1075                  obj: Any = None, options: Any = None) -> None:
1076         self._directive_sections = ['.. index::']
1077         super().__init__(docstring, config, app, what, name, obj, options)
1078 
1079     def _get_location(self) -> str:
1080         try:
1081             filepath = inspect.getfile(self._obj) if self._obj is not None else None
1082         except TypeError:
1083             filepath = None
1084         name = self._name
1085 
1086         if filepath is None and name is None:
1087             return None
1088         elif filepath is None:
1089             filepath = ""
1090 
1091         return ":".join([filepath, "docstring of %s" % name])
1092 
1093     def _escape_args_and_kwargs(self, name: str) -> str:
1094         func = super()._escape_args_and_kwargs
1095 
1096         if ", " in name:
1097             return ", ".join(func(param) for param in name.split(", "))
1098         else:
1099             return func(name)
1100 
1101     def _consume_field(self, parse_type: bool = True, prefer_type: bool = False
1102                        ) -> Tuple[str, str, List[str]]:
1103         line = next(self._line_iter)
1104         if parse_type:
1105             _name, _, _type = self._partition_field_on_colon(line)
1106         else:
1107             _name, _type = line, ''
1108         _name, _type = _name.strip(), _type.strip()
1109         _name = self._escape_args_and_kwargs(_name)
1110 
1111         if prefer_type and not _type:
1112             _type, _name = _name, _type
1113 
1114         if self._config.napoleon_preprocess_types:
1115             _type = _convert_numpy_type_spec(
1116                 _type,
1117                 location=self._get_location(),
1118                 translations=self._config.napoleon_type_aliases or {},
1119             )
1120 
1121         indent = self._get_indent(line) + 1
1122         _desc = self._dedent(self._consume_indented_block(indent))
1123         _desc = self.__class__(_desc, self._config).lines()
1124         return _name, _type, _desc
1125 
1126     def _consume_returns_section(self) -> List[Tuple[str, str, List[str]]]:
1127         return self._consume_fields(prefer_type=True)
1128 
1129     def _consume_section_header(self) -> str:
1130         section = next(self._line_iter)
1131         if not _directive_regex.match(section):
1132             # Consume the header underline
1133             next(self._line_iter)
1134         return section
1135 
1136     def _is_section_break(self) -> bool:
1137         line1, line2 = self._line_iter.peek(2)
1138         return (not self._line_iter.has_next() or
1139                 self._is_section_header() or
1140                 ['', ''] == [line1, line2] or
1141                 (self._is_in_section and
1142                     line1 and
1143                     not self._is_indented(line1, self._section_indent)))
1144 
1145     def _is_section_header(self) -> bool:
1146         section, underline = self._line_iter.peek(2)
1147         section = section.lower()
1148         if section in self._sections and isinstance(underline, str):
1149             return bool(_numpy_section_regex.match(underline))
1150         elif self._directive_sections:
1151             if _directive_regex.match(section):
1152                 for directive_section in self._directive_sections:
1153                     if section.startswith(directive_section):
1154                         return True
1155         return False
1156 
1157     def _parse_see_also_section(self, section: str) -> List[str]:
1158         lines = self._consume_to_next_section()
1159         try:
1160             return self._parse_numpydoc_see_also_section(lines)
1161         except ValueError:
1162             return self._format_admonition('seealso', lines)
1163 
1164     def _parse_numpydoc_see_also_section(self, content: List[str]) -> List[str]:
1165         """
1166         Derived from the NumpyDoc implementation of _parse_see_also.
1167 
1168         See Also
1169         --------
1170         func_name : Descriptive text
1171             continued text
1172         another_func_name : Descriptive text
1173         func_name1, func_name2, :meth:`func_name`, func_name3
1174 
1175         """
1176         items = []
1177 
1178         def parse_item_name(text: str) -> Tuple[str, str]:
1179             """Match ':role:`name`' or 'name'"""
1180             m = self._name_rgx.match(text)
1181             if m:
1182                 g = m.groups()
1183                 if g[1] is None:
1184                     return g[3], None
1185                 else:
1186                     return g[2], g[1]
1187             raise ValueError("%s is not a item name" % text)
1188 
1189         def push_item(name: str, rest: List[str]) -> None:
1190             if not name:
1191                 return
1192             name, role = parse_item_name(name)
1193             items.append((name, list(rest), role))
1194             del rest[:]
1195 
1196         def translate(func, description, role):
1197             translations = self._config.napoleon_type_aliases
1198             if role is not None or not translations:
1199                 return func, description, role
1200 
1201             translated = translations.get(func, func)
1202             match = self._name_rgx.match(translated)
1203             if not match:
1204                 return translated, description, role
1205 
1206             groups = match.groupdict()
1207             role = groups["role"]
1208             new_func = groups["name"] or groups["name2"]
1209 
1210             return new_func, description, role
1211 
1212         current_func = None
1213         rest = []  # type: List[str]
1214 
1215         for line in content:
1216             if not line.strip():
1217                 continue
1218 
1219             m = self._name_rgx.match(line)
1220             if m and line[m.end():].strip().startswith(':'):
1221                 push_item(current_func, rest)
1222                 current_func, line = line[:m.end()], line[m.end():]
1223                 rest = [line.split(':', 1)[1].strip()]
1224                 if not rest[0]:
1225                     rest = []
1226             elif not line.startswith(' '):
1227                 push_item(current_func, rest)
1228                 current_func = None
1229                 if ',' in line:
1230                     for func in line.split(','):
1231                         if func.strip():
1232                             push_item(func, [])
1233                 elif line.strip():
1234                     current_func = line
1235             elif current_func is not None:
1236                 rest.append(line.strip())
1237         push_item(current_func, rest)
1238 
1239         if not items:
1240             return []
1241 
1242         # apply type aliases
1243         items = [
1244             translate(func, description, role)
1245             for func, description, role in items
1246         ]
1247 
1248         lines = []  # type: List[str]
1249         last_had_desc = True
1250         for name, desc, role in items:
1251             if role:
1252                 link = ':%s:`%s`' % (role, name)
1253             else:
1254                 link = ':obj:`%s`' % name
1255             if desc or last_had_desc:
1256                 lines += ['']
1257                 lines += [link]
1258             else:
1259                 lines[-1] += ", %s" % link
1260             if desc:
1261                 lines += self._indent([' '.join(desc)])
1262                 last_had_desc = True
1263             else:
1264                 last_had_desc = False
1265         lines += ['']
1266 
1267         return self._format_admonition('seealso', lines)

</code><intended_behavior>Modify or enhance the docstring parsing functionality to better integrate type hints from the source code into the attribute documentation generated from Google-style docstrings. This could involve checking for existing type hints and preventing the generation of duplicate attribute entries, one from the docstring and one from the type hint, thereby merging them into a single entry.</intended_behavior>, <file>sphinx/ext/autodoc/typehints.py</file>
<class>None</class>
<method>None</method>
<code>
1 """
2     sphinx.ext.autodoc.typehints
3     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
4 
5     Generating content for autodoc using typehints
6 
7     :copyright: Copyright 2007-2020 by the Sphinx team, see AUTHORS.
8     :license: BSD, see LICENSE for details.
9 """
10 
11 import re
12 from collections import OrderedDict
13 from typing import Any, Dict, Iterable, cast
14 
15 from docutils import nodes
16 from docutils.nodes import Element
17 
18 from sphinx import addnodes
19 from sphinx.application import Sphinx
20 from sphinx.util import inspect, typing
21 
22 
23 def record_typehints(app: Sphinx, objtype: str, name: str, obj: Any,
24                      options: Dict, args: str, retann: str) -> None:
25     """Record type hints to env object."""
26     try:
27         if callable(obj):
28             annotations = app.env.temp_data.setdefault('annotations', {})
29             annotation = annotations.setdefault(name, OrderedDict())
30             sig = inspect.signature(obj, type_aliases=app.config.autodoc_type_aliases)
31             for param in sig.parameters.values():
32                 if param.annotation is not param.empty:
33                     annotation[param.name] = typing.stringify(param.annotation)
34             if sig.return_annotation is not sig.empty:
35                 annotation['return'] = typing.stringify(sig.return_annotation)
36     except (TypeError, ValueError):
37         pass
38 
39 
40 def merge_typehints(app: Sphinx, domain: str, objtype: str, contentnode: Element) -> None:
41     if domain != 'py':
42         return
43     if app.config.autodoc_typehints != 'description':
44         return
45     if objtype == 'class' and app.config.autoclass_content not in ('init', 'both'):
46         return
47 
48     try:
49         signature = cast(addnodes.desc_signature, contentnode.parent[0])
50         if signature['module']:
51             fullname = '.'.join([signature['module'], signature['fullname']])
52         else:
53             fullname = signature['fullname']
54     except KeyError:
55         # signature node does not have valid context info for the target object
56         return
57 
58     annotations = app.env.temp_data.get('annotations', {})
59     if annotations.get(fullname, {}):
60         field_lists = [n for n in contentnode if isinstance(n, nodes.field_list)]
61         if field_lists == []:
62             field_list = insert_field_list(contentnode)
63             field_lists.append(field_list)
64 
65         for field_list in field_lists:
66             modify_field_list(field_list, annotations[fullname])
67 
68 
69 def insert_field_list(node: Element) -> nodes.field_list:
70     field_list = nodes.field_list()
71     desc = [n for n in node if isinstance(n, addnodes.desc)]
72     if desc:
73         # insert just before sub object descriptions (ex. methods, nested classes, etc.)
74         index = node.index(desc[0])
75         node.insert(index - 1, [field_list])
76     else:
77         node += field_list
78 
79     return field_list
80 
81 
82 def modify_field_list(node: nodes.field_list, annotations: Dict[str, str]) -> None:
83     arguments = {}  # type: Dict[str, Dict[str, bool]]
84     fields = cast(Iterable[nodes.field], node)
85     for field in fields:
86         field_name = field[0].astext()
87         parts = re.split(' +', field_name)
88         if parts[0] == 'param':
89             if len(parts) == 2:
90                 # :param xxx:
91                 arg = arguments.setdefault(parts[1], {})
92                 arg['param'] = True
93             elif len(parts) > 2:
94                 # :param xxx yyy:
95                 name = ' '.join(parts[2:])
96                 arg = arguments.setdefault(name, {})
97                 arg['param'] = True
98                 arg['type'] = True
99         elif parts[0] == 'type':
100             name = ' '.join(parts[1:])
101             arg = arguments.setdefault(name, {})
102             arg['type'] = True
103         elif parts[0] == 'rtype':
104             arguments['return'] = {'type': True}
105 
106     for name, annotation in annotations.items():
107         if name == 'return':
108             continue
109 
110         arg = arguments.get(name, {})
111         if not arg.get('type'):
112             field = nodes.field()
113             field += nodes.field_name('', 'type ' + name)
114             field += nodes.field_body('', nodes.paragraph('', annotation))
115             node += field
116         if not arg.get('param'):
117             field = nodes.field()
118             field += nodes.field_name('', 'param ' + name)
119             field += nodes.field_body('', nodes.paragraph('', ''))
120             node += field
121 
122     if 'return' in annotations and 'return' not in arguments:
123         field = nodes.field()
124         field += nodes.field_name('', 'rtype')
125         field += nodes.field_body('', nodes.paragraph('', annotation))
126         node += field
127 
128 
129 def setup(app: Sphinx) -> Dict[str, Any]:
130     app.connect('autodoc-process-signature', record_typehints)
131     app.connect('object-description-transform', merge_typehints)
132 
133     return {
134         'version': 'builtin',
135         'parallel_read_safe': True,
136         'parallel_write_safe': True,
137     }

</code><intended_behavior>Enhance the handling of type hints for attributes specifically, with logic to intelligently merge type information with attribute descriptions obtained from docstrings. This process should respect user configurations in `conf.py`, possibly adding new options that allow users to specify their preferred handling method (e.g., prefer docstring types, prefer type hints, merge both with docstring taking precedence, etc.).</intended_behavior>, <file>doc/conf.py</file>
<class>None</class>
<method>None</method>
<code>
1 # Sphinx documentation build configuration file
2 
3 import re
4 
5 import sphinx
6 
7 extensions = ['sphinx.ext.autodoc', 'sphinx.ext.doctest', 'sphinx.ext.todo',
8               'sphinx.ext.autosummary', 'sphinx.ext.extlinks',
9               'sphinx.ext.intersphinx',
10               'sphinx.ext.viewcode', 'sphinx.ext.inheritance_diagram']
11 
12 master_doc = 'contents'
13 templates_path = ['_templates']
14 exclude_patterns = ['_build']
15 
16 project = 'Sphinx'
17 copyright = '2007-2020, Georg Brandl and the Sphinx team'
18 version = sphinx.__display_version__
19 release = version
20 show_authors = True
21 
22 html_theme = 'sphinx13'
23 html_theme_path = ['_themes']
24 modindex_common_prefix = ['sphinx.']
25 html_static_path = ['_static']
26 html_sidebars = {'index': ['indexsidebar.html', 'searchbox.html']}
27 html_additional_pages = {'index': 'index.html'}
28 html_use_opensearch = 'https://www.sphinx-doc.org/en/master'
29 html_baseurl = 'https://www.sphinx-doc.org/en/master/'
30 html_favicon = '_static/favicon.svg'
31 
32 htmlhelp_basename = 'Sphinxdoc'
33 
34 epub_theme = 'epub'
35 epub_basename = 'sphinx'
36 epub_author = 'Georg Brandl'
37 epub_publisher = 'http://sphinx-doc.org/'
38 epub_uid = 'web-site'
39 epub_scheme = 'url'
40 epub_identifier = epub_publisher
41 epub_pre_files = [('index.xhtml', 'Welcome')]
42 epub_post_files = [('usage/installation.xhtml', 'Installing Sphinx'),
43                    ('develop.xhtml', 'Sphinx development')]
44 epub_exclude_files = ['_static/opensearch.xml', '_static/doctools.js',
45                       '_static/jquery.js', '_static/searchtools.js',
46                       '_static/underscore.js', '_static/basic.css',
47                       '_static/language_data.js',
48                       'search.html', '_static/websupport.js']
49 epub_fix_images = False
50 epub_max_image_width = 0
51 epub_show_urls = 'inline'
52 epub_use_index = False
53 epub_guide = (('toc', 'contents.xhtml', 'Table of Contents'),)
54 epub_description = 'Sphinx documentation generator system manual'
55 
56 latex_documents = [('contents', 'sphinx.tex', 'Sphinx Documentation',
57                     'Georg Brandl', 'manual', 1)]
58 latex_logo = '_static/sphinx.png'
59 latex_elements = {
60     'fontenc': r'\usepackage[LGR,X2,T1]{fontenc}',
61     'fontpkg': r'''
62 \usepackage[sc]{mathpazo}
63 \usepackage[scaled]{helvet}
64 \usepackage{courier}
65 \substitutefont{LGR}{\rmdefault}{cmr}
66 \substitutefont{LGR}{\sfdefault}{cmss}
67 \substitutefont{LGR}{\ttdefault}{cmtt}
68 \substitutefont{X2}{\rmdefault}{cmr}
69 \substitutefont{X2}{\sfdefault}{cmss}
70 \substitutefont{X2}{\ttdefault}{cmtt}
71 ''',
72     'passoptionstopackages': '\\PassOptionsToPackage{svgnames}{xcolor}',
73     'preamble': '\\DeclareUnicodeCharacter{229E}{\\ensuremath{\\boxplus}}',
74     'fvset': '\\fvset{fontsize=auto}',
75     # fix missing index entry due to RTD doing only once pdflatex after makeindex
76     'printindex': r'''
77 \IfFileExists{\jobname.ind}
78              {\footnotesize\raggedright\printindex}
79              {\begin{sphinxtheindex}\end{sphinxtheindex}}
80 ''',
81 }
82 latex_show_urls = 'footnote'
83 latex_use_xindy = True
84 
85 autodoc_member_order = 'groupwise'
86 todo_include_todos = True
87 extlinks = {'duref': ('http://docutils.sourceforge.net/docs/ref/rst/'
88                       'restructuredtext.html#%s', ''),
89             'durole': ('http://docutils.sourceforge.net/docs/ref/rst/'
90                        'roles.html#%s', ''),
91             'dudir': ('http://docutils.sourceforge.net/docs/ref/rst/'
92                       'directives.html#%s', '')}
93 
94 man_pages = [
95     ('contents', 'sphinx-all', 'Sphinx documentation generator system manual',
96      'Georg Brandl', 1),
97     ('man/sphinx-build', 'sphinx-build', 'Sphinx documentation generator tool',
98      '', 1),
99     ('man/sphinx-quickstart', 'sphinx-quickstart', 'Sphinx documentation '
100      'template generator', '', 1),
101     ('man/sphinx-apidoc', 'sphinx-apidoc', 'Sphinx API doc generator tool',
102      '', 1),
103     ('man/sphinx-autogen', 'sphinx-autogen', 'Generate autodoc stub pages',
104      '', 1),
105 ]
106 
107 texinfo_documents = [
108     ('contents', 'sphinx', 'Sphinx Documentation', 'Georg Brandl',
109      'Sphinx', 'The Sphinx documentation builder.', 'Documentation tools',
110      1),
111 ]
112 
113 intersphinx_mapping = {'python': ('https://docs.python.org/3/', None)}
114 
115 # Sphinx document translation with sphinx gettext feature uses these settings:
116 locale_dirs = ['locale/']
117 gettext_compact = False
118 
119 
120 # -- Extension interface -------------------------------------------------------
121 
122 from sphinx import addnodes  # noqa
123 
124 event_sig_re = re.compile(r'([a-zA-Z-]+)\s*\((.*)\)')
125 
126 
127 def parse_event(env, sig, signode):
128     m = event_sig_re.match(sig)
129     if not m:
130         signode += addnodes.desc_name(sig, sig)
131         return sig
132     name, args = m.groups()
133     signode += addnodes.desc_name(name, name)
134     plist = addnodes.desc_parameterlist()
135     for arg in args.split(','):
136         arg = arg.strip()
137         plist += addnodes.desc_parameter(arg, arg)
138     signode += plist
139     return name
140 
141 
142 def setup(app):
143     from sphinx.ext.autodoc import cut_lines
144     from sphinx.util.docfields import GroupedField
145     app.connect('autodoc-process-docstring', cut_lines(4, what=['module']))
146     app.add_object_type('confval', 'confval',
147                         objname='configuration value',
148                         indextemplate='pair: %s; configuration value')
149     app.add_object_type('setuptools-confval', 'setuptools-confval',
150                         objname='setuptools configuration value',
151                         indextemplate='pair: %s; setuptools configuration value')
152     fdesc = GroupedField('parameter', label='Parameters',
153                          names=['param'], can_collapse=True)
154     app.add_object_type('event', 'event', 'pair: %s; event', parse_event,
155                         doc_field_types=[fdesc])
156 
157     # workaround for RTD
158     from sphinx.util import logging
159     logger = logging.getLogger(__name__)
160     app.info = lambda *args, **kwargs: logger.info(*args, **kwargs)
161     app.warn = lambda *args, **kwargs: logger.warning(*args, **kwargs)
162     app.debug = lambda *args, **kwargs: logger.debug(*args, **kwargs)

</code><intended_behavior>Introduce new configuration options that provide users with explicit control over how attribute documentation is generated in the presence of both docstrings and type hints. This can include settings to avoid duplication and control the merging behavior.</intended_behavior>]
2025-10-18 18:37:45.741 | INFO     | Search completed. Bug locations: [<file>sphinx/ext/napoleon/docstring.py</file>
<class>None</class>
<method>None</method>
<code>
1 """
2     sphinx.ext.napoleon.docstring
3     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
4 
5 
6     Classes for docstring parsing and formatting.
7 
8 
9     :copyright: Copyright 2007-2020 by the Sphinx team, see AUTHORS.
10     :license: BSD, see LICENSE for details.
11 """
12 
13 import collections
14 import inspect
15 import re
16 from functools import partial
17 from typing import Any, Callable, Dict, List, Tuple, Union
18 
19 from sphinx.application import Sphinx
20 from sphinx.config import Config as SphinxConfig
21 from sphinx.ext.napoleon.iterators import modify_iter
22 from sphinx.locale import _, __
23 from sphinx.util import logging
24 
25 if False:
26     # For type annotation
27     from typing import Type  # for python3.5.1
28 
29 
30 logger = logging.getLogger(__name__)
31 
32 _directive_regex = re.compile(r'\.\. \S+::')
33 _google_section_regex = re.compile(r'^(\s|\w)+:\s*$')
34 _google_typed_arg_regex = re.compile(r'(.+?)\(\s*(.*[^\s]+)\s*\)')
35 _numpy_section_regex = re.compile(r'^[=\-`:\'"~^_*+#<>]{2,}\s*$')
36 _single_colon_regex = re.compile(r'(?<!:):(?!:)')
37 _xref_or_code_regex = re.compile(
38     r'((?::(?:[a-zA-Z0-9]+[\-_+:.])*[a-zA-Z0-9]+:`.+?`)|'
39     r'(?:``.+?``))')
40 _xref_regex = re.compile(
41     r'(?:(?::(?:[a-zA-Z0-9]+[\-_+:.])*[a-zA-Z0-9]+:)?`.+?`)'
42 )
43 _bullet_list_regex = re.compile(r'^(\*|\+|\-)(\s+\S|\s*$)')
44 _enumerated_list_regex = re.compile(
45     r'^(?P<paren>\()?'
46     r'(\d+|#|[ivxlcdm]+|[IVXLCDM]+|[a-zA-Z])'
47     r'(?(paren)\)|\.)(\s+\S|\s*$)')
48 _token_regex = re.compile(
49     r"(,\sor\s|\sor\s|\sof\s|:\s|\sto\s|,\sand\s|\sand\s|,\s"
50     r"|[{]|[}]"
51     r'|"(?:\\"|[^"])*"'
52     r"|'(?:\\'|[^'])*')"
53 )
54 _default_regex = re.compile(
55     r"^default[^_0-9A-Za-z].*$",
56 )
57 _SINGLETONS = ("None", "True", "False", "Ellipsis")
58 
59 
60 class GoogleDocstring:
61     """Convert Google style docstrings to reStructuredText.
62 
63     Parameters
64     ----------
65     docstring : :obj:`str` or :obj:`list` of :obj:`str`
66         The docstring to parse, given either as a string or split into
67         individual lines.
68     config: :obj:`sphinx.ext.napoleon.Config` or :obj:`sphinx.config.Config`
69         The configuration settings to use. If not given, defaults to the
70         config object on `app`; or if `app` is not given defaults to the
71         a new :class:`sphinx.ext.napoleon.Config` object.
72 
73 
74     Other Parameters
75     ----------------
76     app : :class:`sphinx.application.Sphinx`, optional
77         Application object representing the Sphinx process.
78     what : :obj:`str`, optional
79         A string specifying the type of the object to which the docstring
80         belongs. Valid values: "module", "class", "exception", "function",
81         "method", "attribute".
82     name : :obj:`str`, optional
83         The fully qualified name of the object.
84     obj : module, class, exception, function, method, or attribute
85         The object to which the docstring belongs.
86     options : :class:`sphinx.ext.autodoc.Options`, optional
87         The options given to the directive: an object with attributes
88         inherited_members, undoc_members, show_inheritance and noindex that
89         are True if the flag option of same name was given to the auto
90         directive.
91 
92 
93     Example
94     -------
95     >>> from sphinx.ext.napoleon import Config
96     >>> config = Config(napoleon_use_param=True, napoleon_use_rtype=True)
97     >>> docstring = '''One line summary.
98     ...
99     ... Extended description.
100     ...
101     ... Args:
102     ...   arg1(int): Description of `arg1`
103     ...   arg2(str): Description of `arg2`
104     ... Returns:
105     ...   str: Description of return value.
106     ... '''
107     >>> print(GoogleDocstring(docstring, config))
108     One line summary.
109     <BLANKLINE>
110     Extended description.
111     <BLANKLINE>
112     :param arg1: Description of `arg1`
113     :type arg1: int
114     :param arg2: Description of `arg2`
115     :type arg2: str
116     <BLANKLINE>
117     :returns: Description of return value.
118     :rtype: str
119     <BLANKLINE>
120 
121     """
122 
123     _name_rgx = re.compile(r"^\s*((?::(?P<role>\S+):)?`(?P<name>~?[a-zA-Z0-9_.-]+)`|"
124                            r" (?P<name2>~?[a-zA-Z0-9_.-]+))\s*", re.X)
125 
126     def __init__(self, docstring: Union[str, List[str]], config: SphinxConfig = None,
127                  app: Sphinx = None, what: str = '', name: str = '',
128                  obj: Any = None, options: Any = None) -> None:
129         self._config = config
130         self._app = app
131 
132         if not self._config:
133             from sphinx.ext.napoleon import Config
134             self._config = self._app.config if self._app else Config()  # type: ignore
135 
136         if not what:
137             if inspect.isclass(obj):
138                 what = 'class'
139             elif inspect.ismodule(obj):
140                 what = 'module'
141             elif callable(obj):
142                 what = 'function'
143             else:
144                 what = 'object'
145 
146         self._what = what
147         self._name = name
148         self._obj = obj
149         self._opt = options
150         if isinstance(docstring, str):
151             lines = docstring.splitlines()
152         else:
153             lines = docstring
154         self._line_iter = modify_iter(lines, modifier=lambda s: s.rstrip())
155         self._parsed_lines = []  # type: List[str]
156         self._is_in_section = False
157         self._section_indent = 0
158         if not hasattr(self, '_directive_sections'):
159             self._directive_sections = []  # type: List[str]
160         if not hasattr(self, '_sections'):
161             self._sections = {
162                 'args': self._parse_parameters_section,
163                 'arguments': self._parse_parameters_section,
164                 'attention': partial(self._parse_admonition, 'attention'),
165                 'attributes': self._parse_attributes_section,
166                 'caution': partial(self._parse_admonition, 'caution'),
167                 'danger': partial(self._parse_admonition, 'danger'),
168                 'error': partial(self._parse_admonition, 'error'),
169                 'example': self._parse_examples_section,
170                 'examples': self._parse_examples_section,
171                 'hint': partial(self._parse_admonition, 'hint'),
172                 'important': partial(self._parse_admonition, 'important'),
173                 'keyword args': self._parse_keyword_arguments_section,
174                 'keyword arguments': self._parse_keyword_arguments_section,
175                 'methods': self._parse_methods_section,
176                 'note': partial(self._parse_admonition, 'note'),
177                 'notes': self._parse_notes_section,
178                 'other parameters': self._parse_other_parameters_section,
179                 'parameters': self._parse_parameters_section,
180                 'return': self._parse_returns_section,
181                 'returns': self._parse_returns_section,
182                 'raise': self._parse_raises_section,
183                 'raises': self._parse_raises_section,
184                 'references': self._parse_references_section,
185                 'see also': self._parse_see_also_section,
186                 'tip': partial(self._parse_admonition, 'tip'),
187                 'todo': partial(self._parse_admonition, 'todo'),
188                 'warning': partial(self._parse_admonition, 'warning'),
189                 'warnings': partial(self._parse_admonition, 'warning'),
190                 'warn': self._parse_warns_section,
191                 'warns': self._parse_warns_section,
192                 'yield': self._parse_yields_section,
193                 'yields': self._parse_yields_section,
194             }  # type: Dict[str, Callable]
195 
196         self._load_custom_sections()
197 
198         self._parse()
199 
200     def __str__(self) -> str:
201         """Return the parsed docstring in reStructuredText format.
202 
203         Returns
204         -------
205         unicode
206             Unicode version of the docstring.
207 
208         """
209         return '\n'.join(self.lines())
210 
211     def lines(self) -> List[str]:
212         """Return the parsed lines of the docstring in reStructuredText format.
213 
214         Returns
215         -------
216         list(str)
217             The lines of the docstring in a list.
218 
219         """
220         return self._parsed_lines
221 
222     def _consume_indented_block(self, indent: int = 1) -> List[str]:
223         lines = []
224         line = self._line_iter.peek()
225         while(not self._is_section_break() and
226               (not line or self._is_indented(line, indent))):
227             lines.append(next(self._line_iter))
228             line = self._line_iter.peek()
229         return lines
230 
231     def _consume_contiguous(self) -> List[str]:
232         lines = []
233         while (self._line_iter.has_next() and
234                self._line_iter.peek() and
235                not self._is_section_header()):
236             lines.append(next(self._line_iter))
237         return lines
238 
239     def _consume_empty(self) -> List[str]:
240         lines = []
241         line = self._line_iter.peek()
242         while self._line_iter.has_next() and not line:
243             lines.append(next(self._line_iter))
244             line = self._line_iter.peek()
245         return lines
246 
247     def _consume_field(self, parse_type: bool = True, prefer_type: bool = False
248                        ) -> Tuple[str, str, List[str]]:
249         line = next(self._line_iter)
250 
251         before, colon, after = self._partition_field_on_colon(line)
252         _name, _type, _desc = before, '', after
253 
254         if parse_type:
255             match = _google_typed_arg_regex.match(before)
256             if match:
257                 _name = match.group(1).strip()
258                 _type = match.group(2)
259 
260         _name = self._escape_args_and_kwargs(_name)
261 
262         if prefer_type and not _type:
263             _type, _name = _name, _type
264         indent = self._get_indent(line) + 1
265         _descs = [_desc] + self._dedent(self._consume_indented_block(indent))
266         _descs = self.__class__(_descs, self._config).lines()
267         return _name, _type, _descs
268 
269     def _consume_fields(self, parse_type: bool = True, prefer_type: bool = False,
270                         multiple: bool = False) -> List[Tuple[str, str, List[str]]]:
271         self._consume_empty()
272         fields = []
273         while not self._is_section_break():
274             _name, _type, _desc = self._consume_field(parse_type, prefer_type)
275             if multiple and _name:
276                 for name in _name.split(","):
277                     fields.append((name.strip(), _type, _desc))
278             elif _name or _type or _desc:
279                 fields.append((_name, _type, _desc,))
280         return fields
281 
282     def _consume_inline_attribute(self) -> Tuple[str, List[str]]:
283         line = next(self._line_iter)
284         _type, colon, _desc = self._partition_field_on_colon(line)
285         if not colon or not _desc:
286             _type, _desc = _desc, _type
287             _desc += colon
288         _descs = [_desc] + self._dedent(self._consume_to_end())
289         _descs = self.__class__(_descs, self._config).lines()
290         return _type, _descs
291 
292     def _consume_returns_section(self) -> List[Tuple[str, str, List[str]]]:
293         lines = self._dedent(self._consume_to_next_section())
294         if lines:
295             before, colon, after = self._partition_field_on_colon(lines[0])
296             _name, _type, _desc = '', '', lines
297 
298             if colon:
299                 if after:
300                     _desc = [after] + lines[1:]
301                 else:
302                     _desc = lines[1:]
303 
304                 _type = before
305 
306             _desc = self.__class__(_desc, self._config).lines()
307             return [(_name, _type, _desc,)]
308         else:
309             return []
310 
311     def _consume_usage_section(self) -> List[str]:
312         lines = self._dedent(self._consume_to_next_section())
313         return lines
314 
315     def _consume_section_header(self) -> str:
316         section = next(self._line_iter)
317         stripped_section = section.strip(':')
318         if stripped_section.lower() in self._sections:
319             section = stripped_section
320         return section
321 
322     def _consume_to_end(self) -> List[str]:
323         lines = []
324         while self._line_iter.has_next():
325             lines.append(next(self._line_iter))
326         return lines
327 
328     def _consume_to_next_section(self) -> List[str]:
329         self._consume_empty()
330         lines = []
331         while not self._is_section_break():
332             lines.append(next(self._line_iter))
333         return lines + self._consume_empty()
334 
335     def _dedent(self, lines: List[str], full: bool = False) -> List[str]:
336         if full:
337             return [line.lstrip() for line in lines]
338         else:
339             min_indent = self._get_min_indent(lines)
340             return [line[min_indent:] for line in lines]
341 
342     def _escape_args_and_kwargs(self, name: str) -> str:
343         if name.endswith('_') and getattr(self._config, 'strip_signature_backslash', False):
344             name = name[:-1] + r'\_'
345 
346         if name[:2] == '**':
347             return r'\*\*' + name[2:]
348         elif name[:1] == '*':
349             return r'\*' + name[1:]
350         else:
351             return name
352 
353     def _fix_field_desc(self, desc: List[str]) -> List[str]:
354         if self._is_list(desc):
355             desc = [''] + desc
356         elif desc[0].endswith('::'):
357             desc_block = desc[1:]
358             indent = self._get_indent(desc[0])
359             block_indent = self._get_initial_indent(desc_block)
360             if block_indent > indent:
361                 desc = [''] + desc
362             else:
363                 desc = ['', desc[0]] + self._indent(desc_block, 4)
364         return desc
365 
366     def _format_admonition(self, admonition: str, lines: List[str]) -> List[str]:
367         lines = self._strip_empty(lines)
368         if len(lines) == 1:
369             return ['.. %s:: %s' % (admonition, lines[0].strip()), '']
370         elif lines:
371             lines = self._indent(self._dedent(lines), 3)
372             return ['.. %s::' % admonition, ''] + lines + ['']
373         else:
374             return ['.. %s::' % admonition, '']
375 
376     def _format_block(self, prefix: str, lines: List[str], padding: str = None) -> List[str]:
377         if lines:
378             if padding is None:
379                 padding = ' ' * len(prefix)
380             result_lines = []
381             for i, line in enumerate(lines):
382                 if i == 0:
383                     result_lines.append((prefix + line).rstrip())
384                 elif line:
385                     result_lines.append(padding + line)
386                 else:
387                     result_lines.append('')
388             return result_lines
389         else:
390             return [prefix]
391 
392     def _format_docutils_params(self, fields: List[Tuple[str, str, List[str]]],
393                                 field_role: str = 'param', type_role: str = 'type'
394                                 ) -> List[str]:
395         lines = []
396         for _name, _type, _desc in fields:
397             _desc = self._strip_empty(_desc)
398             if any(_desc):
399                 _desc = self._fix_field_desc(_desc)
400                 field = ':%s %s: ' % (field_role, _name)
401                 lines.extend(self._format_block(field, _desc))
402             else:
403                 lines.append(':%s %s:' % (field_role, _name))
404 
405             if _type:
406                 lines.append(':%s %s: %s' % (type_role, _name, _type))
407         return lines + ['']
408 
409     def _format_field(self, _name: str, _type: str, _desc: List[str]) -> List[str]:
410         _desc = self._strip_empty(_desc)
411         has_desc = any(_desc)
412         separator = ' -- ' if has_desc else ''
413         if _name:
414             if _type:
415                 if '`' in _type:
416                     field = '**%s** (%s)%s' % (_name, _type, separator)
417                 else:
418                     field = '**%s** (*%s*)%s' % (_name, _type, separator)
419             else:
420                 field = '**%s**%s' % (_name, separator)
421         elif _type:
422             if '`' in _type:
423                 field = '%s%s' % (_type, separator)
424             else:
425                 field = '*%s*%s' % (_type, separator)
426         else:
427             field = ''
428 
429         if has_desc:
430             _desc = self._fix_field_desc(_desc)
431             if _desc[0]:
432                 return [field + _desc[0]] + _desc[1:]
433             else:
434                 return [field] + _desc
435         else:
436             return [field]
437 
438     def _format_fields(self, field_type: str, fields: List[Tuple[str, str, List[str]]]
439                        ) -> List[str]:
440         field_type = ':%s:' % field_type.strip()
441         padding = ' ' * len(field_type)
442         multi = len(fields) > 1
443         lines = []  # type: List[str]
444         for _name, _type, _desc in fields:
445             field = self._format_field(_name, _type, _desc)
446             if multi:
447                 if lines:
448                     lines.extend(self._format_block(padding + ' * ', field))
449                 else:
450                     lines.extend(self._format_block(field_type + ' * ', field))
451             else:
452                 lines.extend(self._format_block(field_type + ' ', field))
453         if lines and lines[-1]:
454             lines.append('')
455         return lines
456 
457     def _get_current_indent(self, peek_ahead: int = 0) -> int:
458         line = self._line_iter.peek(peek_ahead + 1)[peek_ahead]
459         while line != self._line_iter.sentinel:
460             if line:
461                 return self._get_indent(line)
462             peek_ahead += 1
463             line = self._line_iter.peek(peek_ahead + 1)[peek_ahead]
464         return 0
465 
466     def _get_indent(self, line: str) -> int:
467         for i, s in enumerate(line):
468             if not s.isspace():
469                 return i
470         return len(line)
471 
472     def _get_initial_indent(self, lines: List[str]) -> int:
473         for line in lines:
474             if line:
475                 return self._get_indent(line)
476         return 0
477 
478     def _get_min_indent(self, lines: List[str]) -> int:
479         min_indent = None
480         for line in lines:
481             if line:
482                 indent = self._get_indent(line)
483                 if min_indent is None:
484                     min_indent = indent
485                 elif indent < min_indent:
486                     min_indent = indent
487         return min_indent or 0
488 
489     def _indent(self, lines: List[str], n: int = 4) -> List[str]:
490         return [(' ' * n) + line for line in lines]
491 
492     def _is_indented(self, line: str, indent: int = 1) -> bool:
493         for i, s in enumerate(line):
494             if i >= indent:
495                 return True
496             elif not s.isspace():
497                 return False
498         return False
499 
500     def _is_list(self, lines: List[str]) -> bool:
501         if not lines:
502             return False
503         if _bullet_list_regex.match(lines[0]):
504             return True
505         if _enumerated_list_regex.match(lines[0]):
506             return True
507         if len(lines) < 2 or lines[0].endswith('::'):
508             return False
509         indent = self._get_indent(lines[0])
510         next_indent = indent
511         for line in lines[1:]:
512             if line:
513                 next_indent = self._get_indent(line)
514                 break
515         return next_indent > indent
516 
517     def _is_section_header(self) -> bool:
518         section = self._line_iter.peek().lower()
519         match = _google_section_regex.match(section)
520         if match and section.strip(':') in self._sections:
521             header_indent = self._get_indent(section)
522             section_indent = self._get_current_indent(peek_ahead=1)
523             return section_indent > header_indent
524         elif self._directive_sections:
525             if _directive_regex.match(section):
526                 for directive_section in self._directive_sections:
527                     if section.startswith(directive_section):
528                         return True
529         return False
530 
531     def _is_section_break(self) -> bool:
532         line = self._line_iter.peek()
533         return (not self._line_iter.has_next() or
534                 self._is_section_header() or
535                 (self._is_in_section and
536                     line and
537                     not self._is_indented(line, self._section_indent)))
538 
539     def _load_custom_sections(self) -> None:
540         if self._config.napoleon_custom_sections is not None:
541             for entry in self._config.napoleon_custom_sections:
542                 if isinstance(entry, str):
543                     # if entry is just a label, add to sections list,
544                     # using generic section logic.
545                     self._sections[entry.lower()] = self._parse_custom_generic_section
546                 else:
547                     # otherwise, assume entry is container;
548                     # [0] is new section, [1] is the section to alias.
549                     # in the case of key mismatch, just handle as generic section.
550                     self._sections[entry[0].lower()] = \
551                         self._sections.get(entry[1].lower(),
552                                            self._parse_custom_generic_section)
553 
554     def _parse(self) -> None:
555         self._parsed_lines = self._consume_empty()
556 
557         if self._name and self._what in ('attribute', 'data', 'property'):
558             # Implicit stop using StopIteration no longer allowed in
559             # Python 3.7; see PEP 479
560             res = []  # type: List[str]
561             try:
562                 res = self._parse_attribute_docstring()
563             except StopIteration:
564                 pass
565             self._parsed_lines.extend(res)
566             return
567 
568         while self._line_iter.has_next():
569             if self._is_section_header():
570                 try:
571                     section = self._consume_section_header()
572                     self._is_in_section = True
573                     self._section_indent = self._get_current_indent()
574                     if _directive_regex.match(section):
575                         lines = [section] + self._consume_to_next_section()
576                     else:
577                         lines = self._sections[section.lower()](section)
578                 finally:
579                     self._is_in_section = False
580                     self._section_indent = 0
581             else:
582                 if not self._parsed_lines:
583                     lines = self._consume_contiguous() + self._consume_empty()
584                 else:
585                     lines = self._consume_to_next_section()
586             self._parsed_lines.extend(lines)
587 
588     def _parse_admonition(self, admonition: str, section: str) -> List[str]:
589         # type (str, str) -> List[str]
590         lines = self._consume_to_next_section()
591         return self._format_admonition(admonition, lines)
592 
593     def _parse_attribute_docstring(self) -> List[str]:
594         _type, _desc = self._consume_inline_attribute()
595         lines = self._format_field('', '', _desc)
596         if _type:
597             lines.extend(['', ':type: %s' % _type])
598         return lines
599 
600     def _parse_attributes_section(self, section: str) -> List[str]:
601         lines = []
602         for _name, _type, _desc in self._consume_fields():
603             if self._config.napoleon_use_ivar:
604                 _name = self._qualify_name(_name, self._obj)
605                 field = ':ivar %s: ' % _name
606                 lines.extend(self._format_block(field, _desc))
607                 if _type:
608                     lines.append(':vartype %s: %s' % (_name, _type))
609             else:
610                 lines.append('.. attribute:: ' + _name)
611                 if self._opt and 'noindex' in self._opt:
612                     lines.append('   :noindex:')
613                 lines.append('')
614 
615                 fields = self._format_field('', '', _desc)
616                 lines.extend(self._indent(fields, 3))
617                 if _type:
618                     lines.append('')
619                     lines.extend(self._indent([':type: %s' % _type], 3))
620                 lines.append('')
621         if self._config.napoleon_use_ivar:
622             lines.append('')
623         return lines
624 
625     def _parse_examples_section(self, section: str) -> List[str]:
626         labels = {
627             'example': _('Example'),
628             'examples': _('Examples'),
629         }
630         use_admonition = self._config.napoleon_use_admonition_for_examples
631         label = labels.get(section.lower(), section)
632         return self._parse_generic_section(label, use_admonition)
633 
634     def _parse_custom_generic_section(self, section: str) -> List[str]:
635         # for now, no admonition for simple custom sections
636         return self._parse_generic_section(section, False)
637 
638     def _parse_usage_section(self, section: str) -> List[str]:
639         header = ['.. rubric:: Usage:', '']
640         block = ['.. code-block:: python', '']
641         lines = self._consume_usage_section()
642         lines = self._indent(lines, 3)
643         return header + block + lines + ['']
644 
645     def _parse_generic_section(self, section: str, use_admonition: bool) -> List[str]:
646         lines = self._strip_empty(self._consume_to_next_section())
647         lines = self._dedent(lines)
648         if use_admonition:
649             header = '.. admonition:: %s' % section
650             lines = self._indent(lines, 3)
651         else:
652             header = '.. rubric:: %s' % section
653         if lines:
654             return [header, ''] + lines + ['']
655         else:
656             return [header, '']
657 
658     def _parse_keyword_arguments_section(self, section: str) -> List[str]:
659         fields = self._consume_fields()
660         if self._config.napoleon_use_keyword:
661             return self._format_docutils_params(
662                 fields,
663                 field_role="keyword",
664                 type_role="kwtype")
665         else:
666             return self._format_fields(_('Keyword Arguments'), fields)
667 
668     def _parse_methods_section(self, section: str) -> List[str]:
669         lines = []  # type: List[str]
670         for _name, _type, _desc in self._consume_fields(parse_type=False):
671             lines.append('.. method:: %s' % _name)
672             if self._opt and 'noindex' in self._opt:
673                 lines.append('   :noindex:')
674             if _desc:
675                 lines.extend([''] + self._indent(_desc, 3))
676             lines.append('')
677         return lines
678 
679     def _parse_notes_section(self, section: str) -> List[str]:
680         use_admonition = self._config.napoleon_use_admonition_for_notes
681         return self._parse_generic_section(_('Notes'), use_admonition)
682 
683     def _parse_other_parameters_section(self, section: str) -> List[str]:
684         return self._format_fields(_('Other Parameters'), self._consume_fields())
685 
686     def _parse_parameters_section(self, section: str) -> List[str]:
687         if self._config.napoleon_use_param:
688             # Allow to declare multiple parameters at once (ex: x, y: int)
689             fields = self._consume_fields(multiple=True)
690             return self._format_docutils_params(fields)
691         else:
692             fields = self._consume_fields()
693             return self._format_fields(_('Parameters'), fields)
694 
695     def _parse_raises_section(self, section: str) -> List[str]:
696         fields = self._consume_fields(parse_type=False, prefer_type=True)
697         lines = []  # type: List[str]
698         for _name, _type, _desc in fields:
699             m = self._name_rgx.match(_type)
700             if m and m.group('name'):
701                 _type = m.group('name')
702             elif _xref_regex.match(_type):
703                 pos = _type.find('`')
704                 _type = _type[pos + 1:-1]
705             _type = ' ' + _type if _type else ''
706             _desc = self._strip_empty(_desc)
707             _descs = ' ' + '\n    '.join(_desc) if any(_desc) else ''
708             lines.append(':raises%s:%s' % (_type, _descs))
709         if lines:
710             lines.append('')
711         return lines
712 
713     def _parse_references_section(self, section: str) -> List[str]:
714         use_admonition = self._config.napoleon_use_admonition_for_references
715         return self._parse_generic_section(_('References'), use_admonition)
716 
717     def _parse_returns_section(self, section: str) -> List[str]:
718         fields = self._consume_returns_section()
719         multi = len(fields) > 1
720         if multi:
721             use_rtype = False
722         else:
723             use_rtype = self._config.napoleon_use_rtype
724 
725         lines = []  # type: List[str]
726         for _name, _type, _desc in fields:
727             if use_rtype:
728                 field = self._format_field(_name, '', _desc)
729             else:
730                 field = self._format_field(_name, _type, _desc)
731 
732             if multi:
733                 if lines:
734                     lines.extend(self._format_block('          * ', field))
735                 else:
736                     lines.extend(self._format_block(':returns: * ', field))
737             else:
738                 lines.extend(self._format_block(':returns: ', field))
739                 if _type and use_rtype:
740                     lines.extend([':rtype: %s' % _type, ''])
741         if lines and lines[-1]:
742             lines.append('')
743         return lines
744 
745     def _parse_see_also_section(self, section: str) -> List[str]:
746         return self._parse_admonition('seealso', section)
747 
748     def _parse_warns_section(self, section: str) -> List[str]:
749         return self._format_fields(_('Warns'), self._consume_fields())
750 
751     def _parse_yields_section(self, section: str) -> List[str]:
752         fields = self._consume_returns_section()
753         return self._format_fields(_('Yields'), fields)
754 
755     def _partition_field_on_colon(self, line: str) -> Tuple[str, str, str]:
756         before_colon = []
757         after_colon = []
758         colon = ''
759         found_colon = False
760         for i, source in enumerate(_xref_or_code_regex.split(line)):
761             if found_colon:
762                 after_colon.append(source)
763             else:
764                 m = _single_colon_regex.search(source)
765                 if (i % 2) == 0 and m:
766                     found_colon = True
767                     colon = source[m.start(): m.end()]
768                     before_colon.append(source[:m.start()])
769                     after_colon.append(source[m.end():])
770                 else:
771                     before_colon.append(source)
772 
773         return ("".join(before_colon).strip(),
774                 colon,
775                 "".join(after_colon).strip())
776 
777     def _qualify_name(self, attr_name: str, klass: "Type") -> str:
778         if klass and '.' not in attr_name:
779             if attr_name.startswith('~'):
780                 attr_name = attr_name[1:]
781             try:
782                 q = klass.__qualname__
783             except AttributeError:
784                 q = klass.__name__
785             return '~%s.%s' % (q, attr_name)
786         return attr_name
787 
788     def _strip_empty(self, lines: List[str]) -> List[str]:
789         if lines:
790             start = -1
791             for i, line in enumerate(lines):
792                 if line:
793                     start = i
794                     break
795             if start == -1:
796                 lines = []
797             end = -1
798             for i in reversed(range(len(lines))):
799                 line = lines[i]
800                 if line:
801                     end = i
802                     break
803             if start > 0 or end + 1 < len(lines):
804                 lines = lines[start:end + 1]
805         return lines
806 
807 
808 def _recombine_set_tokens(tokens: List[str]) -> List[str]:
809     token_queue = collections.deque(tokens)
810     keywords = ("optional", "default")
811 
812     def takewhile_set(tokens):
813         open_braces = 0
814         previous_token = None
815         while True:
816             try:
817                 token = tokens.popleft()
818             except IndexError:
819                 break
820 
821             if token == ", ":
822                 previous_token = token
823                 continue
824 
825             if not token.strip():
826                 continue
827 
828             if token in keywords:
829                 tokens.appendleft(token)
830                 if previous_token is not None:
831                     tokens.appendleft(previous_token)
832                 break
833 
834             if previous_token is not None:
835                 yield previous_token
836                 previous_token = None
837 
838             if token == "{":
839                 open_braces += 1
840             elif token == "}":
841                 open_braces -= 1
842 
843             yield token
844 
845             if open_braces == 0:
846                 break
847 
848     def combine_set(tokens):
849         while True:
850             try:
851                 token = tokens.popleft()
852             except IndexError:
853                 break
854 
855             if token == "{":
856                 tokens.appendleft("{")
857                 yield "".join(takewhile_set(tokens))
858             else:
859                 yield token
860 
861     return list(combine_set(token_queue))
862 
863 
864 def _tokenize_type_spec(spec: str) -> List[str]:
865     def postprocess(item):
866         if _default_regex.match(item):
867             default = item[:7]
868             # can't be separated by anything other than a single space
869             # for now
870             other = item[8:]
871 
872             return [default, " ", other]
873         else:
874             return [item]
875 
876     tokens = list(
877         item
878         for raw_token in _token_regex.split(spec)
879         for item in postprocess(raw_token)
880         if item
881     )
882     return tokens
883 
884 
885 def _token_type(token: str, location: str = None) -> str:
886     def is_numeric(token):
887         try:
888             # use complex to make sure every numeric value is detected as literal
889             complex(token)
890         except ValueError:
891             return False
892         else:
893             return True
894 
895     if token.startswith(" ") or token.endswith(" "):
896         type_ = "delimiter"
897     elif (
898             is_numeric(token) or
899             (token.startswith("{") and token.endswith("}")) or
900             (token.startswith('"') and token.endswith('"')) or
901             (token.startswith("'") and token.endswith("'"))
902     ):
903         type_ = "literal"
904     elif token.startswith("{"):
905         logger.warning(
906             __("invalid value set (missing closing brace): %s"),
907             token,
908             location=location,
909         )
910         type_ = "literal"
911     elif token.endswith("}"):
912         logger.warning(
913             __("invalid value set (missing opening brace): %s"),
914             token,
915             location=location,
916         )
917         type_ = "literal"
918     elif token.startswith("'") or token.startswith('"'):
919         logger.warning(
920             __("malformed string literal (missing closing quote): %s"),
921             token,
922             location=location,
923         )
924         type_ = "literal"
925     elif token.endswith("'") or token.endswith('"'):
926         logger.warning(
927             __("malformed string literal (missing opening quote): %s"),
928             token,
929             location=location,
930         )
931         type_ = "literal"
932     elif token in ("optional", "default"):
933         # default is not a official keyword (yet) but supported by the
934         # reference implementation (numpydoc) and widely used
935         type_ = "control"
936     elif _xref_regex.match(token):
937         type_ = "reference"
938     else:
939         type_ = "obj"
940 
941     return type_
942 
943 
944 def _convert_numpy_type_spec(_type: str, location: str = None, translations: dict = {}) -> str:
945     def convert_obj(obj, translations, default_translation):
946         translation = translations.get(obj, obj)
947 
948         # use :class: (the default) only if obj is not a standard singleton
949         if translation in _SINGLETONS and default_translation == ":class:`%s`":
950             default_translation = ":obj:`%s`"
951         elif translation == "..." and default_translation == ":class:`%s`":
952             # allow referencing the builtin ...
953             default_translation = ":obj:`%s <Ellipsis>`"
954 
955         if _xref_regex.match(translation) is None:
956             translation = default_translation % translation
957 
958         return translation
959 
960     tokens = _tokenize_type_spec(_type)
961     combined_tokens = _recombine_set_tokens(tokens)
962     types = [
963         (token, _token_type(token, location))
964         for token in combined_tokens
965     ]
966 
967     converters = {
968         "literal": lambda x: "``%s``" % x,
969         "obj": lambda x: convert_obj(x, translations, ":class:`%s`"),
970         "control": lambda x: "*%s*" % x,
971         "delimiter": lambda x: x,
972         "reference": lambda x: x,
973     }
974 
975     converted = "".join(converters.get(type_)(token) for token, type_ in types)
976 
977     return converted
978 
979 
980 class NumpyDocstring(GoogleDocstring):
981     """Convert NumPy style docstrings to reStructuredText.
982 
983     Parameters
984     ----------
985     docstring : :obj:`str` or :obj:`list` of :obj:`str`
986         The docstring to parse, given either as a string or split into
987         individual lines.
988     config: :obj:`sphinx.ext.napoleon.Config` or :obj:`sphinx.config.Config`
989         The configuration settings to use. If not given, defaults to the
990         config object on `app`; or if `app` is not given defaults to the
991         a new :class:`sphinx.ext.napoleon.Config` object.
992 
993 
994     Other Parameters
995     ----------------
996     app : :class:`sphinx.application.Sphinx`, optional
997         Application object representing the Sphinx process.
998     what : :obj:`str`, optional
999         A string specifying the type of the object to which the docstring
1000         belongs. Valid values: "module", "class", "exception", "function",
1001         "method", "attribute".
1002     name : :obj:`str`, optional
1003         The fully qualified name of the object.
1004     obj : module, class, exception, function, method, or attribute
1005         The object to which the docstring belongs.
1006     options : :class:`sphinx.ext.autodoc.Options`, optional
1007         The options given to the directive: an object with attributes
1008         inherited_members, undoc_members, show_inheritance and noindex that
1009         are True if the flag option of same name was given to the auto
1010         directive.
1011 
1012 
1013     Example
1014     -------
1015     >>> from sphinx.ext.napoleon import Config
1016     >>> config = Config(napoleon_use_param=True, napoleon_use_rtype=True)
1017     >>> docstring = '''One line summary.
1018     ...
1019     ... Extended description.
1020     ...
1021     ... Parameters
1022     ... ----------
1023     ... arg1 : int
1024     ...     Description of `arg1`
1025     ... arg2 : str
1026     ...     Description of `arg2`
1027     ... Returns
1028     ... -------
1029     ... str
1030     ...     Description of return value.
1031     ... '''
1032     >>> print(NumpyDocstring(docstring, config))
1033     One line summary.
1034     <BLANKLINE>
1035     Extended description.
1036     <BLANKLINE>
1037     :param arg1: Description of `arg1`
1038     :type arg1: int
1039     :param arg2: Description of `arg2`
1040     :type arg2: str
1041     <BLANKLINE>
1042     :returns: Description of return value.
1043     :rtype: str
1044     <BLANKLINE>
1045 
1046     Methods
1047     -------
1048     __str__()
1049         Return the parsed docstring in reStructuredText format.
1050 
1051         Returns
1052         -------
1053         str
1054             UTF-8 encoded version of the docstring.
1055 
1056     __unicode__()
1057         Return the parsed docstring in reStructuredText format.
1058 
1059         Returns
1060         -------
1061         unicode
1062             Unicode version of the docstring.
1063 
1064     lines()
1065         Return the parsed lines of the docstring in reStructuredText format.
1066 
1067         Returns
1068         -------
1069         list(str)
1070             The lines of the docstring in a list.
1071 
1072     """
1073     def __init__(self, docstring: Union[str, List[str]], config: SphinxConfig = None,
1074                  app: Sphinx = None, what: str = '', name: str = '',
1075                  obj: Any = None, options: Any = None) -> None:
1076         self._directive_sections = ['.. index::']
1077         super().__init__(docstring, config, app, what, name, obj, options)
1078 
1079     def _get_location(self) -> str:
1080         try:
1081             filepath = inspect.getfile(self._obj) if self._obj is not None else None
1082         except TypeError:
1083             filepath = None
1084         name = self._name
1085 
1086         if filepath is None and name is None:
1087             return None
1088         elif filepath is None:
1089             filepath = ""
1090 
1091         return ":".join([filepath, "docstring of %s" % name])
1092 
1093     def _escape_args_and_kwargs(self, name: str) -> str:
1094         func = super()._escape_args_and_kwargs
1095 
1096         if ", " in name:
1097             return ", ".join(func(param) for param in name.split(", "))
1098         else:
1099             return func(name)
1100 
1101     def _consume_field(self, parse_type: bool = True, prefer_type: bool = False
1102                        ) -> Tuple[str, str, List[str]]:
1103         line = next(self._line_iter)
1104         if parse_type:
1105             _name, _, _type = self._partition_field_on_colon(line)
1106         else:
1107             _name, _type = line, ''
1108         _name, _type = _name.strip(), _type.strip()
1109         _name = self._escape_args_and_kwargs(_name)
1110 
1111         if prefer_type and not _type:
1112             _type, _name = _name, _type
1113 
1114         if self._config.napoleon_preprocess_types:
1115             _type = _convert_numpy_type_spec(
1116                 _type,
1117                 location=self._get_location(),
1118                 translations=self._config.napoleon_type_aliases or {},
1119             )
1120 
1121         indent = self._get_indent(line) + 1
1122         _desc = self._dedent(self._consume_indented_block(indent))
1123         _desc = self.__class__(_desc, self._config).lines()
1124         return _name, _type, _desc
1125 
1126     def _consume_returns_section(self) -> List[Tuple[str, str, List[str]]]:
1127         return self._consume_fields(prefer_type=True)
1128 
1129     def _consume_section_header(self) -> str:
1130         section = next(self._line_iter)
1131         if not _directive_regex.match(section):
1132             # Consume the header underline
1133             next(self._line_iter)
1134         return section
1135 
1136     def _is_section_break(self) -> bool:
1137         line1, line2 = self._line_iter.peek(2)
1138         return (not self._line_iter.has_next() or
1139                 self._is_section_header() or
1140                 ['', ''] == [line1, line2] or
1141                 (self._is_in_section and
1142                     line1 and
1143                     not self._is_indented(line1, self._section_indent)))
1144 
1145     def _is_section_header(self) -> bool:
1146         section, underline = self._line_iter.peek(2)
1147         section = section.lower()
1148         if section in self._sections and isinstance(underline, str):
1149             return bool(_numpy_section_regex.match(underline))
1150         elif self._directive_sections:
1151             if _directive_regex.match(section):
1152                 for directive_section in self._directive_sections:
1153                     if section.startswith(directive_section):
1154                         return True
1155         return False
1156 
1157     def _parse_see_also_section(self, section: str) -> List[str]:
1158         lines = self._consume_to_next_section()
1159         try:
1160             return self._parse_numpydoc_see_also_section(lines)
1161         except ValueError:
1162             return self._format_admonition('seealso', lines)
1163 
1164     def _parse_numpydoc_see_also_section(self, content: List[str]) -> List[str]:
1165         """
1166         Derived from the NumpyDoc implementation of _parse_see_also.
1167 
1168         See Also
1169         --------
1170         func_name : Descriptive text
1171             continued text
1172         another_func_name : Descriptive text
1173         func_name1, func_name2, :meth:`func_name`, func_name3
1174 
1175         """
1176         items = []
1177 
1178         def parse_item_name(text: str) -> Tuple[str, str]:
1179             """Match ':role:`name`' or 'name'"""
1180             m = self._name_rgx.match(text)
1181             if m:
1182                 g = m.groups()
1183                 if g[1] is None:
1184                     return g[3], None
1185                 else:
1186                     return g[2], g[1]
1187             raise ValueError("%s is not a item name" % text)
1188 
1189         def push_item(name: str, rest: List[str]) -> None:
1190             if not name:
1191                 return
1192             name, role = parse_item_name(name)
1193             items.append((name, list(rest), role))
1194             del rest[:]
1195 
1196         def translate(func, description, role):
1197             translations = self._config.napoleon_type_aliases
1198             if role is not None or not translations:
1199                 return func, description, role
1200 
1201             translated = translations.get(func, func)
1202             match = self._name_rgx.match(translated)
1203             if not match:
1204                 return translated, description, role
1205 
1206             groups = match.groupdict()
1207             role = groups["role"]
1208             new_func = groups["name"] or groups["name2"]
1209 
1210             return new_func, description, role
1211 
1212         current_func = None
1213         rest = []  # type: List[str]
1214 
1215         for line in content:
1216             if not line.strip():
1217                 continue
1218 
1219             m = self._name_rgx.match(line)
1220             if m and line[m.end():].strip().startswith(':'):
1221                 push_item(current_func, rest)
1222                 current_func, line = line[:m.end()], line[m.end():]
1223                 rest = [line.split(':', 1)[1].strip()]
1224                 if not rest[0]:
1225                     rest = []
1226             elif not line.startswith(' '):
1227                 push_item(current_func, rest)
1228                 current_func = None
1229                 if ',' in line:
1230                     for func in line.split(','):
1231                         if func.strip():
1232                             push_item(func, [])
1233                 elif line.strip():
1234                     current_func = line
1235             elif current_func is not None:
1236                 rest.append(line.strip())
1237         push_item(current_func, rest)
1238 
1239         if not items:
1240             return []
1241 
1242         # apply type aliases
1243         items = [
1244             translate(func, description, role)
1245             for func, description, role in items
1246         ]
1247 
1248         lines = []  # type: List[str]
1249         last_had_desc = True
1250         for name, desc, role in items:
1251             if role:
1252                 link = ':%s:`%s`' % (role, name)
1253             else:
1254                 link = ':obj:`%s`' % name
1255             if desc or last_had_desc:
1256                 lines += ['']
1257                 lines += [link]
1258             else:
1259                 lines[-1] += ", %s" % link
1260             if desc:
1261                 lines += self._indent([' '.join(desc)])
1262                 last_had_desc = True
1263             else:
1264                 last_had_desc = False
1265         lines += ['']
1266 
1267         return self._format_admonition('seealso', lines)

</code><intended_behavior>Modify or enhance the docstring parsing functionality to better integrate type hints from the source code into the attribute documentation generated from Google-style docstrings. This could involve checking for existing type hints and preventing the generation of duplicate attribute entries, one from the docstring and one from the type hint, thereby merging them into a single entry.</intended_behavior>, <file>sphinx/ext/autodoc/typehints.py</file>
<class>None</class>
<method>None</method>
<code>
1 """
2     sphinx.ext.autodoc.typehints
3     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
4 
5     Generating content for autodoc using typehints
6 
7     :copyright: Copyright 2007-2020 by the Sphinx team, see AUTHORS.
8     :license: BSD, see LICENSE for details.
9 """
10 
11 import re
12 from collections import OrderedDict
13 from typing import Any, Dict, Iterable, cast
14 
15 from docutils import nodes
16 from docutils.nodes import Element
17 
18 from sphinx import addnodes
19 from sphinx.application import Sphinx
20 from sphinx.util import inspect, typing
21 
22 
23 def record_typehints(app: Sphinx, objtype: str, name: str, obj: Any,
24                      options: Dict, args: str, retann: str) -> None:
25     """Record type hints to env object."""
26     try:
27         if callable(obj):
28             annotations = app.env.temp_data.setdefault('annotations', {})
29             annotation = annotations.setdefault(name, OrderedDict())
30             sig = inspect.signature(obj, type_aliases=app.config.autodoc_type_aliases)
31             for param in sig.parameters.values():
32                 if param.annotation is not param.empty:
33                     annotation[param.name] = typing.stringify(param.annotation)
34             if sig.return_annotation is not sig.empty:
35                 annotation['return'] = typing.stringify(sig.return_annotation)
36     except (TypeError, ValueError):
37         pass
38 
39 
40 def merge_typehints(app: Sphinx, domain: str, objtype: str, contentnode: Element) -> None:
41     if domain != 'py':
42         return
43     if app.config.autodoc_typehints != 'description':
44         return
45     if objtype == 'class' and app.config.autoclass_content not in ('init', 'both'):
46         return
47 
48     try:
49         signature = cast(addnodes.desc_signature, contentnode.parent[0])
50         if signature['module']:
51             fullname = '.'.join([signature['module'], signature['fullname']])
52         else:
53             fullname = signature['fullname']
54     except KeyError:
55         # signature node does not have valid context info for the target object
56         return
57 
58     annotations = app.env.temp_data.get('annotations', {})
59     if annotations.get(fullname, {}):
60         field_lists = [n for n in contentnode if isinstance(n, nodes.field_list)]
61         if field_lists == []:
62             field_list = insert_field_list(contentnode)
63             field_lists.append(field_list)
64 
65         for field_list in field_lists:
66             modify_field_list(field_list, annotations[fullname])
67 
68 
69 def insert_field_list(node: Element) -> nodes.field_list:
70     field_list = nodes.field_list()
71     desc = [n for n in node if isinstance(n, addnodes.desc)]
72     if desc:
73         # insert just before sub object descriptions (ex. methods, nested classes, etc.)
74         index = node.index(desc[0])
75         node.insert(index - 1, [field_list])
76     else:
77         node += field_list
78 
79     return field_list
80 
81 
82 def modify_field_list(node: nodes.field_list, annotations: Dict[str, str]) -> None:
83     arguments = {}  # type: Dict[str, Dict[str, bool]]
84     fields = cast(Iterable[nodes.field], node)
85     for field in fields:
86         field_name = field[0].astext()
87         parts = re.split(' +', field_name)
88         if parts[0] == 'param':
89             if len(parts) == 2:
90                 # :param xxx:
91                 arg = arguments.setdefault(parts[1], {})
92                 arg['param'] = True
93             elif len(parts) > 2:
94                 # :param xxx yyy:
95                 name = ' '.join(parts[2:])
96                 arg = arguments.setdefault(name, {})
97                 arg['param'] = True
98                 arg['type'] = True
99         elif parts[0] == 'type':
100             name = ' '.join(parts[1:])
101             arg = arguments.setdefault(name, {})
102             arg['type'] = True
103         elif parts[0] == 'rtype':
104             arguments['return'] = {'type': True}
105 
106     for name, annotation in annotations.items():
107         if name == 'return':
108             continue
109 
110         arg = arguments.get(name, {})
111         if not arg.get('type'):
112             field = nodes.field()
113             field += nodes.field_name('', 'type ' + name)
114             field += nodes.field_body('', nodes.paragraph('', annotation))
115             node += field
116         if not arg.get('param'):
117             field = nodes.field()
118             field += nodes.field_name('', 'param ' + name)
119             field += nodes.field_body('', nodes.paragraph('', ''))
120             node += field
121 
122     if 'return' in annotations and 'return' not in arguments:
123         field = nodes.field()
124         field += nodes.field_name('', 'rtype')
125         field += nodes.field_body('', nodes.paragraph('', annotation))
126         node += field
127 
128 
129 def setup(app: Sphinx) -> Dict[str, Any]:
130     app.connect('autodoc-process-signature', record_typehints)
131     app.connect('object-description-transform', merge_typehints)
132 
133     return {
134         'version': 'builtin',
135         'parallel_read_safe': True,
136         'parallel_write_safe': True,
137     }

</code><intended_behavior>Enhance the handling of type hints for attributes specifically, with logic to intelligently merge type information with attribute descriptions obtained from docstrings. This process should respect user configurations in `conf.py`, possibly adding new options that allow users to specify their preferred handling method (e.g., prefer docstring types, prefer type hints, merge both with docstring taking precedence, etc.).</intended_behavior>, <file>doc/conf.py</file>
<class>None</class>
<method>None</method>
<code>
1 # Sphinx documentation build configuration file
2 
3 import re
4 
5 import sphinx
6 
7 extensions = ['sphinx.ext.autodoc', 'sphinx.ext.doctest', 'sphinx.ext.todo',
8               'sphinx.ext.autosummary', 'sphinx.ext.extlinks',
9               'sphinx.ext.intersphinx',
10               'sphinx.ext.viewcode', 'sphinx.ext.inheritance_diagram']
11 
12 master_doc = 'contents'
13 templates_path = ['_templates']
14 exclude_patterns = ['_build']
15 
16 project = 'Sphinx'
17 copyright = '2007-2020, Georg Brandl and the Sphinx team'
18 version = sphinx.__display_version__
19 release = version
20 show_authors = True
21 
22 html_theme = 'sphinx13'
23 html_theme_path = ['_themes']
24 modindex_common_prefix = ['sphinx.']
25 html_static_path = ['_static']
26 html_sidebars = {'index': ['indexsidebar.html', 'searchbox.html']}
27 html_additional_pages = {'index': 'index.html'}
28 html_use_opensearch = 'https://www.sphinx-doc.org/en/master'
29 html_baseurl = 'https://www.sphinx-doc.org/en/master/'
30 html_favicon = '_static/favicon.svg'
31 
32 htmlhelp_basename = 'Sphinxdoc'
33 
34 epub_theme = 'epub'
35 epub_basename = 'sphinx'
36 epub_author = 'Georg Brandl'
37 epub_publisher = 'http://sphinx-doc.org/'
38 epub_uid = 'web-site'
39 epub_scheme = 'url'
40 epub_identifier = epub_publisher
41 epub_pre_files = [('index.xhtml', 'Welcome')]
42 epub_post_files = [('usage/installation.xhtml', 'Installing Sphinx'),
43                    ('develop.xhtml', 'Sphinx development')]
44 epub_exclude_files = ['_static/opensearch.xml', '_static/doctools.js',
45                       '_static/jquery.js', '_static/searchtools.js',
46                       '_static/underscore.js', '_static/basic.css',
47                       '_static/language_data.js',
48                       'search.html', '_static/websupport.js']
49 epub_fix_images = False
50 epub_max_image_width = 0
51 epub_show_urls = 'inline'
52 epub_use_index = False
53 epub_guide = (('toc', 'contents.xhtml', 'Table of Contents'),)
54 epub_description = 'Sphinx documentation generator system manual'
55 
56 latex_documents = [('contents', 'sphinx.tex', 'Sphinx Documentation',
57                     'Georg Brandl', 'manual', 1)]
58 latex_logo = '_static/sphinx.png'
59 latex_elements = {
60     'fontenc': r'\usepackage[LGR,X2,T1]{fontenc}',
61     'fontpkg': r'''
62 \usepackage[sc]{mathpazo}
63 \usepackage[scaled]{helvet}
64 \usepackage{courier}
65 \substitutefont{LGR}{\rmdefault}{cmr}
66 \substitutefont{LGR}{\sfdefault}{cmss}
67 \substitutefont{LGR}{\ttdefault}{cmtt}
68 \substitutefont{X2}{\rmdefault}{cmr}
69 \substitutefont{X2}{\sfdefault}{cmss}
70 \substitutefont{X2}{\ttdefault}{cmtt}
71 ''',
72     'passoptionstopackages': '\\PassOptionsToPackage{svgnames}{xcolor}',
73     'preamble': '\\DeclareUnicodeCharacter{229E}{\\ensuremath{\\boxplus}}',
74     'fvset': '\\fvset{fontsize=auto}',
75     # fix missing index entry due to RTD doing only once pdflatex after makeindex
76     'printindex': r'''
77 \IfFileExists{\jobname.ind}
78              {\footnotesize\raggedright\printindex}
79              {\begin{sphinxtheindex}\end{sphinxtheindex}}
80 ''',
81 }
82 latex_show_urls = 'footnote'
83 latex_use_xindy = True
84 
85 autodoc_member_order = 'groupwise'
86 todo_include_todos = True
87 extlinks = {'duref': ('http://docutils.sourceforge.net/docs/ref/rst/'
88                       'restructuredtext.html#%s', ''),
89             'durole': ('http://docutils.sourceforge.net/docs/ref/rst/'
90                        'roles.html#%s', ''),
91             'dudir': ('http://docutils.sourceforge.net/docs/ref/rst/'
92                       'directives.html#%s', '')}
93 
94 man_pages = [
95     ('contents', 'sphinx-all', 'Sphinx documentation generator system manual',
96      'Georg Brandl', 1),
97     ('man/sphinx-build', 'sphinx-build', 'Sphinx documentation generator tool',
98      '', 1),
99     ('man/sphinx-quickstart', 'sphinx-quickstart', 'Sphinx documentation '
100      'template generator', '', 1),
101     ('man/sphinx-apidoc', 'sphinx-apidoc', 'Sphinx API doc generator tool',
102      '', 1),
103     ('man/sphinx-autogen', 'sphinx-autogen', 'Generate autodoc stub pages',
104      '', 1),
105 ]
106 
107 texinfo_documents = [
108     ('contents', 'sphinx', 'Sphinx Documentation', 'Georg Brandl',
109      'Sphinx', 'The Sphinx documentation builder.', 'Documentation tools',
110      1),
111 ]
112 
113 intersphinx_mapping = {'python': ('https://docs.python.org/3/', None)}
114 
115 # Sphinx document translation with sphinx gettext feature uses these settings:
116 locale_dirs = ['locale/']
117 gettext_compact = False
118 
119 
120 # -- Extension interface -------------------------------------------------------
121 
122 from sphinx import addnodes  # noqa
123 
124 event_sig_re = re.compile(r'([a-zA-Z-]+)\s*\((.*)\)')
125 
126 
127 def parse_event(env, sig, signode):
128     m = event_sig_re.match(sig)
129     if not m:
130         signode += addnodes.desc_name(sig, sig)
131         return sig
132     name, args = m.groups()
133     signode += addnodes.desc_name(name, name)
134     plist = addnodes.desc_parameterlist()
135     for arg in args.split(','):
136         arg = arg.strip()
137         plist += addnodes.desc_parameter(arg, arg)
138     signode += plist
139     return name
140 
141 
142 def setup(app):
143     from sphinx.ext.autodoc import cut_lines
144     from sphinx.util.docfields import GroupedField
145     app.connect('autodoc-process-docstring', cut_lines(4, what=['module']))
146     app.add_object_type('confval', 'confval',
147                         objname='configuration value',
148                         indextemplate='pair: %s; configuration value')
149     app.add_object_type('setuptools-confval', 'setuptools-confval',
150                         objname='setuptools configuration value',
151                         indextemplate='pair: %s; setuptools configuration value')
152     fdesc = GroupedField('parameter', label='Parameters',
153                          names=['param'], can_collapse=True)
154     app.add_object_type('event', 'event', 'pair: %s; event', parse_event,
155                         doc_field_types=[fdesc])
156 
157     # workaround for RTD
158     from sphinx.util import logging
159     logger = logging.getLogger(__name__)
160     app.info = lambda *args, **kwargs: logger.info(*args, **kwargs)
161     app.warn = lambda *args, **kwargs: logger.warning(*args, **kwargs)
162     app.debug = lambda *args, **kwargs: logger.debug(*args, **kwargs)

</code><intended_behavior>Introduce new configuration options that provide users with explicit control over how attribute documentation is generated in the presence of both docstrings and type hints. This can include settings to avoid duplication and control the merging behavior.</intended_behavior>]
2025-10-18 18:37:45.741 | INFO     | Overall retry 0 succeeded; ending workflow
2025-10-18 18:37:45.741 | INFO     | Search-only: skipping patch selection
2025-10-18 18:37:45.814 | INFO     | Task sphinx-doc__sphinx-8291 completed successfully.
2025-10-18 18:37:45.815 | INFO     | No patch generated. You can try running ACR again.
