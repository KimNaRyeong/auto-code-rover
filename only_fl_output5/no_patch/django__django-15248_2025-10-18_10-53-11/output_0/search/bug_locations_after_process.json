[
    {
        "rel_file_path": "django/db/models/deletion.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__4.1/django/db/models/deletion.py",
        "start": 381,
        "end": 449,
        "class_name": "Collector",
        "method_name": "delete",
        "code": "381     def delete(self):\n382         # sort instance collections\n383         for model, instances in self.data.items():\n384             self.data[model] = sorted(instances, key=attrgetter(\"pk\"))\n385 \n386         # if possible, bring the models in an order suitable for databases that\n387         # don't support transactions or cannot defer constraint checks until the\n388         # end of a transaction.\n389         self.sort()\n390         # number of objects deleted for each model label\n391         deleted_counter = Counter()\n392 \n393         # Optimize for the case with a single obj and no dependencies\n394         if len(self.data) == 1 and len(instances) == 1:\n395             instance = list(instances)[0]\n396             if self.can_fast_delete(instance):\n397                 with transaction.mark_for_rollback_on_error(self.using):\n398                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n399                 setattr(instance, model._meta.pk.attname, None)\n400                 return count, {model._meta.label: count}\n401 \n402         with transaction.atomic(using=self.using, savepoint=False):\n403             # send pre_delete signals\n404             for model, obj in self.instances_with_model():\n405                 if not model._meta.auto_created:\n406                     signals.pre_delete.send(\n407                         sender=model, instance=obj, using=self.using\n408                     )\n409 \n410             # fast deletes\n411             for qs in self.fast_deletes:\n412                 count = qs._raw_delete(using=self.using)\n413                 if count:\n414                     deleted_counter[qs.model._meta.label] += count\n415 \n416             # update fields\n417             for model, instances_for_fieldvalues in self.field_updates.items():\n418                 for (field, value), instances in instances_for_fieldvalues.items():\n419                     query = sql.UpdateQuery(model)\n420                     query.update_batch([obj.pk for obj in instances],\n421                                        {field.name: value}, self.using)\n422 \n423             # reverse instance collections\n424             for instances in self.data.values():\n425                 instances.reverse()\n426 \n427             # delete instances\n428             for model, instances in self.data.items():\n429                 query = sql.DeleteQuery(model)\n430                 pk_list = [obj.pk for obj in instances]\n431                 count = query.delete_batch(pk_list, self.using)\n432                 if count:\n433                     deleted_counter[model._meta.label] += count\n434 \n435                 if not model._meta.auto_created:\n436                     for obj in instances:\n437                         signals.post_delete.send(\n438                             sender=model, instance=obj, using=self.using\n439                         )\n440 \n441         # update collected instances\n442         for instances_for_fieldvalues in self.field_updates.values():\n443             for (field, value), instances in instances_for_fieldvalues.items():\n444                 for obj in instances:\n445                     setattr(obj, field.attname, value)\n446         for model, instances in self.data.items():\n447             for instance in instances:\n448                 setattr(instance, model._meta.pk.attname, None)\n449         return sum(deleted_counter.values()), dict(deleted_counter)\n",
        "intended_behavior": "The `delete` method within the `Collector` class should be enhanced to include additional context when dispatching both `pre_delete` and `post_delete` signals. Specifically, the method should be modified to carry information about the deletion's origin, differentiating between deletions initiated via a model instance (`model.delete()`) versus those initiated via a queryset (`queryset.delete()`). This could be accomplished by introducing a new parameter to the signal, such as `deletion_origin` that could be set to an appropriate value based on the context of the deletion call within the `delete` method workflow. This enhancement should be implemented in a way that ensures backward compatibility with existing signal receivers that might not expect the new parameter. As such, the addition should be optional or managed in a way that non-expecting receivers can ignore it without issues. The primary goal is to enrich the context provided by deletion signals without disrupting existing functionalities or signal handling implementations."
    },
    {
        "rel_file_path": "django/db/models/deletion.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__4.1/django/db/models/deletion.py",
        "start": 78,
        "end": 449,
        "class_name": "Collector",
        "method_name": null,
        "code": "78 class Collector:\n79     def __init__(self, using):\n80         self.using = using\n81         # Initially, {model: {instances}}, later values become lists.\n82         self.data = defaultdict(set)\n83         # {model: {(field, value): {instances}}}\n84         self.field_updates = defaultdict(partial(defaultdict, set))\n85         # {model: {field: {instances}}}\n86         self.restricted_objects = defaultdict(partial(defaultdict, set))\n87         # fast_deletes is a list of queryset-likes that can be deleted without\n88         # fetching the objects into memory.\n89         self.fast_deletes = []\n90 \n91         # Tracks deletion-order dependency for databases without transactions\n92         # or ability to defer constraint checks. Only concrete model classes\n93         # should be included, as the dependencies exist only between actual\n94         # database tables; proxy models are represented here by their concrete\n95         # parent.\n96         self.dependencies = defaultdict(set)  # {model: {models}}\n97 \n98     def add(self, objs, source=None, nullable=False, reverse_dependency=False):\n99         \"\"\"\n100         Add 'objs' to the collection of objects to be deleted.  If the call is\n101         the result of a cascade, 'source' should be the model that caused it,\n102         and 'nullable' should be set to True if the relation can be null.\n103 \n104         Return a list of all objects that were not already collected.\n105         \"\"\"\n106         if not objs:\n107             return []\n108         new_objs = []\n109         model = objs[0].__class__\n110         instances = self.data[model]\n111         for obj in objs:\n112             if obj not in instances:\n113                 new_objs.append(obj)\n114         instances.update(new_objs)\n115         # Nullable relationships can be ignored -- they are nulled out before\n116         # deleting, and therefore do not affect the order in which objects have\n117         # to be deleted.\n118         if source is not None and not nullable:\n119             self.add_dependency(source, model, reverse_dependency=reverse_dependency)\n120         return new_objs\n121 \n122     def add_dependency(self, model, dependency, reverse_dependency=False):\n123         if reverse_dependency:\n124             model, dependency = dependency, model\n125         self.dependencies[model._meta.concrete_model].add(dependency._meta.concrete_model)\n126         self.data.setdefault(dependency, self.data.default_factory())\n127 \n128     def add_field_update(self, field, value, objs):\n129         \"\"\"\n130         Schedule a field update. 'objs' must be a homogeneous iterable\n131         collection of model instances (e.g. a QuerySet).\n132         \"\"\"\n133         if not objs:\n134             return\n135         model = objs[0].__class__\n136         self.field_updates[model][field, value].update(objs)\n137 \n138     def add_restricted_objects(self, field, objs):\n139         if objs:\n140             model = objs[0].__class__\n141             self.restricted_objects[model][field].update(objs)\n142 \n143     def clear_restricted_objects_from_set(self, model, objs):\n144         if model in self.restricted_objects:\n145             self.restricted_objects[model] = {\n146                 field: items - objs\n147                 for field, items in self.restricted_objects[model].items()\n148             }\n149 \n150     def clear_restricted_objects_from_queryset(self, model, qs):\n151         if model in self.restricted_objects:\n152             objs = set(qs.filter(pk__in=[\n153                 obj.pk\n154                 for objs in self.restricted_objects[model].values() for obj in objs\n155             ]))\n156             self.clear_restricted_objects_from_set(model, objs)\n157 \n158     def _has_signal_listeners(self, model):\n159         return (\n160             signals.pre_delete.has_listeners(model) or\n161             signals.post_delete.has_listeners(model)\n162         )\n163 \n164     def can_fast_delete(self, objs, from_field=None):\n165         \"\"\"\n166         Determine if the objects in the given queryset-like or single object\n167         can be fast-deleted. This can be done if there are no cascades, no\n168         parents and no signal listeners for the object class.\n169 \n170         The 'from_field' tells where we are coming from - we need this to\n171         determine if the objects are in fact to be deleted. Allow also\n172         skipping parent -> child -> parent chain preventing fast delete of\n173         the child.\n174         \"\"\"\n175         if from_field and from_field.remote_field.on_delete is not CASCADE:\n176             return False\n177         if hasattr(objs, '_meta'):\n178             model = objs._meta.model\n179         elif hasattr(objs, 'model') and hasattr(objs, '_raw_delete'):\n180             model = objs.model\n181         else:\n182             return False\n183         if self._has_signal_listeners(model):\n184             return False\n185         # The use of from_field comes from the need to avoid cascade back to\n186         # parent when parent delete is cascading to child.\n187         opts = model._meta\n188         return (\n189             all(link == from_field for link in opts.concrete_model._meta.parents.values()) and\n190             # Foreign keys pointing to this model.\n191             all(\n192                 related.field.remote_field.on_delete is DO_NOTHING\n193                 for related in get_candidate_relations_to_delete(opts)\n194             ) and (\n195                 # Something like generic foreign key.\n196                 not any(hasattr(field, 'bulk_related_objects') for field in opts.private_fields)\n197             )\n198         )\n199 \n200     def get_del_batches(self, objs, fields):\n201         \"\"\"\n202         Return the objs in suitably sized batches for the used connection.\n203         \"\"\"\n204         field_names = [field.name for field in fields]\n205         conn_batch_size = max(\n206             connections[self.using].ops.bulk_batch_size(field_names, objs), 1)\n207         if len(objs) > conn_batch_size:\n208             return [objs[i:i + conn_batch_size]\n209                     for i in range(0, len(objs), conn_batch_size)]\n210         else:\n211             return [objs]\n212 \n213     def collect(self, objs, source=None, nullable=False, collect_related=True,\n214                 source_attr=None, reverse_dependency=False, keep_parents=False,\n215                 fail_on_restricted=True):\n216         \"\"\"\n217         Add 'objs' to the collection of objects to be deleted as well as all\n218         parent instances.  'objs' must be a homogeneous iterable collection of\n219         model instances (e.g. a QuerySet).  If 'collect_related' is True,\n220         related objects will be handled by their respective on_delete handler.\n221 \n222         If the call is the result of a cascade, 'source' should be the model\n223         that caused it and 'nullable' should be set to True, if the relation\n224         can be null.\n225 \n226         If 'reverse_dependency' is True, 'source' will be deleted before the\n227         current model, rather than after. (Needed for cascading to parent\n228         models, the one case in which the cascade follows the forwards\n229         direction of an FK rather than the reverse direction.)\n230 \n231         If 'keep_parents' is True, data of parent model's will be not deleted.\n232 \n233         If 'fail_on_restricted' is False, error won't be raised even if it's\n234         prohibited to delete such objects due to RESTRICT, that defers\n235         restricted object checking in recursive calls where the top-level call\n236         may need to collect more objects to determine whether restricted ones\n237         can be deleted.\n238         \"\"\"\n239         if self.can_fast_delete(objs):\n240             self.fast_deletes.append(objs)\n241             return\n242         new_objs = self.add(objs, source, nullable,\n243                             reverse_dependency=reverse_dependency)\n244         if not new_objs:\n245             return\n246 \n247         model = new_objs[0].__class__\n248 \n249         if not keep_parents:\n250             # Recursively collect concrete model's parent models, but not their\n251             # related objects. These will be found by meta.get_fields()\n252             concrete_model = model._meta.concrete_model\n253             for ptr in concrete_model._meta.parents.values():\n254                 if ptr:\n255                     parent_objs = [getattr(obj, ptr.name) for obj in new_objs]\n256                     self.collect(parent_objs, source=model,\n257                                  source_attr=ptr.remote_field.related_name,\n258                                  collect_related=False,\n259                                  reverse_dependency=True,\n260                                  fail_on_restricted=False)\n261         if not collect_related:\n262             return\n263 \n264         if keep_parents:\n265             parents = set(model._meta.get_parent_list())\n266         model_fast_deletes = defaultdict(list)\n267         protected_objects = defaultdict(list)\n268         for related in get_candidate_relations_to_delete(model._meta):\n269             # Preserve parent reverse relationships if keep_parents=True.\n270             if keep_parents and related.model in parents:\n271                 continue\n272             field = related.field\n273             if field.remote_field.on_delete == DO_NOTHING:\n274                 continue\n275             related_model = related.related_model\n276             if self.can_fast_delete(related_model, from_field=field):\n277                 model_fast_deletes[related_model].append(field)\n278                 continue\n279             batches = self.get_del_batches(new_objs, [field])\n280             for batch in batches:\n281                 sub_objs = self.related_objects(related_model, [field], batch)\n282                 # Non-referenced fields can be deferred if no signal receivers\n283                 # are connected for the related model as they'll never be\n284                 # exposed to the user. Skip field deferring when some\n285                 # relationships are select_related as interactions between both\n286                 # features are hard to get right. This should only happen in\n287                 # the rare cases where .related_objects is overridden anyway.\n288                 if not (sub_objs.query.select_related or self._has_signal_listeners(related_model)):\n289                     referenced_fields = set(chain.from_iterable(\n290                         (rf.attname for rf in rel.field.foreign_related_fields)\n291                         for rel in get_candidate_relations_to_delete(related_model._meta)\n292                     ))\n293                     sub_objs = sub_objs.only(*tuple(referenced_fields))\n294                 if sub_objs:\n295                     try:\n296                         field.remote_field.on_delete(self, field, sub_objs, self.using)\n297                     except ProtectedError as error:\n298                         key = \"'%s.%s'\" % (field.model.__name__, field.name)\n299                         protected_objects[key] += error.protected_objects\n300         if protected_objects:\n301             raise ProtectedError(\n302                 'Cannot delete some instances of model %r because they are '\n303                 'referenced through protected foreign keys: %s.' % (\n304                     model.__name__,\n305                     ', '.join(protected_objects),\n306                 ),\n307                 set(chain.from_iterable(protected_objects.values())),\n308             )\n309         for related_model, related_fields in model_fast_deletes.items():\n310             batches = self.get_del_batches(new_objs, related_fields)\n311             for batch in batches:\n312                 sub_objs = self.related_objects(related_model, related_fields, batch)\n313                 self.fast_deletes.append(sub_objs)\n314         for field in model._meta.private_fields:\n315             if hasattr(field, 'bulk_related_objects'):\n316                 # It's something like generic foreign key.\n317                 sub_objs = field.bulk_related_objects(new_objs, self.using)\n318                 self.collect(sub_objs, source=model, nullable=True, fail_on_restricted=False)\n319 \n320         if fail_on_restricted:\n321             # Raise an error if collected restricted objects (RESTRICT) aren't\n322             # candidates for deletion also collected via CASCADE.\n323             for related_model, instances in self.data.items():\n324                 self.clear_restricted_objects_from_set(related_model, instances)\n325             for qs in self.fast_deletes:\n326                 self.clear_restricted_objects_from_queryset(qs.model, qs)\n327             if self.restricted_objects.values():\n328                 restricted_objects = defaultdict(list)\n329                 for related_model, fields in self.restricted_objects.items():\n330                     for field, objs in fields.items():\n331                         if objs:\n332                             key = \"'%s.%s'\" % (related_model.__name__, field.name)\n333                             restricted_objects[key] += objs\n334                 if restricted_objects:\n335                     raise RestrictedError(\n336                         'Cannot delete some instances of model %r because '\n337                         'they are referenced through restricted foreign keys: '\n338                         '%s.' % (\n339                             model.__name__,\n340                             ', '.join(restricted_objects),\n341                         ),\n342                         set(chain.from_iterable(restricted_objects.values())),\n343                     )\n344 \n345     def related_objects(self, related_model, related_fields, objs):\n346         \"\"\"\n347         Get a QuerySet of the related model to objs via related fields.\n348         \"\"\"\n349         predicate = query_utils.Q(\n350             *(\n351                 (f'{related_field.name}__in', objs)\n352                 for related_field in related_fields\n353             ),\n354             _connector=query_utils.Q.OR,\n355         )\n356         return related_model._base_manager.using(self.using).filter(predicate)\n357 \n358     def instances_with_model(self):\n359         for model, instances in self.data.items():\n360             for obj in instances:\n361                 yield model, obj\n362 \n363     def sort(self):\n364         sorted_models = []\n365         concrete_models = set()\n366         models = list(self.data)\n367         while len(sorted_models) < len(models):\n368             found = False\n369             for model in models:\n370                 if model in sorted_models:\n371                     continue\n372                 dependencies = self.dependencies.get(model._meta.concrete_model)\n373                 if not (dependencies and dependencies.difference(concrete_models)):\n374                     sorted_models.append(model)\n375                     concrete_models.add(model._meta.concrete_model)\n376                     found = True\n377             if not found:\n378                 return\n379         self.data = {model: self.data[model] for model in sorted_models}\n380 \n381     def delete(self):\n382         # sort instance collections\n383         for model, instances in self.data.items():\n384             self.data[model] = sorted(instances, key=attrgetter(\"pk\"))\n385 \n386         # if possible, bring the models in an order suitable for databases that\n387         # don't support transactions or cannot defer constraint checks until the\n388         # end of a transaction.\n389         self.sort()\n390         # number of objects deleted for each model label\n391         deleted_counter = Counter()\n392 \n393         # Optimize for the case with a single obj and no dependencies\n394         if len(self.data) == 1 and len(instances) == 1:\n395             instance = list(instances)[0]\n396             if self.can_fast_delete(instance):\n397                 with transaction.mark_for_rollback_on_error(self.using):\n398                     count = sql.DeleteQuery(model).delete_batch([instance.pk], self.using)\n399                 setattr(instance, model._meta.pk.attname, None)\n400                 return count, {model._meta.label: count}\n401 \n402         with transaction.atomic(using=self.using, savepoint=False):\n403             # send pre_delete signals\n404             for model, obj in self.instances_with_model():\n405                 if not model._meta.auto_created:\n406                     signals.pre_delete.send(\n407                         sender=model, instance=obj, using=self.using\n408                     )\n409 \n410             # fast deletes\n411             for qs in self.fast_deletes:\n412                 count = qs._raw_delete(using=self.using)\n413                 if count:\n414                     deleted_counter[qs.model._meta.label] += count\n415 \n416             # update fields\n417             for model, instances_for_fieldvalues in self.field_updates.items():\n418                 for (field, value), instances in instances_for_fieldvalues.items():\n419                     query = sql.UpdateQuery(model)\n420                     query.update_batch([obj.pk for obj in instances],\n421                                        {field.name: value}, self.using)\n422 \n423             # reverse instance collections\n424             for instances in self.data.values():\n425                 instances.reverse()\n426 \n427             # delete instances\n428             for model, instances in self.data.items():\n429                 query = sql.DeleteQuery(model)\n430                 pk_list = [obj.pk for obj in instances]\n431                 count = query.delete_batch(pk_list, self.using)\n432                 if count:\n433                     deleted_counter[model._meta.label] += count\n434 \n435                 if not model._meta.auto_created:\n436                     for obj in instances:\n437                         signals.post_delete.send(\n438                             sender=model, instance=obj, using=self.using\n439                         )\n440 \n441         # update collected instances\n442         for instances_for_fieldvalues in self.field_updates.values():\n443             for (field, value), instances in instances_for_fieldvalues.items():\n444                 for obj in instances:\n445                     setattr(obj, field.attname, value)\n446         for model, instances in self.data.items():\n447             for instance in instances:\n448                 setattr(instance, model._meta.pk.attname, None)\n449         return sum(deleted_counter.values()), dict(deleted_counter)\n",
        "intended_behavior": "This class provides additional context to the issue."
    }
]