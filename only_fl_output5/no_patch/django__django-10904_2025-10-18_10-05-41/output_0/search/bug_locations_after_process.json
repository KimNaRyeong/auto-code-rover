[
    {
        "rel_file_path": "django/middleware/csrf.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.0/django/middleware/csrf.py",
        "start": 1,
        "end": 327,
        "class_name": null,
        "method_name": null,
        "code": "1 \"\"\"\n2 Cross Site Request Forgery Middleware.\n3 \n4 This module provides a middleware that implements protection\n5 against request forgeries from other sites.\n6 \"\"\"\n7 import logging\n8 import re\n9 import string\n10 from urllib.parse import urlparse\n11 \n12 from django.conf import settings\n13 from django.core.exceptions import DisallowedHost, ImproperlyConfigured\n14 from django.urls import get_callable\n15 from django.utils.cache import patch_vary_headers\n16 from django.utils.crypto import constant_time_compare, get_random_string\n17 from django.utils.deprecation import MiddlewareMixin\n18 from django.utils.http import is_same_domain\n19 from django.utils.log import log_response\n20 \n21 logger = logging.getLogger('django.security.csrf')\n22 \n23 REASON_NO_REFERER = \"Referer checking failed - no Referer.\"\n24 REASON_BAD_REFERER = \"Referer checking failed - %s does not match any trusted origins.\"\n25 REASON_NO_CSRF_COOKIE = \"CSRF cookie not set.\"\n26 REASON_BAD_TOKEN = \"CSRF token missing or incorrect.\"\n27 REASON_MALFORMED_REFERER = \"Referer checking failed - Referer is malformed.\"\n28 REASON_INSECURE_REFERER = \"Referer checking failed - Referer is insecure while host is secure.\"\n29 \n30 CSRF_SECRET_LENGTH = 32\n31 CSRF_TOKEN_LENGTH = 2 * CSRF_SECRET_LENGTH\n32 CSRF_ALLOWED_CHARS = string.ascii_letters + string.digits\n33 CSRF_SESSION_KEY = '_csrftoken'\n34 \n35 \n36 def _get_failure_view():\n37     \"\"\"Return the view to be used for CSRF rejections.\"\"\"\n38     return get_callable(settings.CSRF_FAILURE_VIEW)\n39 \n40 \n41 def _get_new_csrf_string():\n42     return get_random_string(CSRF_SECRET_LENGTH, allowed_chars=CSRF_ALLOWED_CHARS)\n43 \n44 \n45 def _salt_cipher_secret(secret):\n46     \"\"\"\n47     Given a secret (assumed to be a string of CSRF_ALLOWED_CHARS), generate a\n48     token by adding a salt and using it to encrypt the secret.\n49     \"\"\"\n50     salt = _get_new_csrf_string()\n51     chars = CSRF_ALLOWED_CHARS\n52     pairs = zip((chars.index(x) for x in secret), (chars.index(x) for x in salt))\n53     cipher = ''.join(chars[(x + y) % len(chars)] for x, y in pairs)\n54     return salt + cipher\n55 \n56 \n57 def _unsalt_cipher_token(token):\n58     \"\"\"\n59     Given a token (assumed to be a string of CSRF_ALLOWED_CHARS, of length\n60     CSRF_TOKEN_LENGTH, and that its first half is a salt), use it to decrypt\n61     the second half to produce the original secret.\n62     \"\"\"\n63     salt = token[:CSRF_SECRET_LENGTH]\n64     token = token[CSRF_SECRET_LENGTH:]\n65     chars = CSRF_ALLOWED_CHARS\n66     pairs = zip((chars.index(x) for x in token), (chars.index(x) for x in salt))\n67     secret = ''.join(chars[x - y] for x, y in pairs)  # Note negative values are ok\n68     return secret\n69 \n70 \n71 def _get_new_csrf_token():\n72     return _salt_cipher_secret(_get_new_csrf_string())\n73 \n74 \n75 def get_token(request):\n76     \"\"\"\n77     Return the CSRF token required for a POST form. The token is an\n78     alphanumeric value. A new token is created if one is not already set.\n79 \n80     A side effect of calling this function is to make the csrf_protect\n81     decorator and the CsrfViewMiddleware add a CSRF cookie and a 'Vary: Cookie'\n82     header to the outgoing response.  For this reason, you may need to use this\n83     function lazily, as is done by the csrf context processor.\n84     \"\"\"\n85     if \"CSRF_COOKIE\" not in request.META:\n86         csrf_secret = _get_new_csrf_string()\n87         request.META[\"CSRF_COOKIE\"] = _salt_cipher_secret(csrf_secret)\n88     else:\n89         csrf_secret = _unsalt_cipher_token(request.META[\"CSRF_COOKIE\"])\n90     request.META[\"CSRF_COOKIE_USED\"] = True\n91     return _salt_cipher_secret(csrf_secret)\n92 \n93 \n94 def rotate_token(request):\n95     \"\"\"\n96     Change the CSRF token in use for a request - should be done on login\n97     for security purposes.\n98     \"\"\"\n99     request.META.update({\n100         \"CSRF_COOKIE_USED\": True,\n101         \"CSRF_COOKIE\": _get_new_csrf_token(),\n102     })\n103     request.csrf_cookie_needs_reset = True\n104 \n105 \n106 def _sanitize_token(token):\n107     # Allow only ASCII alphanumerics\n108     if re.search('[^a-zA-Z0-9]', token):\n109         return _get_new_csrf_token()\n110     elif len(token) == CSRF_TOKEN_LENGTH:\n111         return token\n112     elif len(token) == CSRF_SECRET_LENGTH:\n113         # Older Django versions set cookies to values of CSRF_SECRET_LENGTH\n114         # alphanumeric characters. For backwards compatibility, accept\n115         # such values as unsalted secrets.\n116         # It's easier to salt here and be consistent later, rather than add\n117         # different code paths in the checks, although that might be a tad more\n118         # efficient.\n119         return _salt_cipher_secret(token)\n120     return _get_new_csrf_token()\n121 \n122 \n123 def _compare_salted_tokens(request_csrf_token, csrf_token):\n124     # Assume both arguments are sanitized -- that is, strings of\n125     # length CSRF_TOKEN_LENGTH, all CSRF_ALLOWED_CHARS.\n126     return constant_time_compare(\n127         _unsalt_cipher_token(request_csrf_token),\n128         _unsalt_cipher_token(csrf_token),\n129     )\n130 \n131 \n132 class CsrfViewMiddleware(MiddlewareMixin):\n133     \"\"\"\n134     Require a present and correct csrfmiddlewaretoken for POST requests that\n135     have a CSRF cookie, and set an outgoing CSRF cookie.\n136 \n137     This middleware should be used in conjunction with the {% csrf_token %}\n138     template tag.\n139     \"\"\"\n140     # The _accept and _reject methods currently only exist for the sake of the\n141     # requires_csrf_token decorator.\n142     def _accept(self, request):\n143         # Avoid checking the request twice by adding a custom attribute to\n144         # request.  This will be relevant when both decorator and middleware\n145         # are used.\n146         request.csrf_processing_done = True\n147         return None\n148 \n149     def _reject(self, request, reason):\n150         response = _get_failure_view()(request, reason=reason)\n151         log_response(\n152             'Forbidden (%s): %s', reason, request.path,\n153             response=response,\n154             request=request,\n155             logger=logger,\n156         )\n157         return response\n158 \n159     def _get_token(self, request):\n160         if settings.CSRF_USE_SESSIONS:\n161             try:\n162                 return request.session.get(CSRF_SESSION_KEY)\n163             except AttributeError:\n164                 raise ImproperlyConfigured(\n165                     'CSRF_USE_SESSIONS is enabled, but request.session is not '\n166                     'set. SessionMiddleware must appear before CsrfViewMiddleware '\n167                     'in MIDDLEWARE%s.' % ('_CLASSES' if settings.MIDDLEWARE is None else '')\n168                 )\n169         else:\n170             try:\n171                 cookie_token = request.COOKIES[settings.CSRF_COOKIE_NAME]\n172             except KeyError:\n173                 return None\n174 \n175             csrf_token = _sanitize_token(cookie_token)\n176             if csrf_token != cookie_token:\n177                 # Cookie token needed to be replaced;\n178                 # the cookie needs to be reset.\n179                 request.csrf_cookie_needs_reset = True\n180             return csrf_token\n181 \n182     def _set_token(self, request, response):\n183         if settings.CSRF_USE_SESSIONS:\n184             if request.session.get(CSRF_SESSION_KEY) != request.META['CSRF_COOKIE']:\n185                 request.session[CSRF_SESSION_KEY] = request.META['CSRF_COOKIE']\n186         else:\n187             response.set_cookie(\n188                 settings.CSRF_COOKIE_NAME,\n189                 request.META['CSRF_COOKIE'],\n190                 max_age=settings.CSRF_COOKIE_AGE,\n191                 domain=settings.CSRF_COOKIE_DOMAIN,\n192                 path=settings.CSRF_COOKIE_PATH,\n193                 secure=settings.CSRF_COOKIE_SECURE,\n194                 httponly=settings.CSRF_COOKIE_HTTPONLY,\n195                 samesite=settings.CSRF_COOKIE_SAMESITE,\n196             )\n197             # Set the Vary header since content varies with the CSRF cookie.\n198             patch_vary_headers(response, ('Cookie',))\n199 \n200     def process_request(self, request):\n201         csrf_token = self._get_token(request)\n202         if csrf_token is not None:\n203             # Use same token next time.\n204             request.META['CSRF_COOKIE'] = csrf_token\n205 \n206     def process_view(self, request, callback, callback_args, callback_kwargs):\n207         if getattr(request, 'csrf_processing_done', False):\n208             return None\n209 \n210         # Wait until request.META[\"CSRF_COOKIE\"] has been manipulated before\n211         # bailing out, so that get_token still works\n212         if getattr(callback, 'csrf_exempt', False):\n213             return None\n214 \n215         # Assume that anything not defined as 'safe' by RFC7231 needs protection\n216         if request.method not in ('GET', 'HEAD', 'OPTIONS', 'TRACE'):\n217             if getattr(request, '_dont_enforce_csrf_checks', False):\n218                 # Mechanism to turn off CSRF checks for test suite.\n219                 # It comes after the creation of CSRF cookies, so that\n220                 # everything else continues to work exactly the same\n221                 # (e.g. cookies are sent, etc.), but before any\n222                 # branches that call reject().\n223                 return self._accept(request)\n224 \n225             if request.is_secure():\n226                 # Suppose user visits http://example.com/\n227                 # An active network attacker (man-in-the-middle, MITM) sends a\n228                 # POST form that targets https://example.com/detonate-bomb/ and\n229                 # submits it via JavaScript.\n230                 #\n231                 # The attacker will need to provide a CSRF cookie and token, but\n232                 # that's no problem for a MITM and the session-independent\n233                 # secret we're using. So the MITM can circumvent the CSRF\n234                 # protection. This is true for any HTTP connection, but anyone\n235                 # using HTTPS expects better! For this reason, for\n236                 # https://example.com/ we need additional protection that treats\n237                 # http://example.com/ as completely untrusted. Under HTTPS,\n238                 # Barth et al. found that the Referer header is missing for\n239                 # same-domain requests in only about 0.2% of cases or less, so\n240                 # we can use strict Referer checking.\n241                 referer = request.META.get('HTTP_REFERER')\n242                 if referer is None:\n243                     return self._reject(request, REASON_NO_REFERER)\n244 \n245                 referer = urlparse(referer)\n246 \n247                 # Make sure we have a valid URL for Referer.\n248                 if '' in (referer.scheme, referer.netloc):\n249                     return self._reject(request, REASON_MALFORMED_REFERER)\n250 \n251                 # Ensure that our Referer is also secure.\n252                 if referer.scheme != 'https':\n253                     return self._reject(request, REASON_INSECURE_REFERER)\n254 \n255                 # If there isn't a CSRF_COOKIE_DOMAIN, require an exact match\n256                 # match on host:port. If not, obey the cookie rules (or those\n257                 # for the session cookie, if CSRF_USE_SESSIONS).\n258                 good_referer = (\n259                     settings.SESSION_COOKIE_DOMAIN\n260                     if settings.CSRF_USE_SESSIONS\n261                     else settings.CSRF_COOKIE_DOMAIN\n262                 )\n263                 if good_referer is not None:\n264                     server_port = request.get_port()\n265                     if server_port not in ('443', '80'):\n266                         good_referer = '%s:%s' % (good_referer, server_port)\n267                 else:\n268                     try:\n269                         # request.get_host() includes the port.\n270                         good_referer = request.get_host()\n271                     except DisallowedHost:\n272                         pass\n273 \n274                 # Create a list of all acceptable HTTP referers, including the\n275                 # current host if it's permitted by ALLOWED_HOSTS.\n276                 good_hosts = list(settings.CSRF_TRUSTED_ORIGINS)\n277                 if good_referer is not None:\n278                     good_hosts.append(good_referer)\n279 \n280                 if not any(is_same_domain(referer.netloc, host) for host in good_hosts):\n281                     reason = REASON_BAD_REFERER % referer.geturl()\n282                     return self._reject(request, reason)\n283 \n284             csrf_token = request.META.get('CSRF_COOKIE')\n285             if csrf_token is None:\n286                 # No CSRF cookie. For POST requests, we insist on a CSRF cookie,\n287                 # and in this way we can avoid all CSRF attacks, including login\n288                 # CSRF.\n289                 return self._reject(request, REASON_NO_CSRF_COOKIE)\n290 \n291             # Check non-cookie token for match.\n292             request_csrf_token = \"\"\n293             if request.method == \"POST\":\n294                 try:\n295                     request_csrf_token = request.POST.get('csrfmiddlewaretoken', '')\n296                 except IOError:\n297                     # Handle a broken connection before we've completed reading\n298                     # the POST data. process_view shouldn't raise any\n299                     # exceptions, so we'll ignore and serve the user a 403\n300                     # (assuming they're still listening, which they probably\n301                     # aren't because of the error).\n302                     pass\n303 \n304             if request_csrf_token == \"\":\n305                 # Fall back to X-CSRFToken, to make things easier for AJAX,\n306                 # and possible for PUT/DELETE.\n307                 request_csrf_token = request.META.get(settings.CSRF_HEADER_NAME, '')\n308 \n309             request_csrf_token = _sanitize_token(request_csrf_token)\n310             if not _compare_salted_tokens(request_csrf_token, csrf_token):\n311                 return self._reject(request, REASON_BAD_TOKEN)\n312 \n313         return self._accept(request)\n314 \n315     def process_response(self, request, response):\n316         if not getattr(request, 'csrf_cookie_needs_reset', False):\n317             if getattr(response, 'csrf_cookie_set', False):\n318                 return response\n319 \n320         if not request.META.get(\"CSRF_COOKIE_USED\", False):\n321             return response\n322 \n323         # Set the CSRF cookie even if it's already set, so we renew\n324         # the expiry timer.\n325         self._set_token(request, response)\n326         response.csrf_cookie_set = True\n327         return response\n",
        "intended_behavior": "Replace `IOError` with `OSError` while preserving logic for handling IO-related errors during CSRF middleware operations."
    },
    {
        "rel_file_path": "django/http/response.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.0/django/http/response.py",
        "start": 1,
        "end": 558,
        "class_name": null,
        "method_name": null,
        "code": "1 import datetime\n2 import json\n3 import mimetypes\n4 import os\n5 import re\n6 import sys\n7 import time\n8 from email.header import Header\n9 from http.client import responses\n10 from urllib.parse import quote, urlparse\n11 \n12 from django.conf import settings\n13 from django.core import signals, signing\n14 from django.core.exceptions import DisallowedRedirect\n15 from django.core.serializers.json import DjangoJSONEncoder\n16 from django.http.cookie import SimpleCookie\n17 from django.utils import timezone\n18 from django.utils.encoding import iri_to_uri\n19 from django.utils.http import http_date\n20 \n21 _charset_from_content_type_re = re.compile(r';\\s*charset=(?P<charset>[^\\s;]+)', re.I)\n22 \n23 \n24 class BadHeaderError(ValueError):\n25     pass\n26 \n27 \n28 class HttpResponseBase:\n29     \"\"\"\n30     An HTTP response base class with dictionary-accessed headers.\n31 \n32     This class doesn't handle content. It should not be used directly.\n33     Use the HttpResponse and StreamingHttpResponse subclasses instead.\n34     \"\"\"\n35 \n36     status_code = 200\n37 \n38     def __init__(self, content_type=None, status=None, reason=None, charset=None):\n39         # _headers is a mapping of the lowercase name to the original case of\n40         # the header (required for working with legacy systems) and the header\n41         # value. Both the name of the header and its value are ASCII strings.\n42         self._headers = {}\n43         self._closable_objects = []\n44         # This parameter is set by the handler. It's necessary to preserve the\n45         # historical behavior of request_finished.\n46         self._handler_class = None\n47         self.cookies = SimpleCookie()\n48         self.closed = False\n49         if status is not None:\n50             try:\n51                 self.status_code = int(status)\n52             except (ValueError, TypeError):\n53                 raise TypeError('HTTP status code must be an integer.')\n54 \n55             if not 100 <= self.status_code <= 599:\n56                 raise ValueError('HTTP status code must be an integer from 100 to 599.')\n57         self._reason_phrase = reason\n58         self._charset = charset\n59         if content_type is None:\n60             content_type = 'text/html; charset=%s' % self.charset\n61         self['Content-Type'] = content_type\n62 \n63     @property\n64     def reason_phrase(self):\n65         if self._reason_phrase is not None:\n66             return self._reason_phrase\n67         # Leave self._reason_phrase unset in order to use the default\n68         # reason phrase for status code.\n69         return responses.get(self.status_code, 'Unknown Status Code')\n70 \n71     @reason_phrase.setter\n72     def reason_phrase(self, value):\n73         self._reason_phrase = value\n74 \n75     @property\n76     def charset(self):\n77         if self._charset is not None:\n78             return self._charset\n79         content_type = self.get('Content-Type', '')\n80         matched = _charset_from_content_type_re.search(content_type)\n81         if matched:\n82             # Extract the charset and strip its double quotes\n83             return matched.group('charset').replace('\"', '')\n84         return settings.DEFAULT_CHARSET\n85 \n86     @charset.setter\n87     def charset(self, value):\n88         self._charset = value\n89 \n90     def serialize_headers(self):\n91         \"\"\"HTTP headers as a bytestring.\"\"\"\n92         def to_bytes(val, encoding):\n93             return val if isinstance(val, bytes) else val.encode(encoding)\n94 \n95         headers = [\n96             (to_bytes(key, 'ascii') + b': ' + to_bytes(value, 'latin-1'))\n97             for key, value in self._headers.values()\n98         ]\n99         return b'\\r\\n'.join(headers)\n100 \n101     __bytes__ = serialize_headers\n102 \n103     @property\n104     def _content_type_for_repr(self):\n105         return ', \"%s\"' % self['Content-Type'] if 'Content-Type' in self else ''\n106 \n107     def _convert_to_charset(self, value, charset, mime_encode=False):\n108         \"\"\"\n109         Convert headers key/value to ascii/latin-1 native strings.\n110 \n111         `charset` must be 'ascii' or 'latin-1'. If `mime_encode` is True and\n112         `value` can't be represented in the given charset, apply MIME-encoding.\n113         \"\"\"\n114         if not isinstance(value, (bytes, str)):\n115             value = str(value)\n116         if ((isinstance(value, bytes) and (b'\\n' in value or b'\\r' in value)) or\n117                 isinstance(value, str) and ('\\n' in value or '\\r' in value)):\n118             raise BadHeaderError(\"Header values can't contain newlines (got %r)\" % value)\n119         try:\n120             if isinstance(value, str):\n121                 # Ensure string is valid in given charset\n122                 value.encode(charset)\n123             else:\n124                 # Convert bytestring using given charset\n125                 value = value.decode(charset)\n126         except UnicodeError as e:\n127             if mime_encode:\n128                 value = Header(value, 'utf-8', maxlinelen=sys.maxsize).encode()\n129             else:\n130                 e.reason += ', HTTP response headers must be in %s format' % charset\n131                 raise\n132         return value\n133 \n134     def __setitem__(self, header, value):\n135         header = self._convert_to_charset(header, 'ascii')\n136         value = self._convert_to_charset(value, 'latin-1', mime_encode=True)\n137         self._headers[header.lower()] = (header, value)\n138 \n139     def __delitem__(self, header):\n140         self._headers.pop(header.lower(), False)\n141 \n142     def __getitem__(self, header):\n143         return self._headers[header.lower()][1]\n144 \n145     def has_header(self, header):\n146         \"\"\"Case-insensitive check for a header.\"\"\"\n147         return header.lower() in self._headers\n148 \n149     __contains__ = has_header\n150 \n151     def items(self):\n152         return self._headers.values()\n153 \n154     def get(self, header, alternate=None):\n155         return self._headers.get(header.lower(), (None, alternate))[1]\n156 \n157     def set_cookie(self, key, value='', max_age=None, expires=None, path='/',\n158                    domain=None, secure=False, httponly=False, samesite=None):\n159         \"\"\"\n160         Set a cookie.\n161 \n162         ``expires`` can be:\n163         - a string in the correct format,\n164         - a naive ``datetime.datetime`` object in UTC,\n165         - an aware ``datetime.datetime`` object in any time zone.\n166         If it is a ``datetime.datetime`` object then calculate ``max_age``.\n167         \"\"\"\n168         self.cookies[key] = value\n169         if expires is not None:\n170             if isinstance(expires, datetime.datetime):\n171                 if timezone.is_aware(expires):\n172                     expires = timezone.make_naive(expires, timezone.utc)\n173                 delta = expires - expires.utcnow()\n174                 # Add one second so the date matches exactly (a fraction of\n175                 # time gets lost between converting to a timedelta and\n176                 # then the date string).\n177                 delta = delta + datetime.timedelta(seconds=1)\n178                 # Just set max_age - the max_age logic will set expires.\n179                 expires = None\n180                 max_age = max(0, delta.days * 86400 + delta.seconds)\n181             else:\n182                 self.cookies[key]['expires'] = expires\n183         else:\n184             self.cookies[key]['expires'] = ''\n185         if max_age is not None:\n186             self.cookies[key]['max-age'] = max_age\n187             # IE requires expires, so set it if hasn't been already.\n188             if not expires:\n189                 self.cookies[key]['expires'] = http_date(time.time() + max_age)\n190         if path is not None:\n191             self.cookies[key]['path'] = path\n192         if domain is not None:\n193             self.cookies[key]['domain'] = domain\n194         if secure:\n195             self.cookies[key]['secure'] = True\n196         if httponly:\n197             self.cookies[key]['httponly'] = True\n198         if samesite:\n199             if samesite.lower() not in ('lax', 'strict'):\n200                 raise ValueError('samesite must be \"lax\" or \"strict\".')\n201             self.cookies[key]['samesite'] = samesite\n202 \n203     def setdefault(self, key, value):\n204         \"\"\"Set a header unless it has already been set.\"\"\"\n205         if key not in self:\n206             self[key] = value\n207 \n208     def set_signed_cookie(self, key, value, salt='', **kwargs):\n209         value = signing.get_cookie_signer(salt=key + salt).sign(value)\n210         return self.set_cookie(key, value, **kwargs)\n211 \n212     def delete_cookie(self, key, path='/', domain=None):\n213         # Most browsers ignore the Set-Cookie header if the cookie name starts\n214         # with __Host- or __Secure- and the cookie doesn't use the secure flag.\n215         secure = key.startswith(('__Secure-', '__Host-'))\n216         self.set_cookie(\n217             key, max_age=0, path=path, domain=domain, secure=secure,\n218             expires='Thu, 01 Jan 1970 00:00:00 GMT',\n219         )\n220 \n221     # Common methods used by subclasses\n222 \n223     def make_bytes(self, value):\n224         \"\"\"Turn a value into a bytestring encoded in the output charset.\"\"\"\n225         # Per PEP 3333, this response body must be bytes. To avoid returning\n226         # an instance of a subclass, this function returns `bytes(value)`.\n227         # This doesn't make a copy when `value` already contains bytes.\n228 \n229         # Handle string types -- we can't rely on force_bytes here because:\n230         # - Python attempts str conversion first\n231         # - when self._charset != 'utf-8' it re-encodes the content\n232         if isinstance(value, bytes):\n233             return bytes(value)\n234         if isinstance(value, str):\n235             return bytes(value.encode(self.charset))\n236         # Handle non-string types.\n237         return str(value).encode(self.charset)\n238 \n239     # These methods partially implement the file-like object interface.\n240     # See https://docs.python.org/library/io.html#io.IOBase\n241 \n242     # The WSGI server must call this method upon completion of the request.\n243     # See http://blog.dscpl.com.au/2012/10/obligations-for-calling-close-on.html\n244     def close(self):\n245         for closable in self._closable_objects:\n246             try:\n247                 closable.close()\n248             except Exception:\n249                 pass\n250         self.closed = True\n251         signals.request_finished.send(sender=self._handler_class)\n252 \n253     def write(self, content):\n254         raise IOError(\"This %s instance is not writable\" % self.__class__.__name__)\n255 \n256     def flush(self):\n257         pass\n258 \n259     def tell(self):\n260         raise IOError(\"This %s instance cannot tell its position\" % self.__class__.__name__)\n261 \n262     # These methods partially implement a stream-like object interface.\n263     # See https://docs.python.org/library/io.html#io.IOBase\n264 \n265     def readable(self):\n266         return False\n267 \n268     def seekable(self):\n269         return False\n270 \n271     def writable(self):\n272         return False\n273 \n274     def writelines(self, lines):\n275         raise IOError(\"This %s instance is not writable\" % self.__class__.__name__)\n276 \n277 \n278 class HttpResponse(HttpResponseBase):\n279     \"\"\"\n280     An HTTP response class with a string as content.\n281 \n282     This content that can be read, appended to, or replaced.\n283     \"\"\"\n284 \n285     streaming = False\n286 \n287     def __init__(self, content=b'', *args, **kwargs):\n288         super().__init__(*args, **kwargs)\n289         # Content is a bytestring. See the `content` property methods.\n290         self.content = content\n291 \n292     def __repr__(self):\n293         return '<%(cls)s status_code=%(status_code)d%(content_type)s>' % {\n294             'cls': self.__class__.__name__,\n295             'status_code': self.status_code,\n296             'content_type': self._content_type_for_repr,\n297         }\n298 \n299     def serialize(self):\n300         \"\"\"Full HTTP message, including headers, as a bytestring.\"\"\"\n301         return self.serialize_headers() + b'\\r\\n\\r\\n' + self.content\n302 \n303     __bytes__ = serialize\n304 \n305     @property\n306     def content(self):\n307         return b''.join(self._container)\n308 \n309     @content.setter\n310     def content(self, value):\n311         # Consume iterators upon assignment to allow repeated iteration.\n312         if hasattr(value, '__iter__') and not isinstance(value, (bytes, str)):\n313             content = b''.join(self.make_bytes(chunk) for chunk in value)\n314             if hasattr(value, 'close'):\n315                 try:\n316                     value.close()\n317                 except Exception:\n318                     pass\n319         else:\n320             content = self.make_bytes(value)\n321         # Create a list of properly encoded bytestrings to support write().\n322         self._container = [content]\n323 \n324     def __iter__(self):\n325         return iter(self._container)\n326 \n327     def write(self, content):\n328         self._container.append(self.make_bytes(content))\n329 \n330     def tell(self):\n331         return len(self.content)\n332 \n333     def getvalue(self):\n334         return self.content\n335 \n336     def writable(self):\n337         return True\n338 \n339     def writelines(self, lines):\n340         for line in lines:\n341             self.write(line)\n342 \n343 \n344 class StreamingHttpResponse(HttpResponseBase):\n345     \"\"\"\n346     A streaming HTTP response class with an iterator as content.\n347 \n348     This should only be iterated once, when the response is streamed to the\n349     client. However, it can be appended to or replaced with a new iterator\n350     that wraps the original content (or yields entirely new content).\n351     \"\"\"\n352 \n353     streaming = True\n354 \n355     def __init__(self, streaming_content=(), *args, **kwargs):\n356         super().__init__(*args, **kwargs)\n357         # `streaming_content` should be an iterable of bytestrings.\n358         # See the `streaming_content` property methods.\n359         self.streaming_content = streaming_content\n360 \n361     @property\n362     def content(self):\n363         raise AttributeError(\n364             \"This %s instance has no `content` attribute. Use \"\n365             \"`streaming_content` instead.\" % self.__class__.__name__\n366         )\n367 \n368     @property\n369     def streaming_content(self):\n370         return map(self.make_bytes, self._iterator)\n371 \n372     @streaming_content.setter\n373     def streaming_content(self, value):\n374         self._set_streaming_content(value)\n375 \n376     def _set_streaming_content(self, value):\n377         # Ensure we can never iterate on \"value\" more than once.\n378         self._iterator = iter(value)\n379         if hasattr(value, 'close'):\n380             self._closable_objects.append(value)\n381 \n382     def __iter__(self):\n383         return self.streaming_content\n384 \n385     def getvalue(self):\n386         return b''.join(self.streaming_content)\n387 \n388 \n389 class FileResponse(StreamingHttpResponse):\n390     \"\"\"\n391     A streaming HTTP response class optimized for files.\n392     \"\"\"\n393     block_size = 4096\n394 \n395     def __init__(self, *args, as_attachment=False, filename='', **kwargs):\n396         self.as_attachment = as_attachment\n397         self.filename = filename\n398         super().__init__(*args, **kwargs)\n399 \n400     def _set_streaming_content(self, value):\n401         if not hasattr(value, 'read'):\n402             self.file_to_stream = None\n403             return super()._set_streaming_content(value)\n404 \n405         self.file_to_stream = filelike = value\n406         if hasattr(filelike, 'close'):\n407             self._closable_objects.append(filelike)\n408         value = iter(lambda: filelike.read(self.block_size), b'')\n409         self.set_headers(filelike)\n410         super()._set_streaming_content(value)\n411 \n412     def set_headers(self, filelike):\n413         \"\"\"\n414         Set some common response headers (Content-Length, Content-Type, and\n415         Content-Disposition) based on the `filelike` response content.\n416         \"\"\"\n417         encoding_map = {\n418             'bzip2': 'application/x-bzip',\n419             'gzip': 'application/gzip',\n420             'xz': 'application/x-xz',\n421         }\n422         filename = getattr(filelike, 'name', None)\n423         filename = filename if (isinstance(filename, str) and filename) else self.filename\n424         if os.path.isabs(filename):\n425             self['Content-Length'] = os.path.getsize(filelike.name)\n426         elif hasattr(filelike, 'getbuffer'):\n427             self['Content-Length'] = filelike.getbuffer().nbytes\n428 \n429         if self.get('Content-Type', '').startswith('text/html'):\n430             if filename:\n431                 content_type, encoding = mimetypes.guess_type(filename)\n432                 # Encoding isn't set to prevent browsers from automatically\n433                 # uncompressing files.\n434                 content_type = encoding_map.get(encoding, content_type)\n435                 self['Content-Type'] = content_type or 'application/octet-stream'\n436             else:\n437                 self['Content-Type'] = 'application/octet-stream'\n438 \n439         if self.as_attachment:\n440             filename = self.filename or os.path.basename(filename)\n441             if filename:\n442                 try:\n443                     filename.encode('ascii')\n444                     file_expr = 'filename=\"{}\"'.format(filename)\n445                 except UnicodeEncodeError:\n446                     file_expr = \"filename*=utf-8''{}\".format(quote(filename))\n447                 self['Content-Disposition'] = 'attachment; {}'.format(file_expr)\n448 \n449 \n450 class HttpResponseRedirectBase(HttpResponse):\n451     allowed_schemes = ['http', 'https', 'ftp']\n452 \n453     def __init__(self, redirect_to, *args, **kwargs):\n454         super().__init__(*args, **kwargs)\n455         self['Location'] = iri_to_uri(redirect_to)\n456         parsed = urlparse(str(redirect_to))\n457         if parsed.scheme and parsed.scheme not in self.allowed_schemes:\n458             raise DisallowedRedirect(\"Unsafe redirect to URL with protocol '%s'\" % parsed.scheme)\n459 \n460     url = property(lambda self: self['Location'])\n461 \n462     def __repr__(self):\n463         return '<%(cls)s status_code=%(status_code)d%(content_type)s, url=\"%(url)s\">' % {\n464             'cls': self.__class__.__name__,\n465             'status_code': self.status_code,\n466             'content_type': self._content_type_for_repr,\n467             'url': self.url,\n468         }\n469 \n470 \n471 class HttpResponseRedirect(HttpResponseRedirectBase):\n472     status_code = 302\n473 \n474 \n475 class HttpResponsePermanentRedirect(HttpResponseRedirectBase):\n476     status_code = 301\n477 \n478 \n479 class HttpResponseNotModified(HttpResponse):\n480     status_code = 304\n481 \n482     def __init__(self, *args, **kwargs):\n483         super().__init__(*args, **kwargs)\n484         del self['content-type']\n485 \n486     @HttpResponse.content.setter\n487     def content(self, value):\n488         if value:\n489             raise AttributeError(\"You cannot set content to a 304 (Not Modified) response\")\n490         self._container = []\n491 \n492 \n493 class HttpResponseBadRequest(HttpResponse):\n494     status_code = 400\n495 \n496 \n497 class HttpResponseNotFound(HttpResponse):\n498     status_code = 404\n499 \n500 \n501 class HttpResponseForbidden(HttpResponse):\n502     status_code = 403\n503 \n504 \n505 class HttpResponseNotAllowed(HttpResponse):\n506     status_code = 405\n507 \n508     def __init__(self, permitted_methods, *args, **kwargs):\n509         super().__init__(*args, **kwargs)\n510         self['Allow'] = ', '.join(permitted_methods)\n511 \n512     def __repr__(self):\n513         return '<%(cls)s [%(methods)s] status_code=%(status_code)d%(content_type)s>' % {\n514             'cls': self.__class__.__name__,\n515             'status_code': self.status_code,\n516             'content_type': self._content_type_for_repr,\n517             'methods': self['Allow'],\n518         }\n519 \n520 \n521 class HttpResponseGone(HttpResponse):\n522     status_code = 410\n523 \n524 \n525 class HttpResponseServerError(HttpResponse):\n526     status_code = 500\n527 \n528 \n529 class Http404(Exception):\n530     pass\n531 \n532 \n533 class JsonResponse(HttpResponse):\n534     \"\"\"\n535     An HTTP response class that consumes data to be serialized to JSON.\n536 \n537     :param data: Data to be dumped into json. By default only ``dict`` objects\n538       are allowed to be passed due to a security flaw before EcmaScript 5. See\n539       the ``safe`` parameter for more information.\n540     :param encoder: Should be a json encoder class. Defaults to\n541       ``django.core.serializers.json.DjangoJSONEncoder``.\n542     :param safe: Controls if only ``dict`` objects may be serialized. Defaults\n543       to ``True``.\n544     :param json_dumps_params: A dictionary of kwargs passed to json.dumps().\n545     \"\"\"\n546 \n547     def __init__(self, data, encoder=DjangoJSONEncoder, safe=True,\n548                  json_dumps_params=None, **kwargs):\n549         if safe and not isinstance(data, dict):\n550             raise TypeError(\n551                 'In order to allow non-dict objects to be serialized set the '\n552                 'safe parameter to False.'\n553             )\n554         if json_dumps_params is None:\n555             json_dumps_params = {}\n556         kwargs.setdefault('content_type', 'application/json')\n557         data = json.dumps(data, cls=encoder, **json_dumps_params)\n558         super().__init__(content=data, **kwargs)\n",
        "intended_behavior": "Replace `IOError` with `OSError`, maintaining the response handling integrity."
    },
    {
        "rel_file_path": "django/http/request.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.0/django/http/request.py",
        "start": 1,
        "end": 593,
        "class_name": null,
        "method_name": null,
        "code": "1 import copy\n2 import re\n3 from io import BytesIO\n4 from itertools import chain\n5 from urllib.parse import quote, urlencode, urljoin, urlsplit\n6 \n7 from django.conf import settings\n8 from django.core import signing\n9 from django.core.exceptions import (\n10     DisallowedHost, ImproperlyConfigured, RequestDataTooBig,\n11 )\n12 from django.core.files import uploadhandler\n13 from django.http.multipartparser import MultiPartParser, MultiPartParserError\n14 from django.utils.datastructures import (\n15     CaseInsensitiveMapping, ImmutableList, MultiValueDict,\n16 )\n17 from django.utils.encoding import escape_uri_path, iri_to_uri\n18 from django.utils.functional import cached_property\n19 from django.utils.http import is_same_domain, limited_parse_qsl\n20 \n21 RAISE_ERROR = object()\n22 host_validation_re = re.compile(r\"^([a-z0-9.-]+|\\[[a-f0-9]*:[a-f0-9\\.:]+\\])(:\\d+)?$\")\n23 \n24 \n25 class UnreadablePostError(IOError):\n26     pass\n27 \n28 \n29 class RawPostDataException(Exception):\n30     \"\"\"\n31     You cannot access raw_post_data from a request that has\n32     multipart/* POST data if it has been accessed via POST,\n33     FILES, etc..\n34     \"\"\"\n35     pass\n36 \n37 \n38 class HttpRequest:\n39     \"\"\"A basic HTTP request.\"\"\"\n40 \n41     # The encoding used in GET/POST dicts. None means use default setting.\n42     _encoding = None\n43     _upload_handlers = []\n44 \n45     def __init__(self):\n46         # WARNING: The `WSGIRequest` subclass doesn't call `super`.\n47         # Any variable assignment made here should also happen in\n48         # `WSGIRequest.__init__()`.\n49 \n50         self.GET = QueryDict(mutable=True)\n51         self.POST = QueryDict(mutable=True)\n52         self.COOKIES = {}\n53         self.META = {}\n54         self.FILES = MultiValueDict()\n55 \n56         self.path = ''\n57         self.path_info = ''\n58         self.method = None\n59         self.resolver_match = None\n60         self.content_type = None\n61         self.content_params = None\n62 \n63     def __repr__(self):\n64         if self.method is None or not self.get_full_path():\n65             return '<%s>' % self.__class__.__name__\n66         return '<%s: %s %r>' % (self.__class__.__name__, self.method, self.get_full_path())\n67 \n68     @cached_property\n69     def headers(self):\n70         return HttpHeaders(self.META)\n71 \n72     def _get_raw_host(self):\n73         \"\"\"\n74         Return the HTTP host using the environment or request headers. Skip\n75         allowed hosts protection, so may return an insecure host.\n76         \"\"\"\n77         # We try three options, in order of decreasing preference.\n78         if settings.USE_X_FORWARDED_HOST and (\n79                 'HTTP_X_FORWARDED_HOST' in self.META):\n80             host = self.META['HTTP_X_FORWARDED_HOST']\n81         elif 'HTTP_HOST' in self.META:\n82             host = self.META['HTTP_HOST']\n83         else:\n84             # Reconstruct the host using the algorithm from PEP 333.\n85             host = self.META['SERVER_NAME']\n86             server_port = self.get_port()\n87             if server_port != ('443' if self.is_secure() else '80'):\n88                 host = '%s:%s' % (host, server_port)\n89         return host\n90 \n91     def get_host(self):\n92         \"\"\"Return the HTTP host using the environment or request headers.\"\"\"\n93         host = self._get_raw_host()\n94 \n95         # Allow variants of localhost if ALLOWED_HOSTS is empty and DEBUG=True.\n96         allowed_hosts = settings.ALLOWED_HOSTS\n97         if settings.DEBUG and not allowed_hosts:\n98             allowed_hosts = ['localhost', '127.0.0.1', '[::1]']\n99 \n100         domain, port = split_domain_port(host)\n101         if domain and validate_host(domain, allowed_hosts):\n102             return host\n103         else:\n104             msg = \"Invalid HTTP_HOST header: %r.\" % host\n105             if domain:\n106                 msg += \" You may need to add %r to ALLOWED_HOSTS.\" % domain\n107             else:\n108                 msg += \" The domain name provided is not valid according to RFC 1034/1035.\"\n109             raise DisallowedHost(msg)\n110 \n111     def get_port(self):\n112         \"\"\"Return the port number for the request as a string.\"\"\"\n113         if settings.USE_X_FORWARDED_PORT and 'HTTP_X_FORWARDED_PORT' in self.META:\n114             port = self.META['HTTP_X_FORWARDED_PORT']\n115         else:\n116             port = self.META['SERVER_PORT']\n117         return str(port)\n118 \n119     def get_full_path(self, force_append_slash=False):\n120         return self._get_full_path(self.path, force_append_slash)\n121 \n122     def get_full_path_info(self, force_append_slash=False):\n123         return self._get_full_path(self.path_info, force_append_slash)\n124 \n125     def _get_full_path(self, path, force_append_slash):\n126         # RFC 3986 requires query string arguments to be in the ASCII range.\n127         # Rather than crash if this doesn't happen, we encode defensively.\n128         return '%s%s%s' % (\n129             escape_uri_path(path),\n130             '/' if force_append_slash and not path.endswith('/') else '',\n131             ('?' + iri_to_uri(self.META.get('QUERY_STRING', ''))) if self.META.get('QUERY_STRING', '') else ''\n132         )\n133 \n134     def get_signed_cookie(self, key, default=RAISE_ERROR, salt='', max_age=None):\n135         \"\"\"\n136         Attempt to return a signed cookie. If the signature fails or the\n137         cookie has expired, raise an exception, unless the `default` argument\n138         is provided,  in which case return that value.\n139         \"\"\"\n140         try:\n141             cookie_value = self.COOKIES[key]\n142         except KeyError:\n143             if default is not RAISE_ERROR:\n144                 return default\n145             else:\n146                 raise\n147         try:\n148             value = signing.get_cookie_signer(salt=key + salt).unsign(\n149                 cookie_value, max_age=max_age)\n150         except signing.BadSignature:\n151             if default is not RAISE_ERROR:\n152                 return default\n153             else:\n154                 raise\n155         return value\n156 \n157     def get_raw_uri(self):\n158         \"\"\"\n159         Return an absolute URI from variables available in this request. Skip\n160         allowed hosts protection, so may return insecure URI.\n161         \"\"\"\n162         return '{scheme}://{host}{path}'.format(\n163             scheme=self.scheme,\n164             host=self._get_raw_host(),\n165             path=self.get_full_path(),\n166         )\n167 \n168     def build_absolute_uri(self, location=None):\n169         \"\"\"\n170         Build an absolute URI from the location and the variables available in\n171         this request. If no ``location`` is specified, build the absolute URI\n172         using request.get_full_path(). If the location is absolute, convert it\n173         to an RFC 3987 compliant URI and return it. If location is relative or\n174         is scheme-relative (i.e., ``//example.com/``), urljoin() it to a base\n175         URL constructed from the request variables.\n176         \"\"\"\n177         if location is None:\n178             # Make it an absolute url (but schemeless and domainless) for the\n179             # edge case that the path starts with '//'.\n180             location = '//%s' % self.get_full_path()\n181         bits = urlsplit(location)\n182         if not (bits.scheme and bits.netloc):\n183             # Handle the simple, most common case. If the location is absolute\n184             # and a scheme or host (netloc) isn't provided, skip an expensive\n185             # urljoin() as long as no path segments are '.' or '..'.\n186             if (bits.path.startswith('/') and not bits.scheme and not bits.netloc and\n187                     '/./' not in bits.path and '/../' not in bits.path):\n188                 # If location starts with '//' but has no netloc, reuse the\n189                 # schema and netloc from the current request. Strip the double\n190                 # slashes and continue as if it wasn't specified.\n191                 if location.startswith('//'):\n192                     location = location[2:]\n193                 location = self._current_scheme_host + location\n194             else:\n195                 # Join the constructed URL with the provided location, which\n196                 # allows the provided location to apply query strings to the\n197                 # base path.\n198                 location = urljoin(self._current_scheme_host + self.path, location)\n199         return iri_to_uri(location)\n200 \n201     @cached_property\n202     def _current_scheme_host(self):\n203         return '{}://{}'.format(self.scheme, self.get_host())\n204 \n205     def _get_scheme(self):\n206         \"\"\"\n207         Hook for subclasses like WSGIRequest to implement. Return 'http' by\n208         default.\n209         \"\"\"\n210         return 'http'\n211 \n212     @property\n213     def scheme(self):\n214         if settings.SECURE_PROXY_SSL_HEADER:\n215             try:\n216                 header, value = settings.SECURE_PROXY_SSL_HEADER\n217             except ValueError:\n218                 raise ImproperlyConfigured(\n219                     'The SECURE_PROXY_SSL_HEADER setting must be a tuple containing two values.'\n220                 )\n221             if self.META.get(header) == value:\n222                 return 'https'\n223         return self._get_scheme()\n224 \n225     def is_secure(self):\n226         return self.scheme == 'https'\n227 \n228     def is_ajax(self):\n229         return self.META.get('HTTP_X_REQUESTED_WITH') == 'XMLHttpRequest'\n230 \n231     @property\n232     def encoding(self):\n233         return self._encoding\n234 \n235     @encoding.setter\n236     def encoding(self, val):\n237         \"\"\"\n238         Set the encoding used for GET/POST accesses. If the GET or POST\n239         dictionary has already been created, remove and recreate it on the\n240         next access (so that it is decoded correctly).\n241         \"\"\"\n242         self._encoding = val\n243         if hasattr(self, 'GET'):\n244             del self.GET\n245         if hasattr(self, '_post'):\n246             del self._post\n247 \n248     def _initialize_handlers(self):\n249         self._upload_handlers = [uploadhandler.load_handler(handler, self)\n250                                  for handler in settings.FILE_UPLOAD_HANDLERS]\n251 \n252     @property\n253     def upload_handlers(self):\n254         if not self._upload_handlers:\n255             # If there are no upload handlers defined, initialize them from settings.\n256             self._initialize_handlers()\n257         return self._upload_handlers\n258 \n259     @upload_handlers.setter\n260     def upload_handlers(self, upload_handlers):\n261         if hasattr(self, '_files'):\n262             raise AttributeError(\"You cannot set the upload handlers after the upload has been processed.\")\n263         self._upload_handlers = upload_handlers\n264 \n265     def parse_file_upload(self, META, post_data):\n266         \"\"\"Return a tuple of (POST QueryDict, FILES MultiValueDict).\"\"\"\n267         self.upload_handlers = ImmutableList(\n268             self.upload_handlers,\n269             warning=\"You cannot alter upload handlers after the upload has been processed.\"\n270         )\n271         parser = MultiPartParser(META, post_data, self.upload_handlers, self.encoding)\n272         return parser.parse()\n273 \n274     @property\n275     def body(self):\n276         if not hasattr(self, '_body'):\n277             if self._read_started:\n278                 raise RawPostDataException(\"You cannot access body after reading from request's data stream\")\n279 \n280             # Limit the maximum request data size that will be handled in-memory.\n281             if (settings.DATA_UPLOAD_MAX_MEMORY_SIZE is not None and\n282                     int(self.META.get('CONTENT_LENGTH') or 0) > settings.DATA_UPLOAD_MAX_MEMORY_SIZE):\n283                 raise RequestDataTooBig('Request body exceeded settings.DATA_UPLOAD_MAX_MEMORY_SIZE.')\n284 \n285             try:\n286                 self._body = self.read()\n287             except IOError as e:\n288                 raise UnreadablePostError(*e.args) from e\n289             self._stream = BytesIO(self._body)\n290         return self._body\n291 \n292     def _mark_post_parse_error(self):\n293         self._post = QueryDict()\n294         self._files = MultiValueDict()\n295 \n296     def _load_post_and_files(self):\n297         \"\"\"Populate self._post and self._files if the content-type is a form type\"\"\"\n298         if self.method != 'POST':\n299             self._post, self._files = QueryDict(encoding=self._encoding), MultiValueDict()\n300             return\n301         if self._read_started and not hasattr(self, '_body'):\n302             self._mark_post_parse_error()\n303             return\n304 \n305         if self.content_type == 'multipart/form-data':\n306             if hasattr(self, '_body'):\n307                 # Use already read data\n308                 data = BytesIO(self._body)\n309             else:\n310                 data = self\n311             try:\n312                 self._post, self._files = self.parse_file_upload(self.META, data)\n313             except MultiPartParserError:\n314                 # An error occurred while parsing POST data. Since when\n315                 # formatting the error the request handler might access\n316                 # self.POST, set self._post and self._file to prevent\n317                 # attempts to parse POST data again.\n318                 self._mark_post_parse_error()\n319                 raise\n320         elif self.content_type == 'application/x-www-form-urlencoded':\n321             self._post, self._files = QueryDict(self.body, encoding=self._encoding), MultiValueDict()\n322         else:\n323             self._post, self._files = QueryDict(encoding=self._encoding), MultiValueDict()\n324 \n325     def close(self):\n326         if hasattr(self, '_files'):\n327             for f in chain.from_iterable(l[1] for l in self._files.lists()):\n328                 f.close()\n329 \n330     # File-like and iterator interface.\n331     #\n332     # Expects self._stream to be set to an appropriate source of bytes by\n333     # a corresponding request subclass (e.g. WSGIRequest).\n334     # Also when request data has already been read by request.POST or\n335     # request.body, self._stream points to a BytesIO instance\n336     # containing that data.\n337 \n338     def read(self, *args, **kwargs):\n339         self._read_started = True\n340         try:\n341             return self._stream.read(*args, **kwargs)\n342         except IOError as e:\n343             raise UnreadablePostError(*e.args) from e\n344 \n345     def readline(self, *args, **kwargs):\n346         self._read_started = True\n347         try:\n348             return self._stream.readline(*args, **kwargs)\n349         except IOError as e:\n350             raise UnreadablePostError(*e.args) from e\n351 \n352     def __iter__(self):\n353         return iter(self.readline, b'')\n354 \n355     def readlines(self):\n356         return list(self)\n357 \n358 \n359 class HttpHeaders(CaseInsensitiveMapping):\n360     HTTP_PREFIX = 'HTTP_'\n361     # PEP 333 gives two headers which aren't prepended with HTTP_.\n362     UNPREFIXED_HEADERS = {'CONTENT_TYPE', 'CONTENT_LENGTH'}\n363 \n364     def __init__(self, environ):\n365         headers = {}\n366         for header, value in environ.items():\n367             name = self.parse_header_name(header)\n368             if name:\n369                 headers[name] = value\n370         super().__init__(headers)\n371 \n372     @classmethod\n373     def parse_header_name(cls, header):\n374         if header.startswith(cls.HTTP_PREFIX):\n375             header = header[len(cls.HTTP_PREFIX):]\n376         elif header not in cls.UNPREFIXED_HEADERS:\n377             return None\n378         return header.replace('_', '-').title()\n379 \n380 \n381 class QueryDict(MultiValueDict):\n382     \"\"\"\n383     A specialized MultiValueDict which represents a query string.\n384 \n385     A QueryDict can be used to represent GET or POST data. It subclasses\n386     MultiValueDict since keys in such data can be repeated, for instance\n387     in the data from a form with a <select multiple> field.\n388 \n389     By default QueryDicts are immutable, though the copy() method\n390     will always return a mutable copy.\n391 \n392     Both keys and values set on this class are converted from the given encoding\n393     (DEFAULT_CHARSET by default) to str.\n394     \"\"\"\n395 \n396     # These are both reset in __init__, but is specified here at the class\n397     # level so that unpickling will have valid values\n398     _mutable = True\n399     _encoding = None\n400 \n401     def __init__(self, query_string=None, mutable=False, encoding=None):\n402         super().__init__()\n403         self.encoding = encoding or settings.DEFAULT_CHARSET\n404         query_string = query_string or ''\n405         parse_qsl_kwargs = {\n406             'keep_blank_values': True,\n407             'fields_limit': settings.DATA_UPLOAD_MAX_NUMBER_FIELDS,\n408             'encoding': self.encoding,\n409         }\n410         if isinstance(query_string, bytes):\n411             # query_string normally contains URL-encoded data, a subset of ASCII.\n412             try:\n413                 query_string = query_string.decode(self.encoding)\n414             except UnicodeDecodeError:\n415                 # ... but some user agents are misbehaving :-(\n416                 query_string = query_string.decode('iso-8859-1')\n417         for key, value in limited_parse_qsl(query_string, **parse_qsl_kwargs):\n418             self.appendlist(key, value)\n419         self._mutable = mutable\n420 \n421     @classmethod\n422     def fromkeys(cls, iterable, value='', mutable=False, encoding=None):\n423         \"\"\"\n424         Return a new QueryDict with keys (may be repeated) from an iterable and\n425         values from value.\n426         \"\"\"\n427         q = cls('', mutable=True, encoding=encoding)\n428         for key in iterable:\n429             q.appendlist(key, value)\n430         if not mutable:\n431             q._mutable = False\n432         return q\n433 \n434     @property\n435     def encoding(self):\n436         if self._encoding is None:\n437             self._encoding = settings.DEFAULT_CHARSET\n438         return self._encoding\n439 \n440     @encoding.setter\n441     def encoding(self, value):\n442         self._encoding = value\n443 \n444     def _assert_mutable(self):\n445         if not self._mutable:\n446             raise AttributeError(\"This QueryDict instance is immutable\")\n447 \n448     def __setitem__(self, key, value):\n449         self._assert_mutable()\n450         key = bytes_to_text(key, self.encoding)\n451         value = bytes_to_text(value, self.encoding)\n452         super().__setitem__(key, value)\n453 \n454     def __delitem__(self, key):\n455         self._assert_mutable()\n456         super().__delitem__(key)\n457 \n458     def __copy__(self):\n459         result = self.__class__('', mutable=True, encoding=self.encoding)\n460         for key, value in self.lists():\n461             result.setlist(key, value)\n462         return result\n463 \n464     def __deepcopy__(self, memo):\n465         result = self.__class__('', mutable=True, encoding=self.encoding)\n466         memo[id(self)] = result\n467         for key, value in self.lists():\n468             result.setlist(copy.deepcopy(key, memo), copy.deepcopy(value, memo))\n469         return result\n470 \n471     def setlist(self, key, list_):\n472         self._assert_mutable()\n473         key = bytes_to_text(key, self.encoding)\n474         list_ = [bytes_to_text(elt, self.encoding) for elt in list_]\n475         super().setlist(key, list_)\n476 \n477     def setlistdefault(self, key, default_list=None):\n478         self._assert_mutable()\n479         return super().setlistdefault(key, default_list)\n480 \n481     def appendlist(self, key, value):\n482         self._assert_mutable()\n483         key = bytes_to_text(key, self.encoding)\n484         value = bytes_to_text(value, self.encoding)\n485         super().appendlist(key, value)\n486 \n487     def pop(self, key, *args):\n488         self._assert_mutable()\n489         return super().pop(key, *args)\n490 \n491     def popitem(self):\n492         self._assert_mutable()\n493         return super().popitem()\n494 \n495     def clear(self):\n496         self._assert_mutable()\n497         super().clear()\n498 \n499     def setdefault(self, key, default=None):\n500         self._assert_mutable()\n501         key = bytes_to_text(key, self.encoding)\n502         default = bytes_to_text(default, self.encoding)\n503         return super().setdefault(key, default)\n504 \n505     def copy(self):\n506         \"\"\"Return a mutable copy of this object.\"\"\"\n507         return self.__deepcopy__({})\n508 \n509     def urlencode(self, safe=None):\n510         \"\"\"\n511         Return an encoded string of all query string arguments.\n512 \n513         `safe` specifies characters which don't require quoting, for example::\n514 \n515             >>> q = QueryDict(mutable=True)\n516             >>> q['next'] = '/a&b/'\n517             >>> q.urlencode()\n518             'next=%2Fa%26b%2F'\n519             >>> q.urlencode(safe='/')\n520             'next=/a%26b/'\n521         \"\"\"\n522         output = []\n523         if safe:\n524             safe = safe.encode(self.encoding)\n525 \n526             def encode(k, v):\n527                 return '%s=%s' % ((quote(k, safe), quote(v, safe)))\n528         else:\n529             def encode(k, v):\n530                 return urlencode({k: v})\n531         for k, list_ in self.lists():\n532             output.extend(\n533                 encode(k.encode(self.encoding), str(v).encode(self.encoding))\n534                 for v in list_\n535             )\n536         return '&'.join(output)\n537 \n538 \n539 # It's neither necessary nor appropriate to use\n540 # django.utils.encoding.force_text for parsing URLs and form inputs. Thus,\n541 # this slightly more restricted function, used by QueryDict.\n542 def bytes_to_text(s, encoding):\n543     \"\"\"\n544     Convert bytes objects to strings, using the given encoding. Illegally\n545     encoded input characters are replaced with Unicode \"unknown\" codepoint\n546     (\\ufffd).\n547 \n548     Return any non-bytes objects without change.\n549     \"\"\"\n550     if isinstance(s, bytes):\n551         return str(s, encoding, 'replace')\n552     else:\n553         return s\n554 \n555 \n556 def split_domain_port(host):\n557     \"\"\"\n558     Return a (domain, port) tuple from a given host.\n559 \n560     Returned domain is lowercased. If the host is invalid, the domain will be\n561     empty.\n562     \"\"\"\n563     host = host.lower()\n564 \n565     if not host_validation_re.match(host):\n566         return '', ''\n567 \n568     if host[-1] == ']':\n569         # It's an IPv6 address without a port.\n570         return host, ''\n571     bits = host.rsplit(':', 1)\n572     domain, port = bits if len(bits) == 2 else (bits[0], '')\n573     # Remove a trailing dot (if present) from the domain.\n574     domain = domain[:-1] if domain.endswith('.') else domain\n575     return domain, port\n576 \n577 \n578 def validate_host(host, allowed_hosts):\n579     \"\"\"\n580     Validate the given host for this site.\n581 \n582     Check that the host looks valid and matches a host or host pattern in the\n583     given list of ``allowed_hosts``. Any pattern beginning with a period\n584     matches a domain and all its subdomains (e.g. ``.example.com`` matches\n585     ``example.com`` and any subdomain), ``*`` matches anything, and anything\n586     else must match exactly.\n587 \n588     Note: This function assumes that the given host is lowercased and has\n589     already had the port, if any, stripped off.\n590 \n591     Return ``True`` for a valid host, ``False`` otherwise.\n592     \"\"\"\n593     return any(pattern == '*' or is_same_domain(host, pattern) for pattern in allowed_hosts)\n",
        "intended_behavior": "Substitute `IOError` with `OSError` without changing the error handling logic for request processing."
    },
    {
        "rel_file_path": "django/utils/translation/trans_real.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.0/django/utils/translation/trans_real.py",
        "start": 1,
        "end": 515,
        "class_name": null,
        "method_name": null,
        "code": "1 \"\"\"Translation helper functions.\"\"\"\n2 import functools\n3 import gettext as gettext_module\n4 import os\n5 import re\n6 import sys\n7 import warnings\n8 from collections import OrderedDict\n9 from threading import local\n10 \n11 from django.apps import apps\n12 from django.conf import settings\n13 from django.conf.locale import LANG_INFO\n14 from django.core.exceptions import AppRegistryNotReady\n15 from django.core.signals import setting_changed\n16 from django.dispatch import receiver\n17 from django.utils.safestring import SafeData, mark_safe\n18 \n19 from . import LANGUAGE_SESSION_KEY, to_language, to_locale\n20 \n21 # Translations are cached in a dictionary for every language.\n22 # The active translations are stored by threadid to make them thread local.\n23 _translations = {}\n24 _active = local()\n25 \n26 # The default translation is based on the settings file.\n27 _default = None\n28 \n29 # magic gettext number to separate context from message\n30 CONTEXT_SEPARATOR = \"\\x04\"\n31 \n32 # Format of Accept-Language header values. From RFC 2616, section 14.4 and 3.9\n33 # and RFC 3066, section 2.1\n34 accept_language_re = re.compile(r'''\n35         ([A-Za-z]{1,8}(?:-[A-Za-z0-9]{1,8})*|\\*)      # \"en\", \"en-au\", \"x-y-z\", \"es-419\", \"*\"\n36         (?:\\s*;\\s*q=(0(?:\\.\\d{,3})?|1(?:\\.0{,3})?))?  # Optional \"q=1.00\", \"q=0.8\"\n37         (?:\\s*,\\s*|$)                                 # Multiple accepts per header.\n38         ''', re.VERBOSE)\n39 \n40 language_code_re = re.compile(\n41     r'^[a-z]{1,8}(?:-[a-z0-9]{1,8})*(?:@[a-z0-9]{1,20})?$',\n42     re.IGNORECASE\n43 )\n44 \n45 language_code_prefix_re = re.compile(r'^/(\\w+([@-]\\w+)?)(/|$)')\n46 \n47 \n48 @receiver(setting_changed)\n49 def reset_cache(**kwargs):\n50     \"\"\"\n51     Reset global state when LANGUAGES setting has been changed, as some\n52     languages should no longer be accepted.\n53     \"\"\"\n54     if kwargs['setting'] in ('LANGUAGES', 'LANGUAGE_CODE'):\n55         check_for_language.cache_clear()\n56         get_languages.cache_clear()\n57         get_supported_language_variant.cache_clear()\n58 \n59 \n60 class DjangoTranslation(gettext_module.GNUTranslations):\n61     \"\"\"\n62     Set up the GNUTranslations context with regard to output charset.\n63 \n64     This translation object will be constructed out of multiple GNUTranslations\n65     objects by merging their catalogs. It will construct an object for the\n66     requested language and add a fallback to the default language, if it's\n67     different from the requested language.\n68     \"\"\"\n69     domain = 'django'\n70 \n71     def __init__(self, language, domain=None, localedirs=None):\n72         \"\"\"Create a GNUTranslations() using many locale directories\"\"\"\n73         gettext_module.GNUTranslations.__init__(self)\n74         if domain is not None:\n75             self.domain = domain\n76 \n77         self.__language = language\n78         self.__to_language = to_language(language)\n79         self.__locale = to_locale(language)\n80         self._catalog = None\n81         # If a language doesn't have a catalog, use the Germanic default for\n82         # pluralization: anything except one is pluralized.\n83         self.plural = lambda n: int(n != 1)\n84 \n85         if self.domain == 'django':\n86             if localedirs is not None:\n87                 # A module-level cache is used for caching 'django' translations\n88                 warnings.warn(\"localedirs is ignored when domain is 'django'.\", RuntimeWarning)\n89                 localedirs = None\n90             self._init_translation_catalog()\n91 \n92         if localedirs:\n93             for localedir in localedirs:\n94                 translation = self._new_gnu_trans(localedir)\n95                 self.merge(translation)\n96         else:\n97             self._add_installed_apps_translations()\n98 \n99         self._add_local_translations()\n100         if self.__language == settings.LANGUAGE_CODE and self.domain == 'django' and self._catalog is None:\n101             # default lang should have at least one translation file available.\n102             raise IOError(\"No translation files found for default language %s.\" % settings.LANGUAGE_CODE)\n103         self._add_fallback(localedirs)\n104         if self._catalog is None:\n105             # No catalogs found for this language, set an empty catalog.\n106             self._catalog = {}\n107 \n108     def __repr__(self):\n109         return \"<DjangoTranslation lang:%s>\" % self.__language\n110 \n111     def _new_gnu_trans(self, localedir, use_null_fallback=True):\n112         \"\"\"\n113         Return a mergeable gettext.GNUTranslations instance.\n114 \n115         A convenience wrapper. By default gettext uses 'fallback=False'.\n116         Using param `use_null_fallback` to avoid confusion with any other\n117         references to 'fallback'.\n118         \"\"\"\n119         return gettext_module.translation(\n120             domain=self.domain,\n121             localedir=localedir,\n122             languages=[self.__locale],\n123             fallback=use_null_fallback,\n124         )\n125 \n126     def _init_translation_catalog(self):\n127         \"\"\"Create a base catalog using global django translations.\"\"\"\n128         settingsfile = sys.modules[settings.__module__].__file__\n129         localedir = os.path.join(os.path.dirname(settingsfile), 'locale')\n130         translation = self._new_gnu_trans(localedir)\n131         self.merge(translation)\n132 \n133     def _add_installed_apps_translations(self):\n134         \"\"\"Merge translations from each installed app.\"\"\"\n135         try:\n136             app_configs = reversed(list(apps.get_app_configs()))\n137         except AppRegistryNotReady:\n138             raise AppRegistryNotReady(\n139                 \"The translation infrastructure cannot be initialized before the \"\n140                 \"apps registry is ready. Check that you don't make non-lazy \"\n141                 \"gettext calls at import time.\")\n142         for app_config in app_configs:\n143             localedir = os.path.join(app_config.path, 'locale')\n144             if os.path.exists(localedir):\n145                 translation = self._new_gnu_trans(localedir)\n146                 self.merge(translation)\n147 \n148     def _add_local_translations(self):\n149         \"\"\"Merge translations defined in LOCALE_PATHS.\"\"\"\n150         for localedir in reversed(settings.LOCALE_PATHS):\n151             translation = self._new_gnu_trans(localedir)\n152             self.merge(translation)\n153 \n154     def _add_fallback(self, localedirs=None):\n155         \"\"\"Set the GNUTranslations() fallback with the default language.\"\"\"\n156         # Don't set a fallback for the default language or any English variant\n157         # (as it's empty, so it'll ALWAYS fall back to the default language)\n158         if self.__language == settings.LANGUAGE_CODE or self.__language.startswith('en'):\n159             return\n160         if self.domain == 'django':\n161             # Get from cache\n162             default_translation = translation(settings.LANGUAGE_CODE)\n163         else:\n164             default_translation = DjangoTranslation(\n165                 settings.LANGUAGE_CODE, domain=self.domain, localedirs=localedirs\n166             )\n167         self.add_fallback(default_translation)\n168 \n169     def merge(self, other):\n170         \"\"\"Merge another translation into this catalog.\"\"\"\n171         if not getattr(other, '_catalog', None):\n172             return  # NullTranslations() has no _catalog\n173         if self._catalog is None:\n174             # Take plural and _info from first catalog found (generally Django's).\n175             self.plural = other.plural\n176             self._info = other._info.copy()\n177             self._catalog = other._catalog.copy()\n178         else:\n179             self._catalog.update(other._catalog)\n180         if other._fallback:\n181             self.add_fallback(other._fallback)\n182 \n183     def language(self):\n184         \"\"\"Return the translation language.\"\"\"\n185         return self.__language\n186 \n187     def to_language(self):\n188         \"\"\"Return the translation language name.\"\"\"\n189         return self.__to_language\n190 \n191 \n192 def translation(language):\n193     \"\"\"\n194     Return a translation object in the default 'django' domain.\n195     \"\"\"\n196     global _translations\n197     if language not in _translations:\n198         _translations[language] = DjangoTranslation(language)\n199     return _translations[language]\n200 \n201 \n202 def activate(language):\n203     \"\"\"\n204     Fetch the translation object for a given language and install it as the\n205     current translation object for the current thread.\n206     \"\"\"\n207     if not language:\n208         return\n209     _active.value = translation(language)\n210 \n211 \n212 def deactivate():\n213     \"\"\"\n214     Uninstall the active translation object so that further _() calls resolve\n215     to the default translation object.\n216     \"\"\"\n217     if hasattr(_active, \"value\"):\n218         del _active.value\n219 \n220 \n221 def deactivate_all():\n222     \"\"\"\n223     Make the active translation object a NullTranslations() instance. This is\n224     useful when we want delayed translations to appear as the original string\n225     for some reason.\n226     \"\"\"\n227     _active.value = gettext_module.NullTranslations()\n228     _active.value.to_language = lambda *args: None\n229 \n230 \n231 def get_language():\n232     \"\"\"Return the currently selected language.\"\"\"\n233     t = getattr(_active, \"value\", None)\n234     if t is not None:\n235         try:\n236             return t.to_language()\n237         except AttributeError:\n238             pass\n239     # If we don't have a real translation object, assume it's the default language.\n240     return settings.LANGUAGE_CODE\n241 \n242 \n243 def get_language_bidi():\n244     \"\"\"\n245     Return selected language's BiDi layout.\n246 \n247     * False = left-to-right layout\n248     * True = right-to-left layout\n249     \"\"\"\n250     lang = get_language()\n251     if lang is None:\n252         return False\n253     else:\n254         base_lang = get_language().split('-')[0]\n255         return base_lang in settings.LANGUAGES_BIDI\n256 \n257 \n258 def catalog():\n259     \"\"\"\n260     Return the current active catalog for further processing.\n261     This can be used if you need to modify the catalog or want to access the\n262     whole message catalog instead of just translating one string.\n263     \"\"\"\n264     global _default\n265 \n266     t = getattr(_active, \"value\", None)\n267     if t is not None:\n268         return t\n269     if _default is None:\n270         _default = translation(settings.LANGUAGE_CODE)\n271     return _default\n272 \n273 \n274 def gettext(message):\n275     \"\"\"\n276     Translate the 'message' string. It uses the current thread to find the\n277     translation object to use. If no current translation is activated, the\n278     message will be run through the default translation object.\n279     \"\"\"\n280     global _default\n281 \n282     eol_message = message.replace('\\r\\n', '\\n').replace('\\r', '\\n')\n283 \n284     if eol_message:\n285         _default = _default or translation(settings.LANGUAGE_CODE)\n286         translation_object = getattr(_active, \"value\", _default)\n287 \n288         result = translation_object.gettext(eol_message)\n289     else:\n290         # Return an empty value of the corresponding type if an empty message\n291         # is given, instead of metadata, which is the default gettext behavior.\n292         result = type(message)('')\n293 \n294     if isinstance(message, SafeData):\n295         return mark_safe(result)\n296 \n297     return result\n298 \n299 \n300 def pgettext(context, message):\n301     msg_with_ctxt = \"%s%s%s\" % (context, CONTEXT_SEPARATOR, message)\n302     result = gettext(msg_with_ctxt)\n303     if CONTEXT_SEPARATOR in result:\n304         # Translation not found\n305         result = message\n306     elif isinstance(message, SafeData):\n307         result = mark_safe(result)\n308     return result\n309 \n310 \n311 def gettext_noop(message):\n312     \"\"\"\n313     Mark strings for translation but don't translate them now. This can be\n314     used to store strings in global variables that should stay in the base\n315     language (because they might be used externally) and will be translated\n316     later.\n317     \"\"\"\n318     return message\n319 \n320 \n321 def do_ntranslate(singular, plural, number, translation_function):\n322     global _default\n323 \n324     t = getattr(_active, \"value\", None)\n325     if t is not None:\n326         return getattr(t, translation_function)(singular, plural, number)\n327     if _default is None:\n328         _default = translation(settings.LANGUAGE_CODE)\n329     return getattr(_default, translation_function)(singular, plural, number)\n330 \n331 \n332 def ngettext(singular, plural, number):\n333     \"\"\"\n334     Return a string of the translation of either the singular or plural,\n335     based on the number.\n336     \"\"\"\n337     return do_ntranslate(singular, plural, number, 'ngettext')\n338 \n339 \n340 def npgettext(context, singular, plural, number):\n341     msgs_with_ctxt = (\"%s%s%s\" % (context, CONTEXT_SEPARATOR, singular),\n342                       \"%s%s%s\" % (context, CONTEXT_SEPARATOR, plural),\n343                       number)\n344     result = ngettext(*msgs_with_ctxt)\n345     if CONTEXT_SEPARATOR in result:\n346         # Translation not found\n347         result = ngettext(singular, plural, number)\n348     return result\n349 \n350 \n351 def all_locale_paths():\n352     \"\"\"\n353     Return a list of paths to user-provides languages files.\n354     \"\"\"\n355     globalpath = os.path.join(\n356         os.path.dirname(sys.modules[settings.__module__].__file__), 'locale')\n357     app_paths = []\n358     for app_config in apps.get_app_configs():\n359         locale_path = os.path.join(app_config.path, 'locale')\n360         if os.path.exists(locale_path):\n361             app_paths.append(locale_path)\n362     return [globalpath, *settings.LOCALE_PATHS, *app_paths]\n363 \n364 \n365 @functools.lru_cache(maxsize=1000)\n366 def check_for_language(lang_code):\n367     \"\"\"\n368     Check whether there is a global language file for the given language\n369     code. This is used to decide whether a user-provided language is\n370     available.\n371 \n372     lru_cache should have a maxsize to prevent from memory exhaustion attacks,\n373     as the provided language codes are taken from the HTTP request. See also\n374     <https://www.djangoproject.com/weblog/2007/oct/26/security-fix/>.\n375     \"\"\"\n376     # First, a quick check to make sure lang_code is well-formed (#21458)\n377     if lang_code is None or not language_code_re.search(lang_code):\n378         return False\n379     return any(\n380         gettext_module.find('django', path, [to_locale(lang_code)]) is not None\n381         for path in all_locale_paths()\n382     )\n383 \n384 \n385 @functools.lru_cache()\n386 def get_languages():\n387     \"\"\"\n388     Cache of settings.LANGUAGES in an OrderedDict for easy lookups by key.\n389     \"\"\"\n390     return OrderedDict(settings.LANGUAGES)\n391 \n392 \n393 @functools.lru_cache(maxsize=1000)\n394 def get_supported_language_variant(lang_code, strict=False):\n395     \"\"\"\n396     Return the language code that's listed in supported languages, possibly\n397     selecting a more generic variant. Raise LookupError if nothing is found.\n398 \n399     If `strict` is False (the default), look for a country-specific variant\n400     when neither the language code nor its generic variant is found.\n401 \n402     lru_cache should have a maxsize to prevent from memory exhaustion attacks,\n403     as the provided language codes are taken from the HTTP request. See also\n404     <https://www.djangoproject.com/weblog/2007/oct/26/security-fix/>.\n405     \"\"\"\n406     if lang_code:\n407         # If 'fr-ca' is not supported, try special fallback or language-only 'fr'.\n408         possible_lang_codes = [lang_code]\n409         try:\n410             possible_lang_codes.extend(LANG_INFO[lang_code]['fallback'])\n411         except KeyError:\n412             pass\n413         generic_lang_code = lang_code.split('-')[0]\n414         possible_lang_codes.append(generic_lang_code)\n415         supported_lang_codes = get_languages()\n416 \n417         for code in possible_lang_codes:\n418             if code in supported_lang_codes and check_for_language(code):\n419                 return code\n420         if not strict:\n421             # if fr-fr is not supported, try fr-ca.\n422             for supported_code in supported_lang_codes:\n423                 if supported_code.startswith(generic_lang_code + '-'):\n424                     return supported_code\n425     raise LookupError(lang_code)\n426 \n427 \n428 def get_language_from_path(path, strict=False):\n429     \"\"\"\n430     Return the language code if there's a valid language code found in `path`.\n431 \n432     If `strict` is False (the default), look for a country-specific variant\n433     when neither the language code nor its generic variant is found.\n434     \"\"\"\n435     regex_match = language_code_prefix_re.match(path)\n436     if not regex_match:\n437         return None\n438     lang_code = regex_match.group(1)\n439     try:\n440         return get_supported_language_variant(lang_code, strict=strict)\n441     except LookupError:\n442         return None\n443 \n444 \n445 def get_language_from_request(request, check_path=False):\n446     \"\"\"\n447     Analyze the request to find what language the user wants the system to\n448     show. Only languages listed in settings.LANGUAGES are taken into account.\n449     If the user requests a sublanguage where we have a main language, we send\n450     out the main language.\n451 \n452     If check_path is True, the URL path prefix will be checked for a language\n453     code, otherwise this is skipped for backwards compatibility.\n454     \"\"\"\n455     if check_path:\n456         lang_code = get_language_from_path(request.path_info)\n457         if lang_code is not None:\n458             return lang_code\n459 \n460     supported_lang_codes = get_languages()\n461 \n462     if hasattr(request, 'session'):\n463         lang_code = request.session.get(LANGUAGE_SESSION_KEY)\n464         if lang_code in supported_lang_codes and lang_code is not None and check_for_language(lang_code):\n465             return lang_code\n466 \n467     lang_code = request.COOKIES.get(settings.LANGUAGE_COOKIE_NAME)\n468 \n469     try:\n470         return get_supported_language_variant(lang_code)\n471     except LookupError:\n472         pass\n473 \n474     accept = request.META.get('HTTP_ACCEPT_LANGUAGE', '')\n475     for accept_lang, unused in parse_accept_lang_header(accept):\n476         if accept_lang == '*':\n477             break\n478 \n479         if not language_code_re.search(accept_lang):\n480             continue\n481 \n482         try:\n483             return get_supported_language_variant(accept_lang)\n484         except LookupError:\n485             continue\n486 \n487     try:\n488         return get_supported_language_variant(settings.LANGUAGE_CODE)\n489     except LookupError:\n490         return settings.LANGUAGE_CODE\n491 \n492 \n493 @functools.lru_cache(maxsize=1000)\n494 def parse_accept_lang_header(lang_string):\n495     \"\"\"\n496     Parse the lang_string, which is the body of an HTTP Accept-Language\n497     header, and return a tuple of (lang, q-value), ordered by 'q' values.\n498 \n499     Return an empty tuple if there are any format errors in lang_string.\n500     \"\"\"\n501     result = []\n502     pieces = accept_language_re.split(lang_string.lower())\n503     if pieces[-1]:\n504         return ()\n505     for i in range(0, len(pieces) - 1, 3):\n506         first, lang, priority = pieces[i:i + 3]\n507         if first:\n508             return ()\n509         if priority:\n510             priority = float(priority)\n511         else:\n512             priority = 1.0\n513         result.append((lang, priority))\n514     result.sort(key=lambda k: k[1], reverse=True)\n515     return tuple(result)\n",
        "intended_behavior": "Replace `IOError` with `OSError` ensuring translation file access errors are handled effectively."
    },
    {
        "rel_file_path": "django/views/debug.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.0/django/views/debug.py",
        "start": 1,
        "end": 520,
        "class_name": null,
        "method_name": null,
        "code": "1 import functools\n2 import re\n3 import sys\n4 import types\n5 from pathlib import Path\n6 \n7 from django.conf import settings\n8 from django.http import HttpResponse, HttpResponseNotFound\n9 from django.template import Context, Engine, TemplateDoesNotExist\n10 from django.template.defaultfilters import pprint\n11 from django.urls import Resolver404, resolve\n12 from django.utils import timezone\n13 from django.utils.datastructures import MultiValueDict\n14 from django.utils.encoding import force_text\n15 from django.utils.module_loading import import_string\n16 from django.utils.version import get_docs_version\n17 \n18 # Minimal Django templates engine to render the error templates\n19 # regardless of the project's TEMPLATES setting. Templates are\n20 # read directly from the filesystem so that the error handler\n21 # works even if the template loader is broken.\n22 DEBUG_ENGINE = Engine(\n23     debug=True,\n24     libraries={'i18n': 'django.templatetags.i18n'},\n25 )\n26 \n27 HIDDEN_SETTINGS = re.compile('API|TOKEN|KEY|SECRET|PASS|SIGNATURE', flags=re.IGNORECASE)\n28 \n29 CLEANSED_SUBSTITUTE = '********************'\n30 \n31 CURRENT_DIR = Path(__file__).parent\n32 \n33 \n34 class CallableSettingWrapper:\n35     \"\"\"\n36     Object to wrap callable appearing in settings.\n37     * Not to call in the debug page (#21345).\n38     * Not to break the debug page if the callable forbidding to set attributes\n39       (#23070).\n40     \"\"\"\n41     def __init__(self, callable_setting):\n42         self._wrapped = callable_setting\n43 \n44     def __repr__(self):\n45         return repr(self._wrapped)\n46 \n47 \n48 def cleanse_setting(key, value):\n49     \"\"\"\n50     Cleanse an individual setting key/value of sensitive content. If the value\n51     is a dictionary, recursively cleanse the keys in that dictionary.\n52     \"\"\"\n53     try:\n54         if HIDDEN_SETTINGS.search(key):\n55             cleansed = CLEANSED_SUBSTITUTE\n56         else:\n57             if isinstance(value, dict):\n58                 cleansed = {k: cleanse_setting(k, v) for k, v in value.items()}\n59             else:\n60                 cleansed = value\n61     except TypeError:\n62         # If the key isn't regex-able, just return as-is.\n63         cleansed = value\n64 \n65     if callable(cleansed):\n66         # For fixing #21345 and #23070\n67         cleansed = CallableSettingWrapper(cleansed)\n68 \n69     return cleansed\n70 \n71 \n72 def get_safe_settings():\n73     \"\"\"\n74     Return a dictionary of the settings module with values of sensitive\n75     settings replaced with stars (*********).\n76     \"\"\"\n77     settings_dict = {}\n78     for k in dir(settings):\n79         if k.isupper():\n80             settings_dict[k] = cleanse_setting(k, getattr(settings, k))\n81     return settings_dict\n82 \n83 \n84 def technical_500_response(request, exc_type, exc_value, tb, status_code=500):\n85     \"\"\"\n86     Create a technical server error response. The last three arguments are\n87     the values returned from sys.exc_info() and friends.\n88     \"\"\"\n89     reporter = ExceptionReporter(request, exc_type, exc_value, tb)\n90     if request.is_ajax():\n91         text = reporter.get_traceback_text()\n92         return HttpResponse(text, status=status_code, content_type='text/plain; charset=utf-8')\n93     else:\n94         html = reporter.get_traceback_html()\n95         return HttpResponse(html, status=status_code, content_type='text/html')\n96 \n97 \n98 @functools.lru_cache()\n99 def get_default_exception_reporter_filter():\n100     # Instantiate the default filter for the first time and cache it.\n101     return import_string(settings.DEFAULT_EXCEPTION_REPORTER_FILTER)()\n102 \n103 \n104 def get_exception_reporter_filter(request):\n105     default_filter = get_default_exception_reporter_filter()\n106     return getattr(request, 'exception_reporter_filter', default_filter)\n107 \n108 \n109 class ExceptionReporterFilter:\n110     \"\"\"\n111     Base for all exception reporter filter classes. All overridable hooks\n112     contain lenient default behaviors.\n113     \"\"\"\n114 \n115     def get_post_parameters(self, request):\n116         if request is None:\n117             return {}\n118         else:\n119             return request.POST\n120 \n121     def get_traceback_frame_variables(self, request, tb_frame):\n122         return list(tb_frame.f_locals.items())\n123 \n124 \n125 class SafeExceptionReporterFilter(ExceptionReporterFilter):\n126     \"\"\"\n127     Use annotations made by the sensitive_post_parameters and\n128     sensitive_variables decorators to filter out sensitive information.\n129     \"\"\"\n130 \n131     def is_active(self, request):\n132         \"\"\"\n133         This filter is to add safety in production environments (i.e. DEBUG\n134         is False). If DEBUG is True then your site is not safe anyway.\n135         This hook is provided as a convenience to easily activate or\n136         deactivate the filter on a per request basis.\n137         \"\"\"\n138         return settings.DEBUG is False\n139 \n140     def get_cleansed_multivaluedict(self, request, multivaluedict):\n141         \"\"\"\n142         Replace the keys in a MultiValueDict marked as sensitive with stars.\n143         This mitigates leaking sensitive POST parameters if something like\n144         request.POST['nonexistent_key'] throws an exception (#21098).\n145         \"\"\"\n146         sensitive_post_parameters = getattr(request, 'sensitive_post_parameters', [])\n147         if self.is_active(request) and sensitive_post_parameters:\n148             multivaluedict = multivaluedict.copy()\n149             for param in sensitive_post_parameters:\n150                 if param in multivaluedict:\n151                     multivaluedict[param] = CLEANSED_SUBSTITUTE\n152         return multivaluedict\n153 \n154     def get_post_parameters(self, request):\n155         \"\"\"\n156         Replace the values of POST parameters marked as sensitive with\n157         stars (*********).\n158         \"\"\"\n159         if request is None:\n160             return {}\n161         else:\n162             sensitive_post_parameters = getattr(request, 'sensitive_post_parameters', [])\n163             if self.is_active(request) and sensitive_post_parameters:\n164                 cleansed = request.POST.copy()\n165                 if sensitive_post_parameters == '__ALL__':\n166                     # Cleanse all parameters.\n167                     for k in cleansed:\n168                         cleansed[k] = CLEANSED_SUBSTITUTE\n169                     return cleansed\n170                 else:\n171                     # Cleanse only the specified parameters.\n172                     for param in sensitive_post_parameters:\n173                         if param in cleansed:\n174                             cleansed[param] = CLEANSED_SUBSTITUTE\n175                     return cleansed\n176             else:\n177                 return request.POST\n178 \n179     def cleanse_special_types(self, request, value):\n180         try:\n181             # If value is lazy or a complex object of another kind, this check\n182             # might raise an exception. isinstance checks that lazy\n183             # MultiValueDicts will have a return value.\n184             is_multivalue_dict = isinstance(value, MultiValueDict)\n185         except Exception as e:\n186             return '{!r} while evaluating {!r}'.format(e, value)\n187 \n188         if is_multivalue_dict:\n189             # Cleanse MultiValueDicts (request.POST is the one we usually care about)\n190             value = self.get_cleansed_multivaluedict(request, value)\n191         return value\n192 \n193     def get_traceback_frame_variables(self, request, tb_frame):\n194         \"\"\"\n195         Replace the values of variables marked as sensitive with\n196         stars (*********).\n197         \"\"\"\n198         # Loop through the frame's callers to see if the sensitive_variables\n199         # decorator was used.\n200         current_frame = tb_frame.f_back\n201         sensitive_variables = None\n202         while current_frame is not None:\n203             if (current_frame.f_code.co_name == 'sensitive_variables_wrapper' and\n204                     'sensitive_variables_wrapper' in current_frame.f_locals):\n205                 # The sensitive_variables decorator was used, so we take note\n206                 # of the sensitive variables' names.\n207                 wrapper = current_frame.f_locals['sensitive_variables_wrapper']\n208                 sensitive_variables = getattr(wrapper, 'sensitive_variables', None)\n209                 break\n210             current_frame = current_frame.f_back\n211 \n212         cleansed = {}\n213         if self.is_active(request) and sensitive_variables:\n214             if sensitive_variables == '__ALL__':\n215                 # Cleanse all variables\n216                 for name in tb_frame.f_locals:\n217                     cleansed[name] = CLEANSED_SUBSTITUTE\n218             else:\n219                 # Cleanse specified variables\n220                 for name, value in tb_frame.f_locals.items():\n221                     if name in sensitive_variables:\n222                         value = CLEANSED_SUBSTITUTE\n223                     else:\n224                         value = self.cleanse_special_types(request, value)\n225                     cleansed[name] = value\n226         else:\n227             # Potentially cleanse the request and any MultiValueDicts if they\n228             # are one of the frame variables.\n229             for name, value in tb_frame.f_locals.items():\n230                 cleansed[name] = self.cleanse_special_types(request, value)\n231 \n232         if (tb_frame.f_code.co_name == 'sensitive_variables_wrapper' and\n233                 'sensitive_variables_wrapper' in tb_frame.f_locals):\n234             # For good measure, obfuscate the decorated function's arguments in\n235             # the sensitive_variables decorator's frame, in case the variables\n236             # associated with those arguments were meant to be obfuscated from\n237             # the decorated function's frame.\n238             cleansed['func_args'] = CLEANSED_SUBSTITUTE\n239             cleansed['func_kwargs'] = CLEANSED_SUBSTITUTE\n240 \n241         return cleansed.items()\n242 \n243 \n244 class ExceptionReporter:\n245     \"\"\"Organize and coordinate reporting on exceptions.\"\"\"\n246     def __init__(self, request, exc_type, exc_value, tb, is_email=False):\n247         self.request = request\n248         self.filter = get_exception_reporter_filter(self.request)\n249         self.exc_type = exc_type\n250         self.exc_value = exc_value\n251         self.tb = tb\n252         self.is_email = is_email\n253 \n254         self.template_info = getattr(self.exc_value, 'template_debug', None)\n255         self.template_does_not_exist = False\n256         self.postmortem = None\n257 \n258     def get_traceback_data(self):\n259         \"\"\"Return a dictionary containing traceback information.\"\"\"\n260         if self.exc_type and issubclass(self.exc_type, TemplateDoesNotExist):\n261             self.template_does_not_exist = True\n262             self.postmortem = self.exc_value.chain or [self.exc_value]\n263 \n264         frames = self.get_traceback_frames()\n265         for i, frame in enumerate(frames):\n266             if 'vars' in frame:\n267                 frame_vars = []\n268                 for k, v in frame['vars']:\n269                     v = pprint(v)\n270                     # Trim large blobs of data\n271                     if len(v) > 4096:\n272                         v = '%s\u2026 <trimmed %d bytes string>' % (v[0:4096], len(v))\n273                     frame_vars.append((k, v))\n274                 frame['vars'] = frame_vars\n275             frames[i] = frame\n276 \n277         unicode_hint = ''\n278         if self.exc_type and issubclass(self.exc_type, UnicodeError):\n279             start = getattr(self.exc_value, 'start', None)\n280             end = getattr(self.exc_value, 'end', None)\n281             if start is not None and end is not None:\n282                 unicode_str = self.exc_value.args[1]\n283                 unicode_hint = force_text(\n284                     unicode_str[max(start - 5, 0):min(end + 5, len(unicode_str))],\n285                     'ascii', errors='replace'\n286                 )\n287         from django import get_version\n288 \n289         if self.request is None:\n290             user_str = None\n291         else:\n292             try:\n293                 user_str = str(self.request.user)\n294             except Exception:\n295                 # request.user may raise OperationalError if the database is\n296                 # unavailable, for example.\n297                 user_str = '[unable to retrieve the current user]'\n298 \n299         c = {\n300             'is_email': self.is_email,\n301             'unicode_hint': unicode_hint,\n302             'frames': frames,\n303             'request': self.request,\n304             'user_str': user_str,\n305             'filtered_POST_items': list(self.filter.get_post_parameters(self.request).items()),\n306             'settings': get_safe_settings(),\n307             'sys_executable': sys.executable,\n308             'sys_version_info': '%d.%d.%d' % sys.version_info[0:3],\n309             'server_time': timezone.now(),\n310             'django_version_info': get_version(),\n311             'sys_path': sys.path,\n312             'template_info': self.template_info,\n313             'template_does_not_exist': self.template_does_not_exist,\n314             'postmortem': self.postmortem,\n315         }\n316         if self.request is not None:\n317             c['request_GET_items'] = self.request.GET.items()\n318             c['request_FILES_items'] = self.request.FILES.items()\n319             c['request_COOKIES_items'] = self.request.COOKIES.items()\n320         # Check whether exception info is available\n321         if self.exc_type:\n322             c['exception_type'] = self.exc_type.__name__\n323         if self.exc_value:\n324             c['exception_value'] = str(self.exc_value)\n325         if frames:\n326             c['lastframe'] = frames[-1]\n327         return c\n328 \n329     def get_traceback_html(self):\n330         \"\"\"Return HTML version of debug 500 HTTP error page.\"\"\"\n331         with Path(CURRENT_DIR, 'templates', 'technical_500.html').open() as fh:\n332             t = DEBUG_ENGINE.from_string(fh.read())\n333         c = Context(self.get_traceback_data(), use_l10n=False)\n334         return t.render(c)\n335 \n336     def get_traceback_text(self):\n337         \"\"\"Return plain text version of debug 500 HTTP error page.\"\"\"\n338         with Path(CURRENT_DIR, 'templates', 'technical_500.txt').open() as fh:\n339             t = DEBUG_ENGINE.from_string(fh.read())\n340         c = Context(self.get_traceback_data(), autoescape=False, use_l10n=False)\n341         return t.render(c)\n342 \n343     def _get_lines_from_file(self, filename, lineno, context_lines, loader=None, module_name=None):\n344         \"\"\"\n345         Return context_lines before and after lineno from file.\n346         Return (pre_context_lineno, pre_context, context_line, post_context).\n347         \"\"\"\n348         source = None\n349         if hasattr(loader, 'get_source'):\n350             try:\n351                 source = loader.get_source(module_name)\n352             except ImportError:\n353                 pass\n354             if source is not None:\n355                 source = source.splitlines()\n356         if source is None:\n357             try:\n358                 with open(filename, 'rb') as fp:\n359                     source = fp.read().splitlines()\n360             except (OSError, IOError):\n361                 pass\n362         if source is None:\n363             return None, [], None, []\n364 \n365         # If we just read the source from a file, or if the loader did not\n366         # apply tokenize.detect_encoding to decode the source into a\n367         # string, then we should do that ourselves.\n368         if isinstance(source[0], bytes):\n369             encoding = 'ascii'\n370             for line in source[:2]:\n371                 # File coding may be specified. Match pattern from PEP-263\n372                 # (https://www.python.org/dev/peps/pep-0263/)\n373                 match = re.search(br'coding[:=]\\s*([-\\w.]+)', line)\n374                 if match:\n375                     encoding = match.group(1).decode('ascii')\n376                     break\n377             source = [str(sline, encoding, 'replace') for sline in source]\n378 \n379         lower_bound = max(0, lineno - context_lines)\n380         upper_bound = lineno + context_lines\n381 \n382         pre_context = source[lower_bound:lineno]\n383         context_line = source[lineno]\n384         post_context = source[lineno + 1:upper_bound]\n385 \n386         return lower_bound, pre_context, context_line, post_context\n387 \n388     def get_traceback_frames(self):\n389         def explicit_or_implicit_cause(exc_value):\n390             explicit = getattr(exc_value, '__cause__', None)\n391             implicit = getattr(exc_value, '__context__', None)\n392             return explicit or implicit\n393 \n394         # Get the exception and all its causes\n395         exceptions = []\n396         exc_value = self.exc_value\n397         while exc_value:\n398             exceptions.append(exc_value)\n399             exc_value = explicit_or_implicit_cause(exc_value)\n400 \n401         frames = []\n402         # No exceptions were supplied to ExceptionReporter\n403         if not exceptions:\n404             return frames\n405 \n406         # In case there's just one exception, take the traceback from self.tb\n407         exc_value = exceptions.pop()\n408         tb = self.tb if not exceptions else exc_value.__traceback__\n409 \n410         while tb is not None:\n411             # Support for __traceback_hide__ which is used by a few libraries\n412             # to hide internal frames.\n413             if tb.tb_frame.f_locals.get('__traceback_hide__'):\n414                 tb = tb.tb_next\n415                 continue\n416             filename = tb.tb_frame.f_code.co_filename\n417             function = tb.tb_frame.f_code.co_name\n418             lineno = tb.tb_lineno - 1\n419             loader = tb.tb_frame.f_globals.get('__loader__')\n420             module_name = tb.tb_frame.f_globals.get('__name__') or ''\n421             pre_context_lineno, pre_context, context_line, post_context = self._get_lines_from_file(\n422                 filename, lineno, 7, loader, module_name,\n423             )\n424             if pre_context_lineno is None:\n425                 pre_context_lineno = lineno\n426                 pre_context = []\n427                 context_line = '<source code not available>'\n428                 post_context = []\n429             frames.append({\n430                 'exc_cause': explicit_or_implicit_cause(exc_value),\n431                 'exc_cause_explicit': getattr(exc_value, '__cause__', True),\n432                 'tb': tb,\n433                 'type': 'django' if module_name.startswith('django.') else 'user',\n434                 'filename': filename,\n435                 'function': function,\n436                 'lineno': lineno + 1,\n437                 'vars': self.filter.get_traceback_frame_variables(self.request, tb.tb_frame),\n438                 'id': id(tb),\n439                 'pre_context': pre_context,\n440                 'context_line': context_line,\n441                 'post_context': post_context,\n442                 'pre_context_lineno': pre_context_lineno + 1,\n443             })\n444 \n445             # If the traceback for current exception is consumed, try the\n446             # other exception.\n447             if not tb.tb_next and exceptions:\n448                 exc_value = exceptions.pop()\n449                 tb = exc_value.__traceback__\n450             else:\n451                 tb = tb.tb_next\n452 \n453         return frames\n454 \n455 \n456 def technical_404_response(request, exception):\n457     \"\"\"Create a technical 404 error response. `exception` is the Http404.\"\"\"\n458     try:\n459         error_url = exception.args[0]['path']\n460     except (IndexError, TypeError, KeyError):\n461         error_url = request.path_info[1:]  # Trim leading slash\n462 \n463     try:\n464         tried = exception.args[0]['tried']\n465     except (IndexError, TypeError, KeyError):\n466         tried = []\n467     else:\n468         if (not tried or (                  # empty URLconf\n469             request.path == '/' and\n470             len(tried) == 1 and             # default URLconf\n471             len(tried[0]) == 1 and\n472             getattr(tried[0][0], 'app_name', '') == getattr(tried[0][0], 'namespace', '') == 'admin'\n473         )):\n474             return default_urlconf(request)\n475 \n476     urlconf = getattr(request, 'urlconf', settings.ROOT_URLCONF)\n477     if isinstance(urlconf, types.ModuleType):\n478         urlconf = urlconf.__name__\n479 \n480     caller = ''\n481     try:\n482         resolver_match = resolve(request.path)\n483     except Resolver404:\n484         pass\n485     else:\n486         obj = resolver_match.func\n487 \n488         if hasattr(obj, '__name__'):\n489             caller = obj.__name__\n490         elif hasattr(obj, '__class__') and hasattr(obj.__class__, '__name__'):\n491             caller = obj.__class__.__name__\n492 \n493         if hasattr(obj, '__module__'):\n494             module = obj.__module__\n495             caller = '%s.%s' % (module, caller)\n496 \n497     with Path(CURRENT_DIR, 'templates', 'technical_404.html').open() as fh:\n498         t = DEBUG_ENGINE.from_string(fh.read())\n499     c = Context({\n500         'urlconf': urlconf,\n501         'root_urlconf': settings.ROOT_URLCONF,\n502         'request_path': error_url,\n503         'urlpatterns': tried,\n504         'reason': str(exception),\n505         'request': request,\n506         'settings': get_safe_settings(),\n507         'raising_view_name': caller,\n508     })\n509     return HttpResponseNotFound(t.render(c), content_type='text/html')\n510 \n511 \n512 def default_urlconf(request):\n513     \"\"\"Create an empty URLconf 404 error response.\"\"\"\n514     with Path(CURRENT_DIR, 'templates', 'default_urlconf.html').open() as fh:\n515         t = DEBUG_ENGINE.from_string(fh.read())\n516     c = Context({\n517         'version': get_docs_version(),\n518     })\n519 \n520     return HttpResponse(t.render(c), content_type='text/html')\n",
        "intended_behavior": "Replace `IOError` with `OSError` to maintain current error management strategies."
    },
    {
        "rel_file_path": "django/contrib/staticfiles/storage.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.0/django/contrib/staticfiles/storage.py",
        "start": 1,
        "end": 501,
        "class_name": null,
        "method_name": null,
        "code": "1 import hashlib\n2 import json\n3 import os\n4 import posixpath\n5 import re\n6 import warnings\n7 from collections import OrderedDict\n8 from urllib.parse import unquote, urldefrag, urlsplit, urlunsplit\n9 \n10 from django.conf import settings\n11 from django.contrib.staticfiles.utils import check_settings, matches_patterns\n12 from django.core.cache import (\n13     InvalidCacheBackendError, cache as default_cache, caches,\n14 )\n15 from django.core.exceptions import ImproperlyConfigured\n16 from django.core.files.base import ContentFile\n17 from django.core.files.storage import FileSystemStorage, get_storage_class\n18 from django.utils.deprecation import RemovedInDjango31Warning\n19 from django.utils.functional import LazyObject\n20 \n21 \n22 class StaticFilesStorage(FileSystemStorage):\n23     \"\"\"\n24     Standard file system storage for static files.\n25 \n26     The defaults for ``location`` and ``base_url`` are\n27     ``STATIC_ROOT`` and ``STATIC_URL``.\n28     \"\"\"\n29     def __init__(self, location=None, base_url=None, *args, **kwargs):\n30         if location is None:\n31             location = settings.STATIC_ROOT\n32         if base_url is None:\n33             base_url = settings.STATIC_URL\n34         check_settings(base_url)\n35         super().__init__(location, base_url, *args, **kwargs)\n36         # FileSystemStorage fallbacks to MEDIA_ROOT when location\n37         # is empty, so we restore the empty value.\n38         if not location:\n39             self.base_location = None\n40             self.location = None\n41 \n42     def path(self, name):\n43         if not self.location:\n44             raise ImproperlyConfigured(\"You're using the staticfiles app \"\n45                                        \"without having set the STATIC_ROOT \"\n46                                        \"setting to a filesystem path.\")\n47         return super().path(name)\n48 \n49 \n50 class HashedFilesMixin:\n51     default_template = \"\"\"url(\"%s\")\"\"\"\n52     max_post_process_passes = 5\n53     patterns = (\n54         (\"*.css\", (\n55             r\"\"\"(url\\(['\"]{0,1}\\s*(.*?)[\"']{0,1}\\))\"\"\",\n56             (r\"\"\"(@import\\s*[\"']\\s*(.*?)[\"'])\"\"\", \"\"\"@import url(\"%s\")\"\"\"),\n57         )),\n58     )\n59 \n60     def __init__(self, *args, **kwargs):\n61         super().__init__(*args, **kwargs)\n62         self._patterns = OrderedDict()\n63         self.hashed_files = {}\n64         for extension, patterns in self.patterns:\n65             for pattern in patterns:\n66                 if isinstance(pattern, (tuple, list)):\n67                     pattern, template = pattern\n68                 else:\n69                     template = self.default_template\n70                 compiled = re.compile(pattern, re.IGNORECASE)\n71                 self._patterns.setdefault(extension, []).append((compiled, template))\n72 \n73     def file_hash(self, name, content=None):\n74         \"\"\"\n75         Return a hash of the file with the given name and optional content.\n76         \"\"\"\n77         if content is None:\n78             return None\n79         md5 = hashlib.md5()\n80         for chunk in content.chunks():\n81             md5.update(chunk)\n82         return md5.hexdigest()[:12]\n83 \n84     def hashed_name(self, name, content=None, filename=None):\n85         # `filename` is the name of file to hash if `content` isn't given.\n86         # `name` is the base name to construct the new hashed filename from.\n87         parsed_name = urlsplit(unquote(name))\n88         clean_name = parsed_name.path.strip()\n89         filename = (filename and urlsplit(unquote(filename)).path.strip()) or clean_name\n90         opened = content is None\n91         if opened:\n92             if not self.exists(filename):\n93                 raise ValueError(\"The file '%s' could not be found with %r.\" % (filename, self))\n94             try:\n95                 content = self.open(filename)\n96             except IOError:\n97                 # Handle directory paths and fragments\n98                 return name\n99         try:\n100             file_hash = self.file_hash(clean_name, content)\n101         finally:\n102             if opened:\n103                 content.close()\n104         path, filename = os.path.split(clean_name)\n105         root, ext = os.path.splitext(filename)\n106         if file_hash is not None:\n107             file_hash = \".%s\" % file_hash\n108         hashed_name = os.path.join(path, \"%s%s%s\" %\n109                                    (root, file_hash, ext))\n110         unparsed_name = list(parsed_name)\n111         unparsed_name[2] = hashed_name\n112         # Special casing for a @font-face hack, like url(myfont.eot?#iefix\")\n113         # http://www.fontspring.com/blog/the-new-bulletproof-font-face-syntax\n114         if '?#' in name and not unparsed_name[3]:\n115             unparsed_name[2] += '?'\n116         return urlunsplit(unparsed_name)\n117 \n118     def _url(self, hashed_name_func, name, force=False, hashed_files=None):\n119         \"\"\"\n120         Return the non-hashed URL in DEBUG mode.\n121         \"\"\"\n122         if settings.DEBUG and not force:\n123             hashed_name, fragment = name, ''\n124         else:\n125             clean_name, fragment = urldefrag(name)\n126             if urlsplit(clean_name).path.endswith('/'):  # don't hash paths\n127                 hashed_name = name\n128             else:\n129                 args = (clean_name,)\n130                 if hashed_files is not None:\n131                     args += (hashed_files,)\n132                 hashed_name = hashed_name_func(*args)\n133 \n134         final_url = super().url(hashed_name)\n135 \n136         # Special casing for a @font-face hack, like url(myfont.eot?#iefix\")\n137         # http://www.fontspring.com/blog/the-new-bulletproof-font-face-syntax\n138         query_fragment = '?#' in name  # [sic!]\n139         if fragment or query_fragment:\n140             urlparts = list(urlsplit(final_url))\n141             if fragment and not urlparts[4]:\n142                 urlparts[4] = fragment\n143             if query_fragment and not urlparts[3]:\n144                 urlparts[2] += '?'\n145             final_url = urlunsplit(urlparts)\n146 \n147         return unquote(final_url)\n148 \n149     def url(self, name, force=False):\n150         \"\"\"\n151         Return the non-hashed URL in DEBUG mode.\n152         \"\"\"\n153         return self._url(self.stored_name, name, force)\n154 \n155     def url_converter(self, name, hashed_files, template=None):\n156         \"\"\"\n157         Return the custom URL converter for the given file name.\n158         \"\"\"\n159         if template is None:\n160             template = self.default_template\n161 \n162         def converter(matchobj):\n163             \"\"\"\n164             Convert the matched URL to a normalized and hashed URL.\n165 \n166             This requires figuring out which files the matched URL resolves\n167             to and calling the url() method of the storage.\n168             \"\"\"\n169             matched, url = matchobj.groups()\n170 \n171             # Ignore absolute/protocol-relative and data-uri URLs.\n172             if re.match(r'^[a-z]+:', url):\n173                 return matched\n174 \n175             # Ignore absolute URLs that don't point to a static file (dynamic\n176             # CSS / JS?). Note that STATIC_URL cannot be empty.\n177             if url.startswith('/') and not url.startswith(settings.STATIC_URL):\n178                 return matched\n179 \n180             # Strip off the fragment so a path-like fragment won't interfere.\n181             url_path, fragment = urldefrag(url)\n182 \n183             if url_path.startswith('/'):\n184                 # Otherwise the condition above would have returned prematurely.\n185                 assert url_path.startswith(settings.STATIC_URL)\n186                 target_name = url_path[len(settings.STATIC_URL):]\n187             else:\n188                 # We're using the posixpath module to mix paths and URLs conveniently.\n189                 source_name = name if os.sep == '/' else name.replace(os.sep, '/')\n190                 target_name = posixpath.join(posixpath.dirname(source_name), url_path)\n191 \n192             # Determine the hashed name of the target file with the storage backend.\n193             hashed_url = self._url(\n194                 self._stored_name, unquote(target_name),\n195                 force=True, hashed_files=hashed_files,\n196             )\n197 \n198             transformed_url = '/'.join(url_path.split('/')[:-1] + hashed_url.split('/')[-1:])\n199 \n200             # Restore the fragment that was stripped off earlier.\n201             if fragment:\n202                 transformed_url += ('?#' if '?#' in url else '#') + fragment\n203 \n204             # Return the hashed version to the file\n205             return template % unquote(transformed_url)\n206 \n207         return converter\n208 \n209     def post_process(self, paths, dry_run=False, **options):\n210         \"\"\"\n211         Post process the given OrderedDict of files (called from collectstatic).\n212 \n213         Processing is actually two separate operations:\n214 \n215         1. renaming files to include a hash of their content for cache-busting,\n216            and copying those files to the target storage.\n217         2. adjusting files which contain references to other files so they\n218            refer to the cache-busting filenames.\n219 \n220         If either of these are performed on a file, then that file is considered\n221         post-processed.\n222         \"\"\"\n223         # don't even dare to process the files if we're in dry run mode\n224         if dry_run:\n225             return\n226 \n227         # where to store the new paths\n228         hashed_files = OrderedDict()\n229 \n230         # build a list of adjustable files\n231         adjustable_paths = [\n232             path for path in paths\n233             if matches_patterns(path, self._patterns)\n234         ]\n235         # Do a single pass first. Post-process all files once, then repeat for\n236         # adjustable files.\n237         for name, hashed_name, processed, _ in self._post_process(paths, adjustable_paths, hashed_files):\n238             yield name, hashed_name, processed\n239 \n240         paths = {path: paths[path] for path in adjustable_paths}\n241 \n242         for i in range(self.max_post_process_passes):\n243             substitutions = False\n244             for name, hashed_name, processed, subst in self._post_process(paths, adjustable_paths, hashed_files):\n245                 yield name, hashed_name, processed\n246                 substitutions = substitutions or subst\n247 \n248             if not substitutions:\n249                 break\n250 \n251         if substitutions:\n252             yield 'All', None, RuntimeError('Max post-process passes exceeded.')\n253 \n254         # Store the processed paths\n255         self.hashed_files.update(hashed_files)\n256 \n257     def _post_process(self, paths, adjustable_paths, hashed_files):\n258         # Sort the files by directory level\n259         def path_level(name):\n260             return len(name.split(os.sep))\n261 \n262         for name in sorted(paths, key=path_level, reverse=True):\n263             substitutions = True\n264             # use the original, local file, not the copied-but-unprocessed\n265             # file, which might be somewhere far away, like S3\n266             storage, path = paths[name]\n267             with storage.open(path) as original_file:\n268                 cleaned_name = self.clean_name(name)\n269                 hash_key = self.hash_key(cleaned_name)\n270 \n271                 # generate the hash with the original content, even for\n272                 # adjustable files.\n273                 if hash_key not in hashed_files:\n274                     hashed_name = self.hashed_name(name, original_file)\n275                 else:\n276                     hashed_name = hashed_files[hash_key]\n277 \n278                 # then get the original's file content..\n279                 if hasattr(original_file, 'seek'):\n280                     original_file.seek(0)\n281 \n282                 hashed_file_exists = self.exists(hashed_name)\n283                 processed = False\n284 \n285                 # ..to apply each replacement pattern to the content\n286                 if name in adjustable_paths:\n287                     old_hashed_name = hashed_name\n288                     content = original_file.read().decode(settings.FILE_CHARSET)\n289                     for extension, patterns in self._patterns.items():\n290                         if matches_patterns(path, (extension,)):\n291                             for pattern, template in patterns:\n292                                 converter = self.url_converter(name, hashed_files, template)\n293                                 try:\n294                                     content = pattern.sub(converter, content)\n295                                 except ValueError as exc:\n296                                     yield name, None, exc, False\n297                     if hashed_file_exists:\n298                         self.delete(hashed_name)\n299                     # then save the processed result\n300                     content_file = ContentFile(content.encode())\n301                     # Save intermediate file for reference\n302                     saved_name = self._save(hashed_name, content_file)\n303                     hashed_name = self.hashed_name(name, content_file)\n304 \n305                     if self.exists(hashed_name):\n306                         self.delete(hashed_name)\n307 \n308                     saved_name = self._save(hashed_name, content_file)\n309                     hashed_name = self.clean_name(saved_name)\n310                     # If the file hash stayed the same, this file didn't change\n311                     if old_hashed_name == hashed_name:\n312                         substitutions = False\n313                     processed = True\n314 \n315                 if not processed:\n316                     # or handle the case in which neither processing nor\n317                     # a change to the original file happened\n318                     if not hashed_file_exists:\n319                         processed = True\n320                         saved_name = self._save(hashed_name, original_file)\n321                         hashed_name = self.clean_name(saved_name)\n322 \n323                 # and then set the cache accordingly\n324                 hashed_files[hash_key] = hashed_name\n325 \n326                 yield name, hashed_name, processed, substitutions\n327 \n328     def clean_name(self, name):\n329         return name.replace('\\\\', '/')\n330 \n331     def hash_key(self, name):\n332         return name\n333 \n334     def _stored_name(self, name, hashed_files):\n335         # Normalize the path to avoid multiple names for the same file like\n336         # ../foo/bar.css and ../foo/../foo/bar.css which normalize to the same\n337         # path.\n338         name = posixpath.normpath(name)\n339         cleaned_name = self.clean_name(name)\n340         hash_key = self.hash_key(cleaned_name)\n341         cache_name = hashed_files.get(hash_key)\n342         if cache_name is None:\n343             cache_name = self.clean_name(self.hashed_name(name))\n344         return cache_name\n345 \n346     def stored_name(self, name):\n347         cleaned_name = self.clean_name(name)\n348         hash_key = self.hash_key(cleaned_name)\n349         cache_name = self.hashed_files.get(hash_key)\n350         if cache_name:\n351             return cache_name\n352         # No cached name found, recalculate it from the files.\n353         intermediate_name = name\n354         for i in range(self.max_post_process_passes + 1):\n355             cache_name = self.clean_name(\n356                 self.hashed_name(name, content=None, filename=intermediate_name)\n357             )\n358             if intermediate_name == cache_name:\n359                 # Store the hashed name if there was a miss.\n360                 self.hashed_files[hash_key] = cache_name\n361                 return cache_name\n362             else:\n363                 # Move on to the next intermediate file.\n364                 intermediate_name = cache_name\n365         # If the cache name can't be determined after the max number of passes,\n366         # the intermediate files on disk may be corrupt; avoid an infinite loop.\n367         raise ValueError(\"The name '%s' could not be hashed with %r.\" % (name, self))\n368 \n369 \n370 class ManifestFilesMixin(HashedFilesMixin):\n371     manifest_version = '1.0'  # the manifest format standard\n372     manifest_name = 'staticfiles.json'\n373     manifest_strict = True\n374 \n375     def __init__(self, *args, **kwargs):\n376         super().__init__(*args, **kwargs)\n377         self.hashed_files = self.load_manifest()\n378 \n379     def read_manifest(self):\n380         try:\n381             with self.open(self.manifest_name) as manifest:\n382                 return manifest.read().decode()\n383         except IOError:\n384             return None\n385 \n386     def load_manifest(self):\n387         content = self.read_manifest()\n388         if content is None:\n389             return OrderedDict()\n390         try:\n391             stored = json.loads(content, object_pairs_hook=OrderedDict)\n392         except json.JSONDecodeError:\n393             pass\n394         else:\n395             version = stored.get('version')\n396             if version == '1.0':\n397                 return stored.get('paths', OrderedDict())\n398         raise ValueError(\"Couldn't load manifest '%s' (version %s)\" %\n399                          (self.manifest_name, self.manifest_version))\n400 \n401     def post_process(self, *args, **kwargs):\n402         self.hashed_files = OrderedDict()\n403         yield from super().post_process(*args, **kwargs)\n404         self.save_manifest()\n405 \n406     def save_manifest(self):\n407         payload = {'paths': self.hashed_files, 'version': self.manifest_version}\n408         if self.exists(self.manifest_name):\n409             self.delete(self.manifest_name)\n410         contents = json.dumps(payload).encode()\n411         self._save(self.manifest_name, ContentFile(contents))\n412 \n413     def stored_name(self, name):\n414         parsed_name = urlsplit(unquote(name))\n415         clean_name = parsed_name.path.strip()\n416         hash_key = self.hash_key(clean_name)\n417         cache_name = self.hashed_files.get(hash_key)\n418         if cache_name is None:\n419             if self.manifest_strict:\n420                 raise ValueError(\"Missing staticfiles manifest entry for '%s'\" % clean_name)\n421             cache_name = self.clean_name(self.hashed_name(name))\n422         unparsed_name = list(parsed_name)\n423         unparsed_name[2] = cache_name\n424         # Special casing for a @font-face hack, like url(myfont.eot?#iefix\")\n425         # http://www.fontspring.com/blog/the-new-bulletproof-font-face-syntax\n426         if '?#' in name and not unparsed_name[3]:\n427             unparsed_name[2] += '?'\n428         return urlunsplit(unparsed_name)\n429 \n430 \n431 class _MappingCache:\n432     \"\"\"\n433     A small dict-like wrapper for a given cache backend instance.\n434     \"\"\"\n435     def __init__(self, cache):\n436         self.cache = cache\n437 \n438     def __setitem__(self, key, value):\n439         self.cache.set(key, value)\n440 \n441     def __getitem__(self, key):\n442         value = self.cache.get(key)\n443         if value is None:\n444             raise KeyError(\"Couldn't find a file name '%s'\" % key)\n445         return value\n446 \n447     def clear(self):\n448         self.cache.clear()\n449 \n450     def update(self, data):\n451         self.cache.set_many(data)\n452 \n453     def get(self, key, default=None):\n454         try:\n455             return self[key]\n456         except KeyError:\n457             return default\n458 \n459 \n460 class CachedFilesMixin(HashedFilesMixin):\n461     def __init__(self, *args, **kwargs):\n462         super().__init__(*args, **kwargs)\n463         try:\n464             self.hashed_files = _MappingCache(caches['staticfiles'])\n465         except InvalidCacheBackendError:\n466             # Use the default backend\n467             self.hashed_files = _MappingCache(default_cache)\n468 \n469     def hash_key(self, name):\n470         key = hashlib.md5(self.clean_name(name).encode()).hexdigest()\n471         return 'staticfiles:%s' % key\n472 \n473 \n474 class CachedStaticFilesStorage(CachedFilesMixin, StaticFilesStorage):\n475     \"\"\"\n476     A static file system storage backend which also saves\n477     hashed copies of the files it saves.\n478     \"\"\"\n479     def __init__(self, *args, **kwargs):\n480         warnings.warn(\n481             'CachedStaticFilesStorage is deprecated in favor of '\n482             'ManifestStaticFilesStorage.',\n483             RemovedInDjango31Warning, stacklevel=2,\n484         )\n485         super().__init__(*args, **kwargs)\n486 \n487 \n488 class ManifestStaticFilesStorage(ManifestFilesMixin, StaticFilesStorage):\n489     \"\"\"\n490     A static file system storage backend which also saves\n491     hashed copies of the files it saves.\n492     \"\"\"\n493     pass\n494 \n495 \n496 class ConfiguredStorage(LazyObject):\n497     def _setup(self):\n498         self._wrapped = get_storage_class(settings.STATICFILES_STORAGE)()\n499 \n500 \n501 staticfiles_storage = ConfiguredStorage()\n",
        "intended_behavior": "Replace `IOError` with `OSError` to maintain current error management strategies."
    },
    {
        "rel_file_path": "django/contrib/gis/geos/libgeos.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.0/django/contrib/gis/geos/libgeos.py",
        "start": 21,
        "end": 71,
        "class_name": null,
        "method_name": "load_geos",
        "code": "21 def load_geos():\n22     # Custom library path set?\n23     try:\n24         from django.conf import settings\n25         lib_path = settings.GEOS_LIBRARY_PATH\n26     except (AttributeError, EnvironmentError,\n27             ImportError, ImproperlyConfigured):\n28         lib_path = None\n29 \n30     # Setting the appropriate names for the GEOS-C library.\n31     if lib_path:\n32         lib_names = None\n33     elif os.name == 'nt':\n34         # Windows NT libraries\n35         lib_names = ['geos_c', 'libgeos_c-1']\n36     elif os.name == 'posix':\n37         # *NIX libraries\n38         lib_names = ['geos_c', 'GEOS']\n39     else:\n40         raise ImportError('Unsupported OS \"%s\"' % os.name)\n41 \n42     # Using the ctypes `find_library` utility to find the path to the GEOS\n43     # shared library.  This is better than manually specifying each library name\n44     # and extension (e.g., libgeos_c.[so|so.1|dylib].).\n45     if lib_names:\n46         for lib_name in lib_names:\n47             lib_path = find_library(lib_name)\n48             if lib_path is not None:\n49                 break\n50 \n51     # No GEOS library could be found.\n52     if lib_path is None:\n53         raise ImportError(\n54             'Could not find the GEOS library (tried \"%s\"). '\n55             'Try setting GEOS_LIBRARY_PATH in your settings.' %\n56             '\", \"'.join(lib_names)\n57         )\n58     # Getting the GEOS C library.  The C interface (CDLL) is used for\n59     # both *NIX and Windows.\n60     # See the GEOS C API source code for more details on the library function calls:\n61     #  http://geos.refractions.net/ro/doxygen_docs/html/geos__c_8h-source.html\n62     _lgeos = CDLL(lib_path)\n63     # Here we set up the prototypes for the initGEOS_r and finishGEOS_r\n64     # routines.  These functions aren't actually called until they are\n65     # attached to a GEOS context handle -- this actually occurs in\n66     # geos/prototypes/threadsafe.py.\n67     _lgeos.initGEOS_r.restype = CONTEXT_PTR\n68     _lgeos.finishGEOS_r.argtypes = [CONTEXT_PTR]\n69     # Set restype for compatibility across 32 and 64-bit platforms.\n70     _lgeos.GEOSversion.restype = c_char_p\n71     return _lgeos\n",
        "intended_behavior": "`EnvironmentError` should be replaced with `OSError`, maintaining error handling for GIS feature loading."
    },
    {
        "rel_file_path": "django/contrib/gis/gdal/libgdal.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.0/django/contrib/gis/gdal/libgdal.py",
        "start": 1,
        "end": 124,
        "class_name": null,
        "method_name": null,
        "code": "1 import logging\n2 import os\n3 import re\n4 from ctypes import CDLL, CFUNCTYPE, c_char_p, c_int\n5 from ctypes.util import find_library\n6 \n7 from django.contrib.gis.gdal.error import GDALException\n8 from django.core.exceptions import ImproperlyConfigured\n9 \n10 logger = logging.getLogger('django.contrib.gis')\n11 \n12 # Custom library path set?\n13 try:\n14     from django.conf import settings\n15     lib_path = settings.GDAL_LIBRARY_PATH\n16 except (AttributeError, EnvironmentError,\n17         ImportError, ImproperlyConfigured):\n18     lib_path = None\n19 \n20 if lib_path:\n21     lib_names = None\n22 elif os.name == 'nt':\n23     # Windows NT shared libraries\n24     lib_names = ['gdal203', 'gdal202', 'gdal201', 'gdal20', 'gdal111']\n25 elif os.name == 'posix':\n26     # *NIX library names.\n27     lib_names = ['gdal', 'GDAL', 'gdal2.3.0', 'gdal2.2.0', 'gdal2.1.0', 'gdal2.0.0', 'gdal1.11.0']\n28 else:\n29     raise ImproperlyConfigured('GDAL is unsupported on OS \"%s\".' % os.name)\n30 \n31 # Using the ctypes `find_library` utility  to find the\n32 # path to the GDAL library from the list of library names.\n33 if lib_names:\n34     for lib_name in lib_names:\n35         lib_path = find_library(lib_name)\n36         if lib_path is not None:\n37             break\n38 \n39 if lib_path is None:\n40     raise ImproperlyConfigured(\n41         'Could not find the GDAL library (tried \"%s\"). Is GDAL installed? '\n42         'If it is, try setting GDAL_LIBRARY_PATH in your settings.'\n43         % '\", \"'.join(lib_names)\n44     )\n45 \n46 # This loads the GDAL/OGR C library\n47 lgdal = CDLL(lib_path)\n48 \n49 # On Windows, the GDAL binaries have some OSR routines exported with\n50 # STDCALL, while others are not.  Thus, the library will also need to\n51 # be loaded up as WinDLL for said OSR functions that require the\n52 # different calling convention.\n53 if os.name == 'nt':\n54     from ctypes import WinDLL\n55     lwingdal = WinDLL(lib_path)\n56 \n57 \n58 def std_call(func):\n59     \"\"\"\n60     Return the correct STDCALL function for certain OSR routines on Win32\n61     platforms.\n62     \"\"\"\n63     if os.name == 'nt':\n64         return lwingdal[func]\n65     else:\n66         return lgdal[func]\n67 \n68 \n69 # #### Version-information functions. ####\n70 \n71 # Return GDAL library version information with the given key.\n72 _version_info = std_call('GDALVersionInfo')\n73 _version_info.argtypes = [c_char_p]\n74 _version_info.restype = c_char_p\n75 \n76 \n77 def gdal_version():\n78     \"Return only the GDAL version number information.\"\n79     return _version_info(b'RELEASE_NAME')\n80 \n81 \n82 def gdal_full_version():\n83     \"Return the full GDAL version information.\"\n84     return _version_info('')\n85 \n86 \n87 version_regex = re.compile(r'^(?P<major>\\d+)\\.(?P<minor>\\d+)(\\.(?P<subminor>\\d+))?')\n88 \n89 \n90 def gdal_version_info():\n91     ver = gdal_version().decode()\n92     m = version_regex.match(ver)\n93     if not m:\n94         raise GDALException('Could not parse GDAL version string \"%s\"' % ver)\n95     return {key: m.group(key) for key in ('major', 'minor', 'subminor')}\n96 \n97 \n98 _verinfo = gdal_version_info()\n99 GDAL_MAJOR_VERSION = int(_verinfo['major'])\n100 GDAL_MINOR_VERSION = int(_verinfo['minor'])\n101 GDAL_SUBMINOR_VERSION = _verinfo['subminor'] and int(_verinfo['subminor'])\n102 GDAL_VERSION = (GDAL_MAJOR_VERSION, GDAL_MINOR_VERSION, GDAL_SUBMINOR_VERSION)\n103 del _verinfo\n104 \n105 # Set library error handling so as errors are logged\n106 CPLErrorHandler = CFUNCTYPE(None, c_int, c_int, c_char_p)\n107 \n108 \n109 def err_handler(error_class, error_number, message):\n110     logger.error('GDAL_ERROR %d: %s', error_number, message)\n111 \n112 \n113 err_handler = CPLErrorHandler(err_handler)\n114 \n115 \n116 def function(name, args, restype):\n117     func = std_call(name)\n118     func.argtypes = args\n119     func.restype = restype\n120     return func\n121 \n122 \n123 set_error_handler = function('CPLSetErrorHandler', [CPLErrorHandler], CPLErrorHandler)\n124 set_error_handler(err_handler)\n",
        "intended_behavior": "Replace `EnvironmentError` with `OSError` for configuration and library loading errors handling."
    },
    {
        "rel_file_path": "django/core/management/commands/runserver.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.0/django/core/management/commands/runserver.py",
        "start": 1,
        "end": 161,
        "class_name": null,
        "method_name": null,
        "code": "1 import errno\n2 import os\n3 import re\n4 import socket\n5 import sys\n6 from datetime import datetime\n7 \n8 from django.conf import settings\n9 from django.core.management.base import BaseCommand, CommandError\n10 from django.core.servers.basehttp import (\n11     WSGIServer, get_internal_wsgi_application, run,\n12 )\n13 from django.utils import autoreload\n14 \n15 naiveip_re = re.compile(r\"\"\"^(?:\n16 (?P<addr>\n17     (?P<ipv4>\\d{1,3}(?:\\.\\d{1,3}){3}) |         # IPv4 address\n18     (?P<ipv6>\\[[a-fA-F0-9:]+\\]) |               # IPv6 address\n19     (?P<fqdn>[a-zA-Z0-9-]+(?:\\.[a-zA-Z0-9-]+)*) # FQDN\n20 ):)?(?P<port>\\d+)$\"\"\", re.X)\n21 \n22 \n23 class Command(BaseCommand):\n24     help = \"Starts a lightweight Web server for development.\"\n25 \n26     # Validation is called explicitly each time the server is reloaded.\n27     requires_system_checks = False\n28     stealth_options = ('shutdown_message',)\n29 \n30     default_addr = '127.0.0.1'\n31     default_addr_ipv6 = '::1'\n32     default_port = '8000'\n33     protocol = 'http'\n34     server_cls = WSGIServer\n35 \n36     def add_arguments(self, parser):\n37         parser.add_argument(\n38             'addrport', nargs='?',\n39             help='Optional port number, or ipaddr:port'\n40         )\n41         parser.add_argument(\n42             '--ipv6', '-6', action='store_true', dest='use_ipv6',\n43             help='Tells Django to use an IPv6 address.',\n44         )\n45         parser.add_argument(\n46             '--nothreading', action='store_false', dest='use_threading',\n47             help='Tells Django to NOT use threading.',\n48         )\n49         parser.add_argument(\n50             '--noreload', action='store_false', dest='use_reloader',\n51             help='Tells Django to NOT use the auto-reloader.',\n52         )\n53 \n54     def execute(self, *args, **options):\n55         if options['no_color']:\n56             # We rely on the environment because it's currently the only\n57             # way to reach WSGIRequestHandler. This seems an acceptable\n58             # compromise considering `runserver` runs indefinitely.\n59             os.environ[\"DJANGO_COLORS\"] = \"nocolor\"\n60         super().execute(*args, **options)\n61 \n62     def get_handler(self, *args, **options):\n63         \"\"\"Return the default WSGI handler for the runner.\"\"\"\n64         return get_internal_wsgi_application()\n65 \n66     def handle(self, *args, **options):\n67         if not settings.DEBUG and not settings.ALLOWED_HOSTS:\n68             raise CommandError('You must set settings.ALLOWED_HOSTS if DEBUG is False.')\n69 \n70         self.use_ipv6 = options['use_ipv6']\n71         if self.use_ipv6 and not socket.has_ipv6:\n72             raise CommandError('Your Python does not support IPv6.')\n73         self._raw_ipv6 = False\n74         if not options['addrport']:\n75             self.addr = ''\n76             self.port = self.default_port\n77         else:\n78             m = re.match(naiveip_re, options['addrport'])\n79             if m is None:\n80                 raise CommandError('\"%s\" is not a valid port number '\n81                                    'or address:port pair.' % options['addrport'])\n82             self.addr, _ipv4, _ipv6, _fqdn, self.port = m.groups()\n83             if not self.port.isdigit():\n84                 raise CommandError(\"%r is not a valid port number.\" % self.port)\n85             if self.addr:\n86                 if _ipv6:\n87                     self.addr = self.addr[1:-1]\n88                     self.use_ipv6 = True\n89                     self._raw_ipv6 = True\n90                 elif self.use_ipv6 and not _fqdn:\n91                     raise CommandError('\"%s\" is not a valid IPv6 address.' % self.addr)\n92         if not self.addr:\n93             self.addr = self.default_addr_ipv6 if self.use_ipv6 else self.default_addr\n94             self._raw_ipv6 = self.use_ipv6\n95         self.run(**options)\n96 \n97     def run(self, **options):\n98         \"\"\"Run the server, using the autoreloader if needed.\"\"\"\n99         use_reloader = options['use_reloader']\n100 \n101         if use_reloader:\n102             autoreload.run_with_reloader(self.inner_run, **options)\n103         else:\n104             self.inner_run(None, **options)\n105 \n106     def inner_run(self, *args, **options):\n107         # If an exception was silenced in ManagementUtility.execute in order\n108         # to be raised in the child process, raise it now.\n109         autoreload.raise_last_exception()\n110 \n111         threading = options['use_threading']\n112         # 'shutdown_message' is a stealth option.\n113         shutdown_message = options.get('shutdown_message', '')\n114         quit_command = 'CTRL-BREAK' if sys.platform == 'win32' else 'CONTROL-C'\n115 \n116         self.stdout.write(\"Performing system checks\u2026\\n\\n\")\n117         self.check(display_num_errors=True)\n118         # Need to check migrations here, so can't use the\n119         # requires_migrations_check attribute.\n120         self.check_migrations()\n121         now = datetime.now().strftime('%B %d, %Y - %X')\n122         self.stdout.write(now)\n123         self.stdout.write((\n124             \"Django version %(version)s, using settings %(settings)r\\n\"\n125             \"Starting development server at %(protocol)s://%(addr)s:%(port)s/\\n\"\n126             \"Quit the server with %(quit_command)s.\\n\"\n127         ) % {\n128             \"version\": self.get_version(),\n129             \"settings\": settings.SETTINGS_MODULE,\n130             \"protocol\": self.protocol,\n131             \"addr\": '[%s]' % self.addr if self._raw_ipv6 else self.addr,\n132             \"port\": self.port,\n133             \"quit_command\": quit_command,\n134         })\n135 \n136         try:\n137             handler = self.get_handler(*args, **options)\n138             run(self.addr, int(self.port), handler,\n139                 ipv6=self.use_ipv6, threading=threading, server_cls=self.server_cls)\n140         except socket.error as e:\n141             # Use helpful error messages instead of ugly tracebacks.\n142             ERRORS = {\n143                 errno.EACCES: \"You don't have permission to access that port.\",\n144                 errno.EADDRINUSE: \"That port is already in use.\",\n145                 errno.EADDRNOTAVAIL: \"That IP address can't be assigned to.\",\n146             }\n147             try:\n148                 error_text = ERRORS[e.errno]\n149             except KeyError:\n150                 error_text = e\n151             self.stderr.write(\"Error: %s\" % error_text)\n152             # Need to use an OS exit because sys.exit doesn't work in a thread\n153             os._exit(1)\n154         except KeyboardInterrupt:\n155             if shutdown_message:\n156                 self.stdout.write(shutdown_message)\n157             sys.exit(0)\n158 \n159 \n160 # Kept for backward compatibility\n161 BaseRunserverCommand = Command\n",
        "intended_behavior": "Replace `socket.error` with `OSError` ensuring robust server operation."
    },
    {
        "rel_file_path": "django/core/servers/basehttp.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.0/django/core/servers/basehttp.py",
        "start": 1,
        "end": 213,
        "class_name": null,
        "method_name": null,
        "code": "1 \"\"\"\n2 HTTP server that implements the Python WSGI protocol (PEP 333, rev 1.21).\n3 \n4 Based on wsgiref.simple_server which is part of the standard library since 2.5.\n5 \n6 This is a simple server for use in testing or debugging Django apps. It hasn't\n7 been reviewed for security issues. DON'T USE IT FOR PRODUCTION USE!\n8 \"\"\"\n9 \n10 import logging\n11 import socket\n12 import socketserver\n13 import sys\n14 from wsgiref import simple_server\n15 \n16 from django.core.exceptions import ImproperlyConfigured\n17 from django.core.handlers.wsgi import LimitedStream\n18 from django.core.wsgi import get_wsgi_application\n19 from django.utils.module_loading import import_string\n20 \n21 __all__ = ('WSGIServer', 'WSGIRequestHandler')\n22 \n23 logger = logging.getLogger('django.server')\n24 \n25 \n26 def get_internal_wsgi_application():\n27     \"\"\"\n28     Load and return the WSGI application as configured by the user in\n29     ``settings.WSGI_APPLICATION``. With the default ``startproject`` layout,\n30     this will be the ``application`` object in ``projectname/wsgi.py``.\n31 \n32     This function, and the ``WSGI_APPLICATION`` setting itself, are only useful\n33     for Django's internal server (runserver); external WSGI servers should just\n34     be configured to point to the correct application object directly.\n35 \n36     If settings.WSGI_APPLICATION is not set (is ``None``), return\n37     whatever ``django.core.wsgi.get_wsgi_application`` returns.\n38     \"\"\"\n39     from django.conf import settings\n40     app_path = getattr(settings, 'WSGI_APPLICATION')\n41     if app_path is None:\n42         return get_wsgi_application()\n43 \n44     try:\n45         return import_string(app_path)\n46     except ImportError as err:\n47         raise ImproperlyConfigured(\n48             \"WSGI application '%s' could not be loaded; \"\n49             \"Error importing module.\" % app_path\n50         ) from err\n51 \n52 \n53 def is_broken_pipe_error():\n54     exc_type, exc_value = sys.exc_info()[:2]\n55     return issubclass(exc_type, socket.error) and exc_value.args[0] == 32\n56 \n57 \n58 class WSGIServer(simple_server.WSGIServer):\n59     \"\"\"BaseHTTPServer that implements the Python WSGI protocol\"\"\"\n60 \n61     request_queue_size = 10\n62 \n63     def __init__(self, *args, ipv6=False, allow_reuse_address=True, **kwargs):\n64         if ipv6:\n65             self.address_family = socket.AF_INET6\n66         self.allow_reuse_address = allow_reuse_address\n67         super().__init__(*args, **kwargs)\n68 \n69     def handle_error(self, request, client_address):\n70         if is_broken_pipe_error():\n71             logger.info(\"- Broken pipe from %s\\n\", client_address)\n72         else:\n73             super().handle_error(request, client_address)\n74 \n75 \n76 class ThreadedWSGIServer(socketserver.ThreadingMixIn, WSGIServer):\n77     \"\"\"A threaded version of the WSGIServer\"\"\"\n78     daemon_threads = True\n79 \n80 \n81 class ServerHandler(simple_server.ServerHandler):\n82     http_version = '1.1'\n83 \n84     def __init__(self, stdin, stdout, stderr, environ, **kwargs):\n85         \"\"\"\n86         Use a LimitedStream so that unread request data will be ignored at\n87         the end of the request. WSGIRequest uses a LimitedStream but it\n88         shouldn't discard the data since the upstream servers usually do this.\n89         This fix applies only for testserver/runserver.\n90         \"\"\"\n91         try:\n92             content_length = int(environ.get('CONTENT_LENGTH'))\n93         except (ValueError, TypeError):\n94             content_length = 0\n95         super().__init__(LimitedStream(stdin, content_length), stdout, stderr, environ, **kwargs)\n96 \n97     def cleanup_headers(self):\n98         super().cleanup_headers()\n99         # HTTP/1.1 requires support for persistent connections. Send 'close' if\n100         # the content length is unknown to prevent clients from reusing the\n101         # connection.\n102         if 'Content-Length' not in self.headers:\n103             self.headers['Connection'] = 'close'\n104         # Mark the connection for closing if it's set as such above or if the\n105         # application sent the header.\n106         if self.headers.get('Connection') == 'close':\n107             self.request_handler.close_connection = True\n108 \n109     def close(self):\n110         self.get_stdin()._read_limited()\n111         super().close()\n112 \n113     def handle_error(self):\n114         # Ignore broken pipe errors, otherwise pass on\n115         if not is_broken_pipe_error():\n116             super().handle_error()\n117 \n118 \n119 class WSGIRequestHandler(simple_server.WSGIRequestHandler):\n120     protocol_version = 'HTTP/1.1'\n121 \n122     def address_string(self):\n123         # Short-circuit parent method to not call socket.getfqdn\n124         return self.client_address[0]\n125 \n126     def log_message(self, format, *args):\n127         extra = {\n128             'request': self.request,\n129             'server_time': self.log_date_time_string(),\n130         }\n131         if args[1][0] == '4':\n132             # 0x16 = Handshake, 0x03 = SSL 3.0 or TLS 1.x\n133             if args[0].startswith('\\x16\\x03'):\n134                 extra['status_code'] = 500\n135                 logger.error(\n136                     \"You're accessing the development server over HTTPS, but \"\n137                     \"it only supports HTTP.\\n\", extra=extra,\n138                 )\n139                 return\n140 \n141         if args[1].isdigit() and len(args[1]) == 3:\n142             status_code = int(args[1])\n143             extra['status_code'] = status_code\n144 \n145             if status_code >= 500:\n146                 level = logger.error\n147             elif status_code >= 400:\n148                 level = logger.warning\n149             else:\n150                 level = logger.info\n151         else:\n152             level = logger.info\n153 \n154         level(format, *args, extra=extra)\n155 \n156     def get_environ(self):\n157         # Strip all headers with underscores in the name before constructing\n158         # the WSGI environ. This prevents header-spoofing based on ambiguity\n159         # between underscores and dashes both normalized to underscores in WSGI\n160         # env vars. Nginx and Apache 2.4+ both do this as well.\n161         for k in self.headers:\n162             if '_' in k:\n163                 del self.headers[k]\n164 \n165         return super().get_environ()\n166 \n167     def handle(self):\n168         self.close_connection = True\n169         self.handle_one_request()\n170         while not self.close_connection:\n171             self.handle_one_request()\n172         try:\n173             self.connection.shutdown(socket.SHUT_WR)\n174         except (socket.error, AttributeError):\n175             pass\n176 \n177     def handle_one_request(self):\n178         \"\"\"Copy of WSGIRequestHandler.handle() but with different ServerHandler\"\"\"\n179         self.raw_requestline = self.rfile.readline(65537)\n180         if len(self.raw_requestline) > 65536:\n181             self.requestline = ''\n182             self.request_version = ''\n183             self.command = ''\n184             self.send_error(414)\n185             return\n186 \n187         if not self.parse_request():  # An error code has been sent, just exit\n188             return\n189 \n190         handler = ServerHandler(\n191             self.rfile, self.wfile, self.get_stderr(), self.get_environ()\n192         )\n193         handler.request_handler = self      # backpointer for logging & connection closing\n194         handler.run(self.server.get_app())\n195 \n196 \n197 def run(addr, port, wsgi_handler, ipv6=False, threading=False, server_cls=WSGIServer):\n198     server_address = (addr, port)\n199     if threading:\n200         httpd_cls = type('WSGIServer', (socketserver.ThreadingMixIn, server_cls), {})\n201     else:\n202         httpd_cls = server_cls\n203     httpd = httpd_cls(server_address, WSGIRequestHandler, ipv6=ipv6)\n204     if threading:\n205         # ThreadingMixIn.daemon_threads indicates how threads will behave on an\n206         # abrupt shutdown; like quitting the server by the user or restarting\n207         # by the auto-reloader. True means the server will not wait for thread\n208         # termination before it quits. This will make auto-reloader faster\n209         # and will prevent the need to kill the server manually if a thread\n210         # isn't terminating correctly.\n211         httpd.daemon_threads = True\n212     httpd.set_app(wsgi_handler)\n213     httpd.serve_forever()\n",
        "intended_behavior": "Replace `socket.error` with `OSError` ensuring network-related errors are handled effectively."
    },
    {
        "rel_file_path": "django/core/mail/backends/smtp.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.0/django/core/mail/backends/smtp.py",
        "start": 1,
        "end": 131,
        "class_name": null,
        "method_name": null,
        "code": "1 \"\"\"SMTP email backend class.\"\"\"\n2 import smtplib\n3 import socket\n4 import ssl\n5 import threading\n6 \n7 from django.conf import settings\n8 from django.core.mail.backends.base import BaseEmailBackend\n9 from django.core.mail.message import sanitize_address\n10 from django.core.mail.utils import DNS_NAME\n11 \n12 \n13 class EmailBackend(BaseEmailBackend):\n14     \"\"\"\n15     A wrapper that manages the SMTP network connection.\n16     \"\"\"\n17     def __init__(self, host=None, port=None, username=None, password=None,\n18                  use_tls=None, fail_silently=False, use_ssl=None, timeout=None,\n19                  ssl_keyfile=None, ssl_certfile=None,\n20                  **kwargs):\n21         super().__init__(fail_silently=fail_silently)\n22         self.host = host or settings.EMAIL_HOST\n23         self.port = port or settings.EMAIL_PORT\n24         self.username = settings.EMAIL_HOST_USER if username is None else username\n25         self.password = settings.EMAIL_HOST_PASSWORD if password is None else password\n26         self.use_tls = settings.EMAIL_USE_TLS if use_tls is None else use_tls\n27         self.use_ssl = settings.EMAIL_USE_SSL if use_ssl is None else use_ssl\n28         self.timeout = settings.EMAIL_TIMEOUT if timeout is None else timeout\n29         self.ssl_keyfile = settings.EMAIL_SSL_KEYFILE if ssl_keyfile is None else ssl_keyfile\n30         self.ssl_certfile = settings.EMAIL_SSL_CERTFILE if ssl_certfile is None else ssl_certfile\n31         if self.use_ssl and self.use_tls:\n32             raise ValueError(\n33                 \"EMAIL_USE_TLS/EMAIL_USE_SSL are mutually exclusive, so only set \"\n34                 \"one of those settings to True.\")\n35         self.connection = None\n36         self._lock = threading.RLock()\n37 \n38     @property\n39     def connection_class(self):\n40         return smtplib.SMTP_SSL if self.use_ssl else smtplib.SMTP\n41 \n42     def open(self):\n43         \"\"\"\n44         Ensure an open connection to the email server. Return whether or not a\n45         new connection was required (True or False) or None if an exception\n46         passed silently.\n47         \"\"\"\n48         if self.connection:\n49             # Nothing to do if the connection is already open.\n50             return False\n51 \n52         # If local_hostname is not specified, socket.getfqdn() gets used.\n53         # For performance, we use the cached FQDN for local_hostname.\n54         connection_params = {'local_hostname': DNS_NAME.get_fqdn()}\n55         if self.timeout is not None:\n56             connection_params['timeout'] = self.timeout\n57         if self.use_ssl:\n58             connection_params.update({\n59                 'keyfile': self.ssl_keyfile,\n60                 'certfile': self.ssl_certfile,\n61             })\n62         try:\n63             self.connection = self.connection_class(self.host, self.port, **connection_params)\n64 \n65             # TLS/SSL are mutually exclusive, so only attempt TLS over\n66             # non-secure connections.\n67             if not self.use_ssl and self.use_tls:\n68                 self.connection.starttls(keyfile=self.ssl_keyfile, certfile=self.ssl_certfile)\n69             if self.username and self.password:\n70                 self.connection.login(self.username, self.password)\n71             return True\n72         except (smtplib.SMTPException, socket.error):\n73             if not self.fail_silently:\n74                 raise\n75 \n76     def close(self):\n77         \"\"\"Close the connection to the email server.\"\"\"\n78         if self.connection is None:\n79             return\n80         try:\n81             try:\n82                 self.connection.quit()\n83             except (ssl.SSLError, smtplib.SMTPServerDisconnected):\n84                 # This happens when calling quit() on a TLS connection\n85                 # sometimes, or when the connection was already disconnected\n86                 # by the server.\n87                 self.connection.close()\n88             except smtplib.SMTPException:\n89                 if self.fail_silently:\n90                     return\n91                 raise\n92         finally:\n93             self.connection = None\n94 \n95     def send_messages(self, email_messages):\n96         \"\"\"\n97         Send one or more EmailMessage objects and return the number of email\n98         messages sent.\n99         \"\"\"\n100         if not email_messages:\n101             return 0\n102         with self._lock:\n103             new_conn_created = self.open()\n104             if not self.connection or new_conn_created is None:\n105                 # We failed silently on open().\n106                 # Trying to send would be pointless.\n107                 return 0\n108             num_sent = 0\n109             for message in email_messages:\n110                 sent = self._send(message)\n111                 if sent:\n112                     num_sent += 1\n113             if new_conn_created:\n114                 self.close()\n115         return num_sent\n116 \n117     def _send(self, email_message):\n118         \"\"\"A helper method that does the actual sending.\"\"\"\n119         if not email_message.recipients():\n120             return False\n121         encoding = email_message.encoding or settings.DEFAULT_CHARSET\n122         from_email = sanitize_address(email_message.from_email, encoding)\n123         recipients = [sanitize_address(addr, encoding) for addr in email_message.recipients()]\n124         message = email_message.message()\n125         try:\n126             self.connection.sendmail(from_email, recipients, message.as_bytes(linesep='\\r\\n'))\n127         except smtplib.SMTPException:\n128             if not self.fail_silently:\n129                 raise\n130             return False\n131         return True\n",
        "intended_behavior": "`socket.error` and `SMTPException` replacements with `OSError` should maintain SMTP operations and error handling as before."
    }
]