[
    {
        "rel_file_path": "django/db/backends/sqlite3/base.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.2/django/db/backends/sqlite3/base.py",
        "start": 1,
        "end": 614,
        "class_name": null,
        "method_name": null,
        "code": "1 \"\"\"\n2 SQLite backend for the sqlite3 module in the standard library.\n3 \"\"\"\n4 import datetime\n5 import decimal\n6 import functools\n7 import hashlib\n8 import math\n9 import operator\n10 import random\n11 import re\n12 import statistics\n13 import warnings\n14 from itertools import chain\n15 from sqlite3 import dbapi2 as Database\n16 \n17 import pytz\n18 \n19 from django.core.exceptions import ImproperlyConfigured\n20 from django.db import IntegrityError\n21 from django.db.backends import utils as backend_utils\n22 from django.db.backends.base.base import BaseDatabaseWrapper\n23 from django.utils import timezone\n24 from django.utils.asyncio import async_unsafe\n25 from django.utils.dateparse import parse_datetime, parse_time\n26 from django.utils.duration import duration_microseconds\n27 from django.utils.regex_helper import _lazy_re_compile\n28 from django.utils.version import PY38\n29 \n30 from .client import DatabaseClient\n31 from .creation import DatabaseCreation\n32 from .features import DatabaseFeatures\n33 from .introspection import DatabaseIntrospection\n34 from .operations import DatabaseOperations\n35 from .schema import DatabaseSchemaEditor\n36 \n37 \n38 def decoder(conv_func):\n39     \"\"\"\n40     Convert bytestrings from Python's sqlite3 interface to a regular string.\n41     \"\"\"\n42     return lambda s: conv_func(s.decode())\n43 \n44 \n45 def none_guard(func):\n46     \"\"\"\n47     Decorator that returns None if any of the arguments to the decorated\n48     function are None. Many SQL functions return NULL if any of their arguments\n49     are NULL. This decorator simplifies the implementation of this for the\n50     custom functions registered below.\n51     \"\"\"\n52     @functools.wraps(func)\n53     def wrapper(*args, **kwargs):\n54         return None if None in args else func(*args, **kwargs)\n55     return wrapper\n56 \n57 \n58 def list_aggregate(function):\n59     \"\"\"\n60     Return an aggregate class that accumulates values in a list and applies\n61     the provided function to the data.\n62     \"\"\"\n63     return type('ListAggregate', (list,), {'finalize': function, 'step': list.append})\n64 \n65 \n66 def check_sqlite_version():\n67     if Database.sqlite_version_info < (3, 8, 3):\n68         raise ImproperlyConfigured('SQLite 3.8.3 or later is required (found %s).' % Database.sqlite_version)\n69 \n70 \n71 check_sqlite_version()\n72 \n73 Database.register_converter(\"bool\", b'1'.__eq__)\n74 Database.register_converter(\"time\", decoder(parse_time))\n75 Database.register_converter(\"datetime\", decoder(parse_datetime))\n76 Database.register_converter(\"timestamp\", decoder(parse_datetime))\n77 \n78 Database.register_adapter(decimal.Decimal, str)\n79 \n80 \n81 class DatabaseWrapper(BaseDatabaseWrapper):\n82     vendor = 'sqlite'\n83     display_name = 'SQLite'\n84     # SQLite doesn't actually support most of these types, but it \"does the right\n85     # thing\" given more verbose field definitions, so leave them as is so that\n86     # schema inspection is more useful.\n87     data_types = {\n88         'AutoField': 'integer',\n89         'BigAutoField': 'integer',\n90         'BinaryField': 'BLOB',\n91         'BooleanField': 'bool',\n92         'CharField': 'varchar(%(max_length)s)',\n93         'DateField': 'date',\n94         'DateTimeField': 'datetime',\n95         'DecimalField': 'decimal',\n96         'DurationField': 'bigint',\n97         'FileField': 'varchar(%(max_length)s)',\n98         'FilePathField': 'varchar(%(max_length)s)',\n99         'FloatField': 'real',\n100         'IntegerField': 'integer',\n101         'BigIntegerField': 'bigint',\n102         'IPAddressField': 'char(15)',\n103         'GenericIPAddressField': 'char(39)',\n104         'JSONField': 'text',\n105         'NullBooleanField': 'bool',\n106         'OneToOneField': 'integer',\n107         'PositiveBigIntegerField': 'bigint unsigned',\n108         'PositiveIntegerField': 'integer unsigned',\n109         'PositiveSmallIntegerField': 'smallint unsigned',\n110         'SlugField': 'varchar(%(max_length)s)',\n111         'SmallAutoField': 'integer',\n112         'SmallIntegerField': 'smallint',\n113         'TextField': 'text',\n114         'TimeField': 'time',\n115         'UUIDField': 'char(32)',\n116     }\n117     data_type_check_constraints = {\n118         'PositiveBigIntegerField': '\"%(column)s\" >= 0',\n119         'JSONField': '(JSON_VALID(\"%(column)s\") OR \"%(column)s\" IS NULL)',\n120         'PositiveIntegerField': '\"%(column)s\" >= 0',\n121         'PositiveSmallIntegerField': '\"%(column)s\" >= 0',\n122     }\n123     data_types_suffix = {\n124         'AutoField': 'AUTOINCREMENT',\n125         'BigAutoField': 'AUTOINCREMENT',\n126         'SmallAutoField': 'AUTOINCREMENT',\n127     }\n128     # SQLite requires LIKE statements to include an ESCAPE clause if the value\n129     # being escaped has a percent or underscore in it.\n130     # See https://www.sqlite.org/lang_expr.html for an explanation.\n131     operators = {\n132         'exact': '= %s',\n133         'iexact': \"LIKE %s ESCAPE '\\\\'\",\n134         'contains': \"LIKE %s ESCAPE '\\\\'\",\n135         'icontains': \"LIKE %s ESCAPE '\\\\'\",\n136         'regex': 'REGEXP %s',\n137         'iregex': \"REGEXP '(?i)' || %s\",\n138         'gt': '> %s',\n139         'gte': '>= %s',\n140         'lt': '< %s',\n141         'lte': '<= %s',\n142         'startswith': \"LIKE %s ESCAPE '\\\\'\",\n143         'endswith': \"LIKE %s ESCAPE '\\\\'\",\n144         'istartswith': \"LIKE %s ESCAPE '\\\\'\",\n145         'iendswith': \"LIKE %s ESCAPE '\\\\'\",\n146     }\n147 \n148     # The patterns below are used to generate SQL pattern lookup clauses when\n149     # the right-hand side of the lookup isn't a raw string (it might be an expression\n150     # or the result of a bilateral transformation).\n151     # In those cases, special characters for LIKE operators (e.g. \\, *, _) should be\n152     # escaped on database side.\n153     #\n154     # Note: we use str.format() here for readability as '%' is used as a wildcard for\n155     # the LIKE operator.\n156     pattern_esc = r\"REPLACE(REPLACE(REPLACE({}, '\\', '\\\\'), '%%', '\\%%'), '_', '\\_')\"\n157     pattern_ops = {\n158         'contains': r\"LIKE '%%' || {} || '%%' ESCAPE '\\'\",\n159         'icontains': r\"LIKE '%%' || UPPER({}) || '%%' ESCAPE '\\'\",\n160         'startswith': r\"LIKE {} || '%%' ESCAPE '\\'\",\n161         'istartswith': r\"LIKE UPPER({}) || '%%' ESCAPE '\\'\",\n162         'endswith': r\"LIKE '%%' || {} ESCAPE '\\'\",\n163         'iendswith': r\"LIKE '%%' || UPPER({}) ESCAPE '\\'\",\n164     }\n165 \n166     Database = Database\n167     SchemaEditorClass = DatabaseSchemaEditor\n168     # Classes instantiated in __init__().\n169     client_class = DatabaseClient\n170     creation_class = DatabaseCreation\n171     features_class = DatabaseFeatures\n172     introspection_class = DatabaseIntrospection\n173     ops_class = DatabaseOperations\n174 \n175     def get_connection_params(self):\n176         settings_dict = self.settings_dict\n177         if not settings_dict['NAME']:\n178             raise ImproperlyConfigured(\n179                 \"settings.DATABASES is improperly configured. \"\n180                 \"Please supply the NAME value.\")\n181         kwargs = {\n182             # TODO: Remove str() when dropping support for PY36.\n183             # https://bugs.python.org/issue33496\n184             'database': str(settings_dict['NAME']),\n185             'detect_types': Database.PARSE_DECLTYPES | Database.PARSE_COLNAMES,\n186             **settings_dict['OPTIONS'],\n187         }\n188         # Always allow the underlying SQLite connection to be shareable\n189         # between multiple threads. The safe-guarding will be handled at a\n190         # higher level by the `BaseDatabaseWrapper.allow_thread_sharing`\n191         # property. This is necessary as the shareability is disabled by\n192         # default in pysqlite and it cannot be changed once a connection is\n193         # opened.\n194         if 'check_same_thread' in kwargs and kwargs['check_same_thread']:\n195             warnings.warn(\n196                 'The `check_same_thread` option was provided and set to '\n197                 'True. It will be overridden with False. Use the '\n198                 '`DatabaseWrapper.allow_thread_sharing` property instead '\n199                 'for controlling thread shareability.',\n200                 RuntimeWarning\n201             )\n202         kwargs.update({'check_same_thread': False, 'uri': True})\n203         return kwargs\n204 \n205     @async_unsafe\n206     def get_new_connection(self, conn_params):\n207         conn = Database.connect(**conn_params)\n208         if PY38:\n209             create_deterministic_function = functools.partial(\n210                 conn.create_function,\n211                 deterministic=True,\n212             )\n213         else:\n214             create_deterministic_function = conn.create_function\n215         create_deterministic_function('django_date_extract', 2, _sqlite_datetime_extract)\n216         create_deterministic_function('django_date_trunc', 4, _sqlite_date_trunc)\n217         create_deterministic_function('django_datetime_cast_date', 3, _sqlite_datetime_cast_date)\n218         create_deterministic_function('django_datetime_cast_time', 3, _sqlite_datetime_cast_time)\n219         create_deterministic_function('django_datetime_extract', 4, _sqlite_datetime_extract)\n220         create_deterministic_function('django_datetime_trunc', 4, _sqlite_datetime_trunc)\n221         create_deterministic_function('django_time_extract', 2, _sqlite_time_extract)\n222         create_deterministic_function('django_time_trunc', 4, _sqlite_time_trunc)\n223         create_deterministic_function('django_time_diff', 2, _sqlite_time_diff)\n224         create_deterministic_function('django_timestamp_diff', 2, _sqlite_timestamp_diff)\n225         create_deterministic_function('django_format_dtdelta', 3, _sqlite_format_dtdelta)\n226         create_deterministic_function('regexp', 2, _sqlite_regexp)\n227         create_deterministic_function('ACOS', 1, none_guard(math.acos))\n228         create_deterministic_function('ASIN', 1, none_guard(math.asin))\n229         create_deterministic_function('ATAN', 1, none_guard(math.atan))\n230         create_deterministic_function('ATAN2', 2, none_guard(math.atan2))\n231         create_deterministic_function('BITXOR', 2, none_guard(operator.xor))\n232         create_deterministic_function('CEILING', 1, none_guard(math.ceil))\n233         create_deterministic_function('COS', 1, none_guard(math.cos))\n234         create_deterministic_function('COT', 1, none_guard(lambda x: 1 / math.tan(x)))\n235         create_deterministic_function('DEGREES', 1, none_guard(math.degrees))\n236         create_deterministic_function('EXP', 1, none_guard(math.exp))\n237         create_deterministic_function('FLOOR', 1, none_guard(math.floor))\n238         create_deterministic_function('LN', 1, none_guard(math.log))\n239         create_deterministic_function('LOG', 2, none_guard(lambda x, y: math.log(y, x)))\n240         create_deterministic_function('LPAD', 3, _sqlite_lpad)\n241         create_deterministic_function('MD5', 1, none_guard(lambda x: hashlib.md5(x.encode()).hexdigest()))\n242         create_deterministic_function('MOD', 2, none_guard(math.fmod))\n243         create_deterministic_function('PI', 0, lambda: math.pi)\n244         create_deterministic_function('POWER', 2, none_guard(operator.pow))\n245         create_deterministic_function('RADIANS', 1, none_guard(math.radians))\n246         create_deterministic_function('REPEAT', 2, none_guard(operator.mul))\n247         create_deterministic_function('REVERSE', 1, none_guard(lambda x: x[::-1]))\n248         create_deterministic_function('RPAD', 3, _sqlite_rpad)\n249         create_deterministic_function('SHA1', 1, none_guard(lambda x: hashlib.sha1(x.encode()).hexdigest()))\n250         create_deterministic_function('SHA224', 1, none_guard(lambda x: hashlib.sha224(x.encode()).hexdigest()))\n251         create_deterministic_function('SHA256', 1, none_guard(lambda x: hashlib.sha256(x.encode()).hexdigest()))\n252         create_deterministic_function('SHA384', 1, none_guard(lambda x: hashlib.sha384(x.encode()).hexdigest()))\n253         create_deterministic_function('SHA512', 1, none_guard(lambda x: hashlib.sha512(x.encode()).hexdigest()))\n254         create_deterministic_function('SIGN', 1, none_guard(lambda x: (x > 0) - (x < 0)))\n255         create_deterministic_function('SIN', 1, none_guard(math.sin))\n256         create_deterministic_function('SQRT', 1, none_guard(math.sqrt))\n257         create_deterministic_function('TAN', 1, none_guard(math.tan))\n258         # Don't use the built-in RANDOM() function because it returns a value\n259         # in the range [2^63, 2^63 - 1] instead of [0, 1).\n260         conn.create_function('RAND', 0, random.random)\n261         conn.create_aggregate('STDDEV_POP', 1, list_aggregate(statistics.pstdev))\n262         conn.create_aggregate('STDDEV_SAMP', 1, list_aggregate(statistics.stdev))\n263         conn.create_aggregate('VAR_POP', 1, list_aggregate(statistics.pvariance))\n264         conn.create_aggregate('VAR_SAMP', 1, list_aggregate(statistics.variance))\n265         conn.execute('PRAGMA foreign_keys = ON')\n266         return conn\n267 \n268     def init_connection_state(self):\n269         pass\n270 \n271     def create_cursor(self, name=None):\n272         return self.connection.cursor(factory=SQLiteCursorWrapper)\n273 \n274     @async_unsafe\n275     def close(self):\n276         self.validate_thread_sharing()\n277         # If database is in memory, closing the connection destroys the\n278         # database. To prevent accidental data loss, ignore close requests on\n279         # an in-memory db.\n280         if not self.is_in_memory_db():\n281             BaseDatabaseWrapper.close(self)\n282 \n283     def _savepoint_allowed(self):\n284         # When 'isolation_level' is not None, sqlite3 commits before each\n285         # savepoint; it's a bug. When it is None, savepoints don't make sense\n286         # because autocommit is enabled. The only exception is inside 'atomic'\n287         # blocks. To work around that bug, on SQLite, 'atomic' starts a\n288         # transaction explicitly rather than simply disable autocommit.\n289         return self.in_atomic_block\n290 \n291     def _set_autocommit(self, autocommit):\n292         if autocommit:\n293             level = None\n294         else:\n295             # sqlite3's internal default is ''. It's different from None.\n296             # See Modules/_sqlite/connection.c.\n297             level = ''\n298         # 'isolation_level' is a misleading API.\n299         # SQLite always runs at the SERIALIZABLE isolation level.\n300         with self.wrap_database_errors:\n301             self.connection.isolation_level = level\n302 \n303     def disable_constraint_checking(self):\n304         with self.cursor() as cursor:\n305             cursor.execute('PRAGMA foreign_keys = OFF')\n306             # Foreign key constraints cannot be turned off while in a multi-\n307             # statement transaction. Fetch the current state of the pragma\n308             # to determine if constraints are effectively disabled.\n309             enabled = cursor.execute('PRAGMA foreign_keys').fetchone()[0]\n310         return not bool(enabled)\n311 \n312     def enable_constraint_checking(self):\n313         with self.cursor() as cursor:\n314             cursor.execute('PRAGMA foreign_keys = ON')\n315 \n316     def check_constraints(self, table_names=None):\n317         \"\"\"\n318         Check each table name in `table_names` for rows with invalid foreign\n319         key references. This method is intended to be used in conjunction with\n320         `disable_constraint_checking()` and `enable_constraint_checking()`, to\n321         determine if rows with invalid references were entered while constraint\n322         checks were off.\n323         \"\"\"\n324         if self.features.supports_pragma_foreign_key_check:\n325             with self.cursor() as cursor:\n326                 if table_names is None:\n327                     violations = cursor.execute('PRAGMA foreign_key_check').fetchall()\n328                 else:\n329                     violations = chain.from_iterable(\n330                         cursor.execute(\n331                             'PRAGMA foreign_key_check(%s)'\n332                             % self.ops.quote_name(table_name)\n333                         ).fetchall()\n334                         for table_name in table_names\n335                     )\n336                 # See https://www.sqlite.org/pragma.html#pragma_foreign_key_check\n337                 for table_name, rowid, referenced_table_name, foreign_key_index in violations:\n338                     foreign_key = cursor.execute(\n339                         'PRAGMA foreign_key_list(%s)' % self.ops.quote_name(table_name)\n340                     ).fetchall()[foreign_key_index]\n341                     column_name, referenced_column_name = foreign_key[3:5]\n342                     primary_key_column_name = self.introspection.get_primary_key_column(cursor, table_name)\n343                     primary_key_value, bad_value = cursor.execute(\n344                         'SELECT %s, %s FROM %s WHERE rowid = %%s' % (\n345                             self.ops.quote_name(primary_key_column_name),\n346                             self.ops.quote_name(column_name),\n347                             self.ops.quote_name(table_name),\n348                         ),\n349                         (rowid,),\n350                     ).fetchone()\n351                     raise IntegrityError(\n352                         \"The row in table '%s' with primary key '%s' has an \"\n353                         \"invalid foreign key: %s.%s contains a value '%s' that \"\n354                         \"does not have a corresponding value in %s.%s.\" % (\n355                             table_name, primary_key_value, table_name, column_name,\n356                             bad_value, referenced_table_name, referenced_column_name\n357                         )\n358                     )\n359         else:\n360             with self.cursor() as cursor:\n361                 if table_names is None:\n362                     table_names = self.introspection.table_names(cursor)\n363                 for table_name in table_names:\n364                     primary_key_column_name = self.introspection.get_primary_key_column(cursor, table_name)\n365                     if not primary_key_column_name:\n366                         continue\n367                     key_columns = self.introspection.get_key_columns(cursor, table_name)\n368                     for column_name, referenced_table_name, referenced_column_name in key_columns:\n369                         cursor.execute(\n370                             \"\"\"\n371                             SELECT REFERRING.`%s`, REFERRING.`%s` FROM `%s` as REFERRING\n372                             LEFT JOIN `%s` as REFERRED\n373                             ON (REFERRING.`%s` = REFERRED.`%s`)\n374                             WHERE REFERRING.`%s` IS NOT NULL AND REFERRED.`%s` IS NULL\n375                             \"\"\"\n376                             % (\n377                                 primary_key_column_name, column_name, table_name,\n378                                 referenced_table_name, column_name, referenced_column_name,\n379                                 column_name, referenced_column_name,\n380                             )\n381                         )\n382                         for bad_row in cursor.fetchall():\n383                             raise IntegrityError(\n384                                 \"The row in table '%s' with primary key '%s' has an \"\n385                                 \"invalid foreign key: %s.%s contains a value '%s' that \"\n386                                 \"does not have a corresponding value in %s.%s.\" % (\n387                                     table_name, bad_row[0], table_name, column_name,\n388                                     bad_row[1], referenced_table_name, referenced_column_name,\n389                                 )\n390                             )\n391 \n392     def is_usable(self):\n393         return True\n394 \n395     def _start_transaction_under_autocommit(self):\n396         \"\"\"\n397         Start a transaction explicitly in autocommit mode.\n398 \n399         Staying in autocommit mode works around a bug of sqlite3 that breaks\n400         savepoints when autocommit is disabled.\n401         \"\"\"\n402         self.cursor().execute(\"BEGIN\")\n403 \n404     def is_in_memory_db(self):\n405         return self.creation.is_in_memory_db(self.settings_dict['NAME'])\n406 \n407 \n408 FORMAT_QMARK_REGEX = _lazy_re_compile(r'(?<!%)%s')\n409 \n410 \n411 class SQLiteCursorWrapper(Database.Cursor):\n412     \"\"\"\n413     Django uses \"format\" style placeholders, but pysqlite2 uses \"qmark\" style.\n414     This fixes it -- but note that if you want to use a literal \"%s\" in a query,\n415     you'll need to use \"%%s\".\n416     \"\"\"\n417     def execute(self, query, params=None):\n418         if params is None:\n419             return Database.Cursor.execute(self, query)\n420         query = self.convert_query(query)\n421         return Database.Cursor.execute(self, query, params)\n422 \n423     def executemany(self, query, param_list):\n424         query = self.convert_query(query)\n425         return Database.Cursor.executemany(self, query, param_list)\n426 \n427     def convert_query(self, query):\n428         return FORMAT_QMARK_REGEX.sub('?', query).replace('%%', '%')\n429 \n430 \n431 def _sqlite_datetime_parse(dt, tzname=None, conn_tzname=None):\n432     if dt is None:\n433         return None\n434     try:\n435         dt = backend_utils.typecast_timestamp(dt)\n436     except (TypeError, ValueError):\n437         return None\n438     if conn_tzname:\n439         dt = dt.replace(tzinfo=pytz.timezone(conn_tzname))\n440     if tzname is not None and tzname != conn_tzname:\n441         sign_index = tzname.find('+') + tzname.find('-') + 1\n442         if sign_index > -1:\n443             sign = tzname[sign_index]\n444             tzname, offset = tzname.split(sign)\n445             if offset:\n446                 hours, minutes = offset.split(':')\n447                 offset_delta = datetime.timedelta(hours=int(hours), minutes=int(minutes))\n448                 dt += offset_delta if sign == '+' else -offset_delta\n449         dt = timezone.localtime(dt, pytz.timezone(tzname))\n450     return dt\n451 \n452 \n453 def _sqlite_date_trunc(lookup_type, dt, tzname, conn_tzname):\n454     dt = _sqlite_datetime_parse(dt, tzname, conn_tzname)\n455     if dt is None:\n456         return None\n457     if lookup_type == 'year':\n458         return \"%i-01-01\" % dt.year\n459     elif lookup_type == 'quarter':\n460         month_in_quarter = dt.month - (dt.month - 1) % 3\n461         return '%i-%02i-01' % (dt.year, month_in_quarter)\n462     elif lookup_type == 'month':\n463         return \"%i-%02i-01\" % (dt.year, dt.month)\n464     elif lookup_type == 'week':\n465         dt = dt - datetime.timedelta(days=dt.weekday())\n466         return \"%i-%02i-%02i\" % (dt.year, dt.month, dt.day)\n467     elif lookup_type == 'day':\n468         return \"%i-%02i-%02i\" % (dt.year, dt.month, dt.day)\n469 \n470 \n471 def _sqlite_time_trunc(lookup_type, dt, tzname, conn_tzname):\n472     if dt is None:\n473         return None\n474     dt_parsed = _sqlite_datetime_parse(dt, tzname, conn_tzname)\n475     if dt_parsed is None:\n476         try:\n477             dt = backend_utils.typecast_time(dt)\n478         except (ValueError, TypeError):\n479             return None\n480     else:\n481         dt = dt_parsed\n482     if lookup_type == 'hour':\n483         return \"%02i:00:00\" % dt.hour\n484     elif lookup_type == 'minute':\n485         return \"%02i:%02i:00\" % (dt.hour, dt.minute)\n486     elif lookup_type == 'second':\n487         return \"%02i:%02i:%02i\" % (dt.hour, dt.minute, dt.second)\n488 \n489 \n490 def _sqlite_datetime_cast_date(dt, tzname, conn_tzname):\n491     dt = _sqlite_datetime_parse(dt, tzname, conn_tzname)\n492     if dt is None:\n493         return None\n494     return dt.date().isoformat()\n495 \n496 \n497 def _sqlite_datetime_cast_time(dt, tzname, conn_tzname):\n498     dt = _sqlite_datetime_parse(dt, tzname, conn_tzname)\n499     if dt is None:\n500         return None\n501     return dt.time().isoformat()\n502 \n503 \n504 def _sqlite_datetime_extract(lookup_type, dt, tzname=None, conn_tzname=None):\n505     dt = _sqlite_datetime_parse(dt, tzname, conn_tzname)\n506     if dt is None:\n507         return None\n508     if lookup_type == 'week_day':\n509         return (dt.isoweekday() % 7) + 1\n510     elif lookup_type == 'iso_week_day':\n511         return dt.isoweekday()\n512     elif lookup_type == 'week':\n513         return dt.isocalendar()[1]\n514     elif lookup_type == 'quarter':\n515         return math.ceil(dt.month / 3)\n516     elif lookup_type == 'iso_year':\n517         return dt.isocalendar()[0]\n518     else:\n519         return getattr(dt, lookup_type)\n520 \n521 \n522 def _sqlite_datetime_trunc(lookup_type, dt, tzname, conn_tzname):\n523     dt = _sqlite_datetime_parse(dt, tzname, conn_tzname)\n524     if dt is None:\n525         return None\n526     if lookup_type == 'year':\n527         return \"%i-01-01 00:00:00\" % dt.year\n528     elif lookup_type == 'quarter':\n529         month_in_quarter = dt.month - (dt.month - 1) % 3\n530         return '%i-%02i-01 00:00:00' % (dt.year, month_in_quarter)\n531     elif lookup_type == 'month':\n532         return \"%i-%02i-01 00:00:00\" % (dt.year, dt.month)\n533     elif lookup_type == 'week':\n534         dt = dt - datetime.timedelta(days=dt.weekday())\n535         return \"%i-%02i-%02i 00:00:00\" % (dt.year, dt.month, dt.day)\n536     elif lookup_type == 'day':\n537         return \"%i-%02i-%02i 00:00:00\" % (dt.year, dt.month, dt.day)\n538     elif lookup_type == 'hour':\n539         return \"%i-%02i-%02i %02i:00:00\" % (dt.year, dt.month, dt.day, dt.hour)\n540     elif lookup_type == 'minute':\n541         return \"%i-%02i-%02i %02i:%02i:00\" % (dt.year, dt.month, dt.day, dt.hour, dt.minute)\n542     elif lookup_type == 'second':\n543         return \"%i-%02i-%02i %02i:%02i:%02i\" % (dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second)\n544 \n545 \n546 def _sqlite_time_extract(lookup_type, dt):\n547     if dt is None:\n548         return None\n549     try:\n550         dt = backend_utils.typecast_time(dt)\n551     except (ValueError, TypeError):\n552         return None\n553     return getattr(dt, lookup_type)\n554 \n555 \n556 @none_guard\n557 def _sqlite_format_dtdelta(conn, lhs, rhs):\n558     \"\"\"\n559     LHS and RHS can be either:\n560     - An integer number of microseconds\n561     - A string representing a datetime\n562     \"\"\"\n563     try:\n564         real_lhs = datetime.timedelta(0, 0, lhs) if isinstance(lhs, int) else backend_utils.typecast_timestamp(lhs)\n565         real_rhs = datetime.timedelta(0, 0, rhs) if isinstance(rhs, int) else backend_utils.typecast_timestamp(rhs)\n566         if conn.strip() == '+':\n567             out = real_lhs + real_rhs\n568         else:\n569             out = real_lhs - real_rhs\n570     except (ValueError, TypeError):\n571         return None\n572     # typecast_timestamp returns a date or a datetime without timezone.\n573     # It will be formatted as \"%Y-%m-%d\" or \"%Y-%m-%d %H:%M:%S[.%f]\"\n574     return str(out)\n575 \n576 \n577 @none_guard\n578 def _sqlite_time_diff(lhs, rhs):\n579     left = backend_utils.typecast_time(lhs)\n580     right = backend_utils.typecast_time(rhs)\n581     return (\n582         (left.hour * 60 * 60 * 1000000) +\n583         (left.minute * 60 * 1000000) +\n584         (left.second * 1000000) +\n585         (left.microsecond) -\n586         (right.hour * 60 * 60 * 1000000) -\n587         (right.minute * 60 * 1000000) -\n588         (right.second * 1000000) -\n589         (right.microsecond)\n590     )\n591 \n592 \n593 @none_guard\n594 def _sqlite_timestamp_diff(lhs, rhs):\n595     left = backend_utils.typecast_timestamp(lhs)\n596     right = backend_utils.typecast_timestamp(rhs)\n597     return duration_microseconds(left - right)\n598 \n599 \n600 @none_guard\n601 def _sqlite_regexp(re_pattern, re_string):\n602     return bool(re.search(re_pattern, str(re_string)))\n603 \n604 \n605 @none_guard\n606 def _sqlite_lpad(text, length, fill_text):\n607     if len(text) >= length:\n608         return text[:length]\n609     return (fill_text * length)[:length - len(text)] + text\n610 \n611 \n612 @none_guard\n613 def _sqlite_rpad(text, length, fill_text):\n614     return (text + fill_text * length)[:length]\n",
        "intended_behavior": "This file should ensure on initialization or connection to the SQLite database, the version of SQLite is checked to be 3.9.0 or higher, and raise an appropriate error message if not."
    },
    {
        "rel_file_path": "django/db/backends/sqlite3/schema.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.2/django/db/backends/sqlite3/schema.py",
        "start": 1,
        "end": 434,
        "class_name": null,
        "method_name": null,
        "code": "1 import copy\n2 from decimal import Decimal\n3 \n4 from django.apps.registry import Apps\n5 from django.db import NotSupportedError\n6 from django.db.backends.base.schema import BaseDatabaseSchemaEditor\n7 from django.db.backends.ddl_references import Statement\n8 from django.db.backends.utils import strip_quotes\n9 from django.db.models import UniqueConstraint\n10 from django.db.transaction import atomic\n11 \n12 \n13 class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n14 \n15     sql_delete_table = \"DROP TABLE %(table)s\"\n16     sql_create_fk = None\n17     sql_create_inline_fk = \"REFERENCES %(to_table)s (%(to_column)s) DEFERRABLE INITIALLY DEFERRED\"\n18     sql_create_unique = \"CREATE UNIQUE INDEX %(name)s ON %(table)s (%(columns)s)\"\n19     sql_delete_unique = \"DROP INDEX %(name)s\"\n20 \n21     def __enter__(self):\n22         # Some SQLite schema alterations need foreign key constraints to be\n23         # disabled. Enforce it here for the duration of the schema edition.\n24         if not self.connection.disable_constraint_checking():\n25             raise NotSupportedError(\n26                 'SQLite schema editor cannot be used while foreign key '\n27                 'constraint checks are enabled. Make sure to disable them '\n28                 'before entering a transaction.atomic() context because '\n29                 'SQLite does not support disabling them in the middle of '\n30                 'a multi-statement transaction.'\n31             )\n32         return super().__enter__()\n33 \n34     def __exit__(self, exc_type, exc_value, traceback):\n35         self.connection.check_constraints()\n36         super().__exit__(exc_type, exc_value, traceback)\n37         self.connection.enable_constraint_checking()\n38 \n39     def quote_value(self, value):\n40         # The backend \"mostly works\" without this function and there are use\n41         # cases for compiling Python without the sqlite3 libraries (e.g.\n42         # security hardening).\n43         try:\n44             import sqlite3\n45             value = sqlite3.adapt(value)\n46         except ImportError:\n47             pass\n48         except sqlite3.ProgrammingError:\n49             pass\n50         # Manual emulation of SQLite parameter quoting\n51         if isinstance(value, bool):\n52             return str(int(value))\n53         elif isinstance(value, (Decimal, float, int)):\n54             return str(value)\n55         elif isinstance(value, str):\n56             return \"'%s'\" % value.replace(\"\\'\", \"\\'\\'\")\n57         elif value is None:\n58             return \"NULL\"\n59         elif isinstance(value, (bytes, bytearray, memoryview)):\n60             # Bytes are only allowed for BLOB fields, encoded as string\n61             # literals containing hexadecimal data and preceded by a single \"X\"\n62             # character.\n63             return \"X'%s'\" % value.hex()\n64         else:\n65             raise ValueError(\"Cannot quote parameter value %r of type %s\" % (value, type(value)))\n66 \n67     def _is_referenced_by_fk_constraint(self, table_name, column_name=None, ignore_self=False):\n68         \"\"\"\n69         Return whether or not the provided table name is referenced by another\n70         one. If `column_name` is specified, only references pointing to that\n71         column are considered. If `ignore_self` is True, self-referential\n72         constraints are ignored.\n73         \"\"\"\n74         with self.connection.cursor() as cursor:\n75             for other_table in self.connection.introspection.get_table_list(cursor):\n76                 if ignore_self and other_table.name == table_name:\n77                     continue\n78                 constraints = self.connection.introspection._get_foreign_key_constraints(cursor, other_table.name)\n79                 for constraint in constraints.values():\n80                     constraint_table, constraint_column = constraint['foreign_key']\n81                     if (constraint_table == table_name and\n82                             (column_name is None or constraint_column == column_name)):\n83                         return True\n84         return False\n85 \n86     def alter_db_table(self, model, old_db_table, new_db_table, disable_constraints=True):\n87         if (not self.connection.features.supports_atomic_references_rename and\n88                 disable_constraints and self._is_referenced_by_fk_constraint(old_db_table)):\n89             if self.connection.in_atomic_block:\n90                 raise NotSupportedError((\n91                     'Renaming the %r table while in a transaction is not '\n92                     'supported on SQLite < 3.26 because it would break referential '\n93                     'integrity. Try adding `atomic = False` to the Migration class.'\n94                 ) % old_db_table)\n95             self.connection.enable_constraint_checking()\n96             super().alter_db_table(model, old_db_table, new_db_table)\n97             self.connection.disable_constraint_checking()\n98         else:\n99             super().alter_db_table(model, old_db_table, new_db_table)\n100 \n101     def alter_field(self, model, old_field, new_field, strict=False):\n102         if not self._field_should_be_altered(old_field, new_field):\n103             return\n104         old_field_name = old_field.name\n105         table_name = model._meta.db_table\n106         _, old_column_name = old_field.get_attname_column()\n107         if (new_field.name != old_field_name and\n108                 not self.connection.features.supports_atomic_references_rename and\n109                 self._is_referenced_by_fk_constraint(table_name, old_column_name, ignore_self=True)):\n110             if self.connection.in_atomic_block:\n111                 raise NotSupportedError((\n112                     'Renaming the %r.%r column while in a transaction is not '\n113                     'supported on SQLite < 3.26 because it would break referential '\n114                     'integrity. Try adding `atomic = False` to the Migration class.'\n115                 ) % (model._meta.db_table, old_field_name))\n116             with atomic(self.connection.alias):\n117                 super().alter_field(model, old_field, new_field, strict=strict)\n118                 # Follow SQLite's documented procedure for performing changes\n119                 # that don't affect the on-disk content.\n120                 # https://sqlite.org/lang_altertable.html#otheralter\n121                 with self.connection.cursor() as cursor:\n122                     schema_version = cursor.execute('PRAGMA schema_version').fetchone()[0]\n123                     cursor.execute('PRAGMA writable_schema = 1')\n124                     references_template = ' REFERENCES \"%s\" (\"%%s\") ' % table_name\n125                     new_column_name = new_field.get_attname_column()[1]\n126                     search = references_template % old_column_name\n127                     replacement = references_template % new_column_name\n128                     cursor.execute('UPDATE sqlite_master SET sql = replace(sql, %s, %s)', (search, replacement))\n129                     cursor.execute('PRAGMA schema_version = %d' % (schema_version + 1))\n130                     cursor.execute('PRAGMA writable_schema = 0')\n131                     # The integrity check will raise an exception and rollback\n132                     # the transaction if the sqlite_master updates corrupt the\n133                     # database.\n134                     cursor.execute('PRAGMA integrity_check')\n135             # Perform a VACUUM to refresh the database representation from\n136             # the sqlite_master table.\n137             with self.connection.cursor() as cursor:\n138                 cursor.execute('VACUUM')\n139         else:\n140             super().alter_field(model, old_field, new_field, strict=strict)\n141 \n142     def _remake_table(self, model, create_field=None, delete_field=None, alter_field=None):\n143         \"\"\"\n144         Shortcut to transform a model from old_model into new_model\n145 \n146         This follows the correct procedure to perform non-rename or column\n147         addition operations based on SQLite's documentation\n148 \n149         https://www.sqlite.org/lang_altertable.html#caution\n150 \n151         The essential steps are:\n152           1. Create a table with the updated definition called \"new__app_model\"\n153           2. Copy the data from the existing \"app_model\" table to the new table\n154           3. Drop the \"app_model\" table\n155           4. Rename the \"new__app_model\" table to \"app_model\"\n156           5. Restore any index of the previous \"app_model\" table.\n157         \"\"\"\n158         # Self-referential fields must be recreated rather than copied from\n159         # the old model to ensure their remote_field.field_name doesn't refer\n160         # to an altered field.\n161         def is_self_referential(f):\n162             return f.is_relation and f.remote_field.model is model\n163         # Work out the new fields dict / mapping\n164         body = {\n165             f.name: f.clone() if is_self_referential(f) else f\n166             for f in model._meta.local_concrete_fields\n167         }\n168         # Since mapping might mix column names and default values,\n169         # its values must be already quoted.\n170         mapping = {f.column: self.quote_name(f.column) for f in model._meta.local_concrete_fields}\n171         # This maps field names (not columns) for things like unique_together\n172         rename_mapping = {}\n173         # If any of the new or altered fields is introducing a new PK,\n174         # remove the old one\n175         restore_pk_field = None\n176         if getattr(create_field, 'primary_key', False) or (\n177                 alter_field and getattr(alter_field[1], 'primary_key', False)):\n178             for name, field in list(body.items()):\n179                 if field.primary_key:\n180                     field.primary_key = False\n181                     restore_pk_field = field\n182                     if field.auto_created:\n183                         del body[name]\n184                         del mapping[field.column]\n185         # Add in any created fields\n186         if create_field:\n187             body[create_field.name] = create_field\n188             # Choose a default and insert it into the copy map\n189             if not create_field.many_to_many and create_field.concrete:\n190                 mapping[create_field.column] = self.quote_value(\n191                     self.effective_default(create_field)\n192                 )\n193         # Add in any altered fields\n194         if alter_field:\n195             old_field, new_field = alter_field\n196             body.pop(old_field.name, None)\n197             mapping.pop(old_field.column, None)\n198             body[new_field.name] = new_field\n199             if old_field.null and not new_field.null:\n200                 case_sql = \"coalesce(%(col)s, %(default)s)\" % {\n201                     'col': self.quote_name(old_field.column),\n202                     'default': self.quote_value(self.effective_default(new_field))\n203                 }\n204                 mapping[new_field.column] = case_sql\n205             else:\n206                 mapping[new_field.column] = self.quote_name(old_field.column)\n207             rename_mapping[old_field.name] = new_field.name\n208         # Remove any deleted fields\n209         if delete_field:\n210             del body[delete_field.name]\n211             del mapping[delete_field.column]\n212             # Remove any implicit M2M tables\n213             if delete_field.many_to_many and delete_field.remote_field.through._meta.auto_created:\n214                 return self.delete_model(delete_field.remote_field.through)\n215         # Work inside a new app registry\n216         apps = Apps()\n217 \n218         # Work out the new value of unique_together, taking renames into\n219         # account\n220         unique_together = [\n221             [rename_mapping.get(n, n) for n in unique]\n222             for unique in model._meta.unique_together\n223         ]\n224 \n225         # Work out the new value for index_together, taking renames into\n226         # account\n227         index_together = [\n228             [rename_mapping.get(n, n) for n in index]\n229             for index in model._meta.index_together\n230         ]\n231 \n232         indexes = model._meta.indexes\n233         if delete_field:\n234             indexes = [\n235                 index for index in indexes\n236                 if delete_field.name not in index.fields\n237             ]\n238 \n239         constraints = list(model._meta.constraints)\n240 \n241         # Provide isolated instances of the fields to the new model body so\n242         # that the existing model's internals aren't interfered with when\n243         # the dummy model is constructed.\n244         body_copy = copy.deepcopy(body)\n245 \n246         # Construct a new model with the new fields to allow self referential\n247         # primary key to resolve to. This model won't ever be materialized as a\n248         # table and solely exists for foreign key reference resolution purposes.\n249         # This wouldn't be required if the schema editor was operating on model\n250         # states instead of rendered models.\n251         meta_contents = {\n252             'app_label': model._meta.app_label,\n253             'db_table': model._meta.db_table,\n254             'unique_together': unique_together,\n255             'index_together': index_together,\n256             'indexes': indexes,\n257             'constraints': constraints,\n258             'apps': apps,\n259         }\n260         meta = type(\"Meta\", (), meta_contents)\n261         body_copy['Meta'] = meta\n262         body_copy['__module__'] = model.__module__\n263         type(model._meta.object_name, model.__bases__, body_copy)\n264 \n265         # Construct a model with a renamed table name.\n266         body_copy = copy.deepcopy(body)\n267         meta_contents = {\n268             'app_label': model._meta.app_label,\n269             'db_table': 'new__%s' % strip_quotes(model._meta.db_table),\n270             'unique_together': unique_together,\n271             'index_together': index_together,\n272             'indexes': indexes,\n273             'constraints': constraints,\n274             'apps': apps,\n275         }\n276         meta = type(\"Meta\", (), meta_contents)\n277         body_copy['Meta'] = meta\n278         body_copy['__module__'] = model.__module__\n279         new_model = type('New%s' % model._meta.object_name, model.__bases__, body_copy)\n280 \n281         # Create a new table with the updated schema.\n282         self.create_model(new_model)\n283 \n284         # Copy data from the old table into the new table\n285         self.execute(\"INSERT INTO %s (%s) SELECT %s FROM %s\" % (\n286             self.quote_name(new_model._meta.db_table),\n287             ', '.join(self.quote_name(x) for x in mapping),\n288             ', '.join(mapping.values()),\n289             self.quote_name(model._meta.db_table),\n290         ))\n291 \n292         # Delete the old table to make way for the new\n293         self.delete_model(model, handle_autom2m=False)\n294 \n295         # Rename the new table to take way for the old\n296         self.alter_db_table(\n297             new_model, new_model._meta.db_table, model._meta.db_table,\n298             disable_constraints=False,\n299         )\n300 \n301         # Run deferred SQL on correct table\n302         for sql in self.deferred_sql:\n303             self.execute(sql)\n304         self.deferred_sql = []\n305         # Fix any PK-removed field\n306         if restore_pk_field:\n307             restore_pk_field.primary_key = True\n308 \n309     def delete_model(self, model, handle_autom2m=True):\n310         if handle_autom2m:\n311             super().delete_model(model)\n312         else:\n313             # Delete the table (and only that)\n314             self.execute(self.sql_delete_table % {\n315                 \"table\": self.quote_name(model._meta.db_table),\n316             })\n317             # Remove all deferred statements referencing the deleted table.\n318             for sql in list(self.deferred_sql):\n319                 if isinstance(sql, Statement) and sql.references_table(model._meta.db_table):\n320                     self.deferred_sql.remove(sql)\n321 \n322     def add_field(self, model, field):\n323         \"\"\"\n324         Create a field on a model. Usually involves adding a column, but may\n325         involve adding a table instead (for M2M fields).\n326         \"\"\"\n327         # Special-case implicit M2M tables\n328         if field.many_to_many and field.remote_field.through._meta.auto_created:\n329             return self.create_model(field.remote_field.through)\n330         self._remake_table(model, create_field=field)\n331 \n332     def remove_field(self, model, field):\n333         \"\"\"\n334         Remove a field from a model. Usually involves deleting a column,\n335         but for M2Ms may involve deleting a table.\n336         \"\"\"\n337         # M2M fields are a special case\n338         if field.many_to_many:\n339             # For implicit M2M tables, delete the auto-created table\n340             if field.remote_field.through._meta.auto_created:\n341                 self.delete_model(field.remote_field.through)\n342             # For explicit \"through\" M2M fields, do nothing\n343         # For everything else, remake.\n344         else:\n345             # It might not actually have a column behind it\n346             if field.db_parameters(connection=self.connection)['type'] is None:\n347                 return\n348             self._remake_table(model, delete_field=field)\n349 \n350     def _alter_field(self, model, old_field, new_field, old_type, new_type,\n351                      old_db_params, new_db_params, strict=False):\n352         \"\"\"Perform a \"physical\" (non-ManyToMany) field update.\"\"\"\n353         # Use \"ALTER TABLE ... RENAME COLUMN\" if only the column name\n354         # changed and there aren't any constraints.\n355         if (self.connection.features.can_alter_table_rename_column and\n356             old_field.column != new_field.column and\n357             self.column_sql(model, old_field) == self.column_sql(model, new_field) and\n358             not (old_field.remote_field and old_field.db_constraint or\n359                  new_field.remote_field and new_field.db_constraint)):\n360             return self.execute(self._rename_field_sql(model._meta.db_table, old_field, new_field, new_type))\n361         # Alter by remaking table\n362         self._remake_table(model, alter_field=(old_field, new_field))\n363         # Rebuild tables with FKs pointing to this field.\n364         if new_field.unique and old_type != new_type:\n365             related_models = set()\n366             opts = new_field.model._meta\n367             for remote_field in opts.related_objects:\n368                 # Ignore self-relationship since the table was already rebuilt.\n369                 if remote_field.related_model == model:\n370                     continue\n371                 if not remote_field.many_to_many:\n372                     if remote_field.field_name == new_field.name:\n373                         related_models.add(remote_field.related_model)\n374                 elif new_field.primary_key and remote_field.through._meta.auto_created:\n375                     related_models.add(remote_field.through)\n376             if new_field.primary_key:\n377                 for many_to_many in opts.many_to_many:\n378                     # Ignore self-relationship since the table was already rebuilt.\n379                     if many_to_many.related_model == model:\n380                         continue\n381                     if many_to_many.remote_field.through._meta.auto_created:\n382                         related_models.add(many_to_many.remote_field.through)\n383             for related_model in related_models:\n384                 self._remake_table(related_model)\n385 \n386     def _alter_many_to_many(self, model, old_field, new_field, strict):\n387         \"\"\"Alter M2Ms to repoint their to= endpoints.\"\"\"\n388         if old_field.remote_field.through._meta.db_table == new_field.remote_field.through._meta.db_table:\n389             # The field name didn't change, but some options did; we have to propagate this altering.\n390             self._remake_table(\n391                 old_field.remote_field.through,\n392                 alter_field=(\n393                     # We need the field that points to the target model, so we can tell alter_field to change it -\n394                     # this is m2m_reverse_field_name() (as opposed to m2m_field_name, which points to our model)\n395                     old_field.remote_field.through._meta.get_field(old_field.m2m_reverse_field_name()),\n396                     new_field.remote_field.through._meta.get_field(new_field.m2m_reverse_field_name()),\n397                 ),\n398             )\n399             return\n400 \n401         # Make a new through table\n402         self.create_model(new_field.remote_field.through)\n403         # Copy the data across\n404         self.execute(\"INSERT INTO %s (%s) SELECT %s FROM %s\" % (\n405             self.quote_name(new_field.remote_field.through._meta.db_table),\n406             ', '.join([\n407                 \"id\",\n408                 new_field.m2m_column_name(),\n409                 new_field.m2m_reverse_name(),\n410             ]),\n411             ', '.join([\n412                 \"id\",\n413                 old_field.m2m_column_name(),\n414                 old_field.m2m_reverse_name(),\n415             ]),\n416             self.quote_name(old_field.remote_field.through._meta.db_table),\n417         ))\n418         # Delete the old through table\n419         self.delete_model(old_field.remote_field.through)\n420 \n421     def add_constraint(self, model, constraint):\n422         if isinstance(constraint, UniqueConstraint) and constraint.condition:\n423             super().add_constraint(model, constraint)\n424         else:\n425             self._remake_table(model)\n426 \n427     def remove_constraint(self, model, constraint):\n428         if isinstance(constraint, UniqueConstraint) and constraint.condition:\n429             super().remove_constraint(model, constraint)\n430         else:\n431             self._remake_table(model)\n432 \n433     def _collate_sql(self, collation):\n434         return ' COLLATE ' + collation\n",
        "intended_behavior": "This file should be updated to use features like indexes on expressions in SQLite 3.9.0 directly, removing checks or conditional logic for supporting older versions."
    }
]