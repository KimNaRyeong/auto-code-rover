[
    {
        "rel_file_path": "django/db/migrations/migration.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__4.1/django/db/migrations/migration.py",
        "start": 7,
        "end": 201,
        "class_name": "Migration",
        "method_name": null,
        "code": "7 class Migration:\n8     \"\"\"\n9     The base class for all migrations.\n10 \n11     Migration files will import this from django.db.migrations.Migration\n12     and subclass it as a class called Migration. It will have one or more\n13     of the following attributes:\n14 \n15      - operations: A list of Operation instances, probably from django.db.migrations.operations\n16      - dependencies: A list of tuples of (app_path, migration_name)\n17      - run_before: A list of tuples of (app_path, migration_name)\n18      - replaces: A list of migration_names\n19 \n20     Note that all migrations come out of migrations and into the Loader or\n21     Graph as instances, having been initialized with their app label and name.\n22     \"\"\"\n23 \n24     # Operations to apply during this migration, in order.\n25     operations = []\n26 \n27     # Other migrations that should be run before this migration.\n28     # Should be a list of (app, migration_name).\n29     dependencies = []\n30 \n31     # Other migrations that should be run after this one (i.e. have\n32     # this migration added to their dependencies). Useful to make third-party\n33     # apps' migrations run after your AUTH_USER replacement, for example.\n34     run_before = []\n35 \n36     # Migration names in this app that this migration replaces. If this is\n37     # non-empty, this migration will only be applied if all these migrations\n38     # are not applied.\n39     replaces = []\n40 \n41     # Is this an initial migration? Initial migrations are skipped on\n42     # --fake-initial if the table or fields already exist. If None, check if\n43     # the migration has any dependencies to determine if there are dependencies\n44     # to tell if db introspection needs to be done. If True, always perform\n45     # introspection. If False, never perform introspection.\n46     initial = None\n47 \n48     # Whether to wrap the whole migration in a transaction. Only has an effect\n49     # on database backends which support transactional DDL.\n50     atomic = True\n51 \n52     def __init__(self, name, app_label):\n53         self.name = name\n54         self.app_label = app_label\n55         # Copy dependencies & other attrs as we might mutate them at runtime\n56         self.operations = list(self.__class__.operations)\n57         self.dependencies = list(self.__class__.dependencies)\n58         self.run_before = list(self.__class__.run_before)\n59         self.replaces = list(self.__class__.replaces)\n60 \n61     def __eq__(self, other):\n62         return (\n63             isinstance(other, Migration) and\n64             self.name == other.name and\n65             self.app_label == other.app_label\n66         )\n67 \n68     def __repr__(self):\n69         return \"<Migration %s.%s>\" % (self.app_label, self.name)\n70 \n71     def __str__(self):\n72         return \"%s.%s\" % (self.app_label, self.name)\n73 \n74     def __hash__(self):\n75         return hash(\"%s.%s\" % (self.app_label, self.name))\n76 \n77     def mutate_state(self, project_state, preserve=True):\n78         \"\"\"\n79         Take a ProjectState and return a new one with the migration's\n80         operations applied to it. Preserve the original object state by\n81         default and return a mutated state from a copy.\n82         \"\"\"\n83         new_state = project_state\n84         if preserve:\n85             new_state = project_state.clone()\n86 \n87         for operation in self.operations:\n88             operation.state_forwards(self.app_label, new_state)\n89         return new_state\n90 \n91     def apply(self, project_state, schema_editor, collect_sql=False):\n92         \"\"\"\n93         Take a project_state representing all migrations prior to this one\n94         and a schema_editor for a live database and apply the migration\n95         in a forwards order.\n96 \n97         Return the resulting project state for efficient reuse by following\n98         Migrations.\n99         \"\"\"\n100         for operation in self.operations:\n101             # If this operation cannot be represented as SQL, place a comment\n102             # there instead\n103             if collect_sql:\n104                 schema_editor.collected_sql.append(\"--\")\n105                 if not operation.reduces_to_sql:\n106                     schema_editor.collected_sql.append(\n107                         \"-- MIGRATION NOW PERFORMS OPERATION THAT CANNOT BE WRITTEN AS SQL:\"\n108                     )\n109                 schema_editor.collected_sql.append(\"-- %s\" % operation.describe())\n110                 schema_editor.collected_sql.append(\"--\")\n111                 if not operation.reduces_to_sql:\n112                     continue\n113             # Save the state before the operation has run\n114             old_state = project_state.clone()\n115             operation.state_forwards(self.app_label, project_state)\n116             # Run the operation\n117             atomic_operation = operation.atomic or (self.atomic and operation.atomic is not False)\n118             if not schema_editor.atomic_migration and atomic_operation:\n119                 # Force a transaction on a non-transactional-DDL backend or an\n120                 # atomic operation inside a non-atomic migration.\n121                 with atomic(schema_editor.connection.alias):\n122                     operation.database_forwards(self.app_label, schema_editor, old_state, project_state)\n123             else:\n124                 # Normal behaviour\n125                 operation.database_forwards(self.app_label, schema_editor, old_state, project_state)\n126         return project_state\n127 \n128     def unapply(self, project_state, schema_editor, collect_sql=False):\n129         \"\"\"\n130         Take a project_state representing all migrations prior to this one\n131         and a schema_editor for a live database and apply the migration\n132         in a reverse order.\n133 \n134         The backwards migration process consists of two phases:\n135 \n136         1. The intermediate states from right before the first until right\n137            after the last operation inside this migration are preserved.\n138         2. The operations are applied in reverse order using the states\n139            recorded in step 1.\n140         \"\"\"\n141         # Construct all the intermediate states we need for a reverse migration\n142         to_run = []\n143         new_state = project_state\n144         # Phase 1\n145         for operation in self.operations:\n146             # If it's irreversible, error out\n147             if not operation.reversible:\n148                 raise IrreversibleError(\"Operation %s in %s is not reversible\" % (operation, self))\n149             # Preserve new state from previous run to not tamper the same state\n150             # over all operations\n151             new_state = new_state.clone()\n152             old_state = new_state.clone()\n153             operation.state_forwards(self.app_label, new_state)\n154             to_run.insert(0, (operation, old_state, new_state))\n155 \n156         # Phase 2\n157         for operation, to_state, from_state in to_run:\n158             if collect_sql:\n159                 schema_editor.collected_sql.append(\"--\")\n160                 if not operation.reduces_to_sql:\n161                     schema_editor.collected_sql.append(\n162                         \"-- MIGRATION NOW PERFORMS OPERATION THAT CANNOT BE WRITTEN AS SQL:\"\n163                     )\n164                 schema_editor.collected_sql.append(\"-- %s\" % operation.describe())\n165                 schema_editor.collected_sql.append(\"--\")\n166                 if not operation.reduces_to_sql:\n167                     continue\n168             atomic_operation = operation.atomic or (self.atomic and operation.atomic is not False)\n169             if not schema_editor.atomic_migration and atomic_operation:\n170                 # Force a transaction on a non-transactional-DDL backend or an\n171                 # atomic operation inside a non-atomic migration.\n172                 with atomic(schema_editor.connection.alias):\n173                     operation.database_backwards(self.app_label, schema_editor, from_state, to_state)\n174             else:\n175                 # Normal behaviour\n176                 operation.database_backwards(self.app_label, schema_editor, from_state, to_state)\n177         return project_state\n178 \n179     def suggest_name(self):\n180         \"\"\"\n181         Suggest a name for the operations this migration might represent. Names\n182         are not guaranteed to be unique, but put some effort into the fallback\n183         name to avoid VCS conflicts if possible.\n184         \"\"\"\n185         if self.initial:\n186             return 'initial'\n187 \n188         raw_fragments = [op.migration_name_fragment for op in self.operations]\n189         fragments = [name for name in raw_fragments if name]\n190 \n191         if not fragments or len(fragments) != len(self.operations):\n192             return 'auto_%s' % get_migration_name_timestamp()\n193 \n194         name = fragments[0]\n195         for fragment in fragments[1:]:\n196             new_name = f'{name}_{fragment}'\n197             if len(new_name) > 52:\n198                 name = f'{name}_and_more'\n199                 break\n200             name = new_name\n201         return name\n",
        "intended_behavior": "Ensure that utilities or methods within this class that contribute to migration file naming (even indirectly via utility methods used by other classes or processes) correctly account for both squashed and non-squashed migrations when determining the next migration number, ensuring no overlap or reiteration of numbers."
    },
    {
        "rel_file_path": "django/db/migrations/autodetector.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__4.1/django/db/migrations/autodetector.py",
        "start": 18,
        "end": 1337,
        "class_name": "MigrationAutodetector",
        "method_name": null,
        "code": "18 class MigrationAutodetector:\n19     \"\"\"\n20     Take a pair of ProjectStates and compare them to see what the first would\n21     need doing to make it match the second (the second usually being the\n22     project's current state).\n23 \n24     Note that this naturally operates on entire projects at a time,\n25     as it's likely that changes interact (for example, you can't\n26     add a ForeignKey without having a migration to add the table it\n27     depends on first). A user interface may offer single-app usage\n28     if it wishes, with the caveat that it may not always be possible.\n29     \"\"\"\n30 \n31     def __init__(self, from_state, to_state, questioner=None):\n32         self.from_state = from_state\n33         self.to_state = to_state\n34         self.questioner = questioner or MigrationQuestioner()\n35         self.existing_apps = {app for app, model in from_state.models}\n36 \n37     def changes(self, graph, trim_to_apps=None, convert_apps=None, migration_name=None):\n38         \"\"\"\n39         Main entry point to produce a list of applicable changes.\n40         Take a graph to base names on and an optional set of apps\n41         to try and restrict to (restriction is not guaranteed)\n42         \"\"\"\n43         changes = self._detect_changes(convert_apps, graph)\n44         changes = self.arrange_for_graph(changes, graph, migration_name)\n45         if trim_to_apps:\n46             changes = self._trim_to_apps(changes, trim_to_apps)\n47         return changes\n48 \n49     def deep_deconstruct(self, obj):\n50         \"\"\"\n51         Recursive deconstruction for a field and its arguments.\n52         Used for full comparison for rename/alter; sometimes a single-level\n53         deconstruction will not compare correctly.\n54         \"\"\"\n55         if isinstance(obj, list):\n56             return [self.deep_deconstruct(value) for value in obj]\n57         elif isinstance(obj, tuple):\n58             return tuple(self.deep_deconstruct(value) for value in obj)\n59         elif isinstance(obj, dict):\n60             return {\n61                 key: self.deep_deconstruct(value)\n62                 for key, value in obj.items()\n63             }\n64         elif isinstance(obj, functools.partial):\n65             return (obj.func, self.deep_deconstruct(obj.args), self.deep_deconstruct(obj.keywords))\n66         elif isinstance(obj, COMPILED_REGEX_TYPE):\n67             return RegexObject(obj)\n68         elif isinstance(obj, type):\n69             # If this is a type that implements 'deconstruct' as an instance method,\n70             # avoid treating this as being deconstructible itself - see #22951\n71             return obj\n72         elif hasattr(obj, 'deconstruct'):\n73             deconstructed = obj.deconstruct()\n74             if isinstance(obj, models.Field):\n75                 # we have a field which also returns a name\n76                 deconstructed = deconstructed[1:]\n77             path, args, kwargs = deconstructed\n78             return (\n79                 path,\n80                 [self.deep_deconstruct(value) for value in args],\n81                 {\n82                     key: self.deep_deconstruct(value)\n83                     for key, value in kwargs.items()\n84                 },\n85             )\n86         else:\n87             return obj\n88 \n89     def only_relation_agnostic_fields(self, fields):\n90         \"\"\"\n91         Return a definition of the fields that ignores field names and\n92         what related fields actually relate to. Used for detecting renames (as\n93         the related fields change during renames).\n94         \"\"\"\n95         fields_def = []\n96         for name, field in sorted(fields.items()):\n97             deconstruction = self.deep_deconstruct(field)\n98             if field.remote_field and field.remote_field.model:\n99                 del deconstruction[2]['to']\n100             fields_def.append(deconstruction)\n101         return fields_def\n102 \n103     def _detect_changes(self, convert_apps=None, graph=None):\n104         \"\"\"\n105         Return a dict of migration plans which will achieve the\n106         change from from_state to to_state. The dict has app labels\n107         as keys and a list of migrations as values.\n108 \n109         The resulting migrations aren't specially named, but the names\n110         do matter for dependencies inside the set.\n111 \n112         convert_apps is the list of apps to convert to use migrations\n113         (i.e. to make initial migrations for, in the usual case)\n114 \n115         graph is an optional argument that, if provided, can help improve\n116         dependency generation and avoid potential circular dependencies.\n117         \"\"\"\n118         # The first phase is generating all the operations for each app\n119         # and gathering them into a big per-app list.\n120         # Then go through that list, order it, and split into migrations to\n121         # resolve dependencies caused by M2Ms and FKs.\n122         self.generated_operations = {}\n123         self.altered_indexes = {}\n124         self.altered_constraints = {}\n125 \n126         # Prepare some old/new state and model lists, separating\n127         # proxy models and ignoring unmigrated apps.\n128         self.old_model_keys = set()\n129         self.old_proxy_keys = set()\n130         self.old_unmanaged_keys = set()\n131         self.new_model_keys = set()\n132         self.new_proxy_keys = set()\n133         self.new_unmanaged_keys = set()\n134         for (app_label, model_name), model_state in self.from_state.models.items():\n135             if not model_state.options.get('managed', True):\n136                 self.old_unmanaged_keys.add((app_label, model_name))\n137             elif app_label not in self.from_state.real_apps:\n138                 if model_state.options.get('proxy'):\n139                     self.old_proxy_keys.add((app_label, model_name))\n140                 else:\n141                     self.old_model_keys.add((app_label, model_name))\n142 \n143         for (app_label, model_name), model_state in self.to_state.models.items():\n144             if not model_state.options.get('managed', True):\n145                 self.new_unmanaged_keys.add((app_label, model_name))\n146             elif (\n147                 app_label not in self.from_state.real_apps or\n148                 (convert_apps and app_label in convert_apps)\n149             ):\n150                 if model_state.options.get('proxy'):\n151                     self.new_proxy_keys.add((app_label, model_name))\n152                 else:\n153                     self.new_model_keys.add((app_label, model_name))\n154 \n155         self.from_state.resolve_fields_and_relations()\n156         self.to_state.resolve_fields_and_relations()\n157 \n158         # Renames have to come first\n159         self.generate_renamed_models()\n160 \n161         # Prepare lists of fields and generate through model map\n162         self._prepare_field_lists()\n163         self._generate_through_model_map()\n164 \n165         # Generate non-rename model operations\n166         self.generate_deleted_models()\n167         self.generate_created_models()\n168         self.generate_deleted_proxies()\n169         self.generate_created_proxies()\n170         self.generate_altered_options()\n171         self.generate_altered_managers()\n172 \n173         # Create the altered indexes and store them in self.altered_indexes.\n174         # This avoids the same computation in generate_removed_indexes()\n175         # and generate_added_indexes().\n176         self.create_altered_indexes()\n177         self.create_altered_constraints()\n178         # Generate index removal operations before field is removed\n179         self.generate_removed_constraints()\n180         self.generate_removed_indexes()\n181         # Generate field operations\n182         self.generate_renamed_fields()\n183         self.generate_removed_fields()\n184         self.generate_added_fields()\n185         self.generate_altered_fields()\n186         self.generate_altered_order_with_respect_to()\n187         self.generate_altered_unique_together()\n188         self.generate_altered_index_together()\n189         self.generate_added_indexes()\n190         self.generate_added_constraints()\n191         self.generate_altered_db_table()\n192 \n193         self._sort_migrations()\n194         self._build_migration_list(graph)\n195         self._optimize_migrations()\n196 \n197         return self.migrations\n198 \n199     def _prepare_field_lists(self):\n200         \"\"\"\n201         Prepare field lists and a list of the fields that used through models\n202         in the old state so dependencies can be made from the through model\n203         deletion to the field that uses it.\n204         \"\"\"\n205         self.kept_model_keys = self.old_model_keys & self.new_model_keys\n206         self.kept_proxy_keys = self.old_proxy_keys & self.new_proxy_keys\n207         self.kept_unmanaged_keys = self.old_unmanaged_keys & self.new_unmanaged_keys\n208         self.through_users = {}\n209         self.old_field_keys = {\n210             (app_label, model_name, field_name)\n211             for app_label, model_name in self.kept_model_keys\n212             for field_name in self.from_state.models[\n213                 app_label,\n214                 self.renamed_models.get((app_label, model_name), model_name)\n215             ].fields\n216         }\n217         self.new_field_keys = {\n218             (app_label, model_name, field_name)\n219             for app_label, model_name in self.kept_model_keys\n220             for field_name in self.to_state.models[app_label, model_name].fields\n221         }\n222 \n223     def _generate_through_model_map(self):\n224         \"\"\"Through model map generation.\"\"\"\n225         for app_label, model_name in sorted(self.old_model_keys):\n226             old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n227             old_model_state = self.from_state.models[app_label, old_model_name]\n228             for field_name, field in old_model_state.fields.items():\n229                 if hasattr(field, 'remote_field') and getattr(field.remote_field, 'through', None):\n230                     through_key = resolve_relation(field.remote_field.through, app_label, model_name)\n231                     self.through_users[through_key] = (app_label, old_model_name, field_name)\n232 \n233     @staticmethod\n234     def _resolve_dependency(dependency):\n235         \"\"\"\n236         Return the resolved dependency and a boolean denoting whether or not\n237         it was swappable.\n238         \"\"\"\n239         if dependency[0] != '__setting__':\n240             return dependency, False\n241         resolved_app_label, resolved_object_name = getattr(settings, dependency[1]).split('.')\n242         return (resolved_app_label, resolved_object_name.lower()) + dependency[2:], True\n243 \n244     def _build_migration_list(self, graph=None):\n245         \"\"\"\n246         Chop the lists of operations up into migrations with dependencies on\n247         each other. Do this by going through an app's list of operations until\n248         one is found that has an outgoing dependency that isn't in another\n249         app's migration yet (hasn't been chopped off its list). Then chop off\n250         the operations before it into a migration and move onto the next app.\n251         If the loops completes without doing anything, there's a circular\n252         dependency (which _should_ be impossible as the operations are\n253         all split at this point so they can't depend and be depended on).\n254         \"\"\"\n255         self.migrations = {}\n256         num_ops = sum(len(x) for x in self.generated_operations.values())\n257         chop_mode = False\n258         while num_ops:\n259             # On every iteration, we step through all the apps and see if there\n260             # is a completed set of operations.\n261             # If we find that a subset of the operations are complete we can\n262             # try to chop it off from the rest and continue, but we only\n263             # do this if we've already been through the list once before\n264             # without any chopping and nothing has changed.\n265             for app_label in sorted(self.generated_operations):\n266                 chopped = []\n267                 dependencies = set()\n268                 for operation in list(self.generated_operations[app_label]):\n269                     deps_satisfied = True\n270                     operation_dependencies = set()\n271                     for dep in operation._auto_deps:\n272                         # Temporarily resolve the swappable dependency to\n273                         # prevent circular references. While keeping the\n274                         # dependency checks on the resolved model, add the\n275                         # swappable dependencies.\n276                         original_dep = dep\n277                         dep, is_swappable_dep = self._resolve_dependency(dep)\n278                         if dep[0] != app_label:\n279                             # External app dependency. See if it's not yet\n280                             # satisfied.\n281                             for other_operation in self.generated_operations.get(dep[0], []):\n282                                 if self.check_dependency(other_operation, dep):\n283                                     deps_satisfied = False\n284                                     break\n285                             if not deps_satisfied:\n286                                 break\n287                             else:\n288                                 if is_swappable_dep:\n289                                     operation_dependencies.add((original_dep[0], original_dep[1]))\n290                                 elif dep[0] in self.migrations:\n291                                     operation_dependencies.add((dep[0], self.migrations[dep[0]][-1].name))\n292                                 else:\n293                                     # If we can't find the other app, we add a first/last dependency,\n294                                     # but only if we've already been through once and checked everything\n295                                     if chop_mode:\n296                                         # If the app already exists, we add a dependency on the last migration,\n297                                         # as we don't know which migration contains the target field.\n298                                         # If it's not yet migrated or has no migrations, we use __first__\n299                                         if graph and graph.leaf_nodes(dep[0]):\n300                                             operation_dependencies.add(graph.leaf_nodes(dep[0])[0])\n301                                         else:\n302                                             operation_dependencies.add((dep[0], \"__first__\"))\n303                                     else:\n304                                         deps_satisfied = False\n305                     if deps_satisfied:\n306                         chopped.append(operation)\n307                         dependencies.update(operation_dependencies)\n308                         del self.generated_operations[app_label][0]\n309                     else:\n310                         break\n311                 # Make a migration! Well, only if there's stuff to put in it\n312                 if dependencies or chopped:\n313                     if not self.generated_operations[app_label] or chop_mode:\n314                         subclass = type(\"Migration\", (Migration,), {\"operations\": [], \"dependencies\": []})\n315                         instance = subclass(\"auto_%i\" % (len(self.migrations.get(app_label, [])) + 1), app_label)\n316                         instance.dependencies = list(dependencies)\n317                         instance.operations = chopped\n318                         instance.initial = app_label not in self.existing_apps\n319                         self.migrations.setdefault(app_label, []).append(instance)\n320                         chop_mode = False\n321                     else:\n322                         self.generated_operations[app_label] = chopped + self.generated_operations[app_label]\n323             new_num_ops = sum(len(x) for x in self.generated_operations.values())\n324             if new_num_ops == num_ops:\n325                 if not chop_mode:\n326                     chop_mode = True\n327                 else:\n328                     raise ValueError(\"Cannot resolve operation dependencies: %r\" % self.generated_operations)\n329             num_ops = new_num_ops\n330 \n331     def _sort_migrations(self):\n332         \"\"\"\n333         Reorder to make things possible. Reordering may be needed so FKs work\n334         nicely inside the same app.\n335         \"\"\"\n336         for app_label, ops in sorted(self.generated_operations.items()):\n337             # construct a dependency graph for intra-app dependencies\n338             dependency_graph = {op: set() for op in ops}\n339             for op in ops:\n340                 for dep in op._auto_deps:\n341                     # Resolve intra-app dependencies to handle circular\n342                     # references involving a swappable model.\n343                     dep = self._resolve_dependency(dep)[0]\n344                     if dep[0] == app_label:\n345                         for op2 in ops:\n346                             if self.check_dependency(op2, dep):\n347                                 dependency_graph[op].add(op2)\n348 \n349             # we use a stable sort for deterministic tests & general behavior\n350             self.generated_operations[app_label] = stable_topological_sort(ops, dependency_graph)\n351 \n352     def _optimize_migrations(self):\n353         # Add in internal dependencies among the migrations\n354         for app_label, migrations in self.migrations.items():\n355             for m1, m2 in zip(migrations, migrations[1:]):\n356                 m2.dependencies.append((app_label, m1.name))\n357 \n358         # De-dupe dependencies\n359         for migrations in self.migrations.values():\n360             for migration in migrations:\n361                 migration.dependencies = list(set(migration.dependencies))\n362 \n363         # Optimize migrations\n364         for app_label, migrations in self.migrations.items():\n365             for migration in migrations:\n366                 migration.operations = MigrationOptimizer().optimize(migration.operations, app_label)\n367 \n368     def check_dependency(self, operation, dependency):\n369         \"\"\"\n370         Return True if the given operation depends on the given dependency,\n371         False otherwise.\n372         \"\"\"\n373         # Created model\n374         if dependency[2] is None and dependency[3] is True:\n375             return (\n376                 isinstance(operation, operations.CreateModel) and\n377                 operation.name_lower == dependency[1].lower()\n378             )\n379         # Created field\n380         elif dependency[2] is not None and dependency[3] is True:\n381             return (\n382                 (\n383                     isinstance(operation, operations.CreateModel) and\n384                     operation.name_lower == dependency[1].lower() and\n385                     any(dependency[2] == x for x, y in operation.fields)\n386                 ) or\n387                 (\n388                     isinstance(operation, operations.AddField) and\n389                     operation.model_name_lower == dependency[1].lower() and\n390                     operation.name_lower == dependency[2].lower()\n391                 )\n392             )\n393         # Removed field\n394         elif dependency[2] is not None and dependency[3] is False:\n395             return (\n396                 isinstance(operation, operations.RemoveField) and\n397                 operation.model_name_lower == dependency[1].lower() and\n398                 operation.name_lower == dependency[2].lower()\n399             )\n400         # Removed model\n401         elif dependency[2] is None and dependency[3] is False:\n402             return (\n403                 isinstance(operation, operations.DeleteModel) and\n404                 operation.name_lower == dependency[1].lower()\n405             )\n406         # Field being altered\n407         elif dependency[2] is not None and dependency[3] == \"alter\":\n408             return (\n409                 isinstance(operation, operations.AlterField) and\n410                 operation.model_name_lower == dependency[1].lower() and\n411                 operation.name_lower == dependency[2].lower()\n412             )\n413         # order_with_respect_to being unset for a field\n414         elif dependency[2] is not None and dependency[3] == \"order_wrt_unset\":\n415             return (\n416                 isinstance(operation, operations.AlterOrderWithRespectTo) and\n417                 operation.name_lower == dependency[1].lower() and\n418                 (operation.order_with_respect_to or \"\").lower() != dependency[2].lower()\n419             )\n420         # Field is removed and part of an index/unique_together\n421         elif dependency[2] is not None and dependency[3] == \"foo_together_change\":\n422             return (\n423                 isinstance(operation, (operations.AlterUniqueTogether,\n424                                        operations.AlterIndexTogether)) and\n425                 operation.name_lower == dependency[1].lower()\n426             )\n427         # Unknown dependency. Raise an error.\n428         else:\n429             raise ValueError(\"Can't handle dependency %r\" % (dependency,))\n430 \n431     def add_operation(self, app_label, operation, dependencies=None, beginning=False):\n432         # Dependencies are (app_label, model_name, field_name, create/delete as True/False)\n433         operation._auto_deps = dependencies or []\n434         if beginning:\n435             self.generated_operations.setdefault(app_label, []).insert(0, operation)\n436         else:\n437             self.generated_operations.setdefault(app_label, []).append(operation)\n438 \n439     def swappable_first_key(self, item):\n440         \"\"\"\n441         Place potential swappable models first in lists of created models (only\n442         real way to solve #22783).\n443         \"\"\"\n444         try:\n445             model_state = self.to_state.models[item]\n446             base_names = {\n447                 base if isinstance(base, str) else base.__name__\n448                 for base in model_state.bases\n449             }\n450             string_version = \"%s.%s\" % (item[0], item[1])\n451             if (\n452                 model_state.options.get('swappable') or\n453                 \"AbstractUser\" in base_names or\n454                 \"AbstractBaseUser\" in base_names or\n455                 settings.AUTH_USER_MODEL.lower() == string_version.lower()\n456             ):\n457                 return (\"___\" + item[0], \"___\" + item[1])\n458         except LookupError:\n459             pass\n460         return item\n461 \n462     def generate_renamed_models(self):\n463         \"\"\"\n464         Find any renamed models, generate the operations for them, and remove\n465         the old entry from the model lists. Must be run before other\n466         model-level generation.\n467         \"\"\"\n468         self.renamed_models = {}\n469         self.renamed_models_rel = {}\n470         added_models = self.new_model_keys - self.old_model_keys\n471         for app_label, model_name in sorted(added_models):\n472             model_state = self.to_state.models[app_label, model_name]\n473             model_fields_def = self.only_relation_agnostic_fields(model_state.fields)\n474 \n475             removed_models = self.old_model_keys - self.new_model_keys\n476             for rem_app_label, rem_model_name in removed_models:\n477                 if rem_app_label == app_label:\n478                     rem_model_state = self.from_state.models[rem_app_label, rem_model_name]\n479                     rem_model_fields_def = self.only_relation_agnostic_fields(rem_model_state.fields)\n480                     if model_fields_def == rem_model_fields_def:\n481                         if self.questioner.ask_rename_model(rem_model_state, model_state):\n482                             dependencies = []\n483                             fields = list(model_state.fields.values()) + [\n484                                 field.remote_field\n485                                 for relations in self.to_state.relations[app_label, model_name].values()\n486                                 for field in relations.values()\n487                             ]\n488                             for field in fields:\n489                                 if field.is_relation:\n490                                     dependencies.extend(\n491                                         self._get_dependencies_for_foreign_key(\n492                                             app_label, model_name, field, self.to_state,\n493                                         )\n494                                     )\n495                             self.add_operation(\n496                                 app_label,\n497                                 operations.RenameModel(\n498                                     old_name=rem_model_state.name,\n499                                     new_name=model_state.name,\n500                                 ),\n501                                 dependencies=dependencies,\n502                             )\n503                             self.renamed_models[app_label, model_name] = rem_model_name\n504                             renamed_models_rel_key = '%s.%s' % (\n505                                 rem_model_state.app_label,\n506                                 rem_model_state.name_lower,\n507                             )\n508                             self.renamed_models_rel[renamed_models_rel_key] = '%s.%s' % (\n509                                 model_state.app_label,\n510                                 model_state.name_lower,\n511                             )\n512                             self.old_model_keys.remove((rem_app_label, rem_model_name))\n513                             self.old_model_keys.add((app_label, model_name))\n514                             break\n515 \n516     def generate_created_models(self):\n517         \"\"\"\n518         Find all new models (both managed and unmanaged) and make create\n519         operations for them as well as separate operations to create any\n520         foreign key or M2M relationships (these are optimized later, if\n521         possible).\n522 \n523         Defer any model options that refer to collections of fields that might\n524         be deferred (e.g. unique_together, index_together).\n525         \"\"\"\n526         old_keys = self.old_model_keys | self.old_unmanaged_keys\n527         added_models = self.new_model_keys - old_keys\n528         added_unmanaged_models = self.new_unmanaged_keys - old_keys\n529         all_added_models = chain(\n530             sorted(added_models, key=self.swappable_first_key, reverse=True),\n531             sorted(added_unmanaged_models, key=self.swappable_first_key, reverse=True)\n532         )\n533         for app_label, model_name in all_added_models:\n534             model_state = self.to_state.models[app_label, model_name]\n535             # Gather related fields\n536             related_fields = {}\n537             primary_key_rel = None\n538             for field_name, field in model_state.fields.items():\n539                 if field.remote_field:\n540                     if field.remote_field.model:\n541                         if field.primary_key:\n542                             primary_key_rel = field.remote_field.model\n543                         elif not field.remote_field.parent_link:\n544                             related_fields[field_name] = field\n545                     if getattr(field.remote_field, 'through', None):\n546                         related_fields[field_name] = field\n547 \n548             # Are there indexes/unique|index_together to defer?\n549             indexes = model_state.options.pop('indexes')\n550             constraints = model_state.options.pop('constraints')\n551             unique_together = model_state.options.pop('unique_together', None)\n552             index_together = model_state.options.pop('index_together', None)\n553             order_with_respect_to = model_state.options.pop('order_with_respect_to', None)\n554             # Depend on the deletion of any possible proxy version of us\n555             dependencies = [\n556                 (app_label, model_name, None, False),\n557             ]\n558             # Depend on all bases\n559             for base in model_state.bases:\n560                 if isinstance(base, str) and \".\" in base:\n561                     base_app_label, base_name = base.split(\".\", 1)\n562                     dependencies.append((base_app_label, base_name, None, True))\n563                     # Depend on the removal of base fields if the new model has\n564                     # a field with the same name.\n565                     old_base_model_state = self.from_state.models.get((base_app_label, base_name))\n566                     new_base_model_state = self.to_state.models.get((base_app_label, base_name))\n567                     if old_base_model_state and new_base_model_state:\n568                         removed_base_fields = set(old_base_model_state.fields).difference(\n569                             new_base_model_state.fields,\n570                         ).intersection(model_state.fields)\n571                         for removed_base_field in removed_base_fields:\n572                             dependencies.append((base_app_label, base_name, removed_base_field, False))\n573             # Depend on the other end of the primary key if it's a relation\n574             if primary_key_rel:\n575                 dependencies.append(\n576                     resolve_relation(\n577                         primary_key_rel, app_label, model_name,\n578                     ) + (None, True)\n579                 )\n580             # Generate creation operation\n581             self.add_operation(\n582                 app_label,\n583                 operations.CreateModel(\n584                     name=model_state.name,\n585                     fields=[d for d in model_state.fields.items() if d[0] not in related_fields],\n586                     options=model_state.options,\n587                     bases=model_state.bases,\n588                     managers=model_state.managers,\n589                 ),\n590                 dependencies=dependencies,\n591                 beginning=True,\n592             )\n593 \n594             # Don't add operations which modify the database for unmanaged models\n595             if not model_state.options.get('managed', True):\n596                 continue\n597 \n598             # Generate operations for each related field\n599             for name, field in sorted(related_fields.items()):\n600                 dependencies = self._get_dependencies_for_foreign_key(\n601                     app_label, model_name, field, self.to_state,\n602                 )\n603                 # Depend on our own model being created\n604                 dependencies.append((app_label, model_name, None, True))\n605                 # Make operation\n606                 self.add_operation(\n607                     app_label,\n608                     operations.AddField(\n609                         model_name=model_name,\n610                         name=name,\n611                         field=field,\n612                     ),\n613                     dependencies=list(set(dependencies)),\n614                 )\n615             # Generate other opns\n616             if order_with_respect_to:\n617                 self.add_operation(\n618                     app_label,\n619                     operations.AlterOrderWithRespectTo(\n620                         name=model_name,\n621                         order_with_respect_to=order_with_respect_to,\n622                     ),\n623                     dependencies=[\n624                         (app_label, model_name, order_with_respect_to, True),\n625                         (app_label, model_name, None, True),\n626                     ]\n627                 )\n628             related_dependencies = [\n629                 (app_label, model_name, name, True)\n630                 for name in sorted(related_fields)\n631             ]\n632             related_dependencies.append((app_label, model_name, None, True))\n633             for index in indexes:\n634                 self.add_operation(\n635                     app_label,\n636                     operations.AddIndex(\n637                         model_name=model_name,\n638                         index=index,\n639                     ),\n640                     dependencies=related_dependencies,\n641                 )\n642             for constraint in constraints:\n643                 self.add_operation(\n644                     app_label,\n645                     operations.AddConstraint(\n646                         model_name=model_name,\n647                         constraint=constraint,\n648                     ),\n649                     dependencies=related_dependencies,\n650                 )\n651             if unique_together:\n652                 self.add_operation(\n653                     app_label,\n654                     operations.AlterUniqueTogether(\n655                         name=model_name,\n656                         unique_together=unique_together,\n657                     ),\n658                     dependencies=related_dependencies\n659                 )\n660             if index_together:\n661                 self.add_operation(\n662                     app_label,\n663                     operations.AlterIndexTogether(\n664                         name=model_name,\n665                         index_together=index_together,\n666                     ),\n667                     dependencies=related_dependencies\n668                 )\n669             # Fix relationships if the model changed from a proxy model to a\n670             # concrete model.\n671             relations = self.to_state.relations\n672             if (app_label, model_name) in self.old_proxy_keys:\n673                 for related_model_key, related_fields in relations[app_label, model_name].items():\n674                     related_model_state = self.to_state.models[related_model_key]\n675                     for related_field_name, related_field in related_fields.items():\n676                         self.add_operation(\n677                             related_model_state.app_label,\n678                             operations.AlterField(\n679                                 model_name=related_model_state.name,\n680                                 name=related_field_name,\n681                                 field=related_field,\n682                             ),\n683                             dependencies=[(app_label, model_name, None, True)],\n684                         )\n685 \n686     def generate_created_proxies(self):\n687         \"\"\"\n688         Make CreateModel statements for proxy models. Use the same statements\n689         as that way there's less code duplication, but for proxy models it's\n690         safe to skip all the pointless field stuff and chuck out an operation.\n691         \"\"\"\n692         added = self.new_proxy_keys - self.old_proxy_keys\n693         for app_label, model_name in sorted(added):\n694             model_state = self.to_state.models[app_label, model_name]\n695             assert model_state.options.get(\"proxy\")\n696             # Depend on the deletion of any possible non-proxy version of us\n697             dependencies = [\n698                 (app_label, model_name, None, False),\n699             ]\n700             # Depend on all bases\n701             for base in model_state.bases:\n702                 if isinstance(base, str) and \".\" in base:\n703                     base_app_label, base_name = base.split(\".\", 1)\n704                     dependencies.append((base_app_label, base_name, None, True))\n705             # Generate creation operation\n706             self.add_operation(\n707                 app_label,\n708                 operations.CreateModel(\n709                     name=model_state.name,\n710                     fields=[],\n711                     options=model_state.options,\n712                     bases=model_state.bases,\n713                     managers=model_state.managers,\n714                 ),\n715                 # Depend on the deletion of any possible non-proxy version of us\n716                 dependencies=dependencies,\n717             )\n718 \n719     def generate_deleted_models(self):\n720         \"\"\"\n721         Find all deleted models (managed and unmanaged) and make delete\n722         operations for them as well as separate operations to delete any\n723         foreign key or M2M relationships (these are optimized later, if\n724         possible).\n725 \n726         Also bring forward removal of any model options that refer to\n727         collections of fields - the inverse of generate_created_models().\n728         \"\"\"\n729         new_keys = self.new_model_keys | self.new_unmanaged_keys\n730         deleted_models = self.old_model_keys - new_keys\n731         deleted_unmanaged_models = self.old_unmanaged_keys - new_keys\n732         all_deleted_models = chain(sorted(deleted_models), sorted(deleted_unmanaged_models))\n733         for app_label, model_name in all_deleted_models:\n734             model_state = self.from_state.models[app_label, model_name]\n735             # Gather related fields\n736             related_fields = {}\n737             for field_name, field in model_state.fields.items():\n738                 if field.remote_field:\n739                     if field.remote_field.model:\n740                         related_fields[field_name] = field\n741                     if getattr(field.remote_field, 'through', None):\n742                         related_fields[field_name] = field\n743             # Generate option removal first\n744             unique_together = model_state.options.pop('unique_together', None)\n745             index_together = model_state.options.pop('index_together', None)\n746             if unique_together:\n747                 self.add_operation(\n748                     app_label,\n749                     operations.AlterUniqueTogether(\n750                         name=model_name,\n751                         unique_together=None,\n752                     )\n753                 )\n754             if index_together:\n755                 self.add_operation(\n756                     app_label,\n757                     operations.AlterIndexTogether(\n758                         name=model_name,\n759                         index_together=None,\n760                     )\n761                 )\n762             # Then remove each related field\n763             for name in sorted(related_fields):\n764                 self.add_operation(\n765                     app_label,\n766                     operations.RemoveField(\n767                         model_name=model_name,\n768                         name=name,\n769                     )\n770                 )\n771             # Finally, remove the model.\n772             # This depends on both the removal/alteration of all incoming fields\n773             # and the removal of all its own related fields, and if it's\n774             # a through model the field that references it.\n775             dependencies = []\n776             relations = self.from_state.relations\n777             for (related_object_app_label, object_name), relation_related_fields in (\n778                 relations[app_label, model_name].items()\n779             ):\n780                 for field_name, field in relation_related_fields.items():\n781                     dependencies.append(\n782                         (related_object_app_label, object_name, field_name, False),\n783                     )\n784                     if not field.many_to_many:\n785                         dependencies.append(\n786                             (related_object_app_label, object_name, field_name, 'alter'),\n787                         )\n788 \n789             for name in sorted(related_fields):\n790                 dependencies.append((app_label, model_name, name, False))\n791             # We're referenced in another field's through=\n792             through_user = self.through_users.get((app_label, model_state.name_lower))\n793             if through_user:\n794                 dependencies.append((through_user[0], through_user[1], through_user[2], False))\n795             # Finally, make the operation, deduping any dependencies\n796             self.add_operation(\n797                 app_label,\n798                 operations.DeleteModel(\n799                     name=model_state.name,\n800                 ),\n801                 dependencies=list(set(dependencies)),\n802             )\n803 \n804     def generate_deleted_proxies(self):\n805         \"\"\"Make DeleteModel options for proxy models.\"\"\"\n806         deleted = self.old_proxy_keys - self.new_proxy_keys\n807         for app_label, model_name in sorted(deleted):\n808             model_state = self.from_state.models[app_label, model_name]\n809             assert model_state.options.get(\"proxy\")\n810             self.add_operation(\n811                 app_label,\n812                 operations.DeleteModel(\n813                     name=model_state.name,\n814                 ),\n815             )\n816 \n817     def generate_renamed_fields(self):\n818         \"\"\"Work out renamed fields.\"\"\"\n819         self.renamed_fields = {}\n820         for app_label, model_name, field_name in sorted(self.new_field_keys - self.old_field_keys):\n821             old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n822             old_model_state = self.from_state.models[app_label, old_model_name]\n823             new_model_state = self.to_state.models[app_label, old_model_name]\n824             field = new_model_state.get_field(field_name)\n825             # Scan to see if this is actually a rename!\n826             field_dec = self.deep_deconstruct(field)\n827             for rem_app_label, rem_model_name, rem_field_name in sorted(self.old_field_keys - self.new_field_keys):\n828                 if rem_app_label == app_label and rem_model_name == model_name:\n829                     old_field = old_model_state.get_field(rem_field_name)\n830                     old_field_dec = self.deep_deconstruct(old_field)\n831                     if field.remote_field and field.remote_field.model and 'to' in old_field_dec[2]:\n832                         old_rel_to = old_field_dec[2]['to']\n833                         if old_rel_to in self.renamed_models_rel:\n834                             old_field_dec[2]['to'] = self.renamed_models_rel[old_rel_to]\n835                     old_field.set_attributes_from_name(rem_field_name)\n836                     old_db_column = old_field.get_attname_column()[1]\n837                     if (old_field_dec == field_dec or (\n838                             # Was the field renamed and db_column equal to the\n839                             # old field's column added?\n840                             old_field_dec[0:2] == field_dec[0:2] and\n841                             dict(old_field_dec[2], db_column=old_db_column) == field_dec[2])):\n842                         if self.questioner.ask_rename(model_name, rem_field_name, field_name, field):\n843                             self.add_operation(\n844                                 app_label,\n845                                 operations.RenameField(\n846                                     model_name=model_name,\n847                                     old_name=rem_field_name,\n848                                     new_name=field_name,\n849                                 )\n850                             )\n851                             self.old_field_keys.remove((rem_app_label, rem_model_name, rem_field_name))\n852                             self.old_field_keys.add((app_label, model_name, field_name))\n853                             self.renamed_fields[app_label, model_name, field_name] = rem_field_name\n854                             break\n855 \n856     def generate_added_fields(self):\n857         \"\"\"Make AddField operations.\"\"\"\n858         for app_label, model_name, field_name in sorted(self.new_field_keys - self.old_field_keys):\n859             self._generate_added_field(app_label, model_name, field_name)\n860 \n861     def _generate_added_field(self, app_label, model_name, field_name):\n862         field = self.to_state.models[app_label, model_name].get_field(field_name)\n863         # Fields that are foreignkeys/m2ms depend on stuff\n864         dependencies = []\n865         if field.remote_field and field.remote_field.model:\n866             dependencies.extend(self._get_dependencies_for_foreign_key(\n867                 app_label, model_name, field, self.to_state,\n868             ))\n869         # You can't just add NOT NULL fields with no default or fields\n870         # which don't allow empty strings as default.\n871         time_fields = (models.DateField, models.DateTimeField, models.TimeField)\n872         preserve_default = (\n873             field.null or field.has_default() or field.many_to_many or\n874             (field.blank and field.empty_strings_allowed) or\n875             (isinstance(field, time_fields) and field.auto_now)\n876         )\n877         if not preserve_default:\n878             field = field.clone()\n879             if isinstance(field, time_fields) and field.auto_now_add:\n880                 field.default = self.questioner.ask_auto_now_add_addition(field_name, model_name)\n881             else:\n882                 field.default = self.questioner.ask_not_null_addition(field_name, model_name)\n883         if (\n884             field.unique and\n885             field.default is not models.NOT_PROVIDED and\n886             callable(field.default)\n887         ):\n888             self.questioner.ask_unique_callable_default_addition(field_name, model_name)\n889         self.add_operation(\n890             app_label,\n891             operations.AddField(\n892                 model_name=model_name,\n893                 name=field_name,\n894                 field=field,\n895                 preserve_default=preserve_default,\n896             ),\n897             dependencies=dependencies,\n898         )\n899 \n900     def generate_removed_fields(self):\n901         \"\"\"Make RemoveField operations.\"\"\"\n902         for app_label, model_name, field_name in sorted(self.old_field_keys - self.new_field_keys):\n903             self._generate_removed_field(app_label, model_name, field_name)\n904 \n905     def _generate_removed_field(self, app_label, model_name, field_name):\n906         self.add_operation(\n907             app_label,\n908             operations.RemoveField(\n909                 model_name=model_name,\n910                 name=field_name,\n911             ),\n912             # We might need to depend on the removal of an\n913             # order_with_respect_to or index/unique_together operation;\n914             # this is safely ignored if there isn't one\n915             dependencies=[\n916                 (app_label, model_name, field_name, \"order_wrt_unset\"),\n917                 (app_label, model_name, field_name, \"foo_together_change\"),\n918             ],\n919         )\n920 \n921     def generate_altered_fields(self):\n922         \"\"\"\n923         Make AlterField operations, or possibly RemovedField/AddField if alter\n924         isn't possible.\n925         \"\"\"\n926         for app_label, model_name, field_name in sorted(self.old_field_keys & self.new_field_keys):\n927             # Did the field change?\n928             old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n929             old_field_name = self.renamed_fields.get((app_label, model_name, field_name), field_name)\n930             old_field = self.from_state.models[app_label, old_model_name].get_field(old_field_name)\n931             new_field = self.to_state.models[app_label, model_name].get_field(field_name)\n932             dependencies = []\n933             # Implement any model renames on relations; these are handled by RenameModel\n934             # so we need to exclude them from the comparison\n935             if hasattr(new_field, \"remote_field\") and getattr(new_field.remote_field, \"model\", None):\n936                 rename_key = resolve_relation(new_field.remote_field.model, app_label, model_name)\n937                 if rename_key in self.renamed_models:\n938                     new_field.remote_field.model = old_field.remote_field.model\n939                 # Handle ForeignKey which can only have a single to_field.\n940                 remote_field_name = getattr(new_field.remote_field, 'field_name', None)\n941                 if remote_field_name:\n942                     to_field_rename_key = rename_key + (remote_field_name,)\n943                     if to_field_rename_key in self.renamed_fields:\n944                         # Repoint both model and field name because to_field\n945                         # inclusion in ForeignKey.deconstruct() is based on\n946                         # both.\n947                         new_field.remote_field.model = old_field.remote_field.model\n948                         new_field.remote_field.field_name = old_field.remote_field.field_name\n949                 # Handle ForeignObjects which can have multiple from_fields/to_fields.\n950                 from_fields = getattr(new_field, 'from_fields', None)\n951                 if from_fields:\n952                     from_rename_key = (app_label, model_name)\n953                     new_field.from_fields = tuple([\n954                         self.renamed_fields.get(from_rename_key + (from_field,), from_field)\n955                         for from_field in from_fields\n956                     ])\n957                     new_field.to_fields = tuple([\n958                         self.renamed_fields.get(rename_key + (to_field,), to_field)\n959                         for to_field in new_field.to_fields\n960                     ])\n961                 dependencies.extend(self._get_dependencies_for_foreign_key(\n962                     app_label, model_name, new_field, self.to_state,\n963                 ))\n964             if (\n965                 hasattr(new_field, 'remote_field') and\n966                 getattr(new_field.remote_field, 'through', None)\n967             ):\n968                 rename_key = resolve_relation(new_field.remote_field.through, app_label, model_name)\n969                 if rename_key in self.renamed_models:\n970                     new_field.remote_field.through = old_field.remote_field.through\n971             old_field_dec = self.deep_deconstruct(old_field)\n972             new_field_dec = self.deep_deconstruct(new_field)\n973             if old_field_dec != new_field_dec:\n974                 both_m2m = old_field.many_to_many and new_field.many_to_many\n975                 neither_m2m = not old_field.many_to_many and not new_field.many_to_many\n976                 if both_m2m or neither_m2m:\n977                     # Either both fields are m2m or neither is\n978                     preserve_default = True\n979                     if (old_field.null and not new_field.null and not new_field.has_default() and\n980                             not new_field.many_to_many):\n981                         field = new_field.clone()\n982                         new_default = self.questioner.ask_not_null_alteration(field_name, model_name)\n983                         if new_default is not models.NOT_PROVIDED:\n984                             field.default = new_default\n985                             preserve_default = False\n986                     else:\n987                         field = new_field\n988                     self.add_operation(\n989                         app_label,\n990                         operations.AlterField(\n991                             model_name=model_name,\n992                             name=field_name,\n993                             field=field,\n994                             preserve_default=preserve_default,\n995                         ),\n996                         dependencies=dependencies,\n997                     )\n998                 else:\n999                     # We cannot alter between m2m and concrete fields\n1000                     self._generate_removed_field(app_label, model_name, field_name)\n1001                     self._generate_added_field(app_label, model_name, field_name)\n1002 \n1003     def create_altered_indexes(self):\n1004         option_name = operations.AddIndex.option_name\n1005         for app_label, model_name in sorted(self.kept_model_keys):\n1006             old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n1007             old_model_state = self.from_state.models[app_label, old_model_name]\n1008             new_model_state = self.to_state.models[app_label, model_name]\n1009 \n1010             old_indexes = old_model_state.options[option_name]\n1011             new_indexes = new_model_state.options[option_name]\n1012             add_idx = [idx for idx in new_indexes if idx not in old_indexes]\n1013             rem_idx = [idx for idx in old_indexes if idx not in new_indexes]\n1014 \n1015             self.altered_indexes.update({\n1016                 (app_label, model_name): {\n1017                     'added_indexes': add_idx, 'removed_indexes': rem_idx,\n1018                 }\n1019             })\n1020 \n1021     def generate_added_indexes(self):\n1022         for (app_label, model_name), alt_indexes in self.altered_indexes.items():\n1023             for index in alt_indexes['added_indexes']:\n1024                 self.add_operation(\n1025                     app_label,\n1026                     operations.AddIndex(\n1027                         model_name=model_name,\n1028                         index=index,\n1029                     )\n1030                 )\n1031 \n1032     def generate_removed_indexes(self):\n1033         for (app_label, model_name), alt_indexes in self.altered_indexes.items():\n1034             for index in alt_indexes['removed_indexes']:\n1035                 self.add_operation(\n1036                     app_label,\n1037                     operations.RemoveIndex(\n1038                         model_name=model_name,\n1039                         name=index.name,\n1040                     )\n1041                 )\n1042 \n1043     def create_altered_constraints(self):\n1044         option_name = operations.AddConstraint.option_name\n1045         for app_label, model_name in sorted(self.kept_model_keys):\n1046             old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n1047             old_model_state = self.from_state.models[app_label, old_model_name]\n1048             new_model_state = self.to_state.models[app_label, model_name]\n1049 \n1050             old_constraints = old_model_state.options[option_name]\n1051             new_constraints = new_model_state.options[option_name]\n1052             add_constraints = [c for c in new_constraints if c not in old_constraints]\n1053             rem_constraints = [c for c in old_constraints if c not in new_constraints]\n1054 \n1055             self.altered_constraints.update({\n1056                 (app_label, model_name): {\n1057                     'added_constraints': add_constraints, 'removed_constraints': rem_constraints,\n1058                 }\n1059             })\n1060 \n1061     def generate_added_constraints(self):\n1062         for (app_label, model_name), alt_constraints in self.altered_constraints.items():\n1063             for constraint in alt_constraints['added_constraints']:\n1064                 self.add_operation(\n1065                     app_label,\n1066                     operations.AddConstraint(\n1067                         model_name=model_name,\n1068                         constraint=constraint,\n1069                     )\n1070                 )\n1071 \n1072     def generate_removed_constraints(self):\n1073         for (app_label, model_name), alt_constraints in self.altered_constraints.items():\n1074             for constraint in alt_constraints['removed_constraints']:\n1075                 self.add_operation(\n1076                     app_label,\n1077                     operations.RemoveConstraint(\n1078                         model_name=model_name,\n1079                         name=constraint.name,\n1080                     )\n1081                 )\n1082 \n1083     @staticmethod\n1084     def _get_dependencies_for_foreign_key(app_label, model_name, field, project_state):\n1085         remote_field_model = None\n1086         if hasattr(field.remote_field, 'model'):\n1087             remote_field_model = field.remote_field.model\n1088         else:\n1089             relations = project_state.relations[app_label, model_name]\n1090             for (remote_app_label, remote_model_name), fields in relations.items():\n1091                 if any(\n1092                     field == related_field.remote_field\n1093                     for related_field in fields.values()\n1094                 ):\n1095                     remote_field_model = f'{remote_app_label}.{remote_model_name}'\n1096                     break\n1097         # Account for FKs to swappable models\n1098         swappable_setting = getattr(field, 'swappable_setting', None)\n1099         if swappable_setting is not None:\n1100             dep_app_label = \"__setting__\"\n1101             dep_object_name = swappable_setting\n1102         else:\n1103             dep_app_label, dep_object_name = resolve_relation(\n1104                 remote_field_model, app_label, model_name,\n1105             )\n1106         dependencies = [(dep_app_label, dep_object_name, None, True)]\n1107         if getattr(field.remote_field, 'through', None):\n1108             through_app_label, through_object_name = resolve_relation(\n1109                 remote_field_model, app_label, model_name,\n1110             )\n1111             dependencies.append((through_app_label, through_object_name, None, True))\n1112         return dependencies\n1113 \n1114     def _generate_altered_foo_together(self, operation):\n1115         option_name = operation.option_name\n1116         for app_label, model_name in sorted(self.kept_model_keys):\n1117             old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n1118             old_model_state = self.from_state.models[app_label, old_model_name]\n1119             new_model_state = self.to_state.models[app_label, model_name]\n1120 \n1121             # We run the old version through the field renames to account for those\n1122             old_value = old_model_state.options.get(option_name)\n1123             old_value = {\n1124                 tuple(\n1125                     self.renamed_fields.get((app_label, model_name, n), n)\n1126                     for n in unique\n1127                 )\n1128                 for unique in old_value\n1129             } if old_value else set()\n1130 \n1131             new_value = new_model_state.options.get(option_name)\n1132             new_value = set(new_value) if new_value else set()\n1133 \n1134             if old_value != new_value:\n1135                 dependencies = []\n1136                 for foo_togethers in new_value:\n1137                     for field_name in foo_togethers:\n1138                         field = new_model_state.get_field(field_name)\n1139                         if field.remote_field and field.remote_field.model:\n1140                             dependencies.extend(self._get_dependencies_for_foreign_key(\n1141                                 app_label, model_name, field, self.to_state,\n1142                             ))\n1143 \n1144                 self.add_operation(\n1145                     app_label,\n1146                     operation(\n1147                         name=model_name,\n1148                         **{option_name: new_value}\n1149                     ),\n1150                     dependencies=dependencies,\n1151                 )\n1152 \n1153     def generate_altered_unique_together(self):\n1154         self._generate_altered_foo_together(operations.AlterUniqueTogether)\n1155 \n1156     def generate_altered_index_together(self):\n1157         self._generate_altered_foo_together(operations.AlterIndexTogether)\n1158 \n1159     def generate_altered_db_table(self):\n1160         models_to_check = self.kept_model_keys.union(self.kept_proxy_keys, self.kept_unmanaged_keys)\n1161         for app_label, model_name in sorted(models_to_check):\n1162             old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n1163             old_model_state = self.from_state.models[app_label, old_model_name]\n1164             new_model_state = self.to_state.models[app_label, model_name]\n1165             old_db_table_name = old_model_state.options.get('db_table')\n1166             new_db_table_name = new_model_state.options.get('db_table')\n1167             if old_db_table_name != new_db_table_name:\n1168                 self.add_operation(\n1169                     app_label,\n1170                     operations.AlterModelTable(\n1171                         name=model_name,\n1172                         table=new_db_table_name,\n1173                     )\n1174                 )\n1175 \n1176     def generate_altered_options(self):\n1177         \"\"\"\n1178         Work out if any non-schema-affecting options have changed and make an\n1179         operation to represent them in state changes (in case Python code in\n1180         migrations needs them).\n1181         \"\"\"\n1182         models_to_check = self.kept_model_keys.union(\n1183             self.kept_proxy_keys,\n1184             self.kept_unmanaged_keys,\n1185             # unmanaged converted to managed\n1186             self.old_unmanaged_keys & self.new_model_keys,\n1187             # managed converted to unmanaged\n1188             self.old_model_keys & self.new_unmanaged_keys,\n1189         )\n1190 \n1191         for app_label, model_name in sorted(models_to_check):\n1192             old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n1193             old_model_state = self.from_state.models[app_label, old_model_name]\n1194             new_model_state = self.to_state.models[app_label, model_name]\n1195             old_options = {\n1196                 key: value for key, value in old_model_state.options.items()\n1197                 if key in AlterModelOptions.ALTER_OPTION_KEYS\n1198             }\n1199             new_options = {\n1200                 key: value for key, value in new_model_state.options.items()\n1201                 if key in AlterModelOptions.ALTER_OPTION_KEYS\n1202             }\n1203             if old_options != new_options:\n1204                 self.add_operation(\n1205                     app_label,\n1206                     operations.AlterModelOptions(\n1207                         name=model_name,\n1208                         options=new_options,\n1209                     )\n1210                 )\n1211 \n1212     def generate_altered_order_with_respect_to(self):\n1213         for app_label, model_name in sorted(self.kept_model_keys):\n1214             old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n1215             old_model_state = self.from_state.models[app_label, old_model_name]\n1216             new_model_state = self.to_state.models[app_label, model_name]\n1217             if (old_model_state.options.get(\"order_with_respect_to\") !=\n1218                     new_model_state.options.get(\"order_with_respect_to\")):\n1219                 # Make sure it comes second if we're adding\n1220                 # (removal dependency is part of RemoveField)\n1221                 dependencies = []\n1222                 if new_model_state.options.get(\"order_with_respect_to\"):\n1223                     dependencies.append((\n1224                         app_label,\n1225                         model_name,\n1226                         new_model_state.options[\"order_with_respect_to\"],\n1227                         True,\n1228                     ))\n1229                 # Actually generate the operation\n1230                 self.add_operation(\n1231                     app_label,\n1232                     operations.AlterOrderWithRespectTo(\n1233                         name=model_name,\n1234                         order_with_respect_to=new_model_state.options.get('order_with_respect_to'),\n1235                     ),\n1236                     dependencies=dependencies,\n1237                 )\n1238 \n1239     def generate_altered_managers(self):\n1240         for app_label, model_name in sorted(self.kept_model_keys):\n1241             old_model_name = self.renamed_models.get((app_label, model_name), model_name)\n1242             old_model_state = self.from_state.models[app_label, old_model_name]\n1243             new_model_state = self.to_state.models[app_label, model_name]\n1244             if old_model_state.managers != new_model_state.managers:\n1245                 self.add_operation(\n1246                     app_label,\n1247                     operations.AlterModelManagers(\n1248                         name=model_name,\n1249                         managers=new_model_state.managers,\n1250                     )\n1251                 )\n1252 \n1253     def arrange_for_graph(self, changes, graph, migration_name=None):\n1254         \"\"\"\n1255         Take a result from changes() and a MigrationGraph, and fix the names\n1256         and dependencies of the changes so they extend the graph from the leaf\n1257         nodes for each app.\n1258         \"\"\"\n1259         leaves = graph.leaf_nodes()\n1260         name_map = {}\n1261         for app_label, migrations in list(changes.items()):\n1262             if not migrations:\n1263                 continue\n1264             # Find the app label's current leaf node\n1265             app_leaf = None\n1266             for leaf in leaves:\n1267                 if leaf[0] == app_label:\n1268                     app_leaf = leaf\n1269                     break\n1270             # Do they want an initial migration for this app?\n1271             if app_leaf is None and not self.questioner.ask_initial(app_label):\n1272                 # They don't.\n1273                 for migration in migrations:\n1274                     name_map[(app_label, migration.name)] = (app_label, \"__first__\")\n1275                 del changes[app_label]\n1276                 continue\n1277             # Work out the next number in the sequence\n1278             if app_leaf is None:\n1279                 next_number = 1\n1280             else:\n1281                 next_number = (self.parse_number(app_leaf[1]) or 0) + 1\n1282             # Name each migration\n1283             for i, migration in enumerate(migrations):\n1284                 if i == 0 and app_leaf:\n1285                     migration.dependencies.append(app_leaf)\n1286                 new_name_parts = ['%04i' % next_number]\n1287                 if migration_name:\n1288                     new_name_parts.append(migration_name)\n1289                 elif i == 0 and not app_leaf:\n1290                     new_name_parts.append('initial')\n1291                 else:\n1292                     new_name_parts.append(migration.suggest_name()[:100])\n1293                 new_name = '_'.join(new_name_parts)\n1294                 name_map[(app_label, migration.name)] = (app_label, new_name)\n1295                 next_number += 1\n1296                 migration.name = new_name\n1297         # Now fix dependencies\n1298         for migrations in changes.values():\n1299             for migration in migrations:\n1300                 migration.dependencies = [name_map.get(d, d) for d in migration.dependencies]\n1301         return changes\n1302 \n1303     def _trim_to_apps(self, changes, app_labels):\n1304         \"\"\"\n1305         Take changes from arrange_for_graph() and set of app labels, and return\n1306         a modified set of changes which trims out as many migrations that are\n1307         not in app_labels as possible. Note that some other migrations may\n1308         still be present as they may be required dependencies.\n1309         \"\"\"\n1310         # Gather other app dependencies in a first pass\n1311         app_dependencies = {}\n1312         for app_label, migrations in changes.items():\n1313             for migration in migrations:\n1314                 for dep_app_label, name in migration.dependencies:\n1315                     app_dependencies.setdefault(app_label, set()).add(dep_app_label)\n1316         required_apps = set(app_labels)\n1317         # Keep resolving till there's no change\n1318         old_required_apps = None\n1319         while old_required_apps != required_apps:\n1320             old_required_apps = set(required_apps)\n1321             required_apps.update(*[app_dependencies.get(app_label, ()) for app_label in required_apps])\n1322         # Remove all migrations that aren't needed\n1323         for app_label in list(changes):\n1324             if app_label not in required_apps:\n1325                 del changes[app_label]\n1326         return changes\n1327 \n1328     @classmethod\n1329     def parse_number(cls, name):\n1330         \"\"\"\n1331         Given a migration name, try to extract a number from the beginning of\n1332         it. If no number is found, return None.\n1333         \"\"\"\n1334         match = re.match(r'^\\d+', name)\n1335         if match:\n1336             return int(match[0])\n1337         return None\n",
        "intended_behavior": "Adjust the logic within or connected to this class to ensure that when migrations are detected and named, the process fully accounts for the existing migration timeline, including both squashed and unsquashed migrations, to correctly sequence new migration numbers."
    },
    {
        "rel_file_path": "django/core/management/commands/makemigrations.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__4.1/django/core/management/commands/makemigrations.py",
        "start": 1,
        "end": 333,
        "class_name": null,
        "method_name": null,
        "code": "1 import os\n2 import sys\n3 import warnings\n4 from itertools import takewhile\n5 \n6 from django.apps import apps\n7 from django.conf import settings\n8 from django.core.management.base import (\n9     BaseCommand, CommandError, no_translations,\n10 )\n11 from django.db import DEFAULT_DB_ALIAS, OperationalError, connections, router\n12 from django.db.migrations import Migration\n13 from django.db.migrations.autodetector import MigrationAutodetector\n14 from django.db.migrations.loader import MigrationLoader\n15 from django.db.migrations.questioner import (\n16     InteractiveMigrationQuestioner, MigrationQuestioner,\n17     NonInteractiveMigrationQuestioner,\n18 )\n19 from django.db.migrations.state import ProjectState\n20 from django.db.migrations.utils import get_migration_name_timestamp\n21 from django.db.migrations.writer import MigrationWriter\n22 \n23 \n24 class Command(BaseCommand):\n25     help = \"Creates new migration(s) for apps.\"\n26 \n27     def add_arguments(self, parser):\n28         parser.add_argument(\n29             'args', metavar='app_label', nargs='*',\n30             help='Specify the app label(s) to create migrations for.',\n31         )\n32         parser.add_argument(\n33             '--dry-run', action='store_true',\n34             help=\"Just show what migrations would be made; don't actually write them.\",\n35         )\n36         parser.add_argument(\n37             '--merge', action='store_true',\n38             help=\"Enable fixing of migration conflicts.\",\n39         )\n40         parser.add_argument(\n41             '--empty', action='store_true',\n42             help=\"Create an empty migration.\",\n43         )\n44         parser.add_argument(\n45             '--noinput', '--no-input', action='store_false', dest='interactive',\n46             help='Tells Django to NOT prompt the user for input of any kind.',\n47         )\n48         parser.add_argument(\n49             '-n', '--name',\n50             help=\"Use this name for migration file(s).\",\n51         )\n52         parser.add_argument(\n53             '--no-header', action='store_false', dest='include_header',\n54             help='Do not add header comments to new migration file(s).',\n55         )\n56         parser.add_argument(\n57             '--check', action='store_true', dest='check_changes',\n58             help='Exit with a non-zero status if model changes are missing migrations.',\n59         )\n60 \n61     def log(self, msg):\n62         self.stdout.write(msg)\n63 \n64     @no_translations\n65     def handle(self, *app_labels, **options):\n66         self.verbosity = options['verbosity']\n67         self.interactive = options['interactive']\n68         self.dry_run = options['dry_run']\n69         self.merge = options['merge']\n70         self.empty = options['empty']\n71         self.migration_name = options['name']\n72         if self.migration_name and not self.migration_name.isidentifier():\n73             raise CommandError('The migration name must be a valid Python identifier.')\n74         self.include_header = options['include_header']\n75         check_changes = options['check_changes']\n76 \n77         # Make sure the app they asked for exists\n78         app_labels = set(app_labels)\n79         has_bad_labels = False\n80         for app_label in app_labels:\n81             try:\n82                 apps.get_app_config(app_label)\n83             except LookupError as err:\n84                 self.stderr.write(str(err))\n85                 has_bad_labels = True\n86         if has_bad_labels:\n87             sys.exit(2)\n88 \n89         # Load the current graph state. Pass in None for the connection so\n90         # the loader doesn't try to resolve replaced migrations from DB.\n91         loader = MigrationLoader(None, ignore_no_migrations=True)\n92 \n93         # Raise an error if any migrations are applied before their dependencies.\n94         consistency_check_labels = {config.label for config in apps.get_app_configs()}\n95         # Non-default databases are only checked if database routers used.\n96         aliases_to_check = connections if settings.DATABASE_ROUTERS else [DEFAULT_DB_ALIAS]\n97         for alias in sorted(aliases_to_check):\n98             connection = connections[alias]\n99             if (connection.settings_dict['ENGINE'] != 'django.db.backends.dummy' and any(\n100                     # At least one model must be migrated to the database.\n101                     router.allow_migrate(connection.alias, app_label, model_name=model._meta.object_name)\n102                     for app_label in consistency_check_labels\n103                     for model in apps.get_app_config(app_label).get_models()\n104             )):\n105                 try:\n106                     loader.check_consistent_history(connection)\n107                 except OperationalError as error:\n108                     warnings.warn(\n109                         \"Got an error checking a consistent migration history \"\n110                         \"performed for database connection '%s': %s\"\n111                         % (alias, error),\n112                         RuntimeWarning,\n113                     )\n114         # Before anything else, see if there's conflicting apps and drop out\n115         # hard if there are any and they don't want to merge\n116         conflicts = loader.detect_conflicts()\n117 \n118         # If app_labels is specified, filter out conflicting migrations for unspecified apps\n119         if app_labels:\n120             conflicts = {\n121                 app_label: conflict for app_label, conflict in conflicts.items()\n122                 if app_label in app_labels\n123             }\n124 \n125         if conflicts and not self.merge:\n126             name_str = \"; \".join(\n127                 \"%s in %s\" % (\", \".join(names), app)\n128                 for app, names in conflicts.items()\n129             )\n130             raise CommandError(\n131                 \"Conflicting migrations detected; multiple leaf nodes in the \"\n132                 \"migration graph: (%s).\\nTo fix them run \"\n133                 \"'python manage.py makemigrations --merge'\" % name_str\n134             )\n135 \n136         # If they want to merge and there's nothing to merge, then politely exit\n137         if self.merge and not conflicts:\n138             self.log('No conflicts detected to merge.')\n139             return\n140 \n141         # If they want to merge and there is something to merge, then\n142         # divert into the merge code\n143         if self.merge and conflicts:\n144             return self.handle_merge(loader, conflicts)\n145 \n146         if self.interactive:\n147             questioner = InteractiveMigrationQuestioner(specified_apps=app_labels, dry_run=self.dry_run)\n148         else:\n149             questioner = NonInteractiveMigrationQuestioner(\n150                 specified_apps=app_labels,\n151                 dry_run=self.dry_run,\n152                 verbosity=self.verbosity,\n153                 log=self.log,\n154             )\n155         # Set up autodetector\n156         autodetector = MigrationAutodetector(\n157             loader.project_state(),\n158             ProjectState.from_apps(apps),\n159             questioner,\n160         )\n161 \n162         # If they want to make an empty migration, make one for each app\n163         if self.empty:\n164             if not app_labels:\n165                 raise CommandError(\"You must supply at least one app label when using --empty.\")\n166             # Make a fake changes() result we can pass to arrange_for_graph\n167             changes = {\n168                 app: [Migration(\"custom\", app)]\n169                 for app in app_labels\n170             }\n171             changes = autodetector.arrange_for_graph(\n172                 changes=changes,\n173                 graph=loader.graph,\n174                 migration_name=self.migration_name,\n175             )\n176             self.write_migration_files(changes)\n177             return\n178 \n179         # Detect changes\n180         changes = autodetector.changes(\n181             graph=loader.graph,\n182             trim_to_apps=app_labels or None,\n183             convert_apps=app_labels or None,\n184             migration_name=self.migration_name,\n185         )\n186 \n187         if not changes:\n188             # No changes? Tell them.\n189             if self.verbosity >= 1:\n190                 if app_labels:\n191                     if len(app_labels) == 1:\n192                         self.log(\"No changes detected in app '%s'\" % app_labels.pop())\n193                     else:\n194                         self.log(\"No changes detected in apps '%s'\" % (\"', '\".join(app_labels)))\n195                 else:\n196                     self.log('No changes detected')\n197         else:\n198             self.write_migration_files(changes)\n199             if check_changes:\n200                 sys.exit(1)\n201 \n202     def write_migration_files(self, changes):\n203         \"\"\"\n204         Take a changes dict and write them out as migration files.\n205         \"\"\"\n206         directory_created = {}\n207         for app_label, app_migrations in changes.items():\n208             if self.verbosity >= 1:\n209                 self.log(self.style.MIGRATE_HEADING(\"Migrations for '%s':\" % app_label))\n210             for migration in app_migrations:\n211                 # Describe the migration\n212                 writer = MigrationWriter(migration, self.include_header)\n213                 if self.verbosity >= 1:\n214                     # Display a relative path if it's below the current working\n215                     # directory, or an absolute path otherwise.\n216                     try:\n217                         migration_string = os.path.relpath(writer.path)\n218                     except ValueError:\n219                         migration_string = writer.path\n220                     if migration_string.startswith('..'):\n221                         migration_string = writer.path\n222                     self.log('  %s\\n' % self.style.MIGRATE_LABEL(migration_string))\n223                     for operation in migration.operations:\n224                         self.log('    - %s' % operation.describe())\n225                 if not self.dry_run:\n226                     # Write the migrations file to the disk.\n227                     migrations_directory = os.path.dirname(writer.path)\n228                     if not directory_created.get(app_label):\n229                         os.makedirs(migrations_directory, exist_ok=True)\n230                         init_path = os.path.join(migrations_directory, \"__init__.py\")\n231                         if not os.path.isfile(init_path):\n232                             open(init_path, \"w\").close()\n233                         # We just do this once per app\n234                         directory_created[app_label] = True\n235                     migration_string = writer.as_string()\n236                     with open(writer.path, \"w\", encoding='utf-8') as fh:\n237                         fh.write(migration_string)\n238                 elif self.verbosity == 3:\n239                     # Alternatively, makemigrations --dry-run --verbosity 3\n240                     # will log the migrations rather than saving the file to\n241                     # the disk.\n242                     self.log(self.style.MIGRATE_HEADING(\n243                         \"Full migrations file '%s':\" % writer.filename\n244                     ))\n245                     self.log(writer.as_string())\n246 \n247     def handle_merge(self, loader, conflicts):\n248         \"\"\"\n249         Handles merging together conflicted migrations interactively,\n250         if it's safe; otherwise, advises on how to fix it.\n251         \"\"\"\n252         if self.interactive:\n253             questioner = InteractiveMigrationQuestioner()\n254         else:\n255             questioner = MigrationQuestioner(defaults={'ask_merge': True})\n256 \n257         for app_label, migration_names in conflicts.items():\n258             # Grab out the migrations in question, and work out their\n259             # common ancestor.\n260             merge_migrations = []\n261             for migration_name in migration_names:\n262                 migration = loader.get_migration(app_label, migration_name)\n263                 migration.ancestry = [\n264                     mig for mig in loader.graph.forwards_plan((app_label, migration_name))\n265                     if mig[0] == migration.app_label\n266                 ]\n267                 merge_migrations.append(migration)\n268 \n269             def all_items_equal(seq):\n270                 return all(item == seq[0] for item in seq[1:])\n271 \n272             merge_migrations_generations = zip(*(m.ancestry for m in merge_migrations))\n273             common_ancestor_count = sum(1 for common_ancestor_generation\n274                                         in takewhile(all_items_equal, merge_migrations_generations))\n275             if not common_ancestor_count:\n276                 raise ValueError(\"Could not find common ancestor of %s\" % migration_names)\n277             # Now work out the operations along each divergent branch\n278             for migration in merge_migrations:\n279                 migration.branch = migration.ancestry[common_ancestor_count:]\n280                 migrations_ops = (loader.get_migration(node_app, node_name).operations\n281                                   for node_app, node_name in migration.branch)\n282                 migration.merged_operations = sum(migrations_ops, [])\n283             # In future, this could use some of the Optimizer code\n284             # (can_optimize_through) to automatically see if they're\n285             # mergeable. For now, we always just prompt the user.\n286             if self.verbosity > 0:\n287                 self.log(self.style.MIGRATE_HEADING('Merging %s' % app_label))\n288                 for migration in merge_migrations:\n289                     self.log(self.style.MIGRATE_LABEL('  Branch %s' % migration.name))\n290                     for operation in migration.merged_operations:\n291                         self.log('    - %s' % operation.describe())\n292             if questioner.ask_merge(app_label):\n293                 # If they still want to merge it, then write out an empty\n294                 # file depending on the migrations needing merging.\n295                 numbers = [\n296                     MigrationAutodetector.parse_number(migration.name)\n297                     for migration in merge_migrations\n298                 ]\n299                 try:\n300                     biggest_number = max(x for x in numbers if x is not None)\n301                 except ValueError:\n302                     biggest_number = 1\n303                 subclass = type(\"Migration\", (Migration,), {\n304                     \"dependencies\": [(app_label, migration.name) for migration in merge_migrations],\n305                 })\n306                 parts = ['%04i' % (biggest_number + 1)]\n307                 if self.migration_name:\n308                     parts.append(self.migration_name)\n309                 else:\n310                     parts.append('merge')\n311                     leaf_names = '_'.join(sorted(migration.name for migration in merge_migrations))\n312                     if len(leaf_names) > 47:\n313                         parts.append(get_migration_name_timestamp())\n314                     else:\n315                         parts.append(leaf_names)\n316                 migration_name = '_'.join(parts)\n317                 new_migration = subclass(migration_name, app_label)\n318                 writer = MigrationWriter(new_migration, self.include_header)\n319 \n320                 if not self.dry_run:\n321                     # Write the merge migrations file to the disk\n322                     with open(writer.path, \"w\", encoding='utf-8') as fh:\n323                         fh.write(writer.as_string())\n324                     if self.verbosity > 0:\n325                         self.log('\\nCreated new merge migration %s' % writer.path)\n326                 elif self.verbosity == 3:\n327                     # Alternatively, makemigrations --merge --dry-run --verbosity 3\n328                     # will log the merge migrations rather than saving the file\n329                     # to the disk.\n330                     self.log(self.style.MIGRATE_HEADING(\n331                         \"Full merge migrations file '%s':\" % writer.filename\n332                     ))\n333                     self.log(writer.as_string())\n",
        "intended_behavior": "In the process that finalizes and names new migrations, include a verification step that correctly sequences migration numbers by considering the highest existing migration, whether it results from squashed migrations or a linear progression of individual migrations."
    }
]