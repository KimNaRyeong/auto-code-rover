[
    {
        "rel_file_path": "django/db/models/sql/compiler.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.1/django/db/models/sql/compiler.py",
        "start": 472,
        "end": 622,
        "class_name": "SQLCompiler",
        "method_name": "as_sql",
        "code": "472     def as_sql(self, with_limits=True, with_col_aliases=False):\n473         \"\"\"\n474         Create the SQL for this query. Return the SQL string and list of\n475         parameters.\n476 \n477         If 'with_limits' is False, any limit/offset information is not included\n478         in the query.\n479         \"\"\"\n480         refcounts_before = self.query.alias_refcount.copy()\n481         try:\n482             extra_select, order_by, group_by = self.pre_sql_setup()\n483             for_update_part = None\n484             # Is a LIMIT/OFFSET clause needed?\n485             with_limit_offset = with_limits and (self.query.high_mark is not None or self.query.low_mark)\n486             combinator = self.query.combinator\n487             features = self.connection.features\n488             if combinator:\n489                 if not getattr(features, 'supports_select_{}'.format(combinator)):\n490                     raise NotSupportedError('{} is not supported on this database backend.'.format(combinator))\n491                 result, params = self.get_combinator_sql(combinator, self.query.combinator_all)\n492             else:\n493                 distinct_fields, distinct_params = self.get_distinct()\n494                 # This must come after 'select', 'ordering', and 'distinct'\n495                 # (see docstring of get_from_clause() for details).\n496                 from_, f_params = self.get_from_clause()\n497                 where, w_params = self.compile(self.where) if self.where is not None else (\"\", [])\n498                 having, h_params = self.compile(self.having) if self.having is not None else (\"\", [])\n499                 result = ['SELECT']\n500                 params = []\n501 \n502                 if self.query.distinct:\n503                     distinct_result, distinct_params = self.connection.ops.distinct_sql(\n504                         distinct_fields,\n505                         distinct_params,\n506                     )\n507                     result += distinct_result\n508                     params += distinct_params\n509 \n510                 out_cols = []\n511                 col_idx = 1\n512                 for _, (s_sql, s_params), alias in self.select + extra_select:\n513                     if alias:\n514                         s_sql = '%s AS %s' % (s_sql, self.connection.ops.quote_name(alias))\n515                     elif with_col_aliases:\n516                         s_sql = '%s AS %s' % (s_sql, 'Col%d' % col_idx)\n517                         col_idx += 1\n518                     params.extend(s_params)\n519                     out_cols.append(s_sql)\n520 \n521                 result += [', '.join(out_cols), 'FROM', *from_]\n522                 params.extend(f_params)\n523 \n524                 if self.query.select_for_update and self.connection.features.has_select_for_update:\n525                     if self.connection.get_autocommit():\n526                         raise TransactionManagementError('select_for_update cannot be used outside of a transaction.')\n527 \n528                     if with_limit_offset and not self.connection.features.supports_select_for_update_with_limit:\n529                         raise NotSupportedError(\n530                             'LIMIT/OFFSET is not supported with '\n531                             'select_for_update on this database backend.'\n532                         )\n533                     nowait = self.query.select_for_update_nowait\n534                     skip_locked = self.query.select_for_update_skip_locked\n535                     of = self.query.select_for_update_of\n536                     # If it's a NOWAIT/SKIP LOCKED/OF query but the backend\n537                     # doesn't support it, raise NotSupportedError to prevent a\n538                     # possible deadlock.\n539                     if nowait and not self.connection.features.has_select_for_update_nowait:\n540                         raise NotSupportedError('NOWAIT is not supported on this database backend.')\n541                     elif skip_locked and not self.connection.features.has_select_for_update_skip_locked:\n542                         raise NotSupportedError('SKIP LOCKED is not supported on this database backend.')\n543                     elif of and not self.connection.features.has_select_for_update_of:\n544                         raise NotSupportedError('FOR UPDATE OF is not supported on this database backend.')\n545                     for_update_part = self.connection.ops.for_update_sql(\n546                         nowait=nowait,\n547                         skip_locked=skip_locked,\n548                         of=self.get_select_for_update_of_arguments(),\n549                     )\n550 \n551                 if for_update_part and self.connection.features.for_update_after_from:\n552                     result.append(for_update_part)\n553 \n554                 if where:\n555                     result.append('WHERE %s' % where)\n556                     params.extend(w_params)\n557 \n558                 grouping = []\n559                 for g_sql, g_params in group_by:\n560                     grouping.append(g_sql)\n561                     params.extend(g_params)\n562                 if grouping:\n563                     if distinct_fields:\n564                         raise NotImplementedError('annotate() + distinct(fields) is not implemented.')\n565                     order_by = order_by or self.connection.ops.force_no_ordering()\n566                     result.append('GROUP BY %s' % ', '.join(grouping))\n567                     if self._meta_ordering:\n568                         order_by = None\n569                 if having:\n570                     result.append('HAVING %s' % having)\n571                     params.extend(h_params)\n572 \n573             if self.query.explain_query:\n574                 result.insert(0, self.connection.ops.explain_query_prefix(\n575                     self.query.explain_format,\n576                     **self.query.explain_options\n577                 ))\n578 \n579             if order_by:\n580                 ordering = []\n581                 for _, (o_sql, o_params, _) in order_by:\n582                     ordering.append(o_sql)\n583                     params.extend(o_params)\n584                 result.append('ORDER BY %s' % ', '.join(ordering))\n585 \n586             if with_limit_offset:\n587                 result.append(self.connection.ops.limit_offset_sql(self.query.low_mark, self.query.high_mark))\n588 \n589             if for_update_part and not self.connection.features.for_update_after_from:\n590                 result.append(for_update_part)\n591 \n592             if self.query.subquery and extra_select:\n593                 # If the query is used as a subquery, the extra selects would\n594                 # result in more columns than the left-hand side expression is\n595                 # expecting. This can happen when a subquery uses a combination\n596                 # of order_by() and distinct(), forcing the ordering expressions\n597                 # to be selected as well. Wrap the query in another subquery\n598                 # to exclude extraneous selects.\n599                 sub_selects = []\n600                 sub_params = []\n601                 for index, (select, _, alias) in enumerate(self.select, start=1):\n602                     if not alias and with_col_aliases:\n603                         alias = 'col%d' % index\n604                     if alias:\n605                         sub_selects.append(\"%s.%s\" % (\n606                             self.connection.ops.quote_name('subquery'),\n607                             self.connection.ops.quote_name(alias),\n608                         ))\n609                     else:\n610                         select_clone = select.relabeled_clone({select.alias: 'subquery'})\n611                         subselect, subparams = select_clone.as_sql(self, self.connection)\n612                         sub_selects.append(subselect)\n613                         sub_params.extend(subparams)\n614                 return 'SELECT %s FROM (%s) subquery' % (\n615                     ', '.join(sub_selects),\n616                     ' '.join(result),\n617                 ), tuple(sub_params + params)\n618 \n619             return ' '.join(result), tuple(params)\n620         finally:\n621             # Finally do cleanup - get rid of the joins we created above.\n622             self.query.reset_refcounts(refcounts_before)\n",
        "intended_behavior": "This method should be adjusted to allow window expressions within `Case` statements inside the `SELECT` clause. It should correctly identify and permit the referencing of window function results when used as part of conditionals within `SELECT`, ensuring they are not misinterpreted as being part of disallowed clauses like `WHERE`."
    },
    {
        "rel_file_path": "django/db/models/sql/compiler.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.1/django/db/models/sql/compiler.py",
        "start": 21,
        "end": 1186,
        "class_name": "SQLCompiler",
        "method_name": null,
        "code": "21 class SQLCompiler:\n22     def __init__(self, query, connection, using):\n23         self.query = query\n24         self.connection = connection\n25         self.using = using\n26         self.quote_cache = {'*': '*'}\n27         # The select, klass_info, and annotations are needed by QuerySet.iterator()\n28         # these are set as a side-effect of executing the query. Note that we calculate\n29         # separately a list of extra select columns needed for grammatical correctness\n30         # of the query, but these columns are not included in self.select.\n31         self.select = None\n32         self.annotation_col_map = None\n33         self.klass_info = None\n34         # Multiline ordering SQL clause may appear from RawSQL.\n35         self.ordering_parts = re.compile(r'^(.*)\\s(ASC|DESC)(.*)', re.MULTILINE | re.DOTALL)\n36         self._meta_ordering = None\n37 \n38     def setup_query(self):\n39         if all(self.query.alias_refcount[a] == 0 for a in self.query.alias_map):\n40             self.query.get_initial_alias()\n41         self.select, self.klass_info, self.annotation_col_map = self.get_select()\n42         self.col_count = len(self.select)\n43 \n44     def pre_sql_setup(self):\n45         \"\"\"\n46         Do any necessary class setup immediately prior to producing SQL. This\n47         is for things that can't necessarily be done in __init__ because we\n48         might not have all the pieces in place at that time.\n49         \"\"\"\n50         self.setup_query()\n51         order_by = self.get_order_by()\n52         self.where, self.having = self.query.where.split_having()\n53         extra_select = self.get_extra_select(order_by, self.select)\n54         self.has_extra_select = bool(extra_select)\n55         group_by = self.get_group_by(self.select + extra_select, order_by)\n56         return extra_select, order_by, group_by\n57 \n58     def get_group_by(self, select, order_by):\n59         \"\"\"\n60         Return a list of 2-tuples of form (sql, params).\n61 \n62         The logic of what exactly the GROUP BY clause contains is hard\n63         to describe in other words than \"if it passes the test suite,\n64         then it is correct\".\n65         \"\"\"\n66         # Some examples:\n67         #     SomeModel.objects.annotate(Count('somecol'))\n68         #     GROUP BY: all fields of the model\n69         #\n70         #    SomeModel.objects.values('name').annotate(Count('somecol'))\n71         #    GROUP BY: name\n72         #\n73         #    SomeModel.objects.annotate(Count('somecol')).values('name')\n74         #    GROUP BY: all cols of the model\n75         #\n76         #    SomeModel.objects.values('name', 'pk').annotate(Count('somecol')).values('pk')\n77         #    GROUP BY: name, pk\n78         #\n79         #    SomeModel.objects.values('name').annotate(Count('somecol')).values('pk')\n80         #    GROUP BY: name, pk\n81         #\n82         # In fact, the self.query.group_by is the minimal set to GROUP BY. It\n83         # can't be ever restricted to a smaller set, but additional columns in\n84         # HAVING, ORDER BY, and SELECT clauses are added to it. Unfortunately\n85         # the end result is that it is impossible to force the query to have\n86         # a chosen GROUP BY clause - you can almost do this by using the form:\n87         #     .values(*wanted_cols).annotate(AnAggregate())\n88         # but any later annotations, extra selects, values calls that\n89         # refer some column outside of the wanted_cols, order_by, or even\n90         # filter calls can alter the GROUP BY clause.\n91 \n92         # The query.group_by is either None (no GROUP BY at all), True\n93         # (group by select fields), or a list of expressions to be added\n94         # to the group by.\n95         if self.query.group_by is None:\n96             return []\n97         expressions = []\n98         if self.query.group_by is not True:\n99             # If the group by is set to a list (by .values() call most likely),\n100             # then we need to add everything in it to the GROUP BY clause.\n101             # Backwards compatibility hack for setting query.group_by. Remove\n102             # when  we have public API way of forcing the GROUP BY clause.\n103             # Converts string references to expressions.\n104             for expr in self.query.group_by:\n105                 if not hasattr(expr, 'as_sql'):\n106                     expressions.append(self.query.resolve_ref(expr))\n107                 else:\n108                     expressions.append(expr)\n109         # Note that even if the group_by is set, it is only the minimal\n110         # set to group by. So, we need to add cols in select, order_by, and\n111         # having into the select in any case.\n112         for expr, _, _ in select:\n113             cols = expr.get_group_by_cols()\n114             for col in cols:\n115                 expressions.append(col)\n116         for expr, (sql, params, is_ref) in order_by:\n117             # Skip References to the select clause, as all expressions in the\n118             # select clause are already part of the group by.\n119             if not expr.contains_aggregate and not is_ref:\n120                 expressions.extend(expr.get_source_expressions())\n121         having_group_by = self.having.get_group_by_cols() if self.having else ()\n122         for expr in having_group_by:\n123             expressions.append(expr)\n124         result = []\n125         seen = set()\n126         expressions = self.collapse_group_by(expressions, having_group_by)\n127 \n128         for expr in expressions:\n129             sql, params = self.compile(expr)\n130             params_hash = make_hashable(params)\n131             if (sql, params_hash) not in seen:\n132                 result.append((sql, params))\n133                 seen.add((sql, params_hash))\n134         return result\n135 \n136     def collapse_group_by(self, expressions, having):\n137         # If the DB can group by primary key, then group by the primary key of\n138         # query's main model. Note that for PostgreSQL the GROUP BY clause must\n139         # include the primary key of every table, but for MySQL it is enough to\n140         # have the main table's primary key.\n141         if self.connection.features.allows_group_by_pk:\n142             # Determine if the main model's primary key is in the query.\n143             pk = None\n144             for expr in expressions:\n145                 # Is this a reference to query's base table primary key? If the\n146                 # expression isn't a Col-like, then skip the expression.\n147                 if (getattr(expr, 'target', None) == self.query.model._meta.pk and\n148                         getattr(expr, 'alias', None) == self.query.base_table):\n149                     pk = expr\n150                     break\n151             # If the main model's primary key is in the query, group by that\n152             # field, HAVING expressions, and expressions associated with tables\n153             # that don't have a primary key included in the grouped columns.\n154             if pk:\n155                 pk_aliases = {\n156                     expr.alias for expr in expressions\n157                     if hasattr(expr, 'target') and expr.target.primary_key\n158                 }\n159                 expressions = [pk] + [\n160                     expr for expr in expressions\n161                     if expr in having or (\n162                         getattr(expr, 'alias', None) is not None and expr.alias not in pk_aliases\n163                     )\n164                 ]\n165         elif self.connection.features.allows_group_by_selected_pks:\n166             # Filter out all expressions associated with a table's primary key\n167             # present in the grouped columns. This is done by identifying all\n168             # tables that have their primary key included in the grouped\n169             # columns and removing non-primary key columns referring to them.\n170             # Unmanaged models are excluded because they could be representing\n171             # database views on which the optimization might not be allowed.\n172             pks = {\n173                 expr for expr in expressions\n174                 if (\n175                     hasattr(expr, 'target') and\n176                     expr.target.primary_key and\n177                     self.connection.features.allows_group_by_selected_pks_on_model(expr.target.model)\n178                 )\n179             }\n180             aliases = {expr.alias for expr in pks}\n181             expressions = [\n182                 expr for expr in expressions if expr in pks or getattr(expr, 'alias', None) not in aliases\n183             ]\n184         return expressions\n185 \n186     def get_select(self):\n187         \"\"\"\n188         Return three values:\n189         - a list of 3-tuples of (expression, (sql, params), alias)\n190         - a klass_info structure,\n191         - a dictionary of annotations\n192 \n193         The (sql, params) is what the expression will produce, and alias is the\n194         \"AS alias\" for the column (possibly None).\n195 \n196         The klass_info structure contains the following information:\n197         - The base model of the query.\n198         - Which columns for that model are present in the query (by\n199           position of the select clause).\n200         - related_klass_infos: [f, klass_info] to descent into\n201 \n202         The annotations is a dictionary of {'attname': column position} values.\n203         \"\"\"\n204         select = []\n205         klass_info = None\n206         annotations = {}\n207         select_idx = 0\n208         for alias, (sql, params) in self.query.extra_select.items():\n209             annotations[alias] = select_idx\n210             select.append((RawSQL(sql, params), alias))\n211             select_idx += 1\n212         assert not (self.query.select and self.query.default_cols)\n213         if self.query.default_cols:\n214             cols = self.get_default_columns()\n215         else:\n216             # self.query.select is a special case. These columns never go to\n217             # any model.\n218             cols = self.query.select\n219         if cols:\n220             select_list = []\n221             for col in cols:\n222                 select_list.append(select_idx)\n223                 select.append((col, None))\n224                 select_idx += 1\n225             klass_info = {\n226                 'model': self.query.model,\n227                 'select_fields': select_list,\n228             }\n229         for alias, annotation in self.query.annotation_select.items():\n230             annotations[alias] = select_idx\n231             select.append((annotation, alias))\n232             select_idx += 1\n233 \n234         if self.query.select_related:\n235             related_klass_infos = self.get_related_selections(select)\n236             klass_info['related_klass_infos'] = related_klass_infos\n237 \n238             def get_select_from_parent(klass_info):\n239                 for ki in klass_info['related_klass_infos']:\n240                     if ki['from_parent']:\n241                         ki['select_fields'] = (klass_info['select_fields'] +\n242                                                ki['select_fields'])\n243                     get_select_from_parent(ki)\n244             get_select_from_parent(klass_info)\n245 \n246         ret = []\n247         for col, alias in select:\n248             try:\n249                 sql, params = self.compile(col)\n250             except EmptyResultSet:\n251                 # Select a predicate that's always False.\n252                 sql, params = '0', ()\n253             else:\n254                 sql, params = col.select_format(self, sql, params)\n255             ret.append((col, (sql, params), alias))\n256         return ret, klass_info, annotations\n257 \n258     def get_order_by(self):\n259         \"\"\"\n260         Return a list of 2-tuples of form (expr, (sql, params, is_ref)) for the\n261         ORDER BY clause.\n262 \n263         The order_by clause can alter the select clause (for example it\n264         can add aliases to clauses that do not yet have one, or it can\n265         add totally new select clauses).\n266         \"\"\"\n267         if self.query.extra_order_by:\n268             ordering = self.query.extra_order_by\n269         elif not self.query.default_ordering:\n270             ordering = self.query.order_by\n271         elif self.query.order_by:\n272             ordering = self.query.order_by\n273         elif self.query.get_meta().ordering:\n274             ordering = self.query.get_meta().ordering\n275             self._meta_ordering = ordering\n276         else:\n277             ordering = []\n278         if self.query.standard_ordering:\n279             asc, desc = ORDER_DIR['ASC']\n280         else:\n281             asc, desc = ORDER_DIR['DESC']\n282 \n283         order_by = []\n284         for field in ordering:\n285             if hasattr(field, 'resolve_expression'):\n286                 if isinstance(field, Value):\n287                     # output_field must be resolved for constants.\n288                     field = Cast(field, field.output_field)\n289                 if not isinstance(field, OrderBy):\n290                     field = field.asc()\n291                 if not self.query.standard_ordering:\n292                     field = field.copy()\n293                     field.reverse_ordering()\n294                 order_by.append((field, False))\n295                 continue\n296             if field == '?':  # random\n297                 order_by.append((OrderBy(Random()), False))\n298                 continue\n299 \n300             col, order = get_order_dir(field, asc)\n301             descending = order == 'DESC'\n302 \n303             if col in self.query.annotation_select:\n304                 # Reference to expression in SELECT clause\n305                 order_by.append((\n306                     OrderBy(Ref(col, self.query.annotation_select[col]), descending=descending),\n307                     True))\n308                 continue\n309             if col in self.query.annotations:\n310                 # References to an expression which is masked out of the SELECT\n311                 # clause.\n312                 expr = self.query.annotations[col]\n313                 if isinstance(expr, Value):\n314                     # output_field must be resolved for constants.\n315                     expr = Cast(expr, expr.output_field)\n316                 order_by.append((OrderBy(expr, descending=descending), False))\n317                 continue\n318 \n319             if '.' in field:\n320                 # This came in through an extra(order_by=...) addition. Pass it\n321                 # on verbatim.\n322                 table, col = col.split('.', 1)\n323                 order_by.append((\n324                     OrderBy(\n325                         RawSQL('%s.%s' % (self.quote_name_unless_alias(table), col), []),\n326                         descending=descending\n327                     ), False))\n328                 continue\n329 \n330             if not self.query.extra or col not in self.query.extra:\n331                 # 'col' is of the form 'field' or 'field1__field2' or\n332                 # '-field1__field2__field', etc.\n333                 order_by.extend(self.find_ordering_name(\n334                     field, self.query.get_meta(), default_order=asc))\n335             else:\n336                 if col not in self.query.extra_select:\n337                     order_by.append((\n338                         OrderBy(RawSQL(*self.query.extra[col]), descending=descending),\n339                         False))\n340                 else:\n341                     order_by.append((\n342                         OrderBy(Ref(col, RawSQL(*self.query.extra[col])), descending=descending),\n343                         True))\n344         result = []\n345         seen = set()\n346 \n347         for expr, is_ref in order_by:\n348             resolved = expr.resolve_expression(self.query, allow_joins=True, reuse=None)\n349             if self.query.combinator:\n350                 src = resolved.get_source_expressions()[0]\n351                 # Relabel order by columns to raw numbers if this is a combined\n352                 # query; necessary since the columns can't be referenced by the\n353                 # fully qualified name and the simple column names may collide.\n354                 for idx, (sel_expr, _, col_alias) in enumerate(self.select):\n355                     if is_ref and col_alias == src.refs:\n356                         src = src.source\n357                     elif col_alias:\n358                         continue\n359                     if src == sel_expr:\n360                         resolved.set_source_expressions([RawSQL('%d' % (idx + 1), ())])\n361                         break\n362                 else:\n363                     if col_alias:\n364                         raise DatabaseError('ORDER BY term does not match any column in the result set.')\n365                     # Add column used in ORDER BY clause without an alias to\n366                     # the selected columns.\n367                     self.query.add_select_col(src)\n368                     resolved.set_source_expressions([RawSQL('%d' % len(self.query.select), ())])\n369             sql, params = self.compile(resolved)\n370             # Don't add the same column twice, but the order direction is\n371             # not taken into account so we strip it. When this entire method\n372             # is refactored into expressions, then we can check each part as we\n373             # generate it.\n374             without_ordering = self.ordering_parts.search(sql).group(1)\n375             params_hash = make_hashable(params)\n376             if (without_ordering, params_hash) in seen:\n377                 continue\n378             seen.add((without_ordering, params_hash))\n379             result.append((resolved, (sql, params, is_ref)))\n380         return result\n381 \n382     def get_extra_select(self, order_by, select):\n383         extra_select = []\n384         if self.query.distinct and not self.query.distinct_fields:\n385             select_sql = [t[1] for t in select]\n386             for expr, (sql, params, is_ref) in order_by:\n387                 without_ordering = self.ordering_parts.search(sql).group(1)\n388                 if not is_ref and (without_ordering, params) not in select_sql:\n389                     extra_select.append((expr, (without_ordering, params), None))\n390         return extra_select\n391 \n392     def quote_name_unless_alias(self, name):\n393         \"\"\"\n394         A wrapper around connection.ops.quote_name that doesn't quote aliases\n395         for table names. This avoids problems with some SQL dialects that treat\n396         quoted strings specially (e.g. PostgreSQL).\n397         \"\"\"\n398         if name in self.quote_cache:\n399             return self.quote_cache[name]\n400         if ((name in self.query.alias_map and name not in self.query.table_map) or\n401                 name in self.query.extra_select or (\n402                     name in self.query.external_aliases and name not in self.query.table_map)):\n403             self.quote_cache[name] = name\n404             return name\n405         r = self.connection.ops.quote_name(name)\n406         self.quote_cache[name] = r\n407         return r\n408 \n409     def compile(self, node):\n410         vendor_impl = getattr(node, 'as_' + self.connection.vendor, None)\n411         if vendor_impl:\n412             sql, params = vendor_impl(self, self.connection)\n413         else:\n414             sql, params = node.as_sql(self, self.connection)\n415         return sql, params\n416 \n417     def get_combinator_sql(self, combinator, all):\n418         features = self.connection.features\n419         compilers = [\n420             query.get_compiler(self.using, self.connection)\n421             for query in self.query.combined_queries if not query.is_empty()\n422         ]\n423         if not features.supports_slicing_ordering_in_compound:\n424             for query, compiler in zip(self.query.combined_queries, compilers):\n425                 if query.low_mark or query.high_mark:\n426                     raise DatabaseError('LIMIT/OFFSET not allowed in subqueries of compound statements.')\n427                 if compiler.get_order_by():\n428                     raise DatabaseError('ORDER BY not allowed in subqueries of compound statements.')\n429         parts = ()\n430         for compiler in compilers:\n431             try:\n432                 # If the columns list is limited, then all combined queries\n433                 # must have the same columns list. Set the selects defined on\n434                 # the query on all combined queries, if not already set.\n435                 if not compiler.query.values_select and self.query.values_select:\n436                     compiler.query = compiler.query.clone()\n437                     compiler.query.set_values((\n438                         *self.query.extra_select,\n439                         *self.query.values_select,\n440                         *self.query.annotation_select,\n441                     ))\n442                 part_sql, part_args = compiler.as_sql()\n443                 if compiler.query.combinator:\n444                     # Wrap in a subquery if wrapping in parentheses isn't\n445                     # supported.\n446                     if not features.supports_parentheses_in_compound:\n447                         part_sql = 'SELECT * FROM ({})'.format(part_sql)\n448                     # Add parentheses when combining with compound query if not\n449                     # already added for all compound queries.\n450                     elif not features.supports_slicing_ordering_in_compound:\n451                         part_sql = '({})'.format(part_sql)\n452                 parts += ((part_sql, part_args),)\n453             except EmptyResultSet:\n454                 # Omit the empty queryset with UNION and with DIFFERENCE if the\n455                 # first queryset is nonempty.\n456                 if combinator == 'union' or (combinator == 'difference' and parts):\n457                     continue\n458                 raise\n459         if not parts:\n460             raise EmptyResultSet\n461         combinator_sql = self.connection.ops.set_operators[combinator]\n462         if all and combinator == 'union':\n463             combinator_sql += ' ALL'\n464         braces = '({})' if features.supports_slicing_ordering_in_compound else '{}'\n465         sql_parts, args_parts = zip(*((braces.format(sql), args) for sql, args in parts))\n466         result = [' {} '.format(combinator_sql).join(sql_parts)]\n467         params = []\n468         for part in args_parts:\n469             params.extend(part)\n470         return result, params\n471 \n472     def as_sql(self, with_limits=True, with_col_aliases=False):\n473         \"\"\"\n474         Create the SQL for this query. Return the SQL string and list of\n475         parameters.\n476 \n477         If 'with_limits' is False, any limit/offset information is not included\n478         in the query.\n479         \"\"\"\n480         refcounts_before = self.query.alias_refcount.copy()\n481         try:\n482             extra_select, order_by, group_by = self.pre_sql_setup()\n483             for_update_part = None\n484             # Is a LIMIT/OFFSET clause needed?\n485             with_limit_offset = with_limits and (self.query.high_mark is not None or self.query.low_mark)\n486             combinator = self.query.combinator\n487             features = self.connection.features\n488             if combinator:\n489                 if not getattr(features, 'supports_select_{}'.format(combinator)):\n490                     raise NotSupportedError('{} is not supported on this database backend.'.format(combinator))\n491                 result, params = self.get_combinator_sql(combinator, self.query.combinator_all)\n492             else:\n493                 distinct_fields, distinct_params = self.get_distinct()\n494                 # This must come after 'select', 'ordering', and 'distinct'\n495                 # (see docstring of get_from_clause() for details).\n496                 from_, f_params = self.get_from_clause()\n497                 where, w_params = self.compile(self.where) if self.where is not None else (\"\", [])\n498                 having, h_params = self.compile(self.having) if self.having is not None else (\"\", [])\n499                 result = ['SELECT']\n500                 params = []\n501 \n502                 if self.query.distinct:\n503                     distinct_result, distinct_params = self.connection.ops.distinct_sql(\n504                         distinct_fields,\n505                         distinct_params,\n506                     )\n507                     result += distinct_result\n508                     params += distinct_params\n509 \n510                 out_cols = []\n511                 col_idx = 1\n512                 for _, (s_sql, s_params), alias in self.select + extra_select:\n513                     if alias:\n514                         s_sql = '%s AS %s' % (s_sql, self.connection.ops.quote_name(alias))\n515                     elif with_col_aliases:\n516                         s_sql = '%s AS %s' % (s_sql, 'Col%d' % col_idx)\n517                         col_idx += 1\n518                     params.extend(s_params)\n519                     out_cols.append(s_sql)\n520 \n521                 result += [', '.join(out_cols), 'FROM', *from_]\n522                 params.extend(f_params)\n523 \n524                 if self.query.select_for_update and self.connection.features.has_select_for_update:\n525                     if self.connection.get_autocommit():\n526                         raise TransactionManagementError('select_for_update cannot be used outside of a transaction.')\n527 \n528                     if with_limit_offset and not self.connection.features.supports_select_for_update_with_limit:\n529                         raise NotSupportedError(\n530                             'LIMIT/OFFSET is not supported with '\n531                             'select_for_update on this database backend.'\n532                         )\n533                     nowait = self.query.select_for_update_nowait\n534                     skip_locked = self.query.select_for_update_skip_locked\n535                     of = self.query.select_for_update_of\n536                     # If it's a NOWAIT/SKIP LOCKED/OF query but the backend\n537                     # doesn't support it, raise NotSupportedError to prevent a\n538                     # possible deadlock.\n539                     if nowait and not self.connection.features.has_select_for_update_nowait:\n540                         raise NotSupportedError('NOWAIT is not supported on this database backend.')\n541                     elif skip_locked and not self.connection.features.has_select_for_update_skip_locked:\n542                         raise NotSupportedError('SKIP LOCKED is not supported on this database backend.')\n543                     elif of and not self.connection.features.has_select_for_update_of:\n544                         raise NotSupportedError('FOR UPDATE OF is not supported on this database backend.')\n545                     for_update_part = self.connection.ops.for_update_sql(\n546                         nowait=nowait,\n547                         skip_locked=skip_locked,\n548                         of=self.get_select_for_update_of_arguments(),\n549                     )\n550 \n551                 if for_update_part and self.connection.features.for_update_after_from:\n552                     result.append(for_update_part)\n553 \n554                 if where:\n555                     result.append('WHERE %s' % where)\n556                     params.extend(w_params)\n557 \n558                 grouping = []\n559                 for g_sql, g_params in group_by:\n560                     grouping.append(g_sql)\n561                     params.extend(g_params)\n562                 if grouping:\n563                     if distinct_fields:\n564                         raise NotImplementedError('annotate() + distinct(fields) is not implemented.')\n565                     order_by = order_by or self.connection.ops.force_no_ordering()\n566                     result.append('GROUP BY %s' % ', '.join(grouping))\n567                     if self._meta_ordering:\n568                         order_by = None\n569                 if having:\n570                     result.append('HAVING %s' % having)\n571                     params.extend(h_params)\n572 \n573             if self.query.explain_query:\n574                 result.insert(0, self.connection.ops.explain_query_prefix(\n575                     self.query.explain_format,\n576                     **self.query.explain_options\n577                 ))\n578 \n579             if order_by:\n580                 ordering = []\n581                 for _, (o_sql, o_params, _) in order_by:\n582                     ordering.append(o_sql)\n583                     params.extend(o_params)\n584                 result.append('ORDER BY %s' % ', '.join(ordering))\n585 \n586             if with_limit_offset:\n587                 result.append(self.connection.ops.limit_offset_sql(self.query.low_mark, self.query.high_mark))\n588 \n589             if for_update_part and not self.connection.features.for_update_after_from:\n590                 result.append(for_update_part)\n591 \n592             if self.query.subquery and extra_select:\n593                 # If the query is used as a subquery, the extra selects would\n594                 # result in more columns than the left-hand side expression is\n595                 # expecting. This can happen when a subquery uses a combination\n596                 # of order_by() and distinct(), forcing the ordering expressions\n597                 # to be selected as well. Wrap the query in another subquery\n598                 # to exclude extraneous selects.\n599                 sub_selects = []\n600                 sub_params = []\n601                 for index, (select, _, alias) in enumerate(self.select, start=1):\n602                     if not alias and with_col_aliases:\n603                         alias = 'col%d' % index\n604                     if alias:\n605                         sub_selects.append(\"%s.%s\" % (\n606                             self.connection.ops.quote_name('subquery'),\n607                             self.connection.ops.quote_name(alias),\n608                         ))\n609                     else:\n610                         select_clone = select.relabeled_clone({select.alias: 'subquery'})\n611                         subselect, subparams = select_clone.as_sql(self, self.connection)\n612                         sub_selects.append(subselect)\n613                         sub_params.extend(subparams)\n614                 return 'SELECT %s FROM (%s) subquery' % (\n615                     ', '.join(sub_selects),\n616                     ' '.join(result),\n617                 ), tuple(sub_params + params)\n618 \n619             return ' '.join(result), tuple(params)\n620         finally:\n621             # Finally do cleanup - get rid of the joins we created above.\n622             self.query.reset_refcounts(refcounts_before)\n623 \n624     def get_default_columns(self, start_alias=None, opts=None, from_parent=None):\n625         \"\"\"\n626         Compute the default columns for selecting every field in the base\n627         model. Will sometimes be called to pull in related models (e.g. via\n628         select_related), in which case \"opts\" and \"start_alias\" will be given\n629         to provide a starting point for the traversal.\n630 \n631         Return a list of strings, quoted appropriately for use in SQL\n632         directly, as well as a set of aliases used in the select statement (if\n633         'as_pairs' is True, return a list of (alias, col_name) pairs instead\n634         of strings as the first component and None as the second component).\n635         \"\"\"\n636         result = []\n637         if opts is None:\n638             opts = self.query.get_meta()\n639         only_load = self.deferred_to_columns()\n640         start_alias = start_alias or self.query.get_initial_alias()\n641         # The 'seen_models' is used to optimize checking the needed parent\n642         # alias for a given field. This also includes None -> start_alias to\n643         # be used by local fields.\n644         seen_models = {None: start_alias}\n645 \n646         for field in opts.concrete_fields:\n647             model = field.model._meta.concrete_model\n648             # A proxy model will have a different model and concrete_model. We\n649             # will assign None if the field belongs to this model.\n650             if model == opts.model:\n651                 model = None\n652             if from_parent and model is not None and issubclass(\n653                     from_parent._meta.concrete_model, model._meta.concrete_model):\n654                 # Avoid loading data for already loaded parents.\n655                 # We end up here in the case select_related() resolution\n656                 # proceeds from parent model to child model. In that case the\n657                 # parent model data is already present in the SELECT clause,\n658                 # and we want to avoid reloading the same data again.\n659                 continue\n660             if field.model in only_load and field.attname not in only_load[field.model]:\n661                 continue\n662             alias = self.query.join_parent_model(opts, model, start_alias,\n663                                                  seen_models)\n664             column = field.get_col(alias)\n665             result.append(column)\n666         return result\n667 \n668     def get_distinct(self):\n669         \"\"\"\n670         Return a quoted list of fields to use in DISTINCT ON part of the query.\n671 \n672         This method can alter the tables in the query, and thus it must be\n673         called before get_from_clause().\n674         \"\"\"\n675         result = []\n676         params = []\n677         opts = self.query.get_meta()\n678 \n679         for name in self.query.distinct_fields:\n680             parts = name.split(LOOKUP_SEP)\n681             _, targets, alias, joins, path, _, transform_function = self._setup_joins(parts, opts, None)\n682             targets, alias, _ = self.query.trim_joins(targets, joins, path)\n683             for target in targets:\n684                 if name in self.query.annotation_select:\n685                     result.append(name)\n686                 else:\n687                     r, p = self.compile(transform_function(target, alias))\n688                     result.append(r)\n689                     params.append(p)\n690         return result, params\n691 \n692     def find_ordering_name(self, name, opts, alias=None, default_order='ASC',\n693                            already_seen=None):\n694         \"\"\"\n695         Return the table alias (the name might be ambiguous, the alias will\n696         not be) and column name for ordering by the given 'name' parameter.\n697         The 'name' is of the form 'field1__field2__...__fieldN'.\n698         \"\"\"\n699         name, order = get_order_dir(name, default_order)\n700         descending = order == 'DESC'\n701         pieces = name.split(LOOKUP_SEP)\n702         field, targets, alias, joins, path, opts, transform_function = self._setup_joins(pieces, opts, alias)\n703 \n704         # If we get to this point and the field is a relation to another model,\n705         # append the default ordering for that model unless the attribute name\n706         # of the field is specified.\n707         if field.is_relation and opts.ordering and getattr(field, 'attname', None) != name:\n708             # Firstly, avoid infinite loops.\n709             already_seen = already_seen or set()\n710             join_tuple = tuple(getattr(self.query.alias_map[j], 'join_cols', None) for j in joins)\n711             if join_tuple in already_seen:\n712                 raise FieldError('Infinite loop caused by ordering.')\n713             already_seen.add(join_tuple)\n714 \n715             results = []\n716             for item in opts.ordering:\n717                 if hasattr(item, 'resolve_expression') and not isinstance(item, OrderBy):\n718                     item = item.desc() if descending else item.asc()\n719                 if isinstance(item, OrderBy):\n720                     results.append((item, False))\n721                     continue\n722                 results.extend(self.find_ordering_name(item, opts, alias,\n723                                                        order, already_seen))\n724             return results\n725         targets, alias, _ = self.query.trim_joins(targets, joins, path)\n726         return [(OrderBy(transform_function(t, alias), descending=descending), False) for t in targets]\n727 \n728     def _setup_joins(self, pieces, opts, alias):\n729         \"\"\"\n730         Helper method for get_order_by() and get_distinct().\n731 \n732         get_ordering() and get_distinct() must produce same target columns on\n733         same input, as the prefixes of get_ordering() and get_distinct() must\n734         match. Executing SQL where this is not true is an error.\n735         \"\"\"\n736         alias = alias or self.query.get_initial_alias()\n737         field, targets, opts, joins, path, transform_function = self.query.setup_joins(pieces, opts, alias)\n738         alias = joins[-1]\n739         return field, targets, alias, joins, path, opts, transform_function\n740 \n741     def get_from_clause(self):\n742         \"\"\"\n743         Return a list of strings that are joined together to go after the\n744         \"FROM\" part of the query, as well as a list any extra parameters that\n745         need to be included. Subclasses, can override this to create a\n746         from-clause via a \"select\".\n747 \n748         This should only be called after any SQL construction methods that\n749         might change the tables that are needed. This means the select columns,\n750         ordering, and distinct must be done first.\n751         \"\"\"\n752         result = []\n753         params = []\n754         for alias in tuple(self.query.alias_map):\n755             if not self.query.alias_refcount[alias]:\n756                 continue\n757             try:\n758                 from_clause = self.query.alias_map[alias]\n759             except KeyError:\n760                 # Extra tables can end up in self.tables, but not in the\n761                 # alias_map if they aren't in a join. That's OK. We skip them.\n762                 continue\n763             clause_sql, clause_params = self.compile(from_clause)\n764             result.append(clause_sql)\n765             params.extend(clause_params)\n766         for t in self.query.extra_tables:\n767             alias, _ = self.query.table_alias(t)\n768             # Only add the alias if it's not already present (the table_alias()\n769             # call increments the refcount, so an alias refcount of one means\n770             # this is the only reference).\n771             if alias not in self.query.alias_map or self.query.alias_refcount[alias] == 1:\n772                 result.append(', %s' % self.quote_name_unless_alias(alias))\n773         return result, params\n774 \n775     def get_related_selections(self, select, opts=None, root_alias=None, cur_depth=1,\n776                                requested=None, restricted=None):\n777         \"\"\"\n778         Fill in the information needed for a select_related query. The current\n779         depth is measured as the number of connections away from the root model\n780         (for example, cur_depth=1 means we are looking at models with direct\n781         connections to the root model).\n782         \"\"\"\n783         def _get_field_choices():\n784             direct_choices = (f.name for f in opts.fields if f.is_relation)\n785             reverse_choices = (\n786                 f.field.related_query_name()\n787                 for f in opts.related_objects if f.field.unique\n788             )\n789             return chain(direct_choices, reverse_choices, self.query._filtered_relations)\n790 \n791         related_klass_infos = []\n792         if not restricted and cur_depth > self.query.max_depth:\n793             # We've recursed far enough; bail out.\n794             return related_klass_infos\n795 \n796         if not opts:\n797             opts = self.query.get_meta()\n798             root_alias = self.query.get_initial_alias()\n799         only_load = self.query.get_loaded_field_names()\n800 \n801         # Setup for the case when only particular related fields should be\n802         # included in the related selection.\n803         fields_found = set()\n804         if requested is None:\n805             restricted = isinstance(self.query.select_related, dict)\n806             if restricted:\n807                 requested = self.query.select_related\n808 \n809         def get_related_klass_infos(klass_info, related_klass_infos):\n810             klass_info['related_klass_infos'] = related_klass_infos\n811 \n812         for f in opts.fields:\n813             field_model = f.model._meta.concrete_model\n814             fields_found.add(f.name)\n815 \n816             if restricted:\n817                 next = requested.get(f.name, {})\n818                 if not f.is_relation:\n819                     # If a non-related field is used like a relation,\n820                     # or if a single non-relational field is given.\n821                     if next or f.name in requested:\n822                         raise FieldError(\n823                             \"Non-relational field given in select_related: '%s'. \"\n824                             \"Choices are: %s\" % (\n825                                 f.name,\n826                                 \", \".join(_get_field_choices()) or '(none)',\n827                             )\n828                         )\n829             else:\n830                 next = False\n831 \n832             if not select_related_descend(f, restricted, requested,\n833                                           only_load.get(field_model)):\n834                 continue\n835             klass_info = {\n836                 'model': f.remote_field.model,\n837                 'field': f,\n838                 'reverse': False,\n839                 'local_setter': f.set_cached_value,\n840                 'remote_setter': f.remote_field.set_cached_value if f.unique else lambda x, y: None,\n841                 'from_parent': False,\n842             }\n843             related_klass_infos.append(klass_info)\n844             select_fields = []\n845             _, _, _, joins, _, _ = self.query.setup_joins(\n846                 [f.name], opts, root_alias)\n847             alias = joins[-1]\n848             columns = self.get_default_columns(start_alias=alias, opts=f.remote_field.model._meta)\n849             for col in columns:\n850                 select_fields.append(len(select))\n851                 select.append((col, None))\n852             klass_info['select_fields'] = select_fields\n853             next_klass_infos = self.get_related_selections(\n854                 select, f.remote_field.model._meta, alias, cur_depth + 1, next, restricted)\n855             get_related_klass_infos(klass_info, next_klass_infos)\n856 \n857         if restricted:\n858             related_fields = [\n859                 (o.field, o.related_model)\n860                 for o in opts.related_objects\n861                 if o.field.unique and not o.many_to_many\n862             ]\n863             for f, model in related_fields:\n864                 if not select_related_descend(f, restricted, requested,\n865                                               only_load.get(model), reverse=True):\n866                     continue\n867 \n868                 related_field_name = f.related_query_name()\n869                 fields_found.add(related_field_name)\n870 \n871                 join_info = self.query.setup_joins([related_field_name], opts, root_alias)\n872                 alias = join_info.joins[-1]\n873                 from_parent = issubclass(model, opts.model) and model is not opts.model\n874                 klass_info = {\n875                     'model': model,\n876                     'field': f,\n877                     'reverse': True,\n878                     'local_setter': f.remote_field.set_cached_value,\n879                     'remote_setter': f.set_cached_value,\n880                     'from_parent': from_parent,\n881                 }\n882                 related_klass_infos.append(klass_info)\n883                 select_fields = []\n884                 columns = self.get_default_columns(\n885                     start_alias=alias, opts=model._meta, from_parent=opts.model)\n886                 for col in columns:\n887                     select_fields.append(len(select))\n888                     select.append((col, None))\n889                 klass_info['select_fields'] = select_fields\n890                 next = requested.get(f.related_query_name(), {})\n891                 next_klass_infos = self.get_related_selections(\n892                     select, model._meta, alias, cur_depth + 1,\n893                     next, restricted)\n894                 get_related_klass_infos(klass_info, next_klass_infos)\n895 \n896             def local_setter(obj, from_obj):\n897                 # Set a reverse fk object when relation is non-empty.\n898                 if from_obj:\n899                     f.remote_field.set_cached_value(from_obj, obj)\n900 \n901             def remote_setter(name, obj, from_obj):\n902                 setattr(from_obj, name, obj)\n903 \n904             for name in list(requested):\n905                 # Filtered relations work only on the topmost level.\n906                 if cur_depth > 1:\n907                     break\n908                 if name in self.query._filtered_relations:\n909                     fields_found.add(name)\n910                     f, _, join_opts, joins, _, _ = self.query.setup_joins([name], opts, root_alias)\n911                     model = join_opts.model\n912                     alias = joins[-1]\n913                     from_parent = issubclass(model, opts.model) and model is not opts.model\n914                     klass_info = {\n915                         'model': model,\n916                         'field': f,\n917                         'reverse': True,\n918                         'local_setter': local_setter,\n919                         'remote_setter': partial(remote_setter, name),\n920                         'from_parent': from_parent,\n921                     }\n922                     related_klass_infos.append(klass_info)\n923                     select_fields = []\n924                     columns = self.get_default_columns(\n925                         start_alias=alias, opts=model._meta,\n926                         from_parent=opts.model,\n927                     )\n928                     for col in columns:\n929                         select_fields.append(len(select))\n930                         select.append((col, None))\n931                     klass_info['select_fields'] = select_fields\n932                     next_requested = requested.get(name, {})\n933                     next_klass_infos = self.get_related_selections(\n934                         select, opts=model._meta, root_alias=alias,\n935                         cur_depth=cur_depth + 1, requested=next_requested,\n936                         restricted=restricted,\n937                     )\n938                     get_related_klass_infos(klass_info, next_klass_infos)\n939             fields_not_found = set(requested).difference(fields_found)\n940             if fields_not_found:\n941                 invalid_fields = (\"'%s'\" % s for s in fields_not_found)\n942                 raise FieldError(\n943                     'Invalid field name(s) given in select_related: %s. '\n944                     'Choices are: %s' % (\n945                         ', '.join(invalid_fields),\n946                         ', '.join(_get_field_choices()) or '(none)',\n947                     )\n948                 )\n949         return related_klass_infos\n950 \n951     def get_select_for_update_of_arguments(self):\n952         \"\"\"\n953         Return a quoted list of arguments for the SELECT FOR UPDATE OF part of\n954         the query.\n955         \"\"\"\n956         def _get_parent_klass_info(klass_info):\n957             return (\n958                 {\n959                     'model': parent_model,\n960                     'field': parent_link,\n961                     'reverse': False,\n962                     'select_fields': [\n963                         select_index\n964                         for select_index in klass_info['select_fields']\n965                         if self.select[select_index][0].target.model == parent_model\n966                     ],\n967                 }\n968                 for parent_model, parent_link in klass_info['model']._meta.parents.items()\n969             )\n970 \n971         def _get_field_choices():\n972             \"\"\"Yield all allowed field paths in breadth-first search order.\"\"\"\n973             queue = collections.deque([(None, self.klass_info)])\n974             while queue:\n975                 parent_path, klass_info = queue.popleft()\n976                 if parent_path is None:\n977                     path = []\n978                     yield 'self'\n979                 else:\n980                     field = klass_info['field']\n981                     if klass_info['reverse']:\n982                         field = field.remote_field\n983                     path = parent_path + [field.name]\n984                     yield LOOKUP_SEP.join(path)\n985                 queue.extend(\n986                     (path, klass_info)\n987                     for klass_info in _get_parent_klass_info(klass_info)\n988                 )\n989                 queue.extend(\n990                     (path, klass_info)\n991                     for klass_info in klass_info.get('related_klass_infos', [])\n992                 )\n993         result = []\n994         invalid_names = []\n995         for name in self.query.select_for_update_of:\n996             klass_info = self.klass_info\n997             if name == 'self':\n998                 # Find the first selected column from a base model. If it\n999                 # doesn't exist, don't lock a base model.\n1000                 for select_index in klass_info['select_fields']:\n1001                     if self.select[select_index][0].target.model == klass_info['model']:\n1002                         col = self.select[select_index][0]\n1003                         break\n1004                 else:\n1005                     col = None\n1006             else:\n1007                 for part in name.split(LOOKUP_SEP):\n1008                     klass_infos = (\n1009                         *klass_info.get('related_klass_infos', []),\n1010                         *_get_parent_klass_info(klass_info),\n1011                     )\n1012                     for related_klass_info in klass_infos:\n1013                         field = related_klass_info['field']\n1014                         if related_klass_info['reverse']:\n1015                             field = field.remote_field\n1016                         if field.name == part:\n1017                             klass_info = related_klass_info\n1018                             break\n1019                     else:\n1020                         klass_info = None\n1021                         break\n1022                 if klass_info is None:\n1023                     invalid_names.append(name)\n1024                     continue\n1025                 select_index = klass_info['select_fields'][0]\n1026                 col = self.select[select_index][0]\n1027             if col is not None:\n1028                 if self.connection.features.select_for_update_of_column:\n1029                     result.append(self.compile(col)[0])\n1030                 else:\n1031                     result.append(self.quote_name_unless_alias(col.alias))\n1032         if invalid_names:\n1033             raise FieldError(\n1034                 'Invalid field name(s) given in select_for_update(of=(...)): %s. '\n1035                 'Only relational fields followed in the query are allowed. '\n1036                 'Choices are: %s.' % (\n1037                     ', '.join(invalid_names),\n1038                     ', '.join(_get_field_choices()),\n1039                 )\n1040             )\n1041         return result\n1042 \n1043     def deferred_to_columns(self):\n1044         \"\"\"\n1045         Convert the self.deferred_loading data structure to mapping of table\n1046         names to sets of column names which are to be loaded. Return the\n1047         dictionary.\n1048         \"\"\"\n1049         columns = {}\n1050         self.query.deferred_to_data(columns, self.query.get_loaded_field_names_cb)\n1051         return columns\n1052 \n1053     def get_converters(self, expressions):\n1054         converters = {}\n1055         for i, expression in enumerate(expressions):\n1056             if expression:\n1057                 backend_converters = self.connection.ops.get_db_converters(expression)\n1058                 field_converters = expression.get_db_converters(self.connection)\n1059                 if backend_converters or field_converters:\n1060                     converters[i] = (backend_converters + field_converters, expression)\n1061         return converters\n1062 \n1063     def apply_converters(self, rows, converters):\n1064         connection = self.connection\n1065         converters = list(converters.items())\n1066         for row in map(list, rows):\n1067             for pos, (convs, expression) in converters:\n1068                 value = row[pos]\n1069                 for converter in convs:\n1070                     value = converter(value, expression, connection)\n1071                 row[pos] = value\n1072             yield row\n1073 \n1074     def results_iter(self, results=None, tuple_expected=False, chunked_fetch=False,\n1075                      chunk_size=GET_ITERATOR_CHUNK_SIZE):\n1076         \"\"\"Return an iterator over the results from executing this query.\"\"\"\n1077         if results is None:\n1078             results = self.execute_sql(MULTI, chunked_fetch=chunked_fetch, chunk_size=chunk_size)\n1079         fields = [s[0] for s in self.select[0:self.col_count]]\n1080         converters = self.get_converters(fields)\n1081         rows = chain.from_iterable(results)\n1082         if converters:\n1083             rows = self.apply_converters(rows, converters)\n1084             if tuple_expected:\n1085                 rows = map(tuple, rows)\n1086         return rows\n1087 \n1088     def has_results(self):\n1089         \"\"\"\n1090         Backends (e.g. NoSQL) can override this in order to use optimized\n1091         versions of \"query has any results.\"\n1092         \"\"\"\n1093         # This is always executed on a query clone, so we can modify self.query\n1094         self.query.add_extra({'a': 1}, None, None, None, None, None)\n1095         self.query.set_extra_mask(['a'])\n1096         return bool(self.execute_sql(SINGLE))\n1097 \n1098     def execute_sql(self, result_type=MULTI, chunked_fetch=False, chunk_size=GET_ITERATOR_CHUNK_SIZE):\n1099         \"\"\"\n1100         Run the query against the database and return the result(s). The\n1101         return value is a single data item if result_type is SINGLE, or an\n1102         iterator over the results if the result_type is MULTI.\n1103 \n1104         result_type is either MULTI (use fetchmany() to retrieve all rows),\n1105         SINGLE (only retrieve a single row), or None. In this last case, the\n1106         cursor is returned if any query is executed, since it's used by\n1107         subclasses such as InsertQuery). It's possible, however, that no query\n1108         is needed, as the filters describe an empty set. In that case, None is\n1109         returned, to avoid any unnecessary database interaction.\n1110         \"\"\"\n1111         result_type = result_type or NO_RESULTS\n1112         try:\n1113             sql, params = self.as_sql()\n1114             if not sql:\n1115                 raise EmptyResultSet\n1116         except EmptyResultSet:\n1117             if result_type == MULTI:\n1118                 return iter([])\n1119             else:\n1120                 return\n1121         if chunked_fetch:\n1122             cursor = self.connection.chunked_cursor()\n1123         else:\n1124             cursor = self.connection.cursor()\n1125         try:\n1126             cursor.execute(sql, params)\n1127         except Exception:\n1128             # Might fail for server-side cursors (e.g. connection closed)\n1129             cursor.close()\n1130             raise\n1131 \n1132         if result_type == CURSOR:\n1133             # Give the caller the cursor to process and close.\n1134             return cursor\n1135         if result_type == SINGLE:\n1136             try:\n1137                 val = cursor.fetchone()\n1138                 if val:\n1139                     return val[0:self.col_count]\n1140                 return val\n1141             finally:\n1142                 # done with the cursor\n1143                 cursor.close()\n1144         if result_type == NO_RESULTS:\n1145             cursor.close()\n1146             return\n1147 \n1148         result = cursor_iter(\n1149             cursor, self.connection.features.empty_fetchmany_value,\n1150             self.col_count if self.has_extra_select else None,\n1151             chunk_size,\n1152         )\n1153         if not chunked_fetch or not self.connection.features.can_use_chunked_reads:\n1154             try:\n1155                 # If we are using non-chunked reads, we return the same data\n1156                 # structure as normally, but ensure it is all read into memory\n1157                 # before going any further. Use chunked_fetch if requested,\n1158                 # unless the database doesn't support it.\n1159                 return list(result)\n1160             finally:\n1161                 # done with the cursor\n1162                 cursor.close()\n1163         return result\n1164 \n1165     def as_subquery_condition(self, alias, columns, compiler):\n1166         qn = compiler.quote_name_unless_alias\n1167         qn2 = self.connection.ops.quote_name\n1168 \n1169         for index, select_col in enumerate(self.query.select):\n1170             lhs_sql, lhs_params = self.compile(select_col)\n1171             rhs = '%s.%s' % (qn(alias), qn2(columns[index]))\n1172             self.query.where.add(\n1173                 RawSQL('%s = %s' % (lhs_sql, rhs), lhs_params), 'AND')\n1174 \n1175         sql, params = self.as_sql()\n1176         return 'EXISTS (%s)' % sql, params\n1177 \n1178     def explain_query(self):\n1179         result = list(self.execute_sql())\n1180         # Some backends return 1 item tuples with strings, and others return\n1181         # tuples with integers and strings. Flatten them out into strings.\n1182         for row in result[0]:\n1183             if not isinstance(row, str):\n1184                 yield ' '.join(str(c) for c in row)\n1185             else:\n1186                 yield row\n",
        "intended_behavior": "This class provides additional context to the issue."
    },
    {
        "rel_file_path": "django/db/models/expressions.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/django__django/setup_django__django__3.1/django/db/models/expressions.py",
        "start": 1,
        "end": 1320,
        "class_name": null,
        "method_name": null,
        "code": "1 import copy\n2 import datetime\n3 import inspect\n4 from decimal import Decimal\n5 \n6 from django.core.exceptions import EmptyResultSet, FieldError\n7 from django.db import connection\n8 from django.db.models import fields\n9 from django.db.models.query_utils import Q\n10 from django.db.utils import NotSupportedError\n11 from django.utils.deconstruct import deconstructible\n12 from django.utils.functional import cached_property\n13 from django.utils.hashable import make_hashable\n14 \n15 \n16 class SQLiteNumericMixin:\n17     \"\"\"\n18     Some expressions with output_field=DecimalField() must be cast to\n19     numeric to be properly filtered.\n20     \"\"\"\n21     def as_sqlite(self, compiler, connection, **extra_context):\n22         sql, params = self.as_sql(compiler, connection, **extra_context)\n23         try:\n24             if self.output_field.get_internal_type() == 'DecimalField':\n25                 sql = 'CAST(%s AS NUMERIC)' % sql\n26         except FieldError:\n27             pass\n28         return sql, params\n29 \n30 \n31 class Combinable:\n32     \"\"\"\n33     Provide the ability to combine one or two objects with\n34     some connector. For example F('foo') + F('bar').\n35     \"\"\"\n36 \n37     # Arithmetic connectors\n38     ADD = '+'\n39     SUB = '-'\n40     MUL = '*'\n41     DIV = '/'\n42     POW = '^'\n43     # The following is a quoted % operator - it is quoted because it can be\n44     # used in strings that also have parameter substitution.\n45     MOD = '%%'\n46 \n47     # Bitwise operators - note that these are generated by .bitand()\n48     # and .bitor(), the '&' and '|' are reserved for boolean operator\n49     # usage.\n50     BITAND = '&'\n51     BITOR = '|'\n52     BITLEFTSHIFT = '<<'\n53     BITRIGHTSHIFT = '>>'\n54 \n55     def _combine(self, other, connector, reversed):\n56         if not hasattr(other, 'resolve_expression'):\n57             # everything must be resolvable to an expression\n58             if isinstance(other, datetime.timedelta):\n59                 other = DurationValue(other, output_field=fields.DurationField())\n60             else:\n61                 other = Value(other)\n62 \n63         if reversed:\n64             return CombinedExpression(other, connector, self)\n65         return CombinedExpression(self, connector, other)\n66 \n67     #############\n68     # OPERATORS #\n69     #############\n70 \n71     def __neg__(self):\n72         return self._combine(-1, self.MUL, False)\n73 \n74     def __add__(self, other):\n75         return self._combine(other, self.ADD, False)\n76 \n77     def __sub__(self, other):\n78         return self._combine(other, self.SUB, False)\n79 \n80     def __mul__(self, other):\n81         return self._combine(other, self.MUL, False)\n82 \n83     def __truediv__(self, other):\n84         return self._combine(other, self.DIV, False)\n85 \n86     def __mod__(self, other):\n87         return self._combine(other, self.MOD, False)\n88 \n89     def __pow__(self, other):\n90         return self._combine(other, self.POW, False)\n91 \n92     def __and__(self, other):\n93         if getattr(self, 'conditional', False) and getattr(other, 'conditional', False):\n94             return Q(self) & Q(other)\n95         raise NotImplementedError(\n96             \"Use .bitand() and .bitor() for bitwise logical operations.\"\n97         )\n98 \n99     def bitand(self, other):\n100         return self._combine(other, self.BITAND, False)\n101 \n102     def bitleftshift(self, other):\n103         return self._combine(other, self.BITLEFTSHIFT, False)\n104 \n105     def bitrightshift(self, other):\n106         return self._combine(other, self.BITRIGHTSHIFT, False)\n107 \n108     def __or__(self, other):\n109         if getattr(self, 'conditional', False) and getattr(other, 'conditional', False):\n110             return Q(self) | Q(other)\n111         raise NotImplementedError(\n112             \"Use .bitand() and .bitor() for bitwise logical operations.\"\n113         )\n114 \n115     def bitor(self, other):\n116         return self._combine(other, self.BITOR, False)\n117 \n118     def __radd__(self, other):\n119         return self._combine(other, self.ADD, True)\n120 \n121     def __rsub__(self, other):\n122         return self._combine(other, self.SUB, True)\n123 \n124     def __rmul__(self, other):\n125         return self._combine(other, self.MUL, True)\n126 \n127     def __rtruediv__(self, other):\n128         return self._combine(other, self.DIV, True)\n129 \n130     def __rmod__(self, other):\n131         return self._combine(other, self.MOD, True)\n132 \n133     def __rpow__(self, other):\n134         return self._combine(other, self.POW, True)\n135 \n136     def __rand__(self, other):\n137         raise NotImplementedError(\n138             \"Use .bitand() and .bitor() for bitwise logical operations.\"\n139         )\n140 \n141     def __ror__(self, other):\n142         raise NotImplementedError(\n143             \"Use .bitand() and .bitor() for bitwise logical operations.\"\n144         )\n145 \n146 \n147 @deconstructible\n148 class BaseExpression:\n149     \"\"\"Base class for all query expressions.\"\"\"\n150 \n151     # aggregate specific fields\n152     is_summary = False\n153     _output_field_resolved_to_none = False\n154     # Can the expression be used in a WHERE clause?\n155     filterable = True\n156     # Can the expression can be used as a source expression in Window?\n157     window_compatible = False\n158 \n159     def __init__(self, output_field=None):\n160         if output_field is not None:\n161             self.output_field = output_field\n162 \n163     def __getstate__(self):\n164         state = self.__dict__.copy()\n165         state.pop('convert_value', None)\n166         return state\n167 \n168     def get_db_converters(self, connection):\n169         return (\n170             []\n171             if self.convert_value is self._convert_value_noop else\n172             [self.convert_value]\n173         ) + self.output_field.get_db_converters(connection)\n174 \n175     def get_source_expressions(self):\n176         return []\n177 \n178     def set_source_expressions(self, exprs):\n179         assert not exprs\n180 \n181     def _parse_expressions(self, *expressions):\n182         return [\n183             arg if hasattr(arg, 'resolve_expression') else (\n184                 F(arg) if isinstance(arg, str) else Value(arg)\n185             ) for arg in expressions\n186         ]\n187 \n188     def as_sql(self, compiler, connection):\n189         \"\"\"\n190         Responsible for returning a (sql, [params]) tuple to be included\n191         in the current query.\n192 \n193         Different backends can provide their own implementation, by\n194         providing an `as_{vendor}` method and patching the Expression:\n195 \n196         ```\n197         def override_as_sql(self, compiler, connection):\n198             # custom logic\n199             return super().as_sql(compiler, connection)\n200         setattr(Expression, 'as_' + connection.vendor, override_as_sql)\n201         ```\n202 \n203         Arguments:\n204          * compiler: the query compiler responsible for generating the query.\n205            Must have a compile method, returning a (sql, [params]) tuple.\n206            Calling compiler(value) will return a quoted `value`.\n207 \n208          * connection: the database connection used for the current query.\n209 \n210         Return: (sql, params)\n211           Where `sql` is a string containing ordered sql parameters to be\n212           replaced with the elements of the list `params`.\n213         \"\"\"\n214         raise NotImplementedError(\"Subclasses must implement as_sql()\")\n215 \n216     @cached_property\n217     def contains_aggregate(self):\n218         return any(expr and expr.contains_aggregate for expr in self.get_source_expressions())\n219 \n220     @cached_property\n221     def contains_over_clause(self):\n222         return any(expr and expr.contains_over_clause for expr in self.get_source_expressions())\n223 \n224     @cached_property\n225     def contains_column_references(self):\n226         return any(expr and expr.contains_column_references for expr in self.get_source_expressions())\n227 \n228     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n229         \"\"\"\n230         Provide the chance to do any preprocessing or validation before being\n231         added to the query.\n232 \n233         Arguments:\n234          * query: the backend query implementation\n235          * allow_joins: boolean allowing or denying use of joins\n236            in this query\n237          * reuse: a set of reusable joins for multijoins\n238          * summarize: a terminal aggregate clause\n239          * for_save: whether this expression about to be used in a save or update\n240 \n241         Return: an Expression to be added to the query.\n242         \"\"\"\n243         c = self.copy()\n244         c.is_summary = summarize\n245         c.set_source_expressions([\n246             expr.resolve_expression(query, allow_joins, reuse, summarize)\n247             if expr else None\n248             for expr in c.get_source_expressions()\n249         ])\n250         return c\n251 \n252     @property\n253     def conditional(self):\n254         return isinstance(self.output_field, fields.BooleanField)\n255 \n256     @property\n257     def field(self):\n258         return self.output_field\n259 \n260     @cached_property\n261     def output_field(self):\n262         \"\"\"Return the output type of this expressions.\"\"\"\n263         output_field = self._resolve_output_field()\n264         if output_field is None:\n265             self._output_field_resolved_to_none = True\n266             raise FieldError('Cannot resolve expression type, unknown output_field')\n267         return output_field\n268 \n269     @cached_property\n270     def _output_field_or_none(self):\n271         \"\"\"\n272         Return the output field of this expression, or None if\n273         _resolve_output_field() didn't return an output type.\n274         \"\"\"\n275         try:\n276             return self.output_field\n277         except FieldError:\n278             if not self._output_field_resolved_to_none:\n279                 raise\n280 \n281     def _resolve_output_field(self):\n282         \"\"\"\n283         Attempt to infer the output type of the expression. If the output\n284         fields of all source fields match then, simply infer the same type\n285         here. This isn't always correct, but it makes sense most of the time.\n286 \n287         Consider the difference between `2 + 2` and `2 / 3`. Inferring\n288         the type here is a convenience for the common case. The user should\n289         supply their own output_field with more complex computations.\n290 \n291         If a source's output field resolves to None, exclude it from this check.\n292         If all sources are None, then an error is raised higher up the stack in\n293         the output_field property.\n294         \"\"\"\n295         sources_iter = (source for source in self.get_source_fields() if source is not None)\n296         for output_field in sources_iter:\n297             for source in sources_iter:\n298                 if not isinstance(output_field, source.__class__):\n299                     raise FieldError(\n300                         'Expression contains mixed types: %s, %s. You must '\n301                         'set output_field.' % (\n302                             output_field.__class__.__name__,\n303                             source.__class__.__name__,\n304                         )\n305                     )\n306             return output_field\n307 \n308     @staticmethod\n309     def _convert_value_noop(value, expression, connection):\n310         return value\n311 \n312     @cached_property\n313     def convert_value(self):\n314         \"\"\"\n315         Expressions provide their own converters because users have the option\n316         of manually specifying the output_field which may be a different type\n317         from the one the database returns.\n318         \"\"\"\n319         field = self.output_field\n320         internal_type = field.get_internal_type()\n321         if internal_type == 'FloatField':\n322             return lambda value, expression, connection: None if value is None else float(value)\n323         elif internal_type.endswith('IntegerField'):\n324             return lambda value, expression, connection: None if value is None else int(value)\n325         elif internal_type == 'DecimalField':\n326             return lambda value, expression, connection: None if value is None else Decimal(value)\n327         return self._convert_value_noop\n328 \n329     def get_lookup(self, lookup):\n330         return self.output_field.get_lookup(lookup)\n331 \n332     def get_transform(self, name):\n333         return self.output_field.get_transform(name)\n334 \n335     def relabeled_clone(self, change_map):\n336         clone = self.copy()\n337         clone.set_source_expressions([\n338             e.relabeled_clone(change_map) if e is not None else None\n339             for e in self.get_source_expressions()\n340         ])\n341         return clone\n342 \n343     def copy(self):\n344         return copy.copy(self)\n345 \n346     def get_group_by_cols(self, alias=None):\n347         if not self.contains_aggregate:\n348             return [self]\n349         cols = []\n350         for source in self.get_source_expressions():\n351             cols.extend(source.get_group_by_cols())\n352         return cols\n353 \n354     def get_source_fields(self):\n355         \"\"\"Return the underlying field types used by this aggregate.\"\"\"\n356         return [e._output_field_or_none for e in self.get_source_expressions()]\n357 \n358     def asc(self, **kwargs):\n359         return OrderBy(self, **kwargs)\n360 \n361     def desc(self, **kwargs):\n362         return OrderBy(self, descending=True, **kwargs)\n363 \n364     def reverse_ordering(self):\n365         return self\n366 \n367     def flatten(self):\n368         \"\"\"\n369         Recursively yield this expression and all subexpressions, in\n370         depth-first order.\n371         \"\"\"\n372         yield self\n373         for expr in self.get_source_expressions():\n374             if expr:\n375                 yield from expr.flatten()\n376 \n377     def select_format(self, compiler, sql, params):\n378         \"\"\"\n379         Custom format for select clauses. For example, EXISTS expressions need\n380         to be wrapped in CASE WHEN on Oracle.\n381         \"\"\"\n382         return self.output_field.select_format(compiler, sql, params)\n383 \n384     @cached_property\n385     def identity(self):\n386         constructor_signature = inspect.signature(self.__init__)\n387         args, kwargs = self._constructor_args\n388         signature = constructor_signature.bind_partial(*args, **kwargs)\n389         signature.apply_defaults()\n390         arguments = signature.arguments.items()\n391         identity = [self.__class__]\n392         for arg, value in arguments:\n393             if isinstance(value, fields.Field):\n394                 if value.name and value.model:\n395                     value = (value.model._meta.label, value.name)\n396                 else:\n397                     value = type(value)\n398             else:\n399                 value = make_hashable(value)\n400             identity.append((arg, value))\n401         return tuple(identity)\n402 \n403     def __eq__(self, other):\n404         if not isinstance(other, BaseExpression):\n405             return NotImplemented\n406         return other.identity == self.identity\n407 \n408     def __hash__(self):\n409         return hash(self.identity)\n410 \n411 \n412 class Expression(BaseExpression, Combinable):\n413     \"\"\"An expression that can be combined with other expressions.\"\"\"\n414     pass\n415 \n416 \n417 class CombinedExpression(SQLiteNumericMixin, Expression):\n418 \n419     def __init__(self, lhs, connector, rhs, output_field=None):\n420         super().__init__(output_field=output_field)\n421         self.connector = connector\n422         self.lhs = lhs\n423         self.rhs = rhs\n424 \n425     def __repr__(self):\n426         return \"<{}: {}>\".format(self.__class__.__name__, self)\n427 \n428     def __str__(self):\n429         return \"{} {} {}\".format(self.lhs, self.connector, self.rhs)\n430 \n431     def get_source_expressions(self):\n432         return [self.lhs, self.rhs]\n433 \n434     def set_source_expressions(self, exprs):\n435         self.lhs, self.rhs = exprs\n436 \n437     def as_sql(self, compiler, connection):\n438         try:\n439             lhs_output = self.lhs.output_field\n440         except FieldError:\n441             lhs_output = None\n442         try:\n443             rhs_output = self.rhs.output_field\n444         except FieldError:\n445             rhs_output = None\n446         if (not connection.features.has_native_duration_field and\n447                 ((lhs_output and lhs_output.get_internal_type() == 'DurationField') or\n448                  (rhs_output and rhs_output.get_internal_type() == 'DurationField'))):\n449             return DurationExpression(self.lhs, self.connector, self.rhs).as_sql(compiler, connection)\n450         if (lhs_output and rhs_output and self.connector == self.SUB and\n451             lhs_output.get_internal_type() in {'DateField', 'DateTimeField', 'TimeField'} and\n452                 lhs_output.get_internal_type() == rhs_output.get_internal_type()):\n453             return TemporalSubtraction(self.lhs, self.rhs).as_sql(compiler, connection)\n454         expressions = []\n455         expression_params = []\n456         sql, params = compiler.compile(self.lhs)\n457         expressions.append(sql)\n458         expression_params.extend(params)\n459         sql, params = compiler.compile(self.rhs)\n460         expressions.append(sql)\n461         expression_params.extend(params)\n462         # order of precedence\n463         expression_wrapper = '(%s)'\n464         sql = connection.ops.combine_expression(self.connector, expressions)\n465         return expression_wrapper % sql, expression_params\n466 \n467     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n468         c = self.copy()\n469         c.is_summary = summarize\n470         c.lhs = c.lhs.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n471         c.rhs = c.rhs.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n472         return c\n473 \n474 \n475 class DurationExpression(CombinedExpression):\n476     def compile(self, side, compiler, connection):\n477         if not isinstance(side, DurationValue):\n478             try:\n479                 output = side.output_field\n480             except FieldError:\n481                 pass\n482             else:\n483                 if output.get_internal_type() == 'DurationField':\n484                     sql, params = compiler.compile(side)\n485                     return connection.ops.format_for_duration_arithmetic(sql), params\n486         return compiler.compile(side)\n487 \n488     def as_sql(self, compiler, connection):\n489         connection.ops.check_expression_support(self)\n490         expressions = []\n491         expression_params = []\n492         sql, params = self.compile(self.lhs, compiler, connection)\n493         expressions.append(sql)\n494         expression_params.extend(params)\n495         sql, params = self.compile(self.rhs, compiler, connection)\n496         expressions.append(sql)\n497         expression_params.extend(params)\n498         # order of precedence\n499         expression_wrapper = '(%s)'\n500         sql = connection.ops.combine_duration_expression(self.connector, expressions)\n501         return expression_wrapper % sql, expression_params\n502 \n503 \n504 class TemporalSubtraction(CombinedExpression):\n505     output_field = fields.DurationField()\n506 \n507     def __init__(self, lhs, rhs):\n508         super().__init__(lhs, self.SUB, rhs)\n509 \n510     def as_sql(self, compiler, connection):\n511         connection.ops.check_expression_support(self)\n512         lhs = compiler.compile(self.lhs)\n513         rhs = compiler.compile(self.rhs)\n514         return connection.ops.subtract_temporals(self.lhs.output_field.get_internal_type(), lhs, rhs)\n515 \n516 \n517 @deconstructible\n518 class F(Combinable):\n519     \"\"\"An object capable of resolving references to existing query objects.\"\"\"\n520 \n521     def __init__(self, name):\n522         \"\"\"\n523         Arguments:\n524          * name: the name of the field this expression references\n525         \"\"\"\n526         self.name = name\n527 \n528     def __repr__(self):\n529         return \"{}({})\".format(self.__class__.__name__, self.name)\n530 \n531     def resolve_expression(self, query=None, allow_joins=True, reuse=None,\n532                            summarize=False, for_save=False):\n533         return query.resolve_ref(self.name, allow_joins, reuse, summarize)\n534 \n535     def asc(self, **kwargs):\n536         return OrderBy(self, **kwargs)\n537 \n538     def desc(self, **kwargs):\n539         return OrderBy(self, descending=True, **kwargs)\n540 \n541     def __eq__(self, other):\n542         return self.__class__ == other.__class__ and self.name == other.name\n543 \n544     def __hash__(self):\n545         return hash(self.name)\n546 \n547 \n548 class ResolvedOuterRef(F):\n549     \"\"\"\n550     An object that contains a reference to an outer query.\n551 \n552     In this case, the reference to the outer query has been resolved because\n553     the inner query has been used as a subquery.\n554     \"\"\"\n555     contains_aggregate = False\n556 \n557     def as_sql(self, *args, **kwargs):\n558         raise ValueError(\n559             'This queryset contains a reference to an outer query and may '\n560             'only be used in a subquery.'\n561         )\n562 \n563     def relabeled_clone(self, relabels):\n564         return self\n565 \n566 \n567 class OuterRef(F):\n568     def resolve_expression(self, *args, **kwargs):\n569         if isinstance(self.name, self.__class__):\n570             return self.name\n571         return ResolvedOuterRef(self.name)\n572 \n573 \n574 class Func(SQLiteNumericMixin, Expression):\n575     \"\"\"An SQL function call.\"\"\"\n576     function = None\n577     template = '%(function)s(%(expressions)s)'\n578     arg_joiner = ', '\n579     arity = None  # The number of arguments the function accepts.\n580 \n581     def __init__(self, *expressions, output_field=None, **extra):\n582         if self.arity is not None and len(expressions) != self.arity:\n583             raise TypeError(\n584                 \"'%s' takes exactly %s %s (%s given)\" % (\n585                     self.__class__.__name__,\n586                     self.arity,\n587                     \"argument\" if self.arity == 1 else \"arguments\",\n588                     len(expressions),\n589                 )\n590             )\n591         super().__init__(output_field=output_field)\n592         self.source_expressions = self._parse_expressions(*expressions)\n593         self.extra = extra\n594 \n595     def __repr__(self):\n596         args = self.arg_joiner.join(str(arg) for arg in self.source_expressions)\n597         extra = {**self.extra, **self._get_repr_options()}\n598         if extra:\n599             extra = ', '.join(str(key) + '=' + str(val) for key, val in sorted(extra.items()))\n600             return \"{}({}, {})\".format(self.__class__.__name__, args, extra)\n601         return \"{}({})\".format(self.__class__.__name__, args)\n602 \n603     def _get_repr_options(self):\n604         \"\"\"Return a dict of extra __init__() options to include in the repr.\"\"\"\n605         return {}\n606 \n607     def get_source_expressions(self):\n608         return self.source_expressions\n609 \n610     def set_source_expressions(self, exprs):\n611         self.source_expressions = exprs\n612 \n613     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n614         c = self.copy()\n615         c.is_summary = summarize\n616         for pos, arg in enumerate(c.source_expressions):\n617             c.source_expressions[pos] = arg.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n618         return c\n619 \n620     def as_sql(self, compiler, connection, function=None, template=None, arg_joiner=None, **extra_context):\n621         connection.ops.check_expression_support(self)\n622         sql_parts = []\n623         params = []\n624         for arg in self.source_expressions:\n625             arg_sql, arg_params = compiler.compile(arg)\n626             sql_parts.append(arg_sql)\n627             params.extend(arg_params)\n628         data = {**self.extra, **extra_context}\n629         # Use the first supplied value in this order: the parameter to this\n630         # method, a value supplied in __init__()'s **extra (the value in\n631         # `data`), or the value defined on the class.\n632         if function is not None:\n633             data['function'] = function\n634         else:\n635             data.setdefault('function', self.function)\n636         template = template or data.get('template', self.template)\n637         arg_joiner = arg_joiner or data.get('arg_joiner', self.arg_joiner)\n638         data['expressions'] = data['field'] = arg_joiner.join(sql_parts)\n639         return template % data, params\n640 \n641     def copy(self):\n642         copy = super().copy()\n643         copy.source_expressions = self.source_expressions[:]\n644         copy.extra = self.extra.copy()\n645         return copy\n646 \n647 \n648 class Value(Expression):\n649     \"\"\"Represent a wrapped value as a node within an expression.\"\"\"\n650     def __init__(self, value, output_field=None):\n651         \"\"\"\n652         Arguments:\n653          * value: the value this expression represents. The value will be\n654            added into the sql parameter list and properly quoted.\n655 \n656          * output_field: an instance of the model field type that this\n657            expression will return, such as IntegerField() or CharField().\n658         \"\"\"\n659         super().__init__(output_field=output_field)\n660         self.value = value\n661 \n662     def __repr__(self):\n663         return \"{}({})\".format(self.__class__.__name__, self.value)\n664 \n665     def as_sql(self, compiler, connection):\n666         connection.ops.check_expression_support(self)\n667         val = self.value\n668         output_field = self._output_field_or_none\n669         if output_field is not None:\n670             if self.for_save:\n671                 val = output_field.get_db_prep_save(val, connection=connection)\n672             else:\n673                 val = output_field.get_db_prep_value(val, connection=connection)\n674             if hasattr(output_field, 'get_placeholder'):\n675                 return output_field.get_placeholder(val, compiler, connection), [val]\n676         if val is None:\n677             # cx_Oracle does not always convert None to the appropriate\n678             # NULL type (like in case expressions using numbers), so we\n679             # use a literal SQL NULL\n680             return 'NULL', []\n681         return '%s', [val]\n682 \n683     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n684         c = super().resolve_expression(query, allow_joins, reuse, summarize, for_save)\n685         c.for_save = for_save\n686         return c\n687 \n688     def get_group_by_cols(self, alias=None):\n689         return []\n690 \n691 \n692 class DurationValue(Value):\n693     def as_sql(self, compiler, connection):\n694         connection.ops.check_expression_support(self)\n695         if connection.features.has_native_duration_field:\n696             return super().as_sql(compiler, connection)\n697         return connection.ops.date_interval_sql(self.value), []\n698 \n699 \n700 class RawSQL(Expression):\n701     def __init__(self, sql, params, output_field=None):\n702         if output_field is None:\n703             output_field = fields.Field()\n704         self.sql, self.params = sql, params\n705         super().__init__(output_field=output_field)\n706 \n707     def __repr__(self):\n708         return \"{}({}, {})\".format(self.__class__.__name__, self.sql, self.params)\n709 \n710     def as_sql(self, compiler, connection):\n711         return '(%s)' % self.sql, self.params\n712 \n713     def get_group_by_cols(self, alias=None):\n714         return [self]\n715 \n716     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n717         # Resolve parents fields used in raw SQL.\n718         for parent in query.model._meta.get_parent_list():\n719             for parent_field in parent._meta.local_fields:\n720                 _, column_name = parent_field.get_attname_column()\n721                 if column_name.lower() in self.sql.lower():\n722                     query.resolve_ref(parent_field.name, allow_joins, reuse, summarize)\n723                     break\n724         return super().resolve_expression(query, allow_joins, reuse, summarize, for_save)\n725 \n726 \n727 class Star(Expression):\n728     def __repr__(self):\n729         return \"'*'\"\n730 \n731     def as_sql(self, compiler, connection):\n732         return '*', []\n733 \n734 \n735 class Random(Expression):\n736     output_field = fields.FloatField()\n737 \n738     def __repr__(self):\n739         return \"Random()\"\n740 \n741     def as_sql(self, compiler, connection):\n742         return connection.ops.random_function_sql(), []\n743 \n744 \n745 class Col(Expression):\n746 \n747     contains_column_references = True\n748 \n749     def __init__(self, alias, target, output_field=None):\n750         if output_field is None:\n751             output_field = target\n752         super().__init__(output_field=output_field)\n753         self.alias, self.target = alias, target\n754 \n755     def __repr__(self):\n756         alias, target = self.alias, self.target\n757         identifiers = (alias, str(target)) if alias else (str(target),)\n758         return '{}({})'.format(self.__class__.__name__, ', '.join(identifiers))\n759 \n760     def as_sql(self, compiler, connection):\n761         alias, column = self.alias, self.target.column\n762         identifiers = (alias, column) if alias else (column,)\n763         sql = '.'.join(map(compiler.quote_name_unless_alias, identifiers))\n764         return sql, []\n765 \n766     def relabeled_clone(self, relabels):\n767         if self.alias is None:\n768             return self\n769         return self.__class__(relabels.get(self.alias, self.alias), self.target, self.output_field)\n770 \n771     def get_group_by_cols(self, alias=None):\n772         return [self]\n773 \n774     def get_db_converters(self, connection):\n775         if self.target == self.output_field:\n776             return self.output_field.get_db_converters(connection)\n777         return (self.output_field.get_db_converters(connection) +\n778                 self.target.get_db_converters(connection))\n779 \n780 \n781 class Ref(Expression):\n782     \"\"\"\n783     Reference to column alias of the query. For example, Ref('sum_cost') in\n784     qs.annotate(sum_cost=Sum('cost')) query.\n785     \"\"\"\n786     def __init__(self, refs, source):\n787         super().__init__()\n788         self.refs, self.source = refs, source\n789 \n790     def __repr__(self):\n791         return \"{}({}, {})\".format(self.__class__.__name__, self.refs, self.source)\n792 \n793     def get_source_expressions(self):\n794         return [self.source]\n795 \n796     def set_source_expressions(self, exprs):\n797         self.source, = exprs\n798 \n799     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n800         # The sub-expression `source` has already been resolved, as this is\n801         # just a reference to the name of `source`.\n802         return self\n803 \n804     def relabeled_clone(self, relabels):\n805         return self\n806 \n807     def as_sql(self, compiler, connection):\n808         return connection.ops.quote_name(self.refs), []\n809 \n810     def get_group_by_cols(self, alias=None):\n811         return [self]\n812 \n813 \n814 class ExpressionList(Func):\n815     \"\"\"\n816     An expression containing multiple expressions. Can be used to provide a\n817     list of expressions as an argument to another expression, like an\n818     ordering clause.\n819     \"\"\"\n820     template = '%(expressions)s'\n821 \n822     def __init__(self, *expressions, **extra):\n823         if not expressions:\n824             raise ValueError('%s requires at least one expression.' % self.__class__.__name__)\n825         super().__init__(*expressions, **extra)\n826 \n827     def __str__(self):\n828         return self.arg_joiner.join(str(arg) for arg in self.source_expressions)\n829 \n830 \n831 class ExpressionWrapper(Expression):\n832     \"\"\"\n833     An expression that can wrap another expression so that it can provide\n834     extra context to the inner expression, such as the output_field.\n835     \"\"\"\n836 \n837     def __init__(self, expression, output_field):\n838         super().__init__(output_field=output_field)\n839         self.expression = expression\n840 \n841     def set_source_expressions(self, exprs):\n842         self.expression = exprs[0]\n843 \n844     def get_source_expressions(self):\n845         return [self.expression]\n846 \n847     def as_sql(self, compiler, connection):\n848         return self.expression.as_sql(compiler, connection)\n849 \n850     def __repr__(self):\n851         return \"{}({})\".format(self.__class__.__name__, self.expression)\n852 \n853 \n854 class When(Expression):\n855     template = 'WHEN %(condition)s THEN %(result)s'\n856     # This isn't a complete conditional expression, must be used in Case().\n857     conditional = False\n858 \n859     def __init__(self, condition=None, then=None, **lookups):\n860         if lookups and condition is None:\n861             condition, lookups = Q(**lookups), None\n862         if condition is None or not getattr(condition, 'conditional', False) or lookups:\n863             raise TypeError(\n864                 'When() supports a Q object, a boolean expression, or lookups '\n865                 'as a condition.'\n866             )\n867         if isinstance(condition, Q) and not condition:\n868             raise ValueError(\"An empty Q() can't be used as a When() condition.\")\n869         super().__init__(output_field=None)\n870         self.condition = condition\n871         self.result = self._parse_expressions(then)[0]\n872 \n873     def __str__(self):\n874         return \"WHEN %r THEN %r\" % (self.condition, self.result)\n875 \n876     def __repr__(self):\n877         return \"<%s: %s>\" % (self.__class__.__name__, self)\n878 \n879     def get_source_expressions(self):\n880         return [self.condition, self.result]\n881 \n882     def set_source_expressions(self, exprs):\n883         self.condition, self.result = exprs\n884 \n885     def get_source_fields(self):\n886         # We're only interested in the fields of the result expressions.\n887         return [self.result._output_field_or_none]\n888 \n889     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n890         c = self.copy()\n891         c.is_summary = summarize\n892         if hasattr(c.condition, 'resolve_expression'):\n893             c.condition = c.condition.resolve_expression(query, allow_joins, reuse, summarize, False)\n894         c.result = c.result.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n895         return c\n896 \n897     def as_sql(self, compiler, connection, template=None, **extra_context):\n898         connection.ops.check_expression_support(self)\n899         template_params = extra_context\n900         sql_params = []\n901         condition_sql, condition_params = compiler.compile(self.condition)\n902         template_params['condition'] = condition_sql\n903         sql_params.extend(condition_params)\n904         result_sql, result_params = compiler.compile(self.result)\n905         template_params['result'] = result_sql\n906         sql_params.extend(result_params)\n907         template = template or self.template\n908         return template % template_params, sql_params\n909 \n910     def get_group_by_cols(self, alias=None):\n911         # This is not a complete expression and cannot be used in GROUP BY.\n912         cols = []\n913         for source in self.get_source_expressions():\n914             cols.extend(source.get_group_by_cols())\n915         return cols\n916 \n917 \n918 class Case(Expression):\n919     \"\"\"\n920     An SQL searched CASE expression:\n921 \n922         CASE\n923             WHEN n > 0\n924                 THEN 'positive'\n925             WHEN n < 0\n926                 THEN 'negative'\n927             ELSE 'zero'\n928         END\n929     \"\"\"\n930     template = 'CASE %(cases)s ELSE %(default)s END'\n931     case_joiner = ' '\n932 \n933     def __init__(self, *cases, default=None, output_field=None, **extra):\n934         if not all(isinstance(case, When) for case in cases):\n935             raise TypeError(\"Positional arguments must all be When objects.\")\n936         super().__init__(output_field)\n937         self.cases = list(cases)\n938         self.default = self._parse_expressions(default)[0]\n939         self.extra = extra\n940 \n941     def __str__(self):\n942         return \"CASE %s, ELSE %r\" % (', '.join(str(c) for c in self.cases), self.default)\n943 \n944     def __repr__(self):\n945         return \"<%s: %s>\" % (self.__class__.__name__, self)\n946 \n947     def get_source_expressions(self):\n948         return self.cases + [self.default]\n949 \n950     def set_source_expressions(self, exprs):\n951         *self.cases, self.default = exprs\n952 \n953     def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False):\n954         c = self.copy()\n955         c.is_summary = summarize\n956         for pos, case in enumerate(c.cases):\n957             c.cases[pos] = case.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n958         c.default = c.default.resolve_expression(query, allow_joins, reuse, summarize, for_save)\n959         return c\n960 \n961     def copy(self):\n962         c = super().copy()\n963         c.cases = c.cases[:]\n964         return c\n965 \n966     def as_sql(self, compiler, connection, template=None, case_joiner=None, **extra_context):\n967         connection.ops.check_expression_support(self)\n968         if not self.cases:\n969             return compiler.compile(self.default)\n970         template_params = {**self.extra, **extra_context}\n971         case_parts = []\n972         sql_params = []\n973         for case in self.cases:\n974             try:\n975                 case_sql, case_params = compiler.compile(case)\n976             except EmptyResultSet:\n977                 continue\n978             case_parts.append(case_sql)\n979             sql_params.extend(case_params)\n980         default_sql, default_params = compiler.compile(self.default)\n981         if not case_parts:\n982             return default_sql, default_params\n983         case_joiner = case_joiner or self.case_joiner\n984         template_params['cases'] = case_joiner.join(case_parts)\n985         template_params['default'] = default_sql\n986         sql_params.extend(default_params)\n987         template = template or template_params.get('template', self.template)\n988         sql = template % template_params\n989         if self._output_field_or_none is not None:\n990             sql = connection.ops.unification_cast_sql(self.output_field) % sql\n991         return sql, sql_params\n992 \n993 \n994 class Subquery(Expression):\n995     \"\"\"\n996     An explicit subquery. It may contain OuterRef() references to the outer\n997     query which will be resolved when it is applied to that query.\n998     \"\"\"\n999     template = '(%(subquery)s)'\n1000     contains_aggregate = False\n1001 \n1002     def __init__(self, queryset, output_field=None, **extra):\n1003         self.query = queryset.query\n1004         self.extra = extra\n1005         super().__init__(output_field)\n1006 \n1007     def __getstate__(self):\n1008         state = super().__getstate__()\n1009         state.pop('_constructor_args', None)\n1010         return state\n1011 \n1012     def get_source_expressions(self):\n1013         return [self.query]\n1014 \n1015     def set_source_expressions(self, exprs):\n1016         self.query = exprs[0]\n1017 \n1018     def _resolve_output_field(self):\n1019         return self.query.output_field\n1020 \n1021     def copy(self):\n1022         clone = super().copy()\n1023         clone.query = clone.query.clone()\n1024         return clone\n1025 \n1026     @property\n1027     def external_aliases(self):\n1028         return self.query.external_aliases\n1029 \n1030     def as_sql(self, compiler, connection, template=None, **extra_context):\n1031         connection.ops.check_expression_support(self)\n1032         template_params = {**self.extra, **extra_context}\n1033         subquery_sql, sql_params = self.query.as_sql(compiler, connection)\n1034         template_params['subquery'] = subquery_sql[1:-1]\n1035 \n1036         template = template or template_params.get('template', self.template)\n1037         sql = template % template_params\n1038         return sql, sql_params\n1039 \n1040     def get_group_by_cols(self, alias=None):\n1041         if alias:\n1042             return [Ref(alias, self)]\n1043         return []\n1044 \n1045 \n1046 class Exists(Subquery):\n1047     template = 'EXISTS(%(subquery)s)'\n1048     output_field = fields.BooleanField()\n1049 \n1050     def __init__(self, queryset, negated=False, **kwargs):\n1051         # As a performance optimization, remove ordering since EXISTS doesn't\n1052         # care about it, just whether or not a row matches.\n1053         queryset = queryset.order_by()\n1054         self.negated = negated\n1055         super().__init__(queryset, **kwargs)\n1056 \n1057     def __invert__(self):\n1058         clone = self.copy()\n1059         clone.negated = not self.negated\n1060         return clone\n1061 \n1062     def as_sql(self, compiler, connection, template=None, **extra_context):\n1063         sql, params = super().as_sql(compiler, connection, template, **extra_context)\n1064         if self.negated:\n1065             sql = 'NOT {}'.format(sql)\n1066         return sql, params\n1067 \n1068     def select_format(self, compiler, sql, params):\n1069         # Wrap EXISTS() with a CASE WHEN expression if a database backend\n1070         # (e.g. Oracle) doesn't support boolean expression in the SELECT list.\n1071         if not compiler.connection.features.supports_boolean_expr_in_select_clause:\n1072             sql = 'CASE WHEN {} THEN 1 ELSE 0 END'.format(sql)\n1073         return sql, params\n1074 \n1075 \n1076 class OrderBy(BaseExpression):\n1077     template = '%(expression)s %(ordering)s'\n1078     conditional = False\n1079 \n1080     def __init__(self, expression, descending=False, nulls_first=False, nulls_last=False):\n1081         if nulls_first and nulls_last:\n1082             raise ValueError('nulls_first and nulls_last are mutually exclusive')\n1083         self.nulls_first = nulls_first\n1084         self.nulls_last = nulls_last\n1085         self.descending = descending\n1086         if not hasattr(expression, 'resolve_expression'):\n1087             raise ValueError('expression must be an expression type')\n1088         self.expression = expression\n1089 \n1090     def __repr__(self):\n1091         return \"{}({}, descending={})\".format(\n1092             self.__class__.__name__, self.expression, self.descending)\n1093 \n1094     def set_source_expressions(self, exprs):\n1095         self.expression = exprs[0]\n1096 \n1097     def get_source_expressions(self):\n1098         return [self.expression]\n1099 \n1100     def as_sql(self, compiler, connection, template=None, **extra_context):\n1101         template = template or self.template\n1102         if connection.features.supports_order_by_nulls_modifier:\n1103             if self.nulls_last:\n1104                 template = '%s NULLS LAST' % template\n1105             elif self.nulls_first:\n1106                 template = '%s NULLS FIRST' % template\n1107         else:\n1108             if self.nulls_last:\n1109                 template = '%%(expression)s IS NULL, %s' % template\n1110             elif self.nulls_first:\n1111                 template = '%%(expression)s IS NOT NULL, %s' % template\n1112         connection.ops.check_expression_support(self)\n1113         expression_sql, params = compiler.compile(self.expression)\n1114         placeholders = {\n1115             'expression': expression_sql,\n1116             'ordering': 'DESC' if self.descending else 'ASC',\n1117             **extra_context,\n1118         }\n1119         template = template or self.template\n1120         params *= template.count('%(expression)s')\n1121         return (template % placeholders).rstrip(), params\n1122 \n1123     def as_oracle(self, compiler, connection):\n1124         # Oracle doesn't allow ORDER BY EXISTS() unless it's wrapped in\n1125         # a CASE WHEN.\n1126         if isinstance(self.expression, Exists):\n1127             copy = self.copy()\n1128             copy.expression = Case(\n1129                 When(self.expression, then=True),\n1130                 default=False,\n1131                 output_field=fields.BooleanField(),\n1132             )\n1133             return copy.as_sql(compiler, connection)\n1134         return self.as_sql(compiler, connection)\n1135 \n1136     def get_group_by_cols(self, alias=None):\n1137         cols = []\n1138         for source in self.get_source_expressions():\n1139             cols.extend(source.get_group_by_cols())\n1140         return cols\n1141 \n1142     def reverse_ordering(self):\n1143         self.descending = not self.descending\n1144         if self.nulls_first or self.nulls_last:\n1145             self.nulls_first = not self.nulls_first\n1146             self.nulls_last = not self.nulls_last\n1147         return self\n1148 \n1149     def asc(self):\n1150         self.descending = False\n1151 \n1152     def desc(self):\n1153         self.descending = True\n1154 \n1155 \n1156 class Window(Expression):\n1157     template = '%(expression)s OVER (%(window)s)'\n1158     # Although the main expression may either be an aggregate or an\n1159     # expression with an aggregate function, the GROUP BY that will\n1160     # be introduced in the query as a result is not desired.\n1161     contains_aggregate = False\n1162     contains_over_clause = True\n1163     filterable = False\n1164 \n1165     def __init__(self, expression, partition_by=None, order_by=None, frame=None, output_field=None):\n1166         self.partition_by = partition_by\n1167         self.order_by = order_by\n1168         self.frame = frame\n1169 \n1170         if not getattr(expression, 'window_compatible', False):\n1171             raise ValueError(\n1172                 \"Expression '%s' isn't compatible with OVER clauses.\" %\n1173                 expression.__class__.__name__\n1174             )\n1175 \n1176         if self.partition_by is not None:\n1177             if not isinstance(self.partition_by, (tuple, list)):\n1178                 self.partition_by = (self.partition_by,)\n1179             self.partition_by = ExpressionList(*self.partition_by)\n1180 \n1181         if self.order_by is not None:\n1182             if isinstance(self.order_by, (list, tuple)):\n1183                 self.order_by = ExpressionList(*self.order_by)\n1184             elif not isinstance(self.order_by, BaseExpression):\n1185                 raise ValueError(\n1186                     'order_by must be either an Expression or a sequence of '\n1187                     'expressions.'\n1188                 )\n1189         super().__init__(output_field=output_field)\n1190         self.source_expression = self._parse_expressions(expression)[0]\n1191 \n1192     def _resolve_output_field(self):\n1193         return self.source_expression.output_field\n1194 \n1195     def get_source_expressions(self):\n1196         return [self.source_expression, self.partition_by, self.order_by, self.frame]\n1197 \n1198     def set_source_expressions(self, exprs):\n1199         self.source_expression, self.partition_by, self.order_by, self.frame = exprs\n1200 \n1201     def as_sql(self, compiler, connection, template=None):\n1202         connection.ops.check_expression_support(self)\n1203         if not connection.features.supports_over_clause:\n1204             raise NotSupportedError('This backend does not support window expressions.')\n1205         expr_sql, params = compiler.compile(self.source_expression)\n1206         window_sql, window_params = [], []\n1207 \n1208         if self.partition_by is not None:\n1209             sql_expr, sql_params = self.partition_by.as_sql(\n1210                 compiler=compiler, connection=connection,\n1211                 template='PARTITION BY %(expressions)s',\n1212             )\n1213             window_sql.extend(sql_expr)\n1214             window_params.extend(sql_params)\n1215 \n1216         if self.order_by is not None:\n1217             window_sql.append(' ORDER BY ')\n1218             order_sql, order_params = compiler.compile(self.order_by)\n1219             window_sql.extend(order_sql)\n1220             window_params.extend(order_params)\n1221 \n1222         if self.frame:\n1223             frame_sql, frame_params = compiler.compile(self.frame)\n1224             window_sql.append(' ' + frame_sql)\n1225             window_params.extend(frame_params)\n1226 \n1227         params.extend(window_params)\n1228         template = template or self.template\n1229 \n1230         return template % {\n1231             'expression': expr_sql,\n1232             'window': ''.join(window_sql).strip()\n1233         }, params\n1234 \n1235     def __str__(self):\n1236         return '{} OVER ({}{}{})'.format(\n1237             str(self.source_expression),\n1238             'PARTITION BY ' + str(self.partition_by) if self.partition_by else '',\n1239             'ORDER BY ' + str(self.order_by) if self.order_by else '',\n1240             str(self.frame or ''),\n1241         )\n1242 \n1243     def __repr__(self):\n1244         return '<%s: %s>' % (self.__class__.__name__, self)\n1245 \n1246     def get_group_by_cols(self, alias=None):\n1247         return []\n1248 \n1249 \n1250 class WindowFrame(Expression):\n1251     \"\"\"\n1252     Model the frame clause in window expressions. There are two types of frame\n1253     clauses which are subclasses, however, all processing and validation (by no\n1254     means intended to be complete) is done here. Thus, providing an end for a\n1255     frame is optional (the default is UNBOUNDED FOLLOWING, which is the last\n1256     row in the frame).\n1257     \"\"\"\n1258     template = '%(frame_type)s BETWEEN %(start)s AND %(end)s'\n1259 \n1260     def __init__(self, start=None, end=None):\n1261         self.start = Value(start)\n1262         self.end = Value(end)\n1263 \n1264     def set_source_expressions(self, exprs):\n1265         self.start, self.end = exprs\n1266 \n1267     def get_source_expressions(self):\n1268         return [self.start, self.end]\n1269 \n1270     def as_sql(self, compiler, connection):\n1271         connection.ops.check_expression_support(self)\n1272         start, end = self.window_frame_start_end(connection, self.start.value, self.end.value)\n1273         return self.template % {\n1274             'frame_type': self.frame_type,\n1275             'start': start,\n1276             'end': end,\n1277         }, []\n1278 \n1279     def __repr__(self):\n1280         return '<%s: %s>' % (self.__class__.__name__, self)\n1281 \n1282     def get_group_by_cols(self, alias=None):\n1283         return []\n1284 \n1285     def __str__(self):\n1286         if self.start.value is not None and self.start.value < 0:\n1287             start = '%d %s' % (abs(self.start.value), connection.ops.PRECEDING)\n1288         elif self.start.value is not None and self.start.value == 0:\n1289             start = connection.ops.CURRENT_ROW\n1290         else:\n1291             start = connection.ops.UNBOUNDED_PRECEDING\n1292 \n1293         if self.end.value is not None and self.end.value > 0:\n1294             end = '%d %s' % (self.end.value, connection.ops.FOLLOWING)\n1295         elif self.end.value is not None and self.end.value == 0:\n1296             end = connection.ops.CURRENT_ROW\n1297         else:\n1298             end = connection.ops.UNBOUNDED_FOLLOWING\n1299         return self.template % {\n1300             'frame_type': self.frame_type,\n1301             'start': start,\n1302             'end': end,\n1303         }\n1304 \n1305     def window_frame_start_end(self, connection, start, end):\n1306         raise NotImplementedError('Subclasses must implement window_frame_start_end().')\n1307 \n1308 \n1309 class RowRange(WindowFrame):\n1310     frame_type = 'ROWS'\n1311 \n1312     def window_frame_start_end(self, connection, start, end):\n1313         return connection.ops.window_frame_rows_start_end(start, end)\n1314 \n1315 \n1316 class ValueRange(WindowFrame):\n1317     frame_type = 'RANGE'\n1318 \n1319     def window_frame_start_end(self, connection, start, end):\n1320         return connection.ops.window_frame_range_start_end(start, end)\n",
        "intended_behavior": "Ensure that when `Case` expressions include `Window` functions, they are processed in a way that the window function's result is accessible and usable in a `SELECT` clause without raising `NotSupportedError`."
    }
]