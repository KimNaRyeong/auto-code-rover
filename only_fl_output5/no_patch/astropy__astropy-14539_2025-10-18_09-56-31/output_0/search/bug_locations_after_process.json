[
    {
        "rel_file_path": "astropy/io/fits/fitsrec.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/astropy__astropy/setup_astropy__astropy__5.1/astropy/io/fits/fitsrec.py",
        "start": 282,
        "end": 481,
        "class_name": null,
        "method_name": "from_columns",
        "code": "282     def from_columns(cls, columns, nrows=0, fill=False, character_as_bytes=False):\n283         \"\"\"\n284         Given a `ColDefs` object of unknown origin, initialize a new `FITS_rec`\n285         object.\n286 \n287         .. note::\n288 \n289             This was originally part of the ``new_table`` function in the table\n290             module but was moved into a class method since most of its\n291             functionality always had more to do with initializing a `FITS_rec`\n292             object than anything else, and much of it also overlapped with\n293             ``FITS_rec._scale_back``.\n294 \n295         Parameters\n296         ----------\n297         columns : sequence of `Column` or a `ColDefs`\n298             The columns from which to create the table data.  If these\n299             columns have data arrays attached that data may be used in\n300             initializing the new table.  Otherwise the input columns\n301             will be used as a template for a new table with the requested\n302             number of rows.\n303 \n304         nrows : int\n305             Number of rows in the new table.  If the input columns have data\n306             associated with them, the size of the largest input column is used.\n307             Otherwise the default is 0.\n308 \n309         fill : bool\n310             If `True`, will fill all cells with zeros or blanks.  If\n311             `False`, copy the data from input, undefined cells will still\n312             be filled with zeros/blanks.\n313         \"\"\"\n314         if not isinstance(columns, ColDefs):\n315             columns = ColDefs(columns)\n316 \n317         # read the delayed data\n318         for column in columns:\n319             arr = column.array\n320             if isinstance(arr, Delayed):\n321                 if arr.hdu.data is None:\n322                     column.array = None\n323                 else:\n324                     column.array = _get_recarray_field(arr.hdu.data, arr.field)\n325         # Reset columns._arrays (which we may want to just do away with\n326         # altogether\n327         del columns._arrays\n328 \n329         # use the largest column shape as the shape of the record\n330         if nrows == 0:\n331             for arr in columns._arrays:\n332                 if arr is not None:\n333                     dim = arr.shape[0]\n334                 else:\n335                     dim = 0\n336                 if dim > nrows:\n337                     nrows = dim\n338 \n339         raw_data = np.empty(columns.dtype.itemsize * nrows, dtype=np.uint8)\n340         raw_data.fill(ord(columns._padding_byte))\n341         data = np.recarray(nrows, dtype=columns.dtype, buf=raw_data).view(cls)\n342         data._character_as_bytes = character_as_bytes\n343 \n344         # Previously this assignment was made from hdu.columns, but that's a\n345         # bug since if a _TableBaseHDU has a FITS_rec in its .data attribute\n346         # the _TableBaseHDU.columns property is actually returned from\n347         # .data._coldefs, so this assignment was circular!  Don't make that\n348         # mistake again.\n349         # All of this is an artifact of the fragility of the FITS_rec class,\n350         # and that it can't just be initialized by columns...\n351         data._coldefs = columns\n352 \n353         # If fill is True we don't copy anything from the column arrays.  We're\n354         # just using them as a template, and returning a table filled with\n355         # zeros/blanks\n356         if fill:\n357             return data\n358 \n359         # Otherwise we have to fill the recarray with data from the input\n360         # columns\n361         for idx, column in enumerate(columns):\n362             # For each column in the ColDef object, determine the number of\n363             # rows in that column.  This will be either the number of rows in\n364             # the ndarray associated with the column, or the number of rows\n365             # given in the call to this function, which ever is smaller.  If\n366             # the input FILL argument is true, the number of rows is set to\n367             # zero so that no data is copied from the original input data.\n368             arr = column.array\n369 \n370             if arr is None:\n371                 array_size = 0\n372             else:\n373                 array_size = len(arr)\n374 \n375             n = min(array_size, nrows)\n376 \n377             # TODO: At least *some* of this logic is mostly redundant with the\n378             # _convert_foo methods in this class; see if we can eliminate some\n379             # of that duplication.\n380 \n381             if not n:\n382                 # The input column had an empty array, so just use the fill\n383                 # value\n384                 continue\n385 \n386             field = _get_recarray_field(data, idx)\n387             name = column.name\n388             fitsformat = column.format\n389             recformat = fitsformat.recformat\n390 \n391             outarr = field[:n]\n392             inarr = arr[:n]\n393 \n394             if isinstance(recformat, _FormatX):\n395                 # Data is a bit array\n396                 if inarr.shape[-1] == recformat.repeat:\n397                     _wrapx(inarr, outarr, recformat.repeat)\n398                     continue\n399             elif isinstance(recformat, _FormatP):\n400                 data._cache_field(name, _makep(inarr, field, recformat, nrows=nrows))\n401                 continue\n402             # TODO: Find a better way of determining that the column is meant\n403             # to be FITS L formatted\n404             elif recformat[-2:] == FITS2NUMPY[\"L\"] and inarr.dtype == bool:\n405                 # column is boolean\n406                 # The raw data field should be filled with either 'T' or 'F'\n407                 # (not 0).  Use 'F' as a default\n408                 field[:] = ord(\"F\")\n409                 # Also save the original boolean array in data._converted so\n410                 # that it doesn't have to be re-converted\n411                 converted = np.zeros(field.shape, dtype=bool)\n412                 converted[:n] = inarr\n413                 data._cache_field(name, converted)\n414                 # TODO: Maybe this step isn't necessary at all if _scale_back\n415                 # will handle it?\n416                 inarr = np.where(inarr == np.False_, ord(\"F\"), ord(\"T\"))\n417             elif columns[idx]._physical_values and columns[idx]._pseudo_unsigned_ints:\n418                 # Temporary hack...\n419                 bzero = column.bzero\n420                 converted = np.zeros(field.shape, dtype=inarr.dtype)\n421                 converted[:n] = inarr\n422                 data._cache_field(name, converted)\n423                 if n < nrows:\n424                     # Pre-scale rows below the input data\n425                     field[n:] = -bzero\n426 \n427                 inarr = inarr - bzero\n428             elif isinstance(columns, _AsciiColDefs):\n429                 # Regardless whether the format is character or numeric, if the\n430                 # input array contains characters then it's already in the raw\n431                 # format for ASCII tables\n432                 if fitsformat._pseudo_logical:\n433                     # Hack to support converting from 8-bit T/F characters\n434                     # Normally the column array is a chararray of 1 character\n435                     # strings, but we need to view it as a normal ndarray of\n436                     # 8-bit ints to fill it with ASCII codes for 'T' and 'F'\n437                     outarr = field.view(np.uint8, np.ndarray)[:n]\n438                 elif arr.dtype.kind not in (\"S\", \"U\"):\n439                     # Set up views of numeric columns with the appropriate\n440                     # numeric dtype\n441                     # Fill with the appropriate blanks for the column format\n442                     data._cache_field(name, np.zeros(nrows, dtype=arr.dtype))\n443                     outarr = data._converted[name][:n]\n444 \n445                 outarr[:] = inarr\n446                 continue\n447 \n448             if inarr.shape != outarr.shape:\n449                 if (\n450                     inarr.dtype.kind == outarr.dtype.kind\n451                     and inarr.dtype.kind in (\"U\", \"S\")\n452                     and inarr.dtype != outarr.dtype\n453                 ):\n454                     inarr_rowsize = inarr[0].size\n455                     inarr = inarr.flatten().view(outarr.dtype)\n456 \n457                 # This is a special case to handle input arrays with\n458                 # non-trivial TDIMn.\n459                 # By design each row of the outarray is 1-D, while each row of\n460                 # the input array may be n-D\n461                 if outarr.ndim > 1:\n462                     # The normal case where the first dimension is the rows\n463                     inarr_rowsize = inarr[0].size\n464                     inarr = inarr.reshape(n, inarr_rowsize)\n465                     outarr[:, :inarr_rowsize] = inarr\n466                 else:\n467                     # Special case for strings where the out array only has one\n468                     # dimension (the second dimension is rolled up into the\n469                     # strings\n470                     outarr[:n] = inarr.ravel()\n471             else:\n472                 outarr[:] = inarr\n473 \n474         # Now replace the original column array references with the new\n475         # fields\n476         # This is required to prevent the issue reported in\n477         # https://github.com/spacetelescope/PyFITS/issues/99\n478         for idx in range(len(columns)):\n479             columns._arrays[idx] = data.field(idx)\n480 \n481         return data\n",
        "intended_behavior": "This method should ensure that variable-length arrays (VLAs) are correctly initialized and managed when creating table columns from them. It must ensure that the metadata and data representation for VLAs are consistent, such that when a FITS file is written and later compared to itself or an identical copy using FITSDiff, no differences are reported due to mismanagement or incorrect metadata handling of VLAs. The fix should preserve the existing functionality for handling regular arrays and other data types, ensuring only VLAs handling is adjusted if found to be the cause of the issue."
    },
    {
        "rel_file_path": "astropy/io/fits/fitsrec.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/astropy__astropy/setup_astropy__astropy__5.1/astropy/io/fits/fitsrec.py",
        "start": 282,
        "end": 481,
        "class_name": "FITS_rec",
        "method_name": "from_columns",
        "code": "282     def from_columns(cls, columns, nrows=0, fill=False, character_as_bytes=False):\n283         \"\"\"\n284         Given a `ColDefs` object of unknown origin, initialize a new `FITS_rec`\n285         object.\n286 \n287         .. note::\n288 \n289             This was originally part of the ``new_table`` function in the table\n290             module but was moved into a class method since most of its\n291             functionality always had more to do with initializing a `FITS_rec`\n292             object than anything else, and much of it also overlapped with\n293             ``FITS_rec._scale_back``.\n294 \n295         Parameters\n296         ----------\n297         columns : sequence of `Column` or a `ColDefs`\n298             The columns from which to create the table data.  If these\n299             columns have data arrays attached that data may be used in\n300             initializing the new table.  Otherwise the input columns\n301             will be used as a template for a new table with the requested\n302             number of rows.\n303 \n304         nrows : int\n305             Number of rows in the new table.  If the input columns have data\n306             associated with them, the size of the largest input column is used.\n307             Otherwise the default is 0.\n308 \n309         fill : bool\n310             If `True`, will fill all cells with zeros or blanks.  If\n311             `False`, copy the data from input, undefined cells will still\n312             be filled with zeros/blanks.\n313         \"\"\"\n314         if not isinstance(columns, ColDefs):\n315             columns = ColDefs(columns)\n316 \n317         # read the delayed data\n318         for column in columns:\n319             arr = column.array\n320             if isinstance(arr, Delayed):\n321                 if arr.hdu.data is None:\n322                     column.array = None\n323                 else:\n324                     column.array = _get_recarray_field(arr.hdu.data, arr.field)\n325         # Reset columns._arrays (which we may want to just do away with\n326         # altogether\n327         del columns._arrays\n328 \n329         # use the largest column shape as the shape of the record\n330         if nrows == 0:\n331             for arr in columns._arrays:\n332                 if arr is not None:\n333                     dim = arr.shape[0]\n334                 else:\n335                     dim = 0\n336                 if dim > nrows:\n337                     nrows = dim\n338 \n339         raw_data = np.empty(columns.dtype.itemsize * nrows, dtype=np.uint8)\n340         raw_data.fill(ord(columns._padding_byte))\n341         data = np.recarray(nrows, dtype=columns.dtype, buf=raw_data).view(cls)\n342         data._character_as_bytes = character_as_bytes\n343 \n344         # Previously this assignment was made from hdu.columns, but that's a\n345         # bug since if a _TableBaseHDU has a FITS_rec in its .data attribute\n346         # the _TableBaseHDU.columns property is actually returned from\n347         # .data._coldefs, so this assignment was circular!  Don't make that\n348         # mistake again.\n349         # All of this is an artifact of the fragility of the FITS_rec class,\n350         # and that it can't just be initialized by columns...\n351         data._coldefs = columns\n352 \n353         # If fill is True we don't copy anything from the column arrays.  We're\n354         # just using them as a template, and returning a table filled with\n355         # zeros/blanks\n356         if fill:\n357             return data\n358 \n359         # Otherwise we have to fill the recarray with data from the input\n360         # columns\n361         for idx, column in enumerate(columns):\n362             # For each column in the ColDef object, determine the number of\n363             # rows in that column.  This will be either the number of rows in\n364             # the ndarray associated with the column, or the number of rows\n365             # given in the call to this function, which ever is smaller.  If\n366             # the input FILL argument is true, the number of rows is set to\n367             # zero so that no data is copied from the original input data.\n368             arr = column.array\n369 \n370             if arr is None:\n371                 array_size = 0\n372             else:\n373                 array_size = len(arr)\n374 \n375             n = min(array_size, nrows)\n376 \n377             # TODO: At least *some* of this logic is mostly redundant with the\n378             # _convert_foo methods in this class; see if we can eliminate some\n379             # of that duplication.\n380 \n381             if not n:\n382                 # The input column had an empty array, so just use the fill\n383                 # value\n384                 continue\n385 \n386             field = _get_recarray_field(data, idx)\n387             name = column.name\n388             fitsformat = column.format\n389             recformat = fitsformat.recformat\n390 \n391             outarr = field[:n]\n392             inarr = arr[:n]\n393 \n394             if isinstance(recformat, _FormatX):\n395                 # Data is a bit array\n396                 if inarr.shape[-1] == recformat.repeat:\n397                     _wrapx(inarr, outarr, recformat.repeat)\n398                     continue\n399             elif isinstance(recformat, _FormatP):\n400                 data._cache_field(name, _makep(inarr, field, recformat, nrows=nrows))\n401                 continue\n402             # TODO: Find a better way of determining that the column is meant\n403             # to be FITS L formatted\n404             elif recformat[-2:] == FITS2NUMPY[\"L\"] and inarr.dtype == bool:\n405                 # column is boolean\n406                 # The raw data field should be filled with either 'T' or 'F'\n407                 # (not 0).  Use 'F' as a default\n408                 field[:] = ord(\"F\")\n409                 # Also save the original boolean array in data._converted so\n410                 # that it doesn't have to be re-converted\n411                 converted = np.zeros(field.shape, dtype=bool)\n412                 converted[:n] = inarr\n413                 data._cache_field(name, converted)\n414                 # TODO: Maybe this step isn't necessary at all if _scale_back\n415                 # will handle it?\n416                 inarr = np.where(inarr == np.False_, ord(\"F\"), ord(\"T\"))\n417             elif columns[idx]._physical_values and columns[idx]._pseudo_unsigned_ints:\n418                 # Temporary hack...\n419                 bzero = column.bzero\n420                 converted = np.zeros(field.shape, dtype=inarr.dtype)\n421                 converted[:n] = inarr\n422                 data._cache_field(name, converted)\n423                 if n < nrows:\n424                     # Pre-scale rows below the input data\n425                     field[n:] = -bzero\n426 \n427                 inarr = inarr - bzero\n428             elif isinstance(columns, _AsciiColDefs):\n429                 # Regardless whether the format is character or numeric, if the\n430                 # input array contains characters then it's already in the raw\n431                 # format for ASCII tables\n432                 if fitsformat._pseudo_logical:\n433                     # Hack to support converting from 8-bit T/F characters\n434                     # Normally the column array is a chararray of 1 character\n435                     # strings, but we need to view it as a normal ndarray of\n436                     # 8-bit ints to fill it with ASCII codes for 'T' and 'F'\n437                     outarr = field.view(np.uint8, np.ndarray)[:n]\n438                 elif arr.dtype.kind not in (\"S\", \"U\"):\n439                     # Set up views of numeric columns with the appropriate\n440                     # numeric dtype\n441                     # Fill with the appropriate blanks for the column format\n442                     data._cache_field(name, np.zeros(nrows, dtype=arr.dtype))\n443                     outarr = data._converted[name][:n]\n444 \n445                 outarr[:] = inarr\n446                 continue\n447 \n448             if inarr.shape != outarr.shape:\n449                 if (\n450                     inarr.dtype.kind == outarr.dtype.kind\n451                     and inarr.dtype.kind in (\"U\", \"S\")\n452                     and inarr.dtype != outarr.dtype\n453                 ):\n454                     inarr_rowsize = inarr[0].size\n455                     inarr = inarr.flatten().view(outarr.dtype)\n456 \n457                 # This is a special case to handle input arrays with\n458                 # non-trivial TDIMn.\n459                 # By design each row of the outarray is 1-D, while each row of\n460                 # the input array may be n-D\n461                 if outarr.ndim > 1:\n462                     # The normal case where the first dimension is the rows\n463                     inarr_rowsize = inarr[0].size\n464                     inarr = inarr.reshape(n, inarr_rowsize)\n465                     outarr[:, :inarr_rowsize] = inarr\n466                 else:\n467                     # Special case for strings where the out array only has one\n468                     # dimension (the second dimension is rolled up into the\n469                     # strings\n470                     outarr[:n] = inarr.ravel()\n471             else:\n472                 outarr[:] = inarr\n473 \n474         # Now replace the original column array references with the new\n475         # fields\n476         # This is required to prevent the issue reported in\n477         # https://github.com/spacetelescope/PyFITS/issues/99\n478         for idx in range(len(columns)):\n479             columns._arrays[idx] = data.field(idx)\n480 \n481         return data\n",
        "intended_behavior": "This method should ensure that variable-length arrays (VLAs) are correctly initialized and managed when creating table columns from them. It must ensure that the metadata and data representation for VLAs are consistent, such that when a FITS file is written and later compared to itself or an identical copy using FITSDiff, no differences are reported due to mismanagement or incorrect metadata handling of VLAs. The fix should preserve the existing functionality for handling regular arrays and other data types, ensuring only VLAs handling is adjusted if found to be the cause of the issue."
    },
    {
        "rel_file_path": "astropy/io/fits/hdu/table.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/astropy__astropy/setup_astropy__astropy__5.1/astropy/io/fits/hdu/table.py",
        "start": 89,
        "end": 155,
        "class_name": null,
        "method_name": "from_columns",
        "code": "89     def from_columns(\n90         cls,\n91         columns,\n92         header=None,\n93         nrows=0,\n94         fill=False,\n95         character_as_bytes=False,\n96         **kwargs,\n97     ):\n98         \"\"\"\n99         Given either a `ColDefs` object, a sequence of `Column` objects,\n100         or another table HDU or table data (a `FITS_rec` or multi-field\n101         `numpy.ndarray` or `numpy.recarray` object, return a new table HDU of\n102         the class this method was called on using the column definition from\n103         the input.\n104 \n105         See also `FITS_rec.from_columns`.\n106 \n107         Parameters\n108         ----------\n109         columns : sequence of `Column`, `ColDefs` -like\n110             The columns from which to create the table data, or an object with\n111             a column-like structure from which a `ColDefs` can be instantiated.\n112             This includes an existing `BinTableHDU` or `TableHDU`, or a\n113             `numpy.recarray` to give some examples.\n114 \n115             If these columns have data arrays attached that data may be used in\n116             initializing the new table.  Otherwise the input columns will be\n117             used as a template for a new table with the requested number of\n118             rows.\n119 \n120         header : `Header`\n121             An optional `Header` object to instantiate the new HDU yet.  Header\n122             keywords specifically related to defining the table structure (such\n123             as the \"TXXXn\" keywords like TTYPEn) will be overridden by the\n124             supplied column definitions, but all other informational and data\n125             model-specific keywords are kept.\n126 \n127         nrows : int\n128             Number of rows in the new table.  If the input columns have data\n129             associated with them, the size of the largest input column is used.\n130             Otherwise the default is 0.\n131 \n132         fill : bool\n133             If `True`, will fill all cells with zeros or blanks.  If `False`,\n134             copy the data from input, undefined cells will still be filled with\n135             zeros/blanks.\n136 \n137         character_as_bytes : bool\n138             Whether to return bytes for string columns when accessed from the\n139             HDU. By default this is `False` and (unicode) strings are returned,\n140             but for large tables this may use up a lot of memory.\n141 \n142         Notes\n143         -----\n144         Any additional keyword arguments accepted by the HDU class's\n145         ``__init__`` may also be passed in as keyword arguments.\n146         \"\"\"\n147         coldefs = cls._columns_type(columns)\n148         data = FITS_rec.from_columns(\n149             coldefs, nrows=nrows, fill=fill, character_as_bytes=character_as_bytes\n150         )\n151         hdu = cls(\n152             data=data, header=header, character_as_bytes=character_as_bytes, **kwargs\n153         )\n154         coldefs._add_listener(hdu)\n155         return hdu\n",
        "intended_behavior": "Similar to the implementation in fitsrec.py, this method's handling of VLAs must be verified and potentially adjusted. The goal here is to ensure that VLAs are accurately represented in table HDUs, aligning data storage with expectations and FITS standards. Any fix should address potential inconsistencies in VLA handling that might affect FITSDiff's ability to correctly compare FITS files, especially ensuring that comparisons of the file to itself correctly report as identical."
    },
    {
        "rel_file_path": "astropy/io/fits/hdu/table.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/astropy__astropy/setup_astropy__astropy__5.1/astropy/io/fits/hdu/table.py",
        "start": 89,
        "end": 155,
        "class_name": "_TableLikeHDU",
        "method_name": "from_columns",
        "code": "89     def from_columns(\n90         cls,\n91         columns,\n92         header=None,\n93         nrows=0,\n94         fill=False,\n95         character_as_bytes=False,\n96         **kwargs,\n97     ):\n98         \"\"\"\n99         Given either a `ColDefs` object, a sequence of `Column` objects,\n100         or another table HDU or table data (a `FITS_rec` or multi-field\n101         `numpy.ndarray` or `numpy.recarray` object, return a new table HDU of\n102         the class this method was called on using the column definition from\n103         the input.\n104 \n105         See also `FITS_rec.from_columns`.\n106 \n107         Parameters\n108         ----------\n109         columns : sequence of `Column`, `ColDefs` -like\n110             The columns from which to create the table data, or an object with\n111             a column-like structure from which a `ColDefs` can be instantiated.\n112             This includes an existing `BinTableHDU` or `TableHDU`, or a\n113             `numpy.recarray` to give some examples.\n114 \n115             If these columns have data arrays attached that data may be used in\n116             initializing the new table.  Otherwise the input columns will be\n117             used as a template for a new table with the requested number of\n118             rows.\n119 \n120         header : `Header`\n121             An optional `Header` object to instantiate the new HDU yet.  Header\n122             keywords specifically related to defining the table structure (such\n123             as the \"TXXXn\" keywords like TTYPEn) will be overridden by the\n124             supplied column definitions, but all other informational and data\n125             model-specific keywords are kept.\n126 \n127         nrows : int\n128             Number of rows in the new table.  If the input columns have data\n129             associated with them, the size of the largest input column is used.\n130             Otherwise the default is 0.\n131 \n132         fill : bool\n133             If `True`, will fill all cells with zeros or blanks.  If `False`,\n134             copy the data from input, undefined cells will still be filled with\n135             zeros/blanks.\n136 \n137         character_as_bytes : bool\n138             Whether to return bytes for string columns when accessed from the\n139             HDU. By default this is `False` and (unicode) strings are returned,\n140             but for large tables this may use up a lot of memory.\n141 \n142         Notes\n143         -----\n144         Any additional keyword arguments accepted by the HDU class's\n145         ``__init__`` may also be passed in as keyword arguments.\n146         \"\"\"\n147         coldefs = cls._columns_type(columns)\n148         data = FITS_rec.from_columns(\n149             coldefs, nrows=nrows, fill=fill, character_as_bytes=character_as_bytes\n150         )\n151         hdu = cls(\n152             data=data, header=header, character_as_bytes=character_as_bytes, **kwargs\n153         )\n154         coldefs._add_listener(hdu)\n155         return hdu\n",
        "intended_behavior": "Similar to the implementation in fitsrec.py, this method's handling of VLAs must be verified and potentially adjusted. The goal here is to ensure that VLAs are accurately represented in table HDUs, aligning data storage with expectations and FITS standards. Any fix should address potential inconsistencies in VLA handling that might affect FITSDiff's ability to correctly compare FITS files, especially ensuring that comparisons of the file to itself correctly report as identical."
    }
]