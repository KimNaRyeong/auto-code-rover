[
    {
        "rel_file_path": "sklearn/feature_selection/mutual_info_.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/scikit-learn__scikit-learn/setup_scikit-learn__scikit-learn__0.21/sklearn/feature_selection/mutual_info_.py",
        "start": 195,
        "end": 290,
        "class_name": null,
        "method_name": "_estimate_mi",
        "code": "195 def _estimate_mi(X, y, discrete_features='auto', discrete_target=False,\n196                  n_neighbors=3, copy=True, random_state=None):\n197     \"\"\"Estimate mutual information between the features and the target.\n198 \n199     Parameters\n200     ----------\n201     X : array_like or sparse matrix, shape (n_samples, n_features)\n202         Feature matrix.\n203 \n204     y : array_like, shape (n_samples,)\n205         Target vector.\n206 \n207     discrete_features : {'auto', bool, array_like}, default 'auto'\n208         If bool, then determines whether to consider all features discrete\n209         or continuous. If array, then it should be either a boolean mask\n210         with shape (n_features,) or array with indices of discrete features.\n211         If 'auto', it is assigned to False for dense `X` and to True for\n212         sparse `X`.\n213 \n214     discrete_target : bool, default False\n215         Whether to consider `y` as a discrete variable.\n216 \n217     n_neighbors : int, default 3\n218         Number of neighbors to use for MI estimation for continuous variables,\n219         see [1]_ and [2]_. Higher values reduce variance of the estimation, but\n220         could introduce a bias.\n221 \n222     copy : bool, default True\n223         Whether to make a copy of the given data. If set to False, the initial\n224         data will be overwritten.\n225 \n226     random_state : int, RandomState instance or None, optional, default None\n227         The seed of the pseudo random number generator for adding small noise\n228         to continuous variables in order to remove repeated values.  If int,\n229         random_state is the seed used by the random number generator; If\n230         RandomState instance, random_state is the random number generator; If\n231         None, the random number generator is the RandomState instance used by\n232         `np.random`.\n233 \n234     Returns\n235     -------\n236     mi : ndarray, shape (n_features,)\n237         Estimated mutual information between each feature and the target.\n238         A negative value will be replaced by 0.\n239 \n240     References\n241     ----------\n242     .. [1] A. Kraskov, H. Stogbauer and P. Grassberger, \"Estimating mutual\n243            information\". Phys. Rev. E 69, 2004.\n244     .. [2] B. C. Ross \"Mutual Information between Discrete and Continuous\n245            Data Sets\". PLoS ONE 9(2), 2014.\n246     \"\"\"\n247     X, y = check_X_y(X, y, accept_sparse='csc', y_numeric=not discrete_target)\n248     n_samples, n_features = X.shape\n249 \n250     if discrete_features == 'auto':\n251         discrete_features = issparse(X)\n252 \n253     if isinstance(discrete_features, bool):\n254         discrete_mask = np.empty(n_features, dtype=bool)\n255         discrete_mask.fill(discrete_features)\n256     else:\n257         discrete_features = np.asarray(discrete_features)\n258         if discrete_features.dtype != 'bool':\n259             discrete_mask = np.zeros(n_features, dtype=bool)\n260             discrete_mask[discrete_features] = True\n261         else:\n262             discrete_mask = discrete_features\n263 \n264     continuous_mask = ~discrete_mask\n265     if np.any(continuous_mask) and issparse(X):\n266         raise ValueError(\"Sparse matrix `X` can't have continuous features.\")\n267 \n268     rng = check_random_state(random_state)\n269     if np.any(continuous_mask):\n270         if copy:\n271             X = X.copy()\n272 \n273         if not discrete_target:\n274             X[:, continuous_mask] = scale(X[:, continuous_mask],\n275                                           with_mean=False, copy=False)\n276 \n277         # Add small noise to continuous features as advised in Kraskov et. al.\n278         X = X.astype(float, **_astype_copy_false(X))\n279         means = np.maximum(1, np.mean(np.abs(X[:, continuous_mask]), axis=0))\n280         X[:, continuous_mask] += 1e-10 * means * rng.randn(\n281                 n_samples, np.sum(continuous_mask))\n282 \n283     if not discrete_target:\n284         y = scale(y, with_mean=False)\n285         y += 1e-10 * np.maximum(1, np.mean(np.abs(y))) * rng.randn(n_samples)\n286 \n287     mi = [_compute_mi(x, y, discrete_feature, discrete_target, n_neighbors) for\n288           x, discrete_feature in zip(_iterate_columns(X), discrete_mask)]\n289 \n290     return np.array(mi)\n",
        "intended_behavior": "To resolve the issue, the `_estimate_mi` function's handling of `discrete_features` when it equals `'auto'` needs to be refined. Currently, it uses a straightforward comparison `if discrete_features == 'auto':`, which assumes `discrete_features` to be a simple type (string). However, since `discrete_features` can also be a boolean or an array indicating the indices or mask of the discrete features, this comparison could fail or behave unexpectedly in future numpy versions due to type compatibility issues.\n\nThe intended behavior is to ensure that the function can accurately interpret and handle the `discrete_features` parameter when it is set to `'auto'`, a boolean, or an array. When `discrete_features` is `'auto'`, the function should continue to determine whether features are considered discrete or continuous based on the sparsity of `X`. However, this decision should be made through a more robust type check, gracefully handling cases where `discrete_features` is an array or boolean.\n\nSpecifically, the function should:\n- Implement a type check to determine if `discrete_features` is a string before comparing it to `'auto'`. If it is not a string, the function should use an alternative logic to handle boolean or array inputs without attempting the string comparison.\n- Maintain the existing functionality where, if `discrete_features == 'auto'`, the decision on whether features are discrete or continuous is made based on the type and sparsity of `X`.\n- Ensure that any non-string inputs for `discrete_features` (e.g., boolean values or arrays) are handled appropriately, without relying on string comparison logic.\n\nThis adjustment will prevent potential errors with future versions of numpy and ensure that the function remains robust and flexible to different types of `discrete_features` inputs."
    }
]