2025-10-15 19:01:31.292 | INFO     | Starting overall retry 0 with model gpt-4-0125-preview
2025-10-15 19:01:34.158 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=511, output_tokens=12, cost=0.005470
2025-10-15 19:01:45.546 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=691, output_tokens=490, cost=0.021610
2025-10-15 19:01:46.773 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-15 19:01:56.513 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=820, output_tokens=416, cost=0.020680
2025-10-15 19:01:56.522 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-15 19:02:00.240 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=770, output_tokens=96, cost=0.010580
2025-10-15 19:02:00.241 | DEBUG    | Extracted a valid json.
2025-10-15 19:02:00.241 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [
        "search_class(\"EmptyResultSet\")",
        "search_code_in_file(\"raise EmptyResultSet()\", \"django/db/models/lookups.py\")",
        "search_method_in_class(\"get_aggregation\", \"Query\")",
        "search_class(\"Coalesce\")",
        "search_method(\"Coalesce\")",
        "search_class(\"Value\")",
        "search_method(\"Value\")"
    ],
    "bug_locations": []
}
2025-10-15 19:02:00.268 | DEBUG    | Obtained search results from API invocation. Going into next retrieval round.
2025-10-15 19:02:00.269 | DEBUG    | <Agent search> Analyzing search results.
2025-10-15 19:02:28.069 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=2764, output_tokens=973, cost=0.056830
2025-10-15 19:02:28.088 | DEBUG    | <Agent search> Selecting APIs to call.
2025-10-15 19:02:37.567 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=3953, output_tokens=316, cost=0.049010
2025-10-15 19:02:37.571 | DEBUG    | Trying to convert API calls/bug locations into json. Try 1 of 5.
2025-10-15 19:02:47.834 | INFO     | Model (gpt-4-0125-preview) API request cost info: input_tokens=670, output_tokens=318, cost=0.016240
2025-10-15 19:02:47.834 | DEBUG    | Extracted a valid json.
2025-10-15 19:02:47.834 | DEBUG    | Agent proxy return the following json: {
    "API_calls": [],
    "bug_locations": [
        {
            "file": "django/db/models/sql/query.py",
            "class": "Query",
            "method": "get_aggregation",
            "intended_behavior": "This method, which prepares and retrieves aggregate results, should be modified to ensure that when an `EmptyResultSet` scenario is recognized (i.e., when filtering with `pk__in=[]` results in no rows to aggregate), it should still allow for `Coalesce` functions with `Value` to return the specified default value, instead of converting all aggregates to `None`. This enhancement would involve checking for `Coalesce` instances within the query's annotation and ensuring that their defined fallback values are returned in the aggregate result dictionary instead of `None`. This modification must preserve the method's existing functionality for handling non-empty result sets and other kinds of aggregate functions.\n\nThe method will need additional logic around the handling of empty results, specifically acknowledging when aggregates can bypass the `EmptyResultSet` limitation (such as with `Coalesce`). This could involve:\n- Detecting when an aggregate query contains `Coalesce` with `Value`.\n- Ensuring that these cases return the fallback value provided by `Value` within `Coalesce`, even if the query result set is empty.\n\nThis approach maintains the existing functionality for queries that do not involve this specific `Coalesce`-`Value` use case, thus keeping the impact of changes scoped only to the necessary conditions that address the bug."
        }
    ]
}
2025-10-15 19:02:47.846 | DEBUG    | Bug location extracted successfully: [<file>django/db/models/sql/query.py</file>
<class>Query</class>
<method>get_aggregation</method>
<code>
419     def get_aggregation(self, using, added_aggregate_names):
420         """
421         Return the dictionary with the values of the existing aggregations.
422         """
423         if not self.annotation_select:
424             return {}
425         existing_annotations = [
426             annotation for alias, annotation
427             in self.annotations.items()
428             if alias not in added_aggregate_names
429         ]
430         # Decide if we need to use a subquery.
431         #
432         # Existing annotations would cause incorrect results as get_aggregation()
433         # must produce just one result and thus must not use GROUP BY. But we
434         # aren't smart enough to remove the existing annotations from the
435         # query, so those would force us to use GROUP BY.
436         #
437         # If the query has limit or distinct, or uses set operations, then
438         # those operations must be done in a subquery so that the query
439         # aggregates on the limit and/or distinct results instead of applying
440         # the distinct and limit after the aggregation.
441         if (isinstance(self.group_by, tuple) or self.is_sliced or existing_annotations or
442                 self.distinct or self.combinator):
443             from django.db.models.sql.subqueries import AggregateQuery
444             inner_query = self.clone()
445             inner_query.subquery = True
446             outer_query = AggregateQuery(self.model, inner_query)
447             inner_query.select_for_update = False
448             inner_query.select_related = False
449             inner_query.set_annotation_mask(self.annotation_select)
450             # Queries with distinct_fields need ordering and when a limit is
451             # applied we must take the slice from the ordered query. Otherwise
452             # no need for ordering.
453             inner_query.clear_ordering(force=False)
454             if not inner_query.distinct:
455                 # If the inner query uses default select and it has some
456                 # aggregate annotations, then we must make sure the inner
457                 # query is grouped by the main model's primary key. However,
458                 # clearing the select clause can alter results if distinct is
459                 # used.
460                 has_existing_aggregate_annotations = any(
461                     annotation for annotation in existing_annotations
462                     if getattr(annotation, 'contains_aggregate', True)
463                 )
464                 if inner_query.default_cols and has_existing_aggregate_annotations:
465                     inner_query.group_by = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)
466                 inner_query.default_cols = False
467 
468             relabels = {t: 'subquery' for t in inner_query.alias_map}
469             relabels[None] = 'subquery'
470             # Remove any aggregates marked for reduction from the subquery
471             # and move them to the outer AggregateQuery.
472             col_cnt = 0
473             for alias, expression in list(inner_query.annotation_select.items()):
474                 annotation_select_mask = inner_query.annotation_select_mask
475                 if expression.is_summary:
476                     expression, col_cnt = inner_query.rewrite_cols(expression, col_cnt)
477                     outer_query.annotations[alias] = expression.relabeled_clone(relabels)
478                     del inner_query.annotations[alias]
479                     annotation_select_mask.remove(alias)
480                 # Make sure the annotation_select wont use cached results.
481                 inner_query.set_annotation_mask(inner_query.annotation_select_mask)
482             if inner_query.select == () and not inner_query.default_cols and not inner_query.annotation_select_mask:
483                 # In case of Model.objects[0:3].count(), there would be no
484                 # field selected in the inner query, yet we must use a subquery.
485                 # So, make sure at least one field is selected.
486                 inner_query.select = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)
487         else:
488             outer_query = self
489             self.select = ()
490             self.default_cols = False
491             self.extra = {}
492 
493         outer_query.clear_ordering(force=True)
494         outer_query.clear_limits()
495         outer_query.select_for_update = False
496         outer_query.select_related = False
497         compiler = outer_query.get_compiler(using)
498         result = compiler.execute_sql(SINGLE)
499         if result is None:
500             result = [None] * len(outer_query.annotation_select)
501 
502         converters = compiler.get_converters(outer_query.annotation_select.values())
503         result = next(compiler.apply_converters((result,), converters))
504 
505         return dict(zip(outer_query.annotation_select, result))

</code><intended_behavior>This method, which prepares and retrieves aggregate results, should be modified to ensure that when an `EmptyResultSet` scenario is recognized (i.e., when filtering with `pk__in=[]` results in no rows to aggregate), it should still allow for `Coalesce` functions with `Value` to return the specified default value, instead of converting all aggregates to `None`. This enhancement would involve checking for `Coalesce` instances within the query's annotation and ensuring that their defined fallback values are returned in the aggregate result dictionary instead of `None`. This modification must preserve the method's existing functionality for handling non-empty result sets and other kinds of aggregate functions.

The method will need additional logic around the handling of empty results, specifically acknowledging when aggregates can bypass the `EmptyResultSet` limitation (such as with `Coalesce`). This could involve:
- Detecting when an aggregate query contains `Coalesce` with `Value`.
- Ensuring that these cases return the fallback value provided by `Value` within `Coalesce`, even if the query result set is empty.

This approach maintains the existing functionality for queries that do not involve this specific `Coalesce`-`Value` use case, thus keeping the impact of changes scoped only to the necessary conditions that address the bug.</intended_behavior>, <file>django/db/models/sql/query.py</file>
<class>Query</class>
<method>None</method>
<code>
139 class Query(BaseExpression):
140     """A single SQL query."""
141 
142     alias_prefix = 'T'
143     subq_aliases = frozenset([alias_prefix])
144 
145     compiler = 'SQLCompiler'
146 
147     def __init__(self, model, where=WhereNode, alias_cols=True):
148         self.model = model
149         self.alias_refcount = {}
150         # alias_map is the most important data structure regarding joins.
151         # It's used for recording which joins exist in the query and what
152         # types they are. The key is the alias of the joined table (possibly
153         # the table name) and the value is a Join-like object (see
154         # sql.datastructures.Join for more information).
155         self.alias_map = {}
156         # Whether to provide alias to columns during reference resolving.
157         self.alias_cols = alias_cols
158         # Sometimes the query contains references to aliases in outer queries (as
159         # a result of split_exclude). Correct alias quoting needs to know these
160         # aliases too.
161         # Map external tables to whether they are aliased.
162         self.external_aliases = {}
163         self.table_map = {}     # Maps table names to list of aliases.
164         self.default_cols = True
165         self.default_ordering = True
166         self.standard_ordering = True
167         self.used_aliases = set()
168         self.filter_is_sticky = False
169         self.subquery = False
170 
171         # SQL-related attributes
172         # Select and related select clauses are expressions to use in the
173         # SELECT clause of the query.
174         # The select is used for cases where we want to set up the select
175         # clause to contain other than default fields (values(), subqueries...)
176         # Note that annotations go to annotations dictionary.
177         self.select = ()
178         self.where = where()
179         self.where_class = where
180         # The group_by attribute can have one of the following forms:
181         #  - None: no group by at all in the query
182         #  - A tuple of expressions: group by (at least) those expressions.
183         #    String refs are also allowed for now.
184         #  - True: group by all select fields of the model
185         # See compiler.get_group_by() for details.
186         self.group_by = None
187         self.order_by = ()
188         self.low_mark, self.high_mark = 0, None  # Used for offset/limit
189         self.distinct = False
190         self.distinct_fields = ()
191         self.select_for_update = False
192         self.select_for_update_nowait = False
193         self.select_for_update_skip_locked = False
194         self.select_for_update_of = ()
195         self.select_for_no_key_update = False
196 
197         self.select_related = False
198         # Arbitrary limit for select_related to prevents infinite recursion.
199         self.max_depth = 5
200 
201         # Holds the selects defined by a call to values() or values_list()
202         # excluding annotation_select and extra_select.
203         self.values_select = ()
204 
205         # SQL annotation-related attributes
206         self.annotations = {}  # Maps alias -> Annotation Expression
207         self.annotation_select_mask = None
208         self._annotation_select_cache = None
209 
210         # Set combination attributes
211         self.combinator = None
212         self.combinator_all = False
213         self.combined_queries = ()
214 
215         # These are for extensions. The contents are more or less appended
216         # verbatim to the appropriate clause.
217         self.extra = {}  # Maps col_alias -> (col_sql, params).
218         self.extra_select_mask = None
219         self._extra_select_cache = None
220 
221         self.extra_tables = ()
222         self.extra_order_by = ()
223 
224         # A tuple that is a set of model field names and either True, if these
225         # are the fields to defer, or False if these are the only fields to
226         # load.
227         self.deferred_loading = (frozenset(), True)
228 
229         self._filtered_relations = {}
230 
231         self.explain_query = False
232         self.explain_format = None
233         self.explain_options = {}
234 
235     @property
236     def output_field(self):
237         if len(self.select) == 1:
238             select = self.select[0]
239             return getattr(select, 'target', None) or select.field
240         elif len(self.annotation_select) == 1:
241             return next(iter(self.annotation_select.values())).output_field
242 
243     @property
244     def has_select_fields(self):
245         return bool(self.select or self.annotation_select_mask or self.extra_select_mask)
246 
247     @cached_property
248     def base_table(self):
249         for alias in self.alias_map:
250             return alias
251 
252     def __str__(self):
253         """
254         Return the query as a string of SQL with the parameter values
255         substituted in (use sql_with_params() to see the unsubstituted string).
256 
257         Parameter values won't necessarily be quoted correctly, since that is
258         done by the database interface at execution time.
259         """
260         sql, params = self.sql_with_params()
261         return sql % params
262 
263     def sql_with_params(self):
264         """
265         Return the query as an SQL string and the parameters that will be
266         substituted into the query.
267         """
268         return self.get_compiler(DEFAULT_DB_ALIAS).as_sql()
269 
270     def __deepcopy__(self, memo):
271         """Limit the amount of work when a Query is deepcopied."""
272         result = self.clone()
273         memo[id(self)] = result
274         return result
275 
276     def get_compiler(self, using=None, connection=None):
277         if using is None and connection is None:
278             raise ValueError("Need either using or connection")
279         if using:
280             connection = connections[using]
281         return connection.ops.compiler(self.compiler)(self, connection, using)
282 
283     def get_meta(self):
284         """
285         Return the Options instance (the model._meta) from which to start
286         processing. Normally, this is self.model._meta, but it can be changed
287         by subclasses.
288         """
289         return self.model._meta
290 
291     def clone(self):
292         """
293         Return a copy of the current Query. A lightweight alternative to
294         to deepcopy().
295         """
296         obj = Empty()
297         obj.__class__ = self.__class__
298         # Copy references to everything.
299         obj.__dict__ = self.__dict__.copy()
300         # Clone attributes that can't use shallow copy.
301         obj.alias_refcount = self.alias_refcount.copy()
302         obj.alias_map = self.alias_map.copy()
303         obj.external_aliases = self.external_aliases.copy()
304         obj.table_map = self.table_map.copy()
305         obj.where = self.where.clone()
306         obj.annotations = self.annotations.copy()
307         if self.annotation_select_mask is None:
308             obj.annotation_select_mask = None
309         else:
310             obj.annotation_select_mask = self.annotation_select_mask.copy()
311         obj.combined_queries = tuple(query.clone() for query in self.combined_queries)
312         # _annotation_select_cache cannot be copied, as doing so breaks the
313         # (necessary) state in which both annotations and
314         # _annotation_select_cache point to the same underlying objects.
315         # It will get re-populated in the cloned queryset the next time it's
316         # used.
317         obj._annotation_select_cache = None
318         obj.extra = self.extra.copy()
319         if self.extra_select_mask is None:
320             obj.extra_select_mask = None
321         else:
322             obj.extra_select_mask = self.extra_select_mask.copy()
323         if self._extra_select_cache is None:
324             obj._extra_select_cache = None
325         else:
326             obj._extra_select_cache = self._extra_select_cache.copy()
327         if self.select_related is not False:
328             # Use deepcopy because select_related stores fields in nested
329             # dicts.
330             obj.select_related = copy.deepcopy(obj.select_related)
331         if 'subq_aliases' in self.__dict__:
332             obj.subq_aliases = self.subq_aliases.copy()
333         obj.used_aliases = self.used_aliases.copy()
334         obj._filtered_relations = self._filtered_relations.copy()
335         # Clear the cached_property
336         try:
337             del obj.base_table
338         except AttributeError:
339             pass
340         return obj
341 
342     def chain(self, klass=None):
343         """
344         Return a copy of the current Query that's ready for another operation.
345         The klass argument changes the type of the Query, e.g. UpdateQuery.
346         """
347         obj = self.clone()
348         if klass and obj.__class__ != klass:
349             obj.__class__ = klass
350         if not obj.filter_is_sticky:
351             obj.used_aliases = set()
352         obj.filter_is_sticky = False
353         if hasattr(obj, '_setup_query'):
354             obj._setup_query()
355         return obj
356 
357     def relabeled_clone(self, change_map):
358         clone = self.clone()
359         clone.change_aliases(change_map)
360         return clone
361 
362     def _get_col(self, target, field, alias):
363         if not self.alias_cols:
364             alias = None
365         return target.get_col(alias, field)
366 
367     def rewrite_cols(self, annotation, col_cnt):
368         # We must make sure the inner query has the referred columns in it.
369         # If we are aggregating over an annotation, then Django uses Ref()
370         # instances to note this. However, if we are annotating over a column
371         # of a related model, then it might be that column isn't part of the
372         # SELECT clause of the inner query, and we must manually make sure
373         # the column is selected. An example case is:
374         #    .aggregate(Sum('author__awards'))
375         # Resolving this expression results in a join to author, but there
376         # is no guarantee the awards column of author is in the select clause
377         # of the query. Thus we must manually add the column to the inner
378         # query.
379         orig_exprs = annotation.get_source_expressions()
380         new_exprs = []
381         for expr in orig_exprs:
382             # FIXME: These conditions are fairly arbitrary. Identify a better
383             # method of having expressions decide which code path they should
384             # take.
385             if isinstance(expr, Ref):
386                 # Its already a Ref to subquery (see resolve_ref() for
387                 # details)
388                 new_exprs.append(expr)
389             elif isinstance(expr, (WhereNode, Lookup)):
390                 # Decompose the subexpressions further. The code here is
391                 # copied from the else clause, but this condition must appear
392                 # before the contains_aggregate/is_summary condition below.
393                 new_expr, col_cnt = self.rewrite_cols(expr, col_cnt)
394                 new_exprs.append(new_expr)
395             else:
396                 # Reuse aliases of expressions already selected in subquery.
397                 for col_alias, selected_annotation in self.annotation_select.items():
398                     if selected_annotation is expr:
399                         new_expr = Ref(col_alias, expr)
400                         break
401                 else:
402                     # An expression that is not selected the subquery.
403                     if isinstance(expr, Col) or (expr.contains_aggregate and not expr.is_summary):
404                         # Reference column or another aggregate. Select it
405                         # under a non-conflicting alias.
406                         col_cnt += 1
407                         col_alias = '__col%d' % col_cnt
408                         self.annotations[col_alias] = expr
409                         self.append_annotation_mask([col_alias])
410                         new_expr = Ref(col_alias, expr)
411                     else:
412                         # Some other expression not referencing database values
413                         # directly. Its subexpression might contain Cols.
414                         new_expr, col_cnt = self.rewrite_cols(expr, col_cnt)
415                 new_exprs.append(new_expr)
416         annotation.set_source_expressions(new_exprs)
417         return annotation, col_cnt
418 
419     def get_aggregation(self, using, added_aggregate_names):
420         """
421         Return the dictionary with the values of the existing aggregations.
422         """
423         if not self.annotation_select:
424             return {}
425         existing_annotations = [
426             annotation for alias, annotation
427             in self.annotations.items()
428             if alias not in added_aggregate_names
429         ]
430         # Decide if we need to use a subquery.
431         #
432         # Existing annotations would cause incorrect results as get_aggregation()
433         # must produce just one result and thus must not use GROUP BY. But we
434         # aren't smart enough to remove the existing annotations from the
435         # query, so those would force us to use GROUP BY.
436         #
437         # If the query has limit or distinct, or uses set operations, then
438         # those operations must be done in a subquery so that the query
439         # aggregates on the limit and/or distinct results instead of applying
440         # the distinct and limit after the aggregation.
441         if (isinstance(self.group_by, tuple) or self.is_sliced or existing_annotations or
442                 self.distinct or self.combinator):
443             from django.db.models.sql.subqueries import AggregateQuery
444             inner_query = self.clone()
445             inner_query.subquery = True
446             outer_query = AggregateQuery(self.model, inner_query)
447             inner_query.select_for_update = False
448             inner_query.select_related = False
449             inner_query.set_annotation_mask(self.annotation_select)
450             # Queries with distinct_fields need ordering and when a limit is
451             # applied we must take the slice from the ordered query. Otherwise
452             # no need for ordering.
453             inner_query.clear_ordering(force=False)
454             if not inner_query.distinct:
455                 # If the inner query uses default select and it has some
456                 # aggregate annotations, then we must make sure the inner
457                 # query is grouped by the main model's primary key. However,
458                 # clearing the select clause can alter results if distinct is
459                 # used.
460                 has_existing_aggregate_annotations = any(
461                     annotation for annotation in existing_annotations
462                     if getattr(annotation, 'contains_aggregate', True)
463                 )
464                 if inner_query.default_cols and has_existing_aggregate_annotations:
465                     inner_query.group_by = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)
466                 inner_query.default_cols = False
467 
468             relabels = {t: 'subquery' for t in inner_query.alias_map}
469             relabels[None] = 'subquery'
470             # Remove any aggregates marked for reduction from the subquery
471             # and move them to the outer AggregateQuery.
472             col_cnt = 0
473             for alias, expression in list(inner_query.annotation_select.items()):
474                 annotation_select_mask = inner_query.annotation_select_mask
475                 if expression.is_summary:
476                     expression, col_cnt = inner_query.rewrite_cols(expression, col_cnt)
477                     outer_query.annotations[alias] = expression.relabeled_clone(relabels)
478                     del inner_query.annotations[alias]
479                     annotation_select_mask.remove(alias)
480                 # Make sure the annotation_select wont use cached results.
481                 inner_query.set_annotation_mask(inner_query.annotation_select_mask)
482             if inner_query.select == () and not inner_query.default_cols and not inner_query.annotation_select_mask:
483                 # In case of Model.objects[0:3].count(), there would be no
484                 # field selected in the inner query, yet we must use a subquery.
485                 # So, make sure at least one field is selected.
486                 inner_query.select = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)
487         else:
488             outer_query = self
489             self.select = ()
490             self.default_cols = False
491             self.extra = {}
492 
493         outer_query.clear_ordering(force=True)
494         outer_query.clear_limits()
495         outer_query.select_for_update = False
496         outer_query.select_related = False
497         compiler = outer_query.get_compiler(using)
498         result = compiler.execute_sql(SINGLE)
499         if result is None:
500             result = [None] * len(outer_query.annotation_select)
501 
502         converters = compiler.get_converters(outer_query.annotation_select.values())
503         result = next(compiler.apply_converters((result,), converters))
504 
505         return dict(zip(outer_query.annotation_select, result))
506 
507     def get_count(self, using):
508         """
509         Perform a COUNT() query using the current filter constraints.
510         """
511         obj = self.clone()
512         obj.add_annotation(Count('*'), alias='__count', is_summary=True)
513         number = obj.get_aggregation(using, ['__count'])['__count']
514         if number is None:
515             number = 0
516         return number
517 
518     def has_filters(self):
519         return self.where
520 
521     def exists(self, using, limit=True):
522         q = self.clone()
523         if not q.distinct:
524             if q.group_by is True:
525                 q.add_fields((f.attname for f in self.model._meta.concrete_fields), False)
526                 # Disable GROUP BY aliases to avoid orphaning references to the
527                 # SELECT clause which is about to be cleared.
528                 q.set_group_by(allow_aliases=False)
529             q.clear_select_clause()
530         if q.combined_queries and q.combinator == 'union':
531             limit_combined = connections[using].features.supports_slicing_ordering_in_compound
532             q.combined_queries = tuple(
533                 combined_query.exists(using, limit=limit_combined)
534                 for combined_query in q.combined_queries
535             )
536         q.clear_ordering(force=True)
537         if limit:
538             q.set_limits(high=1)
539         q.add_extra({'a': 1}, None, None, None, None, None)
540         q.set_extra_mask(['a'])
541         return q
542 
543     def has_results(self, using):
544         q = self.exists(using)
545         compiler = q.get_compiler(using=using)
546         return compiler.has_results()
547 
548     def explain(self, using, format=None, **options):
549         q = self.clone()
550         q.explain_query = True
551         q.explain_format = format
552         q.explain_options = options
553         compiler = q.get_compiler(using=using)
554         return '\n'.join(compiler.explain_query())
555 
556     def combine(self, rhs, connector):
557         """
558         Merge the 'rhs' query into the current one (with any 'rhs' effects
559         being applied *after* (that is, "to the right of") anything in the
560         current query. 'rhs' is not modified during a call to this function.
561 
562         The 'connector' parameter describes how to connect filters from the
563         'rhs' query.
564         """
565         assert self.model == rhs.model, \
566             "Cannot combine queries on two different base models."
567         if self.is_sliced:
568             raise TypeError('Cannot combine queries once a slice has been taken.')
569         assert self.distinct == rhs.distinct, \
570             "Cannot combine a unique query with a non-unique query."
571         assert self.distinct_fields == rhs.distinct_fields, \
572             "Cannot combine queries with different distinct fields."
573 
574         # Work out how to relabel the rhs aliases, if necessary.
575         change_map = {}
576         conjunction = (connector == AND)
577 
578         # Determine which existing joins can be reused. When combining the
579         # query with AND we must recreate all joins for m2m filters. When
580         # combining with OR we can reuse joins. The reason is that in AND
581         # case a single row can't fulfill a condition like:
582         #     revrel__col=1 & revrel__col=2
583         # But, there might be two different related rows matching this
584         # condition. In OR case a single True is enough, so single row is
585         # enough, too.
586         #
587         # Note that we will be creating duplicate joins for non-m2m joins in
588         # the AND case. The results will be correct but this creates too many
589         # joins. This is something that could be fixed later on.
590         reuse = set() if conjunction else set(self.alias_map)
591         # Base table must be present in the query - this is the same
592         # table on both sides.
593         self.get_initial_alias()
594         joinpromoter = JoinPromoter(connector, 2, False)
595         joinpromoter.add_votes(
596             j for j in self.alias_map if self.alias_map[j].join_type == INNER)
597         rhs_votes = set()
598         # Now, add the joins from rhs query into the new query (skipping base
599         # table).
600         rhs_tables = list(rhs.alias_map)[1:]
601         for alias in rhs_tables:
602             join = rhs.alias_map[alias]
603             # If the left side of the join was already relabeled, use the
604             # updated alias.
605             join = join.relabeled_clone(change_map)
606             new_alias = self.join(join, reuse=reuse)
607             if join.join_type == INNER:
608                 rhs_votes.add(new_alias)
609             # We can't reuse the same join again in the query. If we have two
610             # distinct joins for the same connection in rhs query, then the
611             # combined query must have two joins, too.
612             reuse.discard(new_alias)
613             if alias != new_alias:
614                 change_map[alias] = new_alias
615             if not rhs.alias_refcount[alias]:
616                 # The alias was unused in the rhs query. Unref it so that it
617                 # will be unused in the new query, too. We have to add and
618                 # unref the alias so that join promotion has information of
619                 # the join type for the unused alias.
620                 self.unref_alias(new_alias)
621         joinpromoter.add_votes(rhs_votes)
622         joinpromoter.update_join_types(self)
623 
624         # Combine subqueries aliases to ensure aliases relabelling properly
625         # handle subqueries when combining where and select clauses.
626         self.subq_aliases |= rhs.subq_aliases
627 
628         # Now relabel a copy of the rhs where-clause and add it to the current
629         # one.
630         w = rhs.where.clone()
631         w.relabel_aliases(change_map)
632         self.where.add(w, connector)
633 
634         # Selection columns and extra extensions are those provided by 'rhs'.
635         if rhs.select:
636             self.set_select([col.relabeled_clone(change_map) for col in rhs.select])
637         else:
638             self.select = ()
639 
640         if connector == OR:
641             # It would be nice to be able to handle this, but the queries don't
642             # really make sense (or return consistent value sets). Not worth
643             # the extra complexity when you can write a real query instead.
644             if self.extra and rhs.extra:
645                 raise ValueError("When merging querysets using 'or', you cannot have extra(select=...) on both sides.")
646         self.extra.update(rhs.extra)
647         extra_select_mask = set()
648         if self.extra_select_mask is not None:
649             extra_select_mask.update(self.extra_select_mask)
650         if rhs.extra_select_mask is not None:
651             extra_select_mask.update(rhs.extra_select_mask)
652         if extra_select_mask:
653             self.set_extra_mask(extra_select_mask)
654         self.extra_tables += rhs.extra_tables
655 
656         # Ordering uses the 'rhs' ordering, unless it has none, in which case
657         # the current ordering is used.
658         self.order_by = rhs.order_by or self.order_by
659         self.extra_order_by = rhs.extra_order_by or self.extra_order_by
660 
661     def deferred_to_data(self, target, callback):
662         """
663         Convert the self.deferred_loading data structure to an alternate data
664         structure, describing the field that *will* be loaded. This is used to
665         compute the columns to select from the database and also by the
666         QuerySet class to work out which fields are being initialized on each
667         model. Models that have all their fields included aren't mentioned in
668         the result, only those that have field restrictions in place.
669 
670         The "target" parameter is the instance that is populated (in place).
671         The "callback" is a function that is called whenever a (model, field)
672         pair need to be added to "target". It accepts three parameters:
673         "target", and the model and list of fields being added for that model.
674         """
675         field_names, defer = self.deferred_loading
676         if not field_names:
677             return
678         orig_opts = self.get_meta()
679         seen = {}
680         must_include = {orig_opts.concrete_model: {orig_opts.pk}}
681         for field_name in field_names:
682             parts = field_name.split(LOOKUP_SEP)
683             cur_model = self.model._meta.concrete_model
684             opts = orig_opts
685             for name in parts[:-1]:
686                 old_model = cur_model
687                 if name in self._filtered_relations:
688                     name = self._filtered_relations[name].relation_name
689                 source = opts.get_field(name)
690                 if is_reverse_o2o(source):
691                     cur_model = source.related_model
692                 else:
693                     cur_model = source.remote_field.model
694                 opts = cur_model._meta
695                 # Even if we're "just passing through" this model, we must add
696                 # both the current model's pk and the related reference field
697                 # (if it's not a reverse relation) to the things we select.
698                 if not is_reverse_o2o(source):
699                     must_include[old_model].add(source)
700                 add_to_dict(must_include, cur_model, opts.pk)
701             field = opts.get_field(parts[-1])
702             is_reverse_object = field.auto_created and not field.concrete
703             model = field.related_model if is_reverse_object else field.model
704             model = model._meta.concrete_model
705             if model == opts.model:
706                 model = cur_model
707             if not is_reverse_o2o(field):
708                 add_to_dict(seen, model, field)
709 
710         if defer:
711             # We need to load all fields for each model, except those that
712             # appear in "seen" (for all models that appear in "seen"). The only
713             # slight complexity here is handling fields that exist on parent
714             # models.
715             workset = {}
716             for model, values in seen.items():
717                 for field in model._meta.local_fields:
718                     if field not in values:
719                         m = field.model._meta.concrete_model
720                         add_to_dict(workset, m, field)
721             for model, values in must_include.items():
722                 # If we haven't included a model in workset, we don't add the
723                 # corresponding must_include fields for that model, since an
724                 # empty set means "include all fields". That's why there's no
725                 # "else" branch here.
726                 if model in workset:
727                     workset[model].update(values)
728             for model, values in workset.items():
729                 callback(target, model, values)
730         else:
731             for model, values in must_include.items():
732                 if model in seen:
733                     seen[model].update(values)
734                 else:
735                     # As we've passed through this model, but not explicitly
736                     # included any fields, we have to make sure it's mentioned
737                     # so that only the "must include" fields are pulled in.
738                     seen[model] = values
739             # Now ensure that every model in the inheritance chain is mentioned
740             # in the parent list. Again, it must be mentioned to ensure that
741             # only "must include" fields are pulled in.
742             for model in orig_opts.get_parent_list():
743                 seen.setdefault(model, set())
744             for model, values in seen.items():
745                 callback(target, model, values)
746 
747     def table_alias(self, table_name, create=False, filtered_relation=None):
748         """
749         Return a table alias for the given table_name and whether this is a
750         new alias or not.
751 
752         If 'create' is true, a new alias is always created. Otherwise, the
753         most recently created alias for the table (if one exists) is reused.
754         """
755         alias_list = self.table_map.get(table_name)
756         if not create and alias_list:
757             alias = alias_list[0]
758             self.alias_refcount[alias] += 1
759             return alias, False
760 
761         # Create a new alias for this table.
762         if alias_list:
763             alias = '%s%d' % (self.alias_prefix, len(self.alias_map) + 1)
764             alias_list.append(alias)
765         else:
766             # The first occurrence of a table uses the table name directly.
767             alias = filtered_relation.alias if filtered_relation is not None else table_name
768             self.table_map[table_name] = [alias]
769         self.alias_refcount[alias] = 1
770         return alias, True
771 
772     def ref_alias(self, alias):
773         """Increases the reference count for this alias."""
774         self.alias_refcount[alias] += 1
775 
776     def unref_alias(self, alias, amount=1):
777         """Decreases the reference count for this alias."""
778         self.alias_refcount[alias] -= amount
779 
780     def promote_joins(self, aliases):
781         """
782         Promote recursively the join type of given aliases and its children to
783         an outer join. If 'unconditional' is False, only promote the join if
784         it is nullable or the parent join is an outer join.
785 
786         The children promotion is done to avoid join chains that contain a LOUTER
787         b INNER c. So, if we have currently a INNER b INNER c and a->b is promoted,
788         then we must also promote b->c automatically, or otherwise the promotion
789         of a->b doesn't actually change anything in the query results.
790         """
791         aliases = list(aliases)
792         while aliases:
793             alias = aliases.pop(0)
794             if self.alias_map[alias].join_type is None:
795                 # This is the base table (first FROM entry) - this table
796                 # isn't really joined at all in the query, so we should not
797                 # alter its join type.
798                 continue
799             # Only the first alias (skipped above) should have None join_type
800             assert self.alias_map[alias].join_type is not None
801             parent_alias = self.alias_map[alias].parent_alias
802             parent_louter = parent_alias and self.alias_map[parent_alias].join_type == LOUTER
803             already_louter = self.alias_map[alias].join_type == LOUTER
804             if ((self.alias_map[alias].nullable or parent_louter) and
805                     not already_louter):
806                 self.alias_map[alias] = self.alias_map[alias].promote()
807                 # Join type of 'alias' changed, so re-examine all aliases that
808                 # refer to this one.
809                 aliases.extend(
810                     join for join in self.alias_map
811                     if self.alias_map[join].parent_alias == alias and join not in aliases
812                 )
813 
814     def demote_joins(self, aliases):
815         """
816         Change join type from LOUTER to INNER for all joins in aliases.
817 
818         Similarly to promote_joins(), this method must ensure no join chains
819         containing first an outer, then an inner join are generated. If we
820         are demoting b->c join in chain a LOUTER b LOUTER c then we must
821         demote a->b automatically, or otherwise the demotion of b->c doesn't
822         actually change anything in the query results. .
823         """
824         aliases = list(aliases)
825         while aliases:
826             alias = aliases.pop(0)
827             if self.alias_map[alias].join_type == LOUTER:
828                 self.alias_map[alias] = self.alias_map[alias].demote()
829                 parent_alias = self.alias_map[alias].parent_alias
830                 if self.alias_map[parent_alias].join_type == INNER:
831                     aliases.append(parent_alias)
832 
833     def reset_refcounts(self, to_counts):
834         """
835         Reset reference counts for aliases so that they match the value passed
836         in `to_counts`.
837         """
838         for alias, cur_refcount in self.alias_refcount.copy().items():
839             unref_amount = cur_refcount - to_counts.get(alias, 0)
840             self.unref_alias(alias, unref_amount)
841 
842     def change_aliases(self, change_map):
843         """
844         Change the aliases in change_map (which maps old-alias -> new-alias),
845         relabelling any references to them in select columns and the where
846         clause.
847         """
848         assert set(change_map).isdisjoint(change_map.values())
849 
850         # 1. Update references in "select" (normal columns plus aliases),
851         # "group by" and "where".
852         self.where.relabel_aliases(change_map)
853         if isinstance(self.group_by, tuple):
854             self.group_by = tuple([col.relabeled_clone(change_map) for col in self.group_by])
855         self.select = tuple([col.relabeled_clone(change_map) for col in self.select])
856         self.annotations = self.annotations and {
857             key: col.relabeled_clone(change_map) for key, col in self.annotations.items()
858         }
859 
860         # 2. Rename the alias in the internal table/alias datastructures.
861         for old_alias, new_alias in change_map.items():
862             if old_alias not in self.alias_map:
863                 continue
864             alias_data = self.alias_map[old_alias].relabeled_clone(change_map)
865             self.alias_map[new_alias] = alias_data
866             self.alias_refcount[new_alias] = self.alias_refcount[old_alias]
867             del self.alias_refcount[old_alias]
868             del self.alias_map[old_alias]
869 
870             table_aliases = self.table_map[alias_data.table_name]
871             for pos, alias in enumerate(table_aliases):
872                 if alias == old_alias:
873                     table_aliases[pos] = new_alias
874                     break
875         self.external_aliases = {
876             # Table is aliased or it's being changed and thus is aliased.
877             change_map.get(alias, alias): (aliased or alias in change_map)
878             for alias, aliased in self.external_aliases.items()
879         }
880 
881     def bump_prefix(self, outer_query):
882         """
883         Change the alias prefix to the next letter in the alphabet in a way
884         that the outer query's aliases and this query's aliases will not
885         conflict. Even tables that previously had no alias will get an alias
886         after this call.
887         """
888         def prefix_gen():
889             """
890             Generate a sequence of characters in alphabetical order:
891                 -> 'A', 'B', 'C', ...
892 
893             When the alphabet is finished, the sequence will continue with the
894             Cartesian product:
895                 -> 'AA', 'AB', 'AC', ...
896             """
897             alphabet = ascii_uppercase
898             prefix = chr(ord(self.alias_prefix) + 1)
899             yield prefix
900             for n in count(1):
901                 seq = alphabet[alphabet.index(prefix):] if prefix else alphabet
902                 for s in product(seq, repeat=n):
903                     yield ''.join(s)
904                 prefix = None
905 
906         if self.alias_prefix != outer_query.alias_prefix:
907             # No clashes between self and outer query should be possible.
908             return
909 
910         # Explicitly avoid infinite loop. The constant divider is based on how
911         # much depth recursive subquery references add to the stack. This value
912         # might need to be adjusted when adding or removing function calls from
913         # the code path in charge of performing these operations.
914         local_recursion_limit = sys.getrecursionlimit() // 16
915         for pos, prefix in enumerate(prefix_gen()):
916             if prefix not in self.subq_aliases:
917                 self.alias_prefix = prefix
918                 break
919             if pos > local_recursion_limit:
920                 raise RecursionError(
921                     'Maximum recursion depth exceeded: too many subqueries.'
922                 )
923         self.subq_aliases = self.subq_aliases.union([self.alias_prefix])
924         outer_query.subq_aliases = outer_query.subq_aliases.union(self.subq_aliases)
925         self.change_aliases({
926             alias: '%s%d' % (self.alias_prefix, pos)
927             for pos, alias in enumerate(self.alias_map)
928         })
929 
930     def get_initial_alias(self):
931         """
932         Return the first alias for this query, after increasing its reference
933         count.
934         """
935         if self.alias_map:
936             alias = self.base_table
937             self.ref_alias(alias)
938         else:
939             alias = self.join(BaseTable(self.get_meta().db_table, None))
940         return alias
941 
942     def count_active_tables(self):
943         """
944         Return the number of tables in this query with a non-zero reference
945         count. After execution, the reference counts are zeroed, so tables
946         added in compiler will not be seen by this method.
947         """
948         return len([1 for count in self.alias_refcount.values() if count])
949 
950     def join(self, join, reuse=None):
951         """
952         Return an alias for the 'join', either reusing an existing alias for
953         that join or creating a new one. 'join' is either a
954         sql.datastructures.BaseTable or Join.
955 
956         The 'reuse' parameter can be either None which means all joins are
957         reusable, or it can be a set containing the aliases that can be reused.
958 
959         A join is always created as LOUTER if the lhs alias is LOUTER to make
960         sure chains like t1 LOUTER t2 INNER t3 aren't generated. All new
961         joins are created as LOUTER if the join is nullable.
962         """
963         reuse_aliases = [
964             a for a, j in self.alias_map.items()
965             if (reuse is None or a in reuse) and j.equals(join)
966         ]
967         if reuse_aliases:
968             if join.table_alias in reuse_aliases:
969                 reuse_alias = join.table_alias
970             else:
971                 # Reuse the most recent alias of the joined table
972                 # (a many-to-many relation may be joined multiple times).
973                 reuse_alias = reuse_aliases[-1]
974             self.ref_alias(reuse_alias)
975             return reuse_alias
976 
977         # No reuse is possible, so we need a new alias.
978         alias, _ = self.table_alias(join.table_name, create=True, filtered_relation=join.filtered_relation)
979         if join.join_type:
980             if self.alias_map[join.parent_alias].join_type == LOUTER or join.nullable:
981                 join_type = LOUTER
982             else:
983                 join_type = INNER
984             join.join_type = join_type
985         join.table_alias = alias
986         self.alias_map[alias] = join
987         return alias
988 
989     def join_parent_model(self, opts, model, alias, seen):
990         """
991         Make sure the given 'model' is joined in the query. If 'model' isn't
992         a parent of 'opts' or if it is None this method is a no-op.
993 
994         The 'alias' is the root alias for starting the join, 'seen' is a dict
995         of model -> alias of existing joins. It must also contain a mapping
996         of None -> some alias. This will be returned in the no-op case.
997         """
998         if model in seen:
999             return seen[model]
1000         chain = opts.get_base_chain(model)
1001         if not chain:
1002             return alias
1003         curr_opts = opts
1004         for int_model in chain:
1005             if int_model in seen:
1006                 curr_opts = int_model._meta
1007                 alias = seen[int_model]
1008                 continue
1009             # Proxy model have elements in base chain
1010             # with no parents, assign the new options
1011             # object and skip to the next base in that
1012             # case
1013             if not curr_opts.parents[int_model]:
1014                 curr_opts = int_model._meta
1015                 continue
1016             link_field = curr_opts.get_ancestor_link(int_model)
1017             join_info = self.setup_joins([link_field.name], curr_opts, alias)
1018             curr_opts = int_model._meta
1019             alias = seen[int_model] = join_info.joins[-1]
1020         return alias or seen[None]
1021 
1022     def add_annotation(self, annotation, alias, is_summary=False, select=True):
1023         """Add a single annotation expression to the Query."""
1024         annotation = annotation.resolve_expression(self, allow_joins=True, reuse=None,
1025                                                    summarize=is_summary)
1026         if select:
1027             self.append_annotation_mask([alias])
1028         else:
1029             self.set_annotation_mask(set(self.annotation_select).difference({alias}))
1030         self.annotations[alias] = annotation
1031 
1032     def resolve_expression(self, query, *args, **kwargs):
1033         clone = self.clone()
1034         # Subqueries need to use a different set of aliases than the outer query.
1035         clone.bump_prefix(query)
1036         clone.subquery = True
1037         clone.where.resolve_expression(query, *args, **kwargs)
1038         for key, value in clone.annotations.items():
1039             resolved = value.resolve_expression(query, *args, **kwargs)
1040             if hasattr(resolved, 'external_aliases'):
1041                 resolved.external_aliases.update(clone.external_aliases)
1042             clone.annotations[key] = resolved
1043         # Outer query's aliases are considered external.
1044         for alias, table in query.alias_map.items():
1045             clone.external_aliases[alias] = (
1046                 (isinstance(table, Join) and table.join_field.related_model._meta.db_table != alias) or
1047                 (isinstance(table, BaseTable) and table.table_name != table.table_alias)
1048             )
1049         return clone
1050 
1051     def get_external_cols(self):
1052         exprs = chain(self.annotations.values(), self.where.children)
1053         return [
1054             col for col in self._gen_cols(exprs, include_external=True)
1055             if col.alias in self.external_aliases
1056         ]
1057 
1058     def as_sql(self, compiler, connection):
1059         # Some backends (e.g. Oracle) raise an error when a subquery contains
1060         # unnecessary ORDER BY clause.
1061         if (
1062             self.subquery and
1063             not connection.features.ignores_unnecessary_order_by_in_subqueries
1064         ):
1065             self.clear_ordering(force=False)
1066         sql, params = self.get_compiler(connection=connection).as_sql()
1067         if self.subquery:
1068             sql = '(%s)' % sql
1069         return sql, params
1070 
1071     def resolve_lookup_value(self, value, can_reuse, allow_joins):
1072         if hasattr(value, 'resolve_expression'):
1073             value = value.resolve_expression(
1074                 self, reuse=can_reuse, allow_joins=allow_joins,
1075             )
1076         elif isinstance(value, (list, tuple)):
1077             # The items of the iterable may be expressions and therefore need
1078             # to be resolved independently.
1079             values = (
1080                 self.resolve_lookup_value(sub_value, can_reuse, allow_joins)
1081                 for sub_value in value
1082             )
1083             type_ = type(value)
1084             if hasattr(type_, '_make'):  # namedtuple
1085                 return type_(*values)
1086             return type_(values)
1087         return value
1088 
1089     def solve_lookup_type(self, lookup):
1090         """
1091         Solve the lookup type from the lookup (e.g.: 'foobar__id__icontains').
1092         """
1093         lookup_splitted = lookup.split(LOOKUP_SEP)
1094         if self.annotations:
1095             expression, expression_lookups = refs_expression(lookup_splitted, self.annotations)
1096             if expression:
1097                 return expression_lookups, (), expression
1098         _, field, _, lookup_parts = self.names_to_path(lookup_splitted, self.get_meta())
1099         field_parts = lookup_splitted[0:len(lookup_splitted) - len(lookup_parts)]
1100         if len(lookup_parts) > 1 and not field_parts:
1101             raise FieldError(
1102                 'Invalid lookup "%s" for model %s".' %
1103                 (lookup, self.get_meta().model.__name__)
1104             )
1105         return lookup_parts, field_parts, False
1106 
1107     def check_query_object_type(self, value, opts, field):
1108         """
1109         Check whether the object passed while querying is of the correct type.
1110         If not, raise a ValueError specifying the wrong object.
1111         """
1112         if hasattr(value, '_meta'):
1113             if not check_rel_lookup_compatibility(value._meta.model, opts, field):
1114                 raise ValueError(
1115                     'Cannot query "%s": Must be "%s" instance.' %
1116                     (value, opts.object_name))
1117 
1118     def check_related_objects(self, field, value, opts):
1119         """Check the type of object passed to query relations."""
1120         if field.is_relation:
1121             # Check that the field and the queryset use the same model in a
1122             # query like .filter(author=Author.objects.all()). For example, the
1123             # opts would be Author's (from the author field) and value.model
1124             # would be Author.objects.all() queryset's .model (Author also).
1125             # The field is the related field on the lhs side.
1126             if (isinstance(value, Query) and not value.has_select_fields and
1127                     not check_rel_lookup_compatibility(value.model, opts, field)):
1128                 raise ValueError(
1129                     'Cannot use QuerySet for "%s": Use a QuerySet for "%s".' %
1130                     (value.model._meta.object_name, opts.object_name)
1131                 )
1132             elif hasattr(value, '_meta'):
1133                 self.check_query_object_type(value, opts, field)
1134             elif hasattr(value, '__iter__'):
1135                 for v in value:
1136                     self.check_query_object_type(v, opts, field)
1137 
1138     def check_filterable(self, expression):
1139         """Raise an error if expression cannot be used in a WHERE clause."""
1140         if (
1141             hasattr(expression, 'resolve_expression') and
1142             not getattr(expression, 'filterable', True)
1143         ):
1144             raise NotSupportedError(
1145                 expression.__class__.__name__ + ' is disallowed in the filter '
1146                 'clause.'
1147             )
1148         if hasattr(expression, 'get_source_expressions'):
1149             for expr in expression.get_source_expressions():
1150                 self.check_filterable(expr)
1151 
1152     def build_lookup(self, lookups, lhs, rhs):
1153         """
1154         Try to extract transforms and lookup from given lhs.
1155 
1156         The lhs value is something that works like SQLExpression.
1157         The rhs value is what the lookup is going to compare against.
1158         The lookups is a list of names to extract using get_lookup()
1159         and get_transform().
1160         """
1161         # __exact is the default lookup if one isn't given.
1162         *transforms, lookup_name = lookups or ['exact']
1163         for name in transforms:
1164             lhs = self.try_transform(lhs, name)
1165         # First try get_lookup() so that the lookup takes precedence if the lhs
1166         # supports both transform and lookup for the name.
1167         lookup_class = lhs.get_lookup(lookup_name)
1168         if not lookup_class:
1169             if lhs.field.is_relation:
1170                 raise FieldError('Related Field got invalid lookup: {}'.format(lookup_name))
1171             # A lookup wasn't found. Try to interpret the name as a transform
1172             # and do an Exact lookup against it.
1173             lhs = self.try_transform(lhs, lookup_name)
1174             lookup_name = 'exact'
1175             lookup_class = lhs.get_lookup(lookup_name)
1176             if not lookup_class:
1177                 return
1178 
1179         lookup = lookup_class(lhs, rhs)
1180         # Interpret '__exact=None' as the sql 'is NULL'; otherwise, reject all
1181         # uses of None as a query value unless the lookup supports it.
1182         if lookup.rhs is None and not lookup.can_use_none_as_rhs:
1183             if lookup_name not in ('exact', 'iexact'):
1184                 raise ValueError("Cannot use None as a query value")
1185             return lhs.get_lookup('isnull')(lhs, True)
1186 
1187         # For Oracle '' is equivalent to null. The check must be done at this
1188         # stage because join promotion can't be done in the compiler. Using
1189         # DEFAULT_DB_ALIAS isn't nice but it's the best that can be done here.
1190         # A similar thing is done in is_nullable(), too.
1191         if (connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls and
1192                 lookup_name == 'exact' and lookup.rhs == ''):
1193             return lhs.get_lookup('isnull')(lhs, True)
1194 
1195         return lookup
1196 
1197     def try_transform(self, lhs, name):
1198         """
1199         Helper method for build_lookup(). Try to fetch and initialize
1200         a transform for name parameter from lhs.
1201         """
1202         transform_class = lhs.get_transform(name)
1203         if transform_class:
1204             return transform_class(lhs)
1205         else:
1206             output_field = lhs.output_field.__class__
1207             suggested_lookups = difflib.get_close_matches(name, output_field.get_lookups())
1208             if suggested_lookups:
1209                 suggestion = ', perhaps you meant %s?' % ' or '.join(suggested_lookups)
1210             else:
1211                 suggestion = '.'
1212             raise FieldError(
1213                 "Unsupported lookup '%s' for %s or join on the field not "
1214                 "permitted%s" % (name, output_field.__name__, suggestion)
1215             )
1216 
1217     def build_filter(self, filter_expr, branch_negated=False, current_negated=False,
1218                      can_reuse=None, allow_joins=True, split_subq=True,
1219                      check_filterable=True):
1220         """
1221         Build a WhereNode for a single filter clause but don't add it
1222         to this Query. Query.add_q() will then add this filter to the where
1223         Node.
1224 
1225         The 'branch_negated' tells us if the current branch contains any
1226         negations. This will be used to determine if subqueries are needed.
1227 
1228         The 'current_negated' is used to determine if the current filter is
1229         negated or not and this will be used to determine if IS NULL filtering
1230         is needed.
1231 
1232         The difference between current_negated and branch_negated is that
1233         branch_negated is set on first negation, but current_negated is
1234         flipped for each negation.
1235 
1236         Note that add_filter will not do any negating itself, that is done
1237         upper in the code by add_q().
1238 
1239         The 'can_reuse' is a set of reusable joins for multijoins.
1240 
1241         The method will create a filter clause that can be added to the current
1242         query. However, if the filter isn't added to the query then the caller
1243         is responsible for unreffing the joins used.
1244         """
1245         if isinstance(filter_expr, dict):
1246             raise FieldError("Cannot parse keyword query as dict")
1247         if isinstance(filter_expr, Q):
1248             return self._add_q(
1249                 filter_expr,
1250                 branch_negated=branch_negated,
1251                 current_negated=current_negated,
1252                 used_aliases=can_reuse,
1253                 allow_joins=allow_joins,
1254                 split_subq=split_subq,
1255                 check_filterable=check_filterable,
1256             )
1257         if hasattr(filter_expr, 'resolve_expression'):
1258             if not getattr(filter_expr, 'conditional', False):
1259                 raise TypeError('Cannot filter against a non-conditional expression.')
1260             condition = self.build_lookup(
1261                 ['exact'], filter_expr.resolve_expression(self, allow_joins=allow_joins), True
1262             )
1263             clause = self.where_class()
1264             clause.add(condition, AND)
1265             return clause, []
1266         arg, value = filter_expr
1267         if not arg:
1268             raise FieldError("Cannot parse keyword query %r" % arg)
1269         lookups, parts, reffed_expression = self.solve_lookup_type(arg)
1270 
1271         if check_filterable:
1272             self.check_filterable(reffed_expression)
1273 
1274         if not allow_joins and len(parts) > 1:
1275             raise FieldError("Joined field references are not permitted in this query")
1276 
1277         pre_joins = self.alias_refcount.copy()
1278         value = self.resolve_lookup_value(value, can_reuse, allow_joins)
1279         used_joins = {k for k, v in self.alias_refcount.items() if v > pre_joins.get(k, 0)}
1280 
1281         if check_filterable:
1282             self.check_filterable(value)
1283 
1284         clause = self.where_class()
1285         if reffed_expression:
1286             condition = self.build_lookup(lookups, reffed_expression, value)
1287             clause.add(condition, AND)
1288             return clause, []
1289 
1290         opts = self.get_meta()
1291         alias = self.get_initial_alias()
1292         allow_many = not branch_negated or not split_subq
1293 
1294         try:
1295             join_info = self.setup_joins(
1296                 parts, opts, alias, can_reuse=can_reuse, allow_many=allow_many,
1297             )
1298 
1299             # Prevent iterator from being consumed by check_related_objects()
1300             if isinstance(value, Iterator):
1301                 value = list(value)
1302             self.check_related_objects(join_info.final_field, value, join_info.opts)
1303 
1304             # split_exclude() needs to know which joins were generated for the
1305             # lookup parts
1306             self._lookup_joins = join_info.joins
1307         except MultiJoin as e:
1308             return self.split_exclude(filter_expr, can_reuse, e.names_with_path)
1309 
1310         # Update used_joins before trimming since they are reused to determine
1311         # which joins could be later promoted to INNER.
1312         used_joins.update(join_info.joins)
1313         targets, alias, join_list = self.trim_joins(join_info.targets, join_info.joins, join_info.path)
1314         if can_reuse is not None:
1315             can_reuse.update(join_list)
1316 
1317         if join_info.final_field.is_relation:
1318             # No support for transforms for relational fields
1319             num_lookups = len(lookups)
1320             if num_lookups > 1:
1321                 raise FieldError('Related Field got invalid lookup: {}'.format(lookups[0]))
1322             if len(targets) == 1:
1323                 col = self._get_col(targets[0], join_info.final_field, alias)
1324             else:
1325                 col = MultiColSource(alias, targets, join_info.targets, join_info.final_field)
1326         else:
1327             col = self._get_col(targets[0], join_info.final_field, alias)
1328 
1329         condition = self.build_lookup(lookups, col, value)
1330         lookup_type = condition.lookup_name
1331         clause.add(condition, AND)
1332 
1333         require_outer = lookup_type == 'isnull' and condition.rhs is True and not current_negated
1334         if current_negated and (lookup_type != 'isnull' or condition.rhs is False) and condition.rhs is not None:
1335             require_outer = True
1336             if lookup_type != 'isnull':
1337                 # The condition added here will be SQL like this:
1338                 # NOT (col IS NOT NULL), where the first NOT is added in
1339                 # upper layers of code. The reason for addition is that if col
1340                 # is null, then col != someval will result in SQL "unknown"
1341                 # which isn't the same as in Python. The Python None handling
1342                 # is wanted, and it can be gotten by
1343                 # (col IS NULL OR col != someval)
1344                 #   <=>
1345                 # NOT (col IS NOT NULL AND col = someval).
1346                 if (
1347                     self.is_nullable(targets[0]) or
1348                     self.alias_map[join_list[-1]].join_type == LOUTER
1349                 ):
1350                     lookup_class = targets[0].get_lookup('isnull')
1351                     col = self._get_col(targets[0], join_info.targets[0], alias)
1352                     clause.add(lookup_class(col, False), AND)
1353                 # If someval is a nullable column, someval IS NOT NULL is
1354                 # added.
1355                 if isinstance(value, Col) and self.is_nullable(value.target):
1356                     lookup_class = value.target.get_lookup('isnull')
1357                     clause.add(lookup_class(value, False), AND)
1358         return clause, used_joins if not require_outer else ()
1359 
1360     def add_filter(self, filter_clause):
1361         self.add_q(Q(**{filter_clause[0]: filter_clause[1]}))
1362 
1363     def add_q(self, q_object):
1364         """
1365         A preprocessor for the internal _add_q(). Responsible for doing final
1366         join promotion.
1367         """
1368         # For join promotion this case is doing an AND for the added q_object
1369         # and existing conditions. So, any existing inner join forces the join
1370         # type to remain inner. Existing outer joins can however be demoted.
1371         # (Consider case where rel_a is LOUTER and rel_a__col=1 is added - if
1372         # rel_a doesn't produce any rows, then the whole condition must fail.
1373         # So, demotion is OK.
1374         existing_inner = {a for a in self.alias_map if self.alias_map[a].join_type == INNER}
1375         clause, _ = self._add_q(q_object, self.used_aliases)
1376         if clause:
1377             self.where.add(clause, AND)
1378         self.demote_joins(existing_inner)
1379 
1380     def build_where(self, filter_expr):
1381         return self.build_filter(filter_expr, allow_joins=False)[0]
1382 
1383     def _add_q(self, q_object, used_aliases, branch_negated=False,
1384                current_negated=False, allow_joins=True, split_subq=True,
1385                check_filterable=True):
1386         """Add a Q-object to the current filter."""
1387         connector = q_object.connector
1388         current_negated = current_negated ^ q_object.negated
1389         branch_negated = branch_negated or q_object.negated
1390         target_clause = self.where_class(connector=connector,
1391                                          negated=q_object.negated)
1392         joinpromoter = JoinPromoter(q_object.connector, len(q_object.children), current_negated)
1393         for child in q_object.children:
1394             child_clause, needed_inner = self.build_filter(
1395                 child, can_reuse=used_aliases, branch_negated=branch_negated,
1396                 current_negated=current_negated, allow_joins=allow_joins,
1397                 split_subq=split_subq, check_filterable=check_filterable,
1398             )
1399             joinpromoter.add_votes(needed_inner)
1400             if child_clause:
1401                 target_clause.add(child_clause, connector)
1402         needed_inner = joinpromoter.update_join_types(self)
1403         return target_clause, needed_inner
1404 
1405     def build_filtered_relation_q(self, q_object, reuse, branch_negated=False, current_negated=False):
1406         """Add a FilteredRelation object to the current filter."""
1407         connector = q_object.connector
1408         current_negated ^= q_object.negated
1409         branch_negated = branch_negated or q_object.negated
1410         target_clause = self.where_class(connector=connector, negated=q_object.negated)
1411         for child in q_object.children:
1412             if isinstance(child, Node):
1413                 child_clause = self.build_filtered_relation_q(
1414                     child, reuse=reuse, branch_negated=branch_negated,
1415                     current_negated=current_negated,
1416                 )
1417             else:
1418                 child_clause, _ = self.build_filter(
1419                     child, can_reuse=reuse, branch_negated=branch_negated,
1420                     current_negated=current_negated,
1421                     allow_joins=True, split_subq=False,
1422                 )
1423             target_clause.add(child_clause, connector)
1424         return target_clause
1425 
1426     def add_filtered_relation(self, filtered_relation, alias):
1427         filtered_relation.alias = alias
1428         lookups = dict(get_children_from_q(filtered_relation.condition))
1429         relation_lookup_parts, relation_field_parts, _ = self.solve_lookup_type(filtered_relation.relation_name)
1430         if relation_lookup_parts:
1431             raise ValueError(
1432                 "FilteredRelation's relation_name cannot contain lookups "
1433                 "(got %r)." % filtered_relation.relation_name
1434             )
1435         for lookup in chain(lookups):
1436             lookup_parts, lookup_field_parts, _ = self.solve_lookup_type(lookup)
1437             shift = 2 if not lookup_parts else 1
1438             lookup_field_path = lookup_field_parts[:-shift]
1439             for idx, lookup_field_part in enumerate(lookup_field_path):
1440                 if len(relation_field_parts) > idx:
1441                     if relation_field_parts[idx] != lookup_field_part:
1442                         raise ValueError(
1443                             "FilteredRelation's condition doesn't support "
1444                             "relations outside the %r (got %r)."
1445                             % (filtered_relation.relation_name, lookup)
1446                         )
1447                 else:
1448                     raise ValueError(
1449                         "FilteredRelation's condition doesn't support nested "
1450                         "relations deeper than the relation_name (got %r for "
1451                         "%r)." % (lookup, filtered_relation.relation_name)
1452                     )
1453         self._filtered_relations[filtered_relation.alias] = filtered_relation
1454 
1455     def names_to_path(self, names, opts, allow_many=True, fail_on_missing=False):
1456         """
1457         Walk the list of names and turns them into PathInfo tuples. A single
1458         name in 'names' can generate multiple PathInfos (m2m, for example).
1459 
1460         'names' is the path of names to travel, 'opts' is the model Options we
1461         start the name resolving from, 'allow_many' is as for setup_joins().
1462         If fail_on_missing is set to True, then a name that can't be resolved
1463         will generate a FieldError.
1464 
1465         Return a list of PathInfo tuples. In addition return the final field
1466         (the last used join field) and target (which is a field guaranteed to
1467         contain the same value as the final field). Finally, return those names
1468         that weren't found (which are likely transforms and the final lookup).
1469         """
1470         path, names_with_path = [], []
1471         for pos, name in enumerate(names):
1472             cur_names_with_path = (name, [])
1473             if name == 'pk':
1474                 name = opts.pk.name
1475 
1476             field = None
1477             filtered_relation = None
1478             try:
1479                 field = opts.get_field(name)
1480             except FieldDoesNotExist:
1481                 if name in self.annotation_select:
1482                     field = self.annotation_select[name].output_field
1483                 elif name in self._filtered_relations and pos == 0:
1484                     filtered_relation = self._filtered_relations[name]
1485                     if LOOKUP_SEP in filtered_relation.relation_name:
1486                         parts = filtered_relation.relation_name.split(LOOKUP_SEP)
1487                         filtered_relation_path, field, _, _ = self.names_to_path(
1488                             parts, opts, allow_many, fail_on_missing,
1489                         )
1490                         path.extend(filtered_relation_path[:-1])
1491                     else:
1492                         field = opts.get_field(filtered_relation.relation_name)
1493             if field is not None:
1494                 # Fields that contain one-to-many relations with a generic
1495                 # model (like a GenericForeignKey) cannot generate reverse
1496                 # relations and therefore cannot be used for reverse querying.
1497                 if field.is_relation and not field.related_model:
1498                     raise FieldError(
1499                         "Field %r does not generate an automatic reverse "
1500                         "relation and therefore cannot be used for reverse "
1501                         "querying. If it is a GenericForeignKey, consider "
1502                         "adding a GenericRelation." % name
1503                     )
1504                 try:
1505                     model = field.model._meta.concrete_model
1506                 except AttributeError:
1507                     # QuerySet.annotate() may introduce fields that aren't
1508                     # attached to a model.
1509                     model = None
1510             else:
1511                 # We didn't find the current field, so move position back
1512                 # one step.
1513                 pos -= 1
1514                 if pos == -1 or fail_on_missing:
1515                     available = sorted([
1516                         *get_field_names_from_opts(opts),
1517                         *self.annotation_select,
1518                         *self._filtered_relations,
1519                     ])
1520                     raise FieldError("Cannot resolve keyword '%s' into field. "
1521                                      "Choices are: %s" % (name, ", ".join(available)))
1522                 break
1523             # Check if we need any joins for concrete inheritance cases (the
1524             # field lives in parent, but we are currently in one of its
1525             # children)
1526             if model is not opts.model:
1527                 path_to_parent = opts.get_path_to_parent(model)
1528                 if path_to_parent:
1529                     path.extend(path_to_parent)
1530                     cur_names_with_path[1].extend(path_to_parent)
1531                     opts = path_to_parent[-1].to_opts
1532             if hasattr(field, 'get_path_info'):
1533                 pathinfos = field.get_path_info(filtered_relation)
1534                 if not allow_many:
1535                     for inner_pos, p in enumerate(pathinfos):
1536                         if p.m2m:
1537                             cur_names_with_path[1].extend(pathinfos[0:inner_pos + 1])
1538                             names_with_path.append(cur_names_with_path)
1539                             raise MultiJoin(pos + 1, names_with_path)
1540                 last = pathinfos[-1]
1541                 path.extend(pathinfos)
1542                 final_field = last.join_field
1543                 opts = last.to_opts
1544                 targets = last.target_fields
1545                 cur_names_with_path[1].extend(pathinfos)
1546                 names_with_path.append(cur_names_with_path)
1547             else:
1548                 # Local non-relational field.
1549                 final_field = field
1550                 targets = (field,)
1551                 if fail_on_missing and pos + 1 != len(names):
1552                     raise FieldError(
1553                         "Cannot resolve keyword %r into field. Join on '%s'"
1554                         " not permitted." % (names[pos + 1], name))
1555                 break
1556         return path, final_field, targets, names[pos + 1:]
1557 
1558     def setup_joins(self, names, opts, alias, can_reuse=None, allow_many=True):
1559         """
1560         Compute the necessary table joins for the passage through the fields
1561         given in 'names'. 'opts' is the Options class for the current model
1562         (which gives the table we are starting from), 'alias' is the alias for
1563         the table to start the joining from.
1564 
1565         The 'can_reuse' defines the reverse foreign key joins we can reuse. It
1566         can be None in which case all joins are reusable or a set of aliases
1567         that can be reused. Note that non-reverse foreign keys are always
1568         reusable when using setup_joins().
1569 
1570         If 'allow_many' is False, then any reverse foreign key seen will
1571         generate a MultiJoin exception.
1572 
1573         Return the final field involved in the joins, the target field (used
1574         for any 'where' constraint), the final 'opts' value, the joins, the
1575         field path traveled to generate the joins, and a transform function
1576         that takes a field and alias and is equivalent to `field.get_col(alias)`
1577         in the simple case but wraps field transforms if they were included in
1578         names.
1579 
1580         The target field is the field containing the concrete value. Final
1581         field can be something different, for example foreign key pointing to
1582         that value. Final field is needed for example in some value
1583         conversions (convert 'obj' in fk__id=obj to pk val using the foreign
1584         key field for example).
1585         """
1586         joins = [alias]
1587         # The transform can't be applied yet, as joins must be trimmed later.
1588         # To avoid making every caller of this method look up transforms
1589         # directly, compute transforms here and create a partial that converts
1590         # fields to the appropriate wrapped version.
1591 
1592         def final_transformer(field, alias):
1593             if not self.alias_cols:
1594                 alias = None
1595             return field.get_col(alias)
1596 
1597         # Try resolving all the names as fields first. If there's an error,
1598         # treat trailing names as lookups until a field can be resolved.
1599         last_field_exception = None
1600         for pivot in range(len(names), 0, -1):
1601             try:
1602                 path, final_field, targets, rest = self.names_to_path(
1603                     names[:pivot], opts, allow_many, fail_on_missing=True,
1604                 )
1605             except FieldError as exc:
1606                 if pivot == 1:
1607                     # The first item cannot be a lookup, so it's safe
1608                     # to raise the field error here.
1609                     raise
1610                 else:
1611                     last_field_exception = exc
1612             else:
1613                 # The transforms are the remaining items that couldn't be
1614                 # resolved into fields.
1615                 transforms = names[pivot:]
1616                 break
1617         for name in transforms:
1618             def transform(field, alias, *, name, previous):
1619                 try:
1620                     wrapped = previous(field, alias)
1621                     return self.try_transform(wrapped, name)
1622                 except FieldError:
1623                     # FieldError is raised if the transform doesn't exist.
1624                     if isinstance(final_field, Field) and last_field_exception:
1625                         raise last_field_exception
1626                     else:
1627                         raise
1628             final_transformer = functools.partial(transform, name=name, previous=final_transformer)
1629         # Then, add the path to the query's joins. Note that we can't trim
1630         # joins at this stage - we will need the information about join type
1631         # of the trimmed joins.
1632         for join in path:
1633             if join.filtered_relation:
1634                 filtered_relation = join.filtered_relation.clone()
1635                 table_alias = filtered_relation.alias
1636             else:
1637                 filtered_relation = None
1638                 table_alias = None
1639             opts = join.to_opts
1640             if join.direct:
1641                 nullable = self.is_nullable(join.join_field)
1642             else:
1643                 nullable = True
1644             connection = Join(
1645                 opts.db_table, alias, table_alias, INNER, join.join_field,
1646                 nullable, filtered_relation=filtered_relation,
1647             )
1648             reuse = can_reuse if join.m2m else None
1649             alias = self.join(connection, reuse=reuse)
1650             joins.append(alias)
1651             if filtered_relation:
1652                 filtered_relation.path = joins[:]
1653         return JoinInfo(final_field, targets, opts, joins, path, final_transformer)
1654 
1655     def trim_joins(self, targets, joins, path):
1656         """
1657         The 'target' parameter is the final field being joined to, 'joins'
1658         is the full list of join aliases. The 'path' contain the PathInfos
1659         used to create the joins.
1660 
1661         Return the final target field and table alias and the new active
1662         joins.
1663 
1664         Always trim any direct join if the target column is already in the
1665         previous table. Can't trim reverse joins as it's unknown if there's
1666         anything on the other side of the join.
1667         """
1668         joins = joins[:]
1669         for pos, info in enumerate(reversed(path)):
1670             if len(joins) == 1 or not info.direct:
1671                 break
1672             if info.filtered_relation:
1673                 break
1674             join_targets = {t.column for t in info.join_field.foreign_related_fields}
1675             cur_targets = {t.column for t in targets}
1676             if not cur_targets.issubset(join_targets):
1677                 break
1678             targets_dict = {r[1].column: r[0] for r in info.join_field.related_fields if r[1].column in cur_targets}
1679             targets = tuple(targets_dict[t.column] for t in targets)
1680             self.unref_alias(joins.pop())
1681         return targets, joins[-1], joins
1682 
1683     @classmethod
1684     def _gen_cols(cls, exprs, include_external=False):
1685         for expr in exprs:
1686             if isinstance(expr, Col):
1687                 yield expr
1688             elif include_external and callable(getattr(expr, 'get_external_cols', None)):
1689                 yield from expr.get_external_cols()
1690             else:
1691                 yield from cls._gen_cols(
1692                     expr.get_source_expressions(),
1693                     include_external=include_external,
1694                 )
1695 
1696     @classmethod
1697     def _gen_col_aliases(cls, exprs):
1698         yield from (expr.alias for expr in cls._gen_cols(exprs))
1699 
1700     def resolve_ref(self, name, allow_joins=True, reuse=None, summarize=False):
1701         annotation = self.annotations.get(name)
1702         if annotation is not None:
1703             if not allow_joins:
1704                 for alias in self._gen_col_aliases([annotation]):
1705                     if isinstance(self.alias_map[alias], Join):
1706                         raise FieldError(
1707                             'Joined field references are not permitted in '
1708                             'this query'
1709                         )
1710             if summarize:
1711                 # Summarize currently means we are doing an aggregate() query
1712                 # which is executed as a wrapped subquery if any of the
1713                 # aggregate() elements reference an existing annotation. In
1714                 # that case we need to return a Ref to the subquery's annotation.
1715                 if name not in self.annotation_select:
1716                     raise FieldError(
1717                         "Cannot aggregate over the '%s' alias. Use annotate() "
1718                         "to promote it." % name
1719                     )
1720                 return Ref(name, self.annotation_select[name])
1721             else:
1722                 return annotation
1723         else:
1724             field_list = name.split(LOOKUP_SEP)
1725             annotation = self.annotations.get(field_list[0])
1726             if annotation is not None:
1727                 for transform in field_list[1:]:
1728                     annotation = self.try_transform(annotation, transform)
1729                 return annotation
1730             join_info = self.setup_joins(field_list, self.get_meta(), self.get_initial_alias(), can_reuse=reuse)
1731             targets, final_alias, join_list = self.trim_joins(join_info.targets, join_info.joins, join_info.path)
1732             if not allow_joins and len(join_list) > 1:
1733                 raise FieldError('Joined field references are not permitted in this query')
1734             if len(targets) > 1:
1735                 raise FieldError("Referencing multicolumn fields with F() objects "
1736                                  "isn't supported")
1737             # Verify that the last lookup in name is a field or a transform:
1738             # transform_function() raises FieldError if not.
1739             transform = join_info.transform_function(targets[0], final_alias)
1740             if reuse is not None:
1741                 reuse.update(join_list)
1742             return transform
1743 
1744     def split_exclude(self, filter_expr, can_reuse, names_with_path):
1745         """
1746         When doing an exclude against any kind of N-to-many relation, we need
1747         to use a subquery. This method constructs the nested query, given the
1748         original exclude filter (filter_expr) and the portion up to the first
1749         N-to-many relation field.
1750 
1751         For example, if the origin filter is ~Q(child__name='foo'), filter_expr
1752         is ('child__name', 'foo') and can_reuse is a set of joins usable for
1753         filters in the original query.
1754 
1755         We will turn this into equivalent of:
1756             WHERE NOT EXISTS(
1757                 SELECT 1
1758                 FROM child
1759                 WHERE name = 'foo' AND child.parent_id = parent.id
1760                 LIMIT 1
1761             )
1762         """
1763         filter_lhs, filter_rhs = filter_expr
1764         if isinstance(filter_rhs, OuterRef):
1765             filter_expr = (filter_lhs, OuterRef(filter_rhs))
1766         elif isinstance(filter_rhs, F):
1767             filter_expr = (filter_lhs, OuterRef(filter_rhs.name))
1768         # Generate the inner query.
1769         query = Query(self.model)
1770         query._filtered_relations = self._filtered_relations
1771         query.add_filter(filter_expr)
1772         query.clear_ordering(force=True)
1773         # Try to have as simple as possible subquery -> trim leading joins from
1774         # the subquery.
1775         trimmed_prefix, contains_louter = query.trim_start(names_with_path)
1776 
1777         col = query.select[0]
1778         select_field = col.target
1779         alias = col.alias
1780         if alias in can_reuse:
1781             pk = select_field.model._meta.pk
1782             # Need to add a restriction so that outer query's filters are in effect for
1783             # the subquery, too.
1784             query.bump_prefix(self)
1785             lookup_class = select_field.get_lookup('exact')
1786             # Note that the query.select[0].alias is different from alias
1787             # due to bump_prefix above.
1788             lookup = lookup_class(pk.get_col(query.select[0].alias),
1789                                   pk.get_col(alias))
1790             query.where.add(lookup, AND)
1791             query.external_aliases[alias] = True
1792 
1793         lookup_class = select_field.get_lookup('exact')
1794         lookup = lookup_class(col, ResolvedOuterRef(trimmed_prefix))
1795         query.where.add(lookup, AND)
1796         condition, needed_inner = self.build_filter(Exists(query))
1797 
1798         if contains_louter:
1799             or_null_condition, _ = self.build_filter(
1800                 ('%s__isnull' % trimmed_prefix, True),
1801                 current_negated=True, branch_negated=True, can_reuse=can_reuse)
1802             condition.add(or_null_condition, OR)
1803             # Note that the end result will be:
1804             # (outercol NOT IN innerq AND outercol IS NOT NULL) OR outercol IS NULL.
1805             # This might look crazy but due to how IN works, this seems to be
1806             # correct. If the IS NOT NULL check is removed then outercol NOT
1807             # IN will return UNKNOWN. If the IS NULL check is removed, then if
1808             # outercol IS NULL we will not match the row.
1809         return condition, needed_inner
1810 
1811     def set_empty(self):
1812         self.where.add(NothingNode(), AND)
1813         for query in self.combined_queries:
1814             query.set_empty()
1815 
1816     def is_empty(self):
1817         return any(isinstance(c, NothingNode) for c in self.where.children)
1818 
1819     def set_limits(self, low=None, high=None):
1820         """
1821         Adjust the limits on the rows retrieved. Use low/high to set these,
1822         as it makes it more Pythonic to read and write. When the SQL query is
1823         created, convert them to the appropriate offset and limit values.
1824 
1825         Apply any limits passed in here to the existing constraints. Add low
1826         to the current low value and clamp both to any existing high value.
1827         """
1828         if high is not None:
1829             if self.high_mark is not None:
1830                 self.high_mark = min(self.high_mark, self.low_mark + high)
1831             else:
1832                 self.high_mark = self.low_mark + high
1833         if low is not None:
1834             if self.high_mark is not None:
1835                 self.low_mark = min(self.high_mark, self.low_mark + low)
1836             else:
1837                 self.low_mark = self.low_mark + low
1838 
1839         if self.low_mark == self.high_mark:
1840             self.set_empty()
1841 
1842     def clear_limits(self):
1843         """Clear any existing limits."""
1844         self.low_mark, self.high_mark = 0, None
1845 
1846     @property
1847     def is_sliced(self):
1848         return self.low_mark != 0 or self.high_mark is not None
1849 
1850     def has_limit_one(self):
1851         return self.high_mark is not None and (self.high_mark - self.low_mark) == 1
1852 
1853     def can_filter(self):
1854         """
1855         Return True if adding filters to this instance is still possible.
1856 
1857         Typically, this means no limits or offsets have been put on the results.
1858         """
1859         return not self.is_sliced
1860 
1861     def clear_select_clause(self):
1862         """Remove all fields from SELECT clause."""
1863         self.select = ()
1864         self.default_cols = False
1865         self.select_related = False
1866         self.set_extra_mask(())
1867         self.set_annotation_mask(())
1868 
1869     def clear_select_fields(self):
1870         """
1871         Clear the list of fields to select (but not extra_select columns).
1872         Some queryset types completely replace any existing list of select
1873         columns.
1874         """
1875         self.select = ()
1876         self.values_select = ()
1877 
1878     def add_select_col(self, col, name):
1879         self.select += col,
1880         self.values_select += name,
1881 
1882     def set_select(self, cols):
1883         self.default_cols = False
1884         self.select = tuple(cols)
1885 
1886     def add_distinct_fields(self, *field_names):
1887         """
1888         Add and resolve the given fields to the query's "distinct on" clause.
1889         """
1890         self.distinct_fields = field_names
1891         self.distinct = True
1892 
1893     def add_fields(self, field_names, allow_m2m=True):
1894         """
1895         Add the given (model) fields to the select set. Add the field names in
1896         the order specified.
1897         """
1898         alias = self.get_initial_alias()
1899         opts = self.get_meta()
1900 
1901         try:
1902             cols = []
1903             for name in field_names:
1904                 # Join promotion note - we must not remove any rows here, so
1905                 # if there is no existing joins, use outer join.
1906                 join_info = self.setup_joins(name.split(LOOKUP_SEP), opts, alias, allow_many=allow_m2m)
1907                 targets, final_alias, joins = self.trim_joins(
1908                     join_info.targets,
1909                     join_info.joins,
1910                     join_info.path,
1911                 )
1912                 for target in targets:
1913                     cols.append(join_info.transform_function(target, final_alias))
1914             if cols:
1915                 self.set_select(cols)
1916         except MultiJoin:
1917             raise FieldError("Invalid field name: '%s'" % name)
1918         except FieldError:
1919             if LOOKUP_SEP in name:
1920                 # For lookups spanning over relationships, show the error
1921                 # from the model on which the lookup failed.
1922                 raise
1923             elif name in self.annotations:
1924                 raise FieldError(
1925                     "Cannot select the '%s' alias. Use annotate() to promote "
1926                     "it." % name
1927                 )
1928             else:
1929                 names = sorted([
1930                     *get_field_names_from_opts(opts), *self.extra,
1931                     *self.annotation_select, *self._filtered_relations
1932                 ])
1933                 raise FieldError("Cannot resolve keyword %r into field. "
1934                                  "Choices are: %s" % (name, ", ".join(names)))
1935 
1936     def add_ordering(self, *ordering):
1937         """
1938         Add items from the 'ordering' sequence to the query's "order by"
1939         clause. These items are either field names (not column names) --
1940         possibly with a direction prefix ('-' or '?') -- or OrderBy
1941         expressions.
1942 
1943         If 'ordering' is empty, clear all ordering from the query.
1944         """
1945         errors = []
1946         for item in ordering:
1947             if isinstance(item, str):
1948                 if item == '?':
1949                     continue
1950                 if item.startswith('-'):
1951                     item = item[1:]
1952                 if item in self.annotations:
1953                     continue
1954                 if self.extra and item in self.extra:
1955                     continue
1956                 # names_to_path() validates the lookup. A descriptive
1957                 # FieldError will be raise if it's not.
1958                 self.names_to_path(item.split(LOOKUP_SEP), self.model._meta)
1959             elif not hasattr(item, 'resolve_expression'):
1960                 errors.append(item)
1961             if getattr(item, 'contains_aggregate', False):
1962                 raise FieldError(
1963                     'Using an aggregate in order_by() without also including '
1964                     'it in annotate() is not allowed: %s' % item
1965                 )
1966         if errors:
1967             raise FieldError('Invalid order_by arguments: %s' % errors)
1968         if ordering:
1969             self.order_by += ordering
1970         else:
1971             self.default_ordering = False
1972 
1973     def clear_ordering(self, force=False, clear_default=True):
1974         """
1975         Remove any ordering settings if the current query allows it without
1976         side effects, set 'force' to True to clear the ordering regardless.
1977         If 'clear_default' is True, there will be no ordering in the resulting
1978         query (not even the model's default).
1979         """
1980         if not force and (self.is_sliced or self.distinct_fields or self.select_for_update):
1981             return
1982         self.order_by = ()
1983         self.extra_order_by = ()
1984         if clear_default:
1985             self.default_ordering = False
1986 
1987     def set_group_by(self, allow_aliases=True):
1988         """
1989         Expand the GROUP BY clause required by the query.
1990 
1991         This will usually be the set of all non-aggregate fields in the
1992         return data. If the database backend supports grouping by the
1993         primary key, and the query would be equivalent, the optimization
1994         will be made automatically.
1995         """
1996         # Column names from JOINs to check collisions with aliases.
1997         if allow_aliases:
1998             column_names = set()
1999             seen_models = set()
2000             for join in list(self.alias_map.values())[1:]:  # Skip base table.
2001                 model = join.join_field.related_model
2002                 if model not in seen_models:
2003                     column_names.update({
2004                         field.column
2005                         for field in model._meta.local_concrete_fields
2006                     })
2007                     seen_models.add(model)
2008 
2009         group_by = list(self.select)
2010         if self.annotation_select:
2011             for alias, annotation in self.annotation_select.items():
2012                 if not allow_aliases or alias in column_names:
2013                     alias = None
2014                 group_by_cols = annotation.get_group_by_cols(alias=alias)
2015                 group_by.extend(group_by_cols)
2016         self.group_by = tuple(group_by)
2017 
2018     def add_select_related(self, fields):
2019         """
2020         Set up the select_related data structure so that we only select
2021         certain related models (as opposed to all models, when
2022         self.select_related=True).
2023         """
2024         if isinstance(self.select_related, bool):
2025             field_dict = {}
2026         else:
2027             field_dict = self.select_related
2028         for field in fields:
2029             d = field_dict
2030             for part in field.split(LOOKUP_SEP):
2031                 d = d.setdefault(part, {})
2032         self.select_related = field_dict
2033 
2034     def add_extra(self, select, select_params, where, params, tables, order_by):
2035         """
2036         Add data to the various extra_* attributes for user-created additions
2037         to the query.
2038         """
2039         if select:
2040             # We need to pair any placeholder markers in the 'select'
2041             # dictionary with their parameters in 'select_params' so that
2042             # subsequent updates to the select dictionary also adjust the
2043             # parameters appropriately.
2044             select_pairs = {}
2045             if select_params:
2046                 param_iter = iter(select_params)
2047             else:
2048                 param_iter = iter([])
2049             for name, entry in select.items():
2050                 entry = str(entry)
2051                 entry_params = []
2052                 pos = entry.find("%s")
2053                 while pos != -1:
2054                     if pos == 0 or entry[pos - 1] != '%':
2055                         entry_params.append(next(param_iter))
2056                     pos = entry.find("%s", pos + 2)
2057                 select_pairs[name] = (entry, entry_params)
2058             self.extra.update(select_pairs)
2059         if where or params:
2060             self.where.add(ExtraWhere(where, params), AND)
2061         if tables:
2062             self.extra_tables += tuple(tables)
2063         if order_by:
2064             self.extra_order_by = order_by
2065 
2066     def clear_deferred_loading(self):
2067         """Remove any fields from the deferred loading set."""
2068         self.deferred_loading = (frozenset(), True)
2069 
2070     def add_deferred_loading(self, field_names):
2071         """
2072         Add the given list of model field names to the set of fields to
2073         exclude from loading from the database when automatic column selection
2074         is done. Add the new field names to any existing field names that
2075         are deferred (or removed from any existing field names that are marked
2076         as the only ones for immediate loading).
2077         """
2078         # Fields on related models are stored in the literal double-underscore
2079         # format, so that we can use a set datastructure. We do the foo__bar
2080         # splitting and handling when computing the SQL column names (as part of
2081         # get_columns()).
2082         existing, defer = self.deferred_loading
2083         if defer:
2084             # Add to existing deferred names.
2085             self.deferred_loading = existing.union(field_names), True
2086         else:
2087             # Remove names from the set of any existing "immediate load" names.
2088             self.deferred_loading = existing.difference(field_names), False
2089 
2090     def add_immediate_loading(self, field_names):
2091         """
2092         Add the given list of model field names to the set of fields to
2093         retrieve when the SQL is executed ("immediate loading" fields). The
2094         field names replace any existing immediate loading field names. If
2095         there are field names already specified for deferred loading, remove
2096         those names from the new field_names before storing the new names
2097         for immediate loading. (That is, immediate loading overrides any
2098         existing immediate values, but respects existing deferrals.)
2099         """
2100         existing, defer = self.deferred_loading
2101         field_names = set(field_names)
2102         if 'pk' in field_names:
2103             field_names.remove('pk')
2104             field_names.add(self.get_meta().pk.name)
2105 
2106         if defer:
2107             # Remove any existing deferred names from the current set before
2108             # setting the new names.
2109             self.deferred_loading = field_names.difference(existing), False
2110         else:
2111             # Replace any existing "immediate load" field names.
2112             self.deferred_loading = frozenset(field_names), False
2113 
2114     def get_loaded_field_names(self):
2115         """
2116         If any fields are marked to be deferred, return a dictionary mapping
2117         models to a set of names in those fields that will be loaded. If a
2118         model is not in the returned dictionary, none of its fields are
2119         deferred.
2120 
2121         If no fields are marked for deferral, return an empty dictionary.
2122         """
2123         # We cache this because we call this function multiple times
2124         # (compiler.fill_related_selections, query.iterator)
2125         try:
2126             return self._loaded_field_names_cache
2127         except AttributeError:
2128             collection = {}
2129             self.deferred_to_data(collection, self.get_loaded_field_names_cb)
2130             self._loaded_field_names_cache = collection
2131             return collection
2132 
2133     def get_loaded_field_names_cb(self, target, model, fields):
2134         """Callback used by get_deferred_field_names()."""
2135         target[model] = {f.attname for f in fields}
2136 
2137     def set_annotation_mask(self, names):
2138         """Set the mask of annotations that will be returned by the SELECT."""
2139         if names is None:
2140             self.annotation_select_mask = None
2141         else:
2142             self.annotation_select_mask = set(names)
2143         self._annotation_select_cache = None
2144 
2145     def append_annotation_mask(self, names):
2146         if self.annotation_select_mask is not None:
2147             self.set_annotation_mask(self.annotation_select_mask.union(names))
2148 
2149     def set_extra_mask(self, names):
2150         """
2151         Set the mask of extra select items that will be returned by SELECT.
2152         Don't remove them from the Query since they might be used later.
2153         """
2154         if names is None:
2155             self.extra_select_mask = None
2156         else:
2157             self.extra_select_mask = set(names)
2158         self._extra_select_cache = None
2159 
2160     def set_values(self, fields):
2161         self.select_related = False
2162         self.clear_deferred_loading()
2163         self.clear_select_fields()
2164 
2165         if fields:
2166             field_names = []
2167             extra_names = []
2168             annotation_names = []
2169             if not self.extra and not self.annotations:
2170                 # Shortcut - if there are no extra or annotations, then
2171                 # the values() clause must be just field names.
2172                 field_names = list(fields)
2173             else:
2174                 self.default_cols = False
2175                 for f in fields:
2176                     if f in self.extra_select:
2177                         extra_names.append(f)
2178                     elif f in self.annotation_select:
2179                         annotation_names.append(f)
2180                     else:
2181                         field_names.append(f)
2182             self.set_extra_mask(extra_names)
2183             self.set_annotation_mask(annotation_names)
2184             selected = frozenset(field_names + extra_names + annotation_names)
2185         else:
2186             field_names = [f.attname for f in self.model._meta.concrete_fields]
2187             selected = frozenset(field_names)
2188         # Selected annotations must be known before setting the GROUP BY
2189         # clause.
2190         if self.group_by is True:
2191             self.add_fields((f.attname for f in self.model._meta.concrete_fields), False)
2192             # Disable GROUP BY aliases to avoid orphaning references to the
2193             # SELECT clause which is about to be cleared.
2194             self.set_group_by(allow_aliases=False)
2195             self.clear_select_fields()
2196         elif self.group_by:
2197             # Resolve GROUP BY annotation references if they are not part of
2198             # the selected fields anymore.
2199             group_by = []
2200             for expr in self.group_by:
2201                 if isinstance(expr, Ref) and expr.refs not in selected:
2202                     expr = self.annotations[expr.refs]
2203                 group_by.append(expr)
2204             self.group_by = tuple(group_by)
2205 
2206         self.values_select = tuple(field_names)
2207         self.add_fields(field_names, True)
2208 
2209     @property
2210     def annotation_select(self):
2211         """
2212         Return the dictionary of aggregate columns that are not masked and
2213         should be used in the SELECT clause. Cache this result for performance.
2214         """
2215         if self._annotation_select_cache is not None:
2216             return self._annotation_select_cache
2217         elif not self.annotations:
2218             return {}
2219         elif self.annotation_select_mask is not None:
2220             self._annotation_select_cache = {
2221                 k: v for k, v in self.annotations.items()
2222                 if k in self.annotation_select_mask
2223             }
2224             return self._annotation_select_cache
2225         else:
2226             return self.annotations
2227 
2228     @property
2229     def extra_select(self):
2230         if self._extra_select_cache is not None:
2231             return self._extra_select_cache
2232         if not self.extra:
2233             return {}
2234         elif self.extra_select_mask is not None:
2235             self._extra_select_cache = {
2236                 k: v for k, v in self.extra.items()
2237                 if k in self.extra_select_mask
2238             }
2239             return self._extra_select_cache
2240         else:
2241             return self.extra
2242 
2243     def trim_start(self, names_with_path):
2244         """
2245         Trim joins from the start of the join path. The candidates for trim
2246         are the PathInfos in names_with_path structure that are m2m joins.
2247 
2248         Also set the select column so the start matches the join.
2249 
2250         This method is meant to be used for generating the subquery joins &
2251         cols in split_exclude().
2252 
2253         Return a lookup usable for doing outerq.filter(lookup=self) and a
2254         boolean indicating if the joins in the prefix contain a LEFT OUTER join.
2255         _"""
2256         all_paths = []
2257         for _, paths in names_with_path:
2258             all_paths.extend(paths)
2259         contains_louter = False
2260         # Trim and operate only on tables that were generated for
2261         # the lookup part of the query. That is, avoid trimming
2262         # joins generated for F() expressions.
2263         lookup_tables = [
2264             t for t in self.alias_map
2265             if t in self._lookup_joins or t == self.base_table
2266         ]
2267         for trimmed_paths, path in enumerate(all_paths):
2268             if path.m2m:
2269                 break
2270             if self.alias_map[lookup_tables[trimmed_paths + 1]].join_type == LOUTER:
2271                 contains_louter = True
2272             alias = lookup_tables[trimmed_paths]
2273             self.unref_alias(alias)
2274         # The path.join_field is a Rel, lets get the other side's field
2275         join_field = path.join_field.field
2276         # Build the filter prefix.
2277         paths_in_prefix = trimmed_paths
2278         trimmed_prefix = []
2279         for name, path in names_with_path:
2280             if paths_in_prefix - len(path) < 0:
2281                 break
2282             trimmed_prefix.append(name)
2283             paths_in_prefix -= len(path)
2284         trimmed_prefix.append(
2285             join_field.foreign_related_fields[0].name)
2286         trimmed_prefix = LOOKUP_SEP.join(trimmed_prefix)
2287         # Lets still see if we can trim the first join from the inner query
2288         # (that is, self). We can't do this for:
2289         # - LEFT JOINs because we would miss those rows that have nothing on
2290         #   the outer side,
2291         # - INNER JOINs from filtered relations because we would miss their
2292         #   filters.
2293         first_join = self.alias_map[lookup_tables[trimmed_paths + 1]]
2294         if first_join.join_type != LOUTER and not first_join.filtered_relation:
2295             select_fields = [r[0] for r in join_field.related_fields]
2296             select_alias = lookup_tables[trimmed_paths + 1]
2297             self.unref_alias(lookup_tables[trimmed_paths])
2298             extra_restriction = join_field.get_extra_restriction(
2299                 self.where_class, None, lookup_tables[trimmed_paths + 1])
2300             if extra_restriction:
2301                 self.where.add(extra_restriction, AND)
2302         else:
2303             # TODO: It might be possible to trim more joins from the start of the
2304             # inner query if it happens to have a longer join chain containing the
2305             # values in select_fields. Lets punt this one for now.
2306             select_fields = [r[1] for r in join_field.related_fields]
2307             select_alias = lookup_tables[trimmed_paths]
2308         # The found starting point is likely a Join instead of a BaseTable reference.
2309         # But the first entry in the query's FROM clause must not be a JOIN.
2310         for table in self.alias_map:
2311             if self.alias_refcount[table] > 0:
2312                 self.alias_map[table] = BaseTable(self.alias_map[table].table_name, table)
2313                 break
2314         self.set_select([f.get_col(select_alias) for f in select_fields])
2315         return trimmed_prefix, contains_louter
2316 
2317     def is_nullable(self, field):
2318         """
2319         Check if the given field should be treated as nullable.
2320 
2321         Some backends treat '' as null and Django treats such fields as
2322         nullable for those backends. In such situations field.null can be
2323         False even if we should treat the field as nullable.
2324         """
2325         # We need to use DEFAULT_DB_ALIAS here, as QuerySet does not have
2326         # (nor should it have) knowledge of which connection is going to be
2327         # used. The proper fix would be to defer all decisions where
2328         # is_nullable() is needed to the compiler stage, but that is not easy
2329         # to do currently.
2330         return (
2331             connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls and
2332             field.empty_strings_allowed
2333         ) or field.null

</code><intended_behavior>This class provides additional context to the issue.</intended_behavior>]
2025-10-15 19:02:47.846 | INFO     | Search completed. Bug locations: [<file>django/db/models/sql/query.py</file>
<class>Query</class>
<method>get_aggregation</method>
<code>
419     def get_aggregation(self, using, added_aggregate_names):
420         """
421         Return the dictionary with the values of the existing aggregations.
422         """
423         if not self.annotation_select:
424             return {}
425         existing_annotations = [
426             annotation for alias, annotation
427             in self.annotations.items()
428             if alias not in added_aggregate_names
429         ]
430         # Decide if we need to use a subquery.
431         #
432         # Existing annotations would cause incorrect results as get_aggregation()
433         # must produce just one result and thus must not use GROUP BY. But we
434         # aren't smart enough to remove the existing annotations from the
435         # query, so those would force us to use GROUP BY.
436         #
437         # If the query has limit or distinct, or uses set operations, then
438         # those operations must be done in a subquery so that the query
439         # aggregates on the limit and/or distinct results instead of applying
440         # the distinct and limit after the aggregation.
441         if (isinstance(self.group_by, tuple) or self.is_sliced or existing_annotations or
442                 self.distinct or self.combinator):
443             from django.db.models.sql.subqueries import AggregateQuery
444             inner_query = self.clone()
445             inner_query.subquery = True
446             outer_query = AggregateQuery(self.model, inner_query)
447             inner_query.select_for_update = False
448             inner_query.select_related = False
449             inner_query.set_annotation_mask(self.annotation_select)
450             # Queries with distinct_fields need ordering and when a limit is
451             # applied we must take the slice from the ordered query. Otherwise
452             # no need for ordering.
453             inner_query.clear_ordering(force=False)
454             if not inner_query.distinct:
455                 # If the inner query uses default select and it has some
456                 # aggregate annotations, then we must make sure the inner
457                 # query is grouped by the main model's primary key. However,
458                 # clearing the select clause can alter results if distinct is
459                 # used.
460                 has_existing_aggregate_annotations = any(
461                     annotation for annotation in existing_annotations
462                     if getattr(annotation, 'contains_aggregate', True)
463                 )
464                 if inner_query.default_cols and has_existing_aggregate_annotations:
465                     inner_query.group_by = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)
466                 inner_query.default_cols = False
467 
468             relabels = {t: 'subquery' for t in inner_query.alias_map}
469             relabels[None] = 'subquery'
470             # Remove any aggregates marked for reduction from the subquery
471             # and move them to the outer AggregateQuery.
472             col_cnt = 0
473             for alias, expression in list(inner_query.annotation_select.items()):
474                 annotation_select_mask = inner_query.annotation_select_mask
475                 if expression.is_summary:
476                     expression, col_cnt = inner_query.rewrite_cols(expression, col_cnt)
477                     outer_query.annotations[alias] = expression.relabeled_clone(relabels)
478                     del inner_query.annotations[alias]
479                     annotation_select_mask.remove(alias)
480                 # Make sure the annotation_select wont use cached results.
481                 inner_query.set_annotation_mask(inner_query.annotation_select_mask)
482             if inner_query.select == () and not inner_query.default_cols and not inner_query.annotation_select_mask:
483                 # In case of Model.objects[0:3].count(), there would be no
484                 # field selected in the inner query, yet we must use a subquery.
485                 # So, make sure at least one field is selected.
486                 inner_query.select = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)
487         else:
488             outer_query = self
489             self.select = ()
490             self.default_cols = False
491             self.extra = {}
492 
493         outer_query.clear_ordering(force=True)
494         outer_query.clear_limits()
495         outer_query.select_for_update = False
496         outer_query.select_related = False
497         compiler = outer_query.get_compiler(using)
498         result = compiler.execute_sql(SINGLE)
499         if result is None:
500             result = [None] * len(outer_query.annotation_select)
501 
502         converters = compiler.get_converters(outer_query.annotation_select.values())
503         result = next(compiler.apply_converters((result,), converters))
504 
505         return dict(zip(outer_query.annotation_select, result))

</code><intended_behavior>This method, which prepares and retrieves aggregate results, should be modified to ensure that when an `EmptyResultSet` scenario is recognized (i.e., when filtering with `pk__in=[]` results in no rows to aggregate), it should still allow for `Coalesce` functions with `Value` to return the specified default value, instead of converting all aggregates to `None`. This enhancement would involve checking for `Coalesce` instances within the query's annotation and ensuring that their defined fallback values are returned in the aggregate result dictionary instead of `None`. This modification must preserve the method's existing functionality for handling non-empty result sets and other kinds of aggregate functions.

The method will need additional logic around the handling of empty results, specifically acknowledging when aggregates can bypass the `EmptyResultSet` limitation (such as with `Coalesce`). This could involve:
- Detecting when an aggregate query contains `Coalesce` with `Value`.
- Ensuring that these cases return the fallback value provided by `Value` within `Coalesce`, even if the query result set is empty.

This approach maintains the existing functionality for queries that do not involve this specific `Coalesce`-`Value` use case, thus keeping the impact of changes scoped only to the necessary conditions that address the bug.</intended_behavior>, <file>django/db/models/sql/query.py</file>
<class>Query</class>
<method>None</method>
<code>
139 class Query(BaseExpression):
140     """A single SQL query."""
141 
142     alias_prefix = 'T'
143     subq_aliases = frozenset([alias_prefix])
144 
145     compiler = 'SQLCompiler'
146 
147     def __init__(self, model, where=WhereNode, alias_cols=True):
148         self.model = model
149         self.alias_refcount = {}
150         # alias_map is the most important data structure regarding joins.
151         # It's used for recording which joins exist in the query and what
152         # types they are. The key is the alias of the joined table (possibly
153         # the table name) and the value is a Join-like object (see
154         # sql.datastructures.Join for more information).
155         self.alias_map = {}
156         # Whether to provide alias to columns during reference resolving.
157         self.alias_cols = alias_cols
158         # Sometimes the query contains references to aliases in outer queries (as
159         # a result of split_exclude). Correct alias quoting needs to know these
160         # aliases too.
161         # Map external tables to whether they are aliased.
162         self.external_aliases = {}
163         self.table_map = {}     # Maps table names to list of aliases.
164         self.default_cols = True
165         self.default_ordering = True
166         self.standard_ordering = True
167         self.used_aliases = set()
168         self.filter_is_sticky = False
169         self.subquery = False
170 
171         # SQL-related attributes
172         # Select and related select clauses are expressions to use in the
173         # SELECT clause of the query.
174         # The select is used for cases where we want to set up the select
175         # clause to contain other than default fields (values(), subqueries...)
176         # Note that annotations go to annotations dictionary.
177         self.select = ()
178         self.where = where()
179         self.where_class = where
180         # The group_by attribute can have one of the following forms:
181         #  - None: no group by at all in the query
182         #  - A tuple of expressions: group by (at least) those expressions.
183         #    String refs are also allowed for now.
184         #  - True: group by all select fields of the model
185         # See compiler.get_group_by() for details.
186         self.group_by = None
187         self.order_by = ()
188         self.low_mark, self.high_mark = 0, None  # Used for offset/limit
189         self.distinct = False
190         self.distinct_fields = ()
191         self.select_for_update = False
192         self.select_for_update_nowait = False
193         self.select_for_update_skip_locked = False
194         self.select_for_update_of = ()
195         self.select_for_no_key_update = False
196 
197         self.select_related = False
198         # Arbitrary limit for select_related to prevents infinite recursion.
199         self.max_depth = 5
200 
201         # Holds the selects defined by a call to values() or values_list()
202         # excluding annotation_select and extra_select.
203         self.values_select = ()
204 
205         # SQL annotation-related attributes
206         self.annotations = {}  # Maps alias -> Annotation Expression
207         self.annotation_select_mask = None
208         self._annotation_select_cache = None
209 
210         # Set combination attributes
211         self.combinator = None
212         self.combinator_all = False
213         self.combined_queries = ()
214 
215         # These are for extensions. The contents are more or less appended
216         # verbatim to the appropriate clause.
217         self.extra = {}  # Maps col_alias -> (col_sql, params).
218         self.extra_select_mask = None
219         self._extra_select_cache = None
220 
221         self.extra_tables = ()
222         self.extra_order_by = ()
223 
224         # A tuple that is a set of model field names and either True, if these
225         # are the fields to defer, or False if these are the only fields to
226         # load.
227         self.deferred_loading = (frozenset(), True)
228 
229         self._filtered_relations = {}
230 
231         self.explain_query = False
232         self.explain_format = None
233         self.explain_options = {}
234 
235     @property
236     def output_field(self):
237         if len(self.select) == 1:
238             select = self.select[0]
239             return getattr(select, 'target', None) or select.field
240         elif len(self.annotation_select) == 1:
241             return next(iter(self.annotation_select.values())).output_field
242 
243     @property
244     def has_select_fields(self):
245         return bool(self.select or self.annotation_select_mask or self.extra_select_mask)
246 
247     @cached_property
248     def base_table(self):
249         for alias in self.alias_map:
250             return alias
251 
252     def __str__(self):
253         """
254         Return the query as a string of SQL with the parameter values
255         substituted in (use sql_with_params() to see the unsubstituted string).
256 
257         Parameter values won't necessarily be quoted correctly, since that is
258         done by the database interface at execution time.
259         """
260         sql, params = self.sql_with_params()
261         return sql % params
262 
263     def sql_with_params(self):
264         """
265         Return the query as an SQL string and the parameters that will be
266         substituted into the query.
267         """
268         return self.get_compiler(DEFAULT_DB_ALIAS).as_sql()
269 
270     def __deepcopy__(self, memo):
271         """Limit the amount of work when a Query is deepcopied."""
272         result = self.clone()
273         memo[id(self)] = result
274         return result
275 
276     def get_compiler(self, using=None, connection=None):
277         if using is None and connection is None:
278             raise ValueError("Need either using or connection")
279         if using:
280             connection = connections[using]
281         return connection.ops.compiler(self.compiler)(self, connection, using)
282 
283     def get_meta(self):
284         """
285         Return the Options instance (the model._meta) from which to start
286         processing. Normally, this is self.model._meta, but it can be changed
287         by subclasses.
288         """
289         return self.model._meta
290 
291     def clone(self):
292         """
293         Return a copy of the current Query. A lightweight alternative to
294         to deepcopy().
295         """
296         obj = Empty()
297         obj.__class__ = self.__class__
298         # Copy references to everything.
299         obj.__dict__ = self.__dict__.copy()
300         # Clone attributes that can't use shallow copy.
301         obj.alias_refcount = self.alias_refcount.copy()
302         obj.alias_map = self.alias_map.copy()
303         obj.external_aliases = self.external_aliases.copy()
304         obj.table_map = self.table_map.copy()
305         obj.where = self.where.clone()
306         obj.annotations = self.annotations.copy()
307         if self.annotation_select_mask is None:
308             obj.annotation_select_mask = None
309         else:
310             obj.annotation_select_mask = self.annotation_select_mask.copy()
311         obj.combined_queries = tuple(query.clone() for query in self.combined_queries)
312         # _annotation_select_cache cannot be copied, as doing so breaks the
313         # (necessary) state in which both annotations and
314         # _annotation_select_cache point to the same underlying objects.
315         # It will get re-populated in the cloned queryset the next time it's
316         # used.
317         obj._annotation_select_cache = None
318         obj.extra = self.extra.copy()
319         if self.extra_select_mask is None:
320             obj.extra_select_mask = None
321         else:
322             obj.extra_select_mask = self.extra_select_mask.copy()
323         if self._extra_select_cache is None:
324             obj._extra_select_cache = None
325         else:
326             obj._extra_select_cache = self._extra_select_cache.copy()
327         if self.select_related is not False:
328             # Use deepcopy because select_related stores fields in nested
329             # dicts.
330             obj.select_related = copy.deepcopy(obj.select_related)
331         if 'subq_aliases' in self.__dict__:
332             obj.subq_aliases = self.subq_aliases.copy()
333         obj.used_aliases = self.used_aliases.copy()
334         obj._filtered_relations = self._filtered_relations.copy()
335         # Clear the cached_property
336         try:
337             del obj.base_table
338         except AttributeError:
339             pass
340         return obj
341 
342     def chain(self, klass=None):
343         """
344         Return a copy of the current Query that's ready for another operation.
345         The klass argument changes the type of the Query, e.g. UpdateQuery.
346         """
347         obj = self.clone()
348         if klass and obj.__class__ != klass:
349             obj.__class__ = klass
350         if not obj.filter_is_sticky:
351             obj.used_aliases = set()
352         obj.filter_is_sticky = False
353         if hasattr(obj, '_setup_query'):
354             obj._setup_query()
355         return obj
356 
357     def relabeled_clone(self, change_map):
358         clone = self.clone()
359         clone.change_aliases(change_map)
360         return clone
361 
362     def _get_col(self, target, field, alias):
363         if not self.alias_cols:
364             alias = None
365         return target.get_col(alias, field)
366 
367     def rewrite_cols(self, annotation, col_cnt):
368         # We must make sure the inner query has the referred columns in it.
369         # If we are aggregating over an annotation, then Django uses Ref()
370         # instances to note this. However, if we are annotating over a column
371         # of a related model, then it might be that column isn't part of the
372         # SELECT clause of the inner query, and we must manually make sure
373         # the column is selected. An example case is:
374         #    .aggregate(Sum('author__awards'))
375         # Resolving this expression results in a join to author, but there
376         # is no guarantee the awards column of author is in the select clause
377         # of the query. Thus we must manually add the column to the inner
378         # query.
379         orig_exprs = annotation.get_source_expressions()
380         new_exprs = []
381         for expr in orig_exprs:
382             # FIXME: These conditions are fairly arbitrary. Identify a better
383             # method of having expressions decide which code path they should
384             # take.
385             if isinstance(expr, Ref):
386                 # Its already a Ref to subquery (see resolve_ref() for
387                 # details)
388                 new_exprs.append(expr)
389             elif isinstance(expr, (WhereNode, Lookup)):
390                 # Decompose the subexpressions further. The code here is
391                 # copied from the else clause, but this condition must appear
392                 # before the contains_aggregate/is_summary condition below.
393                 new_expr, col_cnt = self.rewrite_cols(expr, col_cnt)
394                 new_exprs.append(new_expr)
395             else:
396                 # Reuse aliases of expressions already selected in subquery.
397                 for col_alias, selected_annotation in self.annotation_select.items():
398                     if selected_annotation is expr:
399                         new_expr = Ref(col_alias, expr)
400                         break
401                 else:
402                     # An expression that is not selected the subquery.
403                     if isinstance(expr, Col) or (expr.contains_aggregate and not expr.is_summary):
404                         # Reference column or another aggregate. Select it
405                         # under a non-conflicting alias.
406                         col_cnt += 1
407                         col_alias = '__col%d' % col_cnt
408                         self.annotations[col_alias] = expr
409                         self.append_annotation_mask([col_alias])
410                         new_expr = Ref(col_alias, expr)
411                     else:
412                         # Some other expression not referencing database values
413                         # directly. Its subexpression might contain Cols.
414                         new_expr, col_cnt = self.rewrite_cols(expr, col_cnt)
415                 new_exprs.append(new_expr)
416         annotation.set_source_expressions(new_exprs)
417         return annotation, col_cnt
418 
419     def get_aggregation(self, using, added_aggregate_names):
420         """
421         Return the dictionary with the values of the existing aggregations.
422         """
423         if not self.annotation_select:
424             return {}
425         existing_annotations = [
426             annotation for alias, annotation
427             in self.annotations.items()
428             if alias not in added_aggregate_names
429         ]
430         # Decide if we need to use a subquery.
431         #
432         # Existing annotations would cause incorrect results as get_aggregation()
433         # must produce just one result and thus must not use GROUP BY. But we
434         # aren't smart enough to remove the existing annotations from the
435         # query, so those would force us to use GROUP BY.
436         #
437         # If the query has limit or distinct, or uses set operations, then
438         # those operations must be done in a subquery so that the query
439         # aggregates on the limit and/or distinct results instead of applying
440         # the distinct and limit after the aggregation.
441         if (isinstance(self.group_by, tuple) or self.is_sliced or existing_annotations or
442                 self.distinct or self.combinator):
443             from django.db.models.sql.subqueries import AggregateQuery
444             inner_query = self.clone()
445             inner_query.subquery = True
446             outer_query = AggregateQuery(self.model, inner_query)
447             inner_query.select_for_update = False
448             inner_query.select_related = False
449             inner_query.set_annotation_mask(self.annotation_select)
450             # Queries with distinct_fields need ordering and when a limit is
451             # applied we must take the slice from the ordered query. Otherwise
452             # no need for ordering.
453             inner_query.clear_ordering(force=False)
454             if not inner_query.distinct:
455                 # If the inner query uses default select and it has some
456                 # aggregate annotations, then we must make sure the inner
457                 # query is grouped by the main model's primary key. However,
458                 # clearing the select clause can alter results if distinct is
459                 # used.
460                 has_existing_aggregate_annotations = any(
461                     annotation for annotation in existing_annotations
462                     if getattr(annotation, 'contains_aggregate', True)
463                 )
464                 if inner_query.default_cols and has_existing_aggregate_annotations:
465                     inner_query.group_by = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)
466                 inner_query.default_cols = False
467 
468             relabels = {t: 'subquery' for t in inner_query.alias_map}
469             relabels[None] = 'subquery'
470             # Remove any aggregates marked for reduction from the subquery
471             # and move them to the outer AggregateQuery.
472             col_cnt = 0
473             for alias, expression in list(inner_query.annotation_select.items()):
474                 annotation_select_mask = inner_query.annotation_select_mask
475                 if expression.is_summary:
476                     expression, col_cnt = inner_query.rewrite_cols(expression, col_cnt)
477                     outer_query.annotations[alias] = expression.relabeled_clone(relabels)
478                     del inner_query.annotations[alias]
479                     annotation_select_mask.remove(alias)
480                 # Make sure the annotation_select wont use cached results.
481                 inner_query.set_annotation_mask(inner_query.annotation_select_mask)
482             if inner_query.select == () and not inner_query.default_cols and not inner_query.annotation_select_mask:
483                 # In case of Model.objects[0:3].count(), there would be no
484                 # field selected in the inner query, yet we must use a subquery.
485                 # So, make sure at least one field is selected.
486                 inner_query.select = (self.model._meta.pk.get_col(inner_query.get_initial_alias()),)
487         else:
488             outer_query = self
489             self.select = ()
490             self.default_cols = False
491             self.extra = {}
492 
493         outer_query.clear_ordering(force=True)
494         outer_query.clear_limits()
495         outer_query.select_for_update = False
496         outer_query.select_related = False
497         compiler = outer_query.get_compiler(using)
498         result = compiler.execute_sql(SINGLE)
499         if result is None:
500             result = [None] * len(outer_query.annotation_select)
501 
502         converters = compiler.get_converters(outer_query.annotation_select.values())
503         result = next(compiler.apply_converters((result,), converters))
504 
505         return dict(zip(outer_query.annotation_select, result))
506 
507     def get_count(self, using):
508         """
509         Perform a COUNT() query using the current filter constraints.
510         """
511         obj = self.clone()
512         obj.add_annotation(Count('*'), alias='__count', is_summary=True)
513         number = obj.get_aggregation(using, ['__count'])['__count']
514         if number is None:
515             number = 0
516         return number
517 
518     def has_filters(self):
519         return self.where
520 
521     def exists(self, using, limit=True):
522         q = self.clone()
523         if not q.distinct:
524             if q.group_by is True:
525                 q.add_fields((f.attname for f in self.model._meta.concrete_fields), False)
526                 # Disable GROUP BY aliases to avoid orphaning references to the
527                 # SELECT clause which is about to be cleared.
528                 q.set_group_by(allow_aliases=False)
529             q.clear_select_clause()
530         if q.combined_queries and q.combinator == 'union':
531             limit_combined = connections[using].features.supports_slicing_ordering_in_compound
532             q.combined_queries = tuple(
533                 combined_query.exists(using, limit=limit_combined)
534                 for combined_query in q.combined_queries
535             )
536         q.clear_ordering(force=True)
537         if limit:
538             q.set_limits(high=1)
539         q.add_extra({'a': 1}, None, None, None, None, None)
540         q.set_extra_mask(['a'])
541         return q
542 
543     def has_results(self, using):
544         q = self.exists(using)
545         compiler = q.get_compiler(using=using)
546         return compiler.has_results()
547 
548     def explain(self, using, format=None, **options):
549         q = self.clone()
550         q.explain_query = True
551         q.explain_format = format
552         q.explain_options = options
553         compiler = q.get_compiler(using=using)
554         return '\n'.join(compiler.explain_query())
555 
556     def combine(self, rhs, connector):
557         """
558         Merge the 'rhs' query into the current one (with any 'rhs' effects
559         being applied *after* (that is, "to the right of") anything in the
560         current query. 'rhs' is not modified during a call to this function.
561 
562         The 'connector' parameter describes how to connect filters from the
563         'rhs' query.
564         """
565         assert self.model == rhs.model, \
566             "Cannot combine queries on two different base models."
567         if self.is_sliced:
568             raise TypeError('Cannot combine queries once a slice has been taken.')
569         assert self.distinct == rhs.distinct, \
570             "Cannot combine a unique query with a non-unique query."
571         assert self.distinct_fields == rhs.distinct_fields, \
572             "Cannot combine queries with different distinct fields."
573 
574         # Work out how to relabel the rhs aliases, if necessary.
575         change_map = {}
576         conjunction = (connector == AND)
577 
578         # Determine which existing joins can be reused. When combining the
579         # query with AND we must recreate all joins for m2m filters. When
580         # combining with OR we can reuse joins. The reason is that in AND
581         # case a single row can't fulfill a condition like:
582         #     revrel__col=1 & revrel__col=2
583         # But, there might be two different related rows matching this
584         # condition. In OR case a single True is enough, so single row is
585         # enough, too.
586         #
587         # Note that we will be creating duplicate joins for non-m2m joins in
588         # the AND case. The results will be correct but this creates too many
589         # joins. This is something that could be fixed later on.
590         reuse = set() if conjunction else set(self.alias_map)
591         # Base table must be present in the query - this is the same
592         # table on both sides.
593         self.get_initial_alias()
594         joinpromoter = JoinPromoter(connector, 2, False)
595         joinpromoter.add_votes(
596             j for j in self.alias_map if self.alias_map[j].join_type == INNER)
597         rhs_votes = set()
598         # Now, add the joins from rhs query into the new query (skipping base
599         # table).
600         rhs_tables = list(rhs.alias_map)[1:]
601         for alias in rhs_tables:
602             join = rhs.alias_map[alias]
603             # If the left side of the join was already relabeled, use the
604             # updated alias.
605             join = join.relabeled_clone(change_map)
606             new_alias = self.join(join, reuse=reuse)
607             if join.join_type == INNER:
608                 rhs_votes.add(new_alias)
609             # We can't reuse the same join again in the query. If we have two
610             # distinct joins for the same connection in rhs query, then the
611             # combined query must have two joins, too.
612             reuse.discard(new_alias)
613             if alias != new_alias:
614                 change_map[alias] = new_alias
615             if not rhs.alias_refcount[alias]:
616                 # The alias was unused in the rhs query. Unref it so that it
617                 # will be unused in the new query, too. We have to add and
618                 # unref the alias so that join promotion has information of
619                 # the join type for the unused alias.
620                 self.unref_alias(new_alias)
621         joinpromoter.add_votes(rhs_votes)
622         joinpromoter.update_join_types(self)
623 
624         # Combine subqueries aliases to ensure aliases relabelling properly
625         # handle subqueries when combining where and select clauses.
626         self.subq_aliases |= rhs.subq_aliases
627 
628         # Now relabel a copy of the rhs where-clause and add it to the current
629         # one.
630         w = rhs.where.clone()
631         w.relabel_aliases(change_map)
632         self.where.add(w, connector)
633 
634         # Selection columns and extra extensions are those provided by 'rhs'.
635         if rhs.select:
636             self.set_select([col.relabeled_clone(change_map) for col in rhs.select])
637         else:
638             self.select = ()
639 
640         if connector == OR:
641             # It would be nice to be able to handle this, but the queries don't
642             # really make sense (or return consistent value sets). Not worth
643             # the extra complexity when you can write a real query instead.
644             if self.extra and rhs.extra:
645                 raise ValueError("When merging querysets using 'or', you cannot have extra(select=...) on both sides.")
646         self.extra.update(rhs.extra)
647         extra_select_mask = set()
648         if self.extra_select_mask is not None:
649             extra_select_mask.update(self.extra_select_mask)
650         if rhs.extra_select_mask is not None:
651             extra_select_mask.update(rhs.extra_select_mask)
652         if extra_select_mask:
653             self.set_extra_mask(extra_select_mask)
654         self.extra_tables += rhs.extra_tables
655 
656         # Ordering uses the 'rhs' ordering, unless it has none, in which case
657         # the current ordering is used.
658         self.order_by = rhs.order_by or self.order_by
659         self.extra_order_by = rhs.extra_order_by or self.extra_order_by
660 
661     def deferred_to_data(self, target, callback):
662         """
663         Convert the self.deferred_loading data structure to an alternate data
664         structure, describing the field that *will* be loaded. This is used to
665         compute the columns to select from the database and also by the
666         QuerySet class to work out which fields are being initialized on each
667         model. Models that have all their fields included aren't mentioned in
668         the result, only those that have field restrictions in place.
669 
670         The "target" parameter is the instance that is populated (in place).
671         The "callback" is a function that is called whenever a (model, field)
672         pair need to be added to "target". It accepts three parameters:
673         "target", and the model and list of fields being added for that model.
674         """
675         field_names, defer = self.deferred_loading
676         if not field_names:
677             return
678         orig_opts = self.get_meta()
679         seen = {}
680         must_include = {orig_opts.concrete_model: {orig_opts.pk}}
681         for field_name in field_names:
682             parts = field_name.split(LOOKUP_SEP)
683             cur_model = self.model._meta.concrete_model
684             opts = orig_opts
685             for name in parts[:-1]:
686                 old_model = cur_model
687                 if name in self._filtered_relations:
688                     name = self._filtered_relations[name].relation_name
689                 source = opts.get_field(name)
690                 if is_reverse_o2o(source):
691                     cur_model = source.related_model
692                 else:
693                     cur_model = source.remote_field.model
694                 opts = cur_model._meta
695                 # Even if we're "just passing through" this model, we must add
696                 # both the current model's pk and the related reference field
697                 # (if it's not a reverse relation) to the things we select.
698                 if not is_reverse_o2o(source):
699                     must_include[old_model].add(source)
700                 add_to_dict(must_include, cur_model, opts.pk)
701             field = opts.get_field(parts[-1])
702             is_reverse_object = field.auto_created and not field.concrete
703             model = field.related_model if is_reverse_object else field.model
704             model = model._meta.concrete_model
705             if model == opts.model:
706                 model = cur_model
707             if not is_reverse_o2o(field):
708                 add_to_dict(seen, model, field)
709 
710         if defer:
711             # We need to load all fields for each model, except those that
712             # appear in "seen" (for all models that appear in "seen"). The only
713             # slight complexity here is handling fields that exist on parent
714             # models.
715             workset = {}
716             for model, values in seen.items():
717                 for field in model._meta.local_fields:
718                     if field not in values:
719                         m = field.model._meta.concrete_model
720                         add_to_dict(workset, m, field)
721             for model, values in must_include.items():
722                 # If we haven't included a model in workset, we don't add the
723                 # corresponding must_include fields for that model, since an
724                 # empty set means "include all fields". That's why there's no
725                 # "else" branch here.
726                 if model in workset:
727                     workset[model].update(values)
728             for model, values in workset.items():
729                 callback(target, model, values)
730         else:
731             for model, values in must_include.items():
732                 if model in seen:
733                     seen[model].update(values)
734                 else:
735                     # As we've passed through this model, but not explicitly
736                     # included any fields, we have to make sure it's mentioned
737                     # so that only the "must include" fields are pulled in.
738                     seen[model] = values
739             # Now ensure that every model in the inheritance chain is mentioned
740             # in the parent list. Again, it must be mentioned to ensure that
741             # only "must include" fields are pulled in.
742             for model in orig_opts.get_parent_list():
743                 seen.setdefault(model, set())
744             for model, values in seen.items():
745                 callback(target, model, values)
746 
747     def table_alias(self, table_name, create=False, filtered_relation=None):
748         """
749         Return a table alias for the given table_name and whether this is a
750         new alias or not.
751 
752         If 'create' is true, a new alias is always created. Otherwise, the
753         most recently created alias for the table (if one exists) is reused.
754         """
755         alias_list = self.table_map.get(table_name)
756         if not create and alias_list:
757             alias = alias_list[0]
758             self.alias_refcount[alias] += 1
759             return alias, False
760 
761         # Create a new alias for this table.
762         if alias_list:
763             alias = '%s%d' % (self.alias_prefix, len(self.alias_map) + 1)
764             alias_list.append(alias)
765         else:
766             # The first occurrence of a table uses the table name directly.
767             alias = filtered_relation.alias if filtered_relation is not None else table_name
768             self.table_map[table_name] = [alias]
769         self.alias_refcount[alias] = 1
770         return alias, True
771 
772     def ref_alias(self, alias):
773         """Increases the reference count for this alias."""
774         self.alias_refcount[alias] += 1
775 
776     def unref_alias(self, alias, amount=1):
777         """Decreases the reference count for this alias."""
778         self.alias_refcount[alias] -= amount
779 
780     def promote_joins(self, aliases):
781         """
782         Promote recursively the join type of given aliases and its children to
783         an outer join. If 'unconditional' is False, only promote the join if
784         it is nullable or the parent join is an outer join.
785 
786         The children promotion is done to avoid join chains that contain a LOUTER
787         b INNER c. So, if we have currently a INNER b INNER c and a->b is promoted,
788         then we must also promote b->c automatically, or otherwise the promotion
789         of a->b doesn't actually change anything in the query results.
790         """
791         aliases = list(aliases)
792         while aliases:
793             alias = aliases.pop(0)
794             if self.alias_map[alias].join_type is None:
795                 # This is the base table (first FROM entry) - this table
796                 # isn't really joined at all in the query, so we should not
797                 # alter its join type.
798                 continue
799             # Only the first alias (skipped above) should have None join_type
800             assert self.alias_map[alias].join_type is not None
801             parent_alias = self.alias_map[alias].parent_alias
802             parent_louter = parent_alias and self.alias_map[parent_alias].join_type == LOUTER
803             already_louter = self.alias_map[alias].join_type == LOUTER
804             if ((self.alias_map[alias].nullable or parent_louter) and
805                     not already_louter):
806                 self.alias_map[alias] = self.alias_map[alias].promote()
807                 # Join type of 'alias' changed, so re-examine all aliases that
808                 # refer to this one.
809                 aliases.extend(
810                     join for join in self.alias_map
811                     if self.alias_map[join].parent_alias == alias and join not in aliases
812                 )
813 
814     def demote_joins(self, aliases):
815         """
816         Change join type from LOUTER to INNER for all joins in aliases.
817 
818         Similarly to promote_joins(), this method must ensure no join chains
819         containing first an outer, then an inner join are generated. If we
820         are demoting b->c join in chain a LOUTER b LOUTER c then we must
821         demote a->b automatically, or otherwise the demotion of b->c doesn't
822         actually change anything in the query results. .
823         """
824         aliases = list(aliases)
825         while aliases:
826             alias = aliases.pop(0)
827             if self.alias_map[alias].join_type == LOUTER:
828                 self.alias_map[alias] = self.alias_map[alias].demote()
829                 parent_alias = self.alias_map[alias].parent_alias
830                 if self.alias_map[parent_alias].join_type == INNER:
831                     aliases.append(parent_alias)
832 
833     def reset_refcounts(self, to_counts):
834         """
835         Reset reference counts for aliases so that they match the value passed
836         in `to_counts`.
837         """
838         for alias, cur_refcount in self.alias_refcount.copy().items():
839             unref_amount = cur_refcount - to_counts.get(alias, 0)
840             self.unref_alias(alias, unref_amount)
841 
842     def change_aliases(self, change_map):
843         """
844         Change the aliases in change_map (which maps old-alias -> new-alias),
845         relabelling any references to them in select columns and the where
846         clause.
847         """
848         assert set(change_map).isdisjoint(change_map.values())
849 
850         # 1. Update references in "select" (normal columns plus aliases),
851         # "group by" and "where".
852         self.where.relabel_aliases(change_map)
853         if isinstance(self.group_by, tuple):
854             self.group_by = tuple([col.relabeled_clone(change_map) for col in self.group_by])
855         self.select = tuple([col.relabeled_clone(change_map) for col in self.select])
856         self.annotations = self.annotations and {
857             key: col.relabeled_clone(change_map) for key, col in self.annotations.items()
858         }
859 
860         # 2. Rename the alias in the internal table/alias datastructures.
861         for old_alias, new_alias in change_map.items():
862             if old_alias not in self.alias_map:
863                 continue
864             alias_data = self.alias_map[old_alias].relabeled_clone(change_map)
865             self.alias_map[new_alias] = alias_data
866             self.alias_refcount[new_alias] = self.alias_refcount[old_alias]
867             del self.alias_refcount[old_alias]
868             del self.alias_map[old_alias]
869 
870             table_aliases = self.table_map[alias_data.table_name]
871             for pos, alias in enumerate(table_aliases):
872                 if alias == old_alias:
873                     table_aliases[pos] = new_alias
874                     break
875         self.external_aliases = {
876             # Table is aliased or it's being changed and thus is aliased.
877             change_map.get(alias, alias): (aliased or alias in change_map)
878             for alias, aliased in self.external_aliases.items()
879         }
880 
881     def bump_prefix(self, outer_query):
882         """
883         Change the alias prefix to the next letter in the alphabet in a way
884         that the outer query's aliases and this query's aliases will not
885         conflict. Even tables that previously had no alias will get an alias
886         after this call.
887         """
888         def prefix_gen():
889             """
890             Generate a sequence of characters in alphabetical order:
891                 -> 'A', 'B', 'C', ...
892 
893             When the alphabet is finished, the sequence will continue with the
894             Cartesian product:
895                 -> 'AA', 'AB', 'AC', ...
896             """
897             alphabet = ascii_uppercase
898             prefix = chr(ord(self.alias_prefix) + 1)
899             yield prefix
900             for n in count(1):
901                 seq = alphabet[alphabet.index(prefix):] if prefix else alphabet
902                 for s in product(seq, repeat=n):
903                     yield ''.join(s)
904                 prefix = None
905 
906         if self.alias_prefix != outer_query.alias_prefix:
907             # No clashes between self and outer query should be possible.
908             return
909 
910         # Explicitly avoid infinite loop. The constant divider is based on how
911         # much depth recursive subquery references add to the stack. This value
912         # might need to be adjusted when adding or removing function calls from
913         # the code path in charge of performing these operations.
914         local_recursion_limit = sys.getrecursionlimit() // 16
915         for pos, prefix in enumerate(prefix_gen()):
916             if prefix not in self.subq_aliases:
917                 self.alias_prefix = prefix
918                 break
919             if pos > local_recursion_limit:
920                 raise RecursionError(
921                     'Maximum recursion depth exceeded: too many subqueries.'
922                 )
923         self.subq_aliases = self.subq_aliases.union([self.alias_prefix])
924         outer_query.subq_aliases = outer_query.subq_aliases.union(self.subq_aliases)
925         self.change_aliases({
926             alias: '%s%d' % (self.alias_prefix, pos)
927             for pos, alias in enumerate(self.alias_map)
928         })
929 
930     def get_initial_alias(self):
931         """
932         Return the first alias for this query, after increasing its reference
933         count.
934         """
935         if self.alias_map:
936             alias = self.base_table
937             self.ref_alias(alias)
938         else:
939             alias = self.join(BaseTable(self.get_meta().db_table, None))
940         return alias
941 
942     def count_active_tables(self):
943         """
944         Return the number of tables in this query with a non-zero reference
945         count. After execution, the reference counts are zeroed, so tables
946         added in compiler will not be seen by this method.
947         """
948         return len([1 for count in self.alias_refcount.values() if count])
949 
950     def join(self, join, reuse=None):
951         """
952         Return an alias for the 'join', either reusing an existing alias for
953         that join or creating a new one. 'join' is either a
954         sql.datastructures.BaseTable or Join.
955 
956         The 'reuse' parameter can be either None which means all joins are
957         reusable, or it can be a set containing the aliases that can be reused.
958 
959         A join is always created as LOUTER if the lhs alias is LOUTER to make
960         sure chains like t1 LOUTER t2 INNER t3 aren't generated. All new
961         joins are created as LOUTER if the join is nullable.
962         """
963         reuse_aliases = [
964             a for a, j in self.alias_map.items()
965             if (reuse is None or a in reuse) and j.equals(join)
966         ]
967         if reuse_aliases:
968             if join.table_alias in reuse_aliases:
969                 reuse_alias = join.table_alias
970             else:
971                 # Reuse the most recent alias of the joined table
972                 # (a many-to-many relation may be joined multiple times).
973                 reuse_alias = reuse_aliases[-1]
974             self.ref_alias(reuse_alias)
975             return reuse_alias
976 
977         # No reuse is possible, so we need a new alias.
978         alias, _ = self.table_alias(join.table_name, create=True, filtered_relation=join.filtered_relation)
979         if join.join_type:
980             if self.alias_map[join.parent_alias].join_type == LOUTER or join.nullable:
981                 join_type = LOUTER
982             else:
983                 join_type = INNER
984             join.join_type = join_type
985         join.table_alias = alias
986         self.alias_map[alias] = join
987         return alias
988 
989     def join_parent_model(self, opts, model, alias, seen):
990         """
991         Make sure the given 'model' is joined in the query. If 'model' isn't
992         a parent of 'opts' or if it is None this method is a no-op.
993 
994         The 'alias' is the root alias for starting the join, 'seen' is a dict
995         of model -> alias of existing joins. It must also contain a mapping
996         of None -> some alias. This will be returned in the no-op case.
997         """
998         if model in seen:
999             return seen[model]
1000         chain = opts.get_base_chain(model)
1001         if not chain:
1002             return alias
1003         curr_opts = opts
1004         for int_model in chain:
1005             if int_model in seen:
1006                 curr_opts = int_model._meta
1007                 alias = seen[int_model]
1008                 continue
1009             # Proxy model have elements in base chain
1010             # with no parents, assign the new options
1011             # object and skip to the next base in that
1012             # case
1013             if not curr_opts.parents[int_model]:
1014                 curr_opts = int_model._meta
1015                 continue
1016             link_field = curr_opts.get_ancestor_link(int_model)
1017             join_info = self.setup_joins([link_field.name], curr_opts, alias)
1018             curr_opts = int_model._meta
1019             alias = seen[int_model] = join_info.joins[-1]
1020         return alias or seen[None]
1021 
1022     def add_annotation(self, annotation, alias, is_summary=False, select=True):
1023         """Add a single annotation expression to the Query."""
1024         annotation = annotation.resolve_expression(self, allow_joins=True, reuse=None,
1025                                                    summarize=is_summary)
1026         if select:
1027             self.append_annotation_mask([alias])
1028         else:
1029             self.set_annotation_mask(set(self.annotation_select).difference({alias}))
1030         self.annotations[alias] = annotation
1031 
1032     def resolve_expression(self, query, *args, **kwargs):
1033         clone = self.clone()
1034         # Subqueries need to use a different set of aliases than the outer query.
1035         clone.bump_prefix(query)
1036         clone.subquery = True
1037         clone.where.resolve_expression(query, *args, **kwargs)
1038         for key, value in clone.annotations.items():
1039             resolved = value.resolve_expression(query, *args, **kwargs)
1040             if hasattr(resolved, 'external_aliases'):
1041                 resolved.external_aliases.update(clone.external_aliases)
1042             clone.annotations[key] = resolved
1043         # Outer query's aliases are considered external.
1044         for alias, table in query.alias_map.items():
1045             clone.external_aliases[alias] = (
1046                 (isinstance(table, Join) and table.join_field.related_model._meta.db_table != alias) or
1047                 (isinstance(table, BaseTable) and table.table_name != table.table_alias)
1048             )
1049         return clone
1050 
1051     def get_external_cols(self):
1052         exprs = chain(self.annotations.values(), self.where.children)
1053         return [
1054             col for col in self._gen_cols(exprs, include_external=True)
1055             if col.alias in self.external_aliases
1056         ]
1057 
1058     def as_sql(self, compiler, connection):
1059         # Some backends (e.g. Oracle) raise an error when a subquery contains
1060         # unnecessary ORDER BY clause.
1061         if (
1062             self.subquery and
1063             not connection.features.ignores_unnecessary_order_by_in_subqueries
1064         ):
1065             self.clear_ordering(force=False)
1066         sql, params = self.get_compiler(connection=connection).as_sql()
1067         if self.subquery:
1068             sql = '(%s)' % sql
1069         return sql, params
1070 
1071     def resolve_lookup_value(self, value, can_reuse, allow_joins):
1072         if hasattr(value, 'resolve_expression'):
1073             value = value.resolve_expression(
1074                 self, reuse=can_reuse, allow_joins=allow_joins,
1075             )
1076         elif isinstance(value, (list, tuple)):
1077             # The items of the iterable may be expressions and therefore need
1078             # to be resolved independently.
1079             values = (
1080                 self.resolve_lookup_value(sub_value, can_reuse, allow_joins)
1081                 for sub_value in value
1082             )
1083             type_ = type(value)
1084             if hasattr(type_, '_make'):  # namedtuple
1085                 return type_(*values)
1086             return type_(values)
1087         return value
1088 
1089     def solve_lookup_type(self, lookup):
1090         """
1091         Solve the lookup type from the lookup (e.g.: 'foobar__id__icontains').
1092         """
1093         lookup_splitted = lookup.split(LOOKUP_SEP)
1094         if self.annotations:
1095             expression, expression_lookups = refs_expression(lookup_splitted, self.annotations)
1096             if expression:
1097                 return expression_lookups, (), expression
1098         _, field, _, lookup_parts = self.names_to_path(lookup_splitted, self.get_meta())
1099         field_parts = lookup_splitted[0:len(lookup_splitted) - len(lookup_parts)]
1100         if len(lookup_parts) > 1 and not field_parts:
1101             raise FieldError(
1102                 'Invalid lookup "%s" for model %s".' %
1103                 (lookup, self.get_meta().model.__name__)
1104             )
1105         return lookup_parts, field_parts, False
1106 
1107     def check_query_object_type(self, value, opts, field):
1108         """
1109         Check whether the object passed while querying is of the correct type.
1110         If not, raise a ValueError specifying the wrong object.
1111         """
1112         if hasattr(value, '_meta'):
1113             if not check_rel_lookup_compatibility(value._meta.model, opts, field):
1114                 raise ValueError(
1115                     'Cannot query "%s": Must be "%s" instance.' %
1116                     (value, opts.object_name))
1117 
1118     def check_related_objects(self, field, value, opts):
1119         """Check the type of object passed to query relations."""
1120         if field.is_relation:
1121             # Check that the field and the queryset use the same model in a
1122             # query like .filter(author=Author.objects.all()). For example, the
1123             # opts would be Author's (from the author field) and value.model
1124             # would be Author.objects.all() queryset's .model (Author also).
1125             # The field is the related field on the lhs side.
1126             if (isinstance(value, Query) and not value.has_select_fields and
1127                     not check_rel_lookup_compatibility(value.model, opts, field)):
1128                 raise ValueError(
1129                     'Cannot use QuerySet for "%s": Use a QuerySet for "%s".' %
1130                     (value.model._meta.object_name, opts.object_name)
1131                 )
1132             elif hasattr(value, '_meta'):
1133                 self.check_query_object_type(value, opts, field)
1134             elif hasattr(value, '__iter__'):
1135                 for v in value:
1136                     self.check_query_object_type(v, opts, field)
1137 
1138     def check_filterable(self, expression):
1139         """Raise an error if expression cannot be used in a WHERE clause."""
1140         if (
1141             hasattr(expression, 'resolve_expression') and
1142             not getattr(expression, 'filterable', True)
1143         ):
1144             raise NotSupportedError(
1145                 expression.__class__.__name__ + ' is disallowed in the filter '
1146                 'clause.'
1147             )
1148         if hasattr(expression, 'get_source_expressions'):
1149             for expr in expression.get_source_expressions():
1150                 self.check_filterable(expr)
1151 
1152     def build_lookup(self, lookups, lhs, rhs):
1153         """
1154         Try to extract transforms and lookup from given lhs.
1155 
1156         The lhs value is something that works like SQLExpression.
1157         The rhs value is what the lookup is going to compare against.
1158         The lookups is a list of names to extract using get_lookup()
1159         and get_transform().
1160         """
1161         # __exact is the default lookup if one isn't given.
1162         *transforms, lookup_name = lookups or ['exact']
1163         for name in transforms:
1164             lhs = self.try_transform(lhs, name)
1165         # First try get_lookup() so that the lookup takes precedence if the lhs
1166         # supports both transform and lookup for the name.
1167         lookup_class = lhs.get_lookup(lookup_name)
1168         if not lookup_class:
1169             if lhs.field.is_relation:
1170                 raise FieldError('Related Field got invalid lookup: {}'.format(lookup_name))
1171             # A lookup wasn't found. Try to interpret the name as a transform
1172             # and do an Exact lookup against it.
1173             lhs = self.try_transform(lhs, lookup_name)
1174             lookup_name = 'exact'
1175             lookup_class = lhs.get_lookup(lookup_name)
1176             if not lookup_class:
1177                 return
1178 
1179         lookup = lookup_class(lhs, rhs)
1180         # Interpret '__exact=None' as the sql 'is NULL'; otherwise, reject all
1181         # uses of None as a query value unless the lookup supports it.
1182         if lookup.rhs is None and not lookup.can_use_none_as_rhs:
1183             if lookup_name not in ('exact', 'iexact'):
1184                 raise ValueError("Cannot use None as a query value")
1185             return lhs.get_lookup('isnull')(lhs, True)
1186 
1187         # For Oracle '' is equivalent to null. The check must be done at this
1188         # stage because join promotion can't be done in the compiler. Using
1189         # DEFAULT_DB_ALIAS isn't nice but it's the best that can be done here.
1190         # A similar thing is done in is_nullable(), too.
1191         if (connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls and
1192                 lookup_name == 'exact' and lookup.rhs == ''):
1193             return lhs.get_lookup('isnull')(lhs, True)
1194 
1195         return lookup
1196 
1197     def try_transform(self, lhs, name):
1198         """
1199         Helper method for build_lookup(). Try to fetch and initialize
1200         a transform for name parameter from lhs.
1201         """
1202         transform_class = lhs.get_transform(name)
1203         if transform_class:
1204             return transform_class(lhs)
1205         else:
1206             output_field = lhs.output_field.__class__
1207             suggested_lookups = difflib.get_close_matches(name, output_field.get_lookups())
1208             if suggested_lookups:
1209                 suggestion = ', perhaps you meant %s?' % ' or '.join(suggested_lookups)
1210             else:
1211                 suggestion = '.'
1212             raise FieldError(
1213                 "Unsupported lookup '%s' for %s or join on the field not "
1214                 "permitted%s" % (name, output_field.__name__, suggestion)
1215             )
1216 
1217     def build_filter(self, filter_expr, branch_negated=False, current_negated=False,
1218                      can_reuse=None, allow_joins=True, split_subq=True,
1219                      check_filterable=True):
1220         """
1221         Build a WhereNode for a single filter clause but don't add it
1222         to this Query. Query.add_q() will then add this filter to the where
1223         Node.
1224 
1225         The 'branch_negated' tells us if the current branch contains any
1226         negations. This will be used to determine if subqueries are needed.
1227 
1228         The 'current_negated' is used to determine if the current filter is
1229         negated or not and this will be used to determine if IS NULL filtering
1230         is needed.
1231 
1232         The difference between current_negated and branch_negated is that
1233         branch_negated is set on first negation, but current_negated is
1234         flipped for each negation.
1235 
1236         Note that add_filter will not do any negating itself, that is done
1237         upper in the code by add_q().
1238 
1239         The 'can_reuse' is a set of reusable joins for multijoins.
1240 
1241         The method will create a filter clause that can be added to the current
1242         query. However, if the filter isn't added to the query then the caller
1243         is responsible for unreffing the joins used.
1244         """
1245         if isinstance(filter_expr, dict):
1246             raise FieldError("Cannot parse keyword query as dict")
1247         if isinstance(filter_expr, Q):
1248             return self._add_q(
1249                 filter_expr,
1250                 branch_negated=branch_negated,
1251                 current_negated=current_negated,
1252                 used_aliases=can_reuse,
1253                 allow_joins=allow_joins,
1254                 split_subq=split_subq,
1255                 check_filterable=check_filterable,
1256             )
1257         if hasattr(filter_expr, 'resolve_expression'):
1258             if not getattr(filter_expr, 'conditional', False):
1259                 raise TypeError('Cannot filter against a non-conditional expression.')
1260             condition = self.build_lookup(
1261                 ['exact'], filter_expr.resolve_expression(self, allow_joins=allow_joins), True
1262             )
1263             clause = self.where_class()
1264             clause.add(condition, AND)
1265             return clause, []
1266         arg, value = filter_expr
1267         if not arg:
1268             raise FieldError("Cannot parse keyword query %r" % arg)
1269         lookups, parts, reffed_expression = self.solve_lookup_type(arg)
1270 
1271         if check_filterable:
1272             self.check_filterable(reffed_expression)
1273 
1274         if not allow_joins and len(parts) > 1:
1275             raise FieldError("Joined field references are not permitted in this query")
1276 
1277         pre_joins = self.alias_refcount.copy()
1278         value = self.resolve_lookup_value(value, can_reuse, allow_joins)
1279         used_joins = {k for k, v in self.alias_refcount.items() if v > pre_joins.get(k, 0)}
1280 
1281         if check_filterable:
1282             self.check_filterable(value)
1283 
1284         clause = self.where_class()
1285         if reffed_expression:
1286             condition = self.build_lookup(lookups, reffed_expression, value)
1287             clause.add(condition, AND)
1288             return clause, []
1289 
1290         opts = self.get_meta()
1291         alias = self.get_initial_alias()
1292         allow_many = not branch_negated or not split_subq
1293 
1294         try:
1295             join_info = self.setup_joins(
1296                 parts, opts, alias, can_reuse=can_reuse, allow_many=allow_many,
1297             )
1298 
1299             # Prevent iterator from being consumed by check_related_objects()
1300             if isinstance(value, Iterator):
1301                 value = list(value)
1302             self.check_related_objects(join_info.final_field, value, join_info.opts)
1303 
1304             # split_exclude() needs to know which joins were generated for the
1305             # lookup parts
1306             self._lookup_joins = join_info.joins
1307         except MultiJoin as e:
1308             return self.split_exclude(filter_expr, can_reuse, e.names_with_path)
1309 
1310         # Update used_joins before trimming since they are reused to determine
1311         # which joins could be later promoted to INNER.
1312         used_joins.update(join_info.joins)
1313         targets, alias, join_list = self.trim_joins(join_info.targets, join_info.joins, join_info.path)
1314         if can_reuse is not None:
1315             can_reuse.update(join_list)
1316 
1317         if join_info.final_field.is_relation:
1318             # No support for transforms for relational fields
1319             num_lookups = len(lookups)
1320             if num_lookups > 1:
1321                 raise FieldError('Related Field got invalid lookup: {}'.format(lookups[0]))
1322             if len(targets) == 1:
1323                 col = self._get_col(targets[0], join_info.final_field, alias)
1324             else:
1325                 col = MultiColSource(alias, targets, join_info.targets, join_info.final_field)
1326         else:
1327             col = self._get_col(targets[0], join_info.final_field, alias)
1328 
1329         condition = self.build_lookup(lookups, col, value)
1330         lookup_type = condition.lookup_name
1331         clause.add(condition, AND)
1332 
1333         require_outer = lookup_type == 'isnull' and condition.rhs is True and not current_negated
1334         if current_negated and (lookup_type != 'isnull' or condition.rhs is False) and condition.rhs is not None:
1335             require_outer = True
1336             if lookup_type != 'isnull':
1337                 # The condition added here will be SQL like this:
1338                 # NOT (col IS NOT NULL), where the first NOT is added in
1339                 # upper layers of code. The reason for addition is that if col
1340                 # is null, then col != someval will result in SQL "unknown"
1341                 # which isn't the same as in Python. The Python None handling
1342                 # is wanted, and it can be gotten by
1343                 # (col IS NULL OR col != someval)
1344                 #   <=>
1345                 # NOT (col IS NOT NULL AND col = someval).
1346                 if (
1347                     self.is_nullable(targets[0]) or
1348                     self.alias_map[join_list[-1]].join_type == LOUTER
1349                 ):
1350                     lookup_class = targets[0].get_lookup('isnull')
1351                     col = self._get_col(targets[0], join_info.targets[0], alias)
1352                     clause.add(lookup_class(col, False), AND)
1353                 # If someval is a nullable column, someval IS NOT NULL is
1354                 # added.
1355                 if isinstance(value, Col) and self.is_nullable(value.target):
1356                     lookup_class = value.target.get_lookup('isnull')
1357                     clause.add(lookup_class(value, False), AND)
1358         return clause, used_joins if not require_outer else ()
1359 
1360     def add_filter(self, filter_clause):
1361         self.add_q(Q(**{filter_clause[0]: filter_clause[1]}))
1362 
1363     def add_q(self, q_object):
1364         """
1365         A preprocessor for the internal _add_q(). Responsible for doing final
1366         join promotion.
1367         """
1368         # For join promotion this case is doing an AND for the added q_object
1369         # and existing conditions. So, any existing inner join forces the join
1370         # type to remain inner. Existing outer joins can however be demoted.
1371         # (Consider case where rel_a is LOUTER and rel_a__col=1 is added - if
1372         # rel_a doesn't produce any rows, then the whole condition must fail.
1373         # So, demotion is OK.
1374         existing_inner = {a for a in self.alias_map if self.alias_map[a].join_type == INNER}
1375         clause, _ = self._add_q(q_object, self.used_aliases)
1376         if clause:
1377             self.where.add(clause, AND)
1378         self.demote_joins(existing_inner)
1379 
1380     def build_where(self, filter_expr):
1381         return self.build_filter(filter_expr, allow_joins=False)[0]
1382 
1383     def _add_q(self, q_object, used_aliases, branch_negated=False,
1384                current_negated=False, allow_joins=True, split_subq=True,
1385                check_filterable=True):
1386         """Add a Q-object to the current filter."""
1387         connector = q_object.connector
1388         current_negated = current_negated ^ q_object.negated
1389         branch_negated = branch_negated or q_object.negated
1390         target_clause = self.where_class(connector=connector,
1391                                          negated=q_object.negated)
1392         joinpromoter = JoinPromoter(q_object.connector, len(q_object.children), current_negated)
1393         for child in q_object.children:
1394             child_clause, needed_inner = self.build_filter(
1395                 child, can_reuse=used_aliases, branch_negated=branch_negated,
1396                 current_negated=current_negated, allow_joins=allow_joins,
1397                 split_subq=split_subq, check_filterable=check_filterable,
1398             )
1399             joinpromoter.add_votes(needed_inner)
1400             if child_clause:
1401                 target_clause.add(child_clause, connector)
1402         needed_inner = joinpromoter.update_join_types(self)
1403         return target_clause, needed_inner
1404 
1405     def build_filtered_relation_q(self, q_object, reuse, branch_negated=False, current_negated=False):
1406         """Add a FilteredRelation object to the current filter."""
1407         connector = q_object.connector
1408         current_negated ^= q_object.negated
1409         branch_negated = branch_negated or q_object.negated
1410         target_clause = self.where_class(connector=connector, negated=q_object.negated)
1411         for child in q_object.children:
1412             if isinstance(child, Node):
1413                 child_clause = self.build_filtered_relation_q(
1414                     child, reuse=reuse, branch_negated=branch_negated,
1415                     current_negated=current_negated,
1416                 )
1417             else:
1418                 child_clause, _ = self.build_filter(
1419                     child, can_reuse=reuse, branch_negated=branch_negated,
1420                     current_negated=current_negated,
1421                     allow_joins=True, split_subq=False,
1422                 )
1423             target_clause.add(child_clause, connector)
1424         return target_clause
1425 
1426     def add_filtered_relation(self, filtered_relation, alias):
1427         filtered_relation.alias = alias
1428         lookups = dict(get_children_from_q(filtered_relation.condition))
1429         relation_lookup_parts, relation_field_parts, _ = self.solve_lookup_type(filtered_relation.relation_name)
1430         if relation_lookup_parts:
1431             raise ValueError(
1432                 "FilteredRelation's relation_name cannot contain lookups "
1433                 "(got %r)." % filtered_relation.relation_name
1434             )
1435         for lookup in chain(lookups):
1436             lookup_parts, lookup_field_parts, _ = self.solve_lookup_type(lookup)
1437             shift = 2 if not lookup_parts else 1
1438             lookup_field_path = lookup_field_parts[:-shift]
1439             for idx, lookup_field_part in enumerate(lookup_field_path):
1440                 if len(relation_field_parts) > idx:
1441                     if relation_field_parts[idx] != lookup_field_part:
1442                         raise ValueError(
1443                             "FilteredRelation's condition doesn't support "
1444                             "relations outside the %r (got %r)."
1445                             % (filtered_relation.relation_name, lookup)
1446                         )
1447                 else:
1448                     raise ValueError(
1449                         "FilteredRelation's condition doesn't support nested "
1450                         "relations deeper than the relation_name (got %r for "
1451                         "%r)." % (lookup, filtered_relation.relation_name)
1452                     )
1453         self._filtered_relations[filtered_relation.alias] = filtered_relation
1454 
1455     def names_to_path(self, names, opts, allow_many=True, fail_on_missing=False):
1456         """
1457         Walk the list of names and turns them into PathInfo tuples. A single
1458         name in 'names' can generate multiple PathInfos (m2m, for example).
1459 
1460         'names' is the path of names to travel, 'opts' is the model Options we
1461         start the name resolving from, 'allow_many' is as for setup_joins().
1462         If fail_on_missing is set to True, then a name that can't be resolved
1463         will generate a FieldError.
1464 
1465         Return a list of PathInfo tuples. In addition return the final field
1466         (the last used join field) and target (which is a field guaranteed to
1467         contain the same value as the final field). Finally, return those names
1468         that weren't found (which are likely transforms and the final lookup).
1469         """
1470         path, names_with_path = [], []
1471         for pos, name in enumerate(names):
1472             cur_names_with_path = (name, [])
1473             if name == 'pk':
1474                 name = opts.pk.name
1475 
1476             field = None
1477             filtered_relation = None
1478             try:
1479                 field = opts.get_field(name)
1480             except FieldDoesNotExist:
1481                 if name in self.annotation_select:
1482                     field = self.annotation_select[name].output_field
1483                 elif name in self._filtered_relations and pos == 0:
1484                     filtered_relation = self._filtered_relations[name]
1485                     if LOOKUP_SEP in filtered_relation.relation_name:
1486                         parts = filtered_relation.relation_name.split(LOOKUP_SEP)
1487                         filtered_relation_path, field, _, _ = self.names_to_path(
1488                             parts, opts, allow_many, fail_on_missing,
1489                         )
1490                         path.extend(filtered_relation_path[:-1])
1491                     else:
1492                         field = opts.get_field(filtered_relation.relation_name)
1493             if field is not None:
1494                 # Fields that contain one-to-many relations with a generic
1495                 # model (like a GenericForeignKey) cannot generate reverse
1496                 # relations and therefore cannot be used for reverse querying.
1497                 if field.is_relation and not field.related_model:
1498                     raise FieldError(
1499                         "Field %r does not generate an automatic reverse "
1500                         "relation and therefore cannot be used for reverse "
1501                         "querying. If it is a GenericForeignKey, consider "
1502                         "adding a GenericRelation." % name
1503                     )
1504                 try:
1505                     model = field.model._meta.concrete_model
1506                 except AttributeError:
1507                     # QuerySet.annotate() may introduce fields that aren't
1508                     # attached to a model.
1509                     model = None
1510             else:
1511                 # We didn't find the current field, so move position back
1512                 # one step.
1513                 pos -= 1
1514                 if pos == -1 or fail_on_missing:
1515                     available = sorted([
1516                         *get_field_names_from_opts(opts),
1517                         *self.annotation_select,
1518                         *self._filtered_relations,
1519                     ])
1520                     raise FieldError("Cannot resolve keyword '%s' into field. "
1521                                      "Choices are: %s" % (name, ", ".join(available)))
1522                 break
1523             # Check if we need any joins for concrete inheritance cases (the
1524             # field lives in parent, but we are currently in one of its
1525             # children)
1526             if model is not opts.model:
1527                 path_to_parent = opts.get_path_to_parent(model)
1528                 if path_to_parent:
1529                     path.extend(path_to_parent)
1530                     cur_names_with_path[1].extend(path_to_parent)
1531                     opts = path_to_parent[-1].to_opts
1532             if hasattr(field, 'get_path_info'):
1533                 pathinfos = field.get_path_info(filtered_relation)
1534                 if not allow_many:
1535                     for inner_pos, p in enumerate(pathinfos):
1536                         if p.m2m:
1537                             cur_names_with_path[1].extend(pathinfos[0:inner_pos + 1])
1538                             names_with_path.append(cur_names_with_path)
1539                             raise MultiJoin(pos + 1, names_with_path)
1540                 last = pathinfos[-1]
1541                 path.extend(pathinfos)
1542                 final_field = last.join_field
1543                 opts = last.to_opts
1544                 targets = last.target_fields
1545                 cur_names_with_path[1].extend(pathinfos)
1546                 names_with_path.append(cur_names_with_path)
1547             else:
1548                 # Local non-relational field.
1549                 final_field = field
1550                 targets = (field,)
1551                 if fail_on_missing and pos + 1 != len(names):
1552                     raise FieldError(
1553                         "Cannot resolve keyword %r into field. Join on '%s'"
1554                         " not permitted." % (names[pos + 1], name))
1555                 break
1556         return path, final_field, targets, names[pos + 1:]
1557 
1558     def setup_joins(self, names, opts, alias, can_reuse=None, allow_many=True):
1559         """
1560         Compute the necessary table joins for the passage through the fields
1561         given in 'names'. 'opts' is the Options class for the current model
1562         (which gives the table we are starting from), 'alias' is the alias for
1563         the table to start the joining from.
1564 
1565         The 'can_reuse' defines the reverse foreign key joins we can reuse. It
1566         can be None in which case all joins are reusable or a set of aliases
1567         that can be reused. Note that non-reverse foreign keys are always
1568         reusable when using setup_joins().
1569 
1570         If 'allow_many' is False, then any reverse foreign key seen will
1571         generate a MultiJoin exception.
1572 
1573         Return the final field involved in the joins, the target field (used
1574         for any 'where' constraint), the final 'opts' value, the joins, the
1575         field path traveled to generate the joins, and a transform function
1576         that takes a field and alias and is equivalent to `field.get_col(alias)`
1577         in the simple case but wraps field transforms if they were included in
1578         names.
1579 
1580         The target field is the field containing the concrete value. Final
1581         field can be something different, for example foreign key pointing to
1582         that value. Final field is needed for example in some value
1583         conversions (convert 'obj' in fk__id=obj to pk val using the foreign
1584         key field for example).
1585         """
1586         joins = [alias]
1587         # The transform can't be applied yet, as joins must be trimmed later.
1588         # To avoid making every caller of this method look up transforms
1589         # directly, compute transforms here and create a partial that converts
1590         # fields to the appropriate wrapped version.
1591 
1592         def final_transformer(field, alias):
1593             if not self.alias_cols:
1594                 alias = None
1595             return field.get_col(alias)
1596 
1597         # Try resolving all the names as fields first. If there's an error,
1598         # treat trailing names as lookups until a field can be resolved.
1599         last_field_exception = None
1600         for pivot in range(len(names), 0, -1):
1601             try:
1602                 path, final_field, targets, rest = self.names_to_path(
1603                     names[:pivot], opts, allow_many, fail_on_missing=True,
1604                 )
1605             except FieldError as exc:
1606                 if pivot == 1:
1607                     # The first item cannot be a lookup, so it's safe
1608                     # to raise the field error here.
1609                     raise
1610                 else:
1611                     last_field_exception = exc
1612             else:
1613                 # The transforms are the remaining items that couldn't be
1614                 # resolved into fields.
1615                 transforms = names[pivot:]
1616                 break
1617         for name in transforms:
1618             def transform(field, alias, *, name, previous):
1619                 try:
1620                     wrapped = previous(field, alias)
1621                     return self.try_transform(wrapped, name)
1622                 except FieldError:
1623                     # FieldError is raised if the transform doesn't exist.
1624                     if isinstance(final_field, Field) and last_field_exception:
1625                         raise last_field_exception
1626                     else:
1627                         raise
1628             final_transformer = functools.partial(transform, name=name, previous=final_transformer)
1629         # Then, add the path to the query's joins. Note that we can't trim
1630         # joins at this stage - we will need the information about join type
1631         # of the trimmed joins.
1632         for join in path:
1633             if join.filtered_relation:
1634                 filtered_relation = join.filtered_relation.clone()
1635                 table_alias = filtered_relation.alias
1636             else:
1637                 filtered_relation = None
1638                 table_alias = None
1639             opts = join.to_opts
1640             if join.direct:
1641                 nullable = self.is_nullable(join.join_field)
1642             else:
1643                 nullable = True
1644             connection = Join(
1645                 opts.db_table, alias, table_alias, INNER, join.join_field,
1646                 nullable, filtered_relation=filtered_relation,
1647             )
1648             reuse = can_reuse if join.m2m else None
1649             alias = self.join(connection, reuse=reuse)
1650             joins.append(alias)
1651             if filtered_relation:
1652                 filtered_relation.path = joins[:]
1653         return JoinInfo(final_field, targets, opts, joins, path, final_transformer)
1654 
1655     def trim_joins(self, targets, joins, path):
1656         """
1657         The 'target' parameter is the final field being joined to, 'joins'
1658         is the full list of join aliases. The 'path' contain the PathInfos
1659         used to create the joins.
1660 
1661         Return the final target field and table alias and the new active
1662         joins.
1663 
1664         Always trim any direct join if the target column is already in the
1665         previous table. Can't trim reverse joins as it's unknown if there's
1666         anything on the other side of the join.
1667         """
1668         joins = joins[:]
1669         for pos, info in enumerate(reversed(path)):
1670             if len(joins) == 1 or not info.direct:
1671                 break
1672             if info.filtered_relation:
1673                 break
1674             join_targets = {t.column for t in info.join_field.foreign_related_fields}
1675             cur_targets = {t.column for t in targets}
1676             if not cur_targets.issubset(join_targets):
1677                 break
1678             targets_dict = {r[1].column: r[0] for r in info.join_field.related_fields if r[1].column in cur_targets}
1679             targets = tuple(targets_dict[t.column] for t in targets)
1680             self.unref_alias(joins.pop())
1681         return targets, joins[-1], joins
1682 
1683     @classmethod
1684     def _gen_cols(cls, exprs, include_external=False):
1685         for expr in exprs:
1686             if isinstance(expr, Col):
1687                 yield expr
1688             elif include_external and callable(getattr(expr, 'get_external_cols', None)):
1689                 yield from expr.get_external_cols()
1690             else:
1691                 yield from cls._gen_cols(
1692                     expr.get_source_expressions(),
1693                     include_external=include_external,
1694                 )
1695 
1696     @classmethod
1697     def _gen_col_aliases(cls, exprs):
1698         yield from (expr.alias for expr in cls._gen_cols(exprs))
1699 
1700     def resolve_ref(self, name, allow_joins=True, reuse=None, summarize=False):
1701         annotation = self.annotations.get(name)
1702         if annotation is not None:
1703             if not allow_joins:
1704                 for alias in self._gen_col_aliases([annotation]):
1705                     if isinstance(self.alias_map[alias], Join):
1706                         raise FieldError(
1707                             'Joined field references are not permitted in '
1708                             'this query'
1709                         )
1710             if summarize:
1711                 # Summarize currently means we are doing an aggregate() query
1712                 # which is executed as a wrapped subquery if any of the
1713                 # aggregate() elements reference an existing annotation. In
1714                 # that case we need to return a Ref to the subquery's annotation.
1715                 if name not in self.annotation_select:
1716                     raise FieldError(
1717                         "Cannot aggregate over the '%s' alias. Use annotate() "
1718                         "to promote it." % name
1719                     )
1720                 return Ref(name, self.annotation_select[name])
1721             else:
1722                 return annotation
1723         else:
1724             field_list = name.split(LOOKUP_SEP)
1725             annotation = self.annotations.get(field_list[0])
1726             if annotation is not None:
1727                 for transform in field_list[1:]:
1728                     annotation = self.try_transform(annotation, transform)
1729                 return annotation
1730             join_info = self.setup_joins(field_list, self.get_meta(), self.get_initial_alias(), can_reuse=reuse)
1731             targets, final_alias, join_list = self.trim_joins(join_info.targets, join_info.joins, join_info.path)
1732             if not allow_joins and len(join_list) > 1:
1733                 raise FieldError('Joined field references are not permitted in this query')
1734             if len(targets) > 1:
1735                 raise FieldError("Referencing multicolumn fields with F() objects "
1736                                  "isn't supported")
1737             # Verify that the last lookup in name is a field or a transform:
1738             # transform_function() raises FieldError if not.
1739             transform = join_info.transform_function(targets[0], final_alias)
1740             if reuse is not None:
1741                 reuse.update(join_list)
1742             return transform
1743 
1744     def split_exclude(self, filter_expr, can_reuse, names_with_path):
1745         """
1746         When doing an exclude against any kind of N-to-many relation, we need
1747         to use a subquery. This method constructs the nested query, given the
1748         original exclude filter (filter_expr) and the portion up to the first
1749         N-to-many relation field.
1750 
1751         For example, if the origin filter is ~Q(child__name='foo'), filter_expr
1752         is ('child__name', 'foo') and can_reuse is a set of joins usable for
1753         filters in the original query.
1754 
1755         We will turn this into equivalent of:
1756             WHERE NOT EXISTS(
1757                 SELECT 1
1758                 FROM child
1759                 WHERE name = 'foo' AND child.parent_id = parent.id
1760                 LIMIT 1
1761             )
1762         """
1763         filter_lhs, filter_rhs = filter_expr
1764         if isinstance(filter_rhs, OuterRef):
1765             filter_expr = (filter_lhs, OuterRef(filter_rhs))
1766         elif isinstance(filter_rhs, F):
1767             filter_expr = (filter_lhs, OuterRef(filter_rhs.name))
1768         # Generate the inner query.
1769         query = Query(self.model)
1770         query._filtered_relations = self._filtered_relations
1771         query.add_filter(filter_expr)
1772         query.clear_ordering(force=True)
1773         # Try to have as simple as possible subquery -> trim leading joins from
1774         # the subquery.
1775         trimmed_prefix, contains_louter = query.trim_start(names_with_path)
1776 
1777         col = query.select[0]
1778         select_field = col.target
1779         alias = col.alias
1780         if alias in can_reuse:
1781             pk = select_field.model._meta.pk
1782             # Need to add a restriction so that outer query's filters are in effect for
1783             # the subquery, too.
1784             query.bump_prefix(self)
1785             lookup_class = select_field.get_lookup('exact')
1786             # Note that the query.select[0].alias is different from alias
1787             # due to bump_prefix above.
1788             lookup = lookup_class(pk.get_col(query.select[0].alias),
1789                                   pk.get_col(alias))
1790             query.where.add(lookup, AND)
1791             query.external_aliases[alias] = True
1792 
1793         lookup_class = select_field.get_lookup('exact')
1794         lookup = lookup_class(col, ResolvedOuterRef(trimmed_prefix))
1795         query.where.add(lookup, AND)
1796         condition, needed_inner = self.build_filter(Exists(query))
1797 
1798         if contains_louter:
1799             or_null_condition, _ = self.build_filter(
1800                 ('%s__isnull' % trimmed_prefix, True),
1801                 current_negated=True, branch_negated=True, can_reuse=can_reuse)
1802             condition.add(or_null_condition, OR)
1803             # Note that the end result will be:
1804             # (outercol NOT IN innerq AND outercol IS NOT NULL) OR outercol IS NULL.
1805             # This might look crazy but due to how IN works, this seems to be
1806             # correct. If the IS NOT NULL check is removed then outercol NOT
1807             # IN will return UNKNOWN. If the IS NULL check is removed, then if
1808             # outercol IS NULL we will not match the row.
1809         return condition, needed_inner
1810 
1811     def set_empty(self):
1812         self.where.add(NothingNode(), AND)
1813         for query in self.combined_queries:
1814             query.set_empty()
1815 
1816     def is_empty(self):
1817         return any(isinstance(c, NothingNode) for c in self.where.children)
1818 
1819     def set_limits(self, low=None, high=None):
1820         """
1821         Adjust the limits on the rows retrieved. Use low/high to set these,
1822         as it makes it more Pythonic to read and write. When the SQL query is
1823         created, convert them to the appropriate offset and limit values.
1824 
1825         Apply any limits passed in here to the existing constraints. Add low
1826         to the current low value and clamp both to any existing high value.
1827         """
1828         if high is not None:
1829             if self.high_mark is not None:
1830                 self.high_mark = min(self.high_mark, self.low_mark + high)
1831             else:
1832                 self.high_mark = self.low_mark + high
1833         if low is not None:
1834             if self.high_mark is not None:
1835                 self.low_mark = min(self.high_mark, self.low_mark + low)
1836             else:
1837                 self.low_mark = self.low_mark + low
1838 
1839         if self.low_mark == self.high_mark:
1840             self.set_empty()
1841 
1842     def clear_limits(self):
1843         """Clear any existing limits."""
1844         self.low_mark, self.high_mark = 0, None
1845 
1846     @property
1847     def is_sliced(self):
1848         return self.low_mark != 0 or self.high_mark is not None
1849 
1850     def has_limit_one(self):
1851         return self.high_mark is not None and (self.high_mark - self.low_mark) == 1
1852 
1853     def can_filter(self):
1854         """
1855         Return True if adding filters to this instance is still possible.
1856 
1857         Typically, this means no limits or offsets have been put on the results.
1858         """
1859         return not self.is_sliced
1860 
1861     def clear_select_clause(self):
1862         """Remove all fields from SELECT clause."""
1863         self.select = ()
1864         self.default_cols = False
1865         self.select_related = False
1866         self.set_extra_mask(())
1867         self.set_annotation_mask(())
1868 
1869     def clear_select_fields(self):
1870         """
1871         Clear the list of fields to select (but not extra_select columns).
1872         Some queryset types completely replace any existing list of select
1873         columns.
1874         """
1875         self.select = ()
1876         self.values_select = ()
1877 
1878     def add_select_col(self, col, name):
1879         self.select += col,
1880         self.values_select += name,
1881 
1882     def set_select(self, cols):
1883         self.default_cols = False
1884         self.select = tuple(cols)
1885 
1886     def add_distinct_fields(self, *field_names):
1887         """
1888         Add and resolve the given fields to the query's "distinct on" clause.
1889         """
1890         self.distinct_fields = field_names
1891         self.distinct = True
1892 
1893     def add_fields(self, field_names, allow_m2m=True):
1894         """
1895         Add the given (model) fields to the select set. Add the field names in
1896         the order specified.
1897         """
1898         alias = self.get_initial_alias()
1899         opts = self.get_meta()
1900 
1901         try:
1902             cols = []
1903             for name in field_names:
1904                 # Join promotion note - we must not remove any rows here, so
1905                 # if there is no existing joins, use outer join.
1906                 join_info = self.setup_joins(name.split(LOOKUP_SEP), opts, alias, allow_many=allow_m2m)
1907                 targets, final_alias, joins = self.trim_joins(
1908                     join_info.targets,
1909                     join_info.joins,
1910                     join_info.path,
1911                 )
1912                 for target in targets:
1913                     cols.append(join_info.transform_function(target, final_alias))
1914             if cols:
1915                 self.set_select(cols)
1916         except MultiJoin:
1917             raise FieldError("Invalid field name: '%s'" % name)
1918         except FieldError:
1919             if LOOKUP_SEP in name:
1920                 # For lookups spanning over relationships, show the error
1921                 # from the model on which the lookup failed.
1922                 raise
1923             elif name in self.annotations:
1924                 raise FieldError(
1925                     "Cannot select the '%s' alias. Use annotate() to promote "
1926                     "it." % name
1927                 )
1928             else:
1929                 names = sorted([
1930                     *get_field_names_from_opts(opts), *self.extra,
1931                     *self.annotation_select, *self._filtered_relations
1932                 ])
1933                 raise FieldError("Cannot resolve keyword %r into field. "
1934                                  "Choices are: %s" % (name, ", ".join(names)))
1935 
1936     def add_ordering(self, *ordering):
1937         """
1938         Add items from the 'ordering' sequence to the query's "order by"
1939         clause. These items are either field names (not column names) --
1940         possibly with a direction prefix ('-' or '?') -- or OrderBy
1941         expressions.
1942 
1943         If 'ordering' is empty, clear all ordering from the query.
1944         """
1945         errors = []
1946         for item in ordering:
1947             if isinstance(item, str):
1948                 if item == '?':
1949                     continue
1950                 if item.startswith('-'):
1951                     item = item[1:]
1952                 if item in self.annotations:
1953                     continue
1954                 if self.extra and item in self.extra:
1955                     continue
1956                 # names_to_path() validates the lookup. A descriptive
1957                 # FieldError will be raise if it's not.
1958                 self.names_to_path(item.split(LOOKUP_SEP), self.model._meta)
1959             elif not hasattr(item, 'resolve_expression'):
1960                 errors.append(item)
1961             if getattr(item, 'contains_aggregate', False):
1962                 raise FieldError(
1963                     'Using an aggregate in order_by() without also including '
1964                     'it in annotate() is not allowed: %s' % item
1965                 )
1966         if errors:
1967             raise FieldError('Invalid order_by arguments: %s' % errors)
1968         if ordering:
1969             self.order_by += ordering
1970         else:
1971             self.default_ordering = False
1972 
1973     def clear_ordering(self, force=False, clear_default=True):
1974         """
1975         Remove any ordering settings if the current query allows it without
1976         side effects, set 'force' to True to clear the ordering regardless.
1977         If 'clear_default' is True, there will be no ordering in the resulting
1978         query (not even the model's default).
1979         """
1980         if not force and (self.is_sliced or self.distinct_fields or self.select_for_update):
1981             return
1982         self.order_by = ()
1983         self.extra_order_by = ()
1984         if clear_default:
1985             self.default_ordering = False
1986 
1987     def set_group_by(self, allow_aliases=True):
1988         """
1989         Expand the GROUP BY clause required by the query.
1990 
1991         This will usually be the set of all non-aggregate fields in the
1992         return data. If the database backend supports grouping by the
1993         primary key, and the query would be equivalent, the optimization
1994         will be made automatically.
1995         """
1996         # Column names from JOINs to check collisions with aliases.
1997         if allow_aliases:
1998             column_names = set()
1999             seen_models = set()
2000             for join in list(self.alias_map.values())[1:]:  # Skip base table.
2001                 model = join.join_field.related_model
2002                 if model not in seen_models:
2003                     column_names.update({
2004                         field.column
2005                         for field in model._meta.local_concrete_fields
2006                     })
2007                     seen_models.add(model)
2008 
2009         group_by = list(self.select)
2010         if self.annotation_select:
2011             for alias, annotation in self.annotation_select.items():
2012                 if not allow_aliases or alias in column_names:
2013                     alias = None
2014                 group_by_cols = annotation.get_group_by_cols(alias=alias)
2015                 group_by.extend(group_by_cols)
2016         self.group_by = tuple(group_by)
2017 
2018     def add_select_related(self, fields):
2019         """
2020         Set up the select_related data structure so that we only select
2021         certain related models (as opposed to all models, when
2022         self.select_related=True).
2023         """
2024         if isinstance(self.select_related, bool):
2025             field_dict = {}
2026         else:
2027             field_dict = self.select_related
2028         for field in fields:
2029             d = field_dict
2030             for part in field.split(LOOKUP_SEP):
2031                 d = d.setdefault(part, {})
2032         self.select_related = field_dict
2033 
2034     def add_extra(self, select, select_params, where, params, tables, order_by):
2035         """
2036         Add data to the various extra_* attributes for user-created additions
2037         to the query.
2038         """
2039         if select:
2040             # We need to pair any placeholder markers in the 'select'
2041             # dictionary with their parameters in 'select_params' so that
2042             # subsequent updates to the select dictionary also adjust the
2043             # parameters appropriately.
2044             select_pairs = {}
2045             if select_params:
2046                 param_iter = iter(select_params)
2047             else:
2048                 param_iter = iter([])
2049             for name, entry in select.items():
2050                 entry = str(entry)
2051                 entry_params = []
2052                 pos = entry.find("%s")
2053                 while pos != -1:
2054                     if pos == 0 or entry[pos - 1] != '%':
2055                         entry_params.append(next(param_iter))
2056                     pos = entry.find("%s", pos + 2)
2057                 select_pairs[name] = (entry, entry_params)
2058             self.extra.update(select_pairs)
2059         if where or params:
2060             self.where.add(ExtraWhere(where, params), AND)
2061         if tables:
2062             self.extra_tables += tuple(tables)
2063         if order_by:
2064             self.extra_order_by = order_by
2065 
2066     def clear_deferred_loading(self):
2067         """Remove any fields from the deferred loading set."""
2068         self.deferred_loading = (frozenset(), True)
2069 
2070     def add_deferred_loading(self, field_names):
2071         """
2072         Add the given list of model field names to the set of fields to
2073         exclude from loading from the database when automatic column selection
2074         is done. Add the new field names to any existing field names that
2075         are deferred (or removed from any existing field names that are marked
2076         as the only ones for immediate loading).
2077         """
2078         # Fields on related models are stored in the literal double-underscore
2079         # format, so that we can use a set datastructure. We do the foo__bar
2080         # splitting and handling when computing the SQL column names (as part of
2081         # get_columns()).
2082         existing, defer = self.deferred_loading
2083         if defer:
2084             # Add to existing deferred names.
2085             self.deferred_loading = existing.union(field_names), True
2086         else:
2087             # Remove names from the set of any existing "immediate load" names.
2088             self.deferred_loading = existing.difference(field_names), False
2089 
2090     def add_immediate_loading(self, field_names):
2091         """
2092         Add the given list of model field names to the set of fields to
2093         retrieve when the SQL is executed ("immediate loading" fields). The
2094         field names replace any existing immediate loading field names. If
2095         there are field names already specified for deferred loading, remove
2096         those names from the new field_names before storing the new names
2097         for immediate loading. (That is, immediate loading overrides any
2098         existing immediate values, but respects existing deferrals.)
2099         """
2100         existing, defer = self.deferred_loading
2101         field_names = set(field_names)
2102         if 'pk' in field_names:
2103             field_names.remove('pk')
2104             field_names.add(self.get_meta().pk.name)
2105 
2106         if defer:
2107             # Remove any existing deferred names from the current set before
2108             # setting the new names.
2109             self.deferred_loading = field_names.difference(existing), False
2110         else:
2111             # Replace any existing "immediate load" field names.
2112             self.deferred_loading = frozenset(field_names), False
2113 
2114     def get_loaded_field_names(self):
2115         """
2116         If any fields are marked to be deferred, return a dictionary mapping
2117         models to a set of names in those fields that will be loaded. If a
2118         model is not in the returned dictionary, none of its fields are
2119         deferred.
2120 
2121         If no fields are marked for deferral, return an empty dictionary.
2122         """
2123         # We cache this because we call this function multiple times
2124         # (compiler.fill_related_selections, query.iterator)
2125         try:
2126             return self._loaded_field_names_cache
2127         except AttributeError:
2128             collection = {}
2129             self.deferred_to_data(collection, self.get_loaded_field_names_cb)
2130             self._loaded_field_names_cache = collection
2131             return collection
2132 
2133     def get_loaded_field_names_cb(self, target, model, fields):
2134         """Callback used by get_deferred_field_names()."""
2135         target[model] = {f.attname for f in fields}
2136 
2137     def set_annotation_mask(self, names):
2138         """Set the mask of annotations that will be returned by the SELECT."""
2139         if names is None:
2140             self.annotation_select_mask = None
2141         else:
2142             self.annotation_select_mask = set(names)
2143         self._annotation_select_cache = None
2144 
2145     def append_annotation_mask(self, names):
2146         if self.annotation_select_mask is not None:
2147             self.set_annotation_mask(self.annotation_select_mask.union(names))
2148 
2149     def set_extra_mask(self, names):
2150         """
2151         Set the mask of extra select items that will be returned by SELECT.
2152         Don't remove them from the Query since they might be used later.
2153         """
2154         if names is None:
2155             self.extra_select_mask = None
2156         else:
2157             self.extra_select_mask = set(names)
2158         self._extra_select_cache = None
2159 
2160     def set_values(self, fields):
2161         self.select_related = False
2162         self.clear_deferred_loading()
2163         self.clear_select_fields()
2164 
2165         if fields:
2166             field_names = []
2167             extra_names = []
2168             annotation_names = []
2169             if not self.extra and not self.annotations:
2170                 # Shortcut - if there are no extra or annotations, then
2171                 # the values() clause must be just field names.
2172                 field_names = list(fields)
2173             else:
2174                 self.default_cols = False
2175                 for f in fields:
2176                     if f in self.extra_select:
2177                         extra_names.append(f)
2178                     elif f in self.annotation_select:
2179                         annotation_names.append(f)
2180                     else:
2181                         field_names.append(f)
2182             self.set_extra_mask(extra_names)
2183             self.set_annotation_mask(annotation_names)
2184             selected = frozenset(field_names + extra_names + annotation_names)
2185         else:
2186             field_names = [f.attname for f in self.model._meta.concrete_fields]
2187             selected = frozenset(field_names)
2188         # Selected annotations must be known before setting the GROUP BY
2189         # clause.
2190         if self.group_by is True:
2191             self.add_fields((f.attname for f in self.model._meta.concrete_fields), False)
2192             # Disable GROUP BY aliases to avoid orphaning references to the
2193             # SELECT clause which is about to be cleared.
2194             self.set_group_by(allow_aliases=False)
2195             self.clear_select_fields()
2196         elif self.group_by:
2197             # Resolve GROUP BY annotation references if they are not part of
2198             # the selected fields anymore.
2199             group_by = []
2200             for expr in self.group_by:
2201                 if isinstance(expr, Ref) and expr.refs not in selected:
2202                     expr = self.annotations[expr.refs]
2203                 group_by.append(expr)
2204             self.group_by = tuple(group_by)
2205 
2206         self.values_select = tuple(field_names)
2207         self.add_fields(field_names, True)
2208 
2209     @property
2210     def annotation_select(self):
2211         """
2212         Return the dictionary of aggregate columns that are not masked and
2213         should be used in the SELECT clause. Cache this result for performance.
2214         """
2215         if self._annotation_select_cache is not None:
2216             return self._annotation_select_cache
2217         elif not self.annotations:
2218             return {}
2219         elif self.annotation_select_mask is not None:
2220             self._annotation_select_cache = {
2221                 k: v for k, v in self.annotations.items()
2222                 if k in self.annotation_select_mask
2223             }
2224             return self._annotation_select_cache
2225         else:
2226             return self.annotations
2227 
2228     @property
2229     def extra_select(self):
2230         if self._extra_select_cache is not None:
2231             return self._extra_select_cache
2232         if not self.extra:
2233             return {}
2234         elif self.extra_select_mask is not None:
2235             self._extra_select_cache = {
2236                 k: v for k, v in self.extra.items()
2237                 if k in self.extra_select_mask
2238             }
2239             return self._extra_select_cache
2240         else:
2241             return self.extra
2242 
2243     def trim_start(self, names_with_path):
2244         """
2245         Trim joins from the start of the join path. The candidates for trim
2246         are the PathInfos in names_with_path structure that are m2m joins.
2247 
2248         Also set the select column so the start matches the join.
2249 
2250         This method is meant to be used for generating the subquery joins &
2251         cols in split_exclude().
2252 
2253         Return a lookup usable for doing outerq.filter(lookup=self) and a
2254         boolean indicating if the joins in the prefix contain a LEFT OUTER join.
2255         _"""
2256         all_paths = []
2257         for _, paths in names_with_path:
2258             all_paths.extend(paths)
2259         contains_louter = False
2260         # Trim and operate only on tables that were generated for
2261         # the lookup part of the query. That is, avoid trimming
2262         # joins generated for F() expressions.
2263         lookup_tables = [
2264             t for t in self.alias_map
2265             if t in self._lookup_joins or t == self.base_table
2266         ]
2267         for trimmed_paths, path in enumerate(all_paths):
2268             if path.m2m:
2269                 break
2270             if self.alias_map[lookup_tables[trimmed_paths + 1]].join_type == LOUTER:
2271                 contains_louter = True
2272             alias = lookup_tables[trimmed_paths]
2273             self.unref_alias(alias)
2274         # The path.join_field is a Rel, lets get the other side's field
2275         join_field = path.join_field.field
2276         # Build the filter prefix.
2277         paths_in_prefix = trimmed_paths
2278         trimmed_prefix = []
2279         for name, path in names_with_path:
2280             if paths_in_prefix - len(path) < 0:
2281                 break
2282             trimmed_prefix.append(name)
2283             paths_in_prefix -= len(path)
2284         trimmed_prefix.append(
2285             join_field.foreign_related_fields[0].name)
2286         trimmed_prefix = LOOKUP_SEP.join(trimmed_prefix)
2287         # Lets still see if we can trim the first join from the inner query
2288         # (that is, self). We can't do this for:
2289         # - LEFT JOINs because we would miss those rows that have nothing on
2290         #   the outer side,
2291         # - INNER JOINs from filtered relations because we would miss their
2292         #   filters.
2293         first_join = self.alias_map[lookup_tables[trimmed_paths + 1]]
2294         if first_join.join_type != LOUTER and not first_join.filtered_relation:
2295             select_fields = [r[0] for r in join_field.related_fields]
2296             select_alias = lookup_tables[trimmed_paths + 1]
2297             self.unref_alias(lookup_tables[trimmed_paths])
2298             extra_restriction = join_field.get_extra_restriction(
2299                 self.where_class, None, lookup_tables[trimmed_paths + 1])
2300             if extra_restriction:
2301                 self.where.add(extra_restriction, AND)
2302         else:
2303             # TODO: It might be possible to trim more joins from the start of the
2304             # inner query if it happens to have a longer join chain containing the
2305             # values in select_fields. Lets punt this one for now.
2306             select_fields = [r[1] for r in join_field.related_fields]
2307             select_alias = lookup_tables[trimmed_paths]
2308         # The found starting point is likely a Join instead of a BaseTable reference.
2309         # But the first entry in the query's FROM clause must not be a JOIN.
2310         for table in self.alias_map:
2311             if self.alias_refcount[table] > 0:
2312                 self.alias_map[table] = BaseTable(self.alias_map[table].table_name, table)
2313                 break
2314         self.set_select([f.get_col(select_alias) for f in select_fields])
2315         return trimmed_prefix, contains_louter
2316 
2317     def is_nullable(self, field):
2318         """
2319         Check if the given field should be treated as nullable.
2320 
2321         Some backends treat '' as null and Django treats such fields as
2322         nullable for those backends. In such situations field.null can be
2323         False even if we should treat the field as nullable.
2324         """
2325         # We need to use DEFAULT_DB_ALIAS here, as QuerySet does not have
2326         # (nor should it have) knowledge of which connection is going to be
2327         # used. The proper fix would be to defer all decisions where
2328         # is_nullable() is needed to the compiler stage, but that is not easy
2329         # to do currently.
2330         return (
2331             connections[DEFAULT_DB_ALIAS].features.interprets_empty_strings_as_nulls and
2332             field.empty_strings_allowed
2333         ) or field.null

</code><intended_behavior>This class provides additional context to the issue.</intended_behavior>]
2025-10-15 19:02:47.846 | INFO     | Overall retry 0 succeeded; ending workflow
2025-10-15 19:02:47.846 | INFO     | Search-only: skipping patch selection
2025-10-15 19:02:48.026 | INFO     | Task django__django-14430 completed successfully.
2025-10-15 19:02:48.027 | INFO     | No patch generated. You can try running ACR again.
