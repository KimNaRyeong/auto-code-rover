[
    {
        "rel_file_path": "src/_pytest/runner.py",
        "abs_file_path": "/home/kimnal0/auto-code-rover/SWE-bench/testbed/pytest-dev__pytest/setup_pytest-dev__pytest__5.4/src/_pytest/runner.py",
        "start": 1,
        "end": 411,
        "class_name": null,
        "method_name": null,
        "code": "1 \"\"\" basic collect and runtest protocol implementations \"\"\"\n2 import bdb\n3 import os\n4 import sys\n5 from time import perf_counter  # Intentionally not `import time` to avoid being\n6 from time import time  # affected by tests which monkeypatch `time` (issue #185).\n7 from typing import Callable\n8 from typing import Dict\n9 from typing import List\n10 from typing import Optional\n11 from typing import Tuple\n12 \n13 import attr\n14 \n15 from .reports import CollectErrorRepr\n16 from .reports import CollectReport\n17 from .reports import TestReport\n18 from _pytest._code.code import ExceptionChainRepr\n19 from _pytest._code.code import ExceptionInfo\n20 from _pytest.compat import TYPE_CHECKING\n21 from _pytest.nodes import Collector\n22 from _pytest.nodes import Node\n23 from _pytest.outcomes import Exit\n24 from _pytest.outcomes import Skipped\n25 from _pytest.outcomes import TEST_OUTCOME\n26 \n27 if TYPE_CHECKING:\n28     from typing import Type\n29     from typing_extensions import Literal\n30 \n31 #\n32 # pytest plugin hooks\n33 \n34 \n35 def pytest_addoption(parser):\n36     group = parser.getgroup(\"terminal reporting\", \"reporting\", after=\"general\")\n37     group.addoption(\n38         \"--durations\",\n39         action=\"store\",\n40         type=int,\n41         default=None,\n42         metavar=\"N\",\n43         help=\"show N slowest setup/test durations (N=0 for all).\",\n44     )\n45 \n46 \n47 def pytest_terminal_summary(terminalreporter):\n48     durations = terminalreporter.config.option.durations\n49     verbose = terminalreporter.config.getvalue(\"verbose\")\n50     if durations is None:\n51         return\n52     tr = terminalreporter\n53     dlist = []\n54     for replist in tr.stats.values():\n55         for rep in replist:\n56             if hasattr(rep, \"duration\"):\n57                 dlist.append(rep)\n58     if not dlist:\n59         return\n60     dlist.sort(key=lambda x: x.duration)\n61     dlist.reverse()\n62     if not durations:\n63         tr.write_sep(\"=\", \"slowest durations\")\n64     else:\n65         tr.write_sep(\"=\", \"slowest %s durations\" % durations)\n66         dlist = dlist[:durations]\n67 \n68     for i, rep in enumerate(dlist):\n69         if verbose < 2 and rep.duration < 0.005:\n70             tr.write_line(\"\")\n71             tr.write_line(\n72                 \"(%s durations < 0.005s hidden.  Use -vv to show these durations.)\"\n73                 % (len(dlist) - i)\n74             )\n75             break\n76         tr.write_line(\"{:02.2f}s {:<8} {}\".format(rep.duration, rep.when, rep.nodeid))\n77 \n78 \n79 def pytest_sessionstart(session):\n80     session._setupstate = SetupState()\n81 \n82 \n83 def pytest_sessionfinish(session):\n84     session._setupstate.teardown_all()\n85 \n86 \n87 def pytest_runtest_protocol(item, nextitem):\n88     item.ihook.pytest_runtest_logstart(nodeid=item.nodeid, location=item.location)\n89     runtestprotocol(item, nextitem=nextitem)\n90     item.ihook.pytest_runtest_logfinish(nodeid=item.nodeid, location=item.location)\n91     return True\n92 \n93 \n94 def runtestprotocol(item, log=True, nextitem=None):\n95     hasrequest = hasattr(item, \"_request\")\n96     if hasrequest and not item._request:\n97         item._initrequest()\n98     rep = call_and_report(item, \"setup\", log)\n99     reports = [rep]\n100     if rep.passed:\n101         if item.config.getoption(\"setupshow\", False):\n102             show_test_item(item)\n103         if not item.config.getoption(\"setuponly\", False):\n104             reports.append(call_and_report(item, \"call\", log))\n105     reports.append(call_and_report(item, \"teardown\", log, nextitem=nextitem))\n106     # after all teardown hooks have been called\n107     # want funcargs and request info to go away\n108     if hasrequest:\n109         item._request = False\n110         item.funcargs = None\n111     return reports\n112 \n113 \n114 def show_test_item(item):\n115     \"\"\"Show test function, parameters and the fixtures of the test item.\"\"\"\n116     tw = item.config.get_terminal_writer()\n117     tw.line()\n118     tw.write(\" \" * 8)\n119     tw.write(item.nodeid)\n120     used_fixtures = sorted(getattr(item, \"fixturenames\", []))\n121     if used_fixtures:\n122         tw.write(\" (fixtures used: {})\".format(\", \".join(used_fixtures)))\n123 \n124 \n125 def pytest_runtest_setup(item):\n126     _update_current_test_var(item, \"setup\")\n127     item.session._setupstate.prepare(item)\n128 \n129 \n130 def pytest_runtest_call(item):\n131     _update_current_test_var(item, \"call\")\n132     try:\n133         del sys.last_type\n134         del sys.last_value\n135         del sys.last_traceback\n136     except AttributeError:\n137         pass\n138     try:\n139         item.runtest()\n140     except Exception as e:\n141         # Store trace info to allow postmortem debugging\n142         sys.last_type = type(e)\n143         sys.last_value = e\n144         assert e.__traceback__ is not None\n145         # Skip *this* frame\n146         sys.last_traceback = e.__traceback__.tb_next\n147         raise e\n148 \n149 \n150 def pytest_runtest_teardown(item, nextitem):\n151     _update_current_test_var(item, \"teardown\")\n152     item.session._setupstate.teardown_exact(item, nextitem)\n153     _update_current_test_var(item, None)\n154 \n155 \n156 def _update_current_test_var(item, when):\n157     \"\"\"\n158     Update :envvar:`PYTEST_CURRENT_TEST` to reflect the current item and stage.\n159 \n160     If ``when`` is None, delete ``PYTEST_CURRENT_TEST`` from the environment.\n161     \"\"\"\n162     var_name = \"PYTEST_CURRENT_TEST\"\n163     if when:\n164         value = \"{} ({})\".format(item.nodeid, when)\n165         # don't allow null bytes on environment variables (see #2644, #2957)\n166         value = value.replace(\"\\x00\", \"(null)\")\n167         os.environ[var_name] = value\n168     else:\n169         os.environ.pop(var_name)\n170 \n171 \n172 def pytest_report_teststatus(report):\n173     if report.when in (\"setup\", \"teardown\"):\n174         if report.failed:\n175             #      category, shortletter, verbose-word\n176             return \"error\", \"E\", \"ERROR\"\n177         elif report.skipped:\n178             return \"skipped\", \"s\", \"SKIPPED\"\n179         else:\n180             return \"\", \"\", \"\"\n181 \n182 \n183 #\n184 # Implementation\n185 \n186 \n187 def call_and_report(\n188     item, when: \"Literal['setup', 'call', 'teardown']\", log=True, **kwds\n189 ):\n190     call = call_runtest_hook(item, when, **kwds)\n191     hook = item.ihook\n192     report = hook.pytest_runtest_makereport(item=item, call=call)\n193     if log:\n194         hook.pytest_runtest_logreport(report=report)\n195     if check_interactive_exception(call, report):\n196         hook.pytest_exception_interact(node=item, call=call, report=report)\n197     return report\n198 \n199 \n200 def check_interactive_exception(call, report):\n201     return call.excinfo and not (\n202         hasattr(report, \"wasxfail\")\n203         or call.excinfo.errisinstance(Skipped)\n204         or call.excinfo.errisinstance(bdb.BdbQuit)\n205     )\n206 \n207 \n208 def call_runtest_hook(item, when: \"Literal['setup', 'call', 'teardown']\", **kwds):\n209     if when == \"setup\":\n210         ihook = item.ihook.pytest_runtest_setup\n211     elif when == \"call\":\n212         ihook = item.ihook.pytest_runtest_call\n213     elif when == \"teardown\":\n214         ihook = item.ihook.pytest_runtest_teardown\n215     else:\n216         assert False, \"Unhandled runtest hook case: {}\".format(when)\n217     reraise = (Exit,)  # type: Tuple[Type[BaseException], ...]\n218     if not item.config.getoption(\"usepdb\", False):\n219         reraise += (KeyboardInterrupt,)\n220     return CallInfo.from_call(\n221         lambda: ihook(item=item, **kwds), when=when, reraise=reraise\n222     )\n223 \n224 \n225 @attr.s(repr=False)\n226 class CallInfo:\n227     \"\"\" Result/Exception info a function invocation.\n228 \n229     :param result: The return value of the call, if it didn't raise. Can only be accessed\n230         if excinfo is None.\n231     :param Optional[ExceptionInfo] excinfo: The captured exception of the call, if it raised.\n232     :param float start: The system time when the call started, in seconds since the epoch.\n233     :param float stop: The system time when the call ended, in seconds since the epoch.\n234     :param float duration: The call duration, in seconds.\n235     :param str when: The context of invocation: \"setup\", \"call\", \"teardown\", ...\n236     \"\"\"\n237 \n238     _result = attr.ib()\n239     excinfo = attr.ib(type=Optional[ExceptionInfo])\n240     start = attr.ib(type=float)\n241     stop = attr.ib(type=float)\n242     duration = attr.ib(type=float)\n243     when = attr.ib(type=str)\n244 \n245     @property\n246     def result(self):\n247         if self.excinfo is not None:\n248             raise AttributeError(\"{!r} has no valid result\".format(self))\n249         return self._result\n250 \n251     @classmethod\n252     def from_call(cls, func, when, reraise=None) -> \"CallInfo\":\n253         #: context of invocation: one of \"setup\", \"call\",\n254         #: \"teardown\", \"memocollect\"\n255         excinfo = None\n256         start = time()\n257         precise_start = perf_counter()\n258         try:\n259             result = func()\n260         except:  # noqa\n261             excinfo = ExceptionInfo.from_current()\n262             if reraise is not None and excinfo.errisinstance(reraise):\n263                 raise\n264             result = None\n265         # use the perf counter\n266         precise_stop = perf_counter()\n267         duration = precise_stop - precise_start\n268         stop = time()\n269         return cls(\n270             start=start,\n271             stop=stop,\n272             duration=duration,\n273             when=when,\n274             result=result,\n275             excinfo=excinfo,\n276         )\n277 \n278     def __repr__(self):\n279         if self.excinfo is None:\n280             return \"<CallInfo when={!r} result: {!r}>\".format(self.when, self._result)\n281         return \"<CallInfo when={!r} excinfo={!r}>\".format(self.when, self.excinfo)\n282 \n283 \n284 def pytest_runtest_makereport(item, call):\n285     return TestReport.from_item_and_call(item, call)\n286 \n287 \n288 def pytest_make_collect_report(collector: Collector) -> CollectReport:\n289     call = CallInfo.from_call(lambda: list(collector.collect()), \"collect\")\n290     longrepr = None\n291     if not call.excinfo:\n292         outcome = \"passed\"\n293     else:\n294         skip_exceptions = [Skipped]\n295         unittest = sys.modules.get(\"unittest\")\n296         if unittest is not None:\n297             # Type ignored because unittest is loaded dynamically.\n298             skip_exceptions.append(unittest.SkipTest)  # type: ignore\n299         if call.excinfo.errisinstance(tuple(skip_exceptions)):\n300             outcome = \"skipped\"\n301             r_ = collector._repr_failure_py(call.excinfo, \"line\")\n302             assert isinstance(r_, ExceptionChainRepr), repr(r_)\n303             r = r_.reprcrash\n304             assert r\n305             longrepr = (str(r.path), r.lineno, r.message)\n306         else:\n307             outcome = \"failed\"\n308             errorinfo = collector.repr_failure(call.excinfo)\n309             if not hasattr(errorinfo, \"toterminal\"):\n310                 errorinfo = CollectErrorRepr(errorinfo)\n311             longrepr = errorinfo\n312     rep = CollectReport(\n313         collector.nodeid, outcome, longrepr, getattr(call, \"result\", None)\n314     )\n315     rep.call = call  # type: ignore # see collect_one_node\n316     return rep\n317 \n318 \n319 class SetupState:\n320     \"\"\" shared state for setting up/tearing down test items or collectors. \"\"\"\n321 \n322     def __init__(self):\n323         self.stack = []  # type: List[Node]\n324         self._finalizers = {}  # type: Dict[Node, List[Callable[[], None]]]\n325 \n326     def addfinalizer(self, finalizer, colitem):\n327         \"\"\" attach a finalizer to the given colitem. \"\"\"\n328         assert colitem and not isinstance(colitem, tuple)\n329         assert callable(finalizer)\n330         # assert colitem in self.stack  # some unit tests don't setup stack :/\n331         self._finalizers.setdefault(colitem, []).append(finalizer)\n332 \n333     def _pop_and_teardown(self):\n334         colitem = self.stack.pop()\n335         self._teardown_with_finalization(colitem)\n336 \n337     def _callfinalizers(self, colitem):\n338         finalizers = self._finalizers.pop(colitem, None)\n339         exc = None\n340         while finalizers:\n341             fin = finalizers.pop()\n342             try:\n343                 fin()\n344             except TEST_OUTCOME as e:\n345                 # XXX Only first exception will be seen by user,\n346                 #     ideally all should be reported.\n347                 if exc is None:\n348                     exc = e\n349         if exc:\n350             raise exc\n351 \n352     def _teardown_with_finalization(self, colitem):\n353         self._callfinalizers(colitem)\n354         colitem.teardown()\n355         for colitem in self._finalizers:\n356             assert colitem in self.stack\n357 \n358     def teardown_all(self):\n359         while self.stack:\n360             self._pop_and_teardown()\n361         for key in list(self._finalizers):\n362             self._teardown_with_finalization(key)\n363         assert not self._finalizers\n364 \n365     def teardown_exact(self, item, nextitem):\n366         needed_collectors = nextitem and nextitem.listchain() or []\n367         self._teardown_towards(needed_collectors)\n368 \n369     def _teardown_towards(self, needed_collectors):\n370         exc = None\n371         while self.stack:\n372             if self.stack == needed_collectors[: len(self.stack)]:\n373                 break\n374             try:\n375                 self._pop_and_teardown()\n376             except TEST_OUTCOME as e:\n377                 # XXX Only first exception will be seen by user,\n378                 #     ideally all should be reported.\n379                 if exc is None:\n380                     exc = e\n381         if exc:\n382             raise exc\n383 \n384     def prepare(self, colitem):\n385         \"\"\" setup objects along the collector chain to the test-method\n386             and teardown previously setup objects.\"\"\"\n387         needed_collectors = colitem.listchain()\n388         self._teardown_towards(needed_collectors)\n389 \n390         # check if the last collection node has raised an error\n391         for col in self.stack:\n392             if hasattr(col, \"_prepare_exc\"):\n393                 exc = col._prepare_exc\n394                 raise exc\n395         for col in needed_collectors[len(self.stack) :]:\n396             self.stack.append(col)\n397             try:\n398                 col.setup()\n399             except TEST_OUTCOME as e:\n400                 col._prepare_exc = e\n401                 raise e\n402 \n403 \n404 def collect_one_node(collector):\n405     ihook = collector.ihook\n406     ihook.pytest_collectstart(collector=collector)\n407     rep = ihook.pytest_make_collect_report(collector=collector)\n408     call = rep.__dict__.pop(\"call\", None)\n409     if call and check_interactive_exception(call, rep):\n410         ihook.pytest_exception_interact(node=collector, call=call, report=rep)\n411     return rep\n",
        "intended_behavior": "This file likely contains the logic for executing tests and handling their results, including skipped tests. The intended behavior here would be to ensure that when a skip report is generated, the path for the skipped test file is correctly computed relative to the directory where `pytest` is invoked. This would involve checking the logic that formats the path in the skip report to make sure it adjusts paths based on the invocation context. The solution should ensure that if a test is skipped, and its path is above the directory from which `pytest` was invoked, the displayed path in the report accurately reflects the relative location, using `../` prefixes as necessary. This functionality should preserve all existing behaviors regarding how test results are reported and only alter the path formatting for better accuracy in this specific scenario."
    }
]